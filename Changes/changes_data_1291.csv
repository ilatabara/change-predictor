id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fpython-keystoneclient~master~I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b,openstack/python-keystoneclient,master,I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b,Unversioned endpoints in service catalog,MERGED,2014-02-19 05:37:11.000000000,2014-06-25 00:12:15.000000000,2014-06-25 00:12:15.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 616}, {'_account_id': 792}, {'_account_id': 970}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1916}, {'_account_id': 1994}, {'_account_id': 2218}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5638}, {'_account_id': 5707}, {'_account_id': 6159}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6928}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-02-19 05:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/bf95c5eb865270d7e68b80f68882599bb79cfb7f', 'message': 'Unversioned endpoints in service catalog\n\nAlways lookup the endpoint received from a service catalog and determine\nthe real endpoint to use from there.\n\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 2, 'created': '2014-04-25 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/51c545d7b03c15eb942a0797ab55f0ec40b918b3', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 3, 'created': '2014-04-28 02:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9995cfa74bf2f88bfee432db0fc7a74d0421101c', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 4, 'created': '2014-05-02 00:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7dc16f7949b60ec2ac082f86d4a3e427a3a931fa', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 5, 'created': '2014-05-06 00:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8f1ca1d2738ea0eddfadec74c7ae24943e7ee92e', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 6, 'created': '2014-06-10 22:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b10170d21248c823604904cf9565d4ec2907c6f5', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 7, 'created': '2014-06-12 03:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1c890395d27c42c1eb9e5158c7567f45af090bb5', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}, {'number': 8, 'created': '2014-06-22 21:22:13.000000000', 'files': ['keystoneclient/tests/auth/test_identity_common.py', 'keystoneclient/auth/identity/base.py', 'keystoneclient/httpclient.py', 'keystoneclient/_discover.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/11336acf8868a2709cb583af9bbd8a1c442d137f', 'message': 'Unversioned endpoints in service catalog\n\nIf you pass a version number to the endpoint_filter then an identity\nplugin will make a request to the URL in the service catalog and find an\nappropriate URL for the requested version.\n\nIt caches the response to each of the discovery queries so that it\nshould only query once per URL.\n\nThis will only work for applications that create session objects\ndirectly as the legacy model does not use the get_endpoint features of\nan identity plugin.\n\nThis change showed an inconsistency in the docstrings between discovery\nand the usage of discovery so the docstring was fixed.\n\nBlueprint: endpoint-version-query\nChange-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b\n'}]",54,74599,11336acf8868a2709cb583af9bbd8a1c442d137f,55,24,8,7191,,,0,"Unversioned endpoints in service catalog

If you pass a version number to the endpoint_filter then an identity
plugin will make a request to the URL in the service catalog and find an
appropriate URL for the requested version.

It caches the response to each of the discovery queries so that it
should only query once per URL.

This will only work for applications that create session objects
directly as the legacy model does not use the get_endpoint features of
an identity plugin.

This change showed an inconsistency in the docstrings between discovery
and the usage of discovery so the docstring was fixed.

Blueprint: endpoint-version-query
Change-Id: I277f2f6ad6c8cd44f1a9c06cf07d62bc8f8b383b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/99/74599/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/baseclient.py', 'keystoneclient/discover.py', 'keystoneclient/tests/auth/test_identity_v2.py', 'keystoneclient/auth/identity/base.py', 'keystoneclient/tests/auth/test_identity_v3.py', 'keystoneclient/httpclient.py', 'keystoneclient/session.py']",7,bf95c5eb865270d7e68b80f68882599bb79cfb7f,bp/endpoint-version-query," version=None, unstable=False, **kwargs): region_name=region_name, version=version, unstable=unstable)", **kwargs): region_name=region_name),234,18
openstack%2Fnova~master~I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5,openstack/nova,master,I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5,Standardize logging for nova.virt.libvirt,MERGED,2014-05-22 08:35:47.000000000,2014-06-25 00:07:40.000000000,2014-06-24 15:52:52.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-22 08:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39cba812f4bd6a1a872eebb64ab9fdcdba0641a2', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for warning and info levels\n - remove translation of debug logs\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 2, 'created': '2014-05-23 15:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1b94ef22efe1fb6b50a05f2b4fdc9e7e56f9ad7', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for warning and info levels\n - remove translation of debug logs\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 3, 'created': '2014-05-27 12:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d20aa90f85f4925b5ae1d304c516a03892b450fb', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for warning and info levels\n - remove translation of debug logs\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 4, 'created': '2014-06-03 20:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7e7ec1268014ca55a77a80c16871135693e6b7a', 'message': 'Log cleanups for nova.virt.libvirt.firewall\n\nMore log cleanups:\n - add log hints for warning and info levels\n - remove translation of debug logs\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 5, 'created': '2014-06-16 21:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7732ff6caefd38862a5471c3ac41ac0b53a751d', 'message': 'Log cleanups for nova.virt.libvirt.firewall\n\nMore log cleanups:\n - add log hints for warning and info levels\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 6, 'created': '2014-06-17 21:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e334f74dfa4cf21a5a318755d9d2e19fc477a6b3', 'message': 'Log cleanups for nova.virt.libvirt.firewall\n\nMore log cleanups:\n - add log hints for warning and info levels\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 7, 'created': '2014-06-19 03:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12a4921b26dea108ac38e53afd66439395293b88', 'message': 'Log cleanups for nova.virt.libvirt.firewall\n\nMore log cleanups:\n - add log hints for warning and info levels\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 8, 'created': '2014-06-23 05:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e27f939d00f69eff3304e6c14c491033d0594b20', 'message': 'Log cleanups for nova.virt.libvirt.{vif,firewall}\n\nMore log cleanups:\n - add log hints for warning, error and info levels\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n'}, {'number': 9, 'created': '2014-06-24 00:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d550f5501c8613ab17cce9aea074cc7c45f4abc', 'message': ""Standardize logging for nova.virt.libvirt\n\n - add log translation hints for warning, error and info levels\n - remove use of % as a string formatter, use the log functionality\n   instead\n - move from LOG.warning to LOG.warn\n\nLog translation is motivated by oslo's move to prioritized\ntranslation of strings, as documented at\nhttps://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n""}, {'number': 10, 'created': '2014-06-24 11:35:42.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py', 'nova/virt/libvirt/volume.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/libvirt/firewall.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2abb92ba049df6ee1f566a050f0044e5c2b50cdd', 'message': ""Standardize logging for nova.virt.libvirt\n\n - add log translation hints for warning, error and info levels\n - remove use of % as a string formatter, use the log functionality\n   instead\n - move from LOG.warning to LOG.warn\n\nLog translation is motivated by oslo's move to prioritized\ntranslation of strings, as documented at\nhttps://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\n\nChange-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5\n""}]",5,94797,2abb92ba049df6ee1f566a050f0044e5c2b50cdd,105,12,10,2271,,,0,"Standardize logging for nova.virt.libvirt

 - add log translation hints for warning, error and info levels
 - remove use of % as a string formatter, use the log functionality
   instead
 - move from LOG.warning to LOG.warn

Log translation is motivated by oslo's move to prioritized
translation of strings, as documented at
https://wiki.openstack.org/wiki/LoggingStandards#Log_Translation

Change-Id: I61ab8dbcdb73795538ea9d60c0c9d00c425ee1a5
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/94797/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/firewall.py'],1,39cba812f4bd6a1a872eebb64ab9fdcdba0641a2,log-hints,"from nova.openstack.common.gettextutils import _LI from nova.openstack.common.gettextutils import _LW LOG.warn(_LW(""Libvirt module could not be loaded. "" ""NWFilterFirewall will not work correctly."")) LOG.info(_LI('Called setup_basic_filtering in nwfilter'), LOG.info(_LI('Ensuring static filters'), instance=instance) LOG.debug('The nwfilter(%s) is not found.', LOG.debug('The nwfilter(%(instance_filter_name)s) for' '%(name)s is not found.', LOG.debug('iptables firewall: Setup Basic Filtering', LOG.info(_LI('Attempted to unfilter instance which is not ' 'filtered'), instance=instance)","from nova.openstack.common.gettextutils import _ LOG.warn(_(""Libvirt module could not be loaded. "" ""NWFilterFirewall will not work correctly."")) LOG.info(_('Called setup_basic_filtering in nwfilter'), LOG.info(_('Ensuring static filters'), instance=instance) LOG.debug(_('The nwfilter(%s) is not found.'), LOG.debug(_('The nwfilter(%(instance_filter_name)s) for' '%(name)s is not found.'), LOG.debug(_('iptables firewall: Setup Basic Filtering'), LOG.info(_('Attempted to unfilter instance which is not ' 'filtered'), instance=instance)",12,11
openstack%2Ftempest~master~I6bfd93bb4a858923e654391fa556c99ac93c14bf,openstack/tempest,master,I6bfd93bb4a858923e654391fa556c99ac93c14bf,Add Ironic GET validate-node API test,ABANDONED,2014-04-25 04:17:07.000000000,2014-06-25 00:06:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 6773}, {'_account_id': 7428}, {'_account_id': 7882}, {'_account_id': 8824}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-25 04:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a8b73d6fe5e9b5d2ded551c82064190e64159991', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 2, 'created': '2014-04-28 07:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/95f858d64cbbd220f0052e8928115e6eef4a89a1', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 3, 'created': '2014-05-07 11:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5958777af1d6abc799643cf1520874eb4a98bef9', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 4, 'created': '2014-05-27 06:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ef8cfa75b2f10d7ab2e0a0ef572029f63a4ed41', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 5, 'created': '2014-06-20 04:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ada1daaa5fedb24f6c6db8feec26b7c15f4092d5', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 6, 'created': '2014-06-20 09:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e8bec4f97b5bdbaabb6524506e0095fe7e658ba', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}, {'number': 7, 'created': '2014-06-24 09:23:03.000000000', 'files': ['tempest/api/baremetal/test_nodes.py', 'tempest/services/baremetal/v1/base_v1.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7854d1c05eefd27d179143e959bb063d3c3d458c', 'message': 'Add Ironic GET validate-node API test\n\nThis patch adds Ironic GET validate-node API test.\n\nPartially implements blueprint missing-baremetal-api-test\n\nChange-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf\n'}]",13,90282,7854d1c05eefd27d179143e959bb063d3c3d458c,91,10,7,7882,,,0,"Add Ironic GET validate-node API test

This patch adds Ironic GET validate-node API test.

Partially implements blueprint missing-baremetal-api-test

Change-Id: I6bfd93bb4a858923e654391fa556c99ac93c14bf
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/90282/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/baremetal/test_nodes.py', 'tempest/services/baremetal/v1/base_v1.py']",2,a8b73d6fe5e9b5d2ded551c82064190e64159991,bp/missing-baremetal-api-test," @base.handle_errors def validate_node(self, uuid): """""" Validate the driver interfaces. :param uuid: The unique identifier of the port. """""" return self._list_request('nodes/%s/validate' % uuid)",,27,0
openstack%2Fnova~master~Id35a969b92fb92487c8b169ff0729ab1851d30f1,openstack/nova,master,Id35a969b92fb92487c8b169ff0729ab1851d30f1,Fix log debug statement in compute manager,MERGED,2014-06-05 05:27:10.000000000,2014-06-25 00:04:26.000000000,2014-06-24 15:09:25.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-05 05:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37af1d2785428a3293355a04d0558e48db9ec4ac', 'message': ""Fix log debug statement in compute manager\n\nThe patch does the following:\n1. Ensures that there are no translations with log debug messages\n2. Uses ',' instead of '%' with the parameters passed to the debug\n   message\n3. Aligns the debug messages\n\nChange-Id: Id35a969b92fb92487c8b169ff0729ab1851d30f1\n""}, {'number': 2, 'created': '2014-06-24 11:32:33.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d0bc5ac6449d979ec7a83c29b900dc85b364a18a', 'message': ""Fix log debug statement in compute manager\n\nThe patch does the following:\n1. Ensures that there are no translations with log debug messages\n2. Uses ',' instead of '%' with the parameters passed to the debug\n   message\n3. Aligns the debug messages\n\nTrivialFix\n\nChange-Id: Id35a969b92fb92487c8b169ff0729ab1851d30f1\n""}]",0,98032,d0bc5ac6449d979ec7a83c29b900dc85b364a18a,30,10,2,1653,,,0,"Fix log debug statement in compute manager

The patch does the following:
1. Ensures that there are no translations with log debug messages
2. Uses ',' instead of '%' with the parameters passed to the debug
   message
3. Aligns the debug messages

TrivialFix

Change-Id: Id35a969b92fb92487c8b169ff0729ab1851d30f1
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/98032/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,37af1d2785428a3293355a04d0558e48db9ec4ac,debug-manager," 'for instance %s.', LOG.debug(""Cleaning up image %s"", image_id, instance=instance) ""instance was probably deleted."", event) else: LOG.debug(""Ignoring event %s"", event) LOG.debug(""Re-scheduling %(method)s: attempt %(num)d"", {'method': scheduler_method.func_name, 'num': retry['num_attempts']}, instance_uuid=instance_uuid) msg = 'Instance disappeared before build.' msg = 'Instance disappeared during build.' LOG.debug(""terminating bdm %s"", bdm, ""for instance."", msg = 'Instance disappeared during snapshot' LOG.debug(""Going to confirm migration %s"", migration_id, context=context, instance=instance) 'because it is Building.', instance=inst) 'because it is being deleted.', instance=inst) 'because it has been migrated to another ' 'host.', instance=inst) 'because it is being deleted.', instance=inst) ""update."") 'add_aggregate_host') 'remove_aggregate_host') 'cleanup attempts', {'attempts': attempts, 'max': CONF.maximum_instance_delete_attempts}, instance=instance)"," 'for instance %s.' % LOG.debug(""Cleaning up image %s"" % image_id, instance=instance) ""instance was probably deleted."" % event) else: LOG.debug(""Ignoring event %s"" % event) LOG.debug(""Re-scheduling %(method)s: attempt %(num)d"" % {'method': scheduler_method.func_name, 'num': retry['num_attempts']}, instance_uuid=instance_uuid) msg = _('Instance disappeared before build.') msg = _('Instance disappeared during build.') LOG.debug(""terminating bdm %s"" % bdm, ""for instance."", msg = _(""Instance disappeared during snapshot"") LOG.debug(""Going to confirm migration %s"" % migration_id, context=context, instance=instance) 'because it is Building.', instance=inst) 'because it is being deleted.', instance=inst) 'because it has been migrated to another ' 'host.', instance=inst) 'because it is being deleted.', instance=inst) ""update."") 'add_aggregate_host') 'remove_aggregate_host') 'cleanup attempts', {'attempts': attempts, 'max': CONF.maximum_instance_delete_attempts}, instance=instance)",27,27
openstack%2Ffuel-library~master~I0b61c71effcf779801756968b8ed8b8cb93cb54b,openstack/fuel-library,master,I0b61c71effcf779801756968b8ed8b8cb93cb54b,Add link to /root/.cephdeploy.conf -> /etc/ceph/ceph.conf,MERGED,2014-06-24 23:06:56.000000000,2014-06-25 00:04:05.000000000,2014-06-24 23:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8829}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 23:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cb60b02034206d20636a3147adab428b87d3c21c', 'message': ""Add link to /root/.cephdeploy.conf -> /etc/ceph/ceph.conf\n\nceph-deploy requires that it's local config file (previously $(pwd)/ceph.conf)\nis exactly the same as /etc/ceph/ceph.conf on the system or --overwite-conf\nhas to be specified. Since we need to manupliate it and cant guarantee order\n from puppet / ruby we just link to two on the pirmary-controller to avoid\n the issue.\n\nAll addtl users of config should config pull with --overwite-conf and not have\n this issue.\n\nThe old link is left in place at this time to support older versions of ceph-deploy and can be removed in a later release.\n\nCloses-bug: #1333814\nChange-Id: I0b61c71effcf779801756968b8ed8b8cb93cb54b\n""}, {'number': 2, 'created': '2014-06-24 23:20:51.000000000', 'files': ['deployment/puppet/ceph/manifests/conf.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/eecd91cde59483e30397342cdf5ab7e77d95d9ac', 'message': ""Add link to /root/.cephdeploy.conf -> /etc/ceph/ceph.conf\n\nceph-deploy requires that its local config file (previously $(pwd)/ceph.conf)\nis exactly the same as /etc/ceph/ceph.conf on the system or --overwite-conf\nhas to be specified. Since we need to manipulate it and can't guarantee order\n from Puppet / Ruby we just link to two on the primary-controller to avoid\n the issue.\n\nAll additional users of config should config pull with --overwite-conf and\nnot have this issue.\n\nThe old link is left in place at this time to support older versions of\n ceph-deploy and can be removed in a later release.\n\nCloses-bug: #1333814\nChange-Id: I0b61c71effcf779801756968b8ed8b8cb93cb54b\n""}]",5,102381,eecd91cde59483e30397342cdf5ab7e77d95d9ac,22,4,2,8797,,,0,"Add link to /root/.cephdeploy.conf -> /etc/ceph/ceph.conf

ceph-deploy requires that its local config file (previously $(pwd)/ceph.conf)
is exactly the same as /etc/ceph/ceph.conf on the system or --overwite-conf
has to be specified. Since we need to manipulate it and can't guarantee order
 from Puppet / Ruby we just link to two on the primary-controller to avoid
 the issue.

All additional users of config should config pull with --overwite-conf and
not have this issue.

The old link is left in place at this time to support older versions of
 ceph-deploy and can be removed in a later release.

Closes-bug: #1333814
Change-Id: I0b61c71effcf779801756968b8ed8b8cb93cb54b
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/81/102381/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/ceph/manifests/conf.pp'],1,cb60b02034206d20636a3147adab428b87d3c21c,bug/1333814," # New in ceph-deploy >1.3 it uses ~/.cephdeploy.conf instead of # $(pwd)/ceph.conf file {'/root/.cephdeploy.conf': ensure => link, target => '/etc/ceph/ceph.conf' } File['/root/ceph.conf', '/root/.cephdeploy.conf'] -> File['/root/ceph.mon.keyring'] ->", File['/root/ceph.conf'] -> File['/root/ceph.mon.keyring'] ->,8,1
openstack%2Fironic~stable%2Ficehouse~Iab5eee131a59928346fc584f399617b4b9bdb031,openstack/ironic,stable/icehouse,Iab5eee131a59928346fc584f399617b4b9bdb031,Updated from global requirements,MERGED,2014-05-22 18:07:05.000000000,2014-06-25 00:01:20.000000000,2014-06-25 00:00:09.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-05-22 18:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4979c46c38b6d68c78d22640f512a1404595c8e9', 'message': 'Updated from global requirements\n\nChange-Id: Iab5eee131a59928346fc584f399617b4b9bdb031\n'}, {'number': 2, 'created': '2014-06-22 15:25:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/798ea65a23b625d849636bd260681ec5b51682ed', 'message': 'Updated from global requirements\n\nChange-Id: Iab5eee131a59928346fc584f399617b4b9bdb031\n'}]",0,94965,798ea65a23b625d849636bd260681ec5b51682ed,26,7,2,11131,,,0,"Updated from global requirements

Change-Id: Iab5eee131a59928346fc584f399617b4b9bdb031
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/94965/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4979c46c38b6d68c78d22640f512a1404595c8e9,openstack/requirements,six>=1.6.0,six>=1.5.2,1,1
openstack%2Fpython-heatclient~master~Ie5e2307564f578ec13ecf4e5fb688bfa6c5bf556,openstack/python-heatclient,master,Ie5e2307564f578ec13ecf4e5fb688bfa6c5bf556,Updated from global requirements,ABANDONED,2014-06-24 22:04:49.000000000,2014-06-24 23:48:36.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 9536}]","[{'number': 1, 'created': '2014-06-24 22:04:49.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ae8beb39eead05a233507977043d42557d5b541a', 'message': 'Updated from global requirements\n\nChange-Id: Ie5e2307564f578ec13ecf4e5fb688bfa6c5bf556\nCloses-Bug: #1334026\n'}]",0,102364,ae8beb39eead05a233507977043d42557d5b541a,6,3,1,9536,,,0,"Updated from global requirements

Change-Id: Ie5e2307564f578ec13ecf4e5fb688bfa6c5bf556
Closes-Bug: #1334026
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/64/102364/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,ae8beb39eead05a233507977043d42557d5b541a,bug/1334026,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,8,0
openstack%2Fpython-swiftclient~master~I40fb71b83e0e81c29296ae65f68e6f813735efba,openstack/python-swiftclient,master,I40fb71b83e0e81c29296ae65f68e6f813735efba,Updated from global requirements,ABANDONED,2014-06-24 22:08:40.000000000,2014-06-24 23:45:32.000000000,,"[{'_account_id': 3}, {'_account_id': 9536}]","[{'number': 1, 'created': '2014-06-24 22:08:40.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/01a891b9586f18420b203fe786701400be8d1d30', 'message': 'Updated from global requirements\n\nChange-Id: I40fb71b83e0e81c29296ae65f68e6f813735efba\nCloses-Bug: #1334028\n'}]",0,102365,01a891b9586f18420b203fe786701400be8d1d30,5,2,1,9536,,,0,"Updated from global requirements

Change-Id: I40fb71b83e0e81c29296ae65f68e6f813735efba
Closes-Bug: #1334028
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/65/102365/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,01a891b9586f18420b203fe786701400be8d1d30,bug/1334028,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,8,0
openstack%2Fswift~master~Ie6d388f067f5b096b0f96faef151120ba23c8748,openstack/swift,master,Ie6d388f067f5b096b0f96faef151120ba23c8748,Add Storage Policy support to Containers,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:28:22.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4362c830a063ecb7e081053bd9cb99aa5d716b1a', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b75a49a16552d909a7287d8ee2c4436ff0adff4b', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 3, 'created': '2014-05-29 14:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3d2e6e6470f5830f1575b23cf1b905e11dba1e1c', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 4, 'created': '2014-05-29 14:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/98ff15ea4ce0d2ba2e04c185184f742d18ff7122', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 5, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a8c736d7472e49517dd302622e75e1885287daa3', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 6, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ae977eae20ced6b93e644dc653870aca84dac633', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 7, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d0011c19f109fcd53a8920e408300873cd6a9fcf', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 8, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e1536f605f51eb2bb8423448a6d8752ba47fecfe', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 9, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/41574eced9d8f35dbac90d89de4996eee608bc41', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 10, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/920d7124d146f9414780ab8fdec2d461550f6fe0', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 11, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5727f5dcbf646e7db732d92ba936efe617d3b75b', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4c35dd063bb2194b9fb542201ca7f9643def49af', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d672c8f33c50a15d7dad397ad5f801c971c685be', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ba8ce04bf52e7cd14abf687e09d3b46864c3f8ad', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/container/auditor.py', 'swift/account/backend.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/unit/common/ring/test_ring.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/common/test_db.py', 'test/unit/container/test_updater.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/common/db.py', 'swift/container/server.py', 'test/unit/container/test_auditor.py', 'swift/container/backend.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4321bb0af6d7f7593ec507b20a519909055fd9f0', 'message': 'Add Storage Policy support to Containers\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only settable at\ncontainer creation time (PUT request), and cannot be changed without\ndeleting and recreating the container. This is because a container\'s\npolicy index will apply to all its objects, so changing a container\'s\npolicy index would require moving large amounts of object data\naround. If a user wants to change the policy for data in a container,\nthey must create a new container with the desired policy and move the\ndata over.\n\nKeep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nExpose Backend container info on deleted containers.\n\nInclude basic container info in backend headers on 404 responses from the\ncontainer server.  Default empty values are used as placeholders if the\ndatabase does not exist.\n\nSpecifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and\nthe X-Backend-Storage-Policy-Index value will be needed by the reconciler to\ndeal with reconciling out of order object writes in the face of recently\ndeleted containers.\n\n * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.\n * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.\n * Add ""status_changed_at"" key to the response from AccountBroker.get_info.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748\n'}]",56,96029,4321bb0af6d7f7593ec507b20a519909055fd9f0,78,12,15,1179,,,0,"Add Storage Policy support to Containers

Containers now have a storage policy index associated with them,
stored in the container_stat table. This index is only settable at
container creation time (PUT request), and cannot be changed without
deleting and recreating the container. This is because a container's
policy index will apply to all its objects, so changing a container's
policy index would require moving large amounts of object data
around. If a user wants to change the policy for data in a container,
they must create a new container with the desired policy and move the
data over.

Keep status_changed_at up-to-date with status changes.

In particular during container recreation and replication.

When a container-server receives a PUT for a deleted database an extra UPDATE
is issued against the container_stat table to notate the x-timestamp of the
request.

During replication if merge_timestamps causes a container's status to change
(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to
the current time.

Accurate reporting of status_changed_at is useful for container replication
forensics and allows resolution of ""set on create"" attributes like the
upcoming storage_policy_index.

Expose Backend container info on deleted containers.

Include basic container info in backend headers on 404 responses from the
container server.  Default empty values are used as placeholders if the
database does not exist.

Specifically the X-Backend-Status-Changed-At, X-Backend-DELETE-Timestamp and
the X-Backend-Storage-Policy-Index value will be needed by the reconciler to
deal with reconciling out of order object writes in the face of recently
deleted containers.

 * Add ""status_changed_at"" key to the response from ContainerBroker.get_info.
 * Add ""Status Timestamp"" field to swift.cli.info.print_db_info_metadata.
 * Add ""status_changed_at"" key to the response from AccountBroker.get_info.

DocImpact
Implements: blueprint storage-policies
Change-Id: Ie6d388f067f5b096b0f96faef151120ba23c8748
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/96029/13 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/db.py', 'swift/container/server.py', 'test/unit/__init__.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/common/test_db.py', 'test/unit/container/test_updater.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py']",11,4362c830a063ecb7e081053bd9cb99aa5d716b1a,bp/storage-policies,"from swift.common.storage_policy import POLICY_INDEX, POLICY, POLICIES # if a backend policy index is present in resp headers, translate it # here with the friendly policy name if POLICY_INDEX in res.headers: policy = POLICIES.get_by_index(res.headers[POLICY_INDEX]) if policy: res.headers[POLICY] = policy.name",,1851,253
openstack%2Ffuel-ostf~stable%2F4.1~I5fe84387e8e23fb918da2d4cc0bb3e9cf0fe02f8,openstack/fuel-ostf,stable/4.1,I5fe84387e8e23fb918da2d4cc0bb3e9cf0fe02f8,Allow retry on ping probe fail,MERGED,2014-06-24 14:29:05.000000000,2014-06-24 23:27:42.000000000,2014-06-24 23:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 14:29:05.000000000', 'files': ['fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/tests/sanity/test_sanity_infrastructure.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/f4f15b4d98459650c1945b0efc30290a619be824', 'message': 'Allow retry on ping probe fail\n\nPing retry was not run when ping command had finished with error code != 0.\nIt is fixed now. Number of packets to be received is decreased to 1.\n\nCloses-Bug: #1322102\n\nChange-Id: I5fe84387e8e23fb918da2d4cc0bb3e9cf0fe02f8\n'}]",0,102252,f4f15b4d98459650c1945b0efc30290a619be824,11,6,1,8392,,,0,"Allow retry on ping probe fail

Ping retry was not run when ping command had finished with error code != 0.
It is fixed now. Number of packets to be received is decreased to 1.

Closes-Bug: #1322102

Change-Id: I5fe84387e8e23fb918da2d4cc0bb3e9cf0fe02f8
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/52/102252/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/tests/sanity/test_sanity_infrastructure.py']",3,f4f15b4d98459650c1945b0efc30290a619be824,1322102-4_1," cmd = ""ping -q -c1 -w10 8.8.8.8"""," cmd = ""ping -q -c3 -w10 8.8.8.8 | grep 'received' |"" \ "" grep -v '0 received'""",3,11
openstack%2Fswift~master~I459f3ed97df516cb0c9294477c28729c30f48e09,openstack/swift,master,I459f3ed97df516cb0c9294477c28729c30f48e09,Add Storage Policy support to Object Server,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:27:11.000000000,,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e3a1130eae46b97c8f62b09d5678d78fac5f2f63', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/975d0d215cd2980cc8c8ec453282c3e13878b972', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/43f3fc1e59eeaed5a8986886b355ec0964422e6c', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c536a183f9c2a680282e62104da94d2f4a0b4928', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c3038b30255c927e7df23579567c9190bef0fd7d', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5a1723030736563b9c6726a9dd020dd2a7c452bc', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 7, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/27d1fbe484a871dca775ea4fb98335d29b19492c', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/54601d8921a3f214fef862a3dfc878ec4117594c', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cb1737866d8fb16fa08166dc671f17e4eb6360d1', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nContainers now have a storage policy index associated with them,\nstored in the container_stat table. This index is only at container\ncreation time, and cannot be changed without deleting and recreating\nthe container. This is because a container's policy index applies to\nall its objects, so changing a container's policy index would require\nmoving large amounts of object data around.  Thus, if it is desired to\nchange the policy for data in a container, the supported method would\nbe to create a new container with the desired policy and move the data\nover.\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b2019aba548858cc4f1a064136f689df8a0a7be3', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e502e09b7a44cffd4f6abe6bce71bfb1ae672f8', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7a8e8f9f64659b6799720aa76877ff0648787409', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/56dbdd86ca82a30d9c6f5fbb09598567f987f69e', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/obj/server.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/obj/test_server.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/obj/test_diskfile.py', 'swift/proxy/controllers/obj.py', 'test/unit/obj/test_updater.py', 'swift/proxy/server.py', 'test/unit/common/test_wsgi.py', 'test/unit/obj/test_auditor.py', 'swift/obj/updater.py', 'swift/common/request_helpers.py', 'swift/obj/diskfile.py', 'swift/proxy/controllers/base.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3824ff3df71975194fa1b050255c0da8c1acc598', 'message': ""Add Storage Policy support to Object Server\n\nObjects now have a storage policy index associated with them as well;\nthis is determined by their filesystem path. Like before, objects in\npolicy 0 are in /srv/node/$disk/objects; this provides compatibility\non upgrade. (Recall that policy 0 is given to all existing data when a\ncluster is upgraded.) Objects in policy 1 are in\n/srv/node/$disk/objects-1, objects in policy 2 are in\n/srv/node/$disk/objects-2, and so on.\n\n * 'quarantined' dir already created 'objects' subdir so now there\n   will also be objects-N created at the same level\n\nThis commit does not address replicators, auditors, or updaters except\nwhere method signatures changed. They'll still work if your cluster\nhas only one storage policy, though.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I459f3ed97df516cb0c9294477c28729c30f48e09\n""}]",26,96030,3824ff3df71975194fa1b050255c0da8c1acc598,70,12,14,1179,,,0,"Add Storage Policy support to Object Server

Objects now have a storage policy index associated with them as well;
this is determined by their filesystem path. Like before, objects in
policy 0 are in /srv/node/$disk/objects; this provides compatibility
on upgrade. (Recall that policy 0 is given to all existing data when a
cluster is upgraded.) Objects in policy 1 are in
/srv/node/$disk/objects-1, objects in policy 2 are in
/srv/node/$disk/objects-2, and so on.

 * 'quarantined' dir already created 'objects' subdir so now there
   will also be objects-N created at the same level

This commit does not address replicators, auditors, or updaters except
where method signatures changed. They'll still work if your cluster
has only one storage policy, though.

DocImpact
Implements: blueprint storage-policies
Change-Id: I459f3ed97df516cb0c9294477c28729c30f48e09
",git fetch https://review.opendev.org/openstack/swift refs/changes/30/96030/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/functional/tests.py', 'test/unit/obj/test_server.py', 'test/unit/proxy/controllers/test_base.py', 'test/unit/obj/test_diskfile.py', 'swift/proxy/controllers/obj.py', 'test/unit/obj/test_updater.py', 'swift/proxy/server.py', 'test/unit/common/test_wsgi.py', 'test/unit/obj/test_auditor.py', 'swift/obj/updater.py', 'swift/common/request_helpers.py', 'swift/obj/diskfile.py', 'swift/proxy/controllers/base.py', 'test/unit/obj/test_ssync_receiver.py']",18,e3a1130eae46b97c8f62b09d5678d78fac5f2f63,bp/storage-policies," os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE), os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE), os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE),"," os.path.join(self.testdir, 'sda1', diskfile.DATADIR), os.path.join(self.testdir, 'sda1', diskfile.DATADIR), os.path.join(self.testdir, 'sda1', diskfile.DATADIR),",855,251
openstack%2Fswift~master~I66260e99fda37e97d6d2470971b6f811ee9e01be,openstack/swift,master,I66260e99fda37e97d6d2470971b6f811ee9e01be,Fix object-expirer for missing objects,ABANDONED,2014-06-06 20:39:43.000000000,2014-06-24 23:26:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c88cdf6c83c096e3166e7e958b739c5e12227e67', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 2, 'created': '2014-06-06 22:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ffe93716a37c012835773af83c7a2e65a38d1cc2', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 3, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7180a2f0e57d76d6dcb0967b4b91b9de5104a389', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 4, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8312660bfcbdd00f6776349aa1391779620a5f0d', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 5, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd745bc8f801a512d29b469a98e47221aeeff7e2', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 6, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9f9b7027e36c1ec7ac3d54d077db82553ee5a964', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 7, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/87d71aa45d3af09603e8a36559ee02a421287000', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}, {'number': 8, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/obj/test_expirer.py', 'swift/obj/server.py', 'etc/object-expirer.conf-sample', 'test/unit/obj/test_server.py', 'swift/obj/expirer.py', 'test/probe/test_object_expirer.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8d20e0e927d781baad1b71230bfafad6e74661eb', 'message': ""Fix object-expirer for missing objects\n\nCurrently if the object-expirer goes to delete an object and the primary nodes\nare unavailable, or the object is on handoffs - the object servers are unable\nto verify the x-if-delete-at timestamp and return 412, without writing a\ntombstone or updating the containers.  The expirer treats 412 as success and\nthe dark data is not removed form the object servers nor the object removed in\nthe listing.\n\nAs a side effect of this bug, if the expirer encounters split brain the delete\nwould never get processed in the correct storage policy.\n\nIt seems it's just not correct to treat the lack of data as success.  Now the\nobject server will treat x-if-delete at against a non-existent object as a\n404, and to distinguish from a successfull process of an x-if-delete-at\nrequest, will return 204.\n\nThe expirer will treat a 404 response from swift as a failure, and will\ncontinue to attempt to expire the object until it is older that it's\nconfigurable reclaim age.  However swift will only return 404 if the majority\nof nodes are able to return success, or if only even a single node is able to\naccept the x-if-delete-at request the containers will get updated and\nreplicaiton will settle the tombstone - the subsequent x-if-delete-at request\nwill 412 and be removed from the queue.\n\nIt's worth noting that if an object with x-delete-at meta is DELETED (by a\nclient request) an async update for the expiring update containers will be\nprocessed to remove the queue entry - but if no primary nodes handle the\nDELETE request replication will never remove the expiring entry and assuming\nit's scheduled for beyond the tombstones reclaim age - the queue entry will\nnot be processable.  In this case the expirer will attempt to DELETE the\nobject (and get 404s) in vain until the queue entry passes the configurable\nreclaim age.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be\n""}]",0,98511,8d20e0e927d781baad1b71230bfafad6e74661eb,32,4,8,1179,,,0,"Fix object-expirer for missing objects

Currently if the object-expirer goes to delete an object and the primary nodes
are unavailable, or the object is on handoffs - the object servers are unable
to verify the x-if-delete-at timestamp and return 412, without writing a
tombstone or updating the containers.  The expirer treats 412 as success and
the dark data is not removed form the object servers nor the object removed in
the listing.

As a side effect of this bug, if the expirer encounters split brain the delete
would never get processed in the correct storage policy.

It seems it's just not correct to treat the lack of data as success.  Now the
object server will treat x-if-delete at against a non-existent object as a
404, and to distinguish from a successfull process of an x-if-delete-at
request, will return 204.

The expirer will treat a 404 response from swift as a failure, and will
continue to attempt to expire the object until it is older that it's
configurable reclaim age.  However swift will only return 404 if the majority
of nodes are able to return success, or if only even a single node is able to
accept the x-if-delete-at request the containers will get updated and
replicaiton will settle the tombstone - the subsequent x-if-delete-at request
will 412 and be removed from the queue.

It's worth noting that if an object with x-delete-at meta is DELETED (by a
client request) an async update for the expiring update containers will be
processed to remove the queue entry - but if no primary nodes handle the
DELETE request replication will never remove the expiring entry and assuming
it's scheduled for beyond the tombstones reclaim age - the queue entry will
not be processable.  In this case the expirer will attempt to DELETE the
object (and get 404s) in vain until the queue entry passes the configurable
reclaim age.

DocImpact
Implements: blueprint storage-policies
Change-Id: I66260e99fda37e97d6d2470971b6f811ee9e01be
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/98511/6 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_expirer.py', 'swift/obj/server.py', 'etc/object-expirer.conf-sample', 'test/unit/obj/test_server.py', 'swift/obj/expirer.py', 'test/probe/test_object_expirer.py']",6,c88cdf6c83c096e3166e7e958b739c5e12227e67,bp/storage-policies,"#!/usr/bin/python -u # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import random import unittest import uuid from nose import SkipTest from swift.common.internal_client import InternalClient from swift.common.manager import Manager from swift.common.storage_policy import POLICIES from test.probe.common import reset_environment, get_to_final_state from test.probe.test_container_merge_policy_index import BrainSplitter from swiftclient import client class TestObjectExpirer(unittest.TestCase): def setUp(self): if len(POLICIES) < 2: raise SkipTest('Need more than one policy') self.expirer = Manager(['object-expirer']) self.expirer.start() err = self.expirer.stop() if err: raise SkipTest('Unable to verify object-expirer service') conf_files = [] for server in self.expirer.servers: conf_files.extend(server.conf_files()) conf_file = conf_files[0] self.client = InternalClient(conf_file, 'probe-test', 3) (self.pids, self.port2server, self.account_ring, self.container_ring, self.object_ring, self.policy, self.url, self.token, self.account, self.configs) = reset_environment() self.container_name = 'container-%s' % uuid.uuid4() self.object_name = 'object-%s' % uuid.uuid4() self.brain = BrainSplitter(self.url, self.token, self.container_name, self.object_name) def test_expirer_object_split_brain(self): old_policy = random.choice(list(POLICIES)) wrong_policy = random.choice([p for p in POLICIES if p != old_policy]) # create an expiring object and a container with the wrong policy self.brain.stop_primary_half() self.brain.put_container(int(old_policy)) self.brain.put_object(headers={'X-Delete-After': 1}) # get the object timestamp metadata = self.client.get_object_metadata( self.account, self.container_name, self.object_name, headers={'X-Backend-Storage-Policy-Index': int(old_policy)}) create_timestamp = metadata['x-timestamp'] self.brain.start_primary_half() # get the expiring object updates in their queue, while we have all # the servers up Manager(['object-updater']).once() self.brain.stop_handoff_half() self.brain.put_container(int(wrong_policy)) # don't start handoff servers, only wrong policy is available # make sure auto-created containers get in the account listing Manager(['container-updater']).once() # this guy should no-op since it's unable to expire the object self.expirer.once() self.brain.start_handoff_half() get_to_final_state() # validate object is expired found_in_policy = None metadata = self.client.get_object_metadata( self.account, self.container_name, self.object_name, acceptable_statuses=(4,), headers={'X-Backend-Storage-Policy-Index': int(old_policy)}) self.assert_('x-backend-timestamp' in metadata) self.assertEqual(metadata['x-backend-timestamp'], create_timestamp) # but it is still in the listing for obj in self.client.iter_objects(self.account, self.container_name): if self.object_name == obj['name']: break else: self.fail('Did not find listing for %s' % self.object_name) # clear proxy cache client.post_container(self.url, self.token, self.container_name, {}) # run the expirier again after replication self.expirer.once() # object is not in the listing for obj in self.client.iter_objects(self.account, self.container_name): if self.object_name == obj['name']: self.fail('Found listing for %s' % self.object_name) # and validate object is tombstoned found_in_policy = None for policy in POLICIES: metadata = self.client.get_object_metadata( self.account, self.container_name, self.object_name, acceptable_statuses=(4,), headers={'X-Backend-Storage-Policy-Index': int(policy)}) if 'x-backend-timestamp' in metadata: if found_in_policy: self.fail('found object in %s and also %s' % (found_in_policy, policy)) found_in_policy = policy self.assert_('x-backend-timestamp' in metadata) self.assert_(float(metadata['x-backend-timestamp']) > float(create_timestamp)) if __name__ == ""__main__"": unittest.main() ",,286,67
openstack%2Fswift~master~I94e3a7937d9814b9ecef6ca35371e245a43513d3,openstack/swift,master,I94e3a7937d9814b9ecef6ca35371e245a43513d3,Add Storage Policy Support to the Auditor,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:26:51.000000000,,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4a03b3997933e981c409b9d970e24a24cba22f4b', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2459fc4382decfcbe4813958e8fc2bc834db4957', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/65b7cdafaea1d27b24dda02bc14628b3fde23f2a', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a56848613c57c82594fd8d03dc2cc0c27097a7ee', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/18cde7e54cd4024677261c6ac6304a7441f8d105', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/807baf6bcb872c84555fbe5c2e6630207c3de45d', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ebe36fb585b8c66534d76673ecfc7067eda0bca7', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7571f4a20593690781b03b2effd546fe0ee5bf68', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a422d0b18157cb43b234d59c3f223b7ed1d391c6', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/09806c3a5d0161cb4d2d8b64394740f8815dc4be', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ee60f4589e2c9269440a68cce46311e31ee17bfc', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/61db247a1b3dece0fcf4d5982c8704a8a860f16b', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e926eedfe2c9cd85e6a3dcf99f91cec227fe8958', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/obj/test_auditor.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1a0e4d91977bf29a5d70bddcff99b67195669e7f', 'message': ""Add Storage Policy Support to the Auditor\n\nThis patch makes the object auditor policy-aware, so it'll audit\nobjects in any storage policy.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3\n""}]",16,96032,1a0e4d91977bf29a5d70bddcff99b67195669e7f,68,10,14,1179,,,0,"Add Storage Policy Support to the Auditor

This patch makes the object auditor policy-aware, so it'll audit
objects in any storage policy.

DocImpact
Implements: blueprint storage-policies
Change-Id: I94e3a7937d9814b9ecef6ca35371e245a43513d3
",git fetch https://review.opendev.org/openstack/swift refs/changes/32/96032/8 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_auditor.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py']",3,4a03b3997933e981c409b9d970e24a24cba22f4b,bp/storage-policies," # loop through object dirs for all policies for dir in [dir for dir in os.listdir(os.path.join(devices, device)) if dir.startswith(DATADIR_BASE)]: datadir_path = os.path.join(devices, device, dir) # warn if the object dir doesn't match with a policy policy_idx = 0 if '-' in dir: base, policy_idx = dir.split('-', 1) try: get_data_dir(policy_idx) except ValueError: if logger: logger.warn(_('Directory %s does not map to a ' 'valid policy') % dir) partitions = listdir(datadir_path) for partition in partitions: part_path = os.path.join(datadir_path, partition) try: suffixes = listdir(part_path) for asuffix in suffixes: suff_path = os.path.join(part_path, asuffix) try: hashes = listdir(suff_path) except OSError as e: if e.errno != errno.ENOTDIR: raise continue for hsh in hashes: hsh_path = os.path.join(suff_path, hsh) yield AuditLocation(hsh_path, device, partition)"," datadir_path = os.path.join(devices, device, DATADIR_BASE) partitions = listdir(datadir_path) for partition in partitions: part_path = os.path.join(datadir_path, partition) try: suffixes = listdir(part_path) except OSError as e: if e.errno != errno.ENOTDIR: raise continue for asuffix in suffixes: suff_path = os.path.join(part_path, asuffix) try: hashes = listdir(suff_path) for hsh in hashes: hsh_path = os.path.join(suff_path, hsh) yield AuditLocation(hsh_path, device, partition)",136,55
openstack%2Fswift~master~Idaba3255f4109e5150d6c457f913c600fd8923eb,openstack/swift,master,Idaba3255f4109e5150d6c457f913c600fd8923eb,Put X-Backend-Timestamp in object 404 responses,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:26:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/39688cbda2e3d89c79c7b61e55784bbedc44872d', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e82609b8f0ddc87618b72a741c3cf742a8186f1a', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab78ac45fc9f1368cb42c4d8f3070a38a98a929f', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f4e743c588e7654d8ed2260269c0fe92d8bb073', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/91a8af1cd5f79ed8c8977f024887083342ebd1ba', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3df3594f17e7d680ddabcf478020844c9b2c4f9f', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5fc0b68ef9daafa2a5330bc93760e536ca4bf1e9', 'message': 'Put X-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/54e2e3d537f42ee00745adc5c64d98f627fef432', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/328cd43ada443777611d2f20087dae660665e458', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/81bedb87c80c807781288e232f231fe4cc6f3207', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6c8f0da3ae337a3a0204092f3928abeddea09880', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b9f37d309e5b4b48e06ee13aa3e45400b2b93b35', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/295a4d5b8ca53031529f540b6e5aa1777b005fa8', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/0015019ccd5ee41d8048af52ff7dc3533edd88fd', 'message': 'Put X-Backend-Timestamp in object 404 responses\n\nThis way the container reconciler can tell (sometimes) that an object\nwas deleted at a certain time.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb\n'}]",0,96035,0015019ccd5ee41d8048af52ff7dc3533edd88fd,70,8,14,1179,,,0,"Put X-Backend-Timestamp in object 404 responses

This way the container reconciler can tell (sometimes) that an object
was deleted at a certain time.

DocImpact
Implements: blueprint storage-policies
Change-Id: Idaba3255f4109e5150d6c457f913c600fd8923eb
",git fetch https://review.opendev.org/openstack/swift refs/changes/35/96035/14 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/obj/test_server.py']",2,39688cbda2e3d89c79c7b61e55784bbedc44872d,bp/storage-policies," self.assertFalse('X-Timestamp' in resp.headers) self.assertEquals(resp.headers['X-Timestamp'], timestamp) self.assertFalse('X-Timestamp' in resp.headers) self.assertEquals(resp.headers['X-Timestamp'], timestamp)",,16,4
openstack%2Fswift~master~Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d,openstack/swift,master,Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d,Add Storage Policy support to Object Updates,ABANDONED,2014-06-13 18:04:45.000000000,2014-06-24 23:26:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4e8a5d1dbc0398d0a5c8a5de601cbcadefce5dc5', 'message': 'Add Storage Policy support to Object Updates\n\nThe object server will now send its storage policy index to the\ncontainer server synchronously and asynchronously (via async_pending).\n\nEach storage policy gets its own async_pending directory under\n/srv/node/$disk/objects-$N, so there\'s no need to change the on-disk\npickle format; the policy index comes from the async_pending\'s\nfilename. This avoids any hassle on upgrade. (Recall that policy 0\'s\nobjects live in /srv/node/$disk/objects, not objects-0.)  Per-policy\ntempdir as well.\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nThere\'s also a drive by fix to update some backend http mocks for container\nupdate tests that we\'re not fully exercising their their request fakes.\nBecause the object server container update code is resilient to to all manor\nof failure from backend requests the general intent of the tests was\nunaffected but this change cleans up some confusing logging in the debug\nlogger output.\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I07c730bebaee068f75024fa9c2fa9e11e295d9bd\n\nadd to object updates\n\nChange-Id: Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d\n'}, {'number': 2, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/623dccbe46d8dbc69c7bacffc97051af37461f33', 'message': 'Add Storage Policy support to Object Updates\n\nThe object server will now send its storage policy index to the\ncontainer server synchronously and asynchronously (via async_pending).\n\nEach storage policy gets its own async_pending directory under\n/srv/node/$disk/objects-$N, so there\'s no need to change the on-disk\npickle format; the policy index comes from the async_pending\'s\nfilename. This avoids any hassle on upgrade. (Recall that policy 0\'s\nobjects live in /srv/node/$disk/objects, not objects-0.)  Per-policy\ntempdir as well.\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nThere\'s also a drive by fix to update some backend http mocks for container\nupdate tests that we\'re not fully exercising their their request fakes.\nBecause the object server container update code is resilient to to all manor\nof failure from backend requests the general intent of the tests was\nunaffected but this change cleans up some confusing logging in the debug\nlogger output.\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I07c730bebaee068f75024fa9c2fa9e11e295d9bd\n\nadd to object updates\n\nChange-Id: Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d\n'}, {'number': 3, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/daea05ce90743476926a824ec8b372a35cac2f02', 'message': 'Add Storage Policy support to Object Updates\n\nThe object server will now send its storage policy index to the\ncontainer server synchronously and asynchronously (via async_pending).\n\nEach storage policy gets its own async_pending directory under\n/srv/node/$disk/objects-$N, so there\'s no need to change the on-disk\npickle format; the policy index comes from the async_pending\'s\nfilename. This avoids any hassle on upgrade. (Recall that policy 0\'s\nobjects live in /srv/node/$disk/objects, not objects-0.)  Per-policy\ntempdir as well.\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nThere\'s also a drive by fix to update some backend http mocks for container\nupdate tests that we\'re not fully exercising their their request fakes.\nBecause the object server container update code is resilient to to all manor\nof failure from backend requests the general intent of the tests was\nunaffected but this change cleans up some confusing logging in the debug\nlogger output.\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I07c730bebaee068f75024fa9c2fa9e11e295d9bd\n\nadd to object updates\n\nChange-Id: Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d\n'}, {'number': 4, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/obj/updater.py', 'swift/obj/server.py', 'swift/container/server.py', 'swift/obj/mem_server.py', 'test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'test/unit/obj/test_diskfile.py', 'test/unit/obj/test_updater.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d5ca365965fc20117cf7bcebeedf81f965abff76', 'message': 'Add Storage Policy support to Object Updates\n\nThe object server will now send its storage policy index to the\ncontainer server synchronously and asynchronously (via async_pending).\n\nEach storage policy gets its own async_pending directory under\n/srv/node/$disk/objects-$N, so there\'s no need to change the on-disk\npickle format; the policy index comes from the async_pending\'s\nfilename. This avoids any hassle on upgrade. (Recall that policy 0\'s\nobjects live in /srv/node/$disk/objects, not objects-0.)  Per-policy\ntempdir as well.\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nThere\'s also a drive by fix to update some backend http mocks for container\nupdate tests that we\'re not fully exercising their their request fakes.\nBecause the object server container update code is resilient to to all manor\nof failure from backend requests the general intent of the tests was\nunaffected but this change cleans up some confusing logging in the debug\nlogger output.\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I07c730bebaee068f75024fa9c2fa9e11e295d9bd\n\nadd to object updates\n\nChange-Id: Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d\n'}]",2,99979,d5ca365965fc20117cf7bcebeedf81f965abff76,22,6,4,1179,,,0,"Add Storage Policy support to Object Updates

The object server will now send its storage policy index to the
container server synchronously and asynchronously (via async_pending).

Each storage policy gets its own async_pending directory under
/srv/node/$disk/objects-$N, so there's no need to change the on-disk
pickle format; the policy index comes from the async_pending's
filename. This avoids any hassle on upgrade. (Recall that policy 0's
objects live in /srv/node/$disk/objects, not objects-0.)  Per-policy
tempdir as well.

Also clean up a couple little things in the object updater. Now it
won't abort processing when it encounters a file (not directory) named
""async_pending-\d+"", and it won't process updates in a directory that
does not correspond to a storage policy.

That is, if you have policies 1, 2, and 3, but there's a directory on
your disk named ""async_pending-5"", the updater will now skip over that
entirely. It won't even bother doing directory listings at all. This
is a good idea, believe it or not, because there's nothing good that
the container server can do with an update from some unknown storage
policy. It can't update the listing, it can't move the object if it's
misplaced... all it can do is ignore the request, so it's better to
just not send it in the first place. Plus, if this is due to a
misconfiguration on one storage node, then the updates will get
processed once the configuration is fixed.

There's also a drive by fix to update some backend http mocks for container
update tests that we're not fully exercising their their request fakes.
Because the object server container update code is resilient to to all manor
of failure from backend requests the general intent of the tests was
unaffected but this change cleans up some confusing logging in the debug
logger output.

The object-server will send X-Storage-Policy-Index headers with all
requests to container severs, including X-Delete containers and all
object PUT/DELETE requests.  This header value is persisted in the
pickle file for the update and sent along with async requests from the
object-updater as well.

The container server will extract the X-Storage-Policy-Index header from
incoming requests and apply it to container broker calls as appropriate
defaulting to the legacy storage policy 0 to support seemless migration.

DocImpact
Implements: blueprint storage-policies
Change-Id: I07c730bebaee068f75024fa9c2fa9e11e295d9bd

add to object updates

Change-Id: Ic97a422238a0d7bc2a411a71a7aba3f8b42fce4d
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/99979/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'swift/container/server.py', 'swift/obj/server.py', 'swift/obj/mem_server.py', 'test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'test/unit/obj/test_diskfile.py', 'test/unit/obj/test_updater.py', 'swift/obj/diskfile.py']",9,4e8a5d1dbc0398d0a5c8a5de601cbcadefce5dc5,bp/storage-policies," timestamp, policy_idx): async_dir = os.path.join(device_path, get_async_dir(policy_idx)) os.path.join(device_path, get_tmp_dir(policy_idx))) self._tmpdir = join(device_path, get_tmp_dir(policy_idx))"," timestamp): async_dir = os.path.join(device_path, ASYNCDIR_BASE) os.path.join(device_path, 'tmp')) self._tmpdir = join(device_path, 'tmp')",646,207
openstack%2Fswift~master~Ifdb4624841f35953ba80189e669d3ef15d5563fd,openstack/swift,master,Ifdb4624841f35953ba80189e669d3ef15d5563fd,Add storage policy support for the Replicator,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:26:26.000000000,,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2cfe9495b663a17c6051ff2365bfbf75081d70f6', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad6b10d20c92b61ab78468b6a8cb41cd3ed7a7ab', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e352d99adc7924663774f74748f6cd9c335a257e', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/adbf188db28d1433fa7edca847183f7062e7f83b', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/494f7747f4ffc781c672b2109f7719397bbe1124', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c74574b6fc913374e3c32f5ee7f0b386519e32cc', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/785d87fffb5739b71266f019ac6e87c44c301a83', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/98b919d2e8a2860477928fbc1cc96605ead195a3', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/15bcac3693d189840e341a2b0fec6c407bc9c295', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/725e361ab255d00a2155351f7e9820f24cf881b6', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b8f61d027f6bae076a5d2342df4c2a18de864773', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd0b505362704295f4fd7234a65050f4a85dd847', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cad4a07977733a0cd39a1e45a48250d1fb1c4cdc', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/obj/replicator.py', 'swift/obj/server.py', 'test/unit/obj/test_replicator.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/04f297036272320403d86e737ae6b453171d141e', 'message': 'Add storage policy support for the Replicator\n\nThis makes it so that objects stored in all policies get replicated\nproperly. This is only for rsync replication, not ssync.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd\n'}]",2,96033,04f297036272320403d86e737ae6b453171d141e,58,10,14,1179,,,0,"Add storage policy support for the Replicator

This makes it so that objects stored in all policies get replicated
properly. This is only for rsync replication, not ssync.

DocImpact
Implements: blueprint storage-policies
Change-Id: Ifdb4624841f35953ba80189e669d3ef15d5563fd
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/96033/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/replicator.py', 'swift/obj/server.py', 'test/unit/obj/test_replicator.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py']",5,2cfe9495b663a17c6051ff2365bfbf75081d70f6,bp/storage-policies," def get_hashes(self, device, partition, suffix, policy_idx): partition_path = os.path.join(dev_path, get_data_dir(policy_idx), partition)"," def get_hashes(self, device, partition, suffix): partition_path = os.path.join(dev_path, DATADIR_BASE, partition)",250,92
openstack%2Fswift~master~I64879077676d764c6330e03734fc6665bb26f552,openstack/swift,master,I64879077676d764c6330e03734fc6665bb26f552,Add Storage Policy Support to ssync,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:26:19.000000000,,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0522101a046fc1c7f94cdaa793cba76e91107756', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/90863cb3a77ab6b576e01dc8d3934bb8e524dfbf', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/16ea55a38a15351fdc770e6e2d47b224165af553', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57e528664611e32215c745ac762a2c01d3037542', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e033cf91235fed307e0661e9adc2da11a4d8e81e', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/09d6be17b2326032ff27809e34ac87c9236b2eb9', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3ef0aeb72ed681c6b31eff82824e4f51a0dea47d', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e56583c8c0ca22578cef06bbf771778fdfb5c5c7', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f55f1d225dbb846935dd61ce041e7f0d4d03db46', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7078a76138d15967ca83c7958b8b13da335b297d', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/899a4d508f95447a0a684b99211fe0d6ca4630e0', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/93b21e60206c0180193c7a81b006b14156feefe5', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d5bf2cf8183a108a78dc3fa119c8d9be26c9d9a4', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b9707d497ca8c3755f480f08814f921956483b7d', 'message': 'Add Storage Policy Support to ssync\n\nThis patch makes ssync policy aware so that clusters using storage\npolicies and ssync replication will replicate objects in all policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I64879077676d764c6330e03734fc6665bb26f552\n'}]",0,96034,b9707d497ca8c3755f480f08814f921956483b7d,55,6,14,1179,,,0,"Add Storage Policy Support to ssync

This patch makes ssync policy aware so that clusters using storage
policies and ssync replication will replicate objects in all policies.

DocImpact
Implements: blueprint storage-policies
Change-Id: I64879077676d764c6330e03734fc6665bb26f552
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/96034/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_ssync_receiver.py']",6,0522101a046fc1c7f94cdaa793cba76e91107756,bp/storage-policies,"from swift.common.storage_policy import POLICY_INDEX def test_Receiver_with_default_storage_policy(self): req = swob.Request.blank( '/sda1/1', environ={'REQUEST_METHOD': 'REPLICATION'}, body=':MISSING_CHECK: START\r\n' ':MISSING_CHECK: END\r\n' ':UPDATES: START\r\n:UPDATES: END\r\n') rcvr = ssync_receiver.Receiver(self.controller, req) body_lines = [chunk.strip() for chunk in rcvr() if chunk.strip()] self.assertEqual( body_lines, [':MISSING_CHECK: START', ':MISSING_CHECK: END', ':UPDATES: START', ':UPDATES: END']) self.assertEqual(rcvr.policy_idx, 0) @unit.patch_policies() def test_Receiver_with_storage_policy_index_header(self): req = swob.Request.blank( '/sda1/1', environ={'REQUEST_METHOD': 'REPLICATION', 'HTTP_X_BACKEND_STORAGE_POLICY_INDEX': '1'}, body=':MISSING_CHECK: START\r\n' ':MISSING_CHECK: END\r\n' ':UPDATES: START\r\n:UPDATES: END\r\n') rcvr = ssync_receiver.Receiver(self.controller, req) body_lines = [chunk.strip() for chunk in rcvr() if chunk.strip()] self.assertEqual( body_lines, [':MISSING_CHECK: START', ':MISSING_CHECK: END', ':UPDATES: START', ':UPDATES: END']) self.assertEqual(rcvr.policy_idx, 1) os.path.join(self.testdir, 'sda1', diskfile.get_data_dir(0)), @unit.patch_policies def test_MISSING_CHECK_storage_policy(self): object_dir = utils.storage_directory( os.path.join(self.testdir, 'sda1', diskfile.get_data_dir(1)), '1', self.hash1) utils.mkdirs(object_dir) fp = open(os.path.join(object_dir, self.ts1 + '.data'), 'w+') fp.write('1') fp.flush() self.metadata1['Content-Length'] = '1' diskfile.write_metadata(fp, self.metadata1) self.controller.logger = mock.MagicMock() req = swob.Request.blank( '/sda1/1', environ={'REQUEST_METHOD': 'REPLICATION', 'HTTP_X_BACKEND_STORAGE_POLICY_INDEX': '1'}, body=':MISSING_CHECK: START\r\n' + self.hash1 + ' ' + self.ts1 + '\r\n' + self.hash2 + ' ' + self.ts2 + '\r\n' ':MISSING_CHECK: END\r\n' ':UPDATES: START\r\n:UPDATES: END\r\n') resp = req.get_response(self.controller) self.assertEqual( self.body_lines(resp.body), [':MISSING_CHECK: START', self.hash2, ':MISSING_CHECK: END', ':UPDATES: START', ':UPDATES: END']) self.assertEqual(resp.status_int, 200) self.assertFalse(self.controller.logger.error.called) self.assertFalse(self.controller.logger.exception.called) os.path.join(self.testdir, 'sda1', diskfile.get_data_dir(0)), os.path.join(self.testdir, 'sda1', diskfile.get_data_dir(0)), POLICY_INDEX: '0', 'X-Backend-Replication': 'True', 'X-Backend-Replication-Headers': ( 'content-length x-timestamp x-object-meta-test1 ' 'content-encoding specialty-header')}) self.assertEqual(req.read_body, '1') @unit.patch_policies() def test_UPDATES_with_storage_policy(self): _PUT_request = [None] @server.public def _PUT(request): _PUT_request[0] = request request.read_body = request.environ['wsgi.input'].read() return swob.HTTPOk() with mock.patch.object(self.controller, 'PUT', _PUT): self.controller.logger = mock.MagicMock() req = swob.Request.blank( '/device/partition', environ={'REQUEST_METHOD': 'REPLICATION', 'HTTP_X_BACKEND_STORAGE_POLICY_INDEX': '1'}, body=':MISSING_CHECK: START\r\n:MISSING_CHECK: END\r\n' ':UPDATES: START\r\n' 'PUT /a/c/o\r\n' 'Content-Length: 1\r\n' 'X-Timestamp: 1364456113.12344\r\n' 'X-Object-Meta-Test1: one\r\n' 'Content-Encoding: gzip\r\n' 'Specialty-Header: value\r\n' '\r\n' '1') resp = req.get_response(self.controller) self.assertEqual( self.body_lines(resp.body), [':MISSING_CHECK: START', ':MISSING_CHECK: END', ':UPDATES: START', ':UPDATES: END']) self.assertEqual(resp.status_int, 200) self.assertFalse(self.controller.logger.exception.called) self.assertFalse(self.controller.logger.error.called) req = _PUT_request[0] self.assertEqual(req.path, '/device/partition/a/c/o') self.assertEqual(req.content_length, 1) self.assertEqual(req.headers, { 'Content-Length': '1', 'X-Timestamp': '1364456113.12344', 'X-Object-Meta-Test1': 'one', 'Content-Encoding': 'gzip', 'Specialty-Header': 'value', 'Host': 'localhost:80', POLICY_INDEX: '1', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0', POLICY_INDEX: '0',"," os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE), os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE), os.path.join(self.testdir, 'sda1', diskfile.DATADIR_BASE),",274,56
openstack%2Fswift~master~I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9,openstack/swift,master,I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9,Add container-reconciler daemon,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:26:10.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/589b9342f670c1f44181451e511af4c296f2123d', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d74ab0bb59cb1ae80a7208bfd4d22c43bc8cb788', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/820a79f11009488e4eb244793d73e1a6666b95b8', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dac65995562828cebf00e70c5aa23b138bfdd247', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/907fa21af80815aff32e762b4dcaa9f76c7b9024', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b1418996386a545be984a1d6d3cd52364854e02e', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1d96aa2503ad402e04f1b8ddf5775172f9c6ab97', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ac0cae0513d3a794637b32bac78392495d826bf7', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0f9400156e2f528ad5001d879267cfcb5d352d5f', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/83e6ed4b1c2fdadeb3dd721fab26b568f9929081', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/50dc8fdb61d3a9fe0d6b0863cd30ea636814ee16', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0288843daa61c48cdf9a860de5fafc27fa53c329', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/617f777e482407b6fe7f9eae5ba8014b867fce24', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['bin/swift-reconciler-enqueue', 'swift/common/utils.py', 'test/unit/__init__.py', 'etc/container-reconciler.conf-sample', 'swift/common/manager.py', 'test/unit/container/test_reconciler.py', 'setup.cfg', 'bin/swift-container-reconciler', 'swift/container/reconciler.py', 'test/unit/common/middleware/helpers.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3fc4d6f91d48a7b68f108e401a5ee8e2fcdc0100', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}]",46,96038,3fc4d6f91d48a7b68f108e401a5ee8e2fcdc0100,69,11,14,1179,,,0,"Add container-reconciler daemon

This daemon will take objects that are in the wrong storage policy and
move them to the right ones, or delete requests that went to the wrong
storage policy and apply them to the right ones. It operates on a
queue similar to the object-expirer's queue.

Discovering that the object is in the wrong policy will be done in
subsequent commits by the container replicator; this is the daemon
that handles them once they happen.

Like the object expirer, you only need to run one of these per cluster
see etc/container-reconciler.conf.

DocImpact
Implements: blueprint storage-policies
Change-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/96038/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-reconciler-enqueue', 'swift/common/utils.py', 'etc/container-reconciler.conf-sample', 'test/unit/__init__.py', 'swift/common/manager.py', 'test/unit/container/test_reconciler.py', 'setup.cfg', 'bin/swift-container-reconciler', 'swift/container/reconciler.py', 'test/unit/common/middleware/helpers.py', 'test/unit/common/test_utils.py']",11,589b9342f670c1f44181451e511af4c296f2123d,bp/storage-policies," def test_last_modified_date_to_timestamp(self): expectations = { '1970-01-01T00:00:00.000000': 0.0, '2014-02-28T23:22:36.698390': 1393629756.698390, '2011-03-19T04:03:00.604554': 1300507380.604554, } for last_modified, ts in expectations.items(): real = utils.last_modified_date_to_timestamp(last_modified) self.assertEqual(real, ts, ""failed for %s"" % last_modified) ",,2583,11
openstack%2Fswift~master~Icd4b2611b4169e46f216ff9a9839af732971a2bf,openstack/swift,master,Icd4b2611b4169e46f216ff9a9839af732971a2bf,Add Storage Policy support to the Account Reaper,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:25:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a308095c4d3a21bce874c58b46553e41cfbbc653', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/04cbf5b62419a2828a01276a63cd20ce86717642', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/81202ebf4319c88a8468fc5bd999c1c5b834a1c5', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd0399bc429fa447dcf5e237aec40c62cd830bd8', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b4d4ba75d31235b6b4bb597777c11053fc19bb78', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b93220452d7836dbf760aacb8ed3e02edc442f29', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 7, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/24003e208be1d725896a6b880f3663c52c2cbec8', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/080d671f3993953eef844371fabb5c16239f1275', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c7a09152c26006c3d0c131e1dc45ac6d6275afdb', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/04392cbddd560ecb28e9959517349867666717ac', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/642cb525d065eb727c972997773db9bb36cbfef5', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6541171a51517c845e4bf72fd118ade814e60f2c', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2c119fef36dd34d4a1c76c22de7b00146d7647eb', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d9f3226dc4d3ad746fc0fb2aa9227a39f222e3c5', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/account/test_reaper.py', 'test/probe/test_account_reaper.py', 'swift/account/reaper.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2e1ea825aa0b73ef0dbe7eae3bb141c187445ffe', 'message': 'Add Storage Policy support to the Account Reaper\n\nExtract X-Storage-Policy-Index header from container listing request\nand use it when making direct object DELETE requests.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf\n'}]",0,96049,2e1ea825aa0b73ef0dbe7eae3bb141c187445ffe,74,8,15,1179,,,0,"Add Storage Policy support to the Account Reaper

Extract X-Storage-Policy-Index header from container listing request
and use it when making direct object DELETE requests.

DocImpact
Implements: blueprint storage-policies
Change-Id: Icd4b2611b4169e46f216ff9a9839af732971a2bf
",git fetch https://review.opendev.org/openstack/swift refs/changes/49/96049/8 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/account/test_reaper.py', 'test/probe/test_account_reaper.py', 'swift/account/reaper.py']",3,a308095c4d3a21bce874c58b46553e41cfbbc653,bp/storage-policies,"from swift.common.storage_policy import POLICIES, POLICY_INDEX def __init__(self, conf, logger=None): self.logger = logger or get_logger(conf, log_route='account-reaper') def get_object_ring(self, policy_idx): """""" Get the ring identified by the policy index :param policy_idx: Storage policy index :returns: A ring matching the storage policy """""" return POLICIES.get_object_ring(policy_idx, self.swift_dir) def reset_stats(self): self.stats_return_codes = {} self.stats_containers_deleted = 0 self.stats_objects_deleted = 0 self.stats_containers_remaining = 0 self.stats_objects_remaining = 0 self.stats_containers_possibly_remaining = 0 self.stats_objects_possibly_remaining = 0 self.reset_stats() headers, objects = direct_get_container( response_timeout=self.node_timeout) policy_index = headers.get(POLICY_INDEX, 0) nodes, obj['name'], policy_index) container_nodes, obj, policy_index): :param policy_index: The storage policy index of the object's container ring = self.get_object_ring(policy_index) part, nodes = ring.get_nodes(account, container, obj) 'X-Container-Device': cnode['device'], POLICY_INDEX: policy_index})"," def __init__(self, conf): self.logger = get_logger(conf, log_route='account-reaper') def get_object_ring(self): """"""The object :class:`swift.common.ring.Ring` for the cluster."""""" if not self.object_ring: self.object_ring = Ring(self.swift_dir, ring_name='object') return self.object_ring self.stats_return_codes = {} self.stats_containers_deleted = 0 self.stats_objects_deleted = 0 self.stats_containers_remaining = 0 self.stats_objects_remaining = 0 self.stats_containers_possibly_remaining = 0 self.stats_objects_possibly_remaining = 0 objects = direct_get_container( response_timeout=self.node_timeout)[1] nodes, obj['name']) container_nodes, obj): part, nodes = self.get_object_ring().get_nodes(account, container, obj) 'X-Container-Device': cnode['device']})",202,39
openstack%2Fswift~master~Ia484d569619df0bf85f973e4e916de2ac6401d5e,openstack/swift,master,Ia484d569619df0bf85f973e4e916de2ac6401d5e,Extend direct_client,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:25:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}, {'_account_id': 9205}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c1d9e353b82337482720f7d914c2e8eb041bf101', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/88d38edcba659d76b79333837bcea8878b1629e9', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8ccfa6acdcd3919c37122ca8c95b728fd5a6c01a', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3c1a402fd516a54c33e581881c6bdc391f5a39fe', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68b010a294544cd6b7d1152e9df4b57f2e270dda', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7ac42720194ab9a360352501ec5bcb3a93e44139', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 7, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/424318456fac9f33828743f87007b321323629b7', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/55e6037470a81a25ee16ddf5253f8ffc5eb7047d', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f4952c0ad81c65b137f7fe5a295c725a6ef36718', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/72723152c982361989d3ac54cbf7c13c42fcd4cf', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c2f9b9eebce8c243f9ab9dc913d0362703a2bfcd', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad4d0fc30db98e63449a27c1f09c06a724cb473f', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c6b340136b5d0924456789195e31edcbd2cb172b', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/common/test_direct_client.py', 'swift/common/direct_client.py', 'swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d495d3ec72917517aa159159d89dcf881888ca2b', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}]",4,96037,d495d3ec72917517aa159159d89dcf881888ca2b,71,8,14,1179,,,0,"Extend direct_client

Rework header handling and add some methods needed by the reconciler.

 * response headers are case insensitive HeaderKeyDicts
 * add direct client container obj put and delete
 * add headers param to direct head object
 * add headers to DirectClientException

DirectClientException is a subclass of ClientException with a convience
constructor.  ClientException now supports an http_headers kwarg.

Exceptions raised from direct_client will include headers.

DocImpact
Implements: blueprint storage-policies
Change-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/96037/11 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_direct_client.py', 'swift/common/direct_client.py', 'swift/common/exceptions.py']",3,c1d9e353b82337482720f7d914c2e8eb041bf101,bp/storage-policies," http_device='', http_response_content='', http_headers=None): self.http_headers = http_headers or {}"," http_device='', http_response_content=''):",550,287
openstack%2Fswift~master~I01efd2999d6d9c57ee8693ac3a6236ace17c5566,openstack/swift,master,I01efd2999d6d9c57ee8693ac3a6236ace17c5566,Add Storage Policy Support to Recon Middleware,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:24:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/975e2fe09b4dc4775c461ee44bc4587a7dfced2b', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/64e2bdee8d61d21fdf9a2aff95d844b8344dd948', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4e80577743c7a714ca55f0538b244132c66b7c09', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/236f252c18b0910a379ff34f58f33678a7ce7b34', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ed42127715701b9efb9239f262bab5d698e82c96', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ffeb8d864f6e49e392804c42af2ac68a892c8156', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 7, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd245dbf6b8f9be37df1d0d230555522d85fcbcb', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0d6e12727c6f2567feaa4a4f45fec05df2b588e3', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/93d188a1bf63024f5640c0b0082d6bcf699c602c', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/78bfb46b26f7c9bd49d008af372cde07193cafa5', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2d9e41b74139766f98ff271f48123940ad430dca', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ee8678c783d37c53fa7e7e0258d9692cf08117e4', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bbe9ca8d1e335706d564463c729108ad6507923c', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4015210f788f98ee4eec74dd02d7cc5e8c437aa3', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/cli/test_recon.py', 'swift/common/middleware/recon.py', 'test/unit/common/middleware/test_recon.py', 'swift/cli/recon.py', 'test/unit/common/middleware/test_list_endpoints.py', 'swift/common/ring/ring.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8326dc9f2a34581b1e5ab0d27b32d3073827296f', 'message': ""Add Storage Policy Support to Recon Middleware\n\nRecon middleware returns object ring file MD5 sums; this patch\nupdates it to include other object files that may be present\nbecause of Storage Policies.  Also adds unit test coverage for\nthe MD5 reporting function which previously had none.\n\nThe recon script will now check all rings the server responds with\nmatch the on-disk md5's regardless of server-type; including any\nstorage policy object rings.\n\nNote the small change to the ring save method, needed to\nstimulate the right code paths in 2.6 and 2.7 versions of\ngzip to enable testing of ring MD5 sums.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566\n""}]",10,96048,8326dc9f2a34581b1e5ab0d27b32d3073827296f,62,7,15,1179,,,0,"Add Storage Policy Support to Recon Middleware

Recon middleware returns object ring file MD5 sums; this patch
updates it to include other object files that may be present
because of Storage Policies.  Also adds unit test coverage for
the MD5 reporting function which previously had none.

The recon script will now check all rings the server responds with
match the on-disk md5's regardless of server-type; including any
storage policy object rings.

Note the small change to the ring save method, needed to
stimulate the right code paths in 2.6 and 2.7 versions of
gzip to enable testing of ring MD5 sums.

DocImpact
Implements: blueprint storage-policies
Change-Id: I01efd2999d6d9c57ee8693ac3a6236ace17c5566
",git fetch https://review.opendev.org/openstack/swift refs/changes/48/96048/12 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/cli/test_recon.py', 'swift/common/middleware/recon.py', 'test/unit/common/middleware/test_recon.py', 'swift/cli/recon.py', 'test/unit/common/middleware/test_list_endpoints.py', 'swift/common/ring/ring.py']",6,975e2fe09b4dc4775c461ee44bc4587a7dfced2b,bp/storage-policies," def save(self, filename, mtime=1300507380.0): :param mtime: time used to override mtime for gzip, default or None if the caller wants to include time mtime=mtime)"," def save(self, filename): mtime=1300507380.0)",201,25
openstack%2Fswift~master~I6a948908c3e45b70707981d87171cb2cb910fe1e,openstack/swift,master,I6a948908c3e45b70707981d87171cb2cb910fe1e,Refactoring storage policies merge_timestamps,ABANDONED,2014-06-18 07:56:17.000000000,2014-06-24 23:24:07.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 6198}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/69d2683272b0682abdbd3797dda91bdd308f7e09', 'message': 'Refactoring storage policies merge_timestamps\n\n * base implementation of is_deleted phrased to use _is_deleted\n * wrap pre-conn coded _is_deleted inside a transation for merge_timestamps\n\nImplements: blueprint storage-policies\nChange-Id: I6a948908c3e45b70707981d87171cb2cb910fe1e\n'}, {'number': 2, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/account/backend.py', 'swift/common/db.py', 'test/unit/common/test_db.py', 'test/unit/container/test_backend.py', 'test/unit/account/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b02f0db126b873902bdb63f94a3c412082e14a54', 'message': 'Refactoring storage policies merge_timestamps\n\n * base implementation of is_deleted phrased to use _is_deleted\n * wrap pre-conn coded _is_deleted inside a transation for merge_timestamps\n\nImplements: blueprint storage-policies\nChange-Id: I6a948908c3e45b70707981d87171cb2cb910fe1e\n'}]",0,100807,b02f0db126b873902bdb63f94a3c412082e14a54,13,6,2,1179,,,0,"Refactoring storage policies merge_timestamps

 * base implementation of is_deleted phrased to use _is_deleted
 * wrap pre-conn coded _is_deleted inside a transation for merge_timestamps

Implements: blueprint storage-policies
Change-Id: I6a948908c3e45b70707981d87171cb2cb910fe1e
",git fetch https://review.opendev.org/openstack/swift refs/changes/07/100807/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/backend.py', 'swift/common/db.py', 'test/unit/common/test_db.py', 'swift/container/backend.py']",4,69d2683272b0682abdbd3797dda91bdd308f7e09,bp/storage-policies," def _is_deleted_info(self, object_count, put_timestamp, delete_timestamp, **kwargs): Apply delete logic to database info. # The container is considered deleted if the delete_timestamp # value is greater than the put_timestamp, and there are no # objects in the container. return (object_count in (None, '', 0, '0')) and ( float(delete_timestamp) > float(put_timestamp)) def _is_deleted(self, conn): """""" Check container_stat view and evaluate info. :param conn: database conn :returns: True if the DB is considered to be deleted, False otherwise """""" info = conn.execute(''' SELECT put_timestamp, delete_timestamp, object_count FROM container_stat''').fetchone() return self._is_deleted_info(**info) def get_info_is_deleted(self): return info, self._is_deleted_info(**info)"," def is_deleted(self, **kwargs): Check if the DB is considered to be deleted. _info, is_deleted = self.get_info_is_deleted(**kwargs) return is_deleted def get_info_is_deleted(self, timestamp=None): # leave this db as a tombstone for a consistency window if timestamp and info['delete_timestamp'] > timestamp: return info, False # The container is considered deleted if the delete_timestamp # value is greater than the put_timestamp, and there are no # objects in the container. is_deleted = (info['object_count'] in (None, '', 0, '0')) and \ (float(info['delete_timestamp']) > float(info['put_timestamp'])) return info, is_deleted",448,113
openstack%2Fswift~master~I19adbbcefbc086c8467bd904a275d55cde596412,openstack/swift,master,I19adbbcefbc086c8467bd904a275d55cde596412,Fixes probe tests with non-zero default storage policy,ABANDONED,2014-05-29 05:00:57.000000000,2014-06-24 23:23:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ae48223ad9c17f231ddd411ed9224de754bc567d', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 2, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/999660c3619c0c698ca5ee66b4d7e7ec04f255f1', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 3, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f5d3c196119193df941df5c11dc0b904a47c774c', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 4, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/96a62beb721391b4fed978e66200415aec058ff4', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 5, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dc2203fc79ca30c67022ee3353eb726a496cefbc', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 6, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e79326a5a4aa82cf546c4fdb96a98a449225f011', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 7, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/557e11cdc88d17ce102d1278bfd2f5b1cd6188bd', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 8, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad082731123d759a6d977f92d252189139b348e3', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 9, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aaf16598367559b4df4e3493fa61884239e5ab16', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 10, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a1cce50da3b31d54fe0153e02110976b4e74ba0a', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/488d674fe1af745e7f19994cd112cf01659206fd', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9be349a262908abe71c8456f084717e86d1109fe', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nRaise SkipTest if default policy type is not replication\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/04b1a8e9e0926572b2226071ee56d0f7c9a47e89', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/probe/common.py', 'test/probe/test_container_failures.py', 'test/probe/test_replication_servers_working.py', 'test/probe/test_container_merge_policy_index.py', 'test/probe/test_empty_device_handoff.py', 'test/probe/test_account_get_fake_responses_match.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_handoff.py', 'test/probe/test_object_async_update.py', 'test/probe/test_object_failures.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ad2a9cefe5f7355e1861f9f76b9cb2c59b6a83eb', 'message': 'Fixes probe tests with non-zero default storage policy\n\nAdd headers param to direct_client.direct_get_object, which is used in\nprobetests to passthrough the X-Storage-Policy-Index header.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I19adbbcefbc086c8467bd904a275d55cde596412\n'}]",7,96353,ad2a9cefe5f7355e1861f9f76b9cb2c59b6a83eb,78,9,14,1179,,,0,"Fixes probe tests with non-zero default storage policy

Add headers param to direct_client.direct_get_object, which is used in
probetests to passthrough the X-Storage-Policy-Index header.

DocImpact
Implements: blueprint storage-policies
Change-Id: I19adbbcefbc086c8467bd904a275d55cde596412
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/96353/9 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/common.py', 'test/probe/test_container_failures.py', 'test/probe/test_container_merge_policy_index.py', 'test/probe/test_replication_servers_working.py', 'test/probe/test_empty_device_handoff.py', 'test/probe/test_account_get_fake_responses_match.py', 'test/probe/test_account_failures.py', 'test/probe/test_object_async_update.py', 'test/probe/test_object_handoff.py', 'test/probe/test_object_failures.py']",10,ae48223ad9c17f231ddd411ed9224de754bc567d,bp/storage-policies,"from swift.common.storage_policy import POLICY_INDEXfrom swift.obj.diskfile import write_metadata, read_metadata, get_data_dir self.object_ring, self.policy, self.url, self.token, obj_dir = '%s/%s/%s/%s/%s/%s/' % (devices, device, get_data_dir(self.policy.idx), opart, hash_str[-3:], hash_str) onode, opart, self.account, container, obj, headers={ POLICY_INDEX: self.policy.idx})[-1] direct_client.direct_get_object( onode, opart, self.account, container, obj, headers={ POLICY_INDEX: self.policy.idx}) base_headers = {POLICY_INDEX: self.policy.idx} req_headers = base_headers.copy() req_headers.update(header) onode, opart, self.account, container, obj, headers=req_headers)[-1] direct_client.direct_get_object( onode, opart, self.account, container, obj, headers={ POLICY_INDEX: self.policy.idx}) direct_client.direct_get_object( onode, opart, self.account, container, obj, conn_timeout=1, response_timeout=1, headers={POLICY_INDEX: self.policy.idx}) direct_client.direct_head_object( onode, opart, self.account, container, obj, conn_timeout=1, response_timeout=1, headers={POLICY_INDEX: self.policy.idx}) headers = {'X-Object-Meta-1': 'One', 'X-Object-Meta-Two': 'Two', POLICY_INDEX: self.policy.idx} headers=headers,","from swift.obj.diskfile import write_metadata, read_metadata self.object_ring, self.url, self.token, obj_dir = '%s/%s/objects/%s/%s/%s/' % (devices, device, opart, hash_str[-3:], hash_str) onode, opart, self.account, container, obj)[-1] direct_client.direct_get_object(onode, opart, self.account, container, obj) onode, opart, self.account, container, obj, headers=header)[-1] direct_client.direct_get_object(onode, opart, self.account, container, obj) direct_client.direct_get_object(onode, opart, self.account, container, obj, conn_timeout=1, response_timeout=1) direct_client.direct_head_object(onode, opart, self.account, container, obj, conn_timeout=1, response_timeout=1) {'X-Object-Meta-1': 'One', 'X-Object-Meta-Two': 'Two'},",112,64
openstack%2Fswift~master~I5ec251f9a8014dd89764340de927d09466c72221,openstack/swift,master,I5ec251f9a8014dd89764340de927d09466c72221,Add Storage Policy Support to Accounts,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:23:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1417e9c289c865b1bc1d8d40174061d6345fe2f6', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d34e45e6216960c8d15aa745ef2c1ecf9ff619b5', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8e3f2173bda9ae4585cd757e82e7e549b3760428', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a7ec0f01da9aefaa76b13ccdfcaa442b86785da8', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a7823bd5276b4cc6c6bbd4e6b2a2f51b08d18df6', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8620db4d6dbd1b827060f683fea7c19a5dfb76d5', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e9b6579018bc62f443b3d85a1d63dfb18f0d149', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0ad806aa03059f074463f8f8b147c89ca4c01672', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68923ce015890632faec3c24e4fd1ab9948fb9f1', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7c45fa0042ba44da5722f113782448c1ea7f8222', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aa7243b0143e1350c26fd08b7b13b77e86291450', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30dce9f197fce719215d2817e537a32c19bab8e4', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e1f2eb9ac55ec8aecd6e579407a6f299b198f3e3', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/account/backend.py', 'test/unit/account/test_server.py', 'swift/container/server.py', 'swift/container/updater.py', 'swift/account/utils.py', 'test/unit/account/test_replicator.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'test/unit/account/test_backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/00a162c4d42a0f7813058d2ae5c3208b4f7a3157', 'message': 'Add Storage Policy Support to Accounts\n\nThis change updates the account HEAD handler to report out per\npolicy object and byte usage for the account.  Cumulative values\nare still reported and policy names are used in the report\nout (unless request is sent to an account server directly in\nwhich case policy indexes are used for easier accounting).\n\nBelow is an example of the relevant HEAD response for a cluster\nwith 3 policies and just a few small objects:\n\n   X-Account-Container-Count: 3\n   X-Account-Object-Count: 3\n   X-Account-Bytes-Used: 21\n   X-Storage-Policy-Bronze-Object-Count: 1\n   X-Storage-Policy-Bronze-Bytes-Used: 7\n   X-Storage-Policy-Silver-Object-Count: 1\n   X-Storage-Policy-Silver-Bytes-Used: 7\n   X-Storage-Policy-Gold-Object-Count: 1\n   X-Storage-Policy-Gold-Bytes-Used: 7\n\nSet a DEFAULT storage_policy_index for existing container rows during\nmigration.\n\nCopy existing object_count and bytes_used in policy_stat table during\nmigration.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I5ec251f9a8014dd89764340de927d09466c72221\n'}]",17,96041,00a162c4d42a0f7813058d2ae5c3208b4f7a3157,64,8,14,1179,,,0,"Add Storage Policy Support to Accounts

This change updates the account HEAD handler to report out per
policy object and byte usage for the account.  Cumulative values
are still reported and policy names are used in the report
out (unless request is sent to an account server directly in
which case policy indexes are used for easier accounting).

Below is an example of the relevant HEAD response for a cluster
with 3 policies and just a few small objects:

   X-Account-Container-Count: 3
   X-Account-Object-Count: 3
   X-Account-Bytes-Used: 21
   X-Storage-Policy-Bronze-Object-Count: 1
   X-Storage-Policy-Bronze-Bytes-Used: 7
   X-Storage-Policy-Silver-Object-Count: 1
   X-Storage-Policy-Silver-Bytes-Used: 7
   X-Storage-Policy-Gold-Object-Count: 1
   X-Storage-Policy-Gold-Bytes-Used: 7

Set a DEFAULT storage_policy_index for existing container rows during
migration.

Copy existing object_count and bytes_used in policy_stat table during
migration.

DocImpact
Implements: blueprint storage-policies
Change-Id: I5ec251f9a8014dd89764340de927d09466c72221
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/96041/10 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/backend.py', 'swift/container/server.py', 'swift/container/updater.py', 'test/unit/account/test_server.py', 'swift/account/utils.py', 'test/unit/account/test_replicator.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'test/unit/account/test_backend.py']",9,1417e9c289c865b1bc1d8d40174061d6345fe2f6,bp/storage-policies,"import pickle import osfrom tempfile import mkdtemp from shutil import rmtree import sqlite3 import itertools from contextlib import contextmanagerfrom test.unit import patch_policies, with_tempdirfrom swift.common.storage_policy import StoragePolicy, POLICIES @patch_policies broker.put_container('o', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('o', 0, normalize_timestamp(time()), 0, 0, POLICIES.default.idx) broker.put_container('c', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('c', 0, normalize_timestamp(time()), 0, 0, POLICIES.default.idx) broker.put_container('x', 0, 0, 0, 0, POLICIES.default.idx) broker.put_container('y', 0, 0, 0, 0, POLICIES.default.idx) broker.put_container('z', 0, 0, 0, 0, POLICIES.default.idx) def test_delete_db_status(self): start = int(time()) ts = itertools.count(start) broker = AccountBroker(':memory:', account='a') broker.initialize(normalize_timestamp(ts.next())) info = broker.get_info() self.assertEqual(info['put_timestamp'], normalize_timestamp(start)) self.assert_(float(info['created_at']) >= start) self.assertEqual(info['delete_timestamp'], '0') self.assertEqual(info['status_changed_at'], '0') # delete it delete_timestamp = normalize_timestamp(ts.next()) broker.delete_db(delete_timestamp) info = broker.get_info() self.assertEqual(info['put_timestamp'], normalize_timestamp(start)) self.assert_(float(info['created_at']) >= start) self.assertEqual(info['delete_timestamp'], delete_timestamp) self.assertEqual(info['status_changed_at'], delete_timestamp) broker.put_container('o', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('o', 0, normalize_timestamp(time()), 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', otimestamp, 0, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', 0, dtimestamp, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', 0, timestamp, 0, 0, POLICIES.default.idx) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0, POLICIES.default.idx) self.assertEqual(info['put_timestamp'], normalize_timestamp(1)) self.assertEqual(info['delete_timestamp'], '0') self.assertEqual(info['status_changed_at'], '0') broker.put_container('c1', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('c2', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('c2', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('c1', 0, normalize_timestamp(time()), 0, 0, POLICIES.default.idx) broker.put_container('c2', 0, normalize_timestamp(time()), 0, 0, POLICIES.default.idx) normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('3-0049-', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a-', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a-a', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a-a-a', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a-a-b', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('a-b', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('b', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('b-a', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('b-b', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker.put_container('c', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) normalize_timestamp(0), 0, 0, POLICIES.default.idx) normalize_timestamp(0), 0, 0, POLICIES.default.idx) normalize_timestamp(0), 0, 0, POLICIES.default.idx) broker1.put_container('a', normalize_timestamp(1), 0, 0, 0, POLICIES.default.idx) broker1.put_container('b', normalize_timestamp(2), 0, 0, 0, POLICIES.default.idx) broker1.put_container('c', normalize_timestamp(3), 0, 0, 0, POLICIES.default.idx) def test_load_old_pending_puts(self): # pending puts from pre-storage-policy account brokers won't contain # the storage policy index tempdir = mkdtemp() broker_path = os.path.join(tempdir, 'test-load-old.db') try: broker = AccountBroker(broker_path, account='real') broker.initialize(normalize_timestamp(1)) with open(broker_path + '.pending', 'a+b') as pending: pending.write(':') pending.write(pickle.dumps( # name, put_timestamp, delete_timestamp, object_count, # bytes_used, deleted ('oldcon', normalize_timestamp(200), normalize_timestamp(0), 896, 9216695, 0)).encode('base64')) broker._commit_puts() with broker.get() as conn: results = list(conn.execute(''' SELECT name, storage_policy_index FROM container ''')) self.assertEqual(len(results), 1) self.assertEqual(dict(results[0]), {'name': 'oldcon', 'storage_policy_index': 0}) finally: rmtree(tempdir) @patch_policies([StoragePolicy(0, 'zero', False), StoragePolicy(1, 'one', True), StoragePolicy(2, 'two', False), StoragePolicy(3, 'three', False)]) def test_get_policy_stats(self): ts = itertools.count() broker = AccountBroker(':memory:', account='a') broker.initialize(normalize_timestamp(ts.next())) # check empty policy_stats self.assertTrue(broker.empty()) policy_stats = broker.get_policy_stats() self.assertEqual(policy_stats, {}) # add some empty containers for policy in POLICIES: container_name = 'c-%s' % policy.name put_timestamp = normalize_timestamp(ts.next()) broker.put_container(container_name, put_timestamp, 0, 0, 0, policy.idx) policy_stats = broker.get_policy_stats() stats = policy_stats[policy.idx] self.assertEqual(stats['object_count'], 0) self.assertEqual(stats['bytes_used'], 0) # update the containers object & byte count for policy in POLICIES: container_name = 'c-%s' % policy.name put_timestamp = normalize_timestamp(ts.next()) count = policy.idx * 100 # good as any integer broker.put_container(container_name, put_timestamp, 0, count, count, policy.idx) policy_stats = broker.get_policy_stats() stats = policy_stats[policy.idx] self.assertEqual(stats['object_count'], count) self.assertEqual(stats['bytes_used'], count) # check all the policy_stats at once for policy_index, stats in policy_stats.items(): policy = POLICIES[policy_index] count = policy.idx * 100 # coupled with policy for test self.assertEqual(stats['object_count'], count) self.assertEqual(stats['bytes_used'], count) # now delete the containers one by one for policy in POLICIES: container_name = 'c-%s' % policy.name delete_timestamp = normalize_timestamp(ts.next()) broker.put_container(container_name, 0, delete_timestamp, 0, 0, policy.idx) policy_stats = broker.get_policy_stats() stats = policy_stats[policy.idx] self.assertEqual(stats['object_count'], 0) self.assertEqual(stats['bytes_used'], 0) @patch_policies([StoragePolicy(0, 'zero', False), StoragePolicy(1, 'one', True)]) def test_policy_stats_tracking(self): ts = itertools.count() broker = AccountBroker(':memory:', account='a') broker.initialize(normalize_timestamp(ts.next())) # policy 0 broker.put_container('con1', ts.next(), 0, 12, 2798641, 0) broker.put_container('con1', ts.next(), 0, 13, 8156441, 0) # policy 1 broker.put_container('con2', ts.next(), 0, 7, 5751991, 1) broker.put_container('con2', ts.next(), 0, 8, 6085379, 1) stats = broker.get_policy_stats() self.assertEqual(len(stats), 2) self.assertEqual(stats[0]['object_count'], 13) self.assertEqual(stats[0]['bytes_used'], 8156441) self.assertEqual(stats[1]['object_count'], 8) self.assertEqual(stats[1]['bytes_used'], 6085379) # Break encapsulation here to make sure that there's only 2 rows in # the stats table. It's possible that there could be 4 rows (one per # put_container) but that they came out in the right order so that # get_policy_stats() collapsed them down to the right number. To prove # that's not so, we have to go peek at the broker's internals. with broker.get() as conn: nrows = conn.execute( ""SELECT COUNT(*) FROM policy_stat"").fetchall()[0][0] self.assertEqual(nrows, 2) def prespi_AccountBroker_initialize(self, conn, put_timestamp): """""" The AccountBroker initialze() function before we added the policy stat table. Used by test_policy_table_creation() to make sure that the AccountBroker will correctly add the table for cases where the DB existed before the policy suport was added. :param conn: DB connection object :param put_timestamp: put timestamp """""" if not self.account: raise ValueError( 'Attempting to create a new database with no account set') self.create_container_table(conn) self.create_account_stat_table(conn, put_timestamp) def prespi_create_container_table(self, conn): """""" Copied from AccountBroker before the sstoage_policy_index column was added; used for testing with TestAccountBrokerBeforeSPI. Create container table which is specific to the account DB. :param conn: DB connection object """""" conn.executescript("""""" CREATE TABLE container ( ROWID INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, put_timestamp TEXT, delete_timestamp TEXT, object_count INTEGER, bytes_used INTEGER, deleted INTEGER DEFAULT 0 ); CREATE INDEX ix_container_deleted_name ON container (deleted, name); CREATE TRIGGER container_insert AFTER INSERT ON container BEGIN UPDATE account_stat SET container_count = container_count + (1 - new.deleted), object_count = object_count + new.object_count, bytes_used = bytes_used + new.bytes_used, hash = chexor(hash, new.name, new.put_timestamp || '-' || new.delete_timestamp || '-' || new.object_count || '-' || new.bytes_used); END; CREATE TRIGGER container_update BEFORE UPDATE ON container BEGIN SELECT RAISE(FAIL, 'UPDATE not allowed; DELETE and INSERT'); END; CREATE TRIGGER container_delete AFTER DELETE ON container BEGIN UPDATE account_stat SET container_count = container_count - (1 - old.deleted), object_count = object_count - old.object_count, bytes_used = bytes_used - old.bytes_used, hash = chexor(hash, old.name, old.put_timestamp || '-' || old.delete_timestamp || '-' || old.object_count || '-' || old.bytes_used); END; """""") class TestAccountBrokerBeforeSPI(TestAccountBroker): """""" Tests for AccountBroker against databases created before the storage_policy_index column was added. """""" def setUp(self): self._imported_create_container_table = \ AccountBroker.create_container_table AccountBroker.create_container_table = \ prespi_create_container_table self._imported_initialize = AccountBroker._initialize AccountBroker._initialize = prespi_AccountBroker_initialize broker = AccountBroker(':memory:', account='a') broker.initialize(normalize_timestamp('1')) exc = None with broker.get() as conn: try: conn.execute('SELECT storage_policy_index FROM container') except BaseException as err: exc = err self.assert_('no such column: storage_policy_index' in str(exc)) with broker.get() as conn: try: conn.execute('SELECT * FROM policy_stat') except sqlite3.OperationalError as err: self.assert_('no such table: policy_stat' in str(err)) else: self.fail('database created with policy_stat table') def tearDown(self): AccountBroker.create_container_table = \ self._imported_create_container_table AccountBroker._initialize = self._imported_initialize broker = AccountBroker(':memory:', account='a') broker.initialize(normalize_timestamp('1')) with broker.get() as conn: conn.execute('SELECT storage_policy_index FROM container') @with_tempdir def test_policy_table_migration(self, tempdir): db_path = os.path.join(tempdir, 'account.db') # first init an acct DB without the policy_stat table present broker = AccountBroker(db_path, account='a') broker.initialize(normalize_timestamp('1')) with broker.get() as conn: try: conn.execute(''' SELECT * FROM policy_stat ''').fetchone()[0] except sqlite3.OperationalError as err: # confirm that the table really isn't there self.assert_('no such table: policy_stat' in str(err)) else: self.fail('broker did not raise sqlite3.OperationalError ' 'trying to select from policy_stat table!') # make sure we can HEAD this thing w/o the table stats = broker.get_policy_stats() self.assertEqual(len(stats), 0) # now do a PUT to create the table broker.put_container('o', normalize_timestamp(time()), 0, 0, 0, POLICIES.default.idx) broker._commit_puts_stale_ok() # now confirm that the table was created with broker.get() as conn: conn.execute('SELECT * FROM policy_stat') stats = broker.get_policy_stats() self.assertEqual(len(stats), 1) @patch_policies @with_tempdir def test_container_table_migration(self, tempdir): db_path = os.path.join(tempdir, 'account.db') # first init an acct DB without the policy_stat table present broker = AccountBroker(db_path, account='a') broker.initialize(normalize_timestamp('1')) with broker.get() as conn: try: conn.execute(''' SELECT storage_policy_index FROM container ''').fetchone()[0] except sqlite3.OperationalError as err: # confirm that the table doesn't have this column self.assert_('no such column: storage_policy_index' in str(err)) else: self.fail('broker did not raise sqlite3.OperationalError ' 'trying to select from storage_policy_index ' 'from container table!') # manually insert an existing row to avoid migration with broker.get() as conn: conn.execute(''' INSERT INTO container (name, put_timestamp, delete_timestamp, object_count, bytes_used, deleted) VALUES (?, ?, ?, ?, ?, ?) ''', ('test_name', normalize_timestamp(time()), 0, 1, 2, 0)) conn.commit() # make sure we can iter containers without the migration for c in broker.list_containers_iter(1, None, None, None, None): self.assertEqual(c, ('test_name', 1, 2, 0)) # stats table is mysteriously empty... stats = broker.get_policy_stats() self.assertEqual(len(stats), 0) # now do a PUT with a different value for storage_policy_index # which will update the DB schema as well as update policy_stats # for legacy containers in the DB (those without an SPI) other_policy = [p for p in POLICIES if p.idx != 0][0] broker.put_container('test_second', normalize_timestamp(time()), 0, 3, 4, other_policy.idx) broker._commit_puts_stale_ok() with broker.get() as conn: rows = conn.execute(''' SELECT name, storage_policy_index FROM container ''').fetchall() for row in rows: if row[0] == 'test_name': self.assertEqual(row[1], 0) else: self.assertEqual(row[1], other_policy.idx) # we should have stats for both containers stats = broker.get_policy_stats() self.assertEqual(len(stats), 2) self.assertEqual(stats[0]['object_count'], 1) self.assertEqual(stats[0]['bytes_used'], 2) self.assertEqual(stats[1]['object_count'], 3) self.assertEqual(stats[1]['bytes_used'], 4) # now lets delete a container and make sure policy_stats is OK with broker.get() as conn: conn.execute(''' DELETE FROM container WHERE name = ? ''', ('test_name',)) conn.commit() stats = broker.get_policy_stats() self.assertEqual(len(stats), 2) self.assertEqual(stats[0]['object_count'], 0) self.assertEqual(stats[0]['bytes_used'], 0) self.assertEqual(stats[1]['object_count'], 3) self.assertEqual(stats[1]['bytes_used'], 4) @with_tempdir def test_half_upgraded_database(self, tempdir): db_path = os.path.join(tempdir, 'account.db') ts = itertools.count() broker = AccountBroker(db_path, account='a') broker.initialize(normalize_timestamp(ts.next())) self.assertTrue(broker.empty()) # add a container (to pending file) broker.put_container('c', normalize_timestamp(ts.next()), 0, 0, 0, POLICIES.default.idx) real_get = broker.get called = [] @contextmanager def mock_get(): with real_get() as conn: def mock_executescript(script): if called: raise Exception('kaboom!') called.append(script) conn.executescript = mock_executescript yield conn broker.get = mock_get try: broker._commit_puts() except Exception: pass else: self.fail('mock exception was not raised') self.assertEqual(len(called), 1) self.assert_('CREATE TABLE policy_stat' in called[0]) # nothing was commited broker = AccountBroker(db_path, account='a') with broker.get() as conn: try: conn.execute('SELECT * FROM policy_stat') except sqlite3.OperationalError as err: self.assert_('no such table: policy_stat' in str(err)) else: self.fail('half upgraded database!') container_count = conn.execute( 'SELECT count(*) FROM container').fetchone()[0] self.assertEqual(container_count, 0) # try again to commit puts self.assertFalse(broker.empty()) # full migration successful with broker.get() as conn: conn.execute('SELECT * FROM policy_stat') conn.execute('SELECT storage_policy_index FROM container')"," broker.put_container('o', normalize_timestamp(time()), 0, 0, 0) broker.put_container('o', 0, normalize_timestamp(time()), 0, 0) broker.put_container('c', normalize_timestamp(time()), 0, 0, 0) broker.put_container('c', 0, normalize_timestamp(time()), 0, 0) broker.put_container('x', 0, 0, 0, 0) broker.put_container('y', 0, 0, 0, 0) broker.put_container('z', 0, 0, 0, 0) broker.put_container('o', normalize_timestamp(time()), 0, 0, 0) broker.put_container('o', 0, normalize_timestamp(time()), 0, 0) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0) broker.put_container('""{<container \'&\' name>}""', otimestamp, 0, 0, 0) broker.put_container('""{<container \'&\' name>}""', 0, dtimestamp, 0, 0) broker.put_container('""{<container \'&\' name>}""', 0, timestamp, 0, 0) broker.put_container('""{<container \'&\' name>}""', timestamp, 0, 0, 0) broker.put_container('c1', normalize_timestamp(time()), 0, 0, 0) broker.put_container('c2', normalize_timestamp(time()), 0, 0, 0) broker.put_container('c2', normalize_timestamp(time()), 0, 0, 0) broker.put_container('c1', 0, normalize_timestamp(time()), 0, 0) broker.put_container('c2', 0, normalize_timestamp(time()), 0, 0) normalize_timestamp(time()), 0, 0, 0) normalize_timestamp(time()), 0, 0, 0) normalize_timestamp(time()), 0, 0, 0) broker.put_container('3-0049-', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a-', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a-a', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a-a-a', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a-a-b', normalize_timestamp(time()), 0, 0, 0) broker.put_container('a-b', normalize_timestamp(time()), 0, 0, 0) broker.put_container('b', normalize_timestamp(time()), 0, 0, 0) broker.put_container('b-a', normalize_timestamp(time()), 0, 0, 0) broker.put_container('b-b', normalize_timestamp(time()), 0, 0, 0) broker.put_container('c', normalize_timestamp(time()), 0, 0, 0) normalize_timestamp(0), 0, 0) normalize_timestamp(0), 0, 0) normalize_timestamp(0), 0, 0) broker1.put_container('a', normalize_timestamp(1), 0, 0, 0) broker1.put_container('b', normalize_timestamp(2), 0, 0, 0) broker1.put_container('c', normalize_timestamp(3), 0, 0, 0)",995,87
openstack%2Fswift~master~Ib9a0dd42c271145e641437dc04d0ebea1e11fc47,openstack/swift,master,Ib9a0dd42c271145e641437dc04d0ebea1e11fc47,Merge container storage_policy_index,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:23:21.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/47dfab337a0f53ce9986c4c5f2b806c1fc89af6f', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9629d4999214eb9f2aae5e3e3b9f8af0393c43c9', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8c7d9f0033522f87b946e3c18039f2eae00dd868', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8311336a817591ef2cc7002327bda4608f10165f', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a002fa615fdea0744447c960626348e6ebb90602', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/39020872b179b9cf1a63418a6b99542beef3f746', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/860f5d49ffdff2b59b9bf853b94c9c323fcf3d4b', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/091c88e8e72c4f16a2f1d8dce83a4ab2c4657a40', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0194842a4c60d6dc02b0d8b384b94638f0d8716c', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7f6714775d079d5c17988688236ac53ee80a789e', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4afa6df681c839f253807786cd133dc7661d849a', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/221e3d0731782b0ff52343d8b569606ac4468e60', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f9280311ec47abe8844aba88263e1ea07d02ad2d', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/container/test_replicator.py', 'swift/container/server.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'swift/container/replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/81bc31e6ecebb63deb33406b342aebc9e44d3c51', 'message': 'Merge container storage_policy_index\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}]",7,96040,81bc31e6ecebb63deb33406b342aebc9e44d3c51,57,6,14,1179,,,0,"Merge container storage_policy_index

Keep status_changed_at in container databases current with status changes that
occur as a result of container creation, deletion, or re-creation.

Merge container put/delete/created timestamps when handling replicate
responses from remote servers in addition to during the handling of the
REPLICATE request.

When storage policies are configured on a cluster send status_changed_at,
object_count and storage_policy_index as part of container replication sync
args.

Use status_changed_at during replication to determine the oldest active
container and merge storage_policy_index.

DocImpact
Implements: blueprint storage-policies
Change-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/96040/10 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'test/unit/container/test_replicator.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'swift/container/replicator.py']",6,47dfab337a0f53ce9986c4c5f2b806c1fc89af6f,bp/storage-policies,"import time from swift.container.reconciler import incorrect_policy_indexfrom swift.common.utils import json, normalize_timestamp from swift.common.http import is_success from swift.common.storage_policy import POLICIES def _gather_sync_args(self, replication_info): parent = super(ContainerReplicator, self) sync_args = parent._gather_sync_args(replication_info) if len(POLICIES) > 1: sync_args += tuple(replication_info[k] for k in ('status_changed_at', 'count', 'storage_policy_index')) return sync_args def _handle_sync_response(self, node, response, info, broker, http): parent = super(ContainerReplicator, self) if is_success(response.status): remote_info = json.loads(response.data) if incorrect_policy_index(info, remote_info): status_changed_at = normalize_timestamp(time.time()) broker.set_storage_policy_index( remote_info['storage_policy_index'], timestamp=status_changed_at) broker.merge_timestamps(*(remote_info[key] for key in ( 'created_at', 'put_timestamp', 'delete_timestamp'))) rv = parent._handle_sync_response( node, response, info, broker, http) return rv class ContainerReplicatorRpc(db_replicator.ReplicatorRpc): def _parse_sync_args(self, args): parent = super(ContainerReplicatorRpc, self) remote_info = parent._parse_sync_args(args) if len(args) > 9: remote_info['status_changed_at'] = args[7] remote_info['count'] = args[8] remote_info['storage_policy_index'] = args[9] return remote_info def _handle_sync_request(self, broker, remote_info): if incorrect_policy_index(broker.get_info(), remote_info): status_changed_at = normalize_timestamp(time.time()) broker.set_storage_policy_index( remote_info['storage_policy_index'], timestamp=status_changed_at) parent = super(ContainerReplicatorRpc, self) rv = parent._handle_sync_request(broker, remote_info) return rv",,876,81
openstack%2Fswift~master~I0f220869e33c461a4100b21c6324ad725da864fa,openstack/swift,master,I0f220869e33c461a4100b21c6324ad725da864fa,Add LRUCache to common.utils,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:23:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab59aa020faac5c80c5b1313c3ae9229526500fb', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2dd0f1cb7b8739304eab0050d8227bb84f47dfad', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4935b0c9e75328cecd6bedc0b87a3c0aa648f444', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e7e020cff011ec187d4a23d8eef4543eb64b2f16', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c6638d0a36b8b434ddeefd73774dc1f2d5be6e90', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4541967e2f376a55e3d0a95de836c0cfc5ba9d61', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e9635297585cb8064076de271c4923baecf485fa', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/50904eb02e07c545d0ea4f4dc268884b32e31c95', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aace10905b71403c3c5157361405d09876a008a0', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6203abc2f6e108d7af7752f6cb78f61ad3664c34', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8a0a7993664a684d1cedd6735b765030f483fbf9', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d360588a43f7506a319c078163a07d494174f36f', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/644ed5e5c1acadd47aecad450e9e0d3fb8d3885b', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/89d6cc4da427f07cbd8e803473e8e150f3aad242', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/common/utils.py', 'test/unit/container/test_reconciler.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/fbcfb83566c2a56245ed10823f09c1007845b4f5', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}]",12,96045,fbcfb83566c2a56245ed10823f09c1007845b4f5,63,6,15,1179,,,0,"Add LRUCache to common.utils

This decorator will memonize a function using a fixed size cache that evicts
the oldest entries.  It also supports a maxtime paramter to configure a
""time-to-live"" for entries in the cache.

The reconciler code uses this to cache computations of the correct storage
policy index for a container for 30 seconds.

DocImpact
Implements: blueprint storage-policies
Change-Id: I0f220869e33c461a4100b21c6324ad725da864fa
",git fetch https://review.opendev.org/openstack/swift refs/changes/45/96045/9 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/container/test_reconciler.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py']",4,ab59aa020faac5c80c5b1313c3ae9229526500fb,bp/storage-policies,"import mathclass TestLRUCache(unittest.TestCase): def test_maxsize(self): @utils.LRUCache(maxsize=10) def f(*args): return math.sqrt(*args) _orig_math_sqrt = math.sqrt # setup cache [0-10) for i in range(10): self.assertEqual(math.sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate cache [0-10) with patch('math.sqrt'): for i in range(10): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) # update cache [10-20) for i in range(10, 20): self.assertEqual(math.sqrt(i), f(i)) # cache size is fixed self.assertEqual(f.size(), 10) # validate cache [10-20) with patch('math.sqrt'): for i in range(10, 20): self.assertEqual(_orig_math_sqrt(i), f(i)) # validate un-cached [0-10) with patch('math.sqrt', new=None): for i in range(10): self.assertRaises(TypeError, f, i) # cache unchanged self.assertEqual(f.size(), 10) with patch('math.sqrt'): for i in range(10, 20): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) def test_maxtime(self): @utils.LRUCache(maxtime=30) def f(*args): return math.sqrt(*args) self.assertEqual(30, f.maxtime) _orig_math_sqrt = math.sqrt # setup cache [0-10) for i in range(10): self.assertEqual(math.sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate cache [0-10) with patch('math.sqrt'): for i in range(10): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate expired [0-10) the_future = time.time() + 30 with patch('math.sqrt', new=None): with patch('time.time', lambda: the_future): for i in range(10): self.assertRaises(TypeError, f, i) # validate recache [10-20) the_future = time.time() + 31 with patch('time.time', lambda: the_future): for i in range(10): self.assertEqual(math.sqrt(i), f(i)) # reuses cache space self.assertEqual(f.size(), 10) def test_set_maxtime(self): @utils.LRUCache(maxtime=30) def f(*args): return math.sqrt(*args) self.assertEqual(30, f.maxtime) self.assertEqual(2, f(4)) self.assertEqual(1, f.size()) # expire everything f.maxtime = -1 # validate un-cached [0-10) with patch('math.sqrt', new=None): self.assertRaises(TypeError, f, 4) def test_set_maxsize(self): @utils.LRUCache(maxsize=10) def f(*args): return math.sqrt(*args) for i in range(12): f(i) self.assertEqual(f.size(), 10) f.maxsize = 4 for i in range(12): f(i) self.assertEqual(f.size(), 4) ",,233,1
openstack%2Fswift~master~I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3,openstack/swift,master,I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3,Add Storage Policy Support to list_endpoints,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:23:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a360aa64bea08e8d8f612641c398a5e4fea00526', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e11b6948db3e5afd65b7ea1a024c8283cc38b812', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9870b19b9966223df96e26a725a80d7df11e7487', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e3cf6f593668e0b914fdb1b68b6d062e58793873', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ebe2b4c5ac46b3f6d28fa821e7756bf4280326d6', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/86f3ebb4ed57d0e0110f097b1c8a19c1837b587e', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2f06ef7419e636df7c133bbc8927f61cbac51d9d', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3d747f63a2eb4e09285e7e41ed518b5782873970', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/26254106ddcfe0fabc8d7bf340f7bcc72765bdd5', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d083bf0a8906b9bd5d5979ff2d30017581fe8e10', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bbba27d1a1da493f52e82f673beb7333d5339af3', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b2a3d47b3558b770ccab16e7d04901123ebd2ddb', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0279af68fc20ffe865800f064530929bc1050ab4', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/250d3dd90399907a1b5b064d223aafe574edfe09', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nAlso added policy support for custom endpoint names which was\nmissing before and tightened up unit test coverage for both\nfunctional issues addressed here.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/common/middleware/list_endpoints.py', 'test/unit/common/middleware/test_list_endpoints.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/019d7f5cda388c3053e369ca70902d03b72cca22', 'message': 'Add Storage Policy Support to list_endpoints\n\nThis patch makes list_endpoints policy aware so that the object is\nlooked up in the right ring and its actual locations returned to the\nclient.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3\n'}]",4,96046,019d7f5cda388c3053e369ca70902d03b72cca22,71,7,15,1179,,,0,"Add Storage Policy Support to list_endpoints

This patch makes list_endpoints policy aware so that the object is
looked up in the right ring and its actual locations returned to the
client.

DocImpact
Implements: blueprint storage-policies
Change-Id: I56d4b0f4f321a4c72b11ec44d868a194d02ea3a3
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/96046/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/list_endpoints.py', 'test/unit/common/middleware/test_list_endpoints.py']",2,a360aa64bea08e8d8f612641c398a5e4fea00526,bp/storage-policies,"import mockfrom swift.common.utils import json, split_pathfrom swift.common.storage_policy import StoragePolicy, POLICIES from test.unit import patch_policies@patch_policies([StoragePolicy(0, 'zero', False), StoragePolicy(1, 'one', True)]) objectgz_1 = os.path.join(self.testdir, 'object-1.ring.gz') self.policy_to_test = 0 self.expected_path = ('v1', 'a', 'c', 'o1') intended_replica2part2dev_id_o_1 = [ array.array('H', [1, 0, 1, 0]), array.array('H', [1, 0, 1, 0]), array.array('H', [4, 3, 4, 3])] ring.RingData(intended_replica2part2dev_id_o_1, intended_devs, intended_part_shift).save(objectgz_1) def FakeGetInfo(self, env, app, swift_source=None): info = {'status': 0, 'sync_key': None, 'meta': {}, 'cors': {'allow_origin': None, 'expose_headers': None, 'max_age': None}, 'sysmeta': {}, 'read_acl': None, 'object_count': None, 'write_acl': None, 'versions': None, 'bytes': None} info['storage_policy'] = self.policy_to_test (version, account, container, unused) = \ split_path(env['PATH_INFO'], 3, 4, True) self.assertEquals((version, account, container, unused), self.expected_path) return info def test_get_object_ring(self): self.assertEquals(isinstance(self.list_endpoints.get_object_ring(0), ring.Ring), True) self.assertEquals(isinstance(self.list_endpoints.get_object_ring(1), ring.Ring), True) self.assertRaises(ValueError, self.list_endpoints.get_object_ring, 99) # test policies with default endpoint name expected = [[ ""http://10.1.1.1:6000/sdb1/1/a/c/o1"", ""http://10.1.2.2:6000/sdd1/1/a/c/o1""], [ ""http://10.1.1.1:6000/sda1/1/a/c/o1"", ""http://10.1.2.1:6000/sdc1/1/a/c/o1"" ]] PATCHGI = 'swift.common.middleware.list_endpoints.get_container_info' for pol in POLICIES: self.policy_to_test = pol.idx with mock.patch(PATCHGI, self.FakeGetInfo): resp = Request.blank('/endpoints/a/c/o1').get_response( self.list_endpoints) self.assertEquals(resp.status_int, 200) self.assertEquals(resp.content_type, 'application/json') self.assertEquals(json.loads(resp.body), expected[pol.idx]) # test policies with custom endpoint name for pol in POLICIES: # test custom path with trailing slash custom_path_le = list_endpoints.filter_factory({ 'swift_dir': self.testdir, 'list_endpoints_path': '/some/another/path/' })(self.app) self.policy_to_test = pol.idx with mock.patch(PATCHGI, self.FakeGetInfo): resp = Request.blank('/some/another/path/a/c/o1') \ .get_response(custom_path_le) self.assertEquals(resp.status_int, 200) self.assertEquals(resp.content_type, 'application/json') self.assertEquals(json.loads(resp.body), expected[pol.idx]) # test ustom path without trailing slash custom_path_le = list_endpoints.filter_factory({ 'swift_dir': self.testdir, 'list_endpoints_path': '/some/another/path' })(self.app) self.policy_to_test = pol.idx with mock.patch(PATCHGI, self.FakeGetInfo): resp = Request.blank('/some/another/path/a/c/o1') \ .get_response(custom_path_le) self.assertEquals(resp.status_int, 200) self.assertEquals(resp.content_type, 'application/json') self.assertEquals(json.loads(resp.body), expected[pol.idx])","from swift.common.utils import json # test custom path with trailing slash custom_path_le = list_endpoints.filter_factory({ 'swift_dir': self.testdir, 'list_endpoints_path': '/some/another/path/' })(self.app) resp = Request.blank('/some/another/path/a/c/o1') \ .get_response(custom_path_le) self.assertEquals(resp.status_int, 200) self.assertEquals(resp.content_type, 'application/json') self.assertEquals(json.loads(resp.body), [ ""http://10.1.1.1:6000/sdb1/1/a/c/o1"", ""http://10.1.2.2:6000/sdd1/1/a/c/o1"" ]) # test ustom path without trailing slash custom_path_le = list_endpoints.filter_factory({ 'swift_dir': self.testdir, 'list_endpoints_path': '/some/another/path' })(self.app) resp = Request.blank('/some/another/path/a/c/o1') \ .get_response(custom_path_le) self.assertEquals(resp.status_int, 200) self.assertEquals(resp.content_type, 'application/json') self.assertEquals(json.loads(resp.body), [ ""http://10.1.1.1:6000/sdb1/1/a/c/o1"", ""http://10.1.2.2:6000/sdd1/1/a/c/o1"" ])",102,33
openstack%2Fswift~master~If17bc7b9737558d3b9a54eeb6ff3e6b51463f002,openstack/swift,master,If17bc7b9737558d3b9a54eeb6ff3e6b51463f002,Add functional tests for Storage Policy,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:22:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 7233}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/350500d06b1fd399b4e1e723538ab5c2ced7172c', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e019be3931ac6e2bb662ba430f0dd6d41ed80c57', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/71b4e40a07c40027198736325f52db487f696632', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/db3da9804e0f260dd81fbac7e17820d600f892fb', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3bef5738bb61ba11acf918fe2c7bbb4f70e38af3', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3dcb4c48cb51425fca9e2fb9f18efec723c3323a', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9f0d0b571a38bd38d6fea68faa404855b6be178e', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/72b9373cef4af98ff5f1a129c47bf907a02c8cba', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9838f3c0f08b54cf7da676c4511070b2d8e4628e', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/35ea1d91f8aa045b4beea54487bbfcaa5e88e1e2', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e02593a76b94a2aaa9ee7b45e0dc58b832ff2fda', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6bc9e1435b5b45a9d19f0daf3923a5e8f95d70d3', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/27cd911b394de55b8a82ce485b9c6ea517ee7b69', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/functional/test_account.py', 'test/functional/tests.py', 'test/functional/__init__.py', 'test/functional/test_object.py', 'test/functional/test_container.py', 'test/functional/swift_test_client.py', 'swift/proxy/controllers/container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c11ac012522a7e742ac942637af12a3e090d53ef', 'message': 'Add functional tests for Storage Policy\n\n * additional container tests\n * refactor test cross policy copy\n * make functional tests cleanup better\n\nIn-process functional tests only define a single ring and will skip some of\nthe multi-storage policy tests, but have been updated to reload_policies with\nthe patched swift.conf.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002\n'}]",1,96042,c11ac012522a7e742ac942637af12a3e090d53ef,57,6,14,1179,,,0,"Add functional tests for Storage Policy

 * additional container tests
 * refactor test cross policy copy
 * make functional tests cleanup better

In-process functional tests only define a single ring and will skip some of
the multi-storage policy tests, but have been updated to reload_policies with
the patched swift.conf.

DocImpact
Implements: blueprint storage-policies
Change-Id: If17bc7b9737558d3b9a54eeb6ff3e6b51463f002
",git fetch https://review.opendev.org/openstack/swift refs/changes/42/96042/14 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/__init__.py', 'test/functional/test_account.py', 'test/functional/test_object.py', 'test/functional/test_container.py', 'test/functional/swift_test_client.py', 'swift/proxy/controllers/container.py']",6,350500d06b1fd399b4e1e723538ab5c2ced7172c,bp/storage-policies, 'x-versions-location']," 'x-versions-location', POLICY_INDEX.lower()]",386,58
openstack%2Fswift~master~I9b287d15f2426022d669d1186c9e22dd8ca13fb9,openstack/swift,master,I9b287d15f2426022d669d1186c9e22dd8ca13fb9,Extend interface on InternalClient,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:22:46.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/945e157027490dff153a5f68da957d1fe823a183', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ea314de9e350b7df039beb4a4029a78e4c8ae97d', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2b9d4cf259b8de8ed86f291106d3504078ee5827', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6f9e2f5df7025941061347380c34970d848ae9ea', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d611c9769b7aafdc59dffa1428321a104eebf3a4', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c957a5879de260fcce864ea6ca57323a20e9e26c', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 7, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1484b843c64570c9ed2deaa99abf1a72e97745b2', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/332c2157ddadd5de7c825e272fdad35ee4165ce9', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/62d181f5ee3b342f21d4bbc3a49041bdcd2d50da', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2cd90b740d9d3f188716e20dbeaa1305ebae923d', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3d38e4f23cba06c2e0728e7b0a5808b7c9a55c9d', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/456f9bbeb2ec7c0280bdc6bc06e83af5ce9ad7f9', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6046536106793f30462c43273d81473a77b7dc58', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/obj/server.py', 'test/unit/common/test_internal_client.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_base.py', 'swift/common/wsgi.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py', 'test/unit/common/test_wsgi.py', 'test/unit/common/middleware/helpers.py', 'swift/common/internal_client.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8bec50838cfe86ef5f143551c6a5af8fd0f5e621', 'message': ""Extend interface on InternalClient\n\n * add get_object\n * allow extra headers passthrough on HEAD/metadata reqeusts\n * expose (account|container|get_object)_ring properties\n\nPipeline propety access to the auto_create_account_prefix also allows us to\nbypass the early exit on a container HEAD for auto_create_accounts if the\ncontainer-updater hasn't cycled yet.\n\nAllow overriding of storage policy index.\n\nThis is something the reconciler will need so that it can GET from one\npolicy, PUT in another, and then DELETE from the first one again.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9\n""}]",16,96036,8bec50838cfe86ef5f143551c6a5af8fd0f5e621,60,8,14,1179,,,0,"Extend interface on InternalClient

 * add get_object
 * allow extra headers passthrough on HEAD/metadata reqeusts
 * expose (account|container|get_object)_ring properties

Pipeline propety access to the auto_create_account_prefix also allows us to
bypass the early exit on a container HEAD for auto_create_accounts if the
container-updater hasn't cycled yet.

Allow overriding of storage policy index.

This is something the reconciler will need so that it can GET from one
policy, PUT in another, and then DELETE from the first one again.

DocImpact
Implements: blueprint storage-policies
Change-Id: I9b287d15f2426022d669d1186c9e22dd8ca13fb9
",git fetch https://review.opendev.org/openstack/swift refs/changes/36/96036/9 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/common/test_internal_client.py', 'test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_base.py', 'swift/common/wsgi.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py', 'test/unit/common/middleware/helpers.py', 'test/unit/common/test_wsgi.py', 'swift/common/internal_client.py', 'swift/proxy/controllers/base.py']",11,945e157027490dff153a5f68da957d1fe823a183,bp/storage-policies," if not get_info(app, env, account) and not account.startswith( getattr(app, 'auto_create_account_prefix', '.')):"," if not get_info(app, env, account):",435,32
openstack%2Fswift~master~Ica05f41ecf3adb3648cc9182f11f1c8c5c678985,openstack/swift,master,Ica05f41ecf3adb3648cc9182f11f1c8c5c678985,Add Storage Policy Support,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:22:36.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 995}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7680}, {'_account_id': 7847}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2fbf8ea4942c2b2dad2ec32548aa15a0b7c21a84', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname assocaited with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. T allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab2537435261be49424f0b330a6878ed68340366', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname assocaited with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. T allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8b9a03e18841eb4da52ba46fd3e528e111b1c449', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname assocaited with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/82f4f2f1997d1ca144c4343be1811a566dbb430c', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname assocaited with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 5, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a9f5b01ada112e464bb06596b78f5bfbab9c803d', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 6, 'created': '2014-06-02 23:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/28961a464bc358d6e0d993bb9faaace24bcc97c5', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 7, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/18157c884dff384e4b29d9bce47457a76e3bc870', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 8, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/12991ad79f71d3334fbe89ba95409140d01807f5', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 9, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0fa15b2c26325e7daa595fa3923df2a2f0d7e71c', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 10, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e685a4c9b3e9e1ccd25c0d13bcd9143c121be403', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 11, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dc5ed12d95bd71d286ccc128c3308abdad11d6ad', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 12, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b3f8c9570d10b116bf82eab25096741355763c1', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}, {'number': 13, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/46c68aebd14e5c9ee20a89e7638e1daac4576e7b', 'message': ""Add Storage Policy Support\n\nThe basic idea here is to replace the use of a single object ring in\nthe Application class with a collection of object rings. The\ncollection includes not only the Ring object itself but the policy\nname associated with it, the filename for the .gz and any other\nmetadata associated with the policy that may be needed. When\ncontainers are created, a policy (thus a specific obj ring) is\nselected allowing apps to specify policy at container creation time\nand leverage policies simply by using different containers for object\noperations.\n\nThe policy collection is based off of info in the swift.conf file.\nThe format of the sections in the .conf file is as follows:\n\nswift.conf format:\n\n    [storage-policy:0]\n    name = chicken\n\n    [storage-policy:1]\n    name = turkey\n    default = yes\n\nWith the above format:\n\n- Policy 0 will always be used for access to existing containers\n  without the policy specified. The ring name for policy 0 is always\n  'object', assuring backwards compatiblity. The parser will always\n  create a policy 0 even if not specified\n\n- The policy with 'default=yes' is the one used for new container\n  creation. This allows the admin to specify which policy is used without\n  forcing the application to add the metadata.\n\nThis commit simply introduces storage policies and the loading\nthereof; nobody's using it yet. That will follow in subsequent\ncommits.\n\nExpose storage policies in /info\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985\n""}]",135,96027,46c68aebd14e5c9ee20a89e7638e1daac4576e7b,101,16,13,1179,,,0,"Add Storage Policy Support

The basic idea here is to replace the use of a single object ring in
the Application class with a collection of object rings. The
collection includes not only the Ring object itself but the policy
name associated with it, the filename for the .gz and any other
metadata associated with the policy that may be needed. When
containers are created, a policy (thus a specific obj ring) is
selected allowing apps to specify policy at container creation time
and leverage policies simply by using different containers for object
operations.

The policy collection is based off of info in the swift.conf file.
The format of the sections in the .conf file is as follows:

swift.conf format:

    [storage-policy:0]
    name = chicken

    [storage-policy:1]
    name = turkey
    default = yes

With the above format:

- Policy 0 will always be used for access to existing containers
  without the policy specified. The ring name for policy 0 is always
  'object', assuring backwards compatiblity. The parser will always
  create a policy 0 even if not specified

- The policy with 'default=yes' is the one used for new container
  creation. This allows the admin to specify which policy is used without
  forcing the application to add the metadata.

This commit simply introduces storage policies and the loading
thereof; nobody's using it yet. That will follow in subsequent
commits.

Expose storage policies in /info

DocImpact
Implements: blueprint storage-policies
Change-Id: Ica05f41ecf3adb3648cc9182f11f1c8c5c678985
",git fetch https://review.opendev.org/openstack/swift refs/changes/27/96027/13 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/container.rst', 'doc/saio/swift/swift.conf', 'test/unit/proxy/test_server.py', 'doc/source/development_saio.rst', 'test/unit/__init__.py', 'doc/source/middleware.rst', 'doc/source/overview_replication.rst', 'swift/proxy/server.py', 'doc/source/admin_guide.rst', 'doc/source/index.rst', 'doc/saio/bin/remakerings', 'doc/source/overview_architecture.rst', 'test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'doc/source/misc.rst']",16,2fbf8ea4942c2b2dad2ec32548aa15a0b7c21a84,bp/storage-policies, .. _storage_policy: Storage Policy ============== .. automodule:: swift.common.storage_policy :members: :show-inheritance:,,830,23
openstack%2Fswift~master~I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72,openstack/swift,master,I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72,Add reconciler probetest outline,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:22:13.000000000,,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7e39a58f1e0a14c7c2cf4e0726b7fff73dc448e6', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/729c6b8868ad652a3840f47cac2518441d0921e6', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9acfd1aa9e64bcb367947b4a04dd018b88c0d557', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/df697ec89f37d1b947790879cd118a62cb8a83a5', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cdc6d2326166a7b1e7fc8c2b7c888fc5d6e7441e', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/45b4d3695d4ad4697879823bb28198cdc163f117', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9093257b83b9e35083f3b6236f31f0da47c89d3d', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/65724bb3c24e3cdb8165bd979664325469119aac', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/87901f1948ba7e031cb008738f6916354cdad49d', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/79ecac9073f0ef1d5ca015a083ffaa489e6419e0', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bc210adadf7647703b1f5981b3058f2117b52483', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5499bcd4faeeac2097bd7018a8bc705e36f24451', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f5874a9a26c2234c9aec22e0a8acc2f89b855101', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': ['test/probe/test_container_merge_policy_index.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3dff1249f5972460431ca1220ed7da407ce55bef', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}]",6,96039,3dff1249f5972460431ca1220ed7da407ce55bef,69,10,14,1179,,,0,"Add reconciler probetest outline

You can manually setup a split brain scenario for reconciler testing with the
enqueue script using the machinery from the included probetest.  Evoke the
test as a script with with 'split-brain' command for more help.

DocImpact
Implements: blueprint storage-policies
Change-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72
",git fetch https://review.opendev.org/openstack/swift refs/changes/39/96039/6 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_container_merge_policy_index.py'],1,7e39a58f1e0a14c7c2cf4e0726b7fff73dc448e6,bp/storage-policies,"#!/usr/bin/python -u # Copyright (c) 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import sys import itertools import unittest import uuid from optparse import OptionParser from swift.common.manager import Manager from swift.common.storage_policy import POLICIES from swift.common import utils from swift.common.http import HTTP_NOT_FOUND from test.probe.common import reset_environment from swiftclient import client, get_auth, ClientException TIMEOUT = 60 def meta_command(name, bases, attrs): """""" Look for attrs with a truthy attribute __command__ and add them to an attribtue __commands__ on the type that maps names to decorated methods. The decorated methods doc strings also get mapped in __docs__. Also adds a method run(command_name, *args, **kwargs) that will execute the method mapped to the name in __commands__. """""" commands = {} docs = {} for attr, value in attrs.items(): if getattr(value, '__command__', False): commands[attr] = value # methods have always have a __doc__ attribute, sometimes empty docs[attr] = (getattr(value, '__doc__', None) or 'perform the %s command' % attr).strip() attrs['__commands__'] = commands attrs['__docs__'] = docs def run(self, command, *args, **kwargs): return self.__commands__[command](self, *args, **kwargs) attrs.setdefault('run', run) return type(name, bases, attrs) def command(f): f.__command__ = True return f class BrainSplitter(object): __metaclass__ = meta_command def __init__(self, url, token, container_name='test', object_name='test'): self.url = url self.token = token self.container_name = container_name self.object_name = object_name self.servers = Manager(['container-server']) self.policies = itertools.cycle(POLICIES) @command def start_first_half(self): """""" start container servers 1 & 2 """""" tuple(self.servers.start(number=n) for n in (1, 2)) @command def stop_first_half(self): """""" stop container servers 1 & 2 """""" tuple(self.servers.stop(number=n) for n in (1, 2)) @command def start_second_half(self): """""" start container servers 3 & 4 """""" tuple(self.servers.start(number=n) for n in (3, 4)) @command def stop_second_half(self): """""" stop container servers 3 & 4 """""" tuple(self.servers.stop(number=n) for n in (3, 4)) @command def put_container(self, policy_index=None): """""" put container with next storage policy """""" policy = self.policies.next() if policy_index is not None: policy = POLICIES.get_by_index(int(policy_index)) if not policy: raise ValueError('Unknown policy with index %s' % policy) headers = {'X-Storage-Policy': policy.name} client.put_container(self.url, self.token, self.container_name, headers=headers) @command def delete_container(self): """""" delete container """""" client.delete_container(self.url, self.token, self.container_name) @command def put_object(self): """""" issue put for zero byte test object """""" client.put_object(self.url, self.token, self.container_name, self.object_name) @command def delete_object(self): """""" issue delete for test object """""" try: client.delete_object(self.url, self.token, self.container_name, self.object_name) except ClientException as err: if err.http_status != HTTP_NOT_FOUND: raise parser = OptionParser('%prog split-brain [options] ' '<command>[:<args>[,<args>...]] [<command>...]') parser.usage += '\n\nCommands:\n\t' + \ '\n\t'.join(""%s - %s"" % (name, doc) for name, doc in BrainSplitter.__docs__.items()) parser.add_option('-c', '--container', default='container-%s' % uuid.uuid4(), help='set container name') parser.add_option('-o', '--object', default='object-%s' % uuid.uuid4(), help='set object name') class TestContainerMergePolicyIndex(unittest.TestCase): def setUp(self): if len(POLICIES) < 2: raise unittest.SkipTest() (self.pids, self.port2server, self.account_ring, self.container_ring, self.object_ring, self.url, self.token, self.account, self.configs) = reset_environment() self.container_name = 'container-%s' % uuid.uuid4() self.object_name = 'object-%s' % uuid.uuid4() self.brain = BrainSplitter(self.url, self.token, self.container_name, self.object_name) def main(): options, commands = parser.parse_args() commands.remove('split-brain') if not commands: parser.print_help() return 'ERROR: must specifiy at least one command' for cmd_args in commands: cmd = cmd_args.split(':', 1)[0] if cmd not in BrainSplitter.__commands__: parser.print_help() return 'ERROR: unknown command %s' % cmd url, token = get_auth('http://127.0.0.1:8080/auth/v1.0', 'test:tester', 'testing') brain = BrainSplitter(url, token, options.container, options.object) for cmd_args in commands: parts = cmd_args.split(':', 1) command = parts[0] if len(parts) > 1: args = utils.list_from_csv(parts[1]) else: args = () try: brain.run(command, *args) except ClientException as e: print '**WARNING**: %s raised %s' % (command, e) print 'STATUS'.join(['*' * 25] * 2) brain.servers.status() sys.exit() if __name__ == ""__main__"": if any('split-brain' in arg for arg in sys.argv): sys.exit(main()) unittest.main() ",,205,0
openstack%2Fswift~master~If57d3b0ff8c395f21c81fda76458bc34fcb23257,openstack/swift,master,If57d3b0ff8c395f21c81fda76458bc34fcb23257,Add Storage Policy Support to Container Sync,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:21:11.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/889cad10405c2c86f35b80d7121078234c4c162a', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/639baa010f648af896e3da923eca94ac868d7f66', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/35f98559b8d5ea02103ba4f5514a1d95bacecd35', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/741580c6f5f57f783ee249cc55b545ac12502557', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f9fc3d615167a6c1c49d273598b735e934e43834', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8a10957b6d3cbb0d46fa4ab780f6eee8b5794ad9', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2cc13b4ca89a52c904f03ba2201a34dd7e954f5b', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9f3ae3dcfdaf2d53628633d453318563a11d11bb', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/138a3bceca68be175de4dad8e72ae45db8f4ce21', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fc5a715ba1803353a3cb510e7503d4466ded150a', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1435c05257d6d8d8784c755ba23c7ac0e0bb6fe5', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1cee5d70e7d457f034c275077577479dc82cb9ba', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/84096fd22dea4875b95d6005d382ab2315ef26ed', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/62777fb33d52f940248e20193080d1908aa24a66', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['swift/container/sync.py', 'test/unit/common/middleware/test_container_sync.py', 'etc/proxy-server.conf-sample', 'test/unit/container/test_sync.py', 'swift/common/middleware/container_sync.py', 'test/probe/test_container_sync.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6da9799917b632675ee69fe315bacfdb4c7c926a', 'message': ""Add Storage Policy Support to Container Sync\n\nHave container sync get its object ring from POLICIES now,\nupdate tests to use policy index from container_info and pass\nthat along for use in ring selection.\n\nThis change also introduced the option of specifiying in the cluster info\nwhich of the relam/cluster's is the current realm/cluster.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257\n""}]",4,96047,6da9799917b632675ee69fe315bacfdb4c7c926a,69,7,15,1179,,,0,"Add Storage Policy Support to Container Sync

Have container sync get its object ring from POLICIES now,
update tests to use policy index from container_info and pass
that along for use in ring selection.

This change also introduced the option of specifiying in the cluster info
which of the relam/cluster's is the current realm/cluster.

DocImpact
Implements: blueprint storage-policies
Change-Id: If57d3b0ff8c395f21c81fda76458bc34fcb23257
",git fetch https://review.opendev.org/openstack/swift refs/changes/47/96047/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/sync.py', 'test/unit/common/middleware/test_container_sync.py', 'etc/proxy-server.conf-sample', 'test/unit/container/test_sync.py', 'swift/common/middleware/container_sync.py', 'test/probe/test_container_sync.py']",6,889cad10405c2c86f35b80d7121078234c4c162a,bp/storage-policies,"#!/usr/bin/python -u # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import unittest import uuid from urlparse import urlparse import random from swiftclient import client from swift.common.storage_policy import POLICIES from swift.common.manager import Manager from test.probe.common import kill_servers, reset_environment def get_current_realm_cluster(url): parts = urlparse(url) url = parts.scheme + '://' + parts.netloc + '/info' http_conn = client.http_connection(url) try: info = client.get_capabilities(http_conn) except client.ClientException: raise unittest.SkipTest('Unable to retrieve cluster info') try: realms = info['container_sync']['realms'] except KeyError: raise unittest.SkipTest('Unable to find container sync realms') for realm, realm_info in realms.items(): for cluster, options in realm_info['clusters'].items(): if options.get('current', False): return realm, cluster raise unittest.SkipTest('Unable find current realm cluster') class TestContainerSync(unittest.TestCase): def setUp(self): (self.pids, self.port2server, self.account_ring, self.container_ring, self.object_ring, self.url, self.token, self.account, self.configs) = reset_environment() self.realm, self.cluster = get_current_realm_cluster(self.url) def tearDown(self): kill_servers(self.port2server, self.pids) def test_sync(self): base_headers = {'X-Container-Sync-Key': 'secret'} # setup dest container dest_container = 'dest-container-%s' % uuid.uuid4() dest_headers = base_headers.copy() dest_policy = None if len(POLICIES) > 1: dest_policy = random.choice(list(POLICIES)) dest_headers['X-Storage-Policy'] = dest_policy.name client.put_container(self.url, self.token, dest_container, headers=dest_headers) # setup source container source_container = 'source-container-%s' % uuid.uuid4() source_headers = base_headers.copy() sync_to = '//%s/%s/%s/%s' % (self.realm, self.cluster, self.account, dest_container) source_headers['X-Container-Sync-To'] = sync_to if dest_policy: source_policy = random.choice([p for p in POLICIES if p is not dest_policy]) source_headers['X-Storage-Policy'] = source_policy.name client.put_container(self.url, self.token, source_container, headers=source_headers) # upload to source object_name = 'object-%s' % uuid.uuid4() client.put_object(self.url, self.token, source_container, object_name, 'test-body') # cycle container-sync Manager(['container-sync']).once() # retrieve from sync'd container headers, body = client.get_object(self.url, self.token, dest_container, object_name) self.assertEqual(body, 'test-body') if __name__ == ""__main__"": get_current_realm_cluster('http://localhost:8080') unittest.main() ",,329,94
openstack%2Fswift~master~I450d40dc6e2d8f759187dff36d658e52737ae2a5,openstack/swift,master,I450d40dc6e2d8f759187dff36d658e52737ae2a5,Update bin scripts to be storage policy aware,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:21:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 5600}, {'_account_id': 6198}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f17fb4e9023d69a5b274849cecf7528cac3f5b1f', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\nImplements: blueprint storage-policies\n""}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9fee6688e5750797182c9e9850db4edd40d7c4c3', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 3, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eca4f3ee8a4ac8c4f739abe61172fab630449dba', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 4, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f88990b98c75658133bf88ad25573083c932bce', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 5, 'created': '2014-05-30 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0cfd2ab7d1c98a52411276362420b09f92e3fc50', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 6, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c7fd70f44f0437899a9d508282abb8d37e46d34d', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 7, 'created': '2014-06-02 23:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/11f847e03fd1cd8e22c7914db8645560a756af24', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30277fff5f0bab8634102f9ebcaf7ec10e00d068', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/049c69973c43f44e931c7e3fdab70d307a4aa218', 'message': ""Update swift-container-info to be storage policy aware\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4e5d34185839002d7d893bcfc5b51de7db30990c', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 11, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e4f5e6a27867ea0b15713d2feefc39ff9d19fce', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 12, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a0da072ffb63a9391f424c4254f49a72762f8adc', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 13, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4c9352b174ca2e802d17fe699ec7b5560c4cc34b', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 14, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/80f15093f6beb7a52d2cc76ad2ef8b69f3ba8f69', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}, {'number': 15, 'created': '2014-06-19 04:46:36.000000000', 'files': ['bin/swift-object-info', 'swift/cli/info.py', 'bin/swift-get-nodes', 'test/unit/cli/test_info.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6cc10d17de04a7ec19727880cd112898ca25d238', 'message': ""Update bin scripts to be storage policy aware\n\nswift-container-info:\n    Print policy container info\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nLookup policy name in swift.conf; 'Legacy' container will use\npolicy-0's name; 'Unknown' is shown if policy not found in swift.conf\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5\n""}]",12,96043,6cc10d17de04a7ec19727880cd112898ca25d238,66,10,15,1179,,,0,"Update bin scripts to be storage policy aware

swift-container-info:
    Print policy container info

swift-object-info:
    Allow to specify storage policy name when looking for object info
    Notify if there is missmatch between ring location and the actual
    object path in filesystem

swift-get-nodes:
    Allow to specify storage policy name when looking for account/
    container/object ring location
    Notify if there is missmatch between ring and the policy

Lookup policy name in swift.conf; 'Legacy' container will use
policy-0's name; 'Unknown' is shown if policy not found in swift.conf

DocImpact
Implements: blueprint storage-policies
Change-Id: I450d40dc6e2d8f759187dff36d658e52737ae2a5
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/96043/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/cli/info.py', 'test/unit/cli/test_info.py']",2,f17fb4e9023d69a5b274849cecf7528cac3f5b1f,bp/storage-policies,"from test.unit import patch_policies@patch_policies status_changed_at=107.9, Status Timestamp: 1970-01-01 00:01:47.900000 (107.9) status_changed_at='0000000107.90000', x_container_bar='goo', storage_policy_index=1) Status Timestamp: 1970-01-01 00:01:47.900000 (0000000107.90000) Storage Policy: unu (1)", x_container_bar='goo'),19,1
openstack%2Fswift~master~Id85c960b126ec919a481dc62469bf172b7fb8549,openstack/swift,master,Id85c960b126ec919a481dc62469bf172b7fb8549,Add two vector timestamps,ABANDONED,2014-06-11 09:50:51.000000000,2014-06-24 23:20:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/56d4995b402989c9c3bb3e7806876b4775c39c94', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset vector is\nappend to the normalized timestamp form which compares and sorts greater than\nthe fixed width float format but less than a newer timestamp.  The\ninternalized format of timestamps looks like ""1402464677.04188_00000000"" - the\nportion after the underscore is the offset and is formatted a hexadecimal\ninteger.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  The additional time vector allows\nthis modification to happen transparently to the client.  Future changes to\nfast-POST may also take advantage of a offset vector update to change the\n\'content_type\' of a row in the container.  The object-expirer could\npotentially benefit from the offset vector as well.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 2, 'created': '2014-06-11 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/239cc5feb3f00dfdf3efa68fc6af733be82dbcb6', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset vector is\nappend to the normalized timestamp form which compares and sorts greater than\nthe fixed width float format but less than a newer timestamp.  The\ninternalized format of timestamps looks like ""1402464677.04188_00000000"" - the\nportion after the underscore is the offset and is formatted a hexadecimal\ninteger.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  The additional time vector allows\nthis modification to happen transparently to the client.  Future changes to\nfast-POST may also take advantage of a offset vector update to change the\n\'content_type\' of a row in the container.  The object-expirer could\npotentially benefit from the offset vector as well.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 3, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a982ef0a9a71163fc2c6a41c8832fc5dd554034a', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset vector is\nappend to the normalized timestamp form which compares and sorts greater than\nthe fixed width float format but less than a newer timestamp.  The\ninternalized format of timestamps looks like ""1402464677.04188_00000000"" - the\nportion after the underscore is the offset and is formatted a hexadecimal\ninteger.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  The additional time vector allows\nthis modification to happen transparently to the client.  Future changes to\nfast-POST may also take advantage of a offset vector update to change the\n\'content_type\' of a row in the container.  The object-expirer could\npotentially benefit from the offset vector as well.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 4, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/58ddab8967c0c9072f441fa51d1201b02ffc4c9a', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset vector is\nappend to the normalized timestamp form which compares and sorts greater than\nthe fixed width float format but less than a newer timestamp.  The\ninternalized format of timestamps looks like ""1402464677.04188_00000000"" - the\nportion after the underscore is the offset and is formatted a hexadecimal\ninteger.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  The additional time vector allows\nthis modification to happen transparently to the client.  Future changes to\nfast-POST may also take advantage of a offset vector update to change the\n\'content_type\' of a row in the container.  The object-expirer could\npotentially benefit from the offset vector as well.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 5, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f9970f8a7990497dde68f3c1b176f309e1450fc', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset vector is\nappend to the normalized timestamp form which compares and sorts greater than\nthe fixed width float format but less than a newer timestamp.  The\ninternalized format of timestamps looks like ""1402464677.04188_00000000"" - the\nportion after the underscore is the offset and is formatted a hexadecimal\ninteger.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  The additional time vector allows\nthis modification to happen transparently to the client.  Future changes to\nfast-POST may also take advantage of a offset vector update to change the\n\'content_type\' of a row in the container.  The object-expirer could\npotentially benefit from the offset vector as well.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 6, 'created': '2014-06-19 04:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/587e591eb7e79f22318fdcceb80d76c7da09dda6', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset\nvector is append to the normalized timestamp form which compares and\nsorts greater than the fixed width float format but less than a newer\ntimestamp.  The internalized format of timestamps looks like\n""1402464677.04188_0000000000000000"" - the portion after the underscore\nis the offset and is a formatted hexadecimal integer.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  This use-case is valid because\nthe content represented by the user-facing timestamp is not modified in way.\nFuture consumers of the offset vector of timestamps should be mindful of HTTP\nsemitics of If-Modified and take care to avoid deviation in the response from\nthe object server without an accompanying change to the user facing timestamp.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}, {'number': 7, 'created': '2014-06-19 17:18:11.000000000', 'files': ['swift/account/backend.py', 'swift/obj/server.py', 'test/unit/account/test_utils.py', 'test/unit/cli/test_info.py', 'test/unit/common/test_direct_client.py', 'swift/account/utils.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'test/unit/account/test_backend.py', 'swift/proxy/controllers/obj.py', 'swift/common/exceptions.py', 'swift/common/db.py', 'swift/container/server.py', 'swift/container/updater.py', 'swift/common/direct_client.py', 'swift/account/reaper.py', 'test/unit/container/test_reconciler.py', 'swift/common/constraints.py', 'test/unit/common/test_swob.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py', 'swift/obj/diskfile.py', 'swift/cli/info.py', 'test/unit/common/test_constraints.py', 'test/unit/container/test_replicator.py', 'swift/container/sync.py', 'swift/obj/mem_diskfile.py', 'test/unit/obj/test_server.py', 'test/unit/common/test_db.py', 'swift/container/replicator.py', 'test/unit/obj/test_diskfile.py', 'swift/common/utils.py', 'swift/common/db_replicator.py', 'swift/common/swob.py', 'swift/container/backend.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py', 'test/probe/test_object_expirer.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c1dc2fa624d2abaea1c872a4e98bf7880c07c236', 'message': 'Add two vector timestamps\n\nThe normalized form of the X-Timestamp header looks like a float with a fixed\nwidth to ensure stable string sorting - normalized timestamps look like\n""1402464677.04188""\n\nTo support overwrites of existing data without modifying the original\ntimestamp but still maintain consistency a second internal offset\nvector is append to the normalized timestamp form which compares and\nsorts greater than the fixed width float format but less than a newer\ntimestamp.  The internalized format of timestamps looks like\n""1402464677.04188_0000000000000000"" - the portion after the underscore\nis the offset and is a formatted hexadecimal integer.\n\nThe internalized form is not exposed to clients in responses from Swift.\nNormal client operations will not create a timestamp with an offset.\n\nThe Timestamp class in common.utils supports internalized and normalized\nformatting of timestamps and also comparison of timestamp values.  When the\noffset value of a Timestamp is 0 - it\'s considered insignificant and need not\nbe represented in the string format; to support backwards compatibility during\na Swift upgrade the internalized and normalized form of a Timestamp with an\ninsignificant offset are identical.  When a timestamp includes an offset it\nwill always be represented in the internalized form, but is still excluded\nfrom the normalized form.  Timestamps with an equivalent timestamp portion\n(the float part) will compare and order by their offset.  Timestamps with a\ngreater timestamp portion will always compare and order greater than a\nTimestamp with a lesser timestamp regardless of it\'s offset.  String\ncomparison and ordering is guaranteed for the internalized string format, and\nis backwards compatible for normalized timestamps which do not include an\noffset.\n\nThe reconciler currently uses a offset bump to ensure that objects can move to\nthe wrong storage policy and be moved back.  This use-case is valid because\nthe content represented by the user-facing timestamp is not modified in way.\nFuture consumers of the offset vector of timestamps should be mindful of HTTP\nsemantics of If-Modified and take care to avoid deviation in the response from\nthe object server without an accompanying change to the user facing timestamp.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: Id85c960b126ec919a481dc62469bf172b7fb8549\n'}]",45,99315,c1dc2fa624d2abaea1c872a4e98bf7880c07c236,57,8,7,1179,,,0,"Add two vector timestamps

The normalized form of the X-Timestamp header looks like a float with a fixed
width to ensure stable string sorting - normalized timestamps look like
""1402464677.04188""

To support overwrites of existing data without modifying the original
timestamp but still maintain consistency a second internal offset
vector is append to the normalized timestamp form which compares and
sorts greater than the fixed width float format but less than a newer
timestamp.  The internalized format of timestamps looks like
""1402464677.04188_0000000000000000"" - the portion after the underscore
is the offset and is a formatted hexadecimal integer.

The internalized form is not exposed to clients in responses from Swift.
Normal client operations will not create a timestamp with an offset.

The Timestamp class in common.utils supports internalized and normalized
formatting of timestamps and also comparison of timestamp values.  When the
offset value of a Timestamp is 0 - it's considered insignificant and need not
be represented in the string format; to support backwards compatibility during
a Swift upgrade the internalized and normalized form of a Timestamp with an
insignificant offset are identical.  When a timestamp includes an offset it
will always be represented in the internalized form, but is still excluded
from the normalized form.  Timestamps with an equivalent timestamp portion
(the float part) will compare and order by their offset.  Timestamps with a
greater timestamp portion will always compare and order greater than a
Timestamp with a lesser timestamp regardless of it's offset.  String
comparison and ordering is guaranteed for the internalized string format, and
is backwards compatible for normalized timestamps which do not include an
offset.

The reconciler currently uses a offset bump to ensure that objects can move to
the wrong storage policy and be moved back.  This use-case is valid because
the content represented by the user-facing timestamp is not modified in way.
Future consumers of the offset vector of timestamps should be mindful of HTTP
semantics of If-Modified and take care to avoid deviation in the response from
the object server without an accompanying change to the user facing timestamp.

DocImpact
Implements: blueprint storage-policies
Change-Id: Id85c960b126ec919a481dc62469bf172b7fb8549
",git fetch https://review.opendev.org/openstack/swift refs/changes/15/99315/6 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/backend.py', 'swift/obj/server.py', 'test/unit/account/test_utils.py', 'test/unit/cli/test_info.py', 'test/unit/common/test_direct_client.py', 'swift/account/utils.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'test/unit/account/test_backend.py', 'swift/proxy/controllers/obj.py', 'swift/common/exceptions.py', 'swift/common/db.py', 'swift/container/server.py', 'swift/container/updater.py', 'swift/common/direct_client.py', 'swift/account/reaper.py', 'test/unit/container/test_reconciler.py', 'swift/common/constraints.py', 'test/unit/common/test_swob.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py', 'swift/obj/diskfile.py', 'swift/cli/info.py', 'test/unit/common/test_constraints.py', 'test/unit/container/test_replicator.py', 'swift/container/sync.py', 'swift/obj/mem_diskfile.py', 'test/unit/obj/test_server.py', 'swift/container/replicator.py', 'test/unit/obj/test_diskfile.py', 'swift/common/utils.py', 'swift/common/db_replicator.py', 'swift/common/swob.py', 'swift/container/backend.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py', 'test/probe/test_object_expirer.py']",38,56d4995b402989c9c3bb3e7806876b4775c39c94,bp/storage-policies,"from swift.common.utils import Timestamp self.brain.put_object(headers={'X-Delete-After': 2}) create_timestamp = Timestamp(metadata['x-timestamp']) self.assertEqual(Timestamp(metadata['x-backend-timestamp']), self.assert_(Timestamp(metadata['x-backend-timestamp']) > create_timestamp)"," self.brain.put_object(headers={'X-Delete-After': 1}) create_timestamp = metadata['x-timestamp'] self.assertEqual(metadata['x-backend-timestamp'], self.assert_(float(metadata['x-backend-timestamp']) > float(create_timestamp))",1927,862
openstack%2Fswift~master~I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1,openstack/swift,master,I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1,Add Storage Policy Documentation,ABANDONED,2014-05-28 03:40:44.000000000,2014-06-24 23:19:43.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 917}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 1179}, {'_account_id': 1216}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 8859}, {'_account_id': 8871}, {'_account_id': 9625}, {'_account_id': 11608}]","[{'number': 1, 'created': '2014-05-28 03:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/283c559d0823d24da72226e5bb36668a7058803f', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nAlso updates SAIO makerings script and swift.conf to tie in with\nthe docs and create a 2nd policy as part of the SAIO install.\n\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\nImplements: blueprint storage-policies\n'}, {'number': 2, 'created': '2014-05-29 05:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5cbef5aa0d651f8cbff53071f69d08a83c03c2e7', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 3, 'created': '2014-05-29 15:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6927fedc510c9b96b324a769367f30243ff5225c', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 4, 'created': '2014-05-29 15:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e2731241ee652e1330ae08522ad2a29c88471474', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 5, 'created': '2014-05-29 19:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2e858638eaa2827e6730b0101c84f9cb44fdd2e2', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 6, 'created': '2014-05-30 05:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b4a61dcbe1ce198777188d65bb70653b2bcc4378', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 7, 'created': '2014-05-30 23:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f410a9eef2f197d04f7779934c299bf7d9566f3', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 8, 'created': '2014-06-05 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e45e54cc4c22061252e17098684287a81b36748', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 9, 'created': '2014-06-06 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7e6243951d1744794bffc47ded2bfde5accec1e1', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 10, 'created': '2014-06-11 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c450dc0dcd6d59fa92b192006123b71745316033', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 11, 'created': '2014-06-13 18:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f79ef00fc3f0deb164b1370080dcc98a3525bac8', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 12, 'created': '2014-06-14 02:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3a4e52326fa168d086a7aef12af3863ad5bc0c7a', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 13, 'created': '2014-06-18 07:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c3fa1f421b7e775555d8264bad1d9196337d6439', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 14, 'created': '2014-06-19 04:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/806ce07eb91d723d7c1e24724e7880770a33229c', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}, {'number': 15, 'created': '2014-06-19 17:18:11.000000000', 'files': ['doc/source/container.rst', 'doc/saio/swift/swift.conf', 'doc/source/development_saio.rst', 'doc/source/middleware.rst', 'doc/source/overview_replication.rst', 'doc/source/admin_guide.rst', 'doc/source/overview_policies.rst', 'doc/source/index.rst', 'doc/source/policies_saio.rst', 'doc/saio/bin/remakerings', 'doc/source/overview_architecture.rst', 'doc/saio/swift/container-reconciler.conf', 'doc/source/misc.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/e52e8bc9177f6ca860bc69672588811a37440fc2', 'message': 'Add Storage Policy Documentation\n\nAdd overview and example information for using Storage Policies.\n\nDocImpact\nImplements: blueprint storage-policies\nChange-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1\n'}]",212,96026,e52e8bc9177f6ca860bc69672588811a37440fc2,120,19,15,1179,,,0,"Add Storage Policy Documentation

Add overview and example information for using Storage Policies.

DocImpact
Implements: blueprint storage-policies
Change-Id: I6f11f7a1bdaa6f3defb3baa56a820050e5f727f1
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/96026/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/overview_policies.rst', 'doc/source/policies_saio.rst']",2,283c559d0823d24da72226e5bb36668a7058803f,bp/storage-policies,"========================= SAIO and Storage Policies ========================= Depending on when you downloaded your SAIO environment, it may already be prepared with two storage policies that enable some basic functional tests. In the event that you are adding a storage policy to an existing installation, however, the following section will walk you through the steps for setting up Storage Policies. Enabling Storage Policies is very easy regardless of whether you are working with an existing installation or starting a brand new one. Note that for an existing installation, without any of these modifications, the pre-existing object ring will be automatically used for both existing and newly created containers. Now we will create two policies - the first one will be a standard triple replication policy that we will also explicitly set as the default and the second will be setup for reduced replication using a factor of 2x. We will call the first one 'gold' and the second one 'silver'. In this example both policies map to the same devices because it's also important for the for this sample implementation to be simple and easy to understand and adding a bunch of new devices isn't really required to implement a usable set of policies. 1. Edit your ``/etc/swift/swift/conf`` file:: [swift-hash] # random unique strings that can never change (DO NOT LOSE) swift_hash_path_prefix = changeme [storage-policy:0] name = gold default = yes [storage-policy:1] name = silver See :doc:`overview_policies` for detailed information on ``swift.conf`` policy options. 2. Create the ring file for the 'silver' policy and put it in ``/etc/swift``:: swift-ring-builder object-1.builder create 10 2 1 swift-ring-builder object-1.builder add r1z1-127.0.0.1:6010/sdb1 1 swift-ring-builder object-1.builder add r1z2-127.0.0.1:6020/sdb2 1 swift-ring-builder object-1.builder add r1z3-127.0.0.1:6030/sdb3 1 swift-ring-builder object-1.builder add r1z4-127.0.0.1:6040/sdb4 1 swift-ring-builder object-1.builder rebalance Note that the reduced replication of the silver policy is only a function of the replication parameter in the ``swift-ring-builder create`` command and is not specified in ``/etc/swift/swift.conf``. ------------------ Using Policies ------------------ Setting up Storage Policies was very simple, and using them is even simpler. In this section we will create a few containers with different policies and then run some commands to verify that things land where we expect. Now that you've updated your ``/etc/swift/swift.conf`` and created your second object ring per the steps above, lets create a few containers and objects and see how policies work. 1. We will be using the list_endpoints middleware to confirm object locations, so enable that now in your ``proxy-server.conf`` file by adding it to the pipeline and including the filter section as shown below:: pipeline = catch_errors gatekeeper healthcheck proxy-logging cache bulk slo dlo ratelimit crossdomain list-endpoints tempurl tempauth staticweb container-quotas account-quotas proxy-logging proxy-server [filter:list-endpoints] use = egg:swift#list_endpoints 2. Create a container without specifying a policy, it will use the default, 'gold' and then put a test object in it (create the file ``file0.txt`` with your favorite editor with some content):: curl -v -X PUT -H 'X-Auth-Token: AUTH_token' \ http://127.0.0.1:8080/v1/AUTH_test/myCont0 curl -X PUT -v -T file0.txt -H 'X-Auth-Token: AUTH_token' \ http://127.0.0.1:8080/v1/AUTH_test/myCont0/ 3. Now confirm placement of the object with the :ref:`list_endpoints` middleware:: curl -X GET -v -H 'X-Auth-Token: AUTH_toeken' \ http://127.0.0.1:8080/endpoints/v1/AUTH_test/myCont0/file0.txt You should see this: (note placement on expected devices):: [""http://127.0.0.1:6030/sdb3/761/v1/AUTH_test/myCont0/file0.txt"", ""http://127.0.0.1:6010/sdb1/761/v1/AUTH_test/myCont0/file0.txt"", ""http://127.0.0.1:6020/sdb2/761/v1/AUTH_test/myCont0/file0.txt""] 4. Create a container using policy 'silver' and put a different file in it:: curl -v -X PUT -H 'X-Auth-Token: AUTH_token' -H ""X-Storage-Policy: silver"" \ http://127.0.0.1:8080/v1/AUTH_test/myCont1 curl -X PUT -v -T file1.txt -H 'X-Auth-Token: AUTH_token' \ http://127.0.0.1:8080/v1/AUTH_test/myCont1/ 5. Confirm placement of the object for policy 'silver':: curl -X GET -v -H 'X-Auth-Token: AUTH_token' \ http://127.0.0.1:8080/endpoints/v1/AUTH_test/myCont1/file1.txt You should see this: (note placement on expected devices):: [""http://127.0.0.1:6010/sdb1/32/v1/AUTH_test/myCont1/file1.txt"", ""http://127.0.0.1:6040/sdb4/32/v1/AUTH_test/myCont1/file1.txt""] 6. Confirm account information with HEAD, make sure that your container-updater service is running and has executed once since you performed the PUTS or the account database won't be updated yet:: curl -i -X HEAD -H 'X-Auth-Token: AUTH_token' \ http://127.0.0.1:8080/v1/AUTH_test You should see something like this (note that total and per policy stats object sizes will vary):: HTTP/1.1 204 No Content Content-Length: 0 X-Account-Object-Count: 2 X-Account-Bytes-Used: 174 X-Account-Container-Count: 2 X-Account-Storage-Policy-Gold-Object-Count: 1 X-Account-Storage-Policy-Gold-Bytes-Used: 84 X-Account-Storage-Policy-Silver-Object-Count: 1 X-Account-Storage-Policy-Silver-Bytes-Used: 90 X-Timestamp: 1397230339.71525 Content-Type: text/plain; charset=utf-8 Accept-Ranges: bytes X-Trans-Id: tx96e7496b19bb44abb55a3-0053482c75 Date: Fri, 11 Apr 2014 17:55:01 GMT ",,605,0
openstack%2Fironic-python-agent~master~I3a854fd07cd7987425288b61fd6eeac925db0bff,openstack/ironic-python-agent,master,I3a854fd07cd7987425288b61fd6eeac925db0bff,No longer recommend use of ipa-advertise-url,MERGED,2014-06-24 22:35:49.000000000,2014-06-24 23:15:23.000000000,2014-06-24 23:15:23.000000000,"[{'_account_id': 3}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-06-24 22:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/03574950191f9b15a6b76705c982160b5c2fb6e0', 'message': 'No longer reccomend use of ipa-advertise-url\n\nBecause IPA now detects what IP to advertise, specifying this in the PXE\nconfig should no longer be a reccomended default.\n\nChange-Id: I3a854fd07cd7987425288b61fd6eeac925db0bff\n'}, {'number': 2, 'created': '2014-06-24 22:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/176f3524187c69f7cf4469abc1faf317bc98f047', 'message': 'No longer reccomend use of ipa-advertise-url\n\nBecause IPA now detects what IP to advertise, specifying this in the PXE\nconfig should no longer be a recommended default.\n\nChange-Id: I3a854fd07cd7987425288b61fd6eeac925db0bff\n'}, {'number': 3, 'created': '2014-06-24 22:40:04.000000000', 'files': ['imagebuild/coreos/README.md'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b5cd83b13cdb942a6a23840fbb26c3dca94e390d', 'message': 'No longer recommend use of ipa-advertise-url\n\nBecause IPA now detects what IP to advertise, specifying this in the PXE\nconfig should no longer be a recommended default.\n\nChange-Id: I3a854fd07cd7987425288b61fd6eeac925db0bff\n'}]",1,102371,b5cd83b13cdb942a6a23840fbb26c3dca94e390d,16,4,3,10342,,,0,"No longer recommend use of ipa-advertise-url

Because IPA now detects what IP to advertise, specifying this in the PXE
config should no longer be a recommended default.

Change-Id: I3a854fd07cd7987425288b61fd6eeac925db0bff
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/71/102371/3 && git format-patch -1 --stdout FETCH_HEAD,['imagebuild/coreos/README.md'],1,03574950191f9b15a6b76705c982160b5c2fb6e0,,options via the kernel command line. The only values most people will need is:,options via the kernel command line. Values most people will need are: - `ipa-advertise-host=ip-of-server-running-agent`,1,2
openstack%2Fosprofiler~master~I90ef7e18720fecbb91a856d08885ef1347792677,openstack/osprofiler,master,I90ef7e18720fecbb91a856d08885ef1347792677,Remove unused libs from requirments and fix info in setup.cfg,MERGED,2014-06-24 22:23:29.000000000,2014-06-24 23:13:30.000000000,2014-06-24 23:13:30.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-24 22:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/a878f7bd43bdb0297a0dad426c4e80f8a35c4cd5', 'message': 'Remove useless requirments\n\nChange-Id: I90ef7e18720fecbb91a856d08885ef1347792677\n'}, {'number': 2, 'created': '2014-06-24 22:38:04.000000000', 'files': ['requirements.txt', 'babel.cfg', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/a582834e59204fb15fbc36f310377b101b99c184', 'message': 'Remove unused libs from requirments and fix info in setup.cfg\n\nChange-Id: I90ef7e18720fecbb91a856d08885ef1347792677\n'}]",0,102368,a582834e59204fb15fbc36f310377b101b99c184,9,2,2,6172,,,0,"Remove unused libs from requirments and fix info in setup.cfg

Change-Id: I90ef7e18720fecbb91a856d08885ef1347792677
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/68/102368/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a878f7bd43bdb0297a0dad426c4e80f8a35c4cd5,remove_useless_req,,"fixtures>=0.3.14pbr>=0.6,<1.0",0,2
openstack%2Fpuppet-neutron~stable%2Ficehouse~Ie838dacce8c553cf656333005d66b398c23f4bcc,openstack/puppet-neutron,stable/icehouse,Ie838dacce8c553cf656333005d66b398c23f4bcc,Refresh Neutron server,MERGED,2014-06-24 13:18:34.000000000,2014-06-24 23:08:40.000000000,2014-06-24 23:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 7822}, {'_account_id': 11491}]","[{'number': 1, 'created': '2014-06-24 13:18:34.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'manifests/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/29071afcecf77aa30075cc361a724d843d8e97a9', 'message': 'Refresh Neutron server\n\nAfter ML2 configuration is changed Neutron server should be restarted.\nThis patch adds appropriate notification.\n\nChange-Id: Ie838dacce8c553cf656333005d66b398c23f4bcc\n(cherry picked from commit b3203f698f66fd4422916808e4a55b0957c5aaa3)\n'}]",0,102223,29071afcecf77aa30075cc361a724d843d8e97a9,9,4,1,5241,,,0,"Refresh Neutron server

After ML2 configuration is changed Neutron server should be restarted.
This patch adds appropriate notification.

Change-Id: Ie838dacce8c553cf656333005d66b398c23f4bcc
(cherry picked from commit b3203f698f66fd4422916808e4a55b0957c5aaa3)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/23/102223/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_spec.rb', 'manifests/plugins/ml2.pp']",2,29071afcecf77aa30075cc361a724d843d8e97a9,, Neutron_plugin_ml2<||> ~> Service['neutron-server'] ,,6,1
openstack%2Ftrove-integration~master~I6b061290409a84707ee51c374aa7248b6ecadc34,openstack/trove-integration,master,I6b061290409a84707ee51c374aa7248b6ecadc34,MySQL 5.6 disk-image-builder element,ABANDONED,2014-03-10 19:15:48.000000000,2014-06-24 23:05:27.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9782}, {'_account_id': 10163}]","[{'number': 1, 'created': '2014-03-10 19:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/c6501f36b1805a44df690a89dd38b1be314d6f56', 'message': 'MySQL 5.6 disk-image-builder element\n\nChange-Id: I6b061290409a84707ee51c374aa7248b6ecadc34\nImplements: blueprint base-mysql5.6-image\n'}, {'number': 2, 'created': '2014-03-10 19:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/b08579f1c0caad46c0feb318e82240beffad70f1', 'message': 'MySQL 5.6 disk-image-builder element\n\nChange-Id: I6b061290409a84707ee51c374aa7248b6ecadc34\nImplements: blueprint base-mysql56-image\n'}, {'number': 3, 'created': '2014-03-22 00:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/664355cb674512e1d21cf5396a49ace2219f1288', 'message': 'MySQL 5.6 disk-image-builder element\n\nModified logdir adn logerror flag\nChange-Id: I6b061290409a84707ee51c374aa7248b6ecadc34\nImplements: blueprint base-mysql56-image\n'}, {'number': 4, 'created': '2014-03-25 23:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/a89d72a54e38ee5cf4536e503801222a3206a4ea', 'message': 'MySQL 5.6 disk-image-builder element\n\nfix init.d script so that it starts mysql as part of a new process group\nChange-Id: I6b061290409a84707ee51c374aa7248b6ecadc34\nImplements: blueprint base-mysql56-image\n'}, {'number': 5, 'created': '2014-04-08 05:27:19.000000000', 'files': ['scripts/files/elements/ubuntu-mysql-5.6/README.md', 'scripts/files/elements/ubuntu-mysql/install.d/10-mysql', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-mysql-5.6/install.d/10-mysql'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/efd59aaae20ba9a59a75bdf73d228c4c35ce1b89', 'message': 'MySQL 5.6 disk-image-builder element\n\nfix init.d script so that it starts mysql as part of a new process group\nChange-Id: I6b061290409a84707ee51c374aa7248b6ecadc34\nImplements: blueprint base-mysql56-image\n'}]",8,79413,efd59aaae20ba9a59a75bdf73d228c4c35ce1b89,44,7,5,10163,,,0,"MySQL 5.6 disk-image-builder element

fix init.d script so that it starts mysql as part of a new process group
Change-Id: I6b061290409a84707ee51c374aa7248b6ecadc34
Implements: blueprint base-mysql56-image
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/13/79413/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/ubuntu-mysql-5.6/README.md', 'scripts/files/elements/ubuntu-mysql/install.d/10-mysql', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-mysql-5.6/install.d/10-mysql']",4,c6501f36b1805a44df690a89dd38b1be314d6f56,bp/base-mysql56-image,"#!/bin/sh # CONTEXT: GUEST during CONSTRUCTION as ROOT # PURPOSE: Install controller base required packages set -e set -o xtrace tmpdir=`mktemp -d` cd $tmpdir # get Debian package from mysql.com wget http://cdn.mysql.com/Downloads/MySQL-5.6/mysql-5.6.15-debian6.0-x86_64.deb export DEBIAN_FRONTEND=noninteractive apt-get -y install libaio1 dpkg -i mysql-5.6.15-debian6.0-x86_64.deb # create user groupadd mysql useradd -r -g mysql mysql # create data dir mkdir /var/lib/mysql chown -R mysql:mysql /var/lib/mysql # init db /opt/mysql/server-5.6/scripts/mysql_install_db --user=mysql --datadir=/var/lib/mysql # add bin to path sed -i -r 's@PATH=""(.*)""@PATH=""\1:/opt/mysql/server-5.6/bin""@' /etc/environment # create /etc/init.d script cp /opt/mysql/server-5.6/support-files/mysql.server /etc/init.d/mysql-server sed -i 's/datadir=$/datadir=\/var\/lib\/mysql/' /etc/init.d/mysql-server sudo chmod 755 /etc/init.d/mysql-server #sudo update-rc.d mysql-server defaults # create conf dir mkdir -p /etc/mysql/conf.d # copy sample conf cp /opt/mysql/server-5.6/support-files/my-default.cnf /etc/mysql/my.cnf # copy logrotate conf cp /opt/mysql/server-5.6/support-files/mysql-log-rotate /etc/logrotate.d/mysql-server # install python-mysqldb; this will install libmysqlclient18 too; # libmysqlclient18's files will be removed below; we don't uninstall # libmysqlclient18 since apt will complain about missing dependencies apt-get -y install percona-xtrabackup python-mysqldb # symlink some files to where guestagent will look for them for f in /opt/mysql/server-5.6/bin/*; do sudo ln -s $f /usr/bin; done # remove libs from libmysqlclient18 rm -rf /usr/lib/*mysql* for f in /opt/mysql/server-5.6/lib/*; do sudo ln -s $f /usr/lib; done set +e # ignore existing file errors for f in /opt/mysql/server-5.6/share/*; do sudo ln -s $f /usr/share; done set -e ln -s /opt/mysql/server-5.6/bin/mysqld /usr/sbin # pid file path comes from config.template; need to create parent dir at the last minute, so add to startup script sed -i -r 's/case ""\$mode"" in/if [ ! -d `dirname $mysqld_pid_file_path` ]; then mkdir -p `dirname $mysqld_pid_file_path`; chown mysql `dirname $mysqld_pid_file_path`; fi\ncase ""$mode"" in/' /etc/init.d/mysql-server # fix init.d script so that it uses pid_file from config.template sed -i -r 's/\s*--pid-file=\*(.*)/--pid[-_]file=\*\1/' /etc/init.d/mysql-server # mysqld_safe checks a lot of places for datadir but /var/lib/mysql is not one of those places; this is invoked directly on restore from backup sed -i -r 's@DATADIR=/opt/mysql/server-5.6/data@DATADIR=/var/lib/mysql@' /opt/mysql/server-5.6/bin/mysqld_safe cd - rm -rf $tmpdir",,71,2
openstack%2Ffuel-web~master~I0f4e1a28149dee06f6e8496b68fb4bc518c108b1,openstack/fuel-web,master,I0f4e1a28149dee06f6e8496b68fb4bc518c108b1,Add tox to test-requirements.txt,MERGED,2014-06-24 22:49:11.000000000,2014-06-24 22:53:29.000000000,2014-06-24 22:53:28.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 22:49:11.000000000', 'files': ['nailgun/test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e21eb20d030c61f4db90ed32021ef420974cba57', 'message': 'Add tox to test-requirements.txt\n\nChange-Id: I0f4e1a28149dee06f6e8496b68fb4bc518c108b1\nCloses-bug: #1333789\n'}]",0,102375,e21eb20d030c61f4db90ed32021ef420974cba57,9,4,1,8829,,,0,"Add tox to test-requirements.txt

Change-Id: I0f4e1a28149dee06f6e8496b68fb4bc518c108b1
Closes-bug: #1333789
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/75/102375/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/test-requirements.txt'],1,e21eb20d030c61f4db90ed32021ef420974cba57,bug/1333789,tox==1.7.1,,1,0
openstack%2Ftaskflow~master~I2b5d310e967dcd5cd7dc939976c64935bcef221f,openstack/taskflow,master,I2b5d310e967dcd5cd7dc939976c64935bcef221f,Add a deprecation module,ABANDONED,2014-04-11 23:04:04.000000000,2014-06-24 22:43:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6648}, {'_account_id': 6873}, {'_account_id': 7366}, {'_account_id': 8871}, {'_account_id': 10165}]","[{'number': 1, 'created': '2014-04-11 23:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/346dd2a0cbaa22a738557bf59f3992a38e3612ee', 'message': 'Add a decoration helper module\n\nTo allow various modules, classes, functions, moved\ncreate a deprecate module that can be used to mark\nclasses, functions, modules as being deprecated in a\ngiven release.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 2, 'created': '2014-04-12 00:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fe7f9715835bf5cd9210cd785ec43ab41ee9313', 'message': 'Add a decoration helper module\n\nTo allow various modules, classes, functions, moved\ncreate a deprecate module that can be used to mark\nclasses, functions, modules as being deprecated in a\ngiven release.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 3, 'created': '2014-04-12 00:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5d17d4dc906ca0bcb21a65031b2de9877bea63f5', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 4, 'created': '2014-04-12 01:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/33db8ec5562167982e7f32556638bb4644449b74', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 5, 'created': '2014-04-12 01:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a6b6bff9980df995b56259e40b6a5fa320456ce7', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 6, 'created': '2014-04-12 02:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9c91d2c790b7d033f9a627dd9502e84f801c239d', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 7, 'created': '2014-04-12 04:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eac826ddda5c3677ee991687ca908b2785bf1611', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 8, 'created': '2014-04-12 17:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3da9b0a837539b895798d21e3343a0887dc23a84', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 9, 'created': '2014-04-13 23:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e482c0d16a3df5ea8a3bdd10e07795455006941d', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 10, 'created': '2014-04-14 03:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8187364d32b0b059ec1612a1edd9551b9b20816d', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 11, 'created': '2014-04-14 03:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c4513a32fa7f1fb9a594b93c6286b6401efc256f', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 12, 'created': '2014-04-14 03:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cc034f45b425539ee0410743a735822a8688c15e', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 13, 'created': '2014-04-14 03:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d80af69d28570b4689ca4725268d629755801aaa', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 14, 'created': '2014-04-14 03:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0bcadbb917aec54e62e59a8f16a0c119b6fd07fc', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 15, 'created': '2014-04-14 04:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d52fa8da316e16bf3dbf04c40c66bc3c9a457f03', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 16, 'created': '2014-04-14 17:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/09a1137d8ecce52f667660db72fd24984394b300', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 17, 'created': '2014-05-21 22:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b546952cc08f06b4a2bc732cb6a219e524ec7cce', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}, {'number': 18, 'created': '2014-06-03 01:45:36.000000000', 'files': ['requirements.txt', 'taskflow/utils/deprecation.py', 'taskflow/utils/reflection.py', 'taskflow/tests/unit/test_deprecated.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4020d1ebc661cbb396d6fa53185507f7bee4ff8a', 'message': 'Add a deprecation module\n\nTo allow various modules, classes, functions, moved\nobjects to be marked deprecated create a helper\nmodule that can be used to mark classes, functions,\nmodules as being deprecated in a given release and\nuse the warnings system that exists in python to\nmessage about these.\n\nChange-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f\n'}]",4,87055,4020d1ebc661cbb396d6fa53185507f7bee4ff8a,71,7,18,1297,,,0,"Add a deprecation module

To allow various modules, classes, functions, moved
objects to be marked deprecated create a helper
module that can be used to mark classes, functions,
modules as being deprecated in a given release and
use the warnings system that exists in python to
message about these.

Change-Id: I2b5d310e967dcd5cd7dc939976c64935bcef221f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/55/87055/8 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/deprecation.py'],1,346dd2a0cbaa22a738557bf59f3992a38e3612ee,,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import functools import warnings from taskflow.utils import reflection def deprecated_class(message=None): """"""Depreciates a class by printing warnings when initialized."""""" def wrapper(cls): old_init = cls.__init__ def new_init(*args, **kwargs): if not message: warnings.warn(""Class %s is deprecated"" % reflection.get_class_name(cls), DeprecationWarning, 2) else: warnings.warn(message, DeprecationWarning, 2) old_init(*args, **kwargs) cls.__init__ = new_init return cls return wrapper def deprecated(message=None): """"""Depreciates a function by printing warnings when called."""""" def decorator(func): @functools.wraps(func) def wrapper(*args, **kwargs): if not message: warnings.warn(""Function %s is deprecated"" % reflection.get_callable_name(func), DeprecationWarning, 2) else: warnings.warn(message, DeprecationWarning, 2) return func(*args, **kwargs) return wrapper return decorator class moved_class(object): """"""Depreciates a class that was moved to another location by printing warnings when initialized (or attributes are accessed) telling where the new location is. """""" def __init__(self, new_cls, old_name, message=None): self._new_cls = new_cls if not message: self._message = (""%s has moved to %s"" % (old_name, reflection.get_class_name(new_cls))) else: self._message = message self._old_name = old_name def __call__(self, *args, **kwargs): warnings.warn(self._message, DeprecationWarning, 2) return self._new_cls(*args, **kwargs) def __getattr__(self, name): warnings.warn(self._message, DeprecationWarning, 2) return getattr(self._new_cls, name) ",,84,0
openstack%2Fswift~master~Ie803dd1a84d50de7663a7099c32d81807701e188,openstack/swift,master,Ie803dd1a84d50de7663a7099c32d81807701e188,Minor Updates to Storage Policy Docs,MERGED,2014-06-21 13:46:55.000000000,2014-06-24 22:40:31.000000000,2014-06-24 22:40:30.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7479}, {'_account_id': 8542}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-21 13:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f99366ab9c5c01486dd07a05cf51855b49dc1ac4', 'message': 'Minor Updates to Storage Policy Docs\n\nFixed some grammar issues, formatting issues, clarrified some\nwording now that its easier to read fully rendered.\n\nChange-Id: Ie803dd1a84d50de7663a7099c32d81807701e188\n'}, {'number': 2, 'created': '2014-06-23 18:15:14.000000000', 'files': ['doc/source/overview_policies.rst', 'doc/source/overview_architecture.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/f95706ba8a4465b4c0c439430f83734d5c7224df', 'message': 'Minor Updates to Storage Policy Docs\n\nFixed some grammar issues, formatting issues, clarrified some\nwording now that its easier to read fully rendered.\n\nChange-Id: Ie803dd1a84d50de7663a7099c32d81807701e188\n'}]",10,101705,f95706ba8a4465b4c0c439430f83734d5c7224df,41,8,2,7479,,,0,"Minor Updates to Storage Policy Docs

Fixed some grammar issues, formatting issues, clarrified some
wording now that its easier to read fully rendered.

Change-Id: Ie803dd1a84d50de7663a7099c32d81807701e188
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/101705/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/overview_policies.rst', 'doc/source/overview_architecture.rst']",2,f99366ab9c5c01486dd07a05cf51855b49dc1ac4,master,Storage Policies is implemented throughout the entire code base so is an important concept in understanding Swift architecture.,Storage Policies are not implemented as a separate code module but are a core abstraction of Swift architecture.,28,27
openstack%2Fswift~master~Iea3d06de80210e9e504e296d4572583d7ffabeac,openstack/swift,master,Iea3d06de80210e9e504e296d4572583d7ffabeac,Replace POLICY and POLICY_INDEX with string literals,MERGED,2014-06-23 19:59:53.000000000,2014-06-24 22:40:28.000000000,2014-06-24 22:40:28.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 19:59:53.000000000', 'files': ['swift/obj/server.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/proxy/controllers/obj.py', 'test/probe/test_object_handoff.py', 'swift/container/server.py', 'swift/container/updater.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/container/test_sync.py', 'swift/account/reaper.py', 'swift/container/reconciler.py', 'test/unit/obj/test_ssync_receiver.py', 'swift/cli/info.py', 'test/unit/account/test_reaper.py', 'test/unit/account/test_server.py', 'swift/container/sync.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_replicator.py', 'test/unit/obj/test_updater.py', 'test/probe/test_object_failures.py', 'swift/obj/replicator.py', 'swift/obj/updater.py', 'test/probe/test_empty_device_handoff.py', 'swift/common/storage_policy.py', 'swift/common/request_helpers.py', 'swift/proxy/controllers/container.py', 'swift/obj/ssync_receiver.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/873c52e608d46e4c34035a8dd3476e604fe2248e', 'message': ""Replace POLICY and POLICY_INDEX with string literals\n\nReplaced throughout code base &  tox'd. Functional as well\nas probe tests pass with and without policies defined.\n\nPOLICY --> 'X-Storage-Policy'\nPOLICY_INDEX --> 'X-Backend-Storage-Policy-Index'\n\nChange-Id: Iea3d06de80210e9e504e296d4572583d7ffabeac\n""}]",1,101991,873c52e608d46e4c34035a8dd3476e604fe2248e,21,5,1,7479,,,0,"Replace POLICY and POLICY_INDEX with string literals

Replaced throughout code base &  tox'd. Functional as well
as probe tests pass with and without policies defined.

POLICY --> 'X-Storage-Policy'
POLICY_INDEX --> 'X-Backend-Storage-Policy-Index'

Change-Id: Iea3d06de80210e9e504e296d4572583d7ffabeac
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/101991/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/common/test_direct_client.py', 'test/functional/tests.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'swift/proxy/controllers/obj.py', 'test/probe/test_object_handoff.py', 'swift/container/server.py', 'swift/container/updater.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/container/test_sync.py', 'swift/account/reaper.py', 'swift/container/reconciler.py', 'test/unit/obj/test_ssync_receiver.py', 'swift/cli/info.py', 'test/unit/account/test_reaper.py', 'test/unit/account/test_server.py', 'swift/container/sync.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_replicator.py', 'test/unit/obj/test_updater.py', 'test/probe/test_object_failures.py', 'swift/obj/replicator.py', 'swift/obj/updater.py', 'test/probe/test_empty_device_handoff.py', 'swift/common/storage_policy.py', 'swift/common/request_helpers.py', 'swift/proxy/controllers/container.py', 'swift/obj/ssync_receiver.py', 'swift/proxy/controllers/base.py']",33,873c52e608d46e4c34035a8dd3476e604fe2248e,policy_lit,"from swift.common.storage_policy import POLICIES 'storage_policy': headers.get('X-Backend-Storage-Policy-Index'.lower(), '0'), if 'X-Backend-Storage-Policy-Index' in res.headers and \ is_success(res.status_int): policy = \ POLICIES.get_by_index( res.headers['X-Backend-Storage-Policy-Index']) if policy: res.headers['X-Storage-Policy'] = policy.name 'X-Backend-Storage-Policy-Index', res.headers['X-Backend-Storage-Policy-Index'], path)","from swift.common.storage_policy import POLICY_INDEX, POLICY, POLICIES 'storage_policy': headers.get(POLICY_INDEX.lower(), '0'), if POLICY_INDEX in res.headers and is_success(res.status_int): policy = POLICIES.get_by_index(res.headers[POLICY_INDEX]) if policy: res.headers[POLICY] = policy.name POLICY_INDEX, res.headers[POLICY_INDEX], path)",278,228
openstack%2Fdesignate~master~Ie125d861afa16e9aabee25445bbcf198121c6360,openstack/designate,master,Ie125d861afa16e9aabee25445bbcf198121c6360,Implement change tracking in DesignateObjects,MERGED,2014-06-24 20:21:40.000000000,2014-06-24 22:38:24.000000000,2014-06-24 22:38:23.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-06-24 20:21:40.000000000', 'files': ['designate/objects/base.py', 'designate/rpc.py', 'designate/tests/test_objects/test_base.py', 'designate/objects/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/b9dc5a7280dc57ab555bb5afeebc05e2ec563ca9', 'message': 'Implement change tracking in DesignateObjects\n\nChange-Id: Ie125d861afa16e9aabee25445bbcf198121c6360\n'}]",0,102337,b9dc5a7280dc57ab555bb5afeebc05e2ec563ca9,8,5,1,741,,,0,"Implement change tracking in DesignateObjects

Change-Id: Ie125d861afa16e9aabee25445bbcf198121c6360
",git fetch https://review.opendev.org/openstack/designate refs/changes/37/102337/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/objects/base.py', 'designate/rpc.py', 'designate/objects/__init__.py', 'designate/tests/test_objects/test_base.py']",4,b9dc5a7280dc57ab555bb5afeebc05e2ec563ca9,objects-change-tracking,"from designate import objectsclass TestObject(objects.DesignateObject):TEST_OBJECT_PATH = 'designate.tests.test_objects.test_base.TestObject' class DesignateObjectTest(tests.TestCase): def test_from_primitive(self): primitive = { 'designate_object.name': TEST_OBJECT_PATH, 'designate_object.data': { 'id': 'MyID', }, 'designate_object.changes': [], } obj = objects.DesignateObject.from_primitive(primitive) # Validate it has been thawed correctly self.assertEqual('MyID', obj.id) # Ensure the ID field has a value self.assertTrue(obj.obj_attr_is_set('id')) # Ensure the name field has no value self.assertFalse(obj.obj_attr_is_set('name')) # Ensure the changes list is empty self.assertEqual(0, len(obj.obj_what_changed())) self.assertEqual(1, len(obj.obj_what_changed())) self.assertEqual(2, len(obj.obj_what_changed())) expected = { 'designate_object.name': TEST_OBJECT_PATH, 'designate_object.data': { 'id': 'MyID', }, 'designate_object.changes': ['id'], } self.assertEqual(expected, primitive) expected = { 'designate_object.name': TEST_OBJECT_PATH, 'designate_object.data': { 'id': 'MyID', 'name': None, }, 'designate_object.changes': ['id', 'name'], } self.assertEqual(expected, primitive) def test_obj_attr_is_set(self): obj = TestObject() self.assertFalse(obj.obj_attr_is_set('name')) obj.name = ""My Name"" self.assertTrue(obj.obj_attr_is_set('name')) def test_obj_what_changed(self): obj = TestObject() self.assertEqual(set([]), obj.obj_what_changed()) obj.name = ""My Name"" self.assertEqual(set(['name']), obj.obj_what_changed()) def test_obj_get_changes(self): obj = TestObject() self.assertEqual({}, obj.obj_get_changes()) obj.name = ""My Name"" self.assertEqual({'name': ""My Name""}, obj.obj_get_changes()) def test_obj_reset_changes(self): obj = TestObject() obj.name = ""My Name"" self.assertEqual(1, len(obj.obj_what_changed())) obj.obj_reset_changes() self.assertEqual(0, len(obj.obj_what_changed())) def test_obj_reset_changes_subset(self): obj = TestObject() obj.id = ""My ID"" obj.name = ""My Name"" self.assertEqual(2, len(obj.obj_what_changed())) obj.obj_reset_changes(['id']) self.assertEqual(1, len(obj.obj_what_changed())) self.assertEqual({'name': ""My Name""}, obj.obj_get_changes())","from designate.objects import baseclass TestObject(base.DesignateObject):class DesignateObjectTest(tests.TestCase): def test_from_primitive(self): primitive = { 'designate_object.data': { 'id': 'MyID', } } obj = TestObject.from_primitive(primitive) # Validate it has been thawed correctly self.assertEqual('MyID', obj.id) # Ensure the ID field has a value self.assertTrue(obj.attr_is_set('id')) # Ensure the name field has no value self.assertFalse(obj.attr_is_set('name')) self.assertEqual({'id': 'MyID'}, primitive['designate_object.data']) self.assertEqual({'id': 'MyID', 'name': None}, primitive['designate_object.data'])",143,41
openstack%2Fopenstack-manuals~master~Ib52bbbb1ec6e90ad3222ea6685039fd4d3fb366d,openstack/openstack-manuals,master,Ib52bbbb1ec6e90ad3222ea6685039fd4d3fb366d,Publish OPS Guide to /openstack-ops,MERGED,2014-06-23 20:11:18.000000000,2014-06-24 22:36:14.000000000,2014-06-24 22:36:13.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-23 20:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7c874bd007005c12bc32d20278e80b0afc0acbe8', 'message': 'Publish OPS Guide to /openstack-ops\n\nThis depends on https://review.openstack.org/101993:\nPublish OPS Guide to /openstack-ops and not anymore to\n/trunk/openstack-ops.\nAdd redirects as needed.\n\nChange-Id: Ib52bbbb1ec6e90ad3222ea6685039fd4d3fb366d\n'}, {'number': 2, 'created': '2014-06-23 20:36:59.000000000', 'files': ['www/.htaccess', 'doc/admin-guide-cloud/compute/section_compute-images-instances.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/common/section_cli_nova_manage_images.xml', 'doc/common/section_cli_nova_images.xml', 'doc/user-guide-admin/section_cli_nova_manage_flavors.xml', 'www/ops/index.html', 'doc/security-guide/ch012_configuration-management.xml', 'doc/admin-guide-cloud/compute/section_compute-networking-nova.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/19fa888a54e57ef95bc3674382f57775ef3d3efa', 'message': 'Publish OPS Guide to /openstack-ops\n\nThis depends on https://review.openstack.org/101993:\nPublish OPS Guide to /openstack-ops and not anymore to\n/trunk/openstack-ops.\n\nAdd redirects as needed and change all links.\n\nChange-Id: Ib52bbbb1ec6e90ad3222ea6685039fd4d3fb366d\n'}]",0,101996,19fa888a54e57ef95bc3674382f57775ef3d3efa,17,5,2,6547,,,0,"Publish OPS Guide to /openstack-ops

This depends on https://review.openstack.org/101993:
Publish OPS Guide to /openstack-ops and not anymore to
/trunk/openstack-ops.

Add redirects as needed and change all links.

Change-Id: Ib52bbbb1ec6e90ad3222ea6685039fd4d3fb366d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/101996/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/.htaccess', 'www/ops/index.html']",2,7c874bd007005c12bc32d20278e80b0afc0acbe8,ops-guide_no-trunk," <a href=""/openstack-ops/content/"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.html');return false;""> <a class=""button"" href=""/openstack-ops/content/"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.html');return false;""> <a class=""button"" href=""/openstack-ops/openstack-ops-manual.pdf"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.pdf');return false;"">"," <a href=""/trunk/openstack-ops/content/"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.html');return false;""> <a class=""button"" href=""/trunk/openstack-ops/content/"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.html');return false;""> <a class=""button"" href=""/trunk/openstack-ops/openstack-ops-manual-trunk.pdf"" onclick=""recordOutboundLink(this, 'Outbound Links', 'ops.pdf');return false;"">",7,4
openstack%2Fopenstack-manuals~master~I88693edd2e1844d4477f87612191a873c4fe4ea4,openstack/openstack-manuals,master,I88693edd2e1844d4477f87612191a873c4fe4ea4,Add oslotest to the list of oslo libraries,MERGED,2014-06-23 17:25:21.000000000,2014-06-24 22:08:53.000000000,2014-06-24 22:08:53.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2472}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-23 17:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7612c91b1940139779beeb7cd945073e35767fcc', 'message': 'Add oslotest to the list of oslo libraries\n\nChange-Id: I88693edd2e1844d4477f87612191a873c4fe4ea4\n'}, {'number': 2, 'created': '2014-06-23 17:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6403dfedfe28e87d2703c9c9a449977001ab38b4', 'message': 'Add oslotest to the list of oslo libraries\n\nChange-Id: I88693edd2e1844d4477f87612191a873c4fe4ea4\n'}, {'number': 3, 'created': '2014-06-23 20:36:34.000000000', 'files': ['www/developer/openstack-projects.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7e056aad3185bb9033d6990f5916ec7a1717a124', 'message': 'Add oslotest to the list of oslo libraries\n\nChange-Id: I88693edd2e1844d4477f87612191a873c4fe4ea4\n'}]",2,101959,7e056aad3185bb9033d6990f5916ec7a1717a124,19,4,3,2472,,,0,"Add oslotest to the list of oslo libraries

Change-Id: I88693edd2e1844d4477f87612191a873c4fe4ea4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/59/101959/2 && git format-patch -1 --stdout FETCH_HEAD,['www/developer/openstack-projects.html'],1,7612c91b1940139779beeb7cd945073e35767fcc,add-oslotest," <a href=""http://docs.openstack.org/developer/oslotest/""> pbr </a>  Provides a unit test and fixture framework. </dd> <dd>",,6,0
openstack%2Frequirements~master~Ia9f5f5e8a940328954c3e581c6a10c0368096143,openstack/requirements,master,Ia9f5f5e8a940328954c3e581c6a10c0368096143,Add osprofiler to requirements,ABANDONED,2014-05-07 21:33:32.000000000,2014-06-24 22:05:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-05-07 21:33:32.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e2d11243427bd15c37e586cbf7966b178e41da57', 'message': 'Add osprofiler to requirements\n\nThis new library is being created and actively developed to\nmake it easy to profile your code (even across a distributed system),\nhaving it in requirements allows the various openstack projects\nthat would benefit from this kind of profiling begin to start using\nit.\n\nChange-Id: Ia9f5f5e8a940328954c3e581c6a10c0368096143\n'}]",0,92708,e2d11243427bd15c37e586cbf7966b178e41da57,5,2,1,1297,,,0,"Add osprofiler to requirements

This new library is being created and actively developed to
make it easy to profile your code (even across a distributed system),
having it in requirements allows the various openstack projects
that would benefit from this kind of profiling begin to start using
it.

Change-Id: Ia9f5f5e8a940328954c3e581c6a10c0368096143
",git fetch https://review.opendev.org/openstack/requirements refs/changes/08/92708/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e2d11243427bd15c37e586cbf7966b178e41da57,,osprofiler # Apache-2.0,,1,0
openstack%2Fzaqar~master~I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8,openstack/zaqar,master,I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8,V1.1 Functional Tests,MERGED,2014-05-12 12:50:38.000000000,2014-06-24 22:02:11.000000000,2014-06-24 22:02:11.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 7498}, {'_account_id': 10777}, {'_account_id': 11399}]","[{'number': 1, 'created': '2014-05-12 12:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/21bd615956963e45db55ad0f176c140bce7ab105', 'message': 'V1.1 Functional Tests\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\n\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 2, 'created': '2014-05-13 12:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ab9500f0881b0f98511dac9ae716f1a67d86e1f7', 'message': 'V1.1 Functional Tests\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\n\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 3, 'created': '2014-05-13 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fd33f92b287cb0f0c7910f49a6c27e98ce30fa49', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\n\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 4, 'created': '2014-05-19 19:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/278d8315dfb76d77d4f3d9d80eeba5f3f659e583', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\n\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 5, 'created': '2014-05-19 19:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ab4acf3c54b8b0970042886ad3796e79bfeca1d6', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\n\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 6, 'created': '2014-06-10 15:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5ecd103e99624dfcb96dc726b73214a16c4d99a4', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 7, 'created': '2014-06-10 15:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b4b616648f51fc11bc73259bfd539ab9ace9cb13', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 8, 'created': '2014-06-10 17:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5b488c4cda26fdbc3ab4428ac9a44b4b25883a5a', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 9, 'created': '2014-06-12 14:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2a31f112284ec395e35c0aded4549d2903a44d48', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 10, 'created': '2014-06-13 15:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ecccd67fa0a301117d920d843ece1cb3c20f466b', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 11, 'created': '2014-06-23 13:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0ecba41d86b97eb2ef32a55b7840fb60fed70c17', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 12, 'created': '2014-06-23 14:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6774461cc17c918736f233d60a7ed7ff1a5b6fd2', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 13, 'created': '2014-06-23 17:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/45ee3853361d66c3efaf306a0c57ee62aa52c160', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 14, 'created': '2014-06-24 14:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1522c249640e5f61bf514a7c97e5e2ad3043713a', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nImplements: blueprint api-v1.1-functional-tests\n'}, {'number': 15, 'created': '2014-06-24 20:11:26.000000000', 'files': ['marconi/tests/functional/helpers.py', 'tests/functional/wsgi/v1/test_claims.py', 'marconi/queues/api/v1_1/response.py', 'tests/functional/wsgi/v1_1/test_messages.py', 'tests/functional/wsgi/v1_1/__init__.py', 'tests/functional/wsgi/v1_1/test_shards.py', 'tests/functional/wsgi/v1/test_queues.py', 'marconi/tests/functional/config.py', 'tests/functional/wsgi/v1_1/test_claims.py', 'tests/functional/wsgi/v1_1/test_queues.py', 'tests/etc/functional-tests.conf', 'tests/functional/wsgi/v1/test_messages.py', 'marconi/queues/api/v1_1/request.py', 'marconi/queues/api/v1_1/__init__.py', 'marconi/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c1715c6fb190a9cf12e858e677b24dfa525a36e6', 'message': 'V1.1 Functional Tests\n\nAdded tests for new V1.1 functions like pop and shard\nUpdated existing tests for V1.1 return calls\nAdded new json schemas\nEdited functional test base to support multiple schemas\nChange-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8\nPartially-Implements blueprint: api-v1.1-functional-tests\n'}]",35,93295,c1715c6fb190a9cf12e858e677b24dfa525a36e6,73,7,15,11399,,,0,"V1.1 Functional Tests

Added tests for new V1.1 functions like pop and shard
Updated existing tests for V1.1 return calls
Added new json schemas
Edited functional test base to support multiple schemas
Change-Id: I35dfb92af22540609ecb50c1eb5c8fa65e6cadc8
Partially-Implements blueprint: api-v1.1-functional-tests
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/95/93295/9 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/transport/wsgi/v1_1/queues.py', '.gitignore', 'marconi/queues/api/v1/response.py', 'marconi/tests/functional/helpers.py', 'tests/functional/wsgi/v1/test_claims.py', 'marconi/queues/api/v1_1/response.py', 'marconi/queues/transport/wsgi/v1_1/shards.py', 'tests/functional/wsgi/v1_1/test_messages.py', 'tests/functional/wsgi/v1_1/__init__.py', 'tests/functional/wsgi/v1_1/test_shards.py', 'tests/functional/wsgi/v1/test_queues.py', 'tests/etc/functional-marconi.conf', 'tests/functional/wsgi/v1_1/test_claims.py', 'tests/functional/wsgi/v1_1/test_queues.py', 'tox.ini~', 'marconi/queues/transport/wsgi/v1_1/messages.py', 'tests/etc/functional-tests.conf', 'tests/functional/wsgi/v1/test_messages.py', 'marconi/queues/api/v1_1/request.py', 'marconi/queues/api/v1_1/__init__.py', 'marconi/tests/functional/base.py']",21,21bd615956963e45db55ad0f176c140bce7ab105,bp/api-v1,"from marconi.queues.api.v1_1 import response as response_v1_1 if self.cfg.marconi.version == ""v1.1"": self.response = response_v1_1.ResponseSchema(self.limits) else: self.response = response.ResponseSchema(self.limits)", self.response = response.ResponseSchema(self.limits),1932,38
openstack%2Fmanila~master~I9261271c6e77e2afe6033f9466a3ff562cf3fe2f,openstack/manila,master,I9261271c6e77e2afe6033f9466a3ff562cf3fe2f,Fix create_share_from_snapshot method,MERGED,2014-06-20 09:00:17.000000000,2014-06-24 22:00:38.000000000,2014-06-24 22:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-06-20 09:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1171732fe80515cc51f05eb6fc4033bda00a23e2', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\n\nPartially-implements bp implement-backend-details-in-drivers\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}, {'number': 2, 'created': '2014-06-20 10:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9d348d0f127b614215eb92f26e0f497977bcc3bc', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\n\nFixes-Bug: #1332080\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}, {'number': 3, 'created': '2014-06-22 10:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/bc50901a335e4b9478d117ae99ac77c66ab0af78', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\n\nFixes-Bug: #1332080\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}, {'number': 4, 'created': '2014-06-23 06:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/88c1386b654beb8f41ceca9bb781354cdb652091', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\nPartial-Bug: #1332080\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}, {'number': 5, 'created': '2014-06-23 12:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b635ece3b6403b6aa86fd1272d49230177f49f7a', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\nPartial-Bug: #1332080\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}, {'number': 6, 'created': '2014-06-24 08:48:06.000000000', 'files': ['manila/tests/test_share.py', 'manila/share/manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/422285d1b8769e5860ba2f3a7dd6958e330ff4a0', 'message': 'Fix create_share_from_snapshot method\n\nRetreiving share_server of parent share\nand passing it to driver.\nPartial-Bug: #1332080\n\nChange-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f\n'}]",9,101453,422285d1b8769e5860ba2f3a7dd6958e330ff4a0,37,5,6,7534,,,0,"Fix create_share_from_snapshot method

Retreiving share_server of parent share
and passing it to driver.
Partial-Bug: #1332080

Change-Id: I9261271c6e77e2afe6033f9466a3ff562cf3fe2f
",git fetch https://review.opendev.org/openstack/manila refs/changes/53/101453/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_share.py', 'manila/share/manager.py']",2,1171732fe80515cc51f05eb6fc4033bda00a23e2,bp/implement-backend-details-in-drivers," parent_share_server_id = snapshot_ref['share']['share_server_id'] parent_share_server_id = None if parent_share_server_id: share_server = self.db.share_server_get(context, parent_share_server_id) elif share_network_id: if share_server: LOG.debug(""Using share server %s"" % share_server['id']) share_ref = self.db.share_update( context, share_id, {'share_server_id': share_server['id']}) context, share_ref, snapshot_ref, share_server=share_server)"," if share_network_id: share_ref = self.db.share_update( context, share_id, {'share_server_id': share_server['id']}) LOG.debug(""Using share server %s"" % share_server['id']) context, share_ref, snapshot_ref)",33,6
openstack%2Fmanila~master~Icf39422927fc7754c5c47ab717fad178ed44a0dc,openstack/manila,master,Icf39422927fc7754c5c47ab717fad178ed44a0dc,Cleaned up exception module and added unittests,MERGED,2014-06-03 11:37:07.000000000,2014-06-24 21:48:46.000000000,2014-06-24 21:48:46.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 9521}]","[{'number': 1, 'created': '2014-06-03 11:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/957f751c6e310993abc50259177c9558802824f4', 'message': 'Fixed several exceptions\n\nCouple of exceptions is unused and should be removed.\nSeveral exceptions use wrong inheritance that causes\nwrong responce codes.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n'}, {'number': 2, 'created': '2014-06-05 07:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8f4c6dd728f7a5d80d1c6f701fd5826f8d166da9', 'message': 'Fixed several exceptions\n\nCouple of exceptions is unused and should be removed.\nSeveral exceptions use wrong inheritance that causes\nwrong responce codes.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n'}, {'number': 3, 'created': '2014-06-10 11:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/62c59a7729ec5b0616387423f1afa93db4e6df48', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 4, 'created': '2014-06-10 13:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/23db52937fb316d897d82e699ebb40d271a838ef', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 5, 'created': '2014-06-11 07:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0306b99d3220fcf85bec019450ad08853c0d26d4', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 6, 'created': '2014-06-16 09:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3ca2ab32af12d56cfb312766a12caf30b404fda1', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 7, 'created': '2014-06-23 09:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/40e076babae597477c4c185fed45db22d12c6c49', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 8, 'created': '2014-06-23 09:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a2fe808c647ac50a850b61cda07cf809fcc1ef12', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}, {'number': 9, 'created': '2014-06-23 18:02:32.000000000', 'files': ['manila/exception.py', 'manila/tests/test_exception.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8dd80bdccaf1d7bf7c8ff8bbcfdd28fc492b97f8', 'message': ""Cleaned up exception module and added unittests\n\nRemoved unused exceptions and fixed several inheritance\nissues, that causes wrong responce codes.\n\nexceptions MigrationNotFound and MigrationNotFoundByStatus\nare left, because manila just doesn't have migrations yet.\n\nChange-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc\nRelated-Bug: #1325934\n""}]",14,97471,8dd80bdccaf1d7bf7c8ff8bbcfdd28fc492b97f8,59,6,9,8851,,,0,"Cleaned up exception module and added unittests

Removed unused exceptions and fixed several inheritance
issues, that causes wrong responce codes.

exceptions MigrationNotFound and MigrationNotFoundByStatus
are left, because manila just doesn't have migrations yet.

Change-Id: Icf39422927fc7754c5c47ab717fad178ed44a0dc
Related-Bug: #1325934
",git fetch https://review.opendev.org/openstack/manila refs/changes/71/97471/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/exception.py'],1,957f751c6e310993abc50259177c9558802824f4,master,class InvalidShare(Invalid):class InvalidShareAccess(Invalid):class InvalidShareSnapshot(Invalid):class InvalidShareNetwork(Invalid):,"class Duplicate3PARHost(ManilaException): message = _(""3PAR Host already exists: %(err)s. %(info)s"") class Invalid3PARDomain(ManilaException): message = _(""Invalid 3PAR Domain: %(err)s"") class InvalidShare(ManilaException):class InvalidShareAccess(ManilaException):class InvalidShareSnapshot(ManilaException):class InvalidShareNetwork(ManilaException):",4,12
openstack%2Ftrove-integration~master~I94ac4b59fa2697aaedee1f8e44146f6ac790a00b,openstack/trove-integration,master,I94ac4b59fa2697aaedee1f8e44146f6ac790a00b,Add DIB Elements for MongoDB 2.4,ABANDONED,2014-03-02 23:48:16.000000000,2014-06-24 21:47:36.000000000,,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8136}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9749}, {'_account_id': 9782}]","[{'number': 1, 'created': '2014-03-02 23:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/e8e3cd9b616f34099b47691140123cdb037c1ea1', 'message': 'Add dib elements for MongoDB version 2.4.9\n\nAdd scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/* elements\nneeded for building image with  MongoDB version 2.4.9\n\nUses the mongod 10gen repos and NOT the standard distro\nrepos since version 2.4.9 is not available there.\n\nImplements: blueprint mongodb-2.4.9-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 2, 'created': '2014-03-02 23:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/2b08c78c97ea5831d72982843531a3af1f7864d5', 'message': 'Add dib elements for MongoDB version 2.4.9\n\nAdd scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/* elements\nneeded for building image with  MongoDB version 2.4.9\n\nUses the mongod 10gen repos and NOT the standard distro\nrepos since version 2.4.9 is not available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 3, 'created': '2014-03-03 06:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/13d14964d02c6fa5bc05a3ee5aa228128a467ac1', 'message': 'Add dib elements for MongoDB version 2.4.9\n\nAdd scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/* elements\nneeded for building image with  MongoDB version 2.4.9\n\nUses the mongod 10gen repos and NOT the standard distro\nrepos since version 2.4.9 is not available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 4, 'created': '2014-03-03 21:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/6888dbe5e7f8b3ee687f9209cd797f1b8c77a7f0', 'message': 'Add dib elements for MongoDB version 2.4.9\n\nAdd scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/* elements\nneeded for building image with  MongoDB version 2.4.9\n\nUses the mongod 10gen repos and NOT the standard distro\nrepos since version 2.4.9 is not available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 5, 'created': '2014-04-19 00:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/f1a2d6ac5045447794508f291007f8b1cc8dbcfe', 'message': 'Add dib elements for MongoDB version 2.4.9\n\nAdd scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/* elements\nneeded for building image with  MongoDB version 2.4.9\n\nUses the mongod 10gen repos and NOT the standard distro\nrepos since version 2.4.9 is not available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 6, 'created': '2014-04-29 19:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/56df898b2d528c1ea2abe5a52230e59d5261d5e9', 'message': 'Add DIB Elements for MongoDB 2.4\n\nadd scripts/files/elements/ubuntu-mongodb-2.4/install.d/* elements\nneeded for building the mongodb 2.4 image. uses the mongod 10gen\nrepos and not the standard distro repos since the latest 2.4.X\nversions are not necessarily available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 7, 'created': '2014-04-29 19:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/acd619946d6f30603edf700269d34fdae4d570a1', 'message': 'Add DIB Elements for MongoDB 2.4\n\nadd scripts/files/elements/ubuntu-mongodb-2.4/install.d/* elements\nneeded for building the mongodb 2.4 image. uses the mongod 10gen\nrepos and not the standard distro repos since the latest 2.4.X\nversions are not necessarily available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}, {'number': 8, 'created': '2014-04-29 20:06:17.000000000', 'files': ['scripts/files/elements/ubuntu-mongodb-2.4/install.d/README.md', 'scripts/files/elements/ubuntu-mongodb-2.4/install.d/25-trove-mongo-dep', 'scripts/files/elements/ubuntu-mongodb-2.4/install.d/10-mongodb'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/d4653daf6a10ec23d6ae3f5ce85597d7b52a3915', 'message': 'Add DIB Elements for MongoDB 2.4\n\nadd scripts/files/elements/ubuntu-mongodb-2.4/install.d/* elements\nneeded for building the mongodb 2.4 image. uses the mongod 10gen\nrepos and not the standard distro repos since the latest 2.4.X\nversions are not necessarily available there.\n\nImplements: blueprint mongodb249-dib-elements\nChange-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b\n'}]",4,77461,d4653daf6a10ec23d6ae3f5ce85597d7b52a3915,71,12,8,8136,,,0,"Add DIB Elements for MongoDB 2.4

add scripts/files/elements/ubuntu-mongodb-2.4/install.d/* elements
needed for building the mongodb 2.4 image. uses the mongod 10gen
repos and not the standard distro repos since the latest 2.4.X
versions are not necessarily available there.

Implements: blueprint mongodb249-dib-elements
Change-Id: I94ac4b59fa2697aaedee1f8e44146f6ac790a00b
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/61/77461/3 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/README.md', 'scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/10-mongodb', 'tests/integration/int_tests.py', 'scripts/files/elements/ubuntu-mongodb-2.4.9/install.d/25-trove-mongo-dep']",4,e8e3cd9b616f34099b47691140123cdb037c1ea1,bp/mongodb249-dib-elements,# CONTEXT: GUEST during CONSTRUCTION as ROOT # PURPOSE: Install trove guest python dependencies - see redstack functions_qemu set -e set -o xtrace pip install pymongo ,,31,0
openstack%2Fbashate~master~I4e2a30a82501b6ec29d06b49ccba63418cc39fa0,openstack/bashate,master,I4e2a30a82501b6ec29d06b49ccba63418cc39fa0,Refactor in BashateRun class,MERGED,2014-06-24 03:43:44.000000000,2014-06-24 21:40:36.000000000,2014-06-24 21:40:36.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-24 03:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/6b294b393167bb29193e039fc815b8e866bc7eb0', 'message': ""Refactor in BashateRun class\n\nGrab the module level functions that seemed to belong\nunder the 'runtime logic' category and tuck them into\na BashateRun class that should encapsulate the options\nand checks that are used in doing a bashate run against\na set of files. Primarily, this makes it easier to unit test\nthe bashate logic, but also opens up some API possibilities.\n\nLeaving the 'check_*' functions at module level, as they have\na relatively simple contract they need to fulfill for the time\nbeing.\n\nChange-Id: I4e2a30a82501b6ec29d06b49ccba63418cc39fa0\n""}, {'number': 2, 'created': '2014-06-24 03:48:27.000000000', 'files': ['bashate/bashate.py', 'bashate/tests/test_bashate.py'], 'web_link': 'https://opendev.org/openstack/bashate/commit/db3b15cdafa94717dc433a0d949f80e655148c31', 'message': ""Refactor in BashateRun class\n\nGrab the module level functions that seemed to belong\nunder the 'runtime logic' category and tuck them into\na BashateRun class that should encapsulate the options\nand checks that are used in doing a bashate run against\na set of files. Primarily, this makes it easier to unit test\nthe bashate logic, but also opens up some API possibilities.\n\nLeaving the 'check_*' functions at module level, as they have\na relatively simple contract they need to fulfill for the time\nbeing.\n\nChange-Id: I4e2a30a82501b6ec29d06b49ccba63418cc39fa0\n""}]",0,102097,db3b15cdafa94717dc433a0d949f80e655148c31,10,2,2,5371,,,0,"Refactor in BashateRun class

Grab the module level functions that seemed to belong
under the 'runtime logic' category and tuck them into
a BashateRun class that should encapsulate the options
and checks that are used in doing a bashate run against
a set of files. Primarily, this makes it easier to unit test
the bashate logic, but also opens up some API possibilities.

Leaving the 'check_*' functions at module level, as they have
a relatively simple contract they need to fulfill for the time
being.

Change-Id: I4e2a30a82501b6ec29d06b49ccba63418cc39fa0
",git fetch https://review.opendev.org/openstack/bashate refs/changes/97/102097/2 && git format-patch -1 --stdout FETCH_HEAD,"['bashate/bashate.py', 'bashate/tests/test_bashate.py']",2,6b294b393167bb29193e039fc815b8e866bc7eb0,," def test_multi_ignore(self): run = bashate.BashateRun() run.register_ignores('E001|E011') bashate.check_no_trailing_whitespace(""if "", run) bashate.check_if_then(""if "", run) self.assertEqual(run.ERRORS, 0) run = bashate.BashateRun() run.register_ignores('E001') bashate.check_no_trailing_whitespace(""if "", run) self.assertEqual(run.ERRORS, 0) @mock.patch('bashate.bashate.BashateRun.print_error') def test_while_check_for_do(self, m_print_error): run = bashate.BashateRun() bashate.check_for_do(test_line, run) log_error_patcher = mock.patch( 'bashate.bashate.BashateRun.log_error') self.run = bashate.BashateRun() self.run.check_files(test_files, False) self.run.check_files(test_files, False) self.run.check_files(test_files, False)"," # cleanup global IGNOREs def reset_ignores(): bashate.IGNORE = None self.addCleanup(reset_ignores) def test_multi_ignore(self): bashate.register_ignores('E001|E011') bashate.check_no_trailing_whitespace(""if "") bashate.check_if_then(""if "") self.assertEqual(bashate.ERRORS, 0) bashate.register_ignores('E001') bashate.check_no_trailing_whitespace(""if "") self.assertEqual(bashate.ERRORS, 0) @mock.patch('bashate.bashate.print_error') def test_while_check_for_do(self, m_print_error): bashate.check_for_do(test_line) log_error_patcher = mock.patch('bashate.bashate.log_error') bashate.check_files(test_files, False) bashate.check_files(test_files, False) bashate.check_files(test_files, False)",161,150
openstack%2Fbashate~master~I77d55ed9a8ba6557cc18040a3952774be83a17f3,openstack/bashate,master,I77d55ed9a8ba6557cc18040a3952774be83a17f3,Remove redundant doc from top of bashate.py,MERGED,2014-06-24 03:43:44.000000000,2014-06-24 21:39:50.000000000,2014-06-24 21:39:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-24 03:43:44.000000000', 'files': ['bashate/bashate.py'], 'web_link': 'https://opendev.org/openstack/bashate/commit/73ebffa13fa8e69ff0bda864af089758184803d1', 'message': 'Remove redundant doc from top of bashate.py\n\nThis should be all in the README and generated docs\nnow, so having it in two spots is just double\nmaintenance.\n\nChange-Id: I77d55ed9a8ba6557cc18040a3952774be83a17f3\n'}]",0,102096,73ebffa13fa8e69ff0bda864af089758184803d1,7,2,1,5371,,,0,"Remove redundant doc from top of bashate.py

This should be all in the README and generated docs
now, so having it in two spots is just double
maintenance.

Change-Id: I77d55ed9a8ba6557cc18040a3952774be83a17f3
",git fetch https://review.opendev.org/openstack/bashate refs/changes/96/102096/1 && git format-patch -1 --stdout FETCH_HEAD,['bashate/bashate.py'],1,73ebffa13fa8e69ff0bda864af089758184803d1,,,"# bashate - a pep8 equivalent for bash scripts # # this program attempts to be an automated style checker for bash scripts # to fill the same part of code review that pep8 does in most OpenStack # projects. It starts from humble beginnings, and will evolve over time. # # Currently Supported checks # # Errors # Basic white space errors, for consistent indenting # - E001: check that lines do not end with trailing whitespace # - E002: ensure that indents are only spaces, and not hard tabs # - E003: ensure all indents are a multiple of 4 spaces # - E004: file did not end with a newline # # Structure errors # # A set of rules that help keep things consistent in control blocks. # These are ignored on long lines that have a continuation, because # unrolling that is kind of ""interesting"" # # - E010: *do* not on the same line as *for* # - E011: *then* not on the same line as *if* # - E012: heredoc didn't end before EOF ",0,25
openstack%2Fbashate~master~Id1e9db34906653fdfe22336d3c125f33d0e15883,openstack/bashate,master,Id1e9db34906653fdfe22336d3c125f33d0e15883,add python34 target for those of use on trusty,MERGED,2014-06-20 12:15:00.000000000,2014-06-24 21:39:45.000000000,2014-06-24 21:39:45.000000000,"[{'_account_id': 3}, {'_account_id': 5371}]","[{'number': 1, 'created': '2014-06-20 12:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/12544cd4689d19a18efbf14cbc10c064167a5eda', 'message': 'add python34 target for those of use on trusty\n\nChange-Id: Id1e9db34906653fdfe22336d3c125f33d0e15883\n'}, {'number': 2, 'created': '2014-06-20 22:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/8755ec345bd2bb257d51124d350325996eb32af2', 'message': 'add python34 target for those of use on trusty\n\nChange-Id: Id1e9db34906653fdfe22336d3c125f33d0e15883\n'}, {'number': 3, 'created': '2014-06-24 01:00:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/bashate/commit/319a7e5ff31bd28a6e943736dc9713a2d1429717', 'message': 'add python34 target for those of use on trusty\n\nChange-Id: Id1e9db34906653fdfe22336d3c125f33d0e15883\n'}]",0,101508,319a7e5ff31bd28a6e943736dc9713a2d1429717,17,2,3,2750,,,0,"add python34 target for those of use on trusty

Change-Id: Id1e9db34906653fdfe22336d3c125f33d0e15883
",git fetch https://review.opendev.org/openstack/bashate refs/changes/08/101508/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,12544cd4689d19a18efbf14cbc10c064167a5eda,discover,"envlist = py26,py27,py33,py34,pypy,pep8","envlist = py26,py27,py33,pypy,pep8",1,1
openstack%2Ftempest~master~If463afd832d2cae000feab6bb9e8d397b829ee70,openstack/tempest,master,If463afd832d2cae000feab6bb9e8d397b829ee70,Add cases for Cinder scenario test,ABANDONED,2014-06-23 05:58:45.000000000,2014-06-24 21:27:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6484}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 05:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2cc1a983fc8200b63e07850324736048af47519a', 'message': ""Add cases for Cinder scenario test\n\nAdding the volume attach cases for Cinder scenario test, given the\nattach operation is one of the key functions of Cinder and it's a\ntypical user scenario in the daily storage management. Below is the\ndetailed steps:\n\n* Create a new volume and attach it on an instance\n* Format the volume with ext4 and mount the volume on /mnt\n* Write content to /mnt/text\n* Attach, mount the volume to another instance and check the content\n\nChange-Id: If463afd832d2cae000feab6bb9e8d397b829ee70\n""}, {'number': 2, 'created': '2014-06-23 06:03:06.000000000', 'files': ['tempest/scenario/test_volume_boot_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6ec8479b452bbddc6909ba1f1c4f7ce3233f6e94', 'message': ""Add cases for Cinder scenario test\n\nAdding the volume attach cases for Cinder scenario test, given the\nattach operation is one of the key functions of Cinder and it's a\ntypical user scenario in the daily storage management. Below is the\ndetailed steps:\n\n* Create a new volume and attach it on an instance\n* Format the volume with ext4 and mount the volume on /mnt\n* Write content to /mnt/text\n* Attach, mount the volume to another instance and check the content\n\nChange-Id: If463afd832d2cae000feab6bb9e8d397b829ee70\n""}]",0,101805,6ec8479b452bbddc6909ba1f1c4f7ce3233f6e94,26,8,2,6484,,,0,"Add cases for Cinder scenario test

Adding the volume attach cases for Cinder scenario test, given the
attach operation is one of the key functions of Cinder and it's a
typical user scenario in the daily storage management. Below is the
detailed steps:

* Create a new volume and attach it on an instance
* Format the volume with ext4 and mount the volume on /mnt
* Write content to /mnt/text
* Attach, mount the volume to another instance and check the content

Change-Id: If463afd832d2cae000feab6bb9e8d397b829ee70
",git fetch https://review.opendev.org/openstack/tempest refs/changes/05/101805/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_volume_boot_pattern.py'],1,2cc1a983fc8200b63e07850324736048af47519a,bp/volume-scenario-enhancement," * Create a new volume and attach it on an instance * Format the volume with ext4 and mount the volume on /mnt * Write content to /mnt/text * Attach and mount the volume to another instance and check the content def _attach_volumes(self, server, volumes): # NOTE(flwang): calling Nova client to simulate the normal workflow for v in volumes: self.compute_client.volumes.create_server_volume(server, v.id, '/dev/vdx') for v in volumes: self.status_timeout(self.volume_client.volumes, v.id, 'in-use') def _get_content(self, ssh_client, file_loc='/tmp/text'): return ssh_client.exec_command('cat %s' % file_loc ) def _write_text(self, ssh_client, file_loc='/tmp/text'): ssh_client.exec_command('echo ""%s"" > %s; sync' % (text, file_loc)) return self._get_content(ssh_client, file_loc) def _attach_mount(self, server, ssh_client, volumes, be_formated=True): # NOTE(flwang): Though we're attaching the volume on /dev/vdb but it # is not sure, so we have to check the correct device name before = ssh_client.exec_command(""cat /proc/partitions | "" ""awk '{print $NF}'"").split() self._attach_volumes(server.id, volumes) after = ssh_client.exec_command(""cat /proc/partitions | "" ""awk '{print $NF}'"").split() device = set(after).difference(set(before)).pop() if be_formated: ssh_client.exec_command('sudo /usr/sbin/mkfs.ext4 /dev/%s' % device) ssh_client.exec_command('sudo /bin/mount /dev/%s /mnt' % device) def _attach_mount_write(self, server, ssh_client, volumes): self._attach_mount(server, ssh_client, volumes, be_formated=True) ssh_client.exec_command('sudo touch /mnt/text;' 'sudo chown `whoami` /mnt/text') return self._write_text(ssh_client, file_loc='/mnt/text') def _attach_mount_get(self, server, ssh_client, volumes): self._attach_mount(server, ssh_client, volumes, be_formated=False) return self._get_content(ssh_client, file_loc='/mnt/text') # create a new volume, attach and mount it to a new instance, then # write something volume_attached = self.create_volume() text = self._attach_mount_write(instance_from_snapshot, ssh_client, [volume_attached]) self._detach_volumes([volume_attached]) # create a 4th instance, attach the volume on that and check if the # file content is correct create_kwargs = {'key_name': keypair.name, 'security_groups': [self.security_group.name]} instance_4th = self.create_server(create_kwargs=create_kwargs) ssh_client_4th = self._ssh_to_server(instance_4th, keypair) expected_text = self._attach_mount_get(instance_4th, ssh_client_4th, [volume_attached]) self.assertEqual(expected_text, text) self._detach_volumes([volume_origin, volume, volume_attached])"," def _get_content(self, ssh_client): return ssh_client.exec_command('cat /tmp/text') def _write_text(self, ssh_client): ssh_client.exec_command('echo ""%s"" > /tmp/text; sync' % (text)) return self._get_content(ssh_client) self._detach_volumes([volume_origin, volume])",65,6
openstack%2Fneutron~master~I20e8a36085a7192fd80a737ede4283bf058690e9,openstack/neutron,master,I20e8a36085a7192fd80a737ede4283bf058690e9,VPNaaS: Allow vendor extend/override valiadation,ABANDONED,2014-05-30 21:25:00.000000000,2014-06-24 21:20:01.000000000,,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-05-30 21:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8c75f5caa9bc2e517af5237e97ae36afd79735c', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection). Based on feedback, we can continue with\nimplementation of this approach and use it for all L3 services.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestion: Should we only implement validation methods for resources\nthat currently have validation logic (versus doing for all of the\nresources, and maybe never needed the methods)?\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}, {'number': 2, 'created': '2014-06-04 21:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be0e1f0f6091a4d18a00efefcaa70b5919d5eae7', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection). Based on feedback, we can continue with\nimplementation of this approach and use it for all L3 services.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestion: Should we only implement validation methods for resources\nthat currently have validation logic (versus doing for all of the\nresources, and maybe never needed the methods)?\n\nUPDATE: Issue with UT of VPN DBase code. ushed for assistance in\ngeting mock side_effect working.\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}, {'number': 3, 'created': '2014-06-14 00:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6584df2e160f331bafde7d1a87cfbb69c149a5c', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection), but does so for both the reference and\nCisco implementations, so that we can see how it would work when\nthere are different validations done. For the actual commit, we\ncan break this into parts.\n\nThe goal here is to get community feedback on the approach, to see\nif this is the ""right"" method, and then apply it for all L3\nservices. So, I\'m looking for feedback on the approach and not\nnit-pick items.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestions: Should we apply this only to resources that already\nhave multiple implementations (on an as needed basis), or on\nall resources that currently have validation?\n\nShould the corresponding validation related exceptions be moved\nfrom the extension file to the validation module? I\'m thinking so.\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}, {'number': 4, 'created': '2014-06-16 12:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e169a133046cb554e9bc092a9dc101afa2f8737', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection), but does so for both the reference and\nCisco implementations, so that we can see how it would work when\nthere are different validations done. For the actual commit, we\ncan break this into parts.\n\nThe goal here is to get community feedback on the approach, to see\nif this is the ""right"" method, and then apply it for all L3\nservices. So, I\'m looking for feedback on the approach and not\nnit-pick items.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestions: Should we apply this only to resources that already\nhave multiple implementations (on an as needed basis), or on\nall resources that currently have validation?\n\nShould the corresponding validation related exceptions be moved\nfrom the extension file to the validation module? I\'m thinking so.\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}, {'number': 5, 'created': '2014-06-16 16:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3abd1daa1eb8bcff7b7340b99df67d1e3dd2a2b', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection), but does so for both the reference and\nCisco implementations, so that we can see how it would work when\nthere are different validations done. For the actual commit, we\ncan break this into parts.\n\nThe goal here is to get community feedback on the approach, to see\nif this is the ""right"" method, and then apply it for all L3\nservices. So, I\'m looking for feedback on the approach and not\nnit-pick items.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestions: Should we apply this only to resources that already\nhave multiple implementations (on an as needed basis), or on\nall resources that currently have validation?\n\nShould the corresponding validation related exceptions be moved\nfrom the extension file to the validation module? I\'m thinking so.\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}, {'number': 6, 'created': '2014-06-18 01:01:02.000000000', 'files': ['neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/db/vpn/vpn_validator.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/db/vpn/vpn_db.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'neutron/services/vpn/service_drivers/cisco_validator.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/770568182c69f42cf8f2a8263fa3a711343e4dd4', 'message': 'VPNaaS: Allow vendor extend/override valiadation\n\nExtracts out validation for resources into separate methods and\nallows service driver to optionally override or extend the\nvalidation logic.\n\nThis gives different providers the ability to alter the validation,\nbased on thier capabilities, which may differ from the reference\nimplementation.\n\nThe validation is performed during the database transaction, to\nensure consistency, when there are simultaneous requests from\nmultiple clients.\n\nThis WIP just updates two of the resources (VPN service, and IPSec\nsite to site connection), but does so for both the reference and\nCisco implementations, so that we can see how it would work when\nthere are different validations done. For the actual commit, we\ncan break this into parts.\n\nThe goal here is to get community feedback on the approach, to see\nif this is the ""right"" method, and then apply it for all L3\nservices. So, I\'m looking for feedback on the approach and not\nnit-pick items.\n\nNote: The longer term solution may involve using TaskFlow,\nhowever, even with that, we need the ability to override and\nextend validation. This change will be useful in moving in that\ndirection.\n\nQuestions: Should we apply this only to resources that already\nhave multiple implementations (on an as needed basis), or on\nall resources that currently have validation?\n\nShould the corresponding validation related exceptions be moved\nfrom the extension file to the validation module? I\'m thinking so.\n\nPartially-implements: blueprint l3-svcs-vendor-validation\n\nChange-Id: I20e8a36085a7192fd80a737ede4283bf058690e9\n'}]",14,96946,770568182c69f42cf8f2a8263fa3a711343e4dd4,94,19,6,6659,,,0,"VPNaaS: Allow vendor extend/override valiadation

Extracts out validation for resources into separate methods and
allows service driver to optionally override or extend the
validation logic.

This gives different providers the ability to alter the validation,
based on thier capabilities, which may differ from the reference
implementation.

The validation is performed during the database transaction, to
ensure consistency, when there are simultaneous requests from
multiple clients.

This WIP just updates two of the resources (VPN service, and IPSec
site to site connection), but does so for both the reference and
Cisco implementations, so that we can see how it would work when
there are different validations done. For the actual commit, we
can break this into parts.

The goal here is to get community feedback on the approach, to see
if this is the ""right"" method, and then apply it for all L3
services. So, I'm looking for feedback on the approach and not
nit-pick items.

Note: The longer term solution may involve using TaskFlow,
however, even with that, we need the ability to override and
extend validation. This change will be useful in moving in that
direction.

Questions: Should we apply this only to resources that already
have multiple implementations (on an as needed basis), or on
all resources that currently have validation?

Should the corresponding validation related exceptions be moved
from the extension file to the validation module? I'm thinking so.

Partially-implements: blueprint l3-svcs-vendor-validation

Change-Id: I20e8a36085a7192fd80a737ede4283bf058690e9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/96946/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/db/vpn/vpn_db.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py']",5,d8c75f5caa9bc2e517af5237e97ae36afd79735c,bp/l3-svcs-vendor-validation,"from neutron import context as n_ctx from neutron.db import l3_db from neutron.extensions import vpnaasFAKE_SERVICE_ID = _uuid() FAKE_VPN_CONNECTION = { 'vpnservice_id': FAKE_SERVICE_ID } FAKE_ROUTER_ID = _uuid() FAKE_VPN_SERVICE = { 'router_id': FAKE_ROUTER_IDFAKE_ROUTER = {l3_db.EXTERNAL_GW_INFO: FAKE_ROUTER_ID} FAKE_SUBNET_ID = _uuid() IPV4 = 4 IPV6 = 6 class TestIPsecDriverValidation(base.BaseTestCase): def setUp(self): super(TestIPsecDriverValidation, self).setUp() mock.patch('neutron.openstack.common.rpc.create_connection').start() self.l3_plugin = mock.Mock() mock.patch( 'neutron.manager.NeutronManager.get_service_plugins', return_value={constants.L3_ROUTER_NAT: self.l3_plugin}).start() self.core_plugin = mock.Mock() mock.patch('neutron.manager.NeutronManager.get_plugin', return_value=self.core_plugin).start() self.service_plugin = mock.Mock() self.driver = ipsec_driver.IPsecVPNDriver(self.service_plugin) self.context = n_ctx.Context('some_user', 'some_tenant') def test_non_public_router_for_vpn_service(self): """"""Failure test of service validate, when router missing ext. I/F."""""" self.l3_plugin.get_router.return_value = {} # No external gateway vpnservice = {'router_id': 123, 'subnet_id': 456} self.assertRaises(vpnaas.RouterIsNotExternal, self.driver.validate_vpnservice, self.context, vpnservice) def test_subnet_not_connected_for_vpn_service(self): """"""Failure test of service validate, when subnet not on router."""""" self.l3_plugin.get_router.return_value = FAKE_ROUTER self.core_plugin.get_ports.return_value = None vpnservice = {'router_id': FAKE_ROUTER_ID, 'subnet_id': FAKE_SUBNET_ID} self.assertRaises(vpnaas.SubnetIsNotConnectedToRouter, self.driver.validate_vpnservice, self.context, vpnservice) def test_validate_create_using_defaults(self): """"""Check IPSec conn. create validation using defaults. Note: MTU has a default and will always be present on create. However, the DPD settings do not have a default, so the database create method will assign default values for any missing. These defaults are provided to the validate function. """""" ipsec_sitecon = {'mtu': 1500, 'vpnservice_id': FAKE_SERVICE_ID} defaults = {'dpd_action': 'hold', 'dpd_interval': 30, 'dpd_timeout': 120} self.driver.validate_ipsec_site_connection( self.context, ipsec_sitecon, defaults, IPV4) expected = { 'mtu': 1500, 'vpnservice_id': FAKE_SERVICE_ID, 'dpd_action': 'hold', 'dpd_timeout': 120, 'dpd_interval': 30 } self.assertEqual(expected, ipsec_sitecon) def test_bad_dpd_settings_on_create(self): """"""Failure tests of DPD settings for IPSec conn during create."""""" ipsec_sitecon = {'mtu': 1500, 'dpd': {'interval': 100, 'timeout': 100}, 'vpnservice_id': FAKE_SERVICE_ID} defaults = {'dpd_action': 'hold', 'dpd_interval': 30, 'dpd_timeout': 120} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.driver.validate_ipsec_site_connection, self.context, ipsec_sitecon, defaults, IPV4) ipsec_sitecon = {'mtu': 1500, 'dpd': {'interval': 100, 'timeout': 99}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.driver.validate_ipsec_site_connection, self.context, ipsec_sitecon, defaults, IPV4) def test_bad_dpd_settings_on_update(self): """"""Failure tests of DPD settings for IPSec conn. during update. On an update, the user may specify only some of the DPD settings. The validation will check the values provided, and will use the existing (previous) settings, for any that are not provided. Note: The MTU may not be provided, during validation and will be ignored, if that is the case. """""" previous = {'dpd_action': 'hold', 'dpd_interval': 100, 'dpd_timeout': 120} ipsec_sitecon = {'dpd': {'interval': 120}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.driver.validate_ipsec_site_connection, self.context, ipsec_sitecon, previous, IPV4) ipsec_sitecon = {'dpd': {'timeout': 99}, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises(vpnaas.IPsecSiteConnectionDpdIntervalValueError, self.driver.validate_ipsec_site_connection, self.context, ipsec_sitecon, previous, IPV4) def test_bad_mtu_for_ipsec_connection(self): """"""Failure test of invalid MTU values for IPSec conn create/update."""""" defaults = {'dpd_action': 'hold', 'dpd_interval': 30, 'dpd_timeout': 120} for version, limit in ipsec_driver.IPsecVPNDriver.IP_MIN_MTU.items(): ipsec_sitecon = {'mtu': limit - 1, 'vpnservice_id': FAKE_SERVICE_ID} self.assertRaises( vpnaas.IPsecSiteConnectionMtuError, self.driver.validate_ipsec_site_connection, self.context, ipsec_sitecon, defaults, version) ctxt = n_ctx.Context('', 'somebody')","from neutron import contextFAKE_VPN_CONNECTION = { 'vpnservice_id': _uuid() } FAKE_VPN_SERVICE = { 'router_id': _uuid() ctxt = context.Context('', 'somebody')",269,116
openstack%2Fsolum~master~Iff4b776c574374c37d561058f73ffcee1f09a4f8,openstack/solum,master,Iff4b776c574374c37d561058f73ffcee1f09a4f8,docker-py can't be added to reg requirements.txt,ABANDONED,2014-06-23 20:17:49.000000000,2014-06-24 21:13:57.000000000,,"[{'_account_id': 3}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-23 20:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b0dc2737297ba613d255e6f190e35a7ca5125d1c', 'message': ""docker-py can't be added to reg requirements.txt do to oslo restrictions\n\nthis will allow us to install/access it in a controlled method\n\nChange-Id: Iff4b776c574374c37d561058f73ffcee1f09a4f8\n""}, {'number': 2, 'created': '2014-06-23 20:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/de36a375b0c938e004e834554a1d6fb2f65550b1', 'message': ""docker-py can't be added to reg requirements.txt do to oslo restrictions\n\nthis will allow us to install/access it in a controlled method\n\nsee https://review.openstack.org/#/c/76535/ for context\non oslo restrictions.\n\nChange-Id: Iff4b776c574374c37d561058f73ffcee1f09a4f8\n""}, {'number': 3, 'created': '2014-06-24 15:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/84d7bd533146445567b87d5650d06ded482c06e2', 'message': ""docker-py can't be added to reg requirements.txt\ndue to oslo restrictions\n\nthis will allow us to install/access it in a controlled method\n\nsee https://review.openstack.org/#/c/76535/ for context\non oslo restrictions.\n\nChange-Id: Iff4b776c574374c37d561058f73ffcee1f09a4f8\n""}, {'number': 4, 'created': '2014-06-24 15:05:08.000000000', 'files': ['contrib/devstack/lib/solum', 'contrib/docker/requirements.txt', 'contrib/devstack/extras.d/70-solum.sh'], 'web_link': 'https://opendev.org/openstack/solum/commit/f37672803d34a14626e15c9c15f4fa3284d2b249', 'message': ""docker-py can't be added to reg requirements.txt\n\ndue to oslo restrictions\n\nthis will allow us to install/access it in a controlled method\n\nsee https://review.openstack.org/#/c/76535/ for context\non oslo restrictions.\n\nChange-Id: Iff4b776c574374c37d561058f73ffcee1f09a4f8\n""}]",1,101997,f37672803d34a14626e15c9c15f4fa3284d2b249,14,4,4,7858,,,0,"docker-py can't be added to reg requirements.txt

due to oslo restrictions

this will allow us to install/access it in a controlled method

see https://review.openstack.org/#/c/76535/ for context
on oslo restrictions.

Change-Id: Iff4b776c574374c37d561058f73ffcee1f09a4f8
",git fetch https://review.opendev.org/openstack/solum refs/changes/97/101997/4 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/lib/solum', 'contrib/docker/requirements.txt', 'contrib/devstack/extras.d/70-solum.sh']",3,b0dc2737297ba613d255e6f190e35a7ca5125d1c,dockerpy, install_dockerpy,,7,0
openstack%2Ftripleo-image-elements~master~Ic85779aa06f1331c0c73a83a874a38c806bd6ad4,openstack/tripleo-image-elements,master,Ic85779aa06f1331c0c73a83a874a38c806bd6ad4,Check if stunnel.connect_ip is set,MERGED,2014-06-24 10:29:52.000000000,2014-06-24 21:06:10.000000000,2014-06-24 21:06:09.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-06-24 10:29:52.000000000', 'files': ['elements/horizon/files/ports.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fe98bb682d25e2cda40fcb2cc4ad99ed9008f290', 'message': 'Check if stunnel.connect_ip is set\n\nWe already define stunnel metadata, but stunnel.connect_ip is not yet\ndefined. In such case empty IP is generated in ports.conf which causes\nsyntax error.\n\nChange-Id: Ic85779aa06f1331c0c73a83a874a38c806bd6ad4\n'}]",0,102177,fe98bb682d25e2cda40fcb2cc4ad99ed9008f290,16,3,1,7582,,,0,"Check if stunnel.connect_ip is set

We already define stunnel metadata, but stunnel.connect_ip is not yet
defined. In such case empty IP is generated in ports.conf which causes
syntax error.

Change-Id: Ic85779aa06f1331c0c73a83a874a38c806bd6ad4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/77/102177/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/horizon/files/ports.conf'],1,fe98bb682d25e2cda40fcb2cc4ad99ed9008f290,horizon,{{#stunnel.connect_ip}}{{/stunnel.connect_ip}} {{^stunnel.connect_ip}}{{/stunnel.connect_ip}}{{/haproxy}} ,{{#stunnel}}{{/stunnel}} {{^stunnel}}{{/stunnel}}{{/haproxy}},5,5
openstack%2Fpython-openstackclient~master~I7fe831a8c401554f0d3e2a020aeedb52613055d3,openstack/python-openstackclient,master,I7fe831a8c401554f0d3e2a020aeedb52613055d3,Add the argparse module dependency,ABANDONED,2014-06-24 19:50:29.000000000,2014-06-24 20:57:11.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6482}, {'_account_id': 9536}]","[{'number': 1, 'created': '2014-06-24 19:50:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2fc983e5e7aeb67316376896eb9ed421d6709361', 'message': 'Add the argparse module dependency\n\nCloses-Bug #1333949\n\nChange-Id: I7fe831a8c401554f0d3e2a020aeedb52613055d3\n'}]",0,102330,2fc983e5e7aeb67316376896eb9ed421d6709361,7,4,1,9536,,,0,"Add the argparse module dependency

Closes-Bug #1333949

Change-Id: I7fe831a8c401554f0d3e2a020aeedb52613055d3
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/30/102330/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2fc983e5e7aeb67316376896eb9ed421d6709361,bug/1333949,argparse,,1,0
openstack%2Fdesignate~master~I645b380e2980f413ca62e2c8869951b0f0bf2c52,openstack/designate,master,I645b380e2980f413ca62e2c8869951b0f0bf2c52,Fixes default content type on /v2/zones endpoint,MERGED,2014-06-23 15:14:25.000000000,2014-06-24 20:53:42.000000000,2014-06-24 20:53:42.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-06-23 15:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bc45b58cb44e60bcc6b36ab25e714d22f045cdbe', 'message': 'Fixes default content type on /v2/zones endpoint\n\nChange-Id: I645b380e2980f413ca62e2c8869951b0f0bf2c52\nCloses-Bug: #1333312\n'}, {'number': 2, 'created': '2014-06-23 21:01:19.000000000', 'files': ['designate/api/v2/controllers/zones.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/aa035dc73b387d2c9979e6b83ef22c64a5740b6b', 'message': 'Fixes default content type on /v2/zones endpoint\n\nChange-Id: I645b380e2980f413ca62e2c8869951b0f0bf2c52\nCloses-Bug: #1333312\n'}]",2,101929,aa035dc73b387d2c9979e6b83ef22c64a5740b6b,13,4,2,8099,,,0,"Fixes default content type on /v2/zones endpoint

Change-Id: I645b380e2980f413ca62e2c8869951b0f0bf2c52
Closes-Bug: #1333312
",git fetch https://review.opendev.org/openstack/designate refs/changes/29/101929/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/v2/controllers/zones.py'],1,bc45b58cb44e60bcc6b36ab25e714d22f045cdbe,bug/1333312," @pecan.expose(template=None, content_type='text/dns') best_match = request.accept.best_match(['application/json', 'text/dns']) LOG.warn(""Best Match: %s"", best_match)"," @pecan.expose(template=None, content_type='text/dns') best_match = request.accept.best_match(['text/dns', 'application/json'])",4,3
openstack%2Fopenstack-manuals~master~Ic79a452044c32d7decd4ee944ba73f74dcd770eb,openstack/openstack-manuals,master,Ic79a452044c32d7decd4ee944ba73f74dcd770eb,Add Japanese OPS Guide to draft-i18n-manuals,MERGED,2014-06-24 05:03:15.000000000,2014-06-24 20:51:53.000000000,2014-06-24 20:51:53.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 05:03:15.000000000', 'files': ['www/draft-i18n-manuals.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b476b1dc626008ad1088d5c10139c0215b372c45', 'message': ""Add Japanese OPS Guide to draft-i18n-manuals\n\nAdd Japanese OPS Guide, it's not referenced anywhere else.\n\nChange-Id: Ic79a452044c32d7decd4ee944ba73f74dcd770eb\n""}]",0,102102,b476b1dc626008ad1088d5c10139c0215b372c45,8,3,1,6547,,,0,"Add Japanese OPS Guide to draft-i18n-manuals

Add Japanese OPS Guide, it's not referenced anywhere else.

Change-Id: Ic79a452044c32d7decd4ee944ba73f74dcd770eb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/102102/1 && git format-patch -1 --stdout FETCH_HEAD,['www/draft-i18n-manuals.html'],1,b476b1dc626008ad1088d5c10139c0215b372c45,ops-ja-draft," Japanese </a> </li> </ul> <dl> <dd> <a href=""http://docs.openstack.org/ja/openstack-ops/content/""> Operations Guide </a> </dd> </dl> </div> <ul class=""subsectionNav""> <li class=""link""> <a>",,15,0
openstack%2Fopenstack-doc-tools~master~I8a5885022b66f17ddf113199b4a900f10581c748,openstack/openstack-doc-tools,master,I8a5885022b66f17ddf113199b4a900f10581c748,Update README.rst with recent changes,MERGED,2014-06-24 07:18:58.000000000,2014-06-24 20:48:38.000000000,2014-06-24 20:48:38.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 07:18:58.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/fd7a735827c0319718a4458602b02bbc20e5b266', 'message': 'Update README.rst with recent changes\n\nUpdate release notes for 0.16.\n\nChange-Id: I8a5885022b66f17ddf113199b4a900f10581c748\n'}]",0,102123,fd7a735827c0319718a4458602b02bbc20e5b266,8,3,1,6547,,,0,"Update README.rst with recent changes

Update release notes for 0.16.

Change-Id: I8a5885022b66f17ddf113199b4a900f10581c748
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/23/102123/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,fd7a735827c0319718a4458602b02bbc20e5b266,README," environment.* ``autohelp.py``: Add the 'dump' subcommand, include swift. * ``jsoncheck.py``: Add public API. * Added tool to generate a sitemap.xml file. * Added script to prettify HTML and XML syntax.", environment* ``autohelp.py``: add the 'dump' subcommand * ``jsoncheck.py``: add public API,5,3
openstack%2Fdesignate~master~I791e54fb3ff00908aa7eaa935f1e91e0dba879ab,openstack/designate,master,I791e54fb3ff00908aa7eaa935f1e91e0dba879ab,"Added all fields to limits endpoint, and corrected casing",MERGED,2014-06-23 15:26:04.000000000,2014-06-24 20:48:28.000000000,2014-06-24 20:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2014-06-23 15:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4ffdeb0a0abb007c65c5116b3c6d0142a5f38c86', 'message': 'Added all fields to limits endpoint, and corrected casing\n\nChange-Id: I791e54fb3ff00908aa7eaa935f1e91e0dba879ab\n'}, {'number': 2, 'created': '2014-06-23 21:09:45.000000000', 'files': ['designate/api/v2/views/limits.py', 'designate/tests/test_api/test_v2/test_limits.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/eb9f8d584ec544e36664228b84ff5b1d191b786c', 'message': 'Added all fields to limits endpoint, and corrected casing\n\nChange-Id: I791e54fb3ff00908aa7eaa935f1e91e0dba879ab\n'}]",0,101935,eb9f8d584ec544e36664228b84ff5b1d191b786c,15,5,2,8099,,,0,"Added all fields to limits endpoint, and corrected casing

Change-Id: I791e54fb3ff00908aa7eaa935f1e91e0dba879ab
",git fetch https://review.opendev.org/openstack/designate refs/changes/35/101935/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/v2/views/limits.py'],1,4ffdeb0a0abb007c65c5116b3c6d0142a5f38c86,fix-limits-api," ""max_zones"": absolute_limits['domains'], ""max_zone_recordsets"": absolute_limits['domain_recordsets'], ""max_zone_records"": absolute_limits['domain_records'], ""max_recordset_records"": absolute_limits['recordset_records']"," ""maxZones"": absolute_limits['domains'], ""maxZoneRecords"": absolute_limits['domain_records']",4,2
openstack%2Fironic-python-agent~master~Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd,openstack/ironic-python-agent,master,Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd,Better errors for execute() failures,MERGED,2014-06-12 13:50:44.000000000,2014-06-24 20:47:23.000000000,2014-06-24 20:47:22.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-06-12 13:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ebc025358deedf6cbb53aafcb5c988018a0f13b0', 'message': 'Better errors for execute() failures\n\nExceptions raised due to processutils.execute() failing now include\nstdout and stderr.\n\nChange-Id: Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd\n'}, {'number': 2, 'created': '2014-06-12 13:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7e884121cf2211a1eb29be751bf35079590f7855', 'message': 'Better errors for execute() failures\n\nExceptions raised due to processutils.execute() failing now include\nstdout and stderr.\n\nChange-Id: Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd\n'}, {'number': 3, 'created': '2014-06-24 13:51:10.000000000', 'files': ['ironic_python_agent/extensions/standby.py', 'ironic_python_agent/errors.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c5df7070af638c5aaf4d6d2ab626475cc3610c0b', 'message': 'Better errors for execute() failures\n\nExceptions raised due to processutils.execute() failing now include\nstdout and stderr.\n\nChange-Id: Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd\n'}]",2,99666,c5df7070af638c5aaf4d6d2ab626475cc3610c0b,20,4,3,10343,,,0,"Better errors for execute() failures

Exceptions raised due to processutils.execute() failing now include
stdout and stderr.

Change-Id: Id5d1b5bc51d377f9f3c338cd7303ea800f76e5cd
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/66/99666/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/extensions/standby.py', 'ironic_python_agent/errors.py']",2,ebc025358deedf6cbb53aafcb5c988018a0f13b0,fix-processutils-usage," def __init__(self, device, exit_code, stdout, stderr): self.details = ('Writing image to device {0} failed with exit code ' '{1}. stdout: {2}. stderr: {3}') self.details = self.details.format(device, exit_code, stdout, stderr) def __init__(self, device, exit_code, stdout, stderr): '{1}. stdout: {2}. stderr: {3}.' details = details.format(device, exit_code, stdout, stderr) def __init__(self, exit_code, stdout, stderr): self.details = ('Reboot script failed with exit code {0}. stdout: ' '{1}. stderr: {2}.') self.details = self.details.format(exit_code, stdout, stderr)"," def __init__(self, exit_code, device): self.details = 'Writing image to device {0} failed with exit code {1}.' self.details = self.details.format(device, exit_code) def __init__(self, exit_code, device): '{1}.' details = details.format(device, exit_code) def __init__(self, exit_code): self.details = 'Reboot script failed with exit code {0}.' self.details = self.details.format(exit_code)",17,12
openstack%2Fzaqar~master~I856f68f93251881aab1690dc337b697c211f99fa,openstack/zaqar,master,I856f68f93251881aab1690dc337b697c211f99fa,Updated from global requirements,MERGED,2014-06-24 07:21:30.000000000,2014-06-24 20:44:03.000000000,2014-06-24 20:44:02.000000000,"[{'_account_id': 3}, {'_account_id': 6427}, {'_account_id': 7498}, {'_account_id': 8092}]","[{'number': 1, 'created': '2014-06-24 07:21:30.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/737db0b99201029e02040ba5e132585846124942', 'message': 'Updated from global requirements\n\nChange-Id: I856f68f93251881aab1690dc337b697c211f99fa\n'}]",0,102127,737db0b99201029e02040ba5e132585846124942,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I856f68f93251881aab1690dc337b697c211f99fa
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/27/102127/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,737db0b99201029e02040ba5e132585846124942,openstack/requirements,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",2,2
openstack%2Fpython-heatclient~master~Ief1742fb2222b3e363318a5c790bca3fe59252f5,openstack/python-heatclient,master,Ief1742fb2222b3e363318a5c790bca3fe59252f5,The updated version of the six module in heatclient,ABANDONED,2014-06-24 18:51:10.000000000,2014-06-24 20:38:49.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-06-24 18:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a24b577e7d61a617edf2b5093d8eee8ce81f8d4a', 'message': 'The updated version of the six module in heatclient\n\nChange-Id: Ief1742fb2222b3e363318a5c790bca3fe59252f5\nCloses-Bug: #1333882\n'}, {'number': 2, 'created': '2014-06-24 19:23:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/95f4f65346914c2a5dc5d4527e363cd716fcc7fe', 'message': 'The updated version of the six module in heatclient\n\nChange-Id: Ief1742fb2222b3e363318a5c790bca3fe59252f5\nCloses-Bug: #1333882\n'}]",0,102320,95f4f65346914c2a5dc5d4527e363cd716fcc7fe,8,3,2,9536,,,0,"The updated version of the six module in heatclient

Change-Id: Ief1742fb2222b3e363318a5c790bca3fe59252f5
Closes-Bug: #1333882
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/20/102320/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a24b577e7d61a617edf2b5093d8eee8ce81f8d4a,Bug1333882,six>=1.6.0,six>=1.5.2,1,1
openstack%2Ftripleo-image-elements~master~I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3,openstack/tripleo-image-elements,master,I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3,Add keepalive option to rabbitmq config,MERGED,2014-03-20 21:09:40.000000000,2014-06-24 20:33:46.000000000,2014-06-24 20:33:46.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 1605}, {'_account_id': 1865}, {'_account_id': 4190}, {'_account_id': 6969}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8688}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-03-20 21:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/523d3de13e5ea18e61bde8a8163c80db09a9ce4a', 'message': 'WIP - Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 2, 'created': '2014-03-21 17:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e533eaf55f482fe04bd3f84843fc7500d5f7b74e', 'message': 'WIP - Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 3, 'created': '2014-03-21 18:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2f8a059312590f7d4697dda7d988d05d0dcc69dc', 'message': 'WIP - Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 4, 'created': '2014-03-24 15:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bd34033ad40513b3a04dc5ece08b8148f4117df3', 'message': 'WIP - Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 5, 'created': '2014-03-25 11:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d93b4a8fa25294a727cbfcf5b8e402fb8864ec58', 'message': 'WIP - Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 6, 'created': '2014-03-25 12:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f4557182504ecbca2940e857e7343cddcbcc1b86', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 7, 'created': '2014-03-25 16:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5a96ddffbdc65dc4e6c137286b0118930bcdf5d2', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 8, 'created': '2014-03-26 09:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0aeb8fb58330361a8be026e7a1f9eababd9be5ce', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 9, 'created': '2014-04-01 23:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ead217a26b4ae3de0a26fda9f64a7f0437d3cdbe', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 10, 'created': '2014-04-03 23:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9238986c0bc7f2b23ed7fd3f89120e67aa0ef361', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 11, 'created': '2014-04-07 09:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/98797db751d3c2aaca5155cb1f0bccfd535b6fcd', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 12, 'created': '2014-04-07 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5904ef54bc1dcd858d569a134201bc1f781fab84', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nCorresponding heat-template change: https://review.openstack.org/#/c/81934/\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 13, 'created': '2014-04-09 10:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/909ece80c182176c6bd5e9307038e367e51450fb', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nCorresponding heat-template change: https://review.openstack.org/#/c/81934/\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 14, 'created': '2014-04-09 10:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f4035084b0858f51fa7588fe261ce986a965ec04', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\n\nCorresponding heat-template change: https://review.openstack.org/#/c/81934/\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 15, 'created': '2014-04-09 10:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9728d7b3f142306659dd7205637a4f2a74ef9fb0', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\nThis instructs rabbitmq to apply keepalive to its sockets, based on the\nglobal keepalive settings, which can be configured in the network-conf element\nprosed in: https://review.openstack.org/#/c/86277/\n\nCorresponding heat-template change: https://review.openstack.org/#/c/81934/\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 16, 'created': '2014-04-10 13:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/144eeeecefbf24cb7f6e0f424c0761493bc9807d', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\nThis instructs rabbitmq to apply keepalive to its sockets, based on the\nglobal keepalive settings, which can be configured in the network-conf element\nprosed in: Ia3371e9055cb7451f84f129be36a93b6b6c0d3a7\n\nCorresponding heat-template change: Iddae322e6fc4241ef0889e8296481e05b26df2eb\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 17, 'created': '2014-06-06 14:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/caeccbd2737048c0afed0f1b2f54ffc551960a79', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\nThis instructs rabbitmq to apply keepalive to its sockets, based on the\nglobal keepalive settings, which can be configured via the sysctl\nelement.\n\nCorresponding heat-template change: Iddae322e6fc4241ef0889e8296481e05b26df2eb\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 18, 'created': '2014-06-09 15:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e521f356b8426d101231a0eaebdc041d3c9d6f99', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\nThis instructs rabbitmq to apply keepalive to its sockets, based on the\nglobal keepalive settings, which can be configured via the sysctl\nelement.\n\nCorresponding heat-template change: Iddae322e6fc4241ef0889e8296481e05b26df2eb\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}, {'number': 19, 'created': '2014-06-13 08:22:17.000000000', 'files': ['elements/rabbitmq-server/os-config-applier/etc/rabbitmq/rabbitmq.config', 'elements/rabbitmq-server/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7c397acafdb356924ec11fc8f4e6e7b060b0c4ed', 'message': 'Add keepalive option to rabbitmq config\n\nAdd keepalive and other socket options to the rabbitmq config.\nThis instructs rabbitmq to apply keepalive to its sockets, based on the\nglobal keepalive settings, which can be configured via the sysctl\nelement.\n\nDefault is for rabbitmq keepalive to be enabled.\n\nChange-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3\n'}]",39,81920,7c397acafdb356924ec11fc8f4e6e7b060b0c4ed,142,10,19,1605,,,0,"Add keepalive option to rabbitmq config

Add keepalive and other socket options to the rabbitmq config.
This instructs rabbitmq to apply keepalive to its sockets, based on the
global keepalive settings, which can be configured via the sysctl
element.

Default is for rabbitmq keepalive to be enabled.

Change-Id: I4fa26f9cab0ecfe39698a3ef5ac440e2892450d3
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/20/81920/19 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rabbitmq-server/os-config-applier/etc/rabbitmq/rabbitmq.config', 'elements/rabbitmq-server/os-refresh-config/post-configure.d/30-rabbitmq-keepalive', 'elements/rabbitmq-server/os-config-applier/etc/sysctl.d/30-rabbitmq-keepalive.conf']",3,523d3de13e5ea18e61bde8a8163c80db09a9ce4a,rabbitmq-keepalive,{{#rabbit.keepalive}} net.ipv4.tcp_keepalive_probes = {{rabbit.keepalive.probes}} net.ipv4.tcp_keepalive_intvl = {{rabbit.keepalive.interval}} net.ipv4.tcp_keepalive_time = {{rabbit.keepalive.time}} {{/rabbit.keepalive}} ,,20,1
openstack%2Fkeystone~master~I69d1ef4e788a58e3f15104ff9083cf5a4c8dc761,openstack/keystone,master,I69d1ef4e788a58e3f15104ff9083cf5a4c8dc761,"the user_tenant_membership table was replaced by ""assignment""",MERGED,2014-06-24 15:07:59.000000000,2014-06-24 20:26:54.000000000,2014-06-24 20:26:53.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-24 15:07:59.000000000', 'files': ['keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bd59cb32c8798875773bcdb5caf607ff43099804', 'message': 'the user_tenant_membership table was replaced by ""assignment""\n\nThis updates some help text to reference the new assignment table rather\nthan the old table.\n\nChange-Id: I69d1ef4e788a58e3f15104ff9083cf5a4c8dc761\n'}]",0,102266,bd59cb32c8798875773bcdb5caf607ff43099804,9,4,1,4,,,0,"the user_tenant_membership table was replaced by ""assignment""

This updates some help text to reference the new assignment table rather
than the old table.

Change-Id: I69d1ef4e788a58e3f15104ff9083cf5a4c8dc761
",git fetch https://review.opendev.org/openstack/keystone refs/changes/66/102266/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/config.py'],1,bd59cb32c8798875773bcdb5caf607ff43099804,(detached," 'the assignment table with explicit role grants. ' 'After migration, the member_role_id will be used in ' 'the API add_user_to_project.'), 'the assignment table with explicit role grants. ' 'After migration, member_role_name will be ignored.'),"," 'the user_tenant_membership table with explicit ' 'role grants. After migration, the member_role_id ' 'will be used in the API add_user_to_project.'), 'the user_tenant_membership table with explicit ' 'role grants. After migration, member_role_name will ' 'be ignored.'),",5,6
openstack%2Fcookbook-openstack-identity~master~Ifb77c999854d6d6648dd39443409f2ae2593033f,openstack/cookbook-openstack-identity,master,Ifb77c999854d6d6648dd39443409f2ae2593033f,use new python_packages attributes from -common,MERGED,2014-06-17 16:17:08.000000000,2014-06-24 20:21:39.000000000,2014-06-24 20:21:39.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-17 16:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/49b6c43eb6f3dfbce5165b62bbbc4624b41df62b', 'message': 'use new python_packages attributes from -common\n\n*_python_packages attributes are being moved to -common in order to\n remove the duplication from all the cookbooks which are using them\n\n Implements: blueprint move-python-db-client-attrs-to-common\n\nChange-Id: Ifb77c999854d6d6648dd39443409f2ae2593033f\n'}, {'number': 2, 'created': '2014-06-17 16:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/70babdd8179797c0375544d36ff60086786514d0', 'message': 'use new python_packages attributes from -common\n\n*_python_packages attributes are being moved to -common in order to\n remove the duplication from all the cookbooks which are using them\n\n Implements: blueprint move-python-db-client-attrs-to-common\n\nChange-Id: Ifb77c999854d6d6648dd39443409f2ae2593033f\n'}, {'number': 3, 'created': '2014-06-20 07:38:20.000000000', 'files': ['attributes/default.rb', 'CHANGELOG.md', 'metadata.rb', 'README.md', 'recipes/server.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/03ccba7081d8d7befc9054200b7371a45289fc66', 'message': 'use new python_packages attributes from -common\n\n*_python_packages attributes are being moved to -common in order to\n remove the duplication from all the cookbooks which are using them\n\n Implements: blueprint move-python-db-client-attrs-to-common\n\nChange-Id: Ifb77c999854d6d6648dd39443409f2ae2593033f\n'}]",1,100614,03ccba7081d8d7befc9054200b7371a45289fc66,24,6,3,2340,,,0,"use new python_packages attributes from -common

*_python_packages attributes are being moved to -common in order to
 remove the duplication from all the cookbooks which are using them

 Implements: blueprint move-python-db-client-attrs-to-common

Change-Id: Ifb77c999854d6d6648dd39443409f2ae2593033f
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/14/100614/2 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'recipes/server.rb']",2,49b6c43eb6f3dfbce5165b62bbbc4624b41df62b,bp/move-python-db-client-attrs-to-common, node['openstack']['db']['python_packages'][db_type].each do |pkg|," platform_options[""#{db_type}_python_packages""].each do |pkg|",1,8
openstack%2Fcookbook-openstack-common~master~I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc,openstack/cookbook-openstack-common,master,I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc,allow for attribute storage of secrets as an alternative,MERGED,2014-06-18 11:50:45.000000000,2014-06-24 20:19:28.000000000,2014-06-24 20:19:27.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-18 11:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/395a53815476f2876e67b827a4009f5952beda13', 'message': ""allow for attribute storage of secrets as an alternative\n\nIn addition to storing secrets in data bags (the default) we would like to be able to store them in attributes.\n\nThis commit doesn't change the existing passwords API, get_password will\nnow read from attributes when the node['openstack']['use_databags']\nattribute is falsy.\n\nThis commit deprecates the development_mode which was only used as a hack for getting passwords easier without data bags. The attribute storage of passwords should now be sufficient for all those use cases.\n\nChange-Id: I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc\n""}, {'number': 2, 'created': '2014-06-18 12:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/bccd7ed4dbe8aaab19e8551243675f094843ffad', 'message': ""allow for attribute storage of secrets as an alternative\n\nIn addition to storing secrets in data bags (the default) we would like\nto be able to store them in attributes.\n\nThis commit doesn't change the existing passwords API, get_password will\nnow read from attributes when the node['openstack']['use_databags']\nattribute is falsy.\n\nThis commit deprecates the development_mode which was only used as a\nhack for getting passwords easier without data bags. The attribute\nstorage of passwords should now be sufficient for all those use cases.\n\nIncreased rubocop's methodlength maximum to 15 because there are some\ntemporary deprecation warnings which add up, but should go away soon.\n\nChange-Id: I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc\n""}, {'number': 3, 'created': '2014-06-18 12:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/5f0ae31ffe60be1ff6e0a8567c35ba03f2e3869b', 'message': ""allow for attribute storage of secrets as an alternative\n\nIn addition to storing secrets in data bags (the default) we would like\nto be able to store them in attributes.\n\nThis commit doesn't change the existing passwords API, get_password will\nnow read from attributes when the node['openstack']['use_databags']\nattribute is falsy.\n\nThis commit deprecates the development_mode which was only used as a\nhack for getting passwords easier without data bags. The attribute\nstorage of passwords should now be sufficient for all those use cases.\n\nIncreased rubocop's methodlength maximum to 15 because there are some\ntemporary deprecation warnings which add up, but should go away soon.\n\nChange-Id: I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc\n""}, {'number': 4, 'created': '2014-06-20 11:36:33.000000000', 'files': ['attributes/default.rb', 'libraries/passwords.rb', '.rubocop.yml', 'CHANGELOG.md', 'metadata.rb', 'spec/password_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/dbe0bd6818002f13a5af947b76ff90324f2ecc08', 'message': ""allow for attribute storage of secrets as an alternative\n\nIn addition to storing secrets in data bags (the default) we would like\nto be able to store them in attributes.\n\nThis commit doesn't change the existing passwords API, get_password will\nnow read from attributes when the node['openstack']['use_databags']\nattribute is falsy.\n\nThis commit deprecates the development_mode which was only used as a\nhack for getting passwords easier without data bags. The attribute\nstorage of passwords should now be sufficient for all those use cases.\n\nIncreased rubocop's methodlength maximum to 15 because there are some\ntemporary deprecation warnings which add up, but should go away soon.\n\nChange-Id: I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc\n""}]",4,100867,dbe0bd6818002f13a5af947b76ff90324f2ecc08,29,6,4,2340,,,0,"allow for attribute storage of secrets as an alternative

In addition to storing secrets in data bags (the default) we would like
to be able to store them in attributes.

This commit doesn't change the existing passwords API, get_password will
now read from attributes when the node['openstack']['use_databags']
attribute is falsy.

This commit deprecates the development_mode which was only used as a
hack for getting passwords easier without data bags. The attribute
storage of passwords should now be sufficient for all those use cases.

Increased rubocop's methodlength maximum to 15 because there are some
temporary deprecation warnings which add up, but should go away soon.

Change-Id: I1f23878dd3fa83fb40f7b4b56960d57a7b9b89cc
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/67/100867/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'libraries/passwords.rb', 'CHANGELOG.md', 'metadata.rb', 'spec/password_spec.rb']",5,395a53815476f2876e67b827a4009f5952beda13,passwords-attrs," context 'stored in data bags by default' do describe '#secret' do it 'returns databag' do ::Chef::EncryptedDataBagItem.stub(:load).with('passwords', 'nova', 'secret').and_return(value) expect(subject.secret('passwords', 'nova')).to eq('this') end end describe '#get_secret' do it 'returns databag value' do value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with('secrets', 'nova', 'secret').and_return(value) expect(subject.get_secret('nova')).to eq('this') end it 'returns secret from an alternate databag when secrets_data_bag set' do node.set['openstack']['secret']['secrets_data_bag'] = 'myothersecrets' value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with('myothersecrets', 'nova', 'secret').and_return(value) expect(subject.get_secret('nova')).to eq('this') end end describe '#get_password' do ['service', 'db', 'user'].each do |type| it ""returns databag value for #{type}"" do value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with(""#{type}_passwords"", 'nova', 'secret').and_return(value) expect(subject.get_password(type, 'nova')).to eq('this') end end it 'returns nil for an invalid type' do expect(subject.get_password('invalid_type', 'nova')).to be_nil end it 'returns tokens from the secrets_data_bag' do bag_content = {'nova' => 'this'} ::Chef::EncryptedDataBagItem.stub(:load_secret).with( '/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with( 'secrets', 'nova', 'secret').and_return(bag_content) expect(subject.get_password('token', 'nova')).to eq('this') end end end context 'stored in attributes as an alternative' do before { node.set['openstack']['use_databags'] = false } describe '#get_password' do ['service', 'db', 'user', 'token'].each do |type| it ""returns the set attribute for #{type}"" do node.set['openstack']['secret']['nova'][type] = 'very secret' expect(subject.get_password(type, 'nova')).to eq('very secret') end"," describe '#secret' do it 'returns databag' do value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with('passwords', 'nova', 'secret').and_return(value) expect(subject.secret('passwords', 'nova')).to eq('this') end end describe '#get_secret' do it 'returns databag' do value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with('secrets', 'nova', 'secret').and_return(value) expect(subject.get_secret('nova')).to eq('this') end it 'returns secret from an alternate databag when secrets_data_bag set' do node.set['openstack']['secret']['secrets_data_bag'] = 'myothersecrets' value = { 'nova' => 'this' } ::Chef::EncryptedDataBagItem.stub(:load_secret).with('/etc/chef/openstack_data_bag_secret').and_return('secret') ::Chef::EncryptedDataBagItem.stub(:load).with('myothersecrets', 'nova', 'secret').and_return(value) expect(subject.get_secret('nova')).to eq('this') end end describe '#get_password' do ['service', 'db', 'user'].each do |type| it ""returns databag for #{type}"" do ::Chef::EncryptedDataBagItem.stub(:load).with(""#{type}_passwords"", 'nova', 'secret').and_return(value) expect(subject.get_password(type, 'nova')).to eq('this')",105,40
openstack%2Fsahara~master~I0e5239e7b2856f2104130accce1555e59dfa487d,openstack/sahara,master,I0e5239e7b2856f2104130accce1555e59dfa487d,Fixed H405 pep8 style check,MERGED,2014-06-15 13:51:04.000000000,2014-06-24 20:19:00.000000000,2014-06-24 20:19:00.000000000,"[{'_account_id': 3}, {'_account_id': 5892}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-06-15 13:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1d21bb3c779964cc93f173f704fade834534d187', 'message': 'Fixed H405 pep8 style check\n\n* H405  multi line docstring summary not separated with an empty line\n\nChange-Id: I0e5239e7b2856f2104130accce1555e59dfa487d\n'}, {'number': 2, 'created': '2014-06-15 19:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/66c9a24915f35cfdcd386956fbd43cac7e1d6a22', 'message': 'Fixed H405 pep8 style check\n\n* H405  multi line docstring summary not separated with an empty line\n\nChange-Id: I0e5239e7b2856f2104130accce1555e59dfa487d\n'}, {'number': 3, 'created': '2014-06-16 04:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8fd64dcada58c999d2b926a134ec5f200a5d79fa', 'message': 'Fixed H405 pep8 style check\n\n* H405  multi line docstring summary not separated with an empty line\n\nChange-Id: I0e5239e7b2856f2104130accce1555e59dfa487d\n'}, {'number': 4, 'created': '2014-06-18 05:02:58.000000000', 'files': ['sahara/db/sqlalchemy/models.py', 'sahara/service/edp/oozie.py', 'sahara/utils/remote.py', 'sahara/db/api.py', 'sahara/plugins/spark/config_helper.py', 'sahara/plugins/vanilla/v1_2_1/config_helper.py', 'sahara/plugins/general/exceptions.py', 'sahara/context.py', 'sahara/conductor/resource.py', 'sahara/conductor/api.py', 'sahara/tests/unit/utils/test_heat.py', 'sahara/swift/utils.py', 'tox.ini', 'sahara/main.py', 'sahara/tests/unit/db/migration/test_migrations_base.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/851f8a12d970802f25cd61cb8d0abb78a6439462', 'message': 'Fixed H405 pep8 style check\n\n* H405  multi line docstring summary not separated with an empty line\n\nChange-Id: I0e5239e7b2856f2104130accce1555e59dfa487d\n'}]",4,100092,851f8a12d970802f25cd61cb8d0abb78a6439462,53,9,4,7125,,,0,"Fixed H405 pep8 style check

* H405  multi line docstring summary not separated with an empty line

Change-Id: I0e5239e7b2856f2104130accce1555e59dfa487d
",git fetch https://review.opendev.org/openstack/sahara refs/changes/92/100092/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/db/sqlalchemy/models.py', 'sahara/service/edp/oozie.py', 'sahara/utils/remote.py', 'sahara/db/api.py', 'sahara/plugins/spark/config_helper.py', 'sahara/plugins/vanilla/v1_2_1/config_helper.py', 'sahara/plugins/general/exceptions.py', 'sahara/context.py', 'sahara/conductor/resource.py', 'sahara/conductor/api.py', 'sahara/tests/unit/utils/test_heat.py', 'sahara/swift/utils.py', 'tox.ini', 'sahara/main.py', 'sahara/tests/unit/db/migration/test_migrations_base.py', 'sahara/conductor/manager.py']",16,1d21bb3c779964cc93f173f704fade834534d187,pep8-h405," """"""Get all clusters filtered by **kwargs. e.g. cluster_get_all(plugin_name='vanilla', hadoop_version='1.1') """""" """"""Get all JobExecutions filtered by **kwargs. e.g. job_execution_get_all(cluster_id=12, input_id=123) """"""Count number of JobExecutions filtered by **kwargs. e.g. job_execution_count(cluster_id=12, input_id=123)"," """"""Get all clusters filtered by **kwargs e.g. cluster_get_all(plugin_name='vanilla', hadoop_version='1.1') """""" """"""Get all JobExecutions filtered by **kwargs e.g. job_execution_get_all(cluster_id=12, input_id=123) """"""Count number of JobExecutions filtered by **kwargs e.g. job_execution_count(cluster_id=12, input_id=123)",168,130
openstack%2Ftripleo-specs~master~I744067f97563f71762d2c0ea4aa46e50e375a4a9,openstack/tripleo-specs,master,I744067f97563f71762d2c0ea4aa46e50e375a4a9,Spec for the Tuskar template generatation code,ABANDONED,2014-06-02 20:44:10.000000000,2014-06-24 19:41:08.000000000,,"[{'_account_id': 3}, {'_account_id': 7585}, {'_account_id': 8041}, {'_account_id': 8399}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-06-02 20:44:10.000000000', 'files': ['specs/juno/tripleo-juno-tuskar-template-generator.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/b7bb18a9e78dd2263066117710b4d1647bf942fc', 'message': 'Spec for the Tuskar template generatation code\n\nChange-Id: I744067f97563f71762d2c0ea4aa46e50e375a4a9\nPartial-Blueprint: tripleo-juno-tuskar-template-generator\n'}]",6,97335,b7bb18a9e78dd2263066117710b4d1647bf942fc,10,5,1,8399,,,0,"Spec for the Tuskar template generatation code

Change-Id: I744067f97563f71762d2c0ea4aa46e50e375a4a9
Partial-Blueprint: tripleo-juno-tuskar-template-generator
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/35/97335/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/tripleo-juno-tuskar-template-generator.rst'],1,b7bb18a9e78dd2263066117710b4d1647bf942fc,bp/tripleo-juno-tuskar-template-generator,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== Tuskar Heat Template Generator ============================== https://blueprints.launchpad.net/tuskar/+spec/tripleo-juno-tuskar-template-generator In Juno, Tuskar is moving towards replacing the role that merge.py fulfilled in the Icehouse and earlier iterations of TripleO. This process is vastly different from the merge.py of old as it takes advantage of more recent Heat features such as provider resources and environments to allow a more customizable selection of items to include in a cloud provisioned by Tuskar. Problem Description =================== Over the past few months, Tuskar's use cases have moved in a direction of entertaining wildly different cloud configurations. These use cases range from all-in-one setups to installations that split out individual services per node, including separate database and messaging servers. At the same time, the TripleO Heat Templates are undergoing changes to increase their flexibility and reusability by utilizing the HOT format and recent developments in template reuse. Tuskar has use cases for extensibility in the form of ""custom resources"", which correspond to user-created resource providers. A generic resource provider manipulation service will be able to seemlessly incorporate custom providers along side TripleO provided providers. The existing merge.py will begin to be obsoleted as the HOT changes take place. There is a need to provide the following: * Creation of the Heat environment file that contains references to the provider resources selected by the user (known as the ``resource_registry`` in the Heat environment). * Creation of the master stack template for the cloud. * Consolidation of all of the provider resource stack parameters into a single list for the overall stack. Proposed Change =============== This proposal covers the code changes necessary (hereafter, template generator) to fulfill the needs above. .. _template-generator-terminology: **Terminology** * *Deployment Plan* - The generated files to pass to Heat for a particular application being configured (where application, for our purposes, is an overcloud). These files include the master template and the environment file, but does not include each of the provider resource templates (those are stored elsewhere). * *Master Template* - The template that represents the stack that will be created in Heat. Each role added to the deployment plan must have a resource entry in the master template in order for Heat to actually create the resource. .. _template-generator-assumptions: **Assumptions** It makes the following assumptions: * There is an API into the storage mechanism. The details beyond the API are outside of this spec's scope and covered elsewhere (no link currently exists to that spec). This API includes: * Retrieving resource provider templates by name and version. * Storing the deployment plan files, including handling of sensitive data (see the storage spec for more information). * Security, such as authentication and multi-tenancy concerns, are handled outside of the template generator. .. _template-generator-apis: **APIs** The template generator will provide the following APIs: **<Instantiation>** Input: * At instantiation time, the template generator will need to be provided with an object that implements the storage backend APIs. Output: None **Create a New Deployment Plan** Creates the skeleton files of a deployment plan and stores them in Tuskar's persistent storage. Input: * (required) Name of the deployment plan being created. This must be unique from the template generator's point of view. In other words, it is outside the scope of the template generator to apply the logic necessary for two different tenants to use the same deployment plan name (likely falling under the responsibility of the storage API). * (required) Description of the deployment plan. Output: * UUID for referencing the deployment plan. Alternatives ------------ TODO Security Impact --------------- TODO Other End User Impact --------------------- This change is at a lower level layer than the end user will directly see. The end user impact is all handled in the REST API layer :ref:`[2] <template-generator-rest-api-ref>`. Performance Impact ------------------ At this level, there isn't any need for throttling requests. That will occur higher up than this code. There is a potential in having to parse and analyze a number of JSON documents at once. However, the number of different provider resources in play should be on the order of tens and not provide a problem. Other Deployer Impact --------------------- This change is at a lower level layer than the deployer will directly see. Developer Impact ---------------- The overall manager code that handles the REST API calls will need to call into this and is thus dependent on its implementation. This spec defines a fair bit of the expected API but the details should be flushed out first so the integration points are well understood. Implementation ============== Assignee(s) ----------- Primary assignee: jdob Other contributors: None Work Items ---------- TODO Dependencies ============ * Dependent on the TripleO Heat Template conversion to HOT (no current spec exists to link to). Testing ======= This feature will be tested through unit tests. Indirect tests will also occur through the testing infrastructure surrounding the REST APIs :ref:`[2] <template-generator-rest-api-ref>`. Documentation Impact ==================== The code should be documented with docstrings and comments as appropriate. References ========== .. _template-generator-wiki-ref: [1] Design notes on how the deployment plan is generated: https://wiki.openstack.org/wiki/TripleO/TuskarJunoPlanning/TemplateBackend .. _template-generator-rest-api-ref: [2] Blueprint for the REST APIs that will trigger this code to run: https://blueprints.launchpad.net/tuskar/+spec/tripleo-juno-tuskar-rest-api ",,210,0
openstack%2Fkeystone~master~Ib603861ad19a525c112153ac3799f2cbe453d4f7,openstack/keystone,master,Ib603861ad19a525c112153ac3799f2cbe453d4f7,Corrects minor spelling mistakes,MERGED,2014-06-24 13:51:16.000000000,2014-06-24 19:36:31.000000000,2014-06-24 19:36:30.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 9751}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-06-24 13:51:16.000000000', 'files': ['doc/source/developing.rst', 'doc/source/installing.rst', 'keystone/tests/test_v3_catalog.py', 'doc/source/configuration.rst', 'doc/source/api_curl_examples.rst', 'doc/source/setup.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f15471f5fd70b2e0146548d018c735cad040ce68', 'message': 'Corrects minor spelling mistakes\n\nChange-Id: Ib603861ad19a525c112153ac3799f2cbe453d4f7\n'}]",0,102237,f15471f5fd70b2e0146548d018c735cad040ce68,10,5,1,7725,,,0,"Corrects minor spelling mistakes

Change-Id: Ib603861ad19a525c112153ac3799f2cbe453d4f7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/37/102237/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developing.rst', 'doc/source/installing.rst', 'keystone/tests/test_v3_catalog.py', 'doc/source/configuration.rst', 'doc/source/api_curl_examples.rst', 'doc/source/setup.rst']",6,f15471f5fd70b2e0146548d018c735cad040ce68,spelling,"These dependencies can be installed from PyPi_ using the Python tool pip_.We recommend establishing a virtualenv to run keystone within. virtualenv limits the Python environment to just what you're installing as dependencies, # Use 'python setup.py' to link Keystone into Python's site-packagesinvoke Python and import the libraries. If you're using a virtualenv, don't","These dependencies can be installed from PyPi_ using the python tool pip_.We recommend establishing a virtualenv to run keystone within. Virtualenv limits the python environment to just what you're installing as dependencies, # Use python setup.py to link Keystone into python's site-packagesinvoke python and import the libraries. If you're using a virtualenv, don't",19,19
openstack%2Fkeystone~master~I7eb6819de33f4d94a8bae75286bb02436152c64b,openstack/keystone,master,I7eb6819de33f4d94a8bae75286bb02436152c64b,deprecate LDAP config options for 'tenants',MERGED,2014-06-24 15:51:46.000000000,2014-06-24 19:36:28.000000000,2014-06-24 19:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5575}, {'_account_id': 6486}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-24 15:51:46.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/tests/test_ldap_livetest.py', 'keystone/tests/config_files/backend_tls_liveldap.conf', 'keystone/common/config.py', 'doc/source/configuration.rst', 'keystone/tests/config_files/backend_liveldap.conf', 'keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/58fb7978152002f713d2bfcdf27d7ee69b3f2823', 'message': ""deprecate LDAP config options for 'tenants'\n\nThis deprecates all config options using the term 'tenant' in favor of\nnew options using the term 'project'.\n\nChange-Id: I7eb6819de33f4d94a8bae75286bb02436152c64b\nCloses-Bug: 1283841\n""}]",0,102278,58fb7978152002f713d2bfcdf27d7ee69b3f2823,10,7,1,4,,,0,"deprecate LDAP config options for 'tenants'

This deprecates all config options using the term 'tenant' in favor of
new options using the term 'project'.

Change-Id: I7eb6819de33f4d94a8bae75286bb02436152c64b
Closes-Bug: 1283841
",git fetch https://review.opendev.org/openstack/keystone refs/changes/78/102278/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/tests/test_ldap_livetest.py', 'keystone/tests/config_files/backend_tls_liveldap.conf', 'keystone/common/config.py', 'doc/source/configuration.rst', 'keystone/tests/config_files/backend_liveldap.conf', 'keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py']",8,58fb7978152002f713d2bfcdf27d7ee69b3f2823,bug/1283841," options_name = 'project' self.member_attribute = (getattr(conf.ldap, 'project_member_attribute')"," options_name = 'tenant' self.member_attribute = (getattr(conf.ldap, 'tenant_member_attribute')",120,88
openstack%2Fnova~stable%2Ficehouse~I3cfdfe9048fe219fc12cdac8a399b496f237e55e,openstack/nova,stable/icehouse,I3cfdfe9048fe219fc12cdac8a399b496f237e55e,Use no_timer_check with soft-qemu,MERGED,2014-06-14 16:19:28.000000000,2014-06-24 19:36:17.000000000,2014-06-24 19:36:15.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1955}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-06-14 16:19:28.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/485f25df181dedf2ba475f5e550af4f9f41089a3', 'message': ""Use no_timer_check with soft-qemu\n\nThe Linux kernel timer check not working properly\nwhen the hypervisor's thread preempted by the host CPU scheduler.\n\nThe timer check is automatically disabled with other types\nof hypervisors including the hardware accelerated kvm,\nbut timer_check is not disabled when qemu used without hardware acceleration.\n\nThis issue is frequently mischaracterized as an SSH connectivity issue and\ncauses rechecks and occasional boot failures.\n\nThis change adds no_timer_check kernel parameter when we are using\nuec images with qemu.\n\nCloses-Bug: #1312199\nChange-Id: I3cfdfe9048fe219fc12cdac8a399b496f237e55e\n(cherry picked from commit 6b86a61fee15ce1237303fab2f7896f8c3bcad47)\n""}]",0,100065,485f25df181dedf2ba475f5e550af4f9f41089a3,13,6,1,5803,,,0,"Use no_timer_check with soft-qemu

The Linux kernel timer check not working properly
when the hypervisor's thread preempted by the host CPU scheduler.

The timer check is automatically disabled with other types
of hypervisors including the hardware accelerated kvm,
but timer_check is not disabled when qemu used without hardware acceleration.

This issue is frequently mischaracterized as an SSH connectivity issue and
causes rechecks and occasional boot failures.

This change adds no_timer_check kernel parameter when we are using
uec images with qemu.

Closes-Bug: #1312199
Change-Id: I3cfdfe9048fe219fc12cdac8a399b496f237e55e
(cherry picked from commit 6b86a61fee15ce1237303fab2f7896f8c3bcad47)
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/100065/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,485f25df181dedf2ba475f5e550af4f9f41089a3,no_timer_check," if CONF.libvirt.virt_type == ""qemu"": guest.os_cmdline += "" no_timer_check"" if CONF.libvirt.virt_type == ""qemu"": guest.os_cmdline += "" no_timer_check""",,8,0
openstack%2Fdesignate~master~Ia3ef40f30d1b602a80a5eac97853e287f587d4b8,openstack/designate,master,Ia3ef40f30d1b602a80a5eac97853e287f587d4b8,Change log string format to '%' for consistency,MERGED,2014-06-18 23:12:47.000000000,2014-06-24 19:19:14.000000000,2014-06-24 19:19:13.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 11626}]","[{'number': 1, 'created': '2014-06-18 23:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/88e1d87dc994125d88db16e8c462309f566958c1', 'message': ""Change log string format to '%' for consistency\n\nChange-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8\nImplements: blueprint standardize-logging\n""}, {'number': 2, 'created': '2014-06-23 14:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d3916b550cfac63b733a0abc67594332b0d47494', 'message': ""Change log string format to '%' for consistency\n\nChange-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8\nImplements: blueprint standardize-logging\n""}, {'number': 3, 'created': '2014-06-24 14:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ef8414c3fb10fed5ae17c80aff9d4f991ea3cc5c', 'message': ""Change log string format to '%' for consistency\n\nChange-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8\nImplements: blueprint standardize-logging\n""}, {'number': 4, 'created': '2014-06-24 15:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/028085c4d506361b00239e3cd821f7146169fb29', 'message': ""Change log string format to '%' for consistency\n\nChange-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8\nImplements: blueprint standardize-logging\n""}, {'number': 5, 'created': '2014-06-24 18:11:48.000000000', 'files': ['designate/schema/__init__.py', 'designate/mdns/service.py', 'designate/backend/impl_powerdns/migrate_repo/versions/006_add_inherit_ttl_col.py', 'designate/central/service.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/sink/service.py', 'designate/api/middleware.py', 'designate/backend/impl_bind9.py', 'designate/backend/impl_dynect.py', 'designate/manage/tlds.py', 'designate/notification_handler/neutron.py', 'designate/network_api/fake.py', 'designate/backend/base.py', 'designate/notification_handler/base.py', 'designate/service.py', 'designate/plugin.py', 'designate/network_api/neutron.py', 'designate/schema/resolvers.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/99325f8d0747719871e28741b10354b8a254894b', 'message': ""Change log string format to '%' for consistency\n\nChange-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8\nImplements: blueprint standardize-logging\n""}]",3,101047,99325f8d0747719871e28741b10354b8a254894b,31,6,5,11626,,,0,"Change log string format to '%' for consistency

Change-Id: Ia3ef40f30d1b602a80a5eac97853e287f587d4b8
Implements: blueprint standardize-logging
",git fetch https://review.opendev.org/openstack/designate refs/changes/47/101047/4 && git format-patch -1 --stdout FETCH_HEAD,"['designate/schema/__init__.py', 'designate/mdns/service.py', 'designate/central/service.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/backend/impl_dynect.py', 'designate/manage/tlds.py', 'designate/notification_handler/neutron.py', 'designate/network_api/fake.py', 'designate/notification_handler/base.py', 'designate/service.py', 'designate/plugin.py', 'designate/sqlalchemy/session.py', 'designate/network_api/neutron.py', 'designate/schema/resolvers.py']",14,88e1d87dc994125d88db16e8c462309f566958c1,bp/standardize-logging, LOG.debug('Loading remote schema: %s' % uri)," LOG.debug('Loading remote schema: %s', uri)",55,47
openstack%2Ftraining-guides~master~I00fd3879ad300e6a83b547234b24d824eff842e9,openstack/training-guides,master,I00fd3879ad300e6a83b547234b24d824eff842e9,Change IP from API Network to Magement Network,MERGED,2014-06-24 00:35:36.000000000,2014-06-24 19:04:44.000000000,2014-06-24 19:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 7007}, {'_account_id': 11197}]","[{'number': 1, 'created': '2014-06-24 00:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2e3ef6989b2bdd92d87a874280911ca477595aab', 'message': 'Changes destination IP from public to private\n\nChange-Id: I00fd3879ad300e6a83b547234b24d824eff842e9\n'}, {'number': 2, 'created': '2014-06-24 17:14:32.000000000', 'files': ['doc/training-guides/lab003-compute-node.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/24e80915fd81e126e69dea1546ceec0442df27c4', 'message': 'Change IP from API Network to Magement Network\n\nChange IP from API Network to OpenStack Magement Network.\nReplaced destination IP address from public network\n192.168.100.51 to 10.10.10.51.\n\nCloses-bug: #1333139\nChange-Id: I00fd3879ad300e6a83b547234b24d824eff842e9\n'}]",0,102068,24e80915fd81e126e69dea1546ceec0442df27c4,13,4,2,11197,,,0,"Change IP from API Network to Magement Network

Change IP from API Network to OpenStack Magement Network.
Replaced destination IP address from public network
192.168.100.51 to 10.10.10.51.

Closes-bug: #1333139
Change-Id: I00fd3879ad300e6a83b547234b24d824eff842e9
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/68/102068/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/lab003-compute-node.xml'],1,2e3ef6989b2bdd92d87a874280911ca477595aab,bug/1333139,connection = mysql://neutronUser:neutronPass@10.10.10.51/neutron <para><programlisting>rabbit_host = 10.10.10.51auth_host = 10.10.10.51auth_host = 10.10.10.51rabbit_host=10.10.10.51 nova_url=http://10.10.10.51:8774/v1.1/ sql_connection=mysql://novaUser:novaPass@10.10.10.51/novaglance_api_servers=10.10.10.51:9292novncproxy_base_url=http://10.10.10.51:6080/vnc_auto.htmlneutron_url=http://10.10.10.51:9696neutron_admin_auth_url=http://10.10.10.51:35357/v2.0,connection = mysql://neutronUser:neutronPass@192.168.100.51/neutron <para><programlisting>rabbit_host = 192.168.100.51auth_host = 192.168.100.51auth_host = 192.168.100.51rabbit_host=192.168.100.51 nova_url=http://192.168.100.51:8774/v1.1/ sql_connection=mysql://novaUser:novaPass@192.168.100.51/novaglance_api_servers=192.168.100.51:9292novncproxy_base_url=http://192.168.100.51:6080/vnc_auto.htmlneutron_url=http://192.168.100.51:9696neutron_admin_auth_url=http://192.168.100.51:35357/v2.0,11,11
openstack%2Fcinder~master~Ib15ec2764160df30b0d923b8b75ac34aee298857,openstack/cinder,master,Ib15ec2764160df30b0d923b8b75ac34aee298857,Bogus test to satisfy my own silly curiousity,ABANDONED,2014-06-23 22:14:13.000000000,2014-06-24 19:03:23.000000000,,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 22:14:13.000000000', 'files': ['cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff1849c25fa7d84d2c6421c9da19e0db5624d2bd', 'message': 'Bogus test to satisfy my own silly curiousity\n\nJust ignore me\n\nChange-Id: Ib15ec2764160df30b0d923b8b75ac34aee298857\n'}]",0,102034,ff1849c25fa7d84d2c6421c9da19e0db5624d2bd,7,4,1,2243,,,0,"Bogus test to satisfy my own silly curiousity

Just ignore me

Change-Id: Ib15ec2764160df30b0d923b8b75ac34aee298857
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/102034/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/api.py'],1,ff1849c25fa7d84d2c6421c9da19e0db5624d2bd,bogus_test," #if not force and snapshot['status'] not in [""available"", ""error""]: if snapshot['status'] not in [""available"", ""error""]:"," if not force and snapshot['status'] not in [""available"", ""error""]:",2,1
openstack%2Ftripleo-incubator~master~Id030c47ed8e246e7f26615640d5500148de1620e,openstack/tripleo-incubator,master,Id030c47ed8e246e7f26615640d5500148de1620e,Split ssh keys into files per user.,MERGED,2014-06-20 15:15:20.000000000,2014-06-24 19:03:10.000000000,2014-06-24 19:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 7585}, {'_account_id': 8449}, {'_account_id': 9268}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-06-20 15:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/13a07bba92f0bd1456cabaabc1acb24204c05163', 'message': 'Split ssh keys into files per user.\n\nUpdates the way we maintain our SSH keys in TripleO to use\nindividual files per user.\n\nThis change is meant to support adding support for per user\nssh accounts. Right now SSH access to some of the TripleO\nregions are provided directly via the /root account. Using\nindividual ssh accounts per user should allow some extra\nsecurity/auditability. This is a step in that direction...\n\nFor per user ssh access our convention will be that the IRC\nnickname/username field should match the filename of the\nssh-keys file and will be used to provide a /home directory\nand ssh access.\n\nChange-Id: Id030c47ed8e246e7f26615640d5500148de1620e\n'}, {'number': 2, 'created': '2014-06-23 15:59:11.000000000', 'files': ['tripleo-cloud/README.md', 'tripleo-cloud/ssh-keys/devananda', 'tripleo-cloud/ssh-keys/greghaynes', 'tripleo-cloud/ssh-keys/jog0', 'tripleo-cloud/tripleo-cd-ssh-keys', 'tripleo-cloud/ssh-keys/slagle', 'scripts/update-admin-ssh-keys', 'tripleo-cloud/ssh-keys/derekh', 'tripleo-cloud/ssh-keys/dprince', 'tripleo-cloud/ssh-keys/Ng', 'tripleo-cloud/ssh-keys/SpamapS', 'tripleo-cloud/ssh-keys/tchaypo', 'tripleo-cloud/ssh-keys/GheRivero', 'tripleo-cloud/ssh-keys/lifeless'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/67a938fede001db63ddd14acee7d62a1b62060ff', 'message': 'Split ssh keys into files per user.\n\nUpdates the way we maintain our SSH keys in TripleO to use\nindividual files per user.\n\nThis change is meant to support adding support for per user\nssh accounts. Right now SSH access to some of the TripleO\nregions are provided directly via the /root account. Using\nindividual ssh accounts per user should allow some extra\nsecurity/auditability. This is a step in that direction...\n\nFor per user ssh access our convention will be that the IRC\nnickname/username field should match the filename of the\nssh-keys file and will be used to provide a /home directory\nand ssh access.\n\nChange-Id: Id030c47ed8e246e7f26615640d5500148de1620e\n'}]",4,101576,67a938fede001db63ddd14acee7d62a1b62060ff,23,7,2,360,,,0,"Split ssh keys into files per user.

Updates the way we maintain our SSH keys in TripleO to use
individual files per user.

This change is meant to support adding support for per user
ssh accounts. Right now SSH access to some of the TripleO
regions are provided directly via the /root account. Using
individual ssh accounts per user should allow some extra
security/auditability. This is a step in that direction...

For per user ssh access our convention will be that the IRC
nickname/username field should match the filename of the
ssh-keys file and will be used to provide a /home directory
and ssh access.

Change-Id: Id030c47ed8e246e7f26615640d5500148de1620e
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/76/101576/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo-cloud/README.md', 'tripleo-cloud/ssh-keys/devananda', 'tripleo-cloud/ssh-keys/greghaynes', 'tripleo-cloud/ssh-keys/jog0', 'tripleo-cloud/tripleo-cd-ssh-keys', 'tripleo-cloud/ssh-keys/slagle', 'scripts/update-admin-ssh-keys', 'tripleo-cloud/ssh-keys/derekh', 'tripleo-cloud/ssh-keys/dprince', 'tripleo-cloud/ssh-keys/Ng', 'tripleo-cloud/ssh-keys/SpamapS', 'tripleo-cloud/ssh-keys/tchaypo', 'tripleo-cloud/ssh-keys/GheRivero', 'tripleo-cloud/ssh-keys/lifeless']",14,13a07bba92f0bd1456cabaabc1acb24204c05163,ssh_user_accounts,ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA728T0gI08lJFqZQo8lDUgKiE860aWTQz+QSeYAFg2T5TrYbGHKt2GHZy+OHYkAhUiSCjZXogFyh1+TRkQIYCcZTNQdOoMtLVesOk9/jRh6ZIcrQvTzbK2KpLXBMhNX9J+HZ5MiAYTZRX9uJSmvDAxrsof2qcVyYBs67hPdE3s5I0Zg5uNm93M9/ciEr+UWTWiIxounHhiEbdW1LIszBlAtvLpsw9bgtB6rRjygiSvoiXMTt00YhWip9PpxBBa6OqtETF/Qu+Uf+guujTnwO9Ue77kNDoocMrZfDsBxlSG6gsByGO/ue7YlRI1w96W68xaGLFl5cgt60SUK1BIVJW9w== lifeless-64 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDg/kUthl0Em5IEKGQpRYq7Yp5n1aoelJDEi5KzAvvevhCUEzlmgZI/y6cfixSC5ZJpFydZ+FlSDMiFbUwXmzHCSuEteFDtiaFpF+8E5+g7lgvjl0lJ/kWGZEGe9R00lsD9Xj0G1SZXClijS/yFDdpm9Gb2JfCUiruzW2Tu7LkOAdmAwcHw2MrZPMfuPzLFnP/aex1FfokCz+35pgi4EK98znigN5l8XyMG7/wP07WeTUY82lW6ea7bR8X8G9VH+G7iqtwftxpzT+HQJ9+CIK+y1BucGsM6uYTB3aC9bVuUMKVmHpTuLXmKTaAt4rouvGFcHmOFtd6KGqUEFcFqyCij lifeless-hp ,,32,22
openstack%2Fpython-ironicclient~master~Ie9ea577f35f1eb6fc71876be0d4f721887f1d769,openstack/python-ironicclient,master,Ie9ea577f35f1eb6fc71876be0d4f721887f1d769,Updated from global requirements,MERGED,2014-05-28 20:59:41.000000000,2014-06-24 19:02:57.000000000,2014-06-24 19:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}]","[{'number': 1, 'created': '2014-05-28 20:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/35e8f592bdb3e212d388c84af6ff23636fac7e4c', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 2, 'created': '2014-05-29 13:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/7c4af2a05a18ed54853cfbf4311528dab9f5ec7d', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 3, 'created': '2014-05-29 16:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/659e17286370aeb6c5c7535f16e7e52897e1b699', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 4, 'created': '2014-05-30 16:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5f708787ff2fedd6be4c0f2e3f9245c2721f3f13', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 5, 'created': '2014-06-10 00:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5e565975f3db6b9ec8466ffe20f7fa5dcdb32012', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 6, 'created': '2014-06-10 14:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/1fb2007703a6301f976840bedce41078a9411b65', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 7, 'created': '2014-06-11 01:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8b247754207f1a295fda726b5f657a3ed15a1fb4', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 8, 'created': '2014-06-13 22:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f1d474ad29794ff87652140ac28f27c313f1b495', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 9, 'created': '2014-06-16 09:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/861a8e36fdb22ac60bf3f10dd4b99741ca98b74f', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 10, 'created': '2014-06-17 21:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/22ca9b3981d37b5bda96ea6e96103681a62b7b2d', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}, {'number': 11, 'created': '2014-06-18 00:47:26.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/1709fef25f085ec4ebf2686deb636b3a03b00a7a', 'message': 'Updated from global requirements\n\nChange-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769\n'}]",0,96263,1709fef25f085ec4ebf2686deb636b3a03b00a7a,71,6,11,11131,,,0,"Updated from global requirements

Change-Id: Ie9ea577f35f1eb6fc71876be0d4f721887f1d769
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/63/96263/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,35e8f592bdb3e212d388c84af6ff23636fac7e4c,openstack/requirements,"sphinx>=1.2.1,<1.3","sphinx>=1.1.2,<1.2",1,1
openstack%2Ftraining-guides~master~I51aac7571b7b88a052da7ad0d41139260a6a29bf,openstack/training-guides,master,I51aac7571b7b88a052da7ad0d41139260a6a29bf,"Changing destination IP address from public network 192.168.100.51 to private network 10.10.10.51, bug ID 1333139",ABANDONED,2014-06-23 23:52:41.000000000,2014-06-24 18:56:48.000000000,,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7007}, {'_account_id': 11197}]","[{'number': 1, 'created': '2014-06-23 23:52:41.000000000', 'files': ['doc/training-guides/lab003-compute-node.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/1b977a63f49362a1ac5a05f83edc15138679e54a', 'message': 'Changing destination IP address from public network 192.168.100.51 to private network 10.10.10.51, bug ID 1333139\n\nChange-Id: I51aac7571b7b88a052da7ad0d41139260a6a29bf\n'}]",0,102056,1b977a63f49362a1ac5a05f83edc15138679e54a,8,4,1,11197,,,0,"Changing destination IP address from public network 192.168.100.51 to private network 10.10.10.51, bug ID 1333139

Change-Id: I51aac7571b7b88a052da7ad0d41139260a6a29bf
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/56/102056/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/lab003-compute-node.xml'],1,1b977a63f49362a1ac5a05f83edc15138679e54a,bug/1333139,connection = mysql://neutronUser:neutronPass@10.10.10.51/neutron <para><programlisting>rabbit_host = 10.10.10.51auth_host = 10.10.10.51auth_host = 10.10.10.51rabbit_host=10.10.10.51 nova_url=http://10.10.10.51:8774/v1.1/ sql_connection=mysql://novaUser:novaPass@10.10.10.51/novaglance_api_servers=10.10.10.51:9292novncproxy_base_url=http://10.10.10.51:6080/vnc_auto.htmlneutron_url=http://10.10.10.51:9696neutron_admin_auth_url=http://10.10.10.51:35357/v2.0,connection = mysql://neutronUser:neutronPass@192.168.100.51/neutron <para><programlisting>rabbit_host = 192.168.100.51auth_host = 192.168.100.51auth_host = 192.168.100.51rabbit_host=192.168.100.51 nova_url=http://192.168.100.51:8774/v1.1/ sql_connection=mysql://novaUser:novaPass@192.168.100.51/novaglance_api_servers=192.168.100.51:9292novncproxy_base_url=http://192.168.100.51:6080/vnc_auto.htmlneutron_url=http://192.168.100.51:9696neutron_admin_auth_url=http://192.168.100.51:35357/v2.0,11,11
openstack%2Ftempest~master~I585e114a3f35a2bc074ad479fc227b79df36df75,openstack/tempest,master,I585e114a3f35a2bc074ad479fc227b79df36df75,HEAD doesn't return a body,MERGED,2014-06-23 12:32:32.000000000,2014-06-24 18:56:13.000000000,2014-06-24 18:56:13.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 12:32:32.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c9a94f9f94384e9701081cfcdaaa89653f3213d4', 'message': ""HEAD doesn't return a body\n\nThe following warning message was misleading when doing the\nresults of a HEAD method, which never will have a body.\n\nChange-Id: I585e114a3f35a2bc074ad479fc227b79df36df75\n""}]",1,101900,c9a94f9f94384e9701081cfcdaaa89653f3213d4,29,8,1,2750,,,0,"HEAD doesn't return a body

The following warning message was misleading when doing the
results of a HEAD method, which never will have a body.

Change-Id: I585e114a3f35a2bc074ad479fc227b79df36df75
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/101900/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,c9a94f9f94384e9701081cfcdaaa89653f3213d4,headwarn, if method != 'HEAD' and not resp_body and resp.status >= 400:, if not resp_body and resp.status >= 400:,1,1
openstack%2Fkeystone~master~I7d4b6d46666a71601f30da48bd720f847a8dfa09,openstack/keystone,master,I7d4b6d46666a71601f30da48bd720f847a8dfa09,remove unnecessary word in docs: 'an',MERGED,2014-06-10 21:58:42.000000000,2014-06-24 18:56:03.000000000,2014-06-24 18:56:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 11333}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-06-10 21:58:42.000000000', 'files': ['doc/source/http-api.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1cfcf12b2d79bfa3e5cac6d3505c6957c88ce559', 'message': ""remove unnecessary word in docs: 'an'\n\nPer Brant's comment in:\n    https://review.openstack.org/#/c/99075/3/doc/source/http-api.rst\n\nChange-Id: I7d4b6d46666a71601f30da48bd720f847a8dfa09\n""}]",0,99218,1cfcf12b2d79bfa3e5cac6d3505c6957c88ce559,28,6,1,4,,,0,"remove unnecessary word in docs: 'an'

Per Brant's comment in:
    https://review.openstack.org/#/c/99075/3/doc/source/http-api.rst

Change-Id: I7d4b6d46666a71601f30da48bd720f847a8dfa09
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/99218/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/http-api.rst'],1,1cfcf12b2d79bfa3e5cac6d3505c6957c88ce559,(detached,"With unversioned ``identity`` endpoints in the service catalog, you should be able to `authenticate with keystoneclient`_ successfully.","With an unversioned ``identity`` endpoints in the service catalog, you should be able to `authenticate with keystoneclient`_ successfully.",2,2
openstack%2Freviewstats~master~I2e624ef96abd57c3699135f4762b7bf661333af3,openstack/reviewstats,master,I2e624ef96abd57c3699135f4762b7bf661333af3,Update sahara core review team members,MERGED,2014-06-24 09:35:22.000000000,2014-06-24 18:53:14.000000000,2014-06-24 18:53:13.000000000,"[{'_account_id': 3}, {'_account_id': 4190}]","[{'number': 1, 'created': '2014-06-24 09:35:22.000000000', 'files': ['projects/sahara.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/511e847c53c120d58ccd0e914fcc391552cc81ba', 'message': 'Update sahara core review team members\n\nChange-Id: I2e624ef96abd57c3699135f4762b7bf661333af3\n'}]",0,102156,511e847c53c120d58ccd0e914fcc391552cc81ba,7,2,1,6786,,,0,"Update sahara core review team members

Change-Id: I2e624ef96abd57c3699135f4762b7bf661333af3
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/56/102156/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/sahara.json'],1,511e847c53c120d58ccd0e914fcc391552cc81ba,," ""alazarev"", ""tmckay"""," ""alazarev""",2,1
openstack%2Ftripleo-ci~master~I70a1b72d17722be5abd37befc61b867b01e58e7f,openstack/tripleo-ci,master,I70a1b72d17722be5abd37befc61b867b01e58e7f,"Revert ""Try reverting Neutron ovs-agent change""",MERGED,2014-06-20 12:28:10.000000000,2014-06-24 18:45:55.000000000,2014-06-24 18:45:55.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 4190}, {'_account_id': 6928}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-06-20 12:28:10.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7b618b807b215e761c81f576b954c0e1ae7aa361', 'message': 'Revert ""Try reverting Neutron ovs-agent change""\n\nThis reverts commit 098cbda6986d3009993da3fc61e7b6a45db5026c.\n\nThe neutron revert for this has landed:\n\n  https://review.openstack.org/#/c/101395/\n\nSo we no longer need to revert it on our side.\n\nChange-Id: I70a1b72d17722be5abd37befc61b867b01e58e7f\n'}]",0,101513,7b618b807b215e761c81f576b954c0e1ae7aa361,15,5,1,360,,,0,"Revert ""Try reverting Neutron ovs-agent change""

This reverts commit 098cbda6986d3009993da3fc61e7b6a45db5026c.

The neutron revert for this has landed:

  https://review.openstack.org/#/c/101395/

So we no longer need to revert it on our side.

Change-Id: I70a1b72d17722be5abd37befc61b867b01e58e7f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/13/101513/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,7b618b807b215e761c81f576b954c0e1ae7aa361,revert_temp_revert,,# https://review.openstack.org/98755 temprevert neutron e5cdad90f97d3a54a493eca19e7a3ff643426de1 XXX ,0,3
openstack%2Fpython-ceilometerclient~master~Ie598b73c64dece2185955467936dc6544a8a3dc7,openstack/python-ceilometerclient,master,Ie598b73c64dece2185955467936dc6544a8a3dc7,Add methods to resource classes,MERGED,2014-05-01 13:01:14.000000000,2014-06-24 18:40:20.000000000,2014-06-24 18:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7450}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 7930}, {'_account_id': 8871}, {'_account_id': 10488}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-05-01 13:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/2ecacc10fdc4c7940425f283f468d0fc5bc65d2f', 'message': 'Bug 1312146 Resource classes of managers should\nhave methods like delete() and get()\n\nAdded methods which can be called directly from\nresource class.\n\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 2, 'created': '2014-05-01 13:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/408a2a48d31a4fe5c18ed69f1430954b0035f19c', 'message': 'Bug 1312146 Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 3, 'created': '2014-05-05 13:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/76869b8f6c81b14adada99e86b92f3936f10871f', 'message': 'Bug 1312146 Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 4, 'created': '2014-05-06 14:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/c830e482650169cddf60afe3a12292e01ff90c93', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 5, 'created': '2014-05-26 17:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/f9dce84b015677e6fa9bab88a4049aac0b641ead', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 6, 'created': '2014-05-27 14:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/905e9e5c15b5ec87d233e455285eecc14f52d878', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 7, 'created': '2014-05-28 10:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/fc04240e98084faf4ba1d9909703318b3979d2f7', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 8, 'created': '2014-05-30 13:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/502202dd0b3b6af20fbcdbee0232b7d409e4a87f', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 9, 'created': '2014-06-05 12:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/26c042a957deda7005ceb903646c40ab81b06b63', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Added methods which can\nbe called directly from resource class. Methods\nadded to all classes, which have get() or delete().\nAlso added catch of HTTPNotFound for alarm get()\nbecause it affects correct functionality of\nscenario tests.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 10, 'created': '2014-06-09 11:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/0d9de53dc64eacedb974ec0350ea75a71b67d4ce', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Basicly base.Resource\nclass has method get(), which uses id attribute,\nbut classes Alarm, Event, etc. have no this attribute.\nAdded intercept getting of id in the resource classes.\nAlso added catch of HTTPNotFound for alarm get()\nbecause it affects correct functionality of\nscenario tests.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}, {'number': 11, 'created': '2014-06-16 10:42:33.000000000', 'files': ['ceilometerclient/tests/v2/test_resources.py', 'ceilometerclient/v2/shell.py', 'ceilometerclient/tests/v2/test_events.py', 'ceilometerclient/v2/events.py', 'ceilometerclient/tests/v2/test_alarms.py', 'ceilometerclient/v2/alarms.py', 'ceilometerclient/v2/resources.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/b8a3fe54c06c7e04314d39da80b5964a589356f0', 'message': 'Add methods to resource classes\n\nResource classes of managers should have methods\nlike delete() and get(). Basicly base.Resource\nclass has method get(), which uses id attribute,\nbut classes Alarm, Event, etc. have no this attribute.\nAdded intercept getting of id in the resource classes.\nAlso added catch of HTTPNotFound for alarm get()\nbecause it affects correct functionality of\nscenario tests.\n\nCloses-Bug: #1312146\nChange-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7\n'}]",20,91554,b8a3fe54c06c7e04314d39da80b5964a589356f0,70,14,11,10488,,,0,"Add methods to resource classes

Resource classes of managers should have methods
like delete() and get(). Basicly base.Resource
class has method get(), which uses id attribute,
but classes Alarm, Event, etc. have no this attribute.
Added intercept getting of id in the resource classes.
Also added catch of HTTPNotFound for alarm get()
because it affects correct functionality of
scenario tests.

Closes-Bug: #1312146
Change-Id: Ie598b73c64dece2185955467936dc6544a8a3dc7
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/54/91554/9 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/v2/events.py', 'ceilometerclient/v2/alarms.py', 'ceilometerclient/v2/resources.py']",3,2ecacc10fdc4c7940425f283f468d0fc5bc65d2f,master, def get(self): return self.manager.get(self) ,,15,0
openstack%2Fdevstack~stable%2Ficehouse~I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,openstack/devstack,stable/icehouse,I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,retry apt operations to avoid network issues,MERGED,2014-06-24 14:55:49.000000000,2014-06-24 18:40:03.000000000,2014-06-24 18:40:03.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-24 14:55:49.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/85a8d78092c1223382795fbdfab2385045191fdb', 'message': 'retry apt operations to avoid network issues\n\nOne of the major gate failures is do to something being wrong with\nthe apt mirrors. The Acquire group provides an implicit retry on\nnetwork operations which seems like it might be helpful here.\n\nRef: http://linux.die.net/man/5/apt.conf\n\nChange-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27\nRelated-Bug: #1286635\n(cherry picked from commit e83f7785a7609284f74667e266e38e12a29b326b)\n'}]",0,102263,85a8d78092c1223382795fbdfab2385045191fdb,7,2,1,2750,,,0,"retry apt operations to avoid network issues

One of the major gate failures is do to something being wrong with
the apt mirrors. The Acquire group provides an implicit retry on
network operations which seems like it might be helpful here.

Ref: http://linux.die.net/man/5/apt.conf

Change-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27
Related-Bug: #1286635
(cherry picked from commit e83f7785a7609284f74667e266e38e12a29b326b)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/63/102263/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,85a8d78092c1223382795fbdfab2385045191fdb,icehouse,"# For debian/ubuntu make apt attempt to retry network ops on it's own if is_ubuntu; then echo 'APT::Acquire::Retries ""20"";' | sudo tee /etc/apt/apt.conf.d/80retry fi ",,5,0
openstack%2Fdevstack~stable%2Fhavana~I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,openstack/devstack,stable/havana,I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,retry apt operations to avoid network issues,MERGED,2014-06-24 15:03:29.000000000,2014-06-24 18:38:34.000000000,2014-06-24 18:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-24 15:03:29.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/630be3b88ba87a4684aec0c4bf7810e7ad924f38', 'message': 'retry apt operations to avoid network issues\n\nOne of the major gate failures is do to something being wrong with\nthe apt mirrors. The Acquire group provides an implicit retry on\nnetwork operations which seems like it might be helpful here.\n\nRef: http://linux.die.net/man/5/apt.conf\n\nRelated-Bug: #1286635\n(cherry picked from commit e83f7785a7609284f74667e266e38e12a29b326b)\n\nConflicts:\n\tstack.sh\n\nChange-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27\n'}]",0,102264,630be3b88ba87a4684aec0c4bf7810e7ad924f38,7,2,1,2750,,,0,"retry apt operations to avoid network issues

One of the major gate failures is do to something being wrong with
the apt mirrors. The Acquire group provides an implicit retry on
network operations which seems like it might be helpful here.

Ref: http://linux.die.net/man/5/apt.conf

Related-Bug: #1286635
(cherry picked from commit e83f7785a7609284f74667e266e38e12a29b326b)

Conflicts:
	stack.sh

Change-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27
",git fetch https://review.opendev.org/openstack/devstack refs/changes/64/102264/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,630be3b88ba87a4684aec0c4bf7810e7ad924f38,havana,"# For debian/ubuntu make apt attempt to retry network ops on it's own if is_ubuntu; then echo 'APT::Acquire::Retries ""20"";' | sudo tee /etc/apt/apt.conf.d/80retry fi ",,5,0
openstack%2Fpython-keystoneclient~master~Iabe506fa914ac5e742c0c5f4682ed0471c4a64ca,openstack/python-keystoneclient,master,Iabe506fa914ac5e742c0c5f4682ed0471c4a64ca,Doc build fails if warnings,MERGED,2014-06-19 00:12:45.000000000,2014-06-24 18:38:32.000000000,2014-06-24 18:38:31.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-06-19 00:12:45.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/0a9a8476c70ef4f139c692e5a9b8eca6879fd1d2', 'message': 'Doc build fails if warnings\n\nIf the docstrings are invalid then the commit should fail the gate.\n\nChange-Id: Iabe506fa914ac5e742c0c5f4682ed0471c4a64ca\n'}]",0,101061,0a9a8476c70ef4f139c692e5a9b8eca6879fd1d2,13,5,1,6486,,,0,"Doc build fails if warnings

If the docstrings are invalid then the commit should fail the gate.

Change-Id: Iabe506fa914ac5e742c0c5f4682ed0471c4a64ca
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/61/101061/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0a9a8476c70ef4f139c692e5a9b8eca6879fd1d2,doc_cleanup,[pbr] warnerrors = True ,,3,0
openstack%2Fpython-keystoneclient~master~I565c78ef8910353c4e1ce1641b42fba7cdbd77d8,openstack/python-keystoneclient,master,I565c78ef8910353c4e1ce1641b42fba7cdbd77d8,Imports to fix build warnings,MERGED,2014-06-12 19:43:22.000000000,2014-06-24 18:28:11.000000000,2014-06-24 18:28:10.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1091}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-06-12 19:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/850684f5682273ade4d0082eff0b2adf3514873d', 'message': 'Imports to fix build warnings\n\nThere were warnings generated during the build due to missing\nattributes, like this:\n\n keystoneclient.rst:7: WARNING: missing attribute mentioned in\n   :members: or __all__: module keystoneclient.__init__, attribute\n   v2_0\n\nThis is fixed by importing the symbol in __init__.\n\nChange-Id: I565c78ef8910353c4e1ce1641b42fba7cdbd77d8\n'}, {'number': 2, 'created': '2014-06-19 00:12:45.000000000', 'files': ['keystoneclient/apiclient/__init__.py', 'keystoneclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6659902a731767b3405d68e515c8edcc3af81119', 'message': 'Imports to fix build warnings\n\nThere were warnings generated during the build due to missing\nattributes, like this:\n\n keystoneclient.rst:7: WARNING: missing attribute mentioned in\n   :members: or __all__: module keystoneclient.__init__, attribute\n   v2_0\n\nThis is fixed by importing the symbol in __init__.\n\nCloses-Bug: #1315523\n\nChange-Id: I565c78ef8910353c4e1ce1641b42fba7cdbd77d8\n'}]",4,99745,6659902a731767b3405d68e515c8edcc3af81119,38,8,2,6486,,,0,"Imports to fix build warnings

There were warnings generated during the build due to missing
attributes, like this:

 keystoneclient.rst:7: WARNING: missing attribute mentioned in
   :members: or __all__: module keystoneclient.__init__, attribute
   v2_0

This is fixed by importing the symbol in __init__.

Closes-Bug: #1315523

Change-Id: I565c78ef8910353c4e1ce1641b42fba7cdbd77d8
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/45/99745/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/__init__.py'],1,850684f5682273ade4d0082eff0b2adf3514873d,doc_cleanup,from keystoneclient import access from keystoneclient import client from keystoneclient import exceptions from keystoneclient import generic from keystoneclient import httpclient from keystoneclient import service_catalog from keystoneclient import v2_0 from keystoneclient import v3 ,,9,0
openstack%2Fpuppet-neutron~master~I68f3414ef56290ca27d11f8cf26febc100741d46,openstack/puppet-neutron,master,I68f3414ef56290ca27d11f8cf26febc100741d46,Set default metadata backlog to 4096,MERGED,2014-06-08 14:05:10.000000000,2014-06-24 18:23:49.000000000,2014-06-10 12:10:44.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 6967}]","[{'number': 1, 'created': '2014-06-08 14:05:10.000000000', 'files': ['spec/classes/neutron_agents_metadata_spec.rb', 'manifests/agents/metadata.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1055a125eb767d08028ab9818e4bbc2fb0009303', 'message': 'Set default metadata backlog to 4096\n\nWe already optimize the metadata agent by running it in multi-workers,\nwe need by default to set the metadata backlog value.\nInspired from 19:34: https://www.youtube.com/watch?v=AF9r_VQrcJ0\nand https://review.openstack.org/#/c/95372\n\nChange-Id: I68f3414ef56290ca27d11f8cf26febc100741d46\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}]",0,98633,1055a125eb767d08028ab9818e4bbc2fb0009303,11,3,1,3153,,,0,"Set default metadata backlog to 4096

We already optimize the metadata agent by running it in multi-workers,
we need by default to set the metadata backlog value.
Inspired from 19:34: https://www.youtube.com/watch?v=AF9r_VQrcJ0
and https://review.openstack.org/#/c/95372

Change-Id: I68f3414ef56290ca27d11f8cf26febc100741d46
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/33/98633/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_metadata_spec.rb', 'manifests/agents/metadata.pp']",2,1055a125eb767d08028ab9818e4bbc2fb0009303,metadata_backlog,"# [*metadata_backlog*] # (optional) Number of backlog requests to configure the metadata server socket with. # Defaults to 4096 # $metadata_workers = '0', $metadata_backlog = '4096' 'DEFAULT/metadata_backlog': value => $metadata_backlog;", $metadata_workers = '0',9,1
openstack%2Fos-collect-config~master~Id185bb8f180f169072a821b95a774a297db8db1e,openstack/os-collect-config,master,Id185bb8f180f169072a821b95a774a297db8db1e,Updated from global requirements,MERGED,2014-05-28 19:19:40.000000000,2014-06-24 18:11:19.000000000,2014-06-24 18:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 8041}, {'_account_id': 8042}, {'_account_id': 9369}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-05-28 19:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/7fef660158254a20a22da093d18579cd661ccfd2', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 2, 'created': '2014-05-29 16:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/211160b0bbf5185db1f9d598c24331d4e352ff9e', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 3, 'created': '2014-05-30 16:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/ade5e08157512582201053d0c8ebb271b27b36bf', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 4, 'created': '2014-06-04 15:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/b020336787327ad42dfe8d85c5176c20c0b5986b', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 5, 'created': '2014-06-10 14:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/3c844f464d45b400647f0d4d943740da153d0c1b', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 6, 'created': '2014-06-11 01:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/567d51bbca14dffb6684a7d665a8c1cf515f6d84', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 7, 'created': '2014-06-13 22:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/f7d195d5d58f64cb4c9ecd885b068025e87caee1', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 8, 'created': '2014-06-16 09:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/a85ce0066b474f14efea348ed76f11dd491297e8', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 9, 'created': '2014-06-17 15:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/0bd16b3ad0b5b5ce5c1a95368b7a44f73f791072', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 10, 'created': '2014-06-17 21:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/720ee852e792c28b261ff2221c44d2fc69aaa797', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}, {'number': 11, 'created': '2014-06-18 00:46:48.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/308aeb19db7eff9a90988326ffdc153cbd71a60b', 'message': 'Updated from global requirements\n\nChange-Id: Id185bb8f180f169072a821b95a774a297db8db1e\n'}]",0,96234,308aeb19db7eff9a90988326ffdc153cbd71a60b,58,6,11,11131,,,0,"Updated from global requirements

Change-Id: Id185bb8f180f169072a821b95a774a297db8db1e
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/34/96234/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7fef660158254a20a22da093d18579cd661ccfd2,openstack/requirements,"sphinx>=1.2.1,<1.3","sphinx>=1.1.2,<1.2",1,1
openstack%2Fswift~feature%2Fec~I4acb026cd21bae8078dd4179d232420811ddb3b0,openstack/swift,feature/ec,I4acb026cd21bae8078dd4179d232420811ddb3b0,Adding Erasure Code policy support,ABANDONED,2013-10-14 14:16:32.000000000,2014-06-24 18:08:17.000000000,,"[{'_account_id': 5189}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 8433}]","[{'number': 1, 'created': '2013-10-14 14:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/428ff2cb5063b1aa74ade4d631b335e868f90720', 'message': ""Adding Erasure Code policy support\n\nTrying to support EC on key code path\n * Adding EC codes from pyeclib, not sure how to use\n * Adding ECObjectIterable to return the contents of EC objects\n * Filtering EC requests with some helper func\n\nWith some basic codes it should be much easier to talk about the\ndetail design. It's still very buggy.\n\nChange-Id: I4acb026cd21bae8078dd4179d232420811ddb3b0\n""}, {'number': 2, 'created': '2013-10-16 10:55:19.000000000', 'files': ['requirements.txt', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7b6f8972810dc167264a6bf2671d99dfd610c7de', 'message': ""Adding Erasure Code policy support\n\nTrying to support EC on key code path\n * Import pyeclib, all EC requests are calling into this\n * Adding ECObjectIterable to return the contents of EC objects\n * Filtering EC requests with some helper func\n\nWith some basic codes it should be much easier to talk about the\ndetail design. It's still very buggy.\n\nChange-Id: I4acb026cd21bae8078dd4179d232420811ddb3b0\n""}]",2,51613,7b6f8972810dc167264a6bf2671d99dfd610c7de,3,4,2,5189,,,0,"Adding Erasure Code policy support

Trying to support EC on key code path
 * Import pyeclib, all EC requests are calling into this
 * Adding ECObjectIterable to return the contents of EC objects
 * Filtering EC requests with some helper func

With some basic codes it should be much easier to talk about the
detail design. It's still very buggy.

Change-Id: I4acb026cd21bae8078dd4179d232420811ddb3b0
",git fetch https://review.opendev.org/openstack/swift refs/changes/13/51613/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ec.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py']",3,428ff2cb5063b1aa74ade4d631b335e868f90720,bp/ec-proxy-work," #Assuming there's a 'type' in swift.conf to tell if this policy is #an redudent copy like or erasure code like def get_policy_type(self, policy_idx): """""" Get the policy type. :policy_idx: policy index as defined in swift.conf :returns: policy type """""" if policy_idx is None: policy_idx = 0 else: # makes it easier for callers to just pass in a header value policy_idx = int(policy_idx) policy = self.policies.get_by_index(policy_idx) if not policy: raise ValueError(""No policy with index %d"" % policy_idx) return policy.ptype ",,827,1
openstack%2Fswift~feature%2Fec~I0b61d3fb3a042c2c78ab1ef7e1d3fe55689a340c,openstack/swift,feature/ec,I0b61d3fb3a042c2c78ab1ef7e1d3fe55689a340c,Trying out review dependencies again,ABANDONED,2013-09-04 18:57:01.000000000,2014-06-24 18:06:33.000000000,,"[{'_account_id': 4476}, {'_account_id': 8600}]","[{'number': 1, 'created': '2013-09-04 18:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/244971172299da8fe93ba8a9b030dc9662fbdec5', 'message': ""Trying out review dependencies again\n\nHope this don't break. If anyone see's this ignore please.\n\nChange-Id: I0b61d3fb3a042c2c78ab1ef7e1d3fe55689a340c\n""}, {'number': 2, 'created': '2013-09-04 19:19:38.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/swift/commit/49b98d17a78963e0bd44fa866160a133c768e59f', 'message': ""Trying out review dependencies again\n\nHope this don't break. If anyone see's this ignore please.\nAmending old commit\n\nChange-Id: I0b61d3fb3a042c2c78ab1ef7e1d3fe55689a340c\n""}]",0,45096,49b98d17a78963e0bd44fa866160a133c768e59f,2,2,2,4476,,,0,"Trying out review dependencies again

Hope this don't break. If anyone see's this ignore please.
Amending old commit

Change-Id: I0b61d3fb3a042c2c78ab1ef7e1d3fe55689a340c
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/45096/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,244971172299da8fe93ba8a9b030dc9662fbdec5,review_test,#Herp Derp. My name is daniel. Ignore this commit.,,1,0
openstack%2Fswift~feature%2Fec~I92f608690e09bf0fd50e136d641b716cca533fcf,openstack/swift,feature/ec,I92f608690e09bf0fd50e136d641b716cca533fcf,Testing out the new gerrit workflow for updating a dependency. Please ignore this if you can see it.,ABANDONED,2013-09-04 19:03:04.000000000,2014-06-24 18:03:44.000000000,,[],"[{'number': 1, 'created': '2013-09-04 19:03:04.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/swift/commit/22c4aee6991b1363081f8ac76e1c79b5020e92c0', 'message': 'Testing out the new gerrit workflow for updating a dependency.\nPlease ignore this if you can see it.\n\nChange-Id: I92f608690e09bf0fd50e136d641b716cca533fcf\n'}]",0,45098,22c4aee6991b1363081f8ac76e1c79b5020e92c0,1,0,1,8600,,,0,"Testing out the new gerrit workflow for updating a dependency.
Please ignore this if you can see it.

Change-Id: I92f608690e09bf0fd50e136d641b716cca533fcf
",git fetch https://review.opendev.org/openstack/swift refs/changes/98/45098/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,22c4aee6991b1363081f8ac76e1c79b5020e92c0,review_test_dependency,# Updating daniel's stuff. Please ignore it still.,,1,0
openstack%2Fceilometer~master~I3785736455f1f9f548f4c7c06928d6f6cf7d6bc1,openstack/ceilometer,master,I3785736455f1f9f548f4c7c06928d6f6cf7d6bc1,Fix HBase available capabilities list,MERGED,2014-06-24 09:41:35.000000000,2014-06-24 18:00:44.000000000,2014-06-24 18:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-06-24 09:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/349f1a6ae46b81a9c15464de703406085c58e705', 'message': 'Fix HBase available capabilities list\n\nAlarms were not presented in the capabilities list, although this\nfunctionality was already implemented.\n\nChange-Id: I3785736455f1f9f548f4c7c06928d6f6cf7d6bc1\nCloses-bug: #1333610\n'}, {'number': 2, 'created': '2014-06-24 09:48:45.000000000', 'files': ['ceilometer/storage/impl_hbase.py', 'ceilometer/tests/storage/test_impl_hbase.py', 'doc/source/install/dbreco.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2ec87b059ed40fbf0e0532d910f5091f3c081a9b', 'message': 'Fix HBase available capabilities list\n\nAlarms were not presented in the capabilities list, although this\nfunctionality was already implemented. Fixed doc as well.\n\nChange-Id: I3785736455f1f9f548f4c7c06928d6f6cf7d6bc1\nCloses-bug: #1333610\n'}]",0,102159,2ec87b059ed40fbf0e0532d910f5091f3c081a9b,20,8,2,3012,,,0,"Fix HBase available capabilities list

Alarms were not presented in the capabilities list, although this
functionality was already implemented. Fixed doc as well.

Change-Id: I3785736455f1f9f548f4c7c06928d6f6cf7d6bc1
Closes-bug: #1333610
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/59/102159/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_hbase.py', 'ceilometer/tests/storage/test_impl_hbase.py']",2,349f1a6ae46b81a9c15464de703406085c58e705,bug/1333610," 'alarms': {'query': {'simple': True, 'history': {'query': {'simple': True,"," 'alarms': {'query': {'simple': False, 'history': {'query': {'simple': False,",6,2
openstack%2Fdevstack~master~I67aca97770cd6f89072e881ae37e39d70bfaba53,openstack/devstack,master,I67aca97770cd6f89072e881ae37e39d70bfaba53,Bump EPEL release rpm for RHEL 7 to 7.0-2,MERGED,2014-06-23 12:19:14.000000000,2014-06-24 18:00:41.000000000,2014-06-24 18:00:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7065}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 12:19:14.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e66da49c2976992286ab54668af28dbb00d6c529', 'message': 'Bump EPEL release rpm for RHEL 7 to 7.0-2\n\nChange-Id: I67aca97770cd6f89072e881ae37e39d70bfaba53\n'}]",0,101875,e66da49c2976992286ab54668af28dbb00d6c529,15,6,1,7065,,,0,"Bump EPEL release rpm for RHEL 7 to 7.0-2

Change-Id: I67aca97770cd6f89072e881ae37e39d70bfaba53
",git fetch https://review.opendev.org/openstack/devstack refs/changes/75/101875/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,e66da49c2976992286ab54668af28dbb00d6c529,rhel7-epel," EPEL_RPM=${RHEL7_EPEL_RPM:-""http://dl.fedoraproject.org/pub/epel/beta/7/x86_64/epel-release-7-0.2.noarch.rpm""}"," EPEL_RPM=${RHEL7_EPEL_RPM:-""http://dl.fedoraproject.org/pub/epel/beta/7/x86_64/epel-release-7-0.1.noarch.rpm""}",1,1
openstack%2Ftempest~master~I890bdbc14c926ba07f43d60ef5544ff37069d5df,openstack/tempest,master,I890bdbc14c926ba07f43d60ef5544ff37069d5df,provide enough time to do expires in obj tests,MERGED,2014-06-23 20:20:26.000000000,2014-06-24 18:00:33.000000000,2014-06-24 18:00:33.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 20:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ec43553679c40ec452ef09fa8ce175f53270c7a', 'message': 'wip: tweak expire tests\n\nThis is an attempt to try to figure out a way to do something\nsmarter here with how long we wait. There are too many assumptions\nbaked into this test on timing at the moment.\n\nChange-Id: I890bdbc14c926ba07f43d60ef5544ff37069d5df\n'}, {'number': 2, 'created': '2014-06-23 22:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c63d6c9bc37feb1ac618203cdc7e974354ad495e', 'message': 'provide enough time to do expires in obj tests\n\nWhen testing object expiration there are a lot of factors in\nplay, including the amount of time that rest calls take between\nwhen we set the expiration, and when we eventually want to check.\nIf the time in the future is too close then our GET calls have\na real chance of 404ing because the object is gone.\n\nSo we should provide more slack to begin with (10 seconds) and\nthen a variable sleep time at the end to check objects 3 seconds\nafter they should have expired.\n\nCloses-Bug: #1304119\n\nChange-Id: I890bdbc14c926ba07f43d60ef5544ff37069d5df\n'}, {'number': 3, 'created': '2014-06-23 22:09:31.000000000', 'files': ['tempest/api/object_storage/test_object_expiry.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/53ce5ae4d662ca2ba961c6d9e3af0a3a89a1be5c', 'message': 'provide enough time to do expires in obj tests\n\nWhen testing object expiration there are a lot of factors in\nplay, including the amount of time that rest calls take between\nwhen we set the expiration, and when we eventually want to check.\nIf the time in the future is too close then our GET calls have\na real chance of 404ing because the object is gone.\n\nSo we should provide more slack to begin with (10 seconds) and\nthen a variable sleep time at the end to check objects 3 seconds\nafter they should have expired.\n\nCloses-Bug: #1304119\n\nChange-Id: I890bdbc14c926ba07f43d60ef5544ff37069d5df\n'}]",1,102000,53ce5ae4d662ca2ba961c6d9e3af0a3a89a1be5c,23,7,3,2750,,,0,"provide enough time to do expires in obj tests

When testing object expiration there are a lot of factors in
play, including the amount of time that rest calls take between
when we set the expiration, and when we eventually want to check.
If the time in the future is too close then our GET calls have
a real chance of 404ing because the object is gone.

So we should provide more slack to begin with (10 seconds) and
then a variable sleep time at the end to check objects 3 seconds
after they should have expired.

Closes-Bug: #1304119

Change-Id: I890bdbc14c926ba07f43d60ef5544ff37069d5df
",git fetch https://review.opendev.org/openstack/tempest refs/changes/00/102000/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/object_storage/test_object_expiry.py'],1,9ec43553679c40ec452ef09fa8ce175f53270c7a,expire,"from tempest.openstack.common import log as loggingLOG = logging.getLogger(__name__) LOG.debug(""Will expire at %s"" % resp['x-delete-at']) time.sleep(15) metadata = {'X-Delete-After': '10'} metadata = {'X-Delete-At': str(int(time.time()) + 10)}", time.sleep(5) metadata = {'X-Delete-After': '3'} metadata = {'X-Delete-At': str(int(time.time()) + 3)},8,3
openstack%2Fdevstack~master~I7d12a13cea9dffda6c1388ce711b6adf76cae72c,openstack/devstack,master,I7d12a13cea9dffda6c1388ce711b6adf76cae72c,XenAPI: Tail output from stack.sh,MERGED,2014-06-24 12:59:59.000000000,2014-06-24 18:00:30.000000000,2014-06-24 18:00:30.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6735}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-24 12:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d7011ee5521e954b11a1797e57b23424ed727a75', 'message': 'WIP: Do not merge\n\nChange-Id: I7d12a13cea9dffda6c1388ce711b6adf76cae72c\n'}, {'number': 2, 'created': '2014-06-24 13:38:37.000000000', 'files': ['tools/xen/install_os_domU.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dc7ebbb9a42c5d497cb8de18842116c76096a72f', 'message': ""XenAPI: Tail output from stack.sh\n\nWhile installing devstack in XenServer's DomU we can easily\ntrack the output so end-users have much more visibility of\nboth what is going on and what (if anything!) went wrong.\n\nChange-Id: I7d12a13cea9dffda6c1388ce711b6adf76cae72c\n""}]",1,102217,dc7ebbb9a42c5d497cb8de18842116c76096a72f,13,5,2,6735,,,0,"XenAPI: Tail output from stack.sh

While installing devstack in XenServer's DomU we can easily
track the output so end-users have much more visibility of
both what is going on and what (if anything!) went wrong.

Change-Id: I7d12a13cea9dffda6c1388ce711b6adf76cae72c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/17/102217/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/install_os_domU.sh'],1,d7011ee5521e954b11a1797e57b23424ed727a75,devstack-fix," # Watch devstack's output pid=`ssh_no_check -q stack@$OS_VM_MANAGEMENT_ADDRESS pgrep run.sh` ssh_no_check -q stack@$OS_VM_MANAGEMENT_ADDRESS ""tail --pid $pid -n +1 -f /tmp/devstack/log/stack.sh"" "," while ssh_no_check -q stack@$OS_VM_MANAGEMENT_ADDRESS ""service devstack status | grep -q running""; do sleep 10 echo -n ""."" done echo ""done!""",4,5
openstack%2Fdevstack~master~I8e0391cd68e29e6d57c0f35517bf4155110861c7,openstack/devstack,master,I8e0391cd68e29e6d57c0f35517bf4155110861c7,Add an environment variable to enable extensions in keystone,MERGED,2014-05-27 14:18:06.000000000,2014-06-24 18:00:26.000000000,2014-06-24 18:00:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 970}, {'_account_id': 2218}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6482}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 9537}, {'_account_id': 10385}, {'_account_id': 11258}, {'_account_id': 11457}]","[{'number': 1, 'created': '2014-05-27 14:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/191ade9050c86f526b6bfb8cb6376674ab03a07e', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 2, 'created': '2014-05-27 14:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/bd181076f1105599bd2cd84feeafb378745f26fa', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 3, 'created': '2014-05-27 14:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/432dab4e22019165aff7bdbd9fba6b18c4def295', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 4, 'created': '2014-05-27 14:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc5be399602d564de8ae5540a395f11476321734', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 5, 'created': '2014-05-27 22:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/aa8fdbe0aa6d347789e9b6e1fd379f927919647f', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 6, 'created': '2014-05-28 19:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/777b8acaa55554687d904db15e6880d1bc06a795', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 7, 'created': '2014-05-28 21:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e8e87896161f0d76bfe6268971d27ed83e83522', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 8, 'created': '2014-06-02 09:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2a859a6a74e2b5f4414a509586699cd9ce02895f', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}, {'number': 9, 'created': '2014-06-24 08:10:15.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/00da58a0da77e168b8fe01e8909e5f2f8815172e', 'message': 'Add an environment variable to enable extensions in keystone\n\nFollowing https://review.openstack.org/#/c/44401/3\n\nChange-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7\nCloses-Bug: #1218733\nCo-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>\n'}]",20,95778,00da58a0da77e168b8fe01e8909e5f2f8815172e,98,15,9,9537,,,0,"Add an environment variable to enable extensions in keystone

Following https://review.openstack.org/#/c/44401/3

Change-Id: I8e0391cd68e29e6d57c0f35517bf4155110861c7
Closes-Bug: #1218733
Co-Authored-By: Yong Sheng Gong <gongysh@unitedstack.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/95778/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,191ade9050c86f526b6bfb8cb6376674ab03a07e,bug/1218733,"# Set up additional extensions, such as oauth1, endpoint_filter # Example of KEYSTONE_ADDITIONAL_EXTENSIONS=(oauth1:oauth_extension endpoint_filter:endpoint_filter_extension) KEYSTONE_ADDITIONAL_EXTENSIONS=${KEYSTONE_ADDITIONAL_EXTENSIONS:-} # Add keystone extension into keystone v3 application pipeline for extension_value in ""${KEYSTONE_ADDITIONAL_EXTENSIONS}"" ; do api_v3=$(iniget $KEYSTONE_PASTE_INI pipeline:api_v3 pipeline) extension=$(echo $api_v3 | sed -ne ""/${extension_value}/ p;"" ) if [[ ! -n $extension ]]; then api_v3_extension=$(echo $api_v3 | sed -ne ""s/service_v3/${extension_value} service_v3/p;"" ) iniset $KEYSTONE_PASTE_INI pipeline:api_v3 pipeline ""$api_v3_extension"" fi done for extension_value in ""${KEYSTONE_ADDITIONAL_EXTENSIONS}"" ; do $KEYSTONE_DIR/bin/keystone-manage db_sync --extension ""${extension_value}"" done ",,18,0
openstack%2Fsahara-dashboard~master~I99d2ee9c65e396c0ac29365faa00b509634de14d,openstack/sahara-dashboard,master,I99d2ee9c65e396c0ac29365faa00b509634de14d,Fixed issue with required field,MERGED,2014-06-23 15:06:01.000000000,2014-06-24 17:54:28.000000000,2014-06-24 17:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7126}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-06-23 15:06:01.000000000', 'files': ['saharadashboard/clusters/workflows/create.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/488b592686cdf689e9ddc02adadb95190ffaa6dd', 'message': ""Fixed issue with required field\n\nField 'Cluster Template' marked as required, because\nuser can't create cluster if this parameter is not defined.\n\nChange-Id: I99d2ee9c65e396c0ac29365faa00b509634de14d\nCloses-Bug: #1333183\n""}]",0,101927,488b592686cdf689e9ddc02adadb95190ffaa6dd,18,12,1,7227,,,0,"Fixed issue with required field

Field 'Cluster Template' marked as required, because
user can't create cluster if this parameter is not defined.

Change-Id: I99d2ee9c65e396c0ac29365faa00b509634de14d
Closes-Bug: #1333183
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/27/101927/1 && git format-patch -1 --stdout FETCH_HEAD,['saharadashboard/clusters/workflows/create.py'],1,488b592686cdf689e9ddc02adadb95190ffaa6dd,, required=True), required=False),1,1
openstack%2Fdevstack~master~Iae2f09784ffa38efd2f858513bf284c84c32edac,openstack/devstack,master,Iae2f09784ffa38efd2f858513bf284c84c32edac,Handle failure of openstack endpoint,MERGED,2014-06-24 05:08:02.000000000,2014-06-24 17:54:19.000000000,2014-06-24 17:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-24 05:08:02.000000000', 'files': ['tools/create_userrc.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bcdce9ea12a5a0613936bbfdc13f43f7f0c13d97', 'message': 'Handle failure of openstack endpoint\n\nChange 4f7bf6963a1e9ae03bc0ae9189874cba561ad62f introduced finding the\nendpoint via ""openstack endpoint show"" only.  Previously that output\nwas piped through grep, etc. so it handled fell back to a blank\noutput when the endpoints were not available.\n\nIgnore failures of this command so the blank output is matched\n\nChange-Id: Iae2f09784ffa38efd2f858513bf284c84c32edac\n'}]",0,102104,bcdce9ea12a5a0613936bbfdc13f43f7f0c13d97,12,7,1,7118,,,0,"Handle failure of openstack endpoint

Change 4f7bf6963a1e9ae03bc0ae9189874cba561ad62f introduced finding the
endpoint via ""openstack endpoint show"" only.  Previously that output
was piped through grep, etc. so it handled fell back to a blank
output when the endpoints were not available.

Ignore failures of this command so the blank output is matched

Change-Id: Iae2f09784ffa38efd2f858513bf284c84c32edac
",git fetch https://review.opendev.org/openstack/devstack refs/changes/04/102104/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/create_userrc.sh'],1,bcdce9ea12a5a0613936bbfdc13f43f7f0c13d97,handle-endpoint-fail,EC2_URL=$(openstack endpoint show -f value -c publicurl ec2 || true)S3_URL=$(openstack endpoint show -f value -c publicurl s3 || true),EC2_URL=$(openstack endpoint show -f value -c publicurl ec2)S3_URL=$(openstack endpoint show -f value -c publicurl s3),2,2
openstack%2Fdevstack~master~Ia110bd2d0a222e438189c10a9c1a236bd7ea3d0e,openstack/devstack,master,Ia110bd2d0a222e438189c10a9c1a236bd7ea3d0e,Use curl to download from github.com,MERGED,2014-06-24 10:17:11.000000000,2014-06-24 17:54:15.000000000,2014-06-24 17:54:14.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6735}, {'_account_id': 7118}, {'_account_id': 7369}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-24 10:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/687187d9a055a9d8d95d548ac8152ca2be5488f5', 'message': 'Use curl to download from github.com\n\nGithub recently removed some sslv3 ciphers - wget seems to only\nenable a subset of the ciphers available so fails now, but curl\ncontinues to succeed.\n\nChange-Id: Ia110bd2d0a222e438189c10a9c1a236bd7ea3d0e\n'}, {'number': 2, 'created': '2014-06-24 10:37:42.000000000', 'files': ['tools/xen/prepare_guest_template.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8230296ec39abca84d3763f653b0b7d5f300ea82', 'message': 'Use curl to download from github.com\n\nGithub recently removed some sslv3 ciphers - wget seems to only\nenable a subset of the ciphers available so fails now, but curl\ncontinues to succeed.\n\nUse --no-sessionid to work around\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1098711\n\nChange-Id: Ia110bd2d0a222e438189c10a9c1a236bd7ea3d0e\n'}]",0,102173,8230296ec39abca84d3763f653b0b7d5f300ea82,20,7,2,6735,,,0,"Use curl to download from github.com

Github recently removed some sslv3 ciphers - wget seems to only
enable a subset of the ciphers available so fails now, but curl
continues to succeed.

Use --no-sessionid to work around
https://bugzilla.redhat.com/show_bug.cgi?id=1098711

Change-Id: Ia110bd2d0a222e438189c10a9c1a236bd7ea3d0e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/73/102173/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/prepare_guest_template.sh'],1,687187d9a055a9d8d95d548ac8152ca2be5488f5,," curl -L -o ""$XS_TOOLS_FILE_NAME"" $TOOLS_URL", wget $TOOLS_URL -O $XS_TOOLS_FILE_NAME,1,1
openstack%2Fnova~master~I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126,openstack/nova,master,I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126,XenAPI: disable/enable host will be failed when using XenServer,MERGED,2013-11-17 07:08:06.000000000,2014-06-24 17:54:04.000000000,2014-06-24 17:54:02.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 3068}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 5652}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 7629}, {'_account_id': 8163}, {'_account_id': 8430}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2013-11-17 07:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7b36b216ca317efae35500925bb9712accb359c', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 2, 'created': '2013-11-18 15:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38685257c79f22f9864ceb069278362b123a994e', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 3, 'created': '2013-11-19 16:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01ba2b14dd522666b09c3af9932a72ff53a281f7', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 4, 'created': '2013-11-20 04:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9449ed8ceae6c4e044d404612f42d3a4841769e0', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 5, 'created': '2013-11-21 05:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9aece4dab8d69609d2d7ea7fa7ac1d4cb4638a7e', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 6, 'created': '2013-12-04 02:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38c87ccaae7c6f721dbb451a1e7fa1d0fe29fa7f', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 7, 'created': '2013-12-04 13:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8ee2ad6b3d74fb5542b0b3da5a242f18b1673c9', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 8, 'created': '2013-12-09 07:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffccb18e8de7426bf7680e22dfa3b5468db2174c', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 9, 'created': '2014-01-04 09:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c357aa8397face7135224d0fef7734203824c597', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 10, 'created': '2014-02-05 16:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49e64ac4acfe419be000be8e26a4283b9c8618b4', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 11, 'created': '2014-03-08 02:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be7a90880f6372ae473b1f4fb7376b4c816e7ea4', 'message': 'disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was transfer host as parameter for the rpc call of\nset_host_enabled.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 12, 'created': '2014-03-13 16:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d608f739fa509f7dd8bfc2b1837cb552680b9974', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 13, 'created': '2014-03-14 03:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ec010697e38413f64a6572d40f2710ca8b853b1', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 14, 'created': '2014-05-07 12:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a4eda9b328289df095a4b12994c764521edfed7', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 15, 'created': '2014-05-07 23:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0acc084a22484ddc29fc679f9646a0f25247c424', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 16, 'created': '2014-05-22 16:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d16eaddfc10a60163dd97f6bec344d493e5eb36', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\nThis patch was let the API of set_host_enabled() use CONF.host.\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\nCloses-Bug: #1251943\n'}, {'number': 17, 'created': '2014-05-25 02:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/704d96dea4350981ac918b4d07445af4c08f3976', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nCloses-Bug: #1251943\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\n'}, {'number': 18, 'created': '2014-05-30 10:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd863c31f17314d93fd541a7dc8673693b9141c', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nCloses-Bug: #1251943\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\n'}, {'number': 19, 'created': '2014-06-18 02:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc3d7300af48767bb6b92cd6bdb088ee08dd4e66', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nCloses-Bug: #1251943\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\n'}, {'number': 20, 'created': '2014-06-18 13:04:27.000000000', 'files': ['nova/virt/xenapi/driver.py', 'nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f4646b74532d3e75a105290e8333bff92eb838ad', 'message': 'XenAPI: disable/enable host will be failed when using XenServer\n\nWhen disable/enable host with XenServer, the api of set_host_enabled()\nin XenServer driver needs to get service info for the target host, but\nthe rpc call of set_host_enabled() did not transfer target host as\nparameter, this will cause the api call failed.\n\nThis patch was let the API of set_host_enabled() use CONF.host.\n\nCloses-Bug: #1251943\n\nChange-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126\n'}]",26,56812,f4646b74532d3e75a105290e8333bff92eb838ad,165,19,20,7494,,,0,"XenAPI: disable/enable host will be failed when using XenServer

When disable/enable host with XenServer, the api of set_host_enabled()
in XenServer driver needs to get service info for the target host, but
the rpc call of set_host_enabled() did not transfer target host as
parameter, this will cause the api call failed.

This patch was let the API of set_host_enabled() use CONF.host.

Closes-Bug: #1251943

Change-Id: I2b6427df80ee3188d6f7c4eeb4d2e7be300f0126
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/56812/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_host_api.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/rpcapi.py']",3,d7b36b216ca317efae35500925bb9712accb359c,bug/1251943," return cctxt.call(ctxt, 'set_host_enabled', host=host, enabled=enabled)"," return cctxt.call(ctxt, 'set_host_enabled', enabled=enabled)",8,5
openstack%2Fpycadf~master~I3a99ca47662b8590c78d89faf6345ebff6fd771d,openstack/pycadf,master,I3a99ca47662b8590c78d89faf6345ebff6fd771d,Updated from global requirements,MERGED,2014-06-10 14:39:32.000000000,2014-06-24 17:53:59.000000000,2014-06-24 17:53:59.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-10 14:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/de31d5d202c0c8387c696b9ba6a6098d06af5fe6', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 2, 'created': '2014-06-11 01:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/703c4ee7093ada343ba92064dd5207af06be5aab', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 3, 'created': '2014-06-13 22:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/1e0d2478fb46b385209192485cec557a1fbc84c8', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 4, 'created': '2014-06-15 19:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/75d5f4c1677c2d5fc4c80daa9b5676df37f5c8e0', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 5, 'created': '2014-06-16 09:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/43c8b98fd1defbe92aa1e949969e79fe063a305b', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 6, 'created': '2014-06-17 15:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/c7bbb1c7990579d490ac6355e095acbfe15d8099', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 7, 'created': '2014-06-17 21:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/919596978212daa75c3e051d3f2363d64af64670', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 8, 'created': '2014-06-18 00:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/d03da94d90a5a4b7b03d59c8e13a53faa238c1f7', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}, {'number': 9, 'created': '2014-06-20 03:38:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/0fb150cab3979be46c798daf2b2439631aaaeada', 'message': 'Updated from global requirements\n\nChange-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d\n'}]",0,99091,0fb150cab3979be46c798daf2b2439631aaaeada,36,4,9,11131,,,0,"Updated from global requirements

Change-Id: I3a99ca47662b8590c78d89faf6345ebff6fd771d
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/91/99091/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,de31d5d202c0c8387c696b9ba6a6098d06af5fe6,openstack/requirements,"hacking>=0.8.0,<0.10,!=0.9.0","hacking>=0.8.0,<0.9",1,1
openstack%2Fglance~master~I75af34145521f533dcd6f5fd7690f5a68f3b44b3,openstack/glance,master,I75af34145521f533dcd6f5fd7690f5a68f3b44b3,Remove user and key from location in swift,MERGED,2014-06-09 09:24:46.000000000,2014-06-24 17:53:57.000000000,2014-06-24 17:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 5202}, {'_account_id': 7531}, {'_account_id': 7701}, {'_account_id': 9751}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-06-09 09:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6fa54c33aa3f59bfee9a15427639eafe14125c99', 'message': ""Remove user and key from location in swift\n\nThe image locations table stores the swift url for images\nwhich includes the user and key values. This if exposed,\ncan cause security risk. Hence this patch, santizies\nthat information out of the location before storing\nand plugs it back in when it is required.\nIntroduced a new configuration file that supports\nmultiple swift account references. It has the credentials and\nauthurl for each store.  It is specified using\n'swift_store_config_file'.\nIn addition, this patch does the following things:\n\nDifferentiate user and system created swift locations\n\nCurrently we do not differentiate between user supplied\nuri and system created locations that have the account\nreference. This patch introduces new scheme:\n'swift+config' for this purpose.\n\nImage create in V1 should validate the uri in case where location isnt\nspecified.\n\nThis patch ensures that a store is not set while\ncreating an image or updating it.\n\nRelated to bp remove-sensitive-data-from-locations\nImplements blueprint: support-multiple-swift-backends\nImplements bp: v1-image-create-should-validate-the-location-uri\nDocImpact\n\nCo-authored by: sridevik <sridevi.koushik@rackspace.com>,\niccha-sethi <iccha.sethi@rackspace.com>\n\nChange-Id: I75af34145521f533dcd6f5fd7690f5a68f3b44b3\n""}, {'number': 2, 'created': '2014-06-11 06:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bd3a998ec376d67d6ffd86a9338fdf6ad63381d0', 'message': ""Remove user and key from location in swift\n\nThe image locations table stores the swift url for images\nwhich includes the user and key values. This if exposed,\ncan cause security risk. Hence this patch, santizies\nthat information out of the location before storing\nand plugs it back in when it is required.\nIntroduced a new configuration file that supports\nmultiple swift account references. It has the credentials and\nauthurl for each store.  It is specified using\n'swift_store_config_file'.\nIn addition, this patch does the following things:\n\nDifferentiate user and system created swift locations\n\nCurrently we do not differentiate between user supplied\nuri and system created locations that have the account\nreference. This patch introduces new scheme:\n'swift+config' for this purpose.\n\nImage create in V1 should validate the uri in case where location isn't\nspecified.\n\nThis patch ensures that a store is not set while\ncreating an image or updating it.\n\nRelated to bp remove-sensitive-data-from-locations\nImplements blueprint: support-multiple-swift-backends\nImplements bp: v1-image-create-should-validate-the-location-uri\nDocImpact\n\nCo-authored by: sridevik <sridevi.koushik@rackspace.com>,\niccha-sethi <iccha.sethi@rackspace.com>\n\nChange-Id: I75af34145521f533dcd6f5fd7690f5a68f3b44b3\n""}, {'number': 3, 'created': '2014-06-16 15:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b466aaffde54a14c06d70b9e35b9f8ea1e3b0efc', 'message': ""Remove user and key from location in swift\n\nThe image locations table stores the swift url for images\nwhich includes the user and key values. This if exposed,\ncan cause security risk. Hence this patch, santizies\nthat information out of the location before storing\nand plugs it back in when it is required.\nIntroduced a new configuration file that supports\nmultiple swift account references. It has the credentials and\nauthurl for each store.  It is specified using\n'swift_store_config_file'.\nIn addition, this patch does the following things:\n\nDifferentiate user and system created swift locations\n\nCurrently we do not differentiate between user supplied\nuri and system created locations that have the account\nreference. This patch introduces new scheme:\n'swift+config' for this purpose.\n\nImage create in V1 should validate the uri in case where location isn't\nspecified.\n\nThis patch ensures that a store is not set while\ncreating an image or updating it.\n\nRelated to bp remove-sensitive-data-from-locations\nImplements blueprint: support-multiple-swift-backends\nImplements bp: v1-image-create-should-validate-the-location-uri\nDocImpact\n\nCo-authored by: sridevik <sridevi.koushik@rackspace.com>,\niccha-sethi <iccha.sethi@rackspace.com>\n\nChange-Id: I75af34145521f533dcd6f5fd7690f5a68f3b44b3\n""}, {'number': 4, 'created': '2014-06-24 06:43:58.000000000', 'files': ['glance/store/__init__.py', 'glance/tests/unit/common/test_swift_store_utils.py', 'glance/common/exception.py', 'glance/tests/unit/v1/test_api.py', 'glance/common/swift_store_utils.py', 'glance/store/swift.py', 'doc/source/configuring.rst', 'glance/store/base.py', 'etc/glance-swift.conf.sample', 'glance/tests/unit/test_store_location.py', 'etc/glance-api.conf', 'glance/api/v1/images.py', 'glance/tests/unit/test_swift_store.py', 'glance/tests/etc/glance-swift.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/63195aaa3b12e56ae787598e001ac44d62e52865', 'message': ""Remove user and key from location in swift\n\nThe image locations table stores the swift url for images\nwhich includes the user and key values. This if exposed,\ncan cause security risk. Hence this patch, santizies\nthat information out of the location before storing\nand plugs it back in when it is required.\nIntroduced a new configuration file that supports\nmultiple swift account references. It has the credentials and\nauthurl for each store.  It is specified using\n'swift_store_config_file'.\nIn addition, this patch does the following things:\n\nDifferentiate user and system created swift locations\n\nCurrently we do not differentiate between user supplied\nuri and system created locations that have the account\nreference. This patch introduces new scheme:\n'swift+config' for this purpose.\n\nImage create in V1 should validate the uri in case where location isn't\nspecified.\n\nThis patch ensures that a store is not set while\ncreating an image or updating it.\n\nRelated to bp remove-sensitive-data-from-locations\nImplements blueprint: support-multiple-swift-backends\nImplements bp: v1-image-create-should-validate-the-location-uri\nDocImpact\n\nCo-authored by: sridevik <sridevi.koushik@rackspace.com>,\niccha-sethi <iccha.sethi@rackspace.com>,\namalabasha <amala.alungal@rackspace.com>\n\nChange-Id: I75af34145521f533dcd6f5fd7690f5a68f3b44b3\n""}]",14,98722,63195aaa3b12e56ae787598e001ac44d62e52865,45,9,4,7701,,,0,"Remove user and key from location in swift

The image locations table stores the swift url for images
which includes the user and key values. This if exposed,
can cause security risk. Hence this patch, santizies
that information out of the location before storing
and plugs it back in when it is required.
Introduced a new configuration file that supports
multiple swift account references. It has the credentials and
authurl for each store.  It is specified using
'swift_store_config_file'.
In addition, this patch does the following things:

Differentiate user and system created swift locations

Currently we do not differentiate between user supplied
uri and system created locations that have the account
reference. This patch introduces new scheme:
'swift+config' for this purpose.

Image create in V1 should validate the uri in case where location isn't
specified.

This patch ensures that a store is not set while
creating an image or updating it.

Related to bp remove-sensitive-data-from-locations
Implements blueprint: support-multiple-swift-backends
Implements bp: v1-image-create-should-validate-the-location-uri
DocImpact

Co-authored by: sridevik <sridevi.koushik@rackspace.com>,
iccha-sethi <iccha.sethi@rackspace.com>,
amalabasha <amala.alungal@rackspace.com>

Change-Id: I75af34145521f533dcd6f5fd7690f5a68f3b44b3
",git fetch https://review.opendev.org/openstack/glance refs/changes/22/98722/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/__init__.py', 'glance/tests/unit/common/test_swift_store_utils.py', 'glance/common/exception.py', 'glance/tests/unit/v1/test_api.py', 'glance/common/swift_store_utils.py', 'glance/store/swift.py', 'doc/source/configuring.rst', 'glance/store/base.py', 'etc/glance-swift.conf.sample', 'glance/tests/unit/test_store_location.py', 'etc/glance-api.conf', 'glance/api/v1/images.py', 'glance/tests/unit/test_swift_store.py', 'glance/tests/etc/glance-swift.conf']",14,6fa54c33aa3f59bfee9a15427639eafe14125c99,bp/remove-sensitive-data-from-locations,[ref1] user = tenant:user1 key = key1 auth_address = example.com [ref2] user = user2 key = key2 auth_address = http://example.com [store_2] user = tenant:user1 key = key1 auth_address= https://localhost:8080 [store_3] user= tenant:user2 key= key2 auth_address= https://localhost:8080 [store_4] user = tenant:user1 key = key1 auth_address = http://localhost:80 [store_5] user = tenant:user1 key = key1 auth_address = http://localhost [store_6] user = tenant:user1 key = key1 auth_address = https://localhost/v1 ,,691,132
openstack%2Fdevstack~master~I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,openstack/devstack,master,I099f47ed86ad6a3d4296bff4cce75e7f7d946d27,retry apt operations to avoid network issues,MERGED,2014-06-23 12:13:07.000000000,2014-06-24 17:53:55.000000000,2014-06-24 17:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 12:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f67aceeae340aa11753e9e4cafee5bdb2091552e', 'message': 'retry apt operations to avoid network issues\n\nOne of the major gate failures is do to something being wrong with\nthe apt mirrors. The Acquire group provides an implicit retry on\nnetwork operations which seems like it might be helpful here.\n\nRef: http://linux.die.net/man/5/apt.conf\n\nChange-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27\nRelated-Bug: #1286635\n'}, {'number': 2, 'created': '2014-06-23 13:06:30.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e83f7785a7609284f74667e266e38e12a29b326b', 'message': 'retry apt operations to avoid network issues\n\nOne of the major gate failures is do to something being wrong with\nthe apt mirrors. The Acquire group provides an implicit retry on\nnetwork operations which seems like it might be helpful here.\n\nRef: http://linux.die.net/man/5/apt.conf\n\nChange-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27\nRelated-Bug: #1286635\n'}]",0,101870,e83f7785a7609284f74667e266e38e12a29b326b,18,7,2,2750,,,0,"retry apt operations to avoid network issues

One of the major gate failures is do to something being wrong with
the apt mirrors. The Acquire group provides an implicit retry on
network operations which seems like it might be helpful here.

Ref: http://linux.die.net/man/5/apt.conf

Change-Id: I099f47ed86ad6a3d4296bff4cce75e7f7d946d27
Related-Bug: #1286635
",git fetch https://review.opendev.org/openstack/devstack refs/changes/70/101870/2 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,f67aceeae340aa11753e9e4cafee5bdb2091552e,retry,# For debian/ubuntu make apt attempt to retry network ops on it's own if is_ubuntu; then echo 'APT::Acquire::Retries=20' | sudo tee /etc/apt/apt.conf.d/80retry fi ,,5,0
openstack%2Foslo-specs~master~Ic90ba5b007e991e159348a85d40cb67834a855de,openstack/oslo-specs,master,Ic90ba5b007e991e159348a85d40cb67834a855de,Add ChainingRegExpFilter into rootwrap,MERGED,2014-06-06 21:50:29.000000000,2014-06-24 17:53:49.000000000,2014-06-24 17:53:49.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 9176}, {'_account_id': 10115}]","[{'number': 1, 'created': '2014-06-06 21:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/a3732627caa274fd9a554c852ae9eb0ef1fae9e7', 'message': ""Add ChainingRegExpFilter into rootwrap\n\nAdd new filter which accepts utilities prefixed to other commands, such as\n'nice' and 'ionice', to increase maintenability of config files.\n\nBlueprint: chaining-regexp-filter\nChange-Id: Ic90ba5b007e991e159348a85d40cb67834a855de\n""}, {'number': 2, 'created': '2014-06-09 20:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/1a3803b163f61275a3c75dd14bc7bfb3a3575073', 'message': ""Add ChainingRegExpFilter into rootwrap\n\nAdd new filter which accepts utilities prefixed to other commands, such as\n'nice' and 'ionice', to increase maintenability of config files.\n\nBlueprint: chaining-regexp-filter\nChange-Id: Ic90ba5b007e991e159348a85d40cb67834a855de\n""}, {'number': 3, 'created': '2014-06-13 16:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/df7e12bceab5caa0fc7e0ad1a1585177ee3f9ea8', 'message': ""Add ChainingRegExpFilter into rootwrap\n\nAdd new filter which accepts utilities prefixed to other commands, such as\n'nice' and 'ionice', to increase maintenability of config files.\n\nBlueprint: chaining-regexp-filter\nChange-Id: Ic90ba5b007e991e159348a85d40cb67834a855de\n""}, {'number': 4, 'created': '2014-06-19 21:45:02.000000000', 'files': ['specs/juno/chaining-regexp-filter.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/11175ca791b0e230088e113a9209b80aac1ce9c9', 'message': ""Add ChainingRegExpFilter into rootwrap\n\nAdd new filter which accepts utilities prefixed to other commands, such as\n'nice' and 'ionice', to increase maintenability of config files.\n\nBlueprint: chaining-regexp-filter\nChange-Id: Ic90ba5b007e991e159348a85d40cb67834a855de\n""}]",8,98536,11175ca791b0e230088e113a9209b80aac1ce9c9,36,7,4,9176,,,0,"Add ChainingRegExpFilter into rootwrap

Add new filter which accepts utilities prefixed to other commands, such as
'nice' and 'ionice', to increase maintenability of config files.

Blueprint: chaining-regexp-filter
Change-Id: Ic90ba5b007e991e159348a85d40cb67834a855de
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/36/98536/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/chaining-regexp-filter.rst'],1,a3732627caa274fd9a554c852ae9eb0ef1fae9e7,bp/chaining-regexp-filter,"====================================== Add ChainingRegExpFilter into rootwrap ====================================== https://blueprints.launchpad.net/oslo/+spec/chaining-regexp-filter Add new filter which accepts utilities prefixed to other commands, such as 'nice' and 'ionice'. This will increase maintenability of config files. Problem description =================== Currently we don't have a good way to define filters to allow prefix utilities. For example, cinder is using 3 RegExpFilter rules to allow 'ionice' + 'dd' command which cover various 'dd' options. But this is fragile to changes of 'dd' usage (actually these rules are broken now by a bugfix patch for 'dd': https://bugs.launchpad.net/cinder/+bug/1318748 ). Proposed change =============== By adding ChainingRegExpFilter, 'ionice' can be accepted by single rule below safely (that is, accepted only when the following command is acceptable by other filters). ionice: ChainingRegExpFilter, ionice, root, ionice, -c[0-3]( -n[0-7])? This filter regards the length of the regular expressions list as the number of arguments to be checked, and remaining parts are checked by other filters. Alternatives ------------ We could implement a specialized filter class for each prefix command like IpNetnsExecFilter each time it is needed. Impact on Existing APIs ----------------------- None. Security impact --------------- Rules for prefix utilities must be written carefully not to allow unchecked commands executed. For example, it can be dangerous to allowing any string ('.*') for the argument that could be interpreted as command to be executed. Performance Impact ------------------ None. Configuration Impact -------------------- New filter 'ChainingRegExpFilter' will be available. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: tomoki-sekiyama-g Milestones ---------- Target Milestone for completion: Juno-1 Work Items ---------- 1. Implement ChainingRegExpFilter -> https://review.openstack.org/#/c/97336/ Incubation ========== None. Adoption -------- None. Library ------- None. Anticipated API Stabilization ----------------------------- None. Documentation Impact ==================== Usage of ChainingRegExpFilter should be added to the document. Dependencies ============ - This feature provides a good way for Cinder to fix 'ionice' command rules - A cinder patch to implement I/O rate limit requires to execute 'cgexec' prefix utility with rootwrap ( https://review.openstack.org/#/c/92894/ ) References ========== None. .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,128,0
openstack%2Fdesignate~master~Iec62750453f8684201102f22e7bae736df6720a8,openstack/designate,master,Iec62750453f8684201102f22e7bae736df6720a8,Objects should have a concrete list of their fields,MERGED,2014-06-20 19:29:45.000000000,2014-06-24 17:41:28.000000000,2014-06-24 17:41:27.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-06-20 19:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/80bc6b91dd3decaf50494276d5d680cd9f5856a4', 'message': 'Objects should have a concrete list of their fields\n\nObjects should have a concrete list of their fields in order to always be\nable to know if a field is valid for an object, regardless of if the field\nhas had a value set for a particular instance.\n\nAdditionally, Objects now inherit fields from their super-classes, removing\nthe need for special casing RRDATA_FIELDS on RRData objects.\n\nChange-Id: Iec62750453f8684201102f22e7bae736df6720a8\n'}, {'number': 2, 'created': '2014-06-20 19:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d7d7ca266d47f513aa8130bdc9a4f2636ee46cb2', 'message': 'Objects should have a concrete list of their fields\n\nObjects should have a concrete list of their fields in order to always be\nable to know if a field is valid for an object, regardless of if the field\nhas had a value set for a particular instance.\n\nAdditionally, Objects now inherit fields from their super-classes, removing\nthe need for special casing RRDATA_FIELDS on RRData objects.\n\nChange-Id: Iec62750453f8684201102f22e7bae736df6720a8\n'}, {'number': 3, 'created': '2014-06-24 14:32:31.000000000', 'files': ['designate/objects/rrdata_srv.py', 'designate/tests/test_storage/__init__.py', 'designate/objects/rrdata_aaaa.py', 'designate/tests/test_objects/test_base.py', 'designate/api/v1/records.py', 'designate/objects/rrdata_ptr.py', 'designate/objects/base.py', 'designate/objects/rrdata_spf.py', 'designate/objects/rrdata_txt.py', 'designate/objects/tsigkey.py', 'designate/tests/test_objects/__init__.py', 'designate/tests/test_api/test_v1/test_records.py', 'designate/central/service.py', 'designate/objects/tld.py', 'designate/objects/domain.py', 'designate/objects/tenant.py', 'designate/objects/recordset.py', 'designate/objects/rrdata_sshfp.py', 'designate/objects/server.py', 'designate/objects/rrdata_mx.py', 'designate/objects/record.py', 'designate/objects/rrdata_ns.py', 'designate/objects/rrdata_cname.py', 'designate/objects/rrdata_soa.py', 'designate/objects/rrdata_a.py', 'designate/objects/blacklist.py', 'designate/objects/quota.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/625914d469d088407ed8e0893d7ff8ebf13b7a76', 'message': 'Objects should have a concrete list of their fields\n\nObjects should have a concrete list of their fields in order to always be\nable to know if a field is valid for an object, regardless of if the field\nhas had a value set for a particular instance.\n\nAdditionally, Objects now inherit fields from their super-classes, removing\nthe need for special casing RRDATA_FIELDS on RRData objects.\n\nChange-Id: Iec62750453f8684201102f22e7bae736df6720a8\n'}]",7,101632,625914d469d088407ed8e0893d7ff8ebf13b7a76,23,5,3,741,,,0,"Objects should have a concrete list of their fields

Objects should have a concrete list of their fields in order to always be
able to know if a field is valid for an object, regardless of if the field
has had a value set for a particular instance.

Additionally, Objects now inherit fields from their super-classes, removing
the need for special casing RRDATA_FIELDS on RRData objects.

Change-Id: Iec62750453f8684201102f22e7bae736df6720a8
",git fetch https://review.opendev.org/openstack/designate refs/changes/32/101632/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/objects/rrdata_srv.py', 'designate/tests/test_storage/__init__.py', 'designate/objects/rrdata_aaaa.py', 'designate/tests/test_objects/test_base.py', 'designate/api/v1/records.py', 'designate/objects/rrdata_ptr.py', 'designate/objects/base.py', 'designate/objects/rrdata_spf.py', 'designate/objects/rrdata_txt.py', 'designate/objects/tsigkey.py', 'designate/tests/test_objects/__init__.py', 'designate/tests/test_api/test_v1/test_records.py', 'designate/central/service.py', 'designate/objects/tld.py', 'designate/objects/domain.py', 'designate/objects/tenant.py', 'designate/objects/recordset.py', 'designate/objects/rrdata_sshfp.py', 'designate/objects/server.py', 'designate/objects/rrdata_mx.py', 'designate/objects/record.py', 'designate/objects/rrdata_ns.py', 'designate/objects/rrdata_cname.py', 'designate/objects/rrdata_soa.py', 'designate/objects/rrdata_a.py', 'designate/objects/blacklist.py', 'designate/objects/quota.py']",27,80bc6b91dd3decaf50494276d5d680cd9f5856a4,101632,"from designate.objects import base class Quota(base.DesignateObject, base.PersistentObjectMixin):",from designate.objects.base import BaseObject class Quota(BaseObject):,282,129
openstack%2Fswift~feature%2Fec~I9858d972d5be5ce2edfff24307107274a31ba6ad,openstack/swift,feature/ec,I9858d972d5be5ce2edfff24307107274a31ba6ad,Add ability to policies to share rings,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-24 17:35:48.000000000,,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 7479}]","[{'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': ['test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7f5ce0b6660d65c0504e6acf9042e078dbc1c27e', 'message': ""Add ability to policies to share rings\n\nNew key/value pair in the definition of a policy that points to\na different policy's ring instead of the default which assumes\na 1:1 policy to ring relationship.  If the element is included\nerror checking assures that the index specified actually exists.\n\nThis is beneficial for situations where an admin doesn't want\nto partition/separate their hardware into different rings but\nthey still want varrying policies.\n\nChange-Id: I9858d972d5be5ce2edfff24307107274a31ba6ad\n""}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/24c6accbb6b8cd5bdd8732305146d0730eb68fd4', 'message': ""Add ability to policies to share rings\n\nNew key/value pair in the definition of a policy that points to\na different policy's ring instead of the default which assumes\na 1:1 policy to ring relationship.  If the element is included\nerror checking assures that the index specified actually exists.\n\nThis is beneficial for situations where an admin doesn't want\nto partition/separate their hardware into different rings but\nthey still want varrying policies.\n\nChange-Id: I9858d972d5be5ce2edfff24307107274a31ba6ad\n""}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5c99c663ad300420b66dec35a4df2c9fe7539d1d', 'message': ""Add ability to policies to share rings\n\nNew key/value pair in the definition of a policy that points to\na different policy's ring instead of the default which assumes\na 1:1 policy to ring relationship.  If the element is included\nerror checking assures that the index specified actually exists.\n\nThis is beneficial for situations where an admin doesn't want\nto partition/separate their hardware into different rings but\nthey still want varrying policies.\n\nChange-Id: I9858d972d5be5ce2edfff24307107274a31ba6ad\n""}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e3c1d289d87da8824d1d47f13a49d69cac960700', 'message': ""Add ability to policies to share rings\n\nNew key/value pair in the definition of a policy that points to\na different policy's ring instead of the default which assumes\na 1:1 policy to ring relationship.  If the element is included\nerror checking assures that the index specified actually exists.\n\nThis is beneficial for situations where an admin doesn't want\nto partition/separate their hardware into different rings but\nthey still want varrying policies.\n\nChange-Id: I9858d972d5be5ce2edfff24307107274a31ba6ad\n""}]",0,52500,7f5ce0b6660d65c0504e6acf9042e078dbc1c27e,14,3,4,7479,,,0,"Add ability to policies to share rings

New key/value pair in the definition of a policy that points to
a different policy's ring instead of the default which assumes
a 1:1 policy to ring relationship.  If the element is included
error checking assures that the index specified actually exists.

This is beneficial for situations where an admin doesn't want
to partition/separate their hardware into different rings but
they still want varrying policies.

Change-Id: I9858d972d5be5ce2edfff24307107274a31ba6ad
",git fetch https://review.opendev.org/openstack/swift refs/changes/00/52500/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py']",2,7f5ce0b6660d65c0504e6acf9042e078dbc1c27e,share," def __init__(self, idx, name, is_default=False, object_ring=None, ring_num=None): if ring_num is None: self.ring_num = self.idx else: self.ring_num = int(ring_num) if self.idx == 0 or self.ring_num == 0: return 'object-%d' % self.ring_num # Make sure if ring_num is specified, that it refs a valid policy for pol in pols: if self.get_by_index(pol.ring_num) is None: raise ValueError(""Invalid ring_num %s"" % pol.ring_num) try: ring_num = conf.get(section, 'ring_num') except NoOptionError: ring_num = None is_default=config_true_value(is_default), ring_num=ring_num))"," def __init__(self, idx, name, is_default=False, object_ring=None): if self.idx == 0: return 'object-%d' % self.idx is_default=config_true_value(is_default)))",31,5
openstack%2Fswift~feature%2Fec~I94f6d11ad668d39f50f5c57517a2c375b03711a6,openstack/swift,feature/ec,I94f6d11ad668d39f50f5c57517a2c375b03711a6,New iter_nodes_ec to 'insert' handoff when primay fail,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-24 17:35:33.000000000,,"[{'_account_id': 3}, {'_account_id': 5189}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': ['test/unit/proxy/test_server.py', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/542bd2a1d6240fe8897dc17078552f5f3e225d49', 'message': ""New iter_nodes_ec to 'insert' handoff when primay fail\n\nWIP\n\nWhen primary fails, the handoff will be inserted to fullfil the\nnode list. This would save lots of data moving when the node\nrejoins the cluster in EC. Also disable sort_nodes to keep the\nchunk seqence the same as the node sequence in the ring.\n\nChange-Id: I94f6d11ad668d39f50f5c57517a2c375b03711a6\nbp: ec-ring\n""}]",0,65893,542bd2a1d6240fe8897dc17078552f5f3e225d49,8,2,1,5189,,,0,"New iter_nodes_ec to 'insert' handoff when primay fail

WIP

When primary fails, the handoff will be inserted to fullfil the
node list. This would save lots of data moving when the node
rejoins the cluster in EC. Also disable sort_nodes to keep the
chunk seqence the same as the node sequence in the ring.

Change-Id: I94f6d11ad668d39f50f5c57517a2c375b03711a6
bp: ec-ring
",git fetch https://review.opendev.org/openstack/swift refs/changes/93/65893/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'swift/proxy/server.py']",2,542bd2a1d6240fe8897dc17078552f5f3e225d49,bp/ec-ring," def iter_nodes_ec(self, ring, partition, node_iter=None): """""" Yields nodes for a ring partition, skipping over error limited nodes and stopping at the configurable number of nodes. If a node yielded subsequently gets error limited, an extra node will be yielded to take its place. Note that if you're going to iterate over this concurrently from multiple greenthreads, you'll want to use a swift.common.utils.GreenthreadSafeIterator to serialize access. Otherwise, you may get ValueErrors from concurrent access. (You also may not, depending on how logging is configured, the vagaries of socket IO and eventlet, and the phase of the moon.) :param ring: ring to get yield nodes from :param partition: ring partition to yield nodes for :param node_iter: optional iterable of nodes to try. Useful if you want to filter or reorder the nodes. """""" part_nodes = ring.get_part_nodes(partition) if node_iter is None: node_iter = itertools.chain(part_nodes, ring.get_more_nodes(partition)) num_primary_nodes = len(part_nodes) # Use of list() here forcibly yanks the first N nodes (the primary # nodes) from node_iter, so the rest of its values are handoffs. # Don't sort it here to keep the sequence in the ring primary_nodes = list(itertools.islice(node_iter, num_primary_nodes)) handoff_nodes = list(node_iter) nodes_left = self.request_node_count(ring) handoffs = 0 for node in primary_nodes: if not self.error_limited(node): yield node if not self.error_limited(node): nodes_left -= 1 if nodes_left <= 0: return #replace with handoff node elif handoff_nodes: node = handoff_nodes.pop(0) if not self.error_limited(node): handoffs += 1 if self.log_handoffs: self.logger.increment('handoff_count') self.logger.warning( 'Handoff requested (%d)' % handoffs) if handoffs == len(primary_nodes): self.logger.increment('handoff_all_count') yield node if not self.error_limited(node): nodes_left -= 1 if nodes_left <= 0: return for node in handoff_nodes: if not self.error_limited(node): handoffs += 1 if self.log_handoffs: self.logger.increment('handoff_count') self.logger.warning( 'Handoff requested (%d)' % handoffs) if handoffs == len(primary_nodes): self.logger.increment('handoff_all_count') yield node if not self.error_limited(node): nodes_left -= 1 if nodes_left <= 0: return ",,100,0
openstack%2Fswift~feature%2Fec~I0e8ab33c71b25b4240ada1d795640825f5cf06c2,openstack/swift,feature/ec,I0e8ab33c71b25b4240ada1d795640825f5cf06c2,"EC: add new storage policy type, add PyEClib req",ABANDONED,2014-04-28 20:01:23.000000000,2014-06-24 17:35:01.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5189}, {'_account_id': 6198}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 8433}]","[{'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1c348547891be0a4af09283541b69ba92e318107', 'message': ""EC: add new storage policy type, add PyEClib req\n\nThis patch adds support for a new policy type called\n'erasure_coding' to lay the groundwork required to\nsupport Erasure Codes in Swift.\n\nChanges:\n\n - Policy config changes\n   - New policy type 'erasure_coding'\n   - Add ec_type (one of EC implementations exported by\n     PyEClib), ec_k (number of EC data fragments), ec_m\n     (number of EC parity fragments) to swift.conf\n\n - Introduce a PolicyConfig base class to hold policy-\n   specific config parameters.  Inherit ECPolicyConfig\n   to hold ec_type, ec_k and ec_m\n\n - Add EC-specific ring validation and quorum_size to\n   ECPolicyConfig\n\nImplements: blueprint ec-proxy-work\nChange-Id: I0e8ab33c71b25b4240ada1d795640825f5cf06c2\nSigned-off-by: Tushar Gohad <tushar.gohad@intel.com>\n""}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/408b5bb5b6b0924ed9e9bcea1a33925e603c83e9', 'message': ""EC: add new storage policy type, add PyEClib req\n\nThis patch adds support for a new policy type called\n'erasure_coding' to lay the groundwork required to\nsupport Erasure Codes in Swift.\n\nChanges:\n\n - Policy config changes\n   - New policy type 'erasure_coding'\n   - Add ec_type (one of EC implementations exported by\n     PyEClib), ec_k (number of EC data fragments), ec_m\n     (number of EC parity fragments) to swift.conf\n\n - Introduce a PolicyConfig base class to hold policy-\n   specific config parameters.  Inherit ECPolicyConfig\n   to hold ec_type, ec_k and ec_m\n\n - Add EC-specific ring validation and quorum_size to\n   ECPolicyConfig\n\nImplements: blueprint ec-proxy-work\nChange-Id: I0e8ab33c71b25b4240ada1d795640825f5cf06c2\nSigned-off-by: Tushar Gohad <tushar.gohad@intel.com>\n""}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0ebadd1364686e971aa7fc0bd9a57645395f3c44', 'message': ""EC: storage policy support, integrate PyEClib\n\nThis patch adds support for a new policy type called\n'erasure_coding' to lay the groundwork required to\nsupport Erasure Codes in Swift.\n\nChanges:\n\n - Policy config changes\n   - New policy type 'erasure_coding'\n   - Add ec_type (one of EC implementations exported by\n     PyEClib), ec_k (number of EC data fragments), ec_m\n     (number of EC parity fragments) to swift.conf\n\n - Introduce a PolicyConfig base class to hold policy-\n   specific config parameters.  Inherit ECPolicyConfig\n   to hold ec_type, ec_k and ec_m\n\n - Add EC-specific ring validation and quorum_size to\n   ECPolicyConfig\n\nImplements: blueprint ec-proxy-work\nChange-Id: I0e8ab33c71b25b4240ada1d795640825f5cf06c2\nSigned-off-by: Tushar Gohad <tushar.gohad@intel.com>\n""}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': ['requirements.txt', 'swift/common/utils.py', 'test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/92ea5b52c168a2bd2803c7698c83a0ea72d7cc60', 'message': ""EC: add new storage policy type, add PyEClib req\n\nThis patch adds support for a new policy type called\n'erasure_coding' to lay the groundwork required to\nsupport Erasure Codes in Swift.\n\nChanges:\n\n - Policy config changes\n   - New policy type 'erasure_coding'\n   - Add ec_type (one of EC implementations exported by\n     PyEClib), ec_k (number of EC data fragments), ec_m\n     (number of EC parity fragments) to swift.conf\n\n - Introduce a PolicyConfig base class to hold policy-\n   specific config parameters.  Inherit ECPolicyConfig\n   to hold ec_type, ec_k and ec_m\n\n - Add EC-specific ring validation and quorum_size to\n   ECPolicyConfig\n\nImplements: blueprint ec-proxy-work\nChange-Id: I0e8ab33c71b25b4240ada1d795640825f5cf06c2\nSigned-off-by: Tushar Gohad <tushar.gohad@intel.com>\n""}]",0,66482,92ea5b52c168a2bd2803c7698c83a0ea72d7cc60,30,9,4,7485,,,0,"EC: add new storage policy type, add PyEClib req

This patch adds support for a new policy type called
'erasure_coding' to lay the groundwork required to
support Erasure Codes in Swift.

Changes:

 - Policy config changes
   - New policy type 'erasure_coding'
   - Add ec_type (one of EC implementations exported by
     PyEClib), ec_k (number of EC data fragments), ec_m
     (number of EC parity fragments) to swift.conf

 - Introduce a PolicyConfig base class to hold policy-
   specific config parameters.  Inherit ECPolicyConfig
   to hold ec_type, ec_k and ec_m

 - Add EC-specific ring validation and quorum_size to
   ECPolicyConfig

Implements: blueprint ec-proxy-work
Change-Id: I0e8ab33c71b25b4240ada1d795640825f5cf06c2
Signed-off-by: Tushar Gohad <tushar.gohad@intel.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/66482/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'swift/common/utils.py', 'test/unit/common/test_storage_policies.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample']",5,1c348547891be0a4af09283541b69ba92e318107,bp/ec-proxy-work,"# the following declares a policy named 'deepfreeze10+4' which defined to # be policy type 'erasure_coding'. Swift uses PyECLib for Erasure Code # encode/decode functionality. Before you uncomment this section to enable # 'erasure_coding' policies, please make sure you have PyECLib installed. # PyECLib can be downloaded from: # https://bitbucket.org/kmgreen2/pyeclib # Also on PyPi: # https://pypi.python.org/pypi/PyECLib # To help admins choose an Erasure Coding (EC) scheme, PyECLib ships with a # companion tool (pyeclib/tools/pyeclib_conf_tool.py) that allows performance # benchmarking available EC schemes and also creates a sample swift config # entry similar to the one below, for the EC scheme chosen. . #[storage-policy:1] #name = deepfreeze10+4 #type = erasure_coding #ec_type = rs_vand #ec_k = 10 #ec_m = 4 ",,241,5
openstack%2Fswift~feature%2Fec~I0f220869e33c461a4100b21c6324ad725da864fa,openstack/swift,feature/ec,I0f220869e33c461a4100b21c6324ad725da864fa,Add LRUCache to common.utils,ABANDONED,2014-04-29 07:27:42.000000000,2014-06-24 17:33:05.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6e494449bae24a562b32093e2a0a12c184314141', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 2, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f2ebff2a87b73ff14535add9403cf3cbb6026d24', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 3, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8c2d2de863b74e26a7308d7207a555835363b469', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 4, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f6f92b0584c9891979087194704bd327d96267f4', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 5, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c09cc540756c7ca8605fe04afca9eaed674793a0', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 6, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/224fac43b590d0297c6b66e25363895a1ba4a6e6', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 7, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1aa857c135b40d737be226482070b3f07a82a768', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 8, 'created': '2014-05-09 07:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/85370c8240720608e1149a2ff1f9d4a073f77394', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}, {'number': 9, 'created': '2014-05-16 18:57:07.000000000', 'files': ['swift/common/utils.py', 'test/unit/container/test_reconciler.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/29898fc09121380b35fd5d52968dad6c16c4268b', 'message': 'Add LRUCache to common.utils\n\nThis decorator will memonize a function using a fixed size cache that evicts\nthe oldest entries.  It also supports a maxtime paramter to configure a\n""time-to-live"" for entries in the cache.\n\nThe reconciler code uses this to cache computations of the correct storage\npolicy index for a container for 30 seconds.\n\nChange-Id: I0f220869e33c461a4100b21c6324ad725da864fa\n'}]",0,90938,29898fc09121380b35fd5d52968dad6c16c4268b,36,4,9,1179,,,0,"Add LRUCache to common.utils

This decorator will memonize a function using a fixed size cache that evicts
the oldest entries.  It also supports a maxtime paramter to configure a
""time-to-live"" for entries in the cache.

The reconciler code uses this to cache computations of the correct storage
policy index for a container for 30 seconds.

Change-Id: I0f220869e33c461a4100b21c6324ad725da864fa
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/90938/9 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/container/test_reconciler.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py']",4,6e494449bae24a562b32093e2a0a12c184314141,shadow-listings,"import mathclass TestLRUCache(unittest.TestCase): def test_maxsize(self): @utils.LRUCache(maxsize=10) def f(*args): return math.sqrt(*args) _orig_math_sqrt = math.sqrt # setup cache [0-10) for i in range(10): self.assertEqual(math.sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate cache [0-10) with patch('math.sqrt'): for i in range(10): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) # update cache [10-20) for i in range(10, 20): self.assertEqual(math.sqrt(i), f(i)) # cache size is fixed self.assertEqual(f.size(), 10) # validate cache [10-20) with patch('math.sqrt'): for i in range(10, 20): self.assertEqual(_orig_math_sqrt(i), f(i)) # validate un-cached [0-10) with patch('math.sqrt', new=None): for i in range(10): self.assertRaises(TypeError, f, i) # cache unchanged self.assertEqual(f.size(), 10) with patch('math.sqrt'): for i in range(10, 20): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) def test_maxtime(self): @utils.LRUCache(maxtime=30) def f(*args): return math.sqrt(*args) self.assertEqual(30, f.maxtime) _orig_math_sqrt = math.sqrt # setup cache [0-10) for i in range(10): self.assertEqual(math.sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate cache [0-10) with patch('math.sqrt'): for i in range(10): self.assertEqual(_orig_math_sqrt(i), f(i)) self.assertEqual(f.size(), 10) # validate expired [0-10) the_future = time.time() + 30 with patch('math.sqrt', new=None): with patch('time.time', lambda: the_future): for i in range(10): self.assertRaises(TypeError, f, i) # validate recache [10-20) the_future = time.time() + 31 with patch('time.time', lambda: the_future): for i in range(10): self.assertEqual(math.sqrt(i), f(i)) # reuses cache space self.assertEqual(f.size(), 10) def test_set_maxtime(self): @utils.LRUCache(maxtime=30) def f(*args): return math.sqrt(*args) self.assertEqual(30, f.maxtime) self.assertEqual(2, f(4)) self.assertEqual(1, f.size()) # expire everything f.maxtime = 0 # validate un-cached [0-10) with patch('math.sqrt', new=None): self.assertRaises(TypeError, f, 4) def test_set_maxsize(self): @utils.LRUCache(maxsize=10) def f(*args): return math.sqrt(*args) for i in range(12): f(i) self.assertEqual(f.size(), 10) f.maxsize = 4 for i in range(12): f(i) self.assertEqual(f.size(), 4) ",,232,1
openstack%2Fswift~feature%2Fec~Ib9a0dd42c271145e641437dc04d0ebea1e11fc47,openstack/swift,feature/ec,Ib9a0dd42c271145e641437dc04d0ebea1e11fc47,Merge container storage_policy_index values.,ABANDONED,2014-04-10 21:44:31.000000000,2014-06-24 17:32:59.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 5189}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-10 21:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/95e17f4e0231ba0c6036013564104da30af9eab1', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 2, 'created': '2014-04-12 00:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/774c9461e44989fb0f5fcb94cf76e864c88ea5c3', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 3, 'created': '2014-04-17 05:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f9c2c146d281d38d334408472ef95ba1217580d5', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 4, 'created': '2014-04-17 06:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/98a9b122f0cc12c515ad0fc9bbdfc9d04d45b897', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 5, 'created': '2014-04-17 17:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c005d4e1a89fdb531eda332260ebfc8cb63d8698', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 6, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/76651cbb8120b03c18002ae19bcf9c13d9ab6287', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 7, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/22b8c72e40dc778193f3fbd51be4bd853a7a1984', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 8, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/895b9b36240e122c47d9312886c218126a5bca9e', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 9, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2a65f1b1c0152be230efa9ed73741cf299242369', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 10, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ee65c1ae904f9e1e53de2249895edf94cadb4477', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 11, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/36682476f2e04b9267a8baa0fb556863f5af73d6', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 12, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4ab1ce177dd85432dc61d0d9b69e22f101c3cded', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}, {'number': 13, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/unit/container/test_replicator.py', 'swift/container/server.py', 'test/probe/test_container_merge_policy_index.py', 'swift/container/replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ad6238a41ef779b26a6c2d868a4060ab57d1483b', 'message': 'Merge container storage_policy_index values.\n\nKeep status_changed_at in container databases current with status changes that\noccur as a result of container creation, deletion, or re-creation.\n\nMerge container put/delete/created timestamps when handling replicate\nresponses from remote servers in addition to during the handling of the\nREPLICATE request.\n\nWhen storage policies are configured on a cluster send status_changed_at,\nobject_count and storage_policy_index as part of container replication sync\nargs.\n\nUse status_changed_at during replication to determine the oldest active\ncontainer and merge storage_policy_index.\n\nChange-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47\n'}]",2,86720,ad6238a41ef779b26a6c2d868a4060ab57d1483b,55,5,13,1179,,,0,"Merge container storage_policy_index values.

Keep status_changed_at in container databases current with status changes that
occur as a result of container creation, deletion, or re-creation.

Merge container put/delete/created timestamps when handling replicate
responses from remote servers in addition to during the handling of the
REPLICATE request.

When storage policies are configured on a cluster send status_changed_at,
object_count and storage_policy_index as part of container replication sync
args.

Use status_changed_at during replication to determine the oldest active
container and merge storage_policy_index.

Change-Id: Ib9a0dd42c271145e641437dc04d0ebea1e11fc47
",git fetch https://review.opendev.org/openstack/swift refs/changes/20/86720/12 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/db.py', 'swift/container/server.py', 'test/unit/container/test_replicator.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_db_replicator.py', 'test/unit/__init__.py', 'test/unit/common/test_db.py', 'swift/container/replicator.py', 'test/unit/account/test_backend.py', 'swift/container/backend.py']",10,95e17f4e0231ba0c6036013564104da30af9eab1,shadow-listings," def _get_replication_info_missing_defaults(self): # XXX tests parent = super(ContainerBroker, self) return dict(storage_policy_index=0, **parent._get_replication_info_missing_defaults()) def set_storage_policy_index(self, policy_index, timestamp=0): # XXX tests SET storage_policy_index = ?, status_changed_at = MAX(?, status_changed_at) """""", (policy_index, timestamp))"," def set_storage_policy_index(self, policy_index): SET storage_policy_index = ? """""", (policy_index,))",612,45
openstack%2Fswift~feature%2Fec~I3627efcdea75403586dffee46537a60add08bfda,openstack/swift,feature/ec,I3627efcdea75403586dffee46537a60add08bfda,Enqueue misplaced objects during container replication,ABANDONED,2014-04-29 07:27:42.000000000,2014-06-24 17:32:50.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/94c3b2263c3685d7a01fd9699a29f53be40fa291', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 2, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab877197ee43075dd4a53084cf786efcc4851065', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 3, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/76aab74fdb741cf86bddadddec85ab2da9e5322e', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 4, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/871fbb8feeefdb19bc8beae06b770a97ace290b6', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 5, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d94da8f042d7cf52a881c4e56c1d11693452224c', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 6, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1a313b9a3e5e74cc3396b03543ae98a0698d0c03', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 7, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e15ef9cd5d9e33ecfb497f597b82182e46fe6e5d', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}, {'number': 8, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/unit/container/test_replicator.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_db_replicator.py', 'test/unit/__init__.py', 'swift/common/db_replicator.py', 'swift/container/replicator.py', 'swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3739bf0e6ba0aa119ebd997febab1faffeea2f40', 'message': 'Enqueue misplaced objects during container replication\n\nAfter a container database is replicated, a _post_replicate_hook will enqueue\nmisplaced objects for the container-reconciler into the .misplaced_objects\ncontainers.  Items to be reconciled are ""batch loaded"" into the reconciler\nqueue and the end of a container replication cycle by levering container\nreplication itself.\n\nChange-Id: I3627efcdea75403586dffee46537a60add08bfda\n'}]",0,90937,3739bf0e6ba0aa119ebd997febab1faffeea2f40,30,3,8,1179,,,0,"Enqueue misplaced objects during container replication

After a container database is replicated, a _post_replicate_hook will enqueue
misplaced objects for the container-reconciler into the .misplaced_objects
containers.  Items to be reconciled are ""batch loaded"" into the reconciler
queue and the end of a container replication cycle by levering container
replication itself.

Change-Id: I3627efcdea75403586dffee46537a60add08bfda
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/90937/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_replicator.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_db_replicator.py', 'test/unit/__init__.py', 'swift/common/db_replicator.py', 'swift/container/replicator.py', 'swift/common/exceptions.py']",7,94c3b2263c3685d7a01fd9699a29f53be40fa291,shadow-listings,class DeviceUnavailable(SwiftException): pass ,,642,15
openstack%2Fswift~feature%2Fec~Iad42034a078f30fb053c44d1d8dfc927bd59c908,openstack/swift,feature/ec,Iad42034a078f30fb053c44d1d8dfc927bd59c908,Add Storage Policy to container put/delete object,ABANDONED,2014-04-29 07:27:42.000000000,2014-06-24 17:32:43.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 5189}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f01edefc49118d65abf18cd226c07842ac452699', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all requests\nto container severs, including X-Delete containers and all object PUT/DELETE\nrequests.  This header value is persisted in the pickle file for the update\nand sent along with async requests from the object-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 2, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7a100eb0de26151f194cbd5d3e1491f2ebe26f50', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all requests\nto container severs, including X-Delete containers and all object PUT/DELETE\nrequests.  This header value is persisted in the pickle file for the update\nand sent along with async requests from the object-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 3, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68bc2fee56a5e8a29bcbbb068be42d2dfe3485e1', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all requests\nto container severs, including X-Delete containers and all object PUT/DELETE\nrequests.  This header value is persisted in the pickle file for the update\nand sent along with async requests from the object-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 4, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3af376b23940d3adf5377c316c29514471d45e85', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all requests\nto container severs, including X-Delete containers and all object PUT/DELETE\nrequests.  This header value is persisted in the pickle file for the update\nand sent along with async requests from the object-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 5, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/33de1b005fe5c29fc15ec9d8de8514ab4a651ee0', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 6, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6cb37b9e44359dc8691246dfd87580354a369b33', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 7, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2d6de1e7c1f6378cfa7fd3bc9bf33fe88eb634c3', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}, {'number': 8, 'created': '2014-05-16 18:57:07.000000000', 'files': ['swift/obj/updater.py', 'swift/obj/server.py', 'swift/container/server.py', 'test/unit/__init__.py', 'test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2b8bb0372b95fc14d02330e8bff9e363fedce5c8', 'message': 'Add Storage Policy to container put/delete object\n\nThe object-server will send X-Storage-Policy-Index headers with all\nrequests to container severs, including X-Delete containers and all\nobject PUT/DELETE requests.  This header value is persisted in the\npickle file for the update and sent along with async requests from the\nobject-updater as well.\n\nThe container server will extract the X-Storage-Policy-Index header from\nincoming requests and apply it to container broker calls as appropriate\ndefaulting to the legacy storage policy 0 to support seemless migration.\n\nChange-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908\n'}]",0,90936,2b8bb0372b95fc14d02330e8bff9e363fedce5c8,42,5,8,1179,,,0,"Add Storage Policy to container put/delete object

The object-server will send X-Storage-Policy-Index headers with all
requests to container severs, including X-Delete containers and all
object PUT/DELETE requests.  This header value is persisted in the
pickle file for the update and sent along with async requests from the
object-updater as well.

The container server will extract the X-Storage-Policy-Index header from
incoming requests and apply it to container broker calls as appropriate
defaulting to the legacy storage policy 0 to support seemless migration.

Change-Id: Iad42034a078f30fb053c44d1d8dfc927bd59c908
",git fetch https://review.opendev.org/openstack/swift refs/changes/36/90936/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'swift/container/server.py', 'swift/obj/server.py', 'test/unit/obj/test_server.py', 'test/unit/obj/test_updater.py']",5,f01edefc49118d65abf18cd226c07842ac452699,shadow-listings,"import random import itertoolsfrom swift.obj.diskfile import ASYNCDIR_BASE, get_async_dir, DiskFileManagerfrom swift.common import utils, swobfrom test.unit import debug_logger, patch_policies, mocked_http_conn from swift.common.storage_policy import StoragePolicy, POLICIES, POLICY_INDEX def test_obj_put_legacy_updates(self): ts = (normalize_timestamp(t) for t in itertools.count(int(time()))) policy = POLICIES.get_by_index(0) # setup updater conf = { 'devices': self.devices_dir, 'mount_check': 'false', 'swift_dir': self.testdir, } async_dir = os.path.join(self.sda1, get_async_dir(policy.idx)) os.mkdir(async_dir) account, container, obj = 'a', 'c', 'o' # write an async for op in ('PUT', 'DELETE'): self.logger._clear() daemon = object_updater.ObjectUpdater(conf, logger=self.logger) dfmanager = DiskFileManager(conf, daemon.logger) # don't include storage-policy-index in headers_out pickle headers_out = swob.HeaderKeyDict({ 'x-size': 0, 'x-content-type': 'text/plain', 'x-etag': 'd41d8cd98f00b204e9800998ecf8427e', 'x-timestamp': ts.next(), }) data = {'op': op, 'account': account, 'container': container, 'obj': obj, 'headers': headers_out} dfmanager.pickle_async_update(self.sda1, account, container, obj, data, ts.next(), policy.idx) request_log = [] def capture(*args, **kwargs): request_log.append((args, kwargs)) # run once fake_status_codes = [ 200, # object update success 200, # object update success 200, # object update conflict ] with mocked_http_conn(*fake_status_codes, give_connect=capture): daemon.run_once() self.assertEqual(len(fake_status_codes), len(request_log)) for request_args, request_kwargs in request_log: ip, part, method, path, headers, qs, ssl = request_args self.assertEqual(method, op) self.assertEqual(headers[POLICY_INDEX], str(policy.idx)) self.assertEqual(daemon.logger.get_increment_counts(), {'successes': 1, 'unlinks': 1, 'async_pendings': 1}) def test_obj_put_async_updates(self): ts = (normalize_timestamp(t) for t in itertools.count(int(time()))) policy = random.choice(list(POLICIES)) # setup updater conf = { 'devices': self.devices_dir, 'mount_check': 'false', 'swift_dir': self.testdir, } daemon = object_updater.ObjectUpdater(conf, logger=self.logger) async_dir = os.path.join(self.sda1, get_async_dir(policy.idx)) os.mkdir(async_dir) # write an async dfmanager = DiskFileManager(conf, daemon.logger) account, container, obj = 'a', 'c', 'o' op = 'PUT' headers_out = swob.HeaderKeyDict({ 'x-size': 0, 'x-content-type': 'text/plain', 'x-etag': 'd41d8cd98f00b204e9800998ecf8427e', 'x-timestamp': ts.next(), POLICY_INDEX: policy.idx, }) data = {'op': op, 'account': account, 'container': container, 'obj': obj, 'headers': headers_out} dfmanager.pickle_async_update(self.sda1, account, container, obj, data, ts.next(), policy.idx) request_log = [] def capture(*args, **kwargs): request_log.append((args, kwargs)) # run once fake_status_codes = [ 200, # object update success 200, # object update success 200, # object update conflict ] with mocked_http_conn(*fake_status_codes, give_connect=capture): daemon.run_once() self.assertEqual(len(fake_status_codes), len(request_log)) for request_args, request_kwargs in request_log: ip, part, method, path, headers, qs, ssl = request_args self.assertEqual(method, 'PUT') self.assertEqual(headers[POLICY_INDEX], str(policy.idx)) self.assertEqual(daemon.logger.get_increment_counts(), {'successes': 1, 'unlinks': 1, 'async_pendings': 1}) ","from swift.obj.diskfile import ASYNCDIR_BASE, get_async_dirfrom swift.common import utilsfrom test.unit import debug_logger, patch_policies from swift.common.storage_policy import StoragePolicy, POLICIES",163,32
openstack%2Fswift~feature%2Fec~I565d9049d746d26a267fcc6dc366becc57e1029d,openstack/swift,feature/ec,I565d9049d746d26a267fcc6dc366becc57e1029d,Update container storage_policy_index when auditing,ABANDONED,2014-03-26 15:12:16.000000000,2014-06-24 17:32:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 5189}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-03-26 15:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/83ce3fc4804c106ac6a150793913e28e57213685', 'message': 'Update container storage_policy_index when auditing\n\nUpdate ""legacy"" databases to have a 0 SPI in their container_stats\ntable when under auditing\n\nChange-Id: I565d9049d746d26a267fcc6dc366becc57e1029d\n'}, {'number': 2, 'created': '2014-04-02 07:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9e6c3469ed09d0dc23ff33552ef7c212dd3590cf', 'message': 'Update container storage_policy_index when auditing\n\nUpdate ""legacy"" databases to have a 0 SPI in their container_stats\ntable when under auditing\n\nChange-Id: I565d9049d746d26a267fcc6dc366becc57e1029d\n'}, {'number': 3, 'created': '2014-04-08 21:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dee7573085f2e16649acb067369504f308935da1', 'message': 'Update container storage_policy_index when auditing\n\nUpdate ""legacy"" databases schmea during audit if needed.\n\nChange-Id: I565d9049d746d26a267fcc6dc366becc57e1029d\n'}, {'number': 4, 'created': '2014-05-07 21:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8bce06e3909021b0b4968784cce49a55ca76aa88', 'message': 'Update container storage_policy_index when auditing\n\nUpdate ""legacy"" databases schmea during audit if needed.\n\nChange-Id: I565d9049d746d26a267fcc6dc366becc57e1029d\n'}, {'number': 5, 'created': '2014-05-28 05:53:02.000000000', 'files': ['swift/container/auditor.py', 'test/unit/container/test_backend.py', 'test/unit/container/test_auditor.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/73c9a8d40bf7ce63835788974f4c37bc5960aec9', 'message': 'Update container storage_policy_index when auditing\n\nUpdate ""legacy"" databases schmea during audit if needed.\n\nChange-Id: I565d9049d746d26a267fcc6dc366becc57e1029d\n'}]",5,83093,73c9a8d40bf7ce63835788974f4c37bc5960aec9,33,5,5,5189,,,0,"Update container storage_policy_index when auditing

Update ""legacy"" databases schmea during audit if needed.

Change-Id: I565d9049d746d26a267fcc6dc366becc57e1029d
",git fetch https://review.opendev.org/openstack/swift refs/changes/93/83093/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/auditor.py', 'test/unit/container/test_auditor.py']",2,83ce3fc4804c106ac6a150793913e28e57213685,container_migration_rebase,"from contextlib import contextmanagerclass FakeDBConn(object): def __init__(self, has_spi_column): self.has_spi_column = has_spi_column def execute(self, sql_str): if self.has_spi_column: return {'storage_policy_index': 0} else: raise Exception('no such column: storage_policy_index') class FakeContainerBroker(object): @contextmanager def get(self): if self.file.startswith('true_no_spi'): conn = FakeDBConn(False) else: conn = FakeDBConn(True) yield conn if self.file.startswith('true_spi_1'): return {'storage_policy_index': 1} if self.file.startswith('true'): # get_info should always return storage_policy_index value return {'storage_policy_index': 0} def set_storage_policy_index(self, storage_policy_index): with open(self.db_file, 'w+') as f: f.write('{""storage_policy_index"": 0}') # true_no_spi.db: dbfile OK but w/o storage_policy_index column # true_spi.db: dbfile OK and w/ storage_policy_index = 0 # true_spi_1.db: dbfile OK and w/ storage_policy_index = 1 # fail1.db, fail2.db: dbfile error fnames = ['true_no_spi.db', 'true_spi.db', 'true_spi_1.db', for f in files: path = os.path.join(self.testdir, f) with open(path, 'rb') as fn: if f.startswith('true_no_spi'): # auditor will update its container_stat table with spi=0 self.assertEquals('{""storage_policy_index"": 0}', fn.read()) else: # auditor don't touch its container_stat table self.assertEquals(' ', fn.read())","class FakeContainerBroker(object): if self.file.startswith('true'): return 'ok' fnames = ['true1.db', 'true2.db', 'true3.db',",56,3
openstack%2Fswift~feature%2Fec~I938919eb0dde7f473a18c32d1cb26986c1c3c5b7,openstack/swift,feature/ec,I938919eb0dde7f473a18c32d1cb26986c1c3c5b7,Keep status_changed_at up-to-date with status changes.,ABANDONED,2014-04-10 21:19:11.000000000,2014-06-24 17:32:29.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 5189}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-10 21:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fe4fb35fb09c4a874e710aa28ad82f493b9819ed', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra\nUPDATE is issued against the container_stat table to notate the\nx-timestamp of the request.\n\nDuring replication if merge_timestamps causes a container\'s status to\nchange (from DELETED to ACTIVE or vice-versa) the status_changed_at\nfiled is set to the current time.\n\nAccurate reporting of status_changed_at is useful for container\nreplication forensics and allows resolution of ""set on create""\nattributes like the upcoming storage_policy_index.\n\nConflicts:\n\tswift/container/backend.py\n\tswift/container/server.py\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 2, 'created': '2014-04-12 00:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7aec112142366dec4ee81a639c7bc5372c8f750e', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra\nUPDATE is issued against the container_stat table to notate the\nx-timestamp of the request.\n\nDuring replication if merge_timestamps causes a container\'s status to\nchange (from DELETED to ACTIVE or vice-versa) the status_changed_at\nfiled is set to the current time.\n\nAccurate reporting of status_changed_at is useful for container\nreplication forensics and allows resolution of ""set on create""\nattributes like the upcoming storage_policy_index.\n\nConflicts:\n\tswift/container/backend.py\n\tswift/container/server.py\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 3, 'created': '2014-04-17 05:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7590dc5ee4365a5f24c0a485cda37e854258b7f1', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra\nUPDATE is issued against the container_stat table to notate the\nx-timestamp of the request.\n\nDuring replication if merge_timestamps causes a container\'s status to\nchange (from DELETED to ACTIVE or vice-versa) the status_changed_at\nfiled is set to the current time.\n\nAccurate reporting of status_changed_at is useful for container\nreplication forensics and allows resolution of ""set on create""\nattributes like the upcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 4, 'created': '2014-04-17 06:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/da06fab1c484c76e20688701faa342917efb1878', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra\nUPDATE is issued against the container_stat table to notate the\nx-timestamp of the request.\n\nDuring replication if merge_timestamps causes a container\'s status to\nchange (from DELETED to ACTIVE or vice-versa) the status_changed_at\nfiled is set to the current time.\n\nAccurate reporting of status_changed_at is useful for container\nreplication forensics and allows resolution of ""set on create""\nattributes like the upcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 5, 'created': '2014-04-17 17:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/141df92e8d2d3958d3e81054e5bdbab7a41fa301', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra\nUPDATE is issued against the container_stat table to notate the\nx-timestamp of the request.\n\nDuring replication if merge_timestamps causes a container\'s status to\nchange (from DELETED to ACTIVE or vice-versa) the status_changed_at\nfiled is set to the current time.\n\nAccurate reporting of status_changed_at is useful for container\nreplication forensics and allows resolution of ""set on create""\nattributes like the upcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 6, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab8a65c248e7622c57938ab649aac174a7a37a54', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at filed is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 7, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a9396ae8e65c0b74cc82499306362361aa32d56b', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at filed is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 8, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7c61dea5665be6e749e8bd855544025df2332f78', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at filed is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 9, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d470b766b2c1d5228a1e602bd7dfb34612a9fb3', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at filed is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 10, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/53f2b576b7023bc9216a8653afc9460c3c14e6a4', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 11, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/135911af267fef77ea77ec39a68663fa9a7c93c4', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 12, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b8b212e98bb891aa81827999e6741d99283d4007', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}, {'number': 13, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/unit/container/test_replicator.py', 'swift/common/db.py', 'swift/container/server.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'test/unit/account/test_replicator.py', 'test/unit/common/test_db.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7663ef83c44c2b01206e4b9d51829cc3ecd95e68', 'message': 'Keep status_changed_at up-to-date with status changes.\n\nIn particular during container recreation and replication.\n\nWhen a container-server receives a PUT for a deleted database an extra UPDATE\nis issued against the container_stat table to notate the x-timestamp of the\nrequest.\n\nDuring replication if merge_timestamps causes a container\'s status to change\n(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to\nthe current time.\n\nAccurate reporting of status_changed_at is useful for container replication\nforensics and allows resolution of ""set on create"" attributes like the\nupcoming storage_policy_index.\n\nChange-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7\n'}]",0,86714,7663ef83c44c2b01206e4b9d51829cc3ecd95e68,57,5,13,1179,,,0,"Keep status_changed_at up-to-date with status changes.

In particular during container recreation and replication.

When a container-server receives a PUT for a deleted database an extra UPDATE
is issued against the container_stat table to notate the x-timestamp of the
request.

During replication if merge_timestamps causes a container's status to change
(from DELETED to ACTIVE or vice-versa) the status_changed_at field is set to
the current time.

Accurate reporting of status_changed_at is useful for container replication
forensics and allows resolution of ""set on create"" attributes like the
upcoming storage_policy_index.

Change-Id: I938919eb0dde7f473a18c32d1cb26986c1c3c5b7
",git fetch https://review.opendev.org/openstack/swift refs/changes/14/86714/12 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/db.py', 'swift/container/server.py', 'test/unit/container/test_replicator.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'test/unit/account/test_replicator.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py']",9,fe4fb35fb09c4a874e710aa28ad82f493b9819ed,shadow-listings," put_timestamp = ?, status_changed_at = ?, storage_policy_index = ? str(uuid4()), put_timestamp, put_timestamp, storage_policy_index))"," put_timestamp = ?, storage_policy_index = ? str(uuid4()), put_timestamp, storage_policy_index))",627,84
openstack%2Fswift~feature%2Fec~I93fd7d30a3edaba7a847d27086cf859533334bb2,openstack/swift,feature/ec,I93fd7d30a3edaba7a847d27086cf859533334bb2,Update swift-object-info/swift-get-nodes to be storage policy aware,ABANDONED,2014-03-25 08:08:16.000000000,2014-06-24 17:32:22.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 5189}, {'_account_id': 6968}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-03-25 08:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/83fdefa3762dfbfc2ddfb4bdb60b290fc7c3d301', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Extract the storage policy based on the path and add update the\n    Ring locations.\nswift-get-nodes:\n    Extract the storage policy based on the Ring name and update\n    the device location.\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 2, 'created': '2014-03-28 03:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/939ef14d5509ec22a0ecf6268b3406435129adf8', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nWIP\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 3, 'created': '2014-03-31 14:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/841fa00005e4ff545593a6a4dfdac35404867847', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 4, 'created': '2014-04-01 01:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/26e86383d3ee1d8d32d9fd8f501ea49179c5bb1f', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 5, 'created': '2014-05-28 16:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7668e93b72f04f2b86b8f0781d23b1384c199ba1', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 6, 'created': '2014-05-29 15:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c4439c1dea5ca01e72808154be18fa6596f9f883', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 7, 'created': '2014-05-30 16:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5c0e87afebdb83193126f3b7df61c1b94ac4c0e3', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n\n    Also Notify the user if there is missmatch between ring location\n    and the real object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}, {'number': 8, 'created': '2014-05-31 05:30:28.000000000', 'files': ['bin/swift-object-info', 'swift/cli/info.py', 'bin/swift-get-nodes', 'swift/common/utils.py', 'test/unit/cli/test_info.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d550fb30b1be8b0efa50ece58e9d46a6d4c619a0', 'message': 'Update swift-object-info/swift-get-nodes to be storage policy aware\n\nswift-object-info:\n    Allow to specify storage policy name when looking for object info\n    Notify if there is missmatch between ring location and the actual\n    object path in filesystem\n\nswift-get-nodes:\n    Allow to specify storage policy name when looking for account/\n    container/object ring location\n    Notify if there is missmatch between ring and the policy\n\nChange-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2\n'}]",10,82734,d550fb30b1be8b0efa50ece58e9d46a6d4c619a0,66,5,8,5189,,,0,"Update swift-object-info/swift-get-nodes to be storage policy aware

swift-object-info:
    Allow to specify storage policy name when looking for object info
    Notify if there is missmatch between ring location and the actual
    object path in filesystem

swift-get-nodes:
    Allow to specify storage policy name when looking for account/
    container/object ring location
    Notify if there is missmatch between ring and the policy

Change-Id: I93fd7d30a3edaba7a847d27086cf859533334bb2
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/82734/2 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-object-info', 'bin/swift-get-nodes']",2,83fdefa3762dfbfc2ddfb4bdb60b290fc7c3d301,policify_bin," loc = ring_file.rsplit('/', 1)[-1].split('.', 1)[0] if '-' in ring_file: loc = 'objects-' + loc.split('-', 1)[1] else: loc = 'objects' elif '-' in loc and loc.startswith('object'): loc = 'objects-' + loc.split('-', 1)[1]", loc = 'objects',16,4
openstack%2Fswift~feature%2Fec~I15a96adfa876b6b50de707e2e9dff02191e92f3e,openstack/swift,feature/ec,I15a96adfa876b6b50de707e2e9dff02191e92f3e,Add Storage Policies to container.backend,ABANDONED,2014-04-29 07:27:42.000000000,2014-06-24 17:32:16.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbfac59fa60a01bfb1e4fbee76fc8b0358b9f4b7', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 2, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0b36be0f0180a372c16220580e413a5180e92b0b', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 3, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5e7731e93446b4c9f39c2f07eef000f9417c8e8b', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 4, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5b3ecc7339619457eca4e6396d311ab5ce1279ff', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 5, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/493e4066efeaecba0bb3c3d09b73417c7c0cdae0', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 6, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6319d79c1082f1033cfcfb69d988e431c003f581', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 7, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d57560ab52c9c87bb27061bb704e18d5e7f96d06', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}, {'number': 8, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/34150498cee00de16e17b5450550a6d55a97c0ee', 'message': 'Add Storage Policies to container.backend\n\nChange-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e\n'}]",0,90935,34150498cee00de16e17b5450550a6d55a97c0ee,34,4,8,1179,,,0,"Add Storage Policies to container.backend

Change-Id: I15a96adfa876b6b50de707e2e9dff02191e92f3e
",git fetch https://review.opendev.org/openstack/swift refs/changes/35/90935/8 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py']",3,cbfac59fa60a01bfb1e4fbee76fc8b0358b9f4b7,shadow-listings,"POLICY_STAT_TABLE_CREATE = """""" CREATE TABLE policy_stat ( storage_policy_index INTEGER PRIMARY KEY, object_count INTEGER DEFAULT 0, bytes_used INTEGER DEFAULT 0 ); """""" POLICY_STAT_TRIGGER_SCRIPT = """""" CREATE TRIGGER object_insert_policy_stat AFTER INSERT ON object BEGIN UPDATE policy_stat SET object_count = object_count + (1 - new.deleted), bytes_used = bytes_used + new.size WHERE storage_policy_index = new.storage_policy_index; INSERT INTO policy_stat ( storage_policy_index, object_count, bytes_used) SELECT new.storage_policy_index, (1 - new.deleted), new.size WHERE NOT EXISTS( SELECT changes() as change FROM policy_stat WHERE change <> 0 ); UPDATE container_stat SET hash = chexor(hash, new.name, new.created_at); END; CREATE TRIGGER object_delete_policy_stat AFTER DELETE ON object BEGIN UPDATE policy_stat SET object_count = object_count - (1 - old.deleted), bytes_used = bytes_used - old.size WHERE storage_policy_index = old.storage_policy_index; UPDATE container_stat SET hash = chexor(hash, old.name, old.created_at); END; """""" self.create_policy_stat_table(conn, storage_policy_index) deleted INTEGER DEFAULT 0, storage_policy_index INTEGER """""" + POLICY_STAT_TRIGGER_SCRIPT) storage_policy_index INTEGER, reconciler_sync_point INTEGER DEFAULT -1 conn.execute("""""" INSERT INTO container_stat (account, container, created_at, id, put_timestamp, status_changed_at, storage_policy_index) VALUES (?, ?, ?, ?, ?, ?, ?); """""", (self.account, self.container, normalize_timestamp(time.time()), def create_policy_stat_table(self, conn, storage_policy_index=0): """""" Create policy_stat table which is specific to the account DB. Not a part of Pluggable Back-ends, internal to the baseline code. :param conn: DB connection object """""" conn.executescript(POLICY_STAT_TABLE_CREATE) conn.execute("""""" INSERT INTO policy_stat (storage_policy_index) VALUES (?) """""", (storage_policy_index,)) data = pickle.loads(entry.decode('base64')) (name, timestamp, size, content_type, etag, deleted) = data[:6] if len(data) > 6: storage_policy_index = data[6] else: storage_policy_index = 0 'deleted': deleted, 'storage_policy_index': storage_policy_index}) try: row = conn.execute( 'SELECT max(object_count) from policy_stat').fetchone() except sqlite3.OperationalError as err: if not any(msg in str(err) for msg in ( ""no such column: storage_policy_index"", ""no such table: policy_stat"")): raise row = conn.execute( 'SELECT object_count from container_stat').fetchone() def delete_object(self, name, timestamp, storage_policy_index=0): self.put_object(name, timestamp, 0, 'application/deleted', 'noetag', deleted=1, storage_policy_index=storage_policy_index) def put_object(self, name, timestamp, size, content_type, etag, deleted=0, storage_policy_index=0): :param storage_policy_index: the storage policy index for the object 'deleted': deleted, 'storage_policy_index': storage_policy_index} (name, timestamp, size, content_type, etag, deleted, storage_policy_index), trailing_pol = 'c.storage_policy_index' trailing_pol_join = """""" FROM container_stat c LEFT JOIN policy_stat p ON c.storage_policy_index = p.storage_policy_index """""" pre_pol_join = """""" FROM container_stat p """""" data = conn.execute((''' delete_timestamp, status_changed_at, coalesce(p.object_count, 0) AS object_count, coalesce(p.bytes_used, 0) AS bytes_used, reported_put_timestamp, reported_delete_timestamp, reported_object_count, reported_bytes_used, hash, id, %s, %s ''' + trailing_pol_join) % ( trailing_sync, trailing_pol)).fetchone() except sqlite3.OperationalError as err: err_msg = str(err) if all(p in err_msg for p in ( 'no such table:', 'policy_stat')): trailing_pol_join = pre_pol_join elif 'no such column: x_container_sync_point' in err_msg: elif 'no such column: c.storage_policy_index' in err_msg: self.account = data['account'] self.container = data['container'] def get_policy_stats(self): with self.get() as conn: try: info = conn.execute(''' SELECT storage_policy_index, object_count, bytes_used FROM policy_stat ''').fetchall() except sqlite3.OperationalError as err: if not any(msg in str(err) for msg in ( ""no such column: storage_policy_index"", ""no such table: policy_stat"")): raise info = conn.execute(''' SELECT 0 as storage_policy_index, object_count, bytes_used FROM container_stat ''').fetchall() policy_stats = {} for row in info: stats = dict(row) key = stats.pop('storage_policy_index') policy_stats[key] = stats return policy_stats def has_misplaced_objects(self): with self.get() as conn: try: curs = conn.execute("""""" SELECT coalesce(max(object_count), 0) as count FROM policy_stat WHERE storage_policy_index <> ( SELECT storage_policy_index FROM container_stat) """""").fetchone() except sqlite3.OperationalError as err: if not any(msg in str(err) for msg in ( ""no such column: storage_policy_index"", ""no such table: policy_stat"")): raise return False return curs and curs[0] > 0 def set_storage_policy_index(self, policy_index, timestamp=None): if timestamp is None: timestamp = normalize_timestamp(time.time()) def _setit(conn): # XXX test the policy_stat insert conn.execute("""""" INSERT OR IGNORE INTO policy_stat (storage_policy_index) VALUES (?) """""", (policy_index,)) if not any(msg in str(err) for msg in ( ""no such column: storage_policy_index"", ""no such table: policy_stat"")): self._migrate_add_storage_policy(conn) path=None, storage_policy_index=0): orig_tail_query = ''' ORDER BY name LIMIT ? ''' orig_tail_args = [limit - len(results)] # storage policy filter policy_tail_query = ''' AND storage_policy_index = ? ''' + orig_tail_query policy_tail_args = [storage_policy_index] + orig_tail_args tail_query, tail_args = \ policy_tail_query, policy_tail_args try: curs = conn.execute(query + tail_query, tuple(query_args + tail_args)) except sqlite3.OperationalError as err: if 'no such column: storage_policy_index' not in str(err): raise tail_query, tail_args = \ orig_tail_query, orig_tail_args curs = conn.execute(query + tail_query, tuple(query_args + tail_args)) def _really_merge_items(conn): rec.setdefault('storage_policy_index', 0) # legacy AND storage_policy_index = ? conn.execute(query, (rec['name'], rec['created_at'], rec['storage_policy_index'])) query = ''' SELECT 1 FROM object WHERE name = ? AND storage_policy_index = ? ''' if not conn.execute(query, ( rec['name'], rec['storage_policy_index'])).fetchall(): content_type, etag, deleted, storage_policy_index) VALUES (?, ?, ?, ?, ?, ?, ?) rec['content_type'], rec['etag'], rec['deleted'], rec['storage_policy_index']])) with self.get() as conn: try: return _really_merge_items(conn) except sqlite3.OperationalError as err: if 'no such column: storage_policy_index' not in str(err): raise self._migrate_add_storage_policy(conn) return _really_merge_items(conn) def get_reconciler_sync(self): with self.get() as conn: try: return conn.execute(''' SELECT reconciler_sync_point FROM container_stat ''').fetchone()[0] except sqlite3.OperationalError as err: if ""no such column: reconciler_sync_point"" not in str(err): raise return -1 def update_reconciler_sync(self, point): query = """""" UPDATE container_stat SET reconciler_sync_point = ? with self.get() as conn: try: conn.execute(query, (point,)) except sqlite3.OperationalError as err: if ""no such column: reconciler_sync_point"" not in str(err): raise self._migrate_add_storage_policy(conn) conn.execute(query, (point,)) conn.commit() def get_misplaced_since(self, start, count): Get a list of objects sorted by name which are in a storage policy different from the container's storage policy. :param start: last reconciler sync point :param count: maximum number of entries to get :returns: list of tuples of (name, created_at, size, content_type, etag, storage_policy_index) """""" qry = """""" SELECT ROWID, name, created_at, size, content_type, etag, deleted, storage_policy_index FROM object WHERE ROWID > ? AND storage_policy_index != ( SELECT storage_policy_index FROM container_stat LIMIT 1) ORDER BY ROWID ASC LIMIT ? """""" self._commit_puts_stale_ok() with self.get() as conn: try: cur = conn.execute(qry, (start, count)) except sqlite3.OperationalError as err: if ""no such column: storage_policy_index"" not in str(err): raise # shouldn't happen return [] return list(dict(row) for row in cur.fetchall()) def _migrate_add_storage_policy(self, conn): """""" Add the storage_policy_index column to the 'object' table. """""" conn.executescript(POLICY_STAT_TABLE_CREATE + ''' INSERT INTO policy_stat ( storage_policy_index, object_count, bytes_used) SELECT 0, object_count, bytes_used FROM container_stat; ALTER TABLE container_stat ADD COLUMN reconciler_sync_point INTEGER DEFAULT -1; UPDATE container_stat SET storage_policy_index = 0, object_count = -1, bytes_used = -1; ALTER TABLE object ADD COLUMN storage_policy_index INTEGER DEFAULT 0; DROP TRIGGER object_insert; DROP TRIGGER object_delete; ''' + POLICY_STAT_TRIGGER_SCRIPT)"," deleted INTEGER DEFAULT 0 CREATE TRIGGER object_insert AFTER INSERT ON object BEGIN UPDATE container_stat SET object_count = object_count + (1 - new.deleted), bytes_used = bytes_used + new.size, hash = chexor(hash, new.name, new.created_at); END; CREATE TRIGGER object_delete AFTER DELETE ON object BEGIN UPDATE container_stat SET object_count = object_count - (1 - old.deleted), bytes_used = bytes_used - old.size, hash = chexor(hash, old.name, old.created_at); END; """""") object_count INTEGER, bytes_used INTEGER, storage_policy_index INTEGER INSERT INTO container_stat (object_count, bytes_used) VALUES (0, 0); conn.execute(''' UPDATE container_stat SET account = ?, container = ?, created_at = ?, id = ?, put_timestamp = ?, status_changed_at = ?, storage_policy_index = ? ''', (self.account, self.container, normalize_timestamp(time.time()), (name, timestamp, size, content_type, etag, deleted) = \ pickle.loads(entry.decode('base64')) 'deleted': deleted}) row = conn.execute( 'SELECT object_count from container_stat').fetchone() def delete_object(self, name, timestamp): self.put_object(name, timestamp, 0, 'application/deleted', 'noetag', 1) def put_object(self, name, timestamp, size, content_type, etag, deleted=0): 'deleted': deleted} (name, timestamp, size, content_type, etag, deleted), trailing_pol = 'storage_policy_index' data = conn.execute(''' delete_timestamp, status_changed_at, object_count, bytes_used, reported_put_timestamp, reported_delete_timestamp, reported_object_count, reported_bytes_used, hash, id, %s, %s FROM container_stat ''' % (trailing_sync, trailing_pol)).fetchone() except sqlite3.OperationalError as err: if 'no such column: x_container_sync_point' in str(err): elif 'no such column: storage_policy_index' in str(err): def set_storage_policy_index(self, policy_index): def _setit(conn): if ""no such column: storage_policy_index"" not in str(err): self._migrate_add_storage_policy_index(conn) path=None): query += ' ORDER BY name LIMIT ?' query_args.append(limit - len(results)) curs = conn.execute(query, query_args) with self.get() as conn: conn.execute(query, (rec['name'], rec['created_at'])) query = 'SELECT 1 FROM object WHERE name = ?' if not conn.execute(query, (rec['name'],)).fetchall(): content_type, etag, deleted) VALUES (?, ?, ?, ?, ?, ?) rec['content_type'], rec['etag'], rec['deleted']])) def _migrate_add_storage_policy_index(self, conn): Add the storage_policy_index column to the 'container_stat' table. conn.executescript(''' UPDATE container_stat SET storage_policy_index=0; ''')",917,194
openstack%2Fswift~feature%2Fec~Ia484d569619df0bf85f973e4e916de2ac6401d5e,openstack/swift,feature/ec,Ia484d569619df0bf85f973e4e916de2ac6401d5e,Extend direct_client,ABANDONED,2014-04-17 06:00:21.000000000,2014-06-24 17:32:10.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-17 06:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c7b9e2961d46dbcf68ff9e36ed9c929df8ba7215', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 2, 'created': '2014-04-17 06:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1b1318114a991972311574b7906d09d153a61f77', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 3, 'created': '2014-04-17 17:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fefd39425348e61b8176932ac9dc2c3e2c31fa56', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 4, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ff5ff2fdfcae520ca6b57b4496a591491d71468c', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 5, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/235dd917d7f80ece9453eaa29988e9785a5b1e74', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 6, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/747313773a1ba961aef66bdda9f8a92626ff2967', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 7, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/66b75deed87d39f85612f36b29f3decf1ec4ef80', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 8, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ccea4dfb112910778365b928f7f065c0d9a3122a', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 9, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b084a27c0e4e8251e1d389d381ec96f7e9174c6e', 'message': 'Extend direct_client\n\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 10, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eda1707cc029932d1add8c60f1b6ee6bbd8ea8e1', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}, {'number': 11, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/unit/common/test_direct_client.py', 'swift/common/direct_client.py', 'swift/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f66e0d03a0552c3c92c5de635591005210b787c3', 'message': 'Extend direct_client\n\nRework header handling and add some methods needed by the reconciler.\n\n * response headers are case insensitive HeaderKeyDicts\n * add direct client container obj put and delete\n * add headers param to direct head object\n * add headers to DirectClientException\n\nDirectClientException is a subclass of ClientException with a convience\nconstructor.  ClientException now supports an http_headers kwarg.\n\nExceptions raised from direct_client will include headers.\n\nChange-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e\n'}]",0,88144,f66e0d03a0552c3c92c5de635591005210b787c3,44,5,11,1179,,,0,"Extend direct_client

Rework header handling and add some methods needed by the reconciler.

 * response headers are case insensitive HeaderKeyDicts
 * add direct client container obj put and delete
 * add headers param to direct head object
 * add headers to DirectClientException

DirectClientException is a subclass of ClientException with a convience
constructor.  ClientException now supports an http_headers kwarg.

Exceptions raised from direct_client will include headers.

Change-Id: Ia484d569619df0bf85f973e4e916de2ac6401d5e
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/88144/10 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_direct_client.py', 'test/unit/__init__.py', 'swift/common/direct_client.py', 'swift/common/exceptions.py']",4,c7b9e2961d46dbcf68ff9e36ed9c929df8ba7215,shadow-listings," http_device='', http_response_content='', http_headers=None): self.http_headers = http_headers or {}"," http_device='', http_response_content=''):",501,264
openstack%2Fswift~feature%2Fec~I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9,openstack/swift,feature/ec,I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9,Add container-reconciler daemon,ABANDONED,2014-04-08 02:37:01.000000000,2014-06-24 17:32:04.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 8779}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-08 02:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/24a5cb138aff040725a1d474f7ae8c72e18d9c45', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator and the object updater;\nthis is the daemon that handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 2, 'created': '2014-04-11 07:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0704b20fc8e529dd528369916ab668773c26df62', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator and the object updater; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 3, 'created': '2014-04-12 00:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c369b2a35faeff3a4e7ab8041d869a9d77ab463b', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator and the object updater; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 4, 'created': '2014-04-17 06:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d34f92360e70466fb63e8caa21e7c63e61080b8', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator and the object updater; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 5, 'created': '2014-04-17 06:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/58c644609f6130489361c8f04bf1fabcb6c9a37e', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator and the object updater; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 6, 'created': '2014-04-17 17:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/66a3fbaf7becc3023b40320295eebb5eb88ef4bf', 'message': ""Add object-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator and the object updater; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 7, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/54f969e290260364a20440681a28b710657d27a9', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 8, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f80da7c3262ee9ca81e14fbff8ecc5a38a3cdd03', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 9, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e318456caac6b4c25f1948bc9c5da646261c48a7', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 10, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/09a3b32db1ed77a651a1613ea32fff1d96df3630', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 11, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e86abd5b0a8c9746ba817ddb23dafa424a2139ce', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 12, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f7b1b5e81840b4b9014ff142fee35ffae7fd4be8', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and move\nthem to the right ones, or delete requests that went to the wrong storage\npolicy and apply them to the right ones. It operates on a queue similar to the\nobject-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in subsequent\ncommits by the container replicator; this is the daemon that handles them once\nthey happen.\n\nLike the object expirer, you only need to run one of these per cluster see\netc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 13, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/03c9afdb4e0a5caaf227829fef74d958d0e220f0', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}, {'number': 14, 'created': '2014-05-16 18:57:07.000000000', 'files': ['bin/swift-reconciler-enqueue', 'swift/common/utils.py', 'test/unit/__init__.py', 'etc/container-reconciler.conf-sample', 'swift/common/manager.py', 'test/unit/container/test_reconciler.py', 'setup.cfg', 'bin/swift-container-reconciler', 'swift/container/reconciler.py', 'test/unit/common/middleware/helpers.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2adca137c2cc69398b65a80949938a3788a6594f', 'message': ""Add container-reconciler daemon\n\nThis daemon will take objects that are in the wrong storage policy and\nmove them to the right ones, or delete requests that went to the wrong\nstorage policy and apply them to the right ones. It operates on a\nqueue similar to the object-expirer's queue.\n\nDiscovering that the object is in the wrong policy will be done in\nsubsequent commits by the container replicator; this is the daemon\nthat handles them once they happen.\n\nLike the object expirer, you only need to run one of these per cluster\nsee etc/container-reconciler.conf.\n\nChange-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9\n""}]",1,85908,2adca137c2cc69398b65a80949938a3788a6594f,61,6,14,1179,,,0,"Add container-reconciler daemon

This daemon will take objects that are in the wrong storage policy and
move them to the right ones, or delete requests that went to the wrong
storage policy and apply them to the right ones. It operates on a
queue similar to the object-expirer's queue.

Discovering that the object is in the wrong policy will be done in
subsequent commits by the container replicator; this is the daemon
that handles them once they happen.

Like the object expirer, you only need to run one of these per cluster
see etc/container-reconciler.conf.

Change-Id: I5ea62eb77ddcbc7cfebf903429f2ee4c098771c9
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/85908/11 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_direct_client.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/unit/container/test_server.py', 'swift/container/server.py', 'bin/swift-reconciler-enqueue', 'swift/common/utils.py', 'test/probe/test_container_merge_policy_index.py', 'test/unit/common/test_internal_client.py', 'etc/container-reconciler.conf-sample', 'swift/common/direct_client.py', 'swift/common/manager.py', 'test/unit/container/test_reconciler.py', 'setup.cfg', 'bin/swift-container-reconciler', 'swift/container/reconciler.py', 'test/unit/common/middleware/helpers.py', 'test/unit/common/test_utils.py', 'swift/common/internal_client.py', 'swift/proxy/controllers/base.py']",20,24a5cb138aff040725a1d474f7ae8c72e18d9c45,shadow-listings," 'connection', 'x-put-timestamp', 'x-delete-after', 'x-status-changed-at'):"," 'connection', 'x-put-timestamp', 'x-delete-after'):",2669,145
openstack%2Fswift~feature%2Fec~I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72,openstack/swift,feature/ec,I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72,Add reconciler probetest outline,ABANDONED,2014-04-29 07:27:42.000000000,2014-06-24 17:30:57.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-04-29 07:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f7e035bcb832f9355a44ffb52afb8f482d0fee34', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 2, 'created': '2014-04-29 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b79357c71f824fd93d8f1c1b60b5bba1c7d9f61c', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 3, 'created': '2014-05-03 01:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7fb7147657f35d3db07e25c31bb2a94fcff53398', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 4, 'created': '2014-05-06 01:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3dab5ac81db0887cc068b835df4ced4d6a2759e7', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 5, 'created': '2014-05-07 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a64ab42d3ed193abfa96c1119206e42568cef5df', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 6, 'created': '2014-05-07 23:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f5a8f158a8a6c25eb08b28517dce4ce652fe901f', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 7, 'created': '2014-05-09 04:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ea5ee4c1b239db010b03e0df4970c160745db423', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}, {'number': 8, 'created': '2014-05-16 18:57:07.000000000', 'files': ['test/probe/test_container_merge_policy_index.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a6a30048f5ec76f683edfd67091c35ec0e681994', 'message': ""Add reconciler probetest outline\n\nYou can manually setup a split brain scenario for reconciler testing with the\nenqueue script using the machinery from the included probetest.  Evoke the\ntest as a script with with 'split-brain' command for more help.\n\nChange-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72\n""}]",0,90934,a6a30048f5ec76f683edfd67091c35ec0e681994,35,5,8,1179,,,0,"Add reconciler probetest outline

You can manually setup a split brain scenario for reconciler testing with the
enqueue script using the machinery from the included probetest.  Evoke the
test as a script with with 'split-brain' command for more help.

Change-Id: I3a7b3167d674eba5f6e4072b176f6c4d29cdcd72
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/90934/8 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_container_merge_policy_index.py'],1,f7e035bcb832f9355a44ffb52afb8f482d0fee34,shadow-listings,"#!/usr/bin/python -u # Copyright (c) 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import sys import itertools import unittest import uuid from optparse import OptionParser from swift.common.manager import Manager from swift.common.storage_policy import POLICIES from swift.common import utils from swift.common.http import HTTP_NOT_FOUND from test.probe.common import reset_environment from swiftclient import client, get_auth, ClientException TIMEOUT = 60 def meta_command(name, bases, attrs): """""" Look for attrs with a truthy attribute __command__ and add them to an attribtue on the type __commands__ that maps names to decorated methods. The decorated methods doc strings also get mapped in __docs__. Also adds a method run(command_name, *args, **kwargs) that works like you might expect if you don't override it. """""" commands = {} docs = {} for attr, value in attrs.items(): if getattr(value, '__command__', False): commands[attr] = value # methods have always have a __doc__ attribute, sometimes empty docs[attr] = (getattr(value, '__doc__', None) or 'perform the %s command' % attr).strip() attrs['__commands__'] = commands attrs['__docs__'] = docs def run(self, command, *args, **kwargs): return self.__commands__[command](self, *args, **kwargs) attrs.setdefault('run', run) return type(name, bases, attrs) def command(f): f.__command__ = True return f class BrainSplitter(object): __metaclass__ = meta_command def __init__(self, url, token, container_name='test', object_name='test'): self.url = url self.token = token self.container_name = container_name self.object_name = object_name self.servers = Manager(['container-server']) self.policies = itertools.cycle(POLICIES) @command def start_first_half(self): """""" start container servers 1 & 2 """""" tuple(self.servers.start(number=n) for n in (1, 2)) @command def stop_first_half(self): """""" stop container servers 1 & 2 """""" tuple(self.servers.stop(number=n) for n in (1, 2)) @command def start_second_half(self): """""" start container servers 3 & 4 """""" tuple(self.servers.start(number=n) for n in (3, 4)) @command def stop_second_half(self): """""" stop container servers 3 & 4 """""" tuple(self.servers.stop(number=n) for n in (3, 4)) @command def put_container(self, policy_index=None): """""" put container with next storage policy """""" policy = self.policies.next() if policy_index is not None: policy = POLICIES.get_by_index(int(policy_index)) if not policy: raise ValueError('Unknown policy with index %s' % policy) headers = {'X-Storage-Policy': policy.name} client.put_container(self.url, self.token, self.container_name, headers=headers) @command def delete_container(self): """""" delete container """""" client.delete_container(self.url, self.token, self.container_name) @command def put_object(self): """""" issue put for zero byte test object """""" client.put_object(self.url, self.token, self.container_name, self.object_name) @command def delete_object(self): """""" issue delete for test object """""" try: client.delete_object(self.url, self.token, self.container_name, self.object_name) except ClientException as err: if err.http_status != HTTP_NOT_FOUND: raise parser = OptionParser('%prog split-brain [options] ' '<command>[:<args>[,<args>...]] [<command>...]') parser.usage += '\n\nCommands:\n\t' + \ '\n\t'.join(""%s - %s"" % (name, doc) for name, doc in BrainSplitter.__docs__.items()) parser.add_option('-c', '--container', default='container-%s' % uuid.uuid4(), help='set container name') parser.add_option('-o', '--object', default='object-%s' % uuid.uuid4(), help='set container name') parser.add_option('-P', '--policies', help='csv list of policy indexes to use, can effect ' 'the order if you care about that sort of thing...') class TestContainerMergePolicyIndex(unittest.TestCase): def setUp(self): if len(POLICIES) < 2: raise unittest.SkipTest() (self.pids, self.port2server, self.account_ring, self.container_ring, self.object_ring, self.url, self.token, self.account, self.configs) = reset_environment() self.container_name = 'container-%s' % uuid.uuid4() self.object_name = 'object-%s' % uuid.uuid4() self.brain = BrainSplitter(self.url, self.token, self.container_name, self.object_name) def main(): options, commands = parser.parse_args() commands.remove('split-brain') if not commands: parser.print_help() return 'ERROR: must specifiy at least one command' for cmd_args in commands: cmd = cmd_args.split(':', 1)[0] if cmd not in BrainSplitter.__commands__: parser.print_help() return 'ERROR: unknown command %s' % cmd url, token = get_auth('http://127.0.0.1:8080/auth/v1.0', 'test:tester', 'testing') brain = BrainSplitter(url, token, options.container, options.object) for cmd_args in commands: parts = cmd_args.split(':', 1) command = parts[0] if len(parts) > 1: args = utils.list_from_csv(parts[1]) else: args = () try: brain.run(command, *args) except ClientException as e: print '**WARNING**: %s raised %s' % (command, e) print 'STATUS'.join(['*' * 25] * 2) brain.servers.status() sys.exit() if __name__ == ""__main__"": if any('split-brain' in arg for arg in sys.argv): sys.exit(main()) unittest.main() ",,208,0
openstack%2Ffuel-web~master~I816958d31b51fcd16e5defbdf3e822eab3a085cd,openstack/fuel-web,master,I816958d31b51fcd16e5defbdf3e822eab3a085cd,SERVER_PORT for UI and CLI tests depends on env variables,MERGED,2014-06-24 11:37:00.000000000,2014-06-24 17:21:08.000000000,2014-06-24 17:21:08.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 11:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/684e24c8b28f0aa049c95623b8f67726303f6add', 'message': 'Use ports depending on BUILD_EXECUTOR\n\nNailgun web server listens on port depending on BUILD_EXECUTOR\nvariable\n\nDefault port for UI tests - 8020\nDefault port for CLI tests - 8010\n\nChange-Id: I816958d31b51fcd16e5defbdf3e822eab3a085cd\nCloses-Bug: #1282565\n'}, {'number': 2, 'created': '2014-06-24 12:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/36a3433964fb531078127d98e02b0f7f8f1d858c', 'message': 'SERVER_PORT for UI and CLI tests depends on env variables\n\nNailgun web server listens on port depending on\nFUELCLIENT_SERVER_PORT and UI_SERVER_PORT variables\n\nDefault port for UI tests - 5544\nDefault port for CLI tests - 8003\n\nEach subproject should use its own server to guarantee\nsome environment isolation\n\nChange-Id: I816958d31b51fcd16e5defbdf3e822eab3a085cd\nCloses-Bug: #1282565\n'}, {'number': 3, 'created': '2014-06-24 13:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/04c38f72cf424ea368983d4081e9dd3832e07f16', 'message': 'SERVER_PORT for UI and CLI tests depends on env variables\n\nNailgun web server listens on port depending on\nFUELCLIENT_SERVER_PORT and UI_SERVER_PORT variables\n\nDefault port for UI tests - 5544\nDefault port for CLI tests - 8003\n\nEach subproject should use its own server to guarantee\nsome environment isolation\n\nChange-Id: I816958d31b51fcd16e5defbdf3e822eab3a085cd\nCloses-Bug: #1282565\n'}, {'number': 4, 'created': '2014-06-24 13:44:19.000000000', 'files': ['run_tests.sh', 'fuelclient/tests/base.py', 'nailgun/ui_tests/helpers.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/75e2e5330be7ce45c80e5b35fe32663b8f37842f', 'message': 'SERVER_PORT for UI and CLI tests depends on env variables\n\nNailgun web server listens on port depending on\nFUELCLIENT_SERVER_PORT and UI_SERVER_PORT variables\n\nDefault port for UI tests - 5544\nDefault port for CLI tests - 8003\n\nEach subproject should use its own server to guarantee\nsome environment isolation\n\nChange-Id: I816958d31b51fcd16e5defbdf3e822eab3a085cd\nCloses-Bug: #1282565\n'}]",1,102193,75e2e5330be7ce45c80e5b35fe32663b8f37842f,32,5,4,8907,,,0,"SERVER_PORT for UI and CLI tests depends on env variables

Nailgun web server listens on port depending on
FUELCLIENT_SERVER_PORT and UI_SERVER_PORT variables

Default port for UI tests - 5544
Default port for CLI tests - 8003

Each subproject should use its own server to guarantee
some environment isolation

Change-Id: I816958d31b51fcd16e5defbdf3e822eab3a085cd
Closes-Bug: #1282565
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/93/102193/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,684e24c8b28f0aa049c95623b8f67726303f6add,use_different_ports, local BASE_SERVER_PORT=802 local SERVER_PORT=$BASE_SERVER_PORT${BUILD_EXECUTOR:-0} local BASE_SERVER_PORT=801 local SERVER_PORT=$BASE_SERVER_PORT${BUILD_EXECUTOR:-0}, local SERVER_PORT=5544 local SERVER_PORT=8003,4,2
openstack%2Fdevstack~master~If64c54e805257921bb0084566ff85e7d019fa649,openstack/devstack,master,If64c54e805257921bb0084566ff85e7d019fa649,Parse openstackclient output to get EC2 and S3 urls.,ABANDONED,2014-05-26 11:07:59.000000000,2014-06-24 17:20:46.000000000,,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6116}, {'_account_id': 6737}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 8831}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10224}, {'_account_id': 10234}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-26 11:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a24b5239ddf3e9b1d654afaaef5597c9ecaf39ef', 'message': ""Parse openstackclient output to get EC2 and S3 urls.\n\nSome OSes don't support exactly url take by additional\nopenstackclient arguments. Therefore\nIc46a9989321cf6310c56edeeb737c603a4f9c1ed is reworked.\n\nChange-Id: If64c54e805257921bb0084566ff85e7d019fa649\nCloses-Bug: #1322931\n""}, {'number': 2, 'created': '2014-05-30 19:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/df6ce59b83fbdfc5184d12b5f16aeb6d866f3760', 'message': ""Parse openstackclient output to get EC2 and S3 urls.\n\nSome OSes don't support exactly url take by additional\nopenstackclient arguments. Therefore\nIc46a9989321cf6310c56edeeb737c603a4f9c1ed is reworked.\n\nChange-Id: If64c54e805257921bb0084566ff85e7d019fa649\nCloses-Bug: #1322931\nCloses-Bug: #1324651\n""}, {'number': 3, 'created': '2014-06-05 11:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/449a221afcc08d2ba5c9c36b1a124f788adc3436', 'message': ""Parse openstackclient output to get EC2 and S3 urls.\n\nFix following problems:\n1 Usage value format parameter in 'openstack endpoint show' is\nnot compatible with Python 2.6. See Bug#1322931 and Review#95916.\nThis fix doesn't use any additional parameters to avoid compatibility\nproblems, but parses output.\n\n2 When endpoint is not found, openstackclient returns an error,\nwhich is catched by bash. Bash terminates the script execution due to\nerror occured in the single simple command call.\nThis fix uses the command list $(cmd1 | cmd2) instead of simple command\n$(cmd). An error of the first command is ignored, empty output is passed\nto input of the second command.\n\nThe technique used for parsing is identical with ones used in other\nparts of DevStack. See for example getting EC2_ACCESS_KEY in eucarc.\n\nTherefore Ic46a9989321cf6310c56edeeb737c603a4f9c1ed is reworked.\n\nChange-Id: If64c54e805257921bb0084566ff85e7d019fa649\nCloses-Bug: #1322931\nCloses-Bug: #1324651\n""}, {'number': 4, 'created': '2014-06-06 08:11:08.000000000', 'files': ['tools/create_userrc.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/60fbefe19b3803fa28bd51a862d70573213c66f5', 'message': ""Parse openstackclient output to get EC2 and S3 urls.\n\nFix following problems:\n1 Usage value format parameter in 'openstack endpoint show' is\nnot compatible with Python 2.6. See Bug#1322931 and Review#95916.\nThis fix doesn't use any additional parameters to avoid compatibility\nproblems, but parses output.\n\n2 When endpoint is not found, openstackclient returns an error,\nwhich is catched by bash. Bash terminates the script execution due to\nerror occured in the single simple command call.\nThis fix uses the command list $(cmd1 | cmd2) instead of simple command\n$(cmd). An error of the first command is ignored, empty output is passed\nto input of the second command.\n\nThe technique used for parsing is identical with ones used in other\nparts of DevStack. See for example getting EC2_ACCESS_KEY in eucarc.\n\nTherefore Ic46a9989321cf6310c56edeeb737c603a4f9c1ed is reworked.\n\nChange-Id: If64c54e805257921bb0084566ff85e7d019fa649\nCloses-Bug: #1322931\nCloses-Bug: #1324651\n""}]",10,95500,60fbefe19b3803fa28bd51a862d70573213c66f5,61,14,4,10224,,,0,"Parse openstackclient output to get EC2 and S3 urls.

Fix following problems:
1 Usage value format parameter in 'openstack endpoint show' is
not compatible with Python 2.6. See Bug#1322931 and Review#95916.
This fix doesn't use any additional parameters to avoid compatibility
problems, but parses output.

2 When endpoint is not found, openstackclient returns an error,
which is catched by bash. Bash terminates the script execution due to
error occured in the single simple command call.
This fix uses the command list $(cmd1 | cmd2) instead of simple command
$(cmd). An error of the first command is ignored, empty output is passed
to input of the second command.

The technique used for parsing is identical with ones used in other
parts of DevStack. See for example getting EC2_ACCESS_KEY in eucarc.

Therefore Ic46a9989321cf6310c56edeeb737c603a4f9c1ed is reworked.

Change-Id: If64c54e805257921bb0084566ff85e7d019fa649
Closes-Bug: #1322931
Closes-Bug: #1324651
",git fetch https://review.opendev.org/openstack/devstack refs/changes/00/95500/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/create_userrc.sh'],1,a24b5239ddf3e9b1d654afaaef5597c9ecaf39ef,bug/1322931,EC2_URL=$(openstack endpoint show ec2 | awk '/ publicurl / { print $4 }')S3_URL=$(openstack endpoint show s3 | awk '/ publicurl / { print $4 }'),EC2_URL=$(openstack endpoint show -f value -c publicurl ec2)S3_URL=$(openstack endpoint show -f value -c publicurl s3),2,2
openstack%2Ftripleo-image-elements~master~I64bf8aad5bebcd3f2f89c67ac47d8e527a5d9117,openstack/tripleo-image-elements,master,I64bf8aad5bebcd3f2f89c67ac47d8e527a5d9117,Do not use cat in sysctl-set-value,MERGED,2014-06-19 06:59:50.000000000,2014-06-24 17:18:33.000000000,2014-06-24 17:18:32.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-06-19 06:59:50.000000000', 'files': ['elements/sysctl/bin/sysctl-set-value'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f7023f423efd6ba01715afe8e80b75595bc7a557', 'message': 'Do not use cat in sysctl-set-value\n\nUse of cat | grep is an anti-pattern, grep can read files, so drop\nthe use of cat, saving two processes being forked off.\n\nChange-Id: I64bf8aad5bebcd3f2f89c67ac47d8e527a5d9117\n'}]",0,101116,f7023f423efd6ba01715afe8e80b75595bc7a557,15,5,1,9369,,,0,"Do not use cat in sysctl-set-value

Use of cat | grep is an anti-pattern, grep can read files, so drop
the use of cat, saving two processes being forked off.

Change-Id: I64bf8aad5bebcd3f2f89c67ac47d8e527a5d9117
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/16/101116/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/sysctl/bin/sysctl-set-value'],1,f7023f423efd6ba01715afe8e80b75595bc7a557,no-need-for-cat-sysctl," if ! grep -q ""^$NAME = $VALUE"" $FILENAME; then grep ""^$NAME"" $FILENAME"," if ! cat $FILENAME | grep -q ""^$NAME = $VALUE""; then cat $FILENAME | grep ""^$NAME""",2,2
openstack%2Ftripleo-image-elements~master~I208310048d7617ec7726eceee9e4e269f1473510,openstack/tripleo-image-elements,master,I208310048d7617ec7726eceee9e4e269f1473510,Switch from upstart to os-refresh-config for MySQL server-id's,MERGED,2014-05-09 13:47:36.000000000,2014-06-24 17:12:50.000000000,2014-06-24 17:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 1872}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-09 13:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9385a2c5937bab08928c0524c4626448c3a5e0ee', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never ran, as an sysvinit rather\nthat upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 2, 'created': '2014-05-09 14:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/76bcfd47d060f066e680676f6728fe38d08fbe6e', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never ran, as an sysvinit rather\nthat upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 3, 'created': '2014-05-09 16:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e45f0db4c17b2a1059c18c9ef0eb5955ce16ec86', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never ran, as an sysvinit rather\nthat upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 4, 'created': '2014-05-09 16:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dc864cebf085f3662579e166231e6265ffd2972c', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never ran, as an sysvinit rather\nthat upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 5, 'created': '2014-05-18 17:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/26fe874c90a073f67f5061cc9be722b4eb347bb1', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never ran, as an sysvinit rather\nthat upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 6, 'created': '2014-05-26 14:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/48e5c384d9128defa7048b3fc067d812e5171dee', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 7, 'created': '2014-05-26 14:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/334ff77d5a28a2ab13418fea4991dd9e44c8e828', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 8, 'created': '2014-05-26 22:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/301ce9d52cb338d4fa90a456b3f240c554201f10', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 9, 'created': '2014-05-29 10:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/763385ce40d4685c5325d9e83c84982ec22702bb', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 10, 'created': '2014-06-21 15:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/48fdc7c1144c680aa3dc8c19c81b7567d9bde5ea', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}, {'number': 11, 'created': '2014-06-23 20:20:31.000000000', 'files': ['elements/mysql-common/os-refresh-config/configure.d/51-mysql-server-id', 'elements/mysql/os-refresh-config/configure.d/52-mysql-init', 'elements/mariadb/install.d/10-mariadb-packages', 'elements/mysql-common/install.d/mysql-set-server-id.upstart', 'elements/mysql/install.d/10-mysql', 'elements/mariadb-rdo/install.d/10-mariadb-rdo-packages', 'elements/boot-stack/os-refresh-config/configure.d/53-init-openstack'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/32323f847236423615d3e47b41478c0fd824718f', 'message': ""Switch from upstart to os-refresh-config for MySQL server-id's\n\nThis is both more reliable, and more cross-platform. With the\nmysql element, this upstart job is never run, as a sysvinit rather\nthan upstart job triggers mysql.\n\nChange-Id: I208310048d7617ec7726eceee9e4e269f1473510\n""}]",19,93039,32323f847236423615d3e47b41478c0fd824718f,80,10,11,741,,,0,"Switch from upstart to os-refresh-config for MySQL server-id's

This is both more reliable, and more cross-platform. With the
mysql element, this upstart job is never run, as a sysvinit rather
than upstart job triggers mysql.

Change-Id: I208310048d7617ec7726eceee9e4e269f1473510
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/39/93039/11 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql-common/os-refresh-config/pre-configure.d/97-mysql-server-id', 'elements/mariadb/install.d/10-mariadb', 'elements/mysql-common/install.d/mysql-set-server-id.upstart', 'elements/mysql/install.d/10-mysql']",4,9385a2c5937bab08928c0524c4626448c3a5e0ee,mysql,,"if [ ""$(dib-init-system)"" = ""upstart"" ] ; then install $(dirname $0)/mysql-set-server-id.upstart /etc/init/mysql-set-server-id.conf else echo WARNING: server-id will not be set on systems that boot this image! fi ",26,39
openstack%2Fdiskimage-builder~master~Icf9eedf4148141c92e9171f16ae744b88a8d8519,openstack/diskimage-builder,master,Icf9eedf4148141c92e9171f16ae744b88a8d8519,avoid failure if /lib/firmware doesn't exist,MERGED,2014-06-13 22:09:00.000000000,2014-06-24 17:12:40.000000000,2014-06-24 16:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 8399}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-06-13 22:09:00.000000000', 'files': ['lib/ramdisk-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/131fb8c216fefaad738b8716c86f9c79999d1304', 'message': ""avoid failure if /lib/firmware doesn't exist\n\nOn Debian, /lib/firmware is provided by optional packages like\nfirmware-iwlwifi or firmware-linux-free. That's why this directory\nmay not exist.\nThis change ensure the directory exist before trying to copy it\ncontent.\n\nChange-Id: Icf9eedf4148141c92e9171f16ae744b88a8d8519\n""}]",0,100026,131fb8c216fefaad738b8716c86f9c79999d1304,15,4,1,9268,,,0,"avoid failure if /lib/firmware doesn't exist

On Debian, /lib/firmware is provided by optional packages like
firmware-iwlwifi or firmware-linux-free. That's why this directory
may not exist.
This change ensure the directory exist before trying to copy it
content.

Change-Id: Icf9eedf4148141c92e9171f16ae744b88a8d8519
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/26/100026/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ramdisk-functions'],1,131fb8c216fefaad738b8716c86f9c79999d1304,check_firmware," if [ -d $FIRMWARE_DIR ]; then cp -a ""$FIRMWARE_DIR"" ""$TMP_MOUNT_PATH/lib/firmware"" fi"," cp -a ""$FIRMWARE_DIR"" ""$TMP_MOUNT_PATH/lib/firmware""",3,1
openstack%2Fopenstack-manuals~master~I4fc45589fe18e1faca579e722de88a74d0276936,openstack/openstack-manuals,master,I4fc45589fe18e1faca579e722de88a74d0276936,fix a minor typo in storage section,MERGED,2014-06-24 15:15:43.000000000,2014-06-24 17:08:47.000000000,2014-06-24 17:08:46.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 15:15:43.000000000', 'files': ['doc/config-reference/object-storage/section_object-storage-features.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4b9ba6763aedebf585475f2231a61791ba5ceeb5', 'message': 'fix a minor typo in storage section\n\nOpject  Object\n\nChange-Id: I4fc45589fe18e1faca579e722de88a74d0276936\n'}]",0,102268,4b9ba6763aedebf585475f2231a61791ba5ceeb5,8,3,1,9268,,,0,"fix a minor typo in storage section

Opject  Object

Change-Id: I4fc45589fe18e1faca579e722de88a74d0276936
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/102268/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/object-storage/section_object-storage-features.xml'],1,4b9ba6763aedebf585475f2231a61791ba5ceeb5,, <para>Object Storage includes a script called, <para>Opject Storage includes a script called,1,1
openstack%2Ffuel-web~master~I57bf618f9d80312903e859a670c34b051e1bd206,openstack/fuel-web,master,I57bf618f9d80312903e859a670c34b051e1bd206,Fix for stop_deployment test,MERGED,2014-06-18 14:46:22.000000000,2014-06-24 17:04:43.000000000,2014-06-24 17:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-18 14:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3ffb76e12a2bd1da8c3dc8e4a014f34f3ba0d0e3', 'message': ""Fix for stop_deployment test\n\nTask on deployment or provisioning should be in status 'running' for\nchecking stopping deployment. tick_interval parameter added into\nfake_tasks decorator for test_stop_deployment. Without it in some\ncases tasks became into status 'ready' before stop deployment is\nstarted\n\nChange-Id: I57bf618f9d80312903e859a670c34b051e1bd206\nCloses-Bug: #1330895\n""}, {'number': 2, 'created': '2014-06-23 09:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/af4b5689e0228190039a090313d80df040c5cc28', 'message': ""Fix for stop_deployment test\n\nTask on deployment or provisioning should be in status 'running' for\nchecking stopping deployment. tick_interval parameter added into\nfake_tasks decorator for test_stop_deployment. Without it in some\ncases tasks became into status 'ready' before stop deployment is\nstarted \n\nChange-Id: I57bf618f9d80312903e859a670c34b051e1bd206\nCloses-Bug: #1330895\n""}, {'number': 3, 'created': '2014-06-24 08:09:10.000000000', 'files': ['nailgun/nailgun/test/integration/test_stop_deployment.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0d3e02a1ffbb6cbd6aa02d7aab52c011b9f8f8c4', 'message': ""Fix for stop_deployment test\n\nTask on deployment or provisioning should be in status 'running' for\nchecking stopping deployment. tick_interval parameter added into\nfake_tasks decorator for test_stop_deployment. Without it in some\ncases tasks became into status 'ready' before stop deployment is\nstarted\n\nChange-Id: I57bf618f9d80312903e859a670c34b051e1bd206\nCloses-Bug: #1330895\n""}]",2,100928,0d3e02a1ffbb6cbd6aa02d7aab52c011b9f8f8c4,26,8,3,10959,,,0,"Fix for stop_deployment test

Task on deployment or provisioning should be in status 'running' for
checking stopping deployment. tick_interval parameter added into
fake_tasks decorator for test_stop_deployment. Without it in some
cases tasks became into status 'ready' before stop deployment is
started

Change-Id: I57bf618f9d80312903e859a670c34b051e1bd206
Closes-Bug: #1330895
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/28/100928/3 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/test/integration/test_stop_deployment.py'],1,3ffb76e12a2bd1da8c3dc8e4a014f34f3ba0d0e3,stop_deployment_fake_task_sleep," @fake_tasks(recover_nodes=False, tick_interval=1)", @fake_tasks(recover_nodes=False),1,1
openstack%2Fopenstack-manuals~master~I39767e682b1f4ca005fa272544cdd37fc0a998bd,openstack/openstack-manuals,master,I39767e682b1f4ca005fa272544cdd37fc0a998bd,Document LIO iSCSI support,MERGED,2014-06-24 14:10:18.000000000,2014-06-24 17:01:00.000000000,2014-06-24 17:01:00.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 14:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/205f8febe15a823b1d60eea6f3a2ce3cf9abb77d', 'message': 'Document LIO iSCSI support\n\nLIO iSCSI support was added in Grizzly. This patch adds a small section to the\nblock storage section of the admin guide explaining how to turn it on and\nwhich deps/tools to use.\n\nChange-Id: I39767e682b1f4ca005fa272544cdd37fc0a998bd\nCloses-Bug: 1111084\n'}, {'number': 2, 'created': '2014-06-24 15:44:09.000000000', 'files': ['doc/admin-guide-cloud/blockstorage/section_increase-api-throughput.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/admin-guide-cloud/blockstorage/section_backup-block-storage-disks.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/be9b9d90e0791af1190021a9ef7a2f3434c39e64', 'message': 'Document LIO iSCSI support\n\nLIO iSCSI support was added in Grizzly. This patch adds a small section to the\nblock storage section of the admin guide explaining how to turn it on and\nwhich deps/tools to use.\n\nChange-Id: I39767e682b1f4ca005fa272544cdd37fc0a998bd\nCloses-Bug: 1111084\n'}]",2,102245,be9b9d90e0791af1190021a9ef7a2f3434c39e64,13,4,2,612,,,0,"Document LIO iSCSI support

LIO iSCSI support was added in Grizzly. This patch adds a small section to the
block storage section of the admin guide explaining how to turn it on and
which deps/tools to use.

Change-Id: I39767e682b1f4ca005fa272544cdd37fc0a998bd
Closes-Bug: 1111084
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/102245/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/ch_blockstorage.xml'],1,205f8febe15a823b1d60eea6f3a2ce3cf9abb77d,bug/1111084," <section xml:id=""using-lio-iscsi""> <title>Using LIO iSCSI support</title> <para>The default <option>iscsi_helper</option> tool is <literal>tgtadm</literal>. To change to using LIO iSCSI, first install the <literal>python-rtslib</literal> package, and then set <literal>iscsi_helper=lioadm</literal> in <filename>cinder.conf</filename>.</para> <para>Once configured, you can using <command>cinder-rtstool</command> to manage the volumes. It supports the ability to create, delete, and verify volumes, in addition to determining targes and adding iSCSI initators to the system.</para> </section>",,12,0
openstack%2Fceilometer~master~If396742d41a181f7a589cc133d81d1df7c1461d9,openstack/ceilometer,master,If396742d41a181f7a589cc133d81d1df7c1461d9,Updated from global requirements,MERGED,2014-05-30 16:24:34.000000000,2014-06-24 16:55:52.000000000,2014-06-24 16:55:52.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7641}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-05-30 16:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/48d3b703a59246840c0f637a8f9ccc0538c625f4', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 2, 'created': '2014-06-02 18:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c71724cfe93d8d67a0397e8b0c66628c31b007f0', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 3, 'created': '2014-06-03 12:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9a42e55283f6265f1098d69a702990c3724a9641', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 4, 'created': '2014-06-04 15:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2e893bc465b6f78213f6c48fb65d65cc1e427266', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 5, 'created': '2014-06-10 00:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/452c10b2a265911331e9f3adca31756248d87f32', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 6, 'created': '2014-06-10 10:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/889a9ae6141bafb8f3d70a80fbdde35bc7aaad8a', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 7, 'created': '2014-06-10 12:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5d4a7b472fcc47254d41412b5010a4d8afd2208e', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 8, 'created': '2014-06-10 14:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/df013ebd35d6935f6c44e94f602f7a4dddfc083b', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 9, 'created': '2014-06-11 01:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/057592178fb4474f9375ad8dccd69188919fd86c', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 10, 'created': '2014-06-12 04:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6f58297259b2fcd87451624d0e8bd8481073459d', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 11, 'created': '2014-06-12 21:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a223b6002628fced08da07322170eec865fc42e5', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 12, 'created': '2014-06-13 22:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/34ea2d207644cd40f01e1d2ac0f85f710c98d4a7', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 13, 'created': '2014-06-14 05:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c6b84a24e38fc42b34eec7a9067f0a9e9a1fee9d', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 14, 'created': '2014-06-16 09:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/39b8443131a2dfd432931a9409caa66654b1268c', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 15, 'created': '2014-06-17 13:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6c3e3a876ffb47259a5dbf73521646e03581e711', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 16, 'created': '2014-06-17 14:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8e4b36c74b339e5568bd327f2ec6e128446d3cb4', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 17, 'created': '2014-06-17 14:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2165b401df19cd78089f484da972e19bbc762bdd', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 18, 'created': '2014-06-17 20:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cae5c6c930491db3e42ffe6b8e9031a2def5a5b4', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 19, 'created': '2014-06-18 00:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/80619c1991112746614a92399ca9cbf5a5a690be', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 20, 'created': '2014-06-18 14:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8847d4c74a01a7c695bc182813e0c66f599dff14', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 21, 'created': '2014-06-18 14:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d020cf7fbf84008b06fc68777707ba93a6e47b81', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 22, 'created': '2014-06-18 14:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/47a65980c6d13fc382d115bbcb1f881feec131d1', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 23, 'created': '2014-06-19 01:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/72c2c57d8bb0313571f7fd6f041026eb05e36324', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 24, 'created': '2014-06-20 03:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d2258fc8ec8ec083db24aff68ed8825a6363ebb', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 25, 'created': '2014-06-23 05:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cb57276b7f57c3515ded15bbc63ed2251cf5efee', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}, {'number': 26, 'created': '2014-06-24 07:20:06.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d006f5aa418cb7f4dbbd25fe1bde73daa8d79609', 'message': 'Updated from global requirements\n\nChange-Id: If396742d41a181f7a589cc133d81d1df7c1461d9\n'}]",0,96819,d006f5aa418cb7f4dbbd25fe1bde73daa8d79609,122,9,26,11131,,,0,"Updated from global requirements

Change-Id: If396742d41a181f7a589cc133d81d1df7c1461d9
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/19/96819/24 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,48d3b703a59246840c0f637a8f9ccc0538c625f4,openstack/requirements,python-keystoneclient>=0.9.0,python-keystoneclient>=0.8.0,1,1
openstack%2Foslo.i18n~master~I92a3a695cf9391af2a684c9ef7ee62b3fc524129,openstack/oslo.i18n,master,I92a3a695cf9391af2a684c9ef7ee62b3fc524129,Updated from global requirements,MERGED,2014-06-15 19:48:37.000000000,2014-06-24 16:55:50.000000000,2014-06-24 16:55:50.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-06-15 19:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/a5335b26cf39ef3b1a28abdb429e498c9690df57', 'message': 'Updated from global requirements\n\nChange-Id: I92a3a695cf9391af2a684c9ef7ee62b3fc524129\n'}, {'number': 2, 'created': '2014-06-16 09:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/a431380c52d440e3c170d155b429705b607a2411', 'message': 'Updated from global requirements\n\nChange-Id: I92a3a695cf9391af2a684c9ef7ee62b3fc524129\n'}, {'number': 3, 'created': '2014-06-18 00:47:02.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/8850e0e49604ea4a5dbc9bc01a96638e0bb14355', 'message': 'Updated from global requirements\n\nChange-Id: I92a3a695cf9391af2a684c9ef7ee62b3fc524129\n'}]",0,100107,8850e0e49604ea4a5dbc9bc01a96638e0bb14355,15,2,3,11131,,,0,"Updated from global requirements

Change-Id: I92a3a695cf9391af2a684c9ef7ee62b3fc524129
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/07/100107/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a5335b26cf39ef3b1a28abdb429e498c9690df57,openstack/requirements,"hacking>=0.9.1,<0.10 sphinx>=1.1.2,!=1.2.0,<1.3","hacking>=0.8.0,<0.9 sphinx>=1.1.2,<1.2",2,2
openstack%2Fnova~master~I3091bc06a74e32871a743a831ab3db23220ae8f8,openstack/nova,master,I3091bc06a74e32871a743a831ab3db23220ae8f8,Object-ify APIv3 availability_zone extension,MERGED,2014-06-20 15:26:06.000000000,2014-06-24 16:55:40.000000000,2014-06-24 16:55:38.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 15:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cf8d19c8b4df173261dbdb3962819f8db64b3e5', 'message': 'Object-ify APIv3 availability_zone extension\n\nThis makes the availablility_zone extension use the Service object\nfor looking up service details instead of a direct-to-database\ncall.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I3091bc06a74e32871a743a831ab3db23220ae8f8\n'}, {'number': 2, 'created': '2014-06-20 16:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dec998a5bf04cf811365d6522105aa33f2a12784', 'message': 'Object-ify APIv3 availability_zone extension\n\nThis makes the availablility_zone extension use the Service object\nfor looking up service details instead of a direct-to-database\ncall.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I3091bc06a74e32871a743a831ab3db23220ae8f8\n'}, {'number': 3, 'created': '2014-06-23 17:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70f9f60ee32e8e1af65ffdb5e0d591b6db6f42c9', 'message': 'Object-ify APIv3 availability_zone extension\n\nThis makes the availablility_zone extension use the Service object\nfor looking up service details instead of a direct-to-database\ncall.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I3091bc06a74e32871a743a831ab3db23220ae8f8\n'}, {'number': 4, 'created': '2014-06-23 18:58:11.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e21f07cfae5f508fa6456ccf8bc0274ae5510539', 'message': 'Object-ify APIv3 availability_zone extension\n\nThis makes the availablility_zone extension use the Service object\nfor looking up service details instead of a direct-to-database\ncall.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I3091bc06a74e32871a743a831ab3db23220ae8f8\n'}]",1,101579,e21f07cfae5f508fa6456ccf8bc0274ae5510539,55,10,4,4393,,,0,"Object-ify APIv3 availability_zone extension

This makes the availablility_zone extension use the Service object
for looking up service details instead of a direct-to-database
call.

Related to blueprint compute-manager-objects-juno

Change-Id: I3091bc06a74e32871a743a831ab3db23220ae8f8
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/101579/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_availability_zone.py', 'nova/api/openstack/compute/plugins/v3/availability_zone.py']",2,3cf8d19c8b4df173261dbdb3962819f8db64b3e5,bp/compute-manager-objects-juno,"from nova import objects enabled_services = objects.ServiceList.get_all(context, disabled=False)","from nova import db enabled_services = db.service_get_all(context, False)",11,9
openstack%2Ftripleo-incubator~master~Ib5c6729984d7d30462dbc73c6243d000a5495052,openstack/tripleo-incubator,master,Ib5c6729984d7d30462dbc73c6243d000a5495052,Fix Ceilometer undercloud endpoint registration,ABANDONED,2014-06-23 21:29:44.000000000,2014-06-24 16:47:55.000000000,,"[{'_account_id': 3}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-06-23 21:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ceeec8ea0f33c9824f3e058c0637d94359d7cded', 'message': ""Fix Ceilometer undercloud endpoint registration when UI not specified\n\nMatches upstream change I88fcd7b58499b682472d4c29d873d1e769169b5d\n\nWhen USE_UNDERCLOUD_UI setting is not defined the Ceilometer elements\nare not installed, however the endpoint is still registered which\ncauses bad behavior in the Horizon UI. Let's make endpoint registration\ndependent on that setting as well.\n\nChange-Id: Ib5c6729984d7d30462dbc73c6243d000a5495052\n""}, {'number': 2, 'created': '2014-06-24 14:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/6970c6211f708fad96d3657ac86bd6354568dbb5', 'message': ""Fix Ceilometer undercloud endpoint registration when UI not specified\n\nMatches upstream change I88fcd7b58499b682472d4c29d873d1e769169b5d\n\nWhen USE_UNDERCLOUD_UI setting is not defined the Ceilometer elements\nare not installed, however the endpoint is still registered which\ncauses bad behavior in the Horizon UI. Let's make endpoint registration\ndependent on that setting.\n\nChange-Id: Ib5c6729984d7d30462dbc73c6243d000a5495052\n""}, {'number': 3, 'created': '2014-06-24 14:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3e9e579697fcdc3f7e23c96b5ad28fbdd8eaf240', 'message': ""Fix Ceilometer undercloud endpoint registration when UI not specified\n\nMatches upstream change I88fcd7b58499b682472d4c29d873d1e769169b5d\n\nWhen USE_UNDERCLOUD_UI setting is not defined the Ceilometer elements\nare not installed, however the endpoint is still registered which\ncauses bad behavior in the Horizon UI. Let's make endpoint registration\ndependent on that setting as well.\n\nChange-Id: Ib5c6729984d7d30462dbc73c6243d000a5495052\n""}, {'number': 4, 'created': '2014-06-24 14:53:43.000000000', 'files': ['scripts/devtest_undercloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/d571f61a647c406474e338bd7b9ce1cdff339b1d', 'message': ""Fix Ceilometer undercloud endpoint registration\n\nMatches upstream change I88fcd7b58499b682472d4c29d873d1e769169b5d\n\nWhen USE_UNDERCLOUD_UI setting is not defined the Ceilometer elements\nare not installed, however the endpoint is still registered which\ncauses bad behavior in the Horizon UI. Let's make endpoint registration\ndependent on that setting as well.\n\nChange-Id: Ib5c6729984d7d30462dbc73c6243d000a5495052\n""}]",0,102018,d571f61a647c406474e338bd7b9ce1cdff339b1d,15,2,4,7336,,,0,"Fix Ceilometer undercloud endpoint registration

Matches upstream change I88fcd7b58499b682472d4c29d873d1e769169b5d

When USE_UNDERCLOUD_UI setting is not defined the Ceilometer elements
are not installed, however the endpoint is still registered which
causes bad behavior in the Horizon UI. Let's make endpoint registration
dependent on that setting as well.

Change-Id: Ib5c6729984d7d30462dbc73c6243d000a5495052
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/18/102018/4 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_undercloud.sh'],1,ceeec8ea0f33c9824f3e058c0637d94359d7cded,fix-cm-endpoint-undercloud,"#Add Ceilometer to env only if USE_UNDERCLOUD_UI is specified if [ ""$USE_UNDERCLOUD_UI"" -ne 0 ] ; then ENV_JSON=$(jq '.parameters = { ""MysqlInnodbBufferPoolSize"": 100 } + .parameters + { ""CeilometerPassword"": ""'""${UNDERCLOUD_CEILOMETER_PASSWORD}""'"" }' <<< $ENV_JSON) fi # Create service endpoints and optionally include Ceilometer for UI support if [ ""$USE_UNDERCLOUD_UI"" -ne 0 ] ; then setup-endpoints $UNDERCLOUD_IP --ceilometer-password $UNDERCLOUD_CEILOMETER_PASSWORD \ --glance-password $UNDERCLOUD_GLANCE_PASSWORD \ --heat-password $UNDERCLOUD_HEAT_PASSWORD \ --neutron-password $UNDERCLOUD_NEUTRON_PASSWORD \ --nova-password $UNDERCLOUD_NOVA_PASSWORD \ --tuskar-password $UNDERCLOUD_TUSKAR_PASSWORD \ $REGISTER_SERVICE_OPTS else setup-endpoints $UNDERCLOUD_IP --glance-password $UNDERCLOUD_GLANCE_PASSWORD \ --heat-password $UNDERCLOUD_HEAT_PASSWORD \ --neutron-password $UNDERCLOUD_NEUTRON_PASSWORD \ --nova-password $UNDERCLOUD_NOVA_PASSWORD \ --tuskar-password $UNDERCLOUD_TUSKAR_PASSWORD \ $REGISTER_SERVICE_OPTS fi "," ""CeilometerPassword"": ""'""${UNDERCLOUD_CEILOMETER_PASSWORD}""'"",setup-endpoints $UNDERCLOUD_IP --ceilometer-password $UNDERCLOUD_CEILOMETER_PASSWORD \ --glance-password $UNDERCLOUD_GLANCE_PASSWORD \ --heat-password $UNDERCLOUD_HEAT_PASSWORD \ --neutron-password $UNDERCLOUD_NEUTRON_PASSWORD \ --nova-password $UNDERCLOUD_NOVA_PASSWORD \ --tuskar-password $UNDERCLOUD_TUSKAR_PASSWORD \ $REGISTER_SERVICE_OPTS",29,8
openstack%2Fpython-solumclient~master~Ibb450e2ea1759c678d442e98e6224a6dbe18b15f,openstack/python-solumclient,master,Ibb450e2ea1759c678d442e98e6224a6dbe18b15f,Fall back to YAML after failing to parse JSON,ABANDONED,2014-06-24 15:47:00.000000000,2014-06-24 16:46:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-24 15:47:00.000000000', 'files': ['solumclient/common/base.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/94afda9a917bb0c0c3054dc7668e9fe9424bf987', 'message': 'Fall back to YAML after failing to parse JSON\n\nAttempt to parse response content as JSON first,\nbut fall back to YAML if that fails.\n\nChange-Id: Ibb450e2ea1759c678d442e98e6224a6dbe18b15f\n'}]",0,102276,94afda9a917bb0c0c3054dc7668e9fe9424bf987,4,1,1,1375,,,0,"Fall back to YAML after failing to parse JSON

Attempt to parse response content as JSON first,
but fall back to YAML if that fails.

Change-Id: Ibb450e2ea1759c678d442e98e6224a6dbe18b15f
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/76/102276/1 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/common/base.py'],1,94afda9a917bb0c0c3054dc7668e9fe9424bf987,joy,"import simplejson import yaml def jsonoryaml(body): try: return body.json() except simplejson.scanner.JSONDecodeError as e: return yaml.load(body.content) body = self.client.get(url) body = jsonoryaml(body) body = self.client.post(url, json=json) else: body = self.client.get(url) body = jsonoryaml(body) body = self.client.post(url, json=json) body = jsonoryaml(body)"," body = self.client.get(url).json() body = self.client.post(url, json=json).json() else: body = self.client.get(url).json() body = self.client.post(url, json=json).json()",15,4
openstack%2Fosprofiler~master~Ieb9181a2e997e5e3ea02fd91d2b85aa54a4b83be,openstack/osprofiler,master,Ieb9181a2e997e5e3ea02fd91d2b85aa54a4b83be,Add extra docs in sqlalchemy module,MERGED,2014-06-24 16:06:32.000000000,2014-06-24 16:39:25.000000000,2014-06-24 16:39:24.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-24 16:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/c02835ebc592c033d031b1c5bcd54e6bc417d2ca', 'message': 'Add extra docs in sqlalchemy module\n\nChange-Id: Ieb9181a2e997e5e3ea02fd91d2b85aa54a4b83be\n'}, {'number': 2, 'created': '2014-06-24 16:07:44.000000000', 'files': ['osprofiler/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/d6217ffa83da97b411238b4bedcd63e1b14804d4', 'message': 'Add extra docs in sqlalchemy module\n\nChange-Id: Ieb9181a2e997e5e3ea02fd91d2b85aa54a4b83be\n'}]",0,102283,d6217ffa83da97b411238b4bedcd63e1b14804d4,9,2,2,6172,,,0,"Add extra docs in sqlalchemy module

Change-Id: Ieb9181a2e997e5e3ea02fd91d2b85aa54a4b83be
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/83/102283/2 && git format-patch -1 --stdout FETCH_HEAD,['osprofiler/sqlalchemy.py'],1,c02835ebc592c033d031b1c5bcd54e6bc417d2ca,simplify_code," """"""add_tracing does not add even listeners for sqlalchemy. This is quite important in case of sql migrations. Because it's not allowed to add these events. """""" """"""add_tracing adds listeners for sqlalchemy."""""" ",,7,0
openstack%2Fosprofiler~master~I74e05234a5638ffd93dbac9180d4497fcb5093ac,openstack/osprofiler,master,I74e05234a5638ffd93dbac9180d4497fcb5093ac,Make hmac required argument in profiler.Profiler.init,MERGED,2014-06-24 15:48:32.000000000,2014-06-24 16:26:11.000000000,2014-06-24 16:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-24 15:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/284c1bd4cffa7a2bda5eeaf751301fa65748cf82', 'message': 'Make hmac required argument in profiler.Profiler.init\n\nIn previous patch we changed behavior or profiler lib. Currently\nprofiler want create any notification if hmac key is not setted up\nand all messages are not properly signed by it.\n\nSo to avoid mistakes (e.g. forgot to init profiler with hmac key) this\nargument should be required (not optional)\n\nAs well a lot of improvments in docs related to profiler module\n\nChange-Id: I74e05234a5638ffd93dbac9180d4497fcb5093ac\n'}, {'number': 2, 'created': '2014-06-24 15:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/bebaa5b7529d5c7c3bf447fcef956efe67a51b25', 'message': 'Make hmac required argument in profiler.Profiler.init\n\nIn previous patch we changed behavior or profiler lib. Currently\nprofiler want create any notification if hmac key is not setted up\nand all messages are not properly signed by it.\n\nSo to avoid mistakes (e.g. forgot to init profiler with hmac key) this\nargument should be required (not optional)\n\nAs well a lot of improvments in docs related to profiler module\n\nChange-Id: I74e05234a5638ffd93dbac9180d4497fcb5093ac\n'}, {'number': 3, 'created': '2014-06-24 15:51:43.000000000', 'files': ['osprofiler/profiler.py', 'tests/test_profiler.py', 'osprofiler/web.py', 'tests/test_web.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/b6c2275d1dddc34f025eccd522801ba08e7f9d1f', 'message': 'Make hmac required argument in profiler.Profiler.init\n\nIn previous patch we changed behavior or profiler lib. Currently\nprofiler want create any notification if hmac key is not setted up\nand all messages are not properly signed by it.\n\nSo to avoid mistakes (e.g. forgot to init profiler with hmac key) this\nargument should be required (not optional)\n\nAs well a lot of improvments in docs related to profiler module\n\nChange-Id: I74e05234a5638ffd93dbac9180d4497fcb5093ac\n'}]",0,102277,b6c2275d1dddc34f025eccd522801ba08e7f9d1f,11,2,3,6172,,,0,"Make hmac required argument in profiler.Profiler.init

In previous patch we changed behavior or profiler lib. Currently
profiler want create any notification if hmac key is not setted up
and all messages are not properly signed by it.

So to avoid mistakes (e.g. forgot to init profiler with hmac key) this
argument should be required (not optional)

As well a lot of improvments in docs related to profiler module

Change-Id: I74e05234a5638ffd93dbac9180d4497fcb5093ac
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/77/102277/1 && git format-patch -1 --stdout FETCH_HEAD,"['osprofiler/profiler.py', 'tests/test_profiler.py', 'osprofiler/web.py', 'tests/test_web.py']",4,284c1bd4cffa7a2bda5eeaf751301fa65748cf82,simplify_code," profiler.init(None, base_id=""y"", parent_id=""z"") profiler.init(""key"", base_id=""y"", parent_id=""z"") mock_profiler_init.assert_called_once_with(hmac_key, base_id=""1"", parent_id=""2"")"," profiler.init(base_id=""y"", parent_id=""z"") profiler.init(base_id=""y"", parent_id=""z"", hmac_key=""key"") mock_profiler_init.assert_called_once_with(""1"", ""2"", hmac_key)",80,25
openstack%2Fdevstack-gate~master~I54925a468c4dc7eb9390a78d509b9385caa587d4,openstack/devstack-gate,master,I54925a468c4dc7eb9390a78d509b9385caa587d4,Fix typo in DEVSTACK_GATE_TEMPEST_NOVA_V3_API,MERGED,2014-06-23 13:49:40.000000000,2014-06-24 15:59:18.000000000,2014-06-24 15:59:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 6786}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 13:49:40.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e5a09da30cb567cfe0652126ff18f16935314def', 'message': 'Fix typo in DEVSTACK_GATE_TEMPEST_NOVA_V3_API\n\nThis commit fixes a small oversight in setting the nova v3 api tempest\ntests. When this env variable was added to set whether the testing was\nenabled the check used a different variable name than the wrap script.\nAlso neither of these variables matched what was being set by jenkins,\nthis meant that the v3 api tests would never be enabled. This fixes\nthat by ensuring the variables are the same and matches the variable\nset in the JJB template for the v3 api jobs.\n\nChange-Id: I54925a468c4dc7eb9390a78d509b9385caa587d4\n'}]",0,101915,e5a09da30cb567cfe0652126ff18f16935314def,20,7,1,5196,,,0,"Fix typo in DEVSTACK_GATE_TEMPEST_NOVA_V3_API

This commit fixes a small oversight in setting the nova v3 api tempest
tests. When this env variable was added to set whether the testing was
enabled the check used a different variable name than the wrap script.
Also neither of these variables matched what was being set by jenkins,
this meant that the v3 api tests would never be enabled. This fixes
that by ensuring the variables are the same and matches the variable
set in the JJB template for the v3 api jobs.

Change-Id: I54925a468c4dc7eb9390a78d509b9385caa587d4
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/15/101915/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh']",2,e5a09da30cb567cfe0652126ff18f16935314def,(detached,export DEVSTACK_GATE_TEMPEST_NOVA_V3_API=${DEVSTACK_GATE_TEMPEST_NOVA_V3_API:-0},export DEVSTACK_GATE_TEMPEST_NOVA_API_v3=${DEVSTACK_GATE_TEMPEST_NOVA_API_v3:-0},2,2
openstack%2Fapi-site~master~Idd158f47b353e700ee4a84a859b88e3bb1c43a5d,openstack/api-site,master,Idd158f47b353e700ee4a84a859b88e3bb1c43a5d,"Fix: Adding detailed information about pause, unpause, suspend, and resume a server",ABANDONED,2014-06-20 15:48:08.000000000,2014-06-24 15:46:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-20 15:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/26156d01a03a91cd9b5e8d6dcb80bb736dff7322', 'message': 'Fix: updates after code review\n\nChange-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d\n'}, {'number': 2, 'created': '2014-06-23 19:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/db0aa6406ff0c4612adda93123d40c34ce72b2ff', 'message': 'Fix: Adding detailed information about pause, unpause, suspend, and resume a server\nCloses-Bug: 1295718\nChange-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d\n:\n'}, {'number': 3, 'created': '2014-06-23 19:32:42.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/ext/os-admin-actions.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/fec22c98d1c91f51bb4e04c8d8d041a7c38ca3cf', 'message': ' Fix: Adding detailed information about pause, unpause, suspend, and resume a server\n\nCloses-Bug: 1295718\nChange-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d\n'}]",0,101587,fec22c98d1c91f51bb4e04c8d8d041a7c38ca3cf,10,1,3,10279,,,0," Fix: Adding detailed information about pause, unpause, suspend, and resume a server

Closes-Bug: 1295718
Change-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d
",git fetch https://review.opendev.org/openstack/api-site refs/changes/87/101587/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2/ext/os-admin-actions.wadl'],1,26156d01a03a91cd9b5e8d6dcb80bb736dff7322,bug/1295718," making a <command>POST</command> request and setting the <parameter>unpause</parameter> parameter to <replaceable>null</replaceable>. For more information, see <xref linkend =""unpause""/>.</para> <para role=""shortdesc"">Suspends a server and changes its status to SUSPENDED. Administrative users may choose to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.</para>"," running the Unpause Server operation.</para> <para role=""shortdesc"">Suspends a server and changes its status to SUSPENDED. Administrative users may choose to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.</para>",2,3
openstack%2Ffuel-docs~stable%2F5.0~Id0a1f30860c501e1b40c93931ba0afb605e4548a,openstack/fuel-docs,stable/5.0,Id0a1f30860c501e1b40c93931ba0afb605e4548a,Added Fuel Setup guide,MERGED,2014-06-19 19:05:30.000000000,2014-06-24 15:34:30.000000000,2014-06-24 15:34:30.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-06-19 19:05:30.000000000', 'files': ['_images/fuelmenu_Network_Setup.jpg', '_images/fuel_welcome_customized_settings.jpg', '_images/fuelmenu_TimeSync.jpg', '_images/fuelmenu_DNS.jpg', '_images/fuelmenu_PXE_CustomizedSetup.jpg', 'pages/user-guide/initialize-fuel/0400-pxe-config.rst', '_images/fuelmenu_SaveQuit.jpg', '_images/fuelmenu_PXE_Setup.jpg', '_images/fuelmenu_Network_Customized_Setup.jpg', '_images/fuelmenu_Network_Docker.jpg'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1c46dc9c8234add8e64b2aa019d25ef281cfafc6', 'message': 'Added Fuel Setup guide\n\nAdded fuel Setup guide and images.\nIncreased image resolution and added more images.\nAdded options explanation for each section.\nCorrected spelling errors in accordance with comments.\n\nChange-Id: Id0a1f30860c501e1b40c93931ba0afb605e4548a\nCloses-Bug: #1326125\n(cherry picked from commit e64d0bcbd591982dd130075a087e785dca28d625)\n'}]",15,101291,1c46dc9c8234add8e64b2aa019d25ef281cfafc6,13,5,1,8967,,,0,"Added Fuel Setup guide

Added fuel Setup guide and images.
Increased image resolution and added more images.
Added options explanation for each section.
Corrected spelling errors in accordance with comments.

Change-Id: Id0a1f30860c501e1b40c93931ba0afb605e4548a
Closes-Bug: #1326125
(cherry picked from commit e64d0bcbd591982dd130075a087e785dca28d625)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/91/101291/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/fuel_welcome_customized_settings.jpg', '_images/fuelmenu_Network_Setup.jpg', '_images/fuelmenu_TimeSync.jpg', '_images/fuelmenu_DNS.jpg', '_images/fuelmenu_PXE_CustomizedSetup.jpg', 'pages/user-guide/initialize-fuel/0400-pxe-config.rst', '_images/fuelmenu_SaveQuit.jpg', '_images/fuelmenu_PXE_Setup.jpg', '_images/fuelmenu_Network_Customized_Setup.jpg', '_images/fuelmenu_Network_Docker.jpg']",10,1c46dc9c8234add8e64b2aa019d25ef281cfafc6,,,,329,35
openstack%2Fcookbook-openstack-ops-database~master~I6a4593ffb2eb40605f74b27493101b63a7d71eda,openstack/cookbook-openstack-ops-database,master,I6a4593ffb2eb40605f74b27493101b63a7d71eda,Removed commented code from spec/mysql-server_spec.rb,ABANDONED,2014-06-20 18:44:07.000000000,2014-06-24 15:33:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-20 18:44:07.000000000', 'files': ['spec/mysql-server_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/02073322a63b12149bc74d14136beb89d53b0164', 'message': 'Removed commented code from spec/mysql-server_spec.rb\n\nChange-Id: I6a4593ffb2eb40605f74b27493101b63a7d71eda\n'}]",0,101623,02073322a63b12149bc74d14136beb89d53b0164,10,4,1,12044,,,0,"Removed commented code from spec/mysql-server_spec.rb

Change-Id: I6a4593ffb2eb40605f74b27493101b63a7d71eda
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/23/101623/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/mysql-server_spec.rb'],1,02073322a63b12149bc74d14136beb89d53b0164,update-mysql-database-recipe,,"# it 'modifies my.cnf template to notify mysql restart' do # file = chef_run.template '/etc/mysql/my.cnf' # expect(file).to notify('service[mysql]').to(:restart) # end # describe 'lwrps' do # connection = { # host: 'localhost', # username: 'root', # password: 'server-root-password' # } # it 'removes insecure default localhost mysql users' do # resource = chef_run.find_resource( # 'mysql_database', # 'drop empty localhost user' # ).to_hash # expect(resource).to include( # sql: ""DELETE FROM mysql.user WHERE User = '' OR Password = ''"", # connection: connection, # action: [:query] # ) # end # it 'drops the test database' do # resource = chef_run.find_resource( # 'mysql_database', # 'test' # ).to_hash # expect(resource).to include( # connection: connection, # action: [:drop] # ) # end # it 'flushes privileges' do # resource = chef_run.find_resource( # 'mysql_database', # 'FLUSH PRIVILEGES' # ).to_hash # expect(resource).to include( # connection: connection, # sql: 'FLUSH PRIVILEGES', # action: [:query] # ) # end # end",0,50
openstack%2Ftelemetry-specs~master~If6c83c112f1e5d193cf31481cbd11759c7213c7d,openstack/telemetry-specs,master,If6c83c112f1e5d193cf31481cbd11759c7213c7d,Fixed typos found by RETF rules,MERGED,2014-05-29 19:42:14.000000000,2014-06-24 15:29:52.000000000,2014-06-24 15:29:52.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 8290}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-05-29 19:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/278d995f088951a9b60a5a320f40f263609cabf8', 'message': 'fixed typos found by RETF rules\n\nrules are avaialble at https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser/Typos\n\nChange-Id: If6c83c112f1e5d193cf31481cbd11759c7213c7d\n'}, {'number': 2, 'created': '2014-05-29 20:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/9e654e92cc3acd4876931b991157f325912fca8f', 'message': 'Fixed typos found by RETF rules\n\nRules are avaialble at https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser/Typos.\nFixed some more typos found by Dina Belova.\n\nChange-Id: If6c83c112f1e5d193cf31481cbd11759c7213c7d\n'}, {'number': 3, 'created': '2014-06-06 10:44:24.000000000', 'files': ['specs/template.rst', 'specs/juno/dedicated-alarm-database.rst', 'specs/juno/gnocchi.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/30c7bab6a911162a3094fc0d801d27a387b85c38', 'message': 'Fixed typos found by RETF rules\n\nRules are avaialble at https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser/Typos.\nFixed some more typos found by Dina Belova.\n\nChange-Id: If6c83c112f1e5d193cf31481cbd11759c7213c7d\n'}]",8,96565,30c7bab6a911162a3094fc0d801d27a387b85c38,29,7,3,167,,,0,"Fixed typos found by RETF rules

Rules are avaialble at https://en.wikipedia.org/wiki/Wikipedia:AutoWikiBrowser/Typos.
Fixed some more typos found by Dina Belova.

Change-Id: If6c83c112f1e5d193cf31481cbd11759c7213c7d
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/65/96565/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/template.rst', 'specs/juno/dedicated-alarm-database.rst', 'specs/juno/gnocchi.rst']",3,278d995f088951a9b60a5a320f40f263609cabf8,retf,Having the so-called free form metadata associated with each metriclot of redundant information that it is hard to query in an efficient manner.information (the so-called metadata) about resources.,Having the so called free form metadata associated with each metriclot of redundant information that it is hard to query in a efficient manner.information (the so called metadata) about resources.,6,6
openstack%2Fapi-site~master~Idcc7ae26756ff23f3a38247905772789efcd2422,openstack/api-site,master,Idcc7ae26756ff23f3a38247905772789efcd2422,Test ko_KR api-quick-start,MERGED,2014-06-24 10:05:37.000000000,2014-06-24 15:24:29.000000000,2014-06-24 15:24:29.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-06-24 10:05:37.000000000', 'files': ['tools/test-languages.sh'], 'web_link': 'https://opendev.org/openstack/api-site/commit/404029878d4a83b31e9572f5d7272ea92d84d4f3', 'message': ""Test ko_KR api-quick-start\n\nThe guide is translated, let's test it now.\n\nChange-Id: Idcc7ae26756ff23f3a38247905772789efcd2422\n""}]",0,102168,404029878d4a83b31e9572f5d7272ea92d84d4f3,8,3,1,6547,,,0,"Test ko_KR api-quick-start

The guide is translated, let's test it now.

Change-Id: Idcc7ae26756ff23f3a38247905772789efcd2422
",git fetch https://review.opendev.org/openstack/api-site refs/changes/68/102168/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/test-languages.sh'],1,404029878d4a83b31e9572f5d7272ea92d84d4f3,add-ko_KR, test_manuals 'ko_KR' 'api-quick-start',,1,0
openstack%2Foslo-incubator~master~I653264cc556f547d4550bec72c88896f659ab854,openstack/oslo-incubator,master,I653264cc556f547d4550bec72c88896f659ab854,Move Microseconds to date-format instead of log-format,ABANDONED,2014-05-02 01:47:30.000000000,2014-06-24 15:20:30.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-05-02 01:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/848987842cd7bc7d9d7689bfdbe2b12ef06a3b04', 'message': 'Move Microseconds to date-format instead of log-format\n\nMicrosecond resolution has been moved to the date-format string\ninstead of being embeded in the default log string. This makes it\npossible to change the date format (including microseconds) without\nneeding to change both the log-formatting options and the\nlog-date-format option.\n\nChange-Id: I653264cc556f547d4550bec72c88896f659ab854\n'}, {'number': 2, 'created': '2014-05-02 02:35:49.000000000', 'files': ['openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d6619508cb02b8b57e635aff7ff49f323ff12a7e', 'message': ""Move Microseconds to date-format instead of log-format\n\nMicrosecond resolution has been moved to the date-format string\ninstead of being embeded in the default log string. This makes it\npossible to change the date format (including microseconds) without\nneeding to change both the log-formatting options and the\nlog-date-format option.\n\nMoving the microsecond time resolution to the date formatter is done\nby overriding the ``formatTime`` method and doing a simple string\nsub on the %(msecs) substitution format string.\n\nIn the case that the legacy (deprecated) log-format option is used,\nthe %(msecs)03d is removed from the datefmt line (if it exists) as\nthe formatter doesn't know how to handle the substitution.\n\nChange-Id: I653264cc556f547d4550bec72c88896f659ab854\n""}]",2,91718,d6619508cb02b8b57e635aff7ff49f323ff12a7e,15,4,2,2903,,,0,"Move Microseconds to date-format instead of log-format

Microsecond resolution has been moved to the date-format string
instead of being embeded in the default log string. This makes it
possible to change the date format (including microseconds) without
needing to change both the log-formatting options and the
log-date-format option.

Moving the microsecond time resolution to the date formatter is done
by overriding the ``formatTime`` method and doing a simple string
sub on the %(msecs) substitution format string.

In the case that the legacy (deprecated) log-format option is used,
the %(msecs)03d is removed from the datefmt line (if it exists) as
the formatter doesn't know how to handle the substitution.

Change-Id: I653264cc556f547d4550bec72c88896f659ab854
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/18/91718/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/log.py'],1,848987842cd7bc7d9d7689bfdbe2b12ef06a3b04,move_microseconds_to_date_fmt_opt,"_DEFAULT_LOG_DATE_FORMAT = ""%Y-%m-%d %H:%M:%S.%f"" default='%(asctime)s %(process)d %(levelname)s ' default='%(asctime)s %(process)d %(levelname)s ' default='%(asctime)s %(process)d TRACE %(name)s '","_DEFAULT_LOG_DATE_FORMAT = ""%Y-%m-%d %H:%M:%S"" default='%(asctime)s.%(msecs)03d %(process)d %(levelname)s ' default='%(asctime)s.%(msecs)03d %(process)d %(levelname)s ' default='%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s '",4,4
openstack%2Fkeystone-specs~master~I2009716e98b0c29debf25294cc0a8a2f0f71b69a,openstack/keystone-specs,master,I2009716e98b0c29debf25294cc0a8a2f0f71b69a,Propose token versions independent from API versions,ABANDONED,2014-06-06 16:50:05.000000000,2014-06-24 15:19:56.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}]","[{'number': 1, 'created': '2014-06-06 16:50:05.000000000', 'files': ['specs/juno/token-versions.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/73b3ca96d39c6f8a4bcac74de61bd50538b0e1cd', 'message': 'Propose token versions independent from API versions\n\nThis spec proposes a change to make token versions independent of\nAPI versions. This allows for initiatives such as ID-Only tokens\nand drastic restructure of token data without breaking current\nclients.\n\nChange-Id: I2009716e98b0c29debf25294cc0a8a2f0f71b69a\n'}]",7,98464,73b3ca96d39c6f8a4bcac74de61bd50538b0e1cd,8,3,1,2903,,,0,"Propose token versions independent from API versions

This spec proposes a change to make token versions independent of
API versions. This allows for initiatives such as ID-Only tokens
and drastic restructure of token data without breaking current
clients.

Change-Id: I2009716e98b0c29debf25294cc0a8a2f0f71b69a
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/64/98464/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/token-versions.rst'],1,73b3ca96d39c6f8a4bcac74de61bd50538b0e1cd,token_versions,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================== Independent Token Versions ========================== `proposed bp token-versions <https://blueprints.launchpad.net/keystone/+spec/token-versions>`_ Currently the Token version is dependent on the Keystone API version. It should be possible to enhance/change the Token format without needing to change the API version. Problem Description =================== * Token format should not change and have new data added to it within a given version. If the data represented in the token requires additions or restructuring, the token version should increment * Tokens should see a drastic reduction in data within the token. Having the ability to version the Tokens independently of the Keystone API will make this prospect easier. * Tokens should have a test to ensure that the data types and amount of data within the Token does not change. Proposed Change =============== Each token version will have a formatting class (that converts the internal Keystone object to the emitted token). When requesting a token, a specific version can be requested. If a specific token version is requested, the server will attempt to issue a token of that version. * In the case the version exceeds the maximum supported version number a NotImplemented error will be raised. * If no version is specified, the server default will be used. The default version will be a configuration option. * If a version is no longer supported an exception indicating the version is no longer available will be raised. * ``keystoneclient`` will be the location of the emit/decode logic for each token version. If there are other additional mechanisms required to make use of the token version, that logic will be provided with the validation/emit/decode logic (e.g. ID only token may need another mechanism to receive the service catalog). * All APIs that can issue tokens need to support the token version request mechanism. Alternatives ------------ * It would be possible to continue to modify the token format for each API version. No data can be removed from tokens (easily) without potentially breaking clients. Token format has not been declared ""private"" data and therefore an implicit contract on format exists (and should be maintained) * Make no change to the current system. There is a desire to drastically reduce the size of the token. To successfully accomplish this goal keeping with the method of handling tokens is unlikely to happen because of the aforementioned implicit contract on token format. Data Model Impact ----------------- The Token Data model will not change. The emitted serialized format will be token-version specific. REST API Impact --------------- On token issuance a query string of 'token_version=<version>' will be supported (optional). This version will be used to determine what the token format should be emitted as. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? Token format will change. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No changes to access of data or mechanisms to login should occur. * Does this change involve cryptography or hashing? No * Does this change require the use of sudo or any elevated privileges? No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. No * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. No Notifications Impact -------------------- No extra notifications will be emitted. Other End User Impact --------------------- End users will be able to request a specific token version, but the overall interaction with Keystone and OpenStack services should remain 100% the same. Performance Impact ------------------ A reduced token size will improve performance on both signing and validating. Allowing reduction / massive change in token format will allow working towards eliminating bottlenecks caused by the Token format itself. Other Deployer Impact --------------------- Deployers will be able to change the default token format emitted. This requires knowing which keystoneclients are used to interact with their OpenStack deployment. Initially the default will be to emit the current token formats (v2.0 and v3) on the expected interfaces. This default will be maintained for at least 2 cycles to ensure compatibility. Developer Impact ---------------- Developers doing direct introspection on the serialized form of the token will need to understand the new token validation/emit/deserialization logic. No other developer impact should occur. Implementation ============== Assignee(s) ----------- Primary assignee: Morgan Fainberg <mdrnstm> Other contributors: None Work Items ---------- * Implement new Validation / Emitting / Deserialization logic for tokens * Implement the V2.0 and v3 token formatters. * Implement the reduced size v4 token. Potentially ID-Only [1] * Implement query string handler for token version requests on authentication * Implement support in ``auth_token`` middleware to support the new token versions. Dependencies ============ No external dependencies. Testing ======= Unit tests for token format (each format) to ensure no data creep occurs. [2] Documentation Impact ==================== Documentation on the token and data provided should be developed for each supported token format. References ========== * 1. https://gist.github.com/dolph/10757712 * 2. https://bugs.launchpad.net/keystone/+bug/1224273 ",,222,0
openstack%2Foslo.messaging~master~I56dfa54a178962d4ced34e2f15eaf9312b7087cc,openstack/oslo.messaging,master,I56dfa54a178962d4ced34e2f15eaf9312b7087cc,RPC server doc: use the blocking executor,MERGED,2014-06-22 07:48:50.000000000,2014-06-24 15:09:38.000000000,2014-06-24 15:09:37.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 7923}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-22 07:48:50.000000000', 'files': ['oslo/messaging/rpc/server.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/221144600abf3017cb9b787ea1111fe0bb8aa6a0', 'message': 'RPC server doc: use the blocking executor\n\nThe eventlet executor need additional code to make the RPC server sample\nwork. Using the blocking executor makes things easier to setup for a\nnewcomer.\n\nChange-Id: I56dfa54a178962d4ced34e2f15eaf9312b7087cc\n'}]",0,101741,221144600abf3017cb9b787ea1111fe0bb8aa6a0,15,6,1,7923,,,0,"RPC server doc: use the blocking executor

The eventlet executor need additional code to make the RPC server sample
work. Using the blocking executor makes things easier to setup for a
newcomer.

Change-Id: I56dfa54a178962d4ced34e2f15eaf9312b7087cc
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/41/101741/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/rpc/server.py'],1,221144600abf3017cb9b787ea1111fe0bb8aa6a0,rpc-server-doc, executor='blocking'), executor='eventlet'),1,1
openstack-attic%2Fopenstack-security-notes~master~Ic142853a238f30f4f50e2616a533637e8cb895ef,openstack-attic/openstack-security-notes,master,Ic142853a238f30f4f50e2616a533637e8cb895ef,Add OSSN-0018 - Dangerous network configuration,MERGED,2014-06-13 20:12:46.000000000,2014-06-24 15:02:38.000000000,2014-06-24 15:02:37.000000000,"[{'_account_id': 3}, {'_account_id': 1038}, {'_account_id': 1501}, {'_account_id': 1528}, {'_account_id': 1561}, {'_account_id': 2807}, {'_account_id': 7063}, {'_account_id': 9098}, {'_account_id': 11397}, {'_account_id': 11716}, {'_account_id': 11861}, {'_account_id': 12014}]","[{'number': 1, 'created': '2014-06-13 20:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/656c91e54cab9faf1a6a0971f238753e839b55d8', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}, {'number': 2, 'created': '2014-06-16 13:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/4f7e91ad9f500c3f7030f57232a52c4a8c15b168', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}, {'number': 3, 'created': '2014-06-16 16:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/7e754e8744cfd6a3629ad318463a60b534c801c2', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}, {'number': 4, 'created': '2014-06-18 12:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/65f07280d06452b8b3ffbd0cf4ab468be1d2f175', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}, {'number': 5, 'created': '2014-06-18 13:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/eaa63973f73ce036a8abe5d70f2ac09f73316e8b', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}, {'number': 6, 'created': '2014-06-18 16:11:13.000000000', 'files': ['notes/OSSN-0018'], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/c6d62a198a1f5387d40361e05f3b66aa64064d8c', 'message': 'Add OSSN-0018 - Dangerous network configuration\n\nChange-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef\nRelated-Bug: 1316271\n'}]",30,100008,c6d62a198a1f5387d40361e05f3b66aa64064d8c,40,12,6,1528,,,0,"Add OSSN-0018 - Dangerous network configuration

Change-Id: Ic142853a238f30f4f50e2616a533637e8cb895ef
Related-Bug: 1316271
",git fetch https://review.opendev.org/openstack-attic/openstack-security-notes refs/changes/08/100008/5 && git format-patch -1 --stdout FETCH_HEAD,['notes/OSSN-0018'],1,656c91e54cab9faf1a6a0971f238753e839b55d8,bug/1316271,"Network configuration allows guest VMs to connect to host services --- ### Summary ### When using nova-network for managing networking for the instances, some configurations will result in instances being able to reach services running on the host machine. This may be a security issue for the operator. ### Affected Services / Software ### Nova; Folsom, Grizzly, Havana, Icehouse ### Discussion ### OpenStack deployments using nova-network, rather than neutron for network configuration will cause the host running the instances to be reachable on the virtual network. Specifically, booted instances can check the address of their gateway and try to connect to it. Any host service which listens on the interfaces created by OpenStack and does not apply any additional filtering will receive such traffic. This is a security issue in deployments where the OpenStack service users are not trusted parties, or should not be allowed to access underlaying services. Using a specific example of devstack in default configuration, the instance spawned inside of it will see the following routing table: $ ip r s default via 172.16.1.1 dev eth0 172.16.1.0/24 dev eth0 src 172.16.1.2 The instance can then use the gateway's address (172.16.1.1) to connect to the sshd on the host system (if one is running and listening on all interfaces). The host system will see the connection coming from interface `br100`. ### Recommended Actions ### Connections like this can be stopped at various levels (libvirt filters, specific host's iptables entries, ebtables, network service configuration). The recommended way to protect against the incoming connections is to stop the critical services from binding to the nova-controlled interfaces in the first place. Using `sshd` service as an example, the standard configuration on most systems is to bind to all interfaces and all local addresses (""ListenAddress :22"" in sshd_config). In order to configure it only on a specific interface, use ""ListenAddress a.b.c.d:22"" where a.b.c.d is the address assigned to the chosen interface. Similar settings can be found for most other services. List of services listening on all interfaces can be obtained by running command `netstat -ltu`, where the '*:port' in the ""Local Address"" field means service will likely accept connections from the local nova instances. If filtering of the traffic is chosen instead, care must be taken to allow traffic coming from the running instances to services controlled by nova - dhcp and dns providers. ### Contacts / References ### This OSSN : https://wiki.openstack.org/wiki/OSSN/OSSN-0018 Original LaunchPad Bug : https://bugs.launchpad.net/nova/+bug/1316271 OpenStack Security ML : openstack-security@lists.openstack.org OpenStack Security Group : https://launchpad.net/~openstack-ossg ",,64,0
openstack%2Fpython-glanceclient~master~I885a82643d2620f393f21c36b3ad95cb7ed43f2c,openstack/python-glanceclient,master,I885a82643d2620f393f21c36b3ad95cb7ed43f2c,Set purge-props header correctly in image update,MERGED,2014-05-10 00:30:04.000000000,2014-06-24 15:00:23.000000000,2014-06-24 15:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9046}]","[{'number': 1, 'created': '2014-05-10 00:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7651d2d2453db39e02785613830434dfe02fe147', 'message': ""Set purge-props header correctly in image update\n\nCurrently when an image is updated, the purge property\nheader is only set to true in some cases, but when\nrequired it isn't set to false\n\nChange-Id: I885a82643d2620f393f21c36b3ad95cb7ed43f2c\nCloses-Bug: 1318079\n""}, {'number': 2, 'created': '2014-06-19 08:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/180770b0f7b6cb499889aefbaf0df962a3aa8467', 'message': ""Set purge-props header correctly in image update\n\nCurrently when an image is updated, the purge property\nheader is only set to true in some cases, but when\nrequired it isn't set to false\n\nChange-Id: I885a82643d2620f393f21c36b3ad95cb7ed43f2c\nCloses-Bug: 1318079\n""}, {'number': 3, 'created': '2014-06-20 00:37:40.000000000', 'files': ['glanceclient/v1/images.py', 'tests/v1/test_images.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cddc37dcab80eec3eb3b9a2849c09c1ae3892381', 'message': ""Set purge-props header correctly in image update\n\nCurrently when an image is updated, the purge property\nheader is only set to true in some cases, but when\nrequired it isn't set to false\n\nChange-Id: I885a82643d2620f393f21c36b3ad95cb7ed43f2c\nCloses-Bug: 1318079\n""}]",8,93162,cddc37dcab80eec3eb3b9a2849c09c1ae3892381,37,7,3,9046,,,0,"Set purge-props header correctly in image update

Currently when an image is updated, the purge property
header is only set to true in some cases, but when
required it isn't set to false

Change-Id: I885a82643d2620f393f21c36b3ad95cb7ed43f2c
Closes-Bug: 1318079
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/62/93162/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/v1/images.py', 'tests/v1/test_images.py']",2,7651d2d2453db39e02785613830434dfe02fe147,bug/1318079," 'x-glance-registry-purge-props': 'false', expect_headers = {'x-image-meta-size': '3', 'x-glance-registry-purge-props': 'false'} 'x-glance-registry-purge-props': 'false', ('PUT', '/v1/images/1', {'x-image-meta-name': 'image-5', 'x-glance-registry-purge-props': 'false'}, None),"," expect_headers = {'x-image-meta-size': '3'} ('PUT', '/v1/images/1', {'x-image-meta-name': 'image-5'}, None),",12,8
openstack%2Fzaqar~master~I4772568ff91a7a72f2633a0b4fe45d4f11a2c5da,openstack/zaqar,master,I4772568ff91a7a72f2633a0b4fe45d4f11a2c5da,Fix two caching-related comments in the code,MERGED,2014-06-12 16:40:56.000000000,2014-06-24 14:55:42.000000000,2014-06-24 14:55:42.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 8092}]","[{'number': 1, 'created': '2014-06-12 16:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/522c11f644dc43172df1b8a583ef2b0dea4348f9', 'message': 'Fix two caching-related comments in the code\n\nThis patch updates a couple caching-related comments that were\ninaccurate or ambiguous.\n\nSee also: https://review.openstack.org/#/c/67978\n\nChange-Id: I4772568ff91a7a72f2633a0b4fe45d4f11a2c5da\n'}, {'number': 2, 'created': '2014-06-23 17:48:51.000000000', 'files': ['marconi/queues/storage/mongodb/queues.py', 'marconi/queues/storage/pooling.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6646cc310688a3cd8e22cafae9dd7308db9256df', 'message': 'Fix two caching-related comments in the code\n\nThis patch updates a couple caching-related comments that were\ninaccurate or ambiguous.\n\nSee also: https://review.openstack.org/#/c/67978\n\nChange-Id: I4772568ff91a7a72f2633a0b4fe45d4f11a2c5da\n'}]",0,99712,6646cc310688a3cd8e22cafae9dd7308db9256df,18,5,2,6427,,,0,"Fix two caching-related comments in the code

This patch updates a couple caching-related comments that were
inaccurate or ambiguous.

See also: https://review.openstack.org/#/c/67978

Change-Id: I4772568ff91a7a72f2633a0b4fe45d4f11a2c5da
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/12/99712/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/storage/mongodb/queues.py', 'marconi/queues/storage/sharding.py']",2,522c11f644dc43172df1b8a583ef2b0dea4348f9,cache-fixup,# TODO(kgriffs): Make configurable?,# TODO(kgriffs): Make dynamic?,2,2
openstack%2Ffuel-main~master~If7c5e797aa69edf5dcbc0fb70b255a0c178ce8c8,openstack/fuel-main,master,If7c5e797aa69edf5dcbc0fb70b255a0c178ce8c8,Add ceilometer-agent-notification package to requirements,ABANDONED,2014-06-24 14:41:29.000000000,2014-06-24 14:55:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 14:41:29.000000000', 'files': ['requirements-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/be41ac977f4c0291b792f5d1304f9d8bf266b6ba', 'message': 'Add ceilometer-agent-notification package to requirements\n\nChange-Id: If7c5e797aa69edf5dcbc0fb70b255a0c178ce8c8\nPartial-bug: #1333722\n'}]",0,102258,be41ac977f4c0291b792f5d1304f9d8bf266b6ba,7,2,1,7732,,,0,"Add ceilometer-agent-notification package to requirements

Change-Id: If7c5e797aa69edf5dcbc0fb70b255a0c178ce8c8
Partial-bug: #1333722
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/58/102258/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-rpm.txt'],1,be41ac977f4c0291b792f5d1304f9d8bf266b6ba,master,openstack-ceilometer-notification,,1,0
openstack%2Fzaqar~master~I9249747557b0784982f2fe75c1f13fd866a16616,openstack/zaqar,master,I9249747557b0784982f2fe75c1f13fd866a16616,Rename shard to pool,MERGED,2014-06-24 06:16:02.000000000,2014-06-24 14:53:35.000000000,2014-06-24 14:53:34.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 7498}]","[{'number': 1, 'created': '2014-06-24 06:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c2044837a6fccc538b76ff1bf18e29f700b34ffb', 'message': 'Rename shard to pool\n\nChange-Id: I9249747557b0784982f2fe75c1f13fd866a16616\nCloses-Bug: #1333152\n'}, {'number': 2, 'created': '2014-06-24 06:22:37.000000000', 'files': ['doc/source/installing.rst', 'tools/config/oslo.config.generator.rc', 'doc/source/glossary.rst', 'setup.cfg', 'etc/marconi.conf.sample'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1060dd8745190c172ae493970273ca145be89764', 'message': 'Rename shard to pool\n\nMost of the work done in https://review.openstack.org/#/c/96463/\nand here are for those left.\n\nChange-Id: I9249747557b0784982f2fe75c1f13fd866a16616\nCloses-Bug: #1333152\n'}]",0,102116,1060dd8745190c172ae493970273ca145be89764,10,3,2,10634,,,0,"Rename shard to pool

Most of the work done in https://review.openstack.org/#/c/96463/
and here are for those left.

Change-Id: I9249747557b0784982f2fe75c1f13fd866a16616
Closes-Bug: #1333152
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/16/102116/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/installing.rst', 'doc/source/glossary.rst', 'tools/config/oslo.config.generator.rc', 'setup.cfg', 'etc/marconi.conf.sample']",5,c2044837a6fccc538b76ff1bf18e29f700b34ffb,bug/1333152,"# Enable pooling across multiple storage backends. If # pooling is enabled, the storage driver configuration is # used to determine where the catalogue/control plane data # is kept. (boolean value) #pooling=false # Activate endpoints to manage pool registry. (boolean value)[pooling:catalog]# Options defined in marconi.storage.pooling","# ('Enable sharding across multiple storage backends. ', 'If # sharding is enabled, the storage driver ', 'configuration is # used to determine where the ', 'catalogue/control plane data # is kept.') (boolean value) #sharding=false # Activate endpoints to manage shard registry. (boolean value)[sharding:catalog]# Options defined in marconi.storage.sharding",23,23
openstack%2Ffuel-main~master~I4a0bdb8ac9fab6c34836ce72f4d506672d48d394,openstack/fuel-main,master,I4a0bdb8ac9fab6c34836ce72f4d506672d48d394,Add centos-versions.yaml and ubuntu-versions.yaml files for MOS 5.0,MERGED,2014-06-19 13:33:23.000000000,2014-06-24 14:27:02.000000000,2014-06-24 14:27:01.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-19 13:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b9e6e866892ef9b4b2b96c7f4017675d0c594dd8', 'message': 'Add centos-versions.yaml and ubuntu-versions.yaml files for MOS 5.0\n\nCloses-Bug: #1332085\n\nChange-Id: I4a0bdb8ac9fab6c34836ce72f4d506672d48d394\n'}, {'number': 2, 'created': '2014-06-19 13:57:58.000000000', 'files': ['upgrade/config/5.0/centos-versions.yaml', 'upgrade/module.mk', 'upgrade/config/5.0/ubuntu-versions.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5de25510b9154d68efc5aa68440e2cfd8c6b4d29', 'message': 'Add centos-versions.yaml and ubuntu-versions.yaml files for MOS 5.0\n\nCloses-Bug: #1332085\n\nChange-Id: I4a0bdb8ac9fab6c34836ce72f4d506672d48d394\n'}]",0,101207,5de25510b9154d68efc5aa68440e2cfd8c6b4d29,18,5,2,8392,,,0,"Add centos-versions.yaml and ubuntu-versions.yaml files for MOS 5.0

Closes-Bug: #1332085

Change-Id: I4a0bdb8ac9fab6c34836ce72f4d506672d48d394
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/07/101207/1 && git format-patch -1 --stdout FETCH_HEAD,"['upgrade/configs/5.0/ubuntu-versions.yaml', 'upgrade/configs/5.0/centos-versions.yaml']",2,b9e6e866892ef9b4b2b96c7f4017675d0c594dd8,(detached,"abrt: ""2.0.8-21.el6.centos"" abrt-addon-ccpp: ""2.0.8-21.el6.centos"" abrt-addon-kerneloops: ""2.0.8-21.el6.centos"" abrt-addon-python: ""2.0.8-21.el6.centos"" abrt-cli: ""2.0.8-21.el6.centos"" abrt-libs: ""2.0.8-21.el6.centos"" abrt-tui: ""2.0.8-21.el6.centos"" acl: ""2.2.49-6.el6"" acpid: ""1.0.10-2.1.el6"" aic94xx-firmware: ""30-2.el6"" alsa-lib: ""1.0.22-3.el6"" alsa-utils: ""1.0.22-5.el6"" apr: ""1.3.9-5.el6"" apr-util: ""1.3.9-3.el6.1"" apr-util-ldap: ""1.3.9-3.el6.1"" at: ""3.1.10-43.el6_2.1"" atk: ""1.30.0-1.el6"" atlas: ""3.8.4-2.el6"" atmel-firmware: ""1.3-7.el6"" atop: ""1.27-1.el6"" attr: ""2.4.44-7.el6"" audit: ""2.2-2.el6"" audit-libs: ""2.2-2.el6"" augeas-libs: ""1.0.0-5.mira1"" authconfig: ""6.1.12-13.el6"" autoconf: ""2.63-5.1.el6"" automake: ""1.11.1-4.el6"" avahi: ""0.6.25-12.el6"" avahi-libs: ""0.6.25-12.el6"" b43-fwcutter: ""012-2.2.el6"" b43-openfwwf: ""5.2-4.el6"" basesystem: ""10.0-4.el6"" bash: ""4.1.2-15.el6_4"" bc: ""1.06.95-1.el6"" bfa-firmware: ""3.2.21.1-2.el6"" bind-libs: ""9.8.2-0.23.rc1.el6_5.1"" bind-utils: ""9.8.2-0.23.rc1.el6_5.1"" binutils: ""2.20.51.0.2-5.36.el6"" biosdevname: ""0.5.0-2.el6"" blktrace: ""1.0.1-6.el6"" bluez-libs: ""4.66-1.el6"" boost-filesystem: ""1.41.0-18.el6"" boost-iostreams: ""1.41.0-18.el6"" boost-program-options: ""1.41.0-18.el6"" boost-system: ""1.41.0-18.el6"" boost-thread: ""1.41.0-18.el6"" bridge-utils: ""1.2-10.el6"" brlapi: ""0.5.4-7.el6"" brltty: ""4.1-7.el6"" btparser: ""0.17-2.el6"" btrfs-progs: ""0.20-0.2.git91d9eec.el6"" busybox: ""1.15.1-20.el6"" byacc: ""1.9.20070509-7.el6"" bzip2: ""1.0.5-7.el6_0"" bzip2-libs: ""1.0.5-7.el6_0"" ca-certificates: ""2013.1.95-65.1.el6_5"" cairo: ""1.8.8-3.1.el6"" c-ares19: ""1.9.1-4.el6.3"" ccs: ""0.16.2-69.el6_5.1"" celt051: ""0.5.1.3-0.el6"" centos-indexhtml: ""6-1.el6.centos"" centos-release: ""6-5.el6.centos.11.2"" ceph: ""0.67.8-16.g69a99e6.mira1"" ceph-deploy: ""1.2.7-0.mira.1"" ceph-radosgw: ""0.67.8-16.g69a99e6.mira1"" ceph-test: ""0.67.8-16.g69a99e6.mira1"" checkpolicy: ""2.0.22-1.el6"" chkconfig: ""1.3.49.3-2.el6_4.1"" cifs-utils: ""4.8.1-19.el6"" cirros-testvm: ""0.3.1-3"" cirros-testvmware: ""0.3.1-3.mira3"" cloog-ppl: ""0.15.7-1.2.el6"" cluster-glue-libs: ""1.0.11-59.1"" clusterlib: ""3.0.12.1-59.el6_5.2"" cman: ""3.0.12.1-59.el6_5.2"" cobbler: ""2.2.3-4.el6"" cobbler-web: ""2.2.3-4.el6"" compat-readline5: ""5.2-17.1.el6"" conntrack-tools: ""0.9.13-3.mira1"" ConsoleKit: ""0.4.1-3.el6"" ConsoleKit-libs: ""0.4.1-3.el6"" coreutils: ""8.4-31.el6_5.1"" coreutils-libs: ""8.4-31.el6_5.1"" corosync: ""1.4.6-26.2"" corosynclib: ""1.4.6-26.2"" cpio: ""2.10-11.el6_3"" cpp: ""4.4.7-4.el6"" cpufreq-init: ""1.0.0-0.el6"" cpuspeed: ""1.5-20.el6_4"" cracklib: ""2.8.16-4.el6"" cracklib-dicts: ""2.8.16-4.el6"" crda: ""1.1.1_2010.11.22-1.el6"" createrepo: ""0.9.9-18.el6"" crmsh: ""1.2.5-55.2"" cronie: ""1.4.4-12.el6"" cronie-anacron: ""1.4.4-12.el6"" cronie-noanacron: ""1.4.4-12.el6"" crontabs: ""1.10-33.el6"" cryptsetup-luks: ""1.2.0-7.el6"" cryptsetup-luks-libs: ""1.2.0-7.el6"" cups-libs: ""1.4.2-50.el6_4.5"" curl: ""7.19.7-37.el6_4"" cvs: ""1.11.23-16.el6"" cyrus-sasl: ""2.1.23-13.el6_3.1"" cyrus-sasl-lib: ""2.1.23-13.el6_3.1"" cyrus-sasl-md5: ""2.1.23-13.el6_3.1"" cyrus-sasl-plain: ""2.1.23-13.el6_3.1"" daemonize: ""1.7.3-1.el6"" dash: ""0.5.5.1-4.el6"" db4: ""4.7.25-18.el6_4"" db4-cxx: ""4.7.25-18.el6_4"" db4-devel: ""4.7.25-18.el6_4"" db4-utils: ""4.7.25-18.el6_4"" dbus: ""1.2.24-7.el6_3"" dbus-glib: ""0.86-6.el6"" dbus-libs: ""1.2.24-7.el6_3"" dbus-python: ""0.83.0-6.1.el6"" debootstrap: ""1.0.19-2.el6"" dejavu-fonts-common: ""2.30-2.el6"" dejavu-sans-fonts: ""2.30-2.el6"" deltaiso: ""3.5-0.5.20090913git.el6"" deltarpm: ""3.5-0.5.20090913git.el6"" desktop-file-utils: ""0.15-9.el6"" device-mapper: ""1.02.79-8.el6"" device-mapper-event: ""1.02.79-8.el6"" device-mapper-event-libs: ""1.02.79-8.el6"" device-mapper-libs: ""1.02.79-8.el6"" device-mapper-persistent-data: ""0.2.8-4.el6_5"" dhclient: ""4.1.1-38.P1.el6.centos"" dhcp: ""4.1.1-38.P1.el6.centos"" dhcp-common: ""4.1.1-38.P1.el6.centos"" diffutils: ""2.8.1-28.el6"" disktype: ""9-5.el6"" Django: ""1.3.4-1.el6"" Django14: ""1.4.8-1.el6"" dmidecode: ""2.11-2.el6"" dmraid: ""1.0.0.rc16-11.el6"" dmraid-events: ""1.0.0.rc16-11.el6"" dnsmasq: ""2.65-5.el6"" dnsmasq-utils: ""2.65-5.el6"" docker-io: ""0.10.0-2.mira2"" dosfstools: ""3.0.9-4.el6"" dracut: ""004-336.el6_5.2"" dracut-kernel: ""004-336.el6_5.2"" dstat: ""0.7.0-1.el6"" e2fsprogs: ""1.41.12-18.el6"" e2fsprogs-libs: ""1.41.12-18.el6"" ebtables: ""2.0.9-6.el6"" ed: ""1.1-3.3.el6"" efibootmgr: ""0.5.4-11.el6"" eggdbus: ""0.6-3.el6"" eject: ""2.1.5-17.el6"" elfutils: ""0.152-1.el6"" elfutils-libelf: ""0.152-1.el6"" elfutils-libs: ""0.152-1.el6"" erlang-appmon: ""R14B-04.8.el6"" erlang-asn1: ""R14B-04.8.el6"" erlang-common_test: ""R14B-04.8.el6"" erlang-compiler: ""R14B-04.8.el6"" erlang-cosEventDomain: ""R14B-04.8.el6"" erlang-cosEvent: ""R14B-04.8.el6"" erlang-cosFileTransfer: ""R14B-04.8.el6"" erlang-cosNotification: ""R14B-04.8.el6"" erlang-cosProperty: ""R14B-04.8.el6"" erlang-cosTime: ""R14B-04.8.el6"" erlang-cosTransactions: ""R14B-04.8.el6"" erlang-crypto: ""R14B-04.8.el6"" erlang-debugger: ""R14B-04.8.el6"" erlang-dialyzer: ""R14B-04.8.el6"" erlang-diameter: ""R14B-04.8.el6"" erlang-docbuilder: ""R14B-04.8.el6"" erlang-doc: ""R14B-04.8.el6"" erlang-edoc: ""R14B-04.8.el6"" erlang-erl_docgen: ""R14B-04.8.el6"" erlang-erl_interface: ""R14B-04.8.el6"" erlang-erts: ""R14B-04.8.el6"" erlang-et: ""R14B-04.8.el6"" erlang-eunit: ""R14B-04.8.el6"" erlang-examples: ""R14B-04.8.el6"" erlang-gs: ""R14B-04.8.el6"" erlang-hipe: ""R14B-04.8.el6"" erlang-ic: ""R14B-04.8.el6"" erlang-inets: ""R14B-04.8.el6"" erlang-inviso: ""R14B-04.8.el6"" erlang-jinterface: ""R14B-04.8.el6"" erlang-kernel: ""R14B-04.8.el6"" erlang-megaco: ""R14B-04.8.el6"" erlang-mnesia: ""R14B-04.8.el6"" erlang-observer: ""R14B-04.8.el6"" erlang-odbc: ""R14B-04.8.el6"" erlang-orber: ""R14B-04.8.el6"" erlang-os_mon: ""R14B-04.8.el6"" erlang-otp_mibs: ""R14B-04.8.el6"" erlang-parsetools: ""R14B-04.8.el6"" erlang-percept: ""R14B-04.8.el6"" erlang-pman: ""R14B-04.8.el6"" erlang-public_key: ""R14B-04.8.el6"" erlang: ""R14B-04.8.el6"" erlang-reltool: ""R14B-04.8.el6"" erlang-runtime_tools: ""R14B-04.8.el6"" erlang-sasl: ""R14B-04.8.el6"" erlang-snmp: ""R14B-04.8.el6"" erlang-ssh: ""R14B-04.8.el6"" erlang-ssl: ""R14B-04.8.el6"" erlang-stdlib: ""R14B-04.8.el6"" erlang-syntax_tools: ""R14B-04.8.el6"" erlang-test_server: ""R14B-04.8.el6"" erlang-toolbar: ""R14B-04.8.el6"" erlang-tools: ""R14B-04.8.el6"" erlang-tv: ""R14B-04.8.el6"" erlang-typer: ""R14B-04.8.el6"" erlang-webtool: ""R14B-04.8.el6"" erlang-wx: ""R14B-04.8.el6"" erlang-xmerl: ""R14B-04.8.el6"" ethtool: ""3.5-1.4.el6_5"" euca2ools: ""2.1.3-1.el6"" expat: ""2.0.1-11.el6_2"" facter: ""1.7.0-1.el6"" fcgiwrap: ""1.0.3-2"" febootstrap-supermin-helper: ""3.21-4.mira1"" fence-agents: ""3.1.5-35.el6_5.4"" fence-virt: ""0.2.3-15.el6"" fencing-agent: ""0.1.0-1"" file: ""5.04-15.el6"" file-libs: ""5.04-15.el6"" filesystem: ""2.4.30-3.el6"" findutils: ""4.4.2-6.el6"" fipscheck: ""1.2.0-7.el6"" fipscheck-lib: ""1.2.0-7.el6"" flac: ""1.2.1-6.1.el6"" flex: ""2.5.35-8.el6"" fontconfig: ""2.8.0-3.el6"" fontpackages-filesystem: ""1.41-1.1.el6"" fping: ""2.4b2-16.mira1"" fprintd: ""0.1-21.git04fd09cfa.el6"" fprintd-pam: ""0.1-21.git04fd09cfa.el6"" freetype: ""2.3.11-14.el6_3.1"" fuelmenu: ""0.1-1"" fuel-ostf: ""0.1-1"" fuel-utils: ""20131119-2.el6"" fuse: ""2.8.3-4.el6"" fuse-libs: ""2.8.3-4.el6"" galera: ""23.2.2-6.el6"" gamin: ""0.1.10-9.el6"" gawk: ""3.1.7-10.el6"" gcc: ""4.4.7-4.el6"" gcc-c++: ""4.4.7-4.el6"" gd: ""2.0.35-11.el6"" gdb: ""7.2-60.el6_4.1"" gdbm: ""1.8.0-36.el6"" gdbm-devel: ""1.8.0-36.el6"" gdisk: ""0.8.4-1.el6"" genisoimage: ""1.1.10-1.el6"" GeoIP: ""1.4.8-1.el6"" gettext: ""0.17-16.el6"" ghostscript: ""8.70-19.el6"" ghostscript-fonts: ""5.50-23.1.el6"" giflib: ""4.1.6-3.1.el6"" git: ""1.7.1-3.el6_4.1"" glib2: ""2.26.1-7.el6_5"" glibc: ""2.12-1.132.el6_5.1"" glibc-common: ""2.12-1.132.el6_5.1"" glibc-devel: ""2.12-1.132.el6_5.1"" glibc-headers: ""2.12-1.132.el6_5.1"" gmp: ""4.3.1-7.el6_2.2"" gnupg2: ""2.0.14-6.el6_4"" gnutls: ""2.8.5-13.el6_5"" gnutls-utils: ""2.8.5-13.el6_5"" gperftools-libs: ""2.0-11.el6.3"" gpgme: ""1.1.8-3.el6"" gpm-libs: ""1.20.6-12.el6"" gpxe-bootimgs: ""0.9.7-6.10.el6"" grep: ""2.6.3-4.el6_5.1"" groff: ""1.18.1.4-21.el6"" grub: ""0.97-83.el6"" grubby: ""7.0.15-5.el6"" gtk2: ""2.20.1-4.el6"" gzip: ""1.3.12-19.el6_4"" hal: ""0.5.14-11.el6"" hal-info: ""20090716-3.1.el6"" hal-libs: ""0.5.14-11.el6"" haproxy: ""1.4.24-2.el6"" hdparm: ""9.43-4.el6"" hicolor-icon-theme: ""0.11-1.1.el6"" hiera: ""1.3.1-1.mira2"" htop: ""1.0.1-2.el6"" httpd: ""2.2.15-15.el6.1"" httpd-tools: ""2.2.15-15.el6.1"" http-parser: ""2.0-4.20121128gitcd01361.el6"" hunspell: ""1.2.8-16.el6"" hunspell-en: ""0.20090216-7.1.el6"" hwdata: ""0.233-9.1.el6"" iksemel: ""1.4-2.mira1"" info: ""4.13a-8.el6"" initscripts: ""9.03.40-2.el6.centos.1"" ipmitool: ""1.8.11-16.el6"" iproute: ""2.6.32-130.el6.netns.2.mira1"" iptables: ""1.4.7-11.el6"" iptables-ipv6: ""1.4.7-11.el6"" iputils: ""20071127-17.el6_4.2"" ipw2100-firmware: ""1.3-11.el6"" ipw2200-firmware: ""3.1-4.el6"" ipxe-roms-qemu: ""20120328-2.gitaac9718.el6"" irqbalance: ""1.0.4-9.el6_5"" iscsi-initiator-utils: ""6.2.0.873-10.el6"" ivtv-firmware: ""20080701-20.2"" iw: ""3.10-1.1.el6"" iwl1000-firmware: ""39.31.5.1-1.el6"" iwl100-firmware: ""39.31.5.1-1.el6"" iwl3945-firmware: ""15.32.2.9-4.el6"" iwl4965-firmware: ""228.61.2.24-2.1.el6"" iwl5000-firmware: ""8.83.5.1_1-1.el6_1.1"" iwl5150-firmware: ""8.24.2.2-1.el6"" iwl6000-firmware: ""9.221.4.1-1.el6"" iwl6000g2a-firmware: ""17.168.5.3-1.el6"" iwl6050-firmware: ""41.28.5.1-2.el6"" jasper-libs: ""1.900.1-15.el6_1.1"" java-1.6.0-openjdk: ""1.6.0.0-5.1.13.3.el6_5"" jline: ""0.9.94-0.8.el6"" jpackage-utils: ""1.7.5-3.12.el6"" kbd: ""1.15-11.el6"" kbd-misc: ""1.15-11.el6"" keepalived: ""1.2.4-1.el6"" kernel: ""2.6.32-431.el6"" kernel-devel: ""2.6.32-431.el6"" kernel-firmware: ""2.6.32-431.17.1.el6"" kernel-firmware: ""2.6.32-431.el6"" kernel-headers: ""2.6.32-431.el6"" kernel-lt: ""3.10.30-1.mira2"" kernel-lt-devel: ""3.10.30-1.mira2"" kernel-lt-firmware: ""3.10.30-1.mira2"" kernel-lt-headers: ""3.10.30-1.mira2"" kexec-tools: ""2.0.0-273.el6"" keyutils: ""1.4-4.el6"" keyutils-libs: ""1.4-4.el6"" keyutils-libs-devel: ""1.4-4.el6"" kmod-openvswitch: ""1.10.2-1.el6"" kpartx: ""0.4.9-72.el6_5.2"" krb5-devel: ""1.10.3-15.el6_5.1"" krb5-libs: ""1.10.3-15.el6_5.1"" ledmon: ""0.78-1.el6"" less: ""436-10.el6"" leveldb: ""1.7.0-2.el6"" libacl: ""2.2.49-6.el6"" libaio: ""0.3.107-10.el6"" libasyncns: ""0.8-1.1.el6"" libattr: ""2.4.44-7.el6"" libblkid: ""2.17.2-12.14.el6_5"" libcap: ""2.16-5.5.el6"" libcap-ng: ""0.6.4-3.el6_0.1"" libcephfs1: ""0.67.8-16.g69a99e6.mira1"" libcgroup: ""0.40.rc1-5.el6_5.1"" libcom_err: ""1.41.12-18.el6"" libcom_err-devel: ""1.41.12-18.el6"" libconfig: ""1.3.2-1.1.el6"" libcurl: ""7.19.7-37.el6_4"" libdaemon: ""0.14-1.el6"" libdrm: ""2.4.45-2.el6"" libedit: ""2.11-4.20080712cvs.1.el6"" libertas-usb8388-firmware: ""5.110.22.p23-3.1.el6"" libevent: ""1.4.13-4.el6"" libevent-devel: ""1.4.13-4.el6"" libevent-doc: ""1.4.13-4.el6"" libevent-headers: ""1.4.13-4.el6"" libewf: ""20100226-1.el6"" libfcgi: ""2.4.0-alt5.2"" libffi: ""3.0.5-3.2.el6"" libfontenc: ""1.0.5-2.el6"" libfprint: ""0.1.0-19.pre2.el6"" libgcc: ""4.4.7-4.el6"" libgcrypt: ""1.4.5-11.el6_4"" libgfortran: ""4.4.7-4.el6"" libgomp: ""4.4.7-4.el6"" libgpg-error: ""1.7-4.el6"" libgssglue: ""0.1-11.el6"" libguestfs: ""1.20.11-2.mira3"" libguestfs-tools-c: ""1.20.11-2.mira3"" libibverbs: ""1.1.7-1.el6"" libICE: ""1.0.6-1.el6"" libicu: ""4.2.1-9.1.el6_2"" libidn: ""1.18-2.el6"" libjpeg-turbo: ""1.2.1-3.el6_5"" libmongodb: ""2.4.6-1.mira1"" libnetfilter_conntrack: ""0.0.100-2.el6"" libnfnetlink: ""1.0.0-1.el6"" libnih: ""1.0.1-7.el6"" libnl: ""1.1.4-2.el6"" libogg: ""1.1.4-2.1.el6"" libpcap: ""1.4.0-1.20130826git2dbcaa1.el6"" libpciaccess: ""0.13.1-2.el6"" libpng: ""1.2.49-1.el6_2"" libproxy: ""0.3.0-4.el6_3"" libproxy-bin: ""0.3.0-4.el6_3"" libproxy-python: ""0.3.0-4.el6_3"" libqb: ""0.16.0-2.el6"" librados2: ""0.67.8-16.g69a99e6.mira1"" librbd1: ""0.67.8-16.g69a99e6.mira1"" librdmacm: ""1.0.17-1.el6"" librelp: ""0.1.1-4.1.el6"" libreport: ""2.0.9-19.el6.centos"" libreport-cli: ""2.0.9-19.el6.centos"" libreport-compat: ""2.0.9-19.el6.centos"" libreport-plugin-kerneloops: ""2.0.9-19.el6.centos"" libreport-plugin-logger: ""2.0.9-19.el6.centos"" libreport-plugin-mailx: ""2.0.9-19.el6.centos"" libreport-plugin-reportuploader: ""2.0.9-19.el6.centos"" libreport-plugin-rhtsupport: ""2.0.9-19.el6.centos"" libreport-python: ""2.0.9-19.el6.centos"" libselinux: ""2.0.94-5.3.el6_4.1"" libselinux-devel: ""2.0.94-5.3.el6_4.1"" libselinux-ruby: ""2.0.94-5.3.el6_4.1"" libselinux-utils: ""2.0.94-5.3.el6_4.1"" libsemanage: ""2.0.43-4.2.el6"" libsepol: ""2.0.41-4.el6"" libsepol-devel: ""2.0.41-4.el6"" libSM: ""1.2.1-2.el6"" libsmi: ""0.4.8-4.el6"" libsndfile: ""1.0.20-5.el6"" libss: ""1.41.12-18.el6"" libssh2: ""1.4.2-1.el6"" libstdc++: ""4.4.7-4.el6"" libstdc++-devel: ""4.4.7-4.el6"" libsysfs: ""2.1.0-7.el6"" libtalloc: ""2.0.7-2.el6"" libtar: ""1.2.11-17.el6_4.1"" libtasn1: ""2.3-3.el6_2.1"" libtdb: ""1.2.10-1.el6"" libtevent: ""0.9.18-3.el6"" libthai: ""0.1.12-3.el6"" libtiff: ""3.9.4-10.el6_5"" libtirpc: ""0.2.1-6.el6_5.1"" libtool-ltdl: ""2.2.6-15.5.el6"" libudev: ""147-2.51.el6"" libunwind: ""1.1-2.el6"" libusb: ""0.1.12-23.el6"" libusb1: ""1.0.9-0.6.rc1.el6"" libuser: ""0.56.13-5.el6"" libutempter: ""1.1.5-4.1.el6"" libuuid: ""2.17.2-12.14.el6_5"" libuv: ""0.10.4-1.el6"" libuv-devel: ""0.10.4-1.el6"" libvirt: ""0.10.2-29.el6_5.7"" libvirt-client: ""0.10.2-29.el6_5.7"" libvirt-python: ""0.10.2-29.el6_5.7"" libvorbis: ""1.2.3-4.el6_2.1"" libX11: ""1.5.0-4.el6"" libX11-common: ""1.5.0-4.el6"" libXau: ""1.0.6-4.el6"" libxcb: ""1.8.1-1.el6"" libXcomposite: ""0.4.3-4.el6"" libXcursor: ""1.1.13-6.20130524git8f677eaea.el6"" libXdamage: ""1.1.3-4.el6"" libXext: ""1.3.1-2.el6"" libXfixes: ""5.0-3.el6"" libXfont: ""1.4.5-3.el6_5"" libXft: ""2.3.1-2.el6"" libXi: ""1.6.1-3.el6"" libXinerama: ""1.1.2-2.el6"" libxml2: ""2.7.6-14.el6_5.1"" libxml2-python: ""2.7.6-14.el6_5.1"" libXpm: ""3.5.10-2.el6"" libXrandr: ""1.4.0-1.el6"" libXrender: ""0.9.7-2.el6"" libxslt: ""1.1.26-2.el6_3.1"" libXt: ""1.1.3-1.el6"" libXtst: ""1.2.1-2.el6"" libXxf86vm: ""1.1.2-2.el6"" libyaml: ""0.1.3-1.el6"" lm_sensors: ""3.1.1-17.el6"" lm_sensors-libs: ""3.1.1-17.el6"" logrotate: ""3.8.7-1.el6"" lrzip: ""0.614-1.mira1"" lsof: ""4.82-4.el6"" lua: ""5.1.4-4.1.el6"" lvm2: ""2.02.100-8.el6"" lvm2-libs: ""2.02.100-8.el6"" lxc: ""0.9.0-2.mira1"" lxc-libs: ""0.9.0-2.mira1"" lzo: ""2.03-3.1.el6"" lzop: ""1.02-0.9.rc1.el6"" m2crypto: ""0.20.2-9.el6"" m4: ""1.4.13-5.el6"" mailcap: ""2.1.31-2.el6"" mailx: ""12.4-7.el6"" make: ""3.81-20.el6"" MAKEDEV: ""3.24-6.el6"" man: ""1.6f-32.el6"" man-pages: ""3.22-20.el6"" man-pages-overrides: ""6.5.3-1.el6_5"" mc: ""4.7.0.2-3.el6"" mcollective: ""2.3.3-3.el6"" mcollective-client: ""2.3.3-3.el6"" mcollective-common: ""2.3.3-3.el6"" mdadm: ""3.2.6-7.el6_5.2"" memcached: ""1.4.4-3.el6"" mesa-dri1-drivers: ""7.11-8.el6"" mesa-dri-drivers: ""9.2-0.5.el6_5.2"" mesa-dri-filesystem: ""9.2-0.5.el6_5.2"" mesa-libGL: ""9.2-0.5.el6_5.2"" mesa-libGLU: ""9.2-0.5.el6_5.2"" mesa-private-llvm: ""3.3-0.3.rc3.el6"" microcode_ctl: ""1.17-17.el6"" mingetty: ""1.08-5.el6"" mlocate: ""0.22.2-4.el6"" modcluster: ""0.16.2-28.el6"" mod_fastcgi: ""2.4.7-1.ceph.el6"" mod_ssl: ""2.2.15-15.el6.1"" module-init-tools: ""3.9-21.el6_4"" mod_wsgi: ""3.2-1.el6"" mongodb: ""2.4.6-1.mira1"" mongodb-server: ""2.4.6-1.mira1"" mpfr: ""2.4.1-6.el6"" mtools: ""4.0.17-3.el6"" mtr: ""0.75-5.el6"" murano-api: ""0.5.fuel5.0-mira20"" murano-apps: ""0.5-1.mira2"" murano-dashboard: ""0.5.fuel5.0-mira12"" MySQL-client: ""5.5.28-7"" MySQL-client-wsrep: ""5.5.28_wsrep_23.7-12"" mysql-libs: ""5.1.73-3.el6_5"" MySQL-python: ""1.2.5-1.el6"" MySQL-server: ""5.5.28-7"" MySQL-server-wsrep: ""5.5.28_wsrep_23.7-12"" MySQL-shared: ""5.5.28-7"" MySQL-shared-wsrep: ""5.5.28_wsrep_23.7-12"" nagios: ""3.5.0-1.el6"" nagios-common: ""3.5.0-1.el6"" nagios-plugins: ""1.4.16-5.el6"" nagios-plugins-apt: ""1.4.16-5.el6"" nagios-plugins-breeze: ""1.4.16-5.el6"" nagios-plugins-by_ssh: ""1.4.16-5.el6"" nagios-plugins-cluster: ""1.4.16-5.el6"" nagios-plugins-dhcp: ""1.4.16-5.el6"" nagios-plugins-dig: ""1.4.16-5.el6"" nagios-plugins-disk: ""1.4.16-5.el6"" nagios-plugins-disk_smb: ""1.4.16-5.el6"" nagios-plugins-dns: ""1.4.16-5.el6"" nagios-plugins-dummy: ""1.4.16-5.el6"" nagios-plugins-file_age: ""1.4.16-5.el6"" nagios-plugins-flexlm: ""1.4.16-5.el6"" nagios-plugins-hpjd: ""1.4.16-5.el6"" nagios-plugins-http: ""1.4.16-5.el6"" nagios-plugins-icmp: ""1.4.16-5.el6"" nagios-plugins-ide_smart: ""1.4.16-5.el6"" nagios-plugins-ircd: ""1.4.16-5.el6"" nagios-plugins-ldap: ""1.4.16-5.el6"" nagios-plugins-linux_raid: ""1.4.16-5.el6"" nagios-plugins-load: ""1.4.16-5.el6"" nagios-plugins-log: ""1.4.16-5.el6"" nagios-plugins-mailq: ""1.4.16-5.el6"" nagios-plugins-mrtg: ""1.4.16-5.el6"" nagios-plugins-mrtgtraf: ""1.4.16-5.el6"" nagios-plugins-mysql: ""1.4.16-5.el6"" nagios-plugins-nagios: ""1.4.16-5.el6"" nagios-plugins-nrpe: ""2.14-3.el6"" nagios-plugins-nt: ""1.4.16-5.el6"" nagios-plugins-ntp: ""1.4.16-5.el6"" nagios-plugins-ntp-perl: ""1.4.16-5.el6"" nagios-plugins-nwstat: ""1.4.16-5.el6"" nagios-plugins-oracle: ""1.4.16-5.el6"" nagios-plugins-os-libvirt: ""1.0.0-2.el6"" nagios-plugins-os-rabbitmq: ""1.0.0-2.el6"" nagios-plugins-os-swift: ""1.0.0-1.el6"" nagios-plugins-overcr: ""1.4.16-5.el6"" nagios-plugins-perl: ""1.4.16-5.el6"" nagios-plugins-pgsql: ""1.4.16-5.el6"" nagios-plugins-ping: ""1.4.16-5.el6"" nagios-plugins-procs: ""1.4.16-5.el6"" nagios-plugins-real: ""1.4.16-5.el6"" nagios-plugins-rpc: ""1.4.16-5.el6"" nagios-plugins-sensors: ""1.4.16-5.el6"" nagios-plugins-smtp: ""1.4.16-5.el6"" nagios-plugins-snmp: ""1.4.16-5.el6"" nagios-plugins-ssh: ""1.4.16-5.el6"" nagios-plugins-swap: ""1.4.16-5.el6"" nagios-plugins-tcp: ""1.4.16-5.el6"" nagios-plugins-time: ""1.4.16-5.el6"" nagios-plugins-ups: ""1.4.16-5.el6"" nagios-plugins-users: ""1.4.16-5.el6"" nagios-plugins-wave: ""1.4.16-5.el6"" nailgun: ""0.1.0-1"" nailgun-agent: ""0.1.0-1"" nailgun-mcagents: ""0.1.0-1"" nailgun-net-check: ""0.2-1"" nailgun-redhat-license: ""0.0.1-1"" nano: ""2.0.9-7.el6"" ncurses: ""5.7-3.20090208.el6"" ncurses-base: ""5.7-3.20090208.el6"" ncurses-libs: ""5.7-3.20090208.el6"" netcf-libs: ""0.1.9-4.el6_5.2"" netpbm: ""10.47.05-11.el6"" netpbm-progs: ""10.47.05-11.el6"" net-snmp: ""5.5-49.el6_5.1"" net-snmp-libs: ""5.5-49.el6_5.1"" net-snmp-utils: ""5.5-49.el6_5.1"" net-tools: ""1.60-110.el6_2"" newt: ""0.52.11-3.el6"" newt-python: ""0.52.11-3.el6"" nfs-utils: ""1.2.3-39.el6"" nfs-utils-lib: ""1.1.5-6.el6"" nginx: ""1.0.15-4.el6"" nmap-ncat: ""6.40-3.el6"" nodejs: ""0.10.4-1.el6"" nodejs-less: ""1.3.3-3.el6"" novnc: ""0.4-8.el6"" nrpe: ""2.14-3.el6"" nspr: ""4.10.2-1.el6_5"" nss: ""3.15.3-6.el6_5"" nss-softokn: ""3.14.3-10.el6_5"" nss-softokn-freebl: ""3.14.3-10.el6_5"" nss-sysinit: ""3.15.3-6.el6_5"" nss-tools: ""3.15.3-6.el6_5"" nss-util: ""3.15.3-1.el6_5"" ntp: ""4.2.6p5-1.el6.centos"" ntpdate: ""4.2.6p5-1.el6.centos"" ntsysv: ""1.3.49.3-2.el6_4.1"" numactl: ""2.0.7-8.el6"" numad: ""0.5-9.20130814git.el6"" numpy: ""1.4.1-9.el6"" numpy-f2py: ""1.4.1-9.el6"" oddjob: ""0.30-5.el6"" openais: ""1.1.4-47.3"" openaislib: ""1.1.4-47.3"" OpenIPMI-libs: ""2.0.16-14.el6"" openldap: ""2.4.23-34.el6_5.1"" openssh: ""5.3p1-94.el6"" openssh-clients: ""5.3p1-94.el6"" openssh-server: ""5.3p1-94.el6"" openssl098e: ""0.9.8e-17.el6.centos.2"" openssl: ""1.0.1e-16.el6_5.7"" openssl-devel: ""1.0.1e-16.el6_5.7"" openstack-ceilometer-alarm: ""2014.1.fuel5.1-mira0"" openstack-ceilometer-api: ""2014.1.fuel5.1-mira0"" openstack-ceilometer-central: ""2014.1.fuel5.1-mira0"" openstack-ceilometer-collector: ""2014.1.fuel5.1-mira0"" openstack-ceilometer-common: ""2014.1.fuel5.1-mira0"" openstack-ceilometer-compute: ""2014.1.fuel5.1-mira0"" openstack-cinder: ""2014.1.fuel5.0-mira4"" openstack-dashboard: ""2014.1.fuel5.0-mira2"" openstack-glance: ""2014.1.fuel5.0-mira3"" openstack-heat-api: ""2014.1.fuel5.0-mira4"" openstack-heat-api-cfn: ""2014.1.fuel5.0-mira4"" openstack-heat-api-cloudwatch: ""2014.1.fuel5.0-mira4"" openstack-heat-common: ""2014.1.fuel5.0-mira4"" openstack-heat-engine: ""2014.1.fuel5.0-mira4"" openstack-keystone: ""2014.1.fuel5.0-mira3"" openstack-neutron: ""2014.1.fuel5.0-mira5"" openstack-neutron-linuxbridge: ""2014.1.fuel5.0-mira5"" openstack-neutron-openvswitch: ""2014.1.fuel5.0-mira5"" openstack-nova: ""2014.1.fuel5.0-mira11"" openstack-nova-api: ""2014.1.fuel5.0-mira11"" openstack-nova-cells: ""2014.1.fuel5.0-mira11"" openstack-nova-cert: ""2014.1.fuel5.0-mira11"" openstack-nova-common: ""2014.1.fuel5.0-mira11"" openstack-nova-compute: ""2014.1.fuel5.0-mira11"" openstack-nova-conductor: ""2014.1.fuel5.0-mira11"" openstack-nova-console: ""2014.1.fuel5.0-mira11"" openstack-nova-network: ""2014.1.fuel5.0-mira11"" openstack-nova-novncproxy: ""2014.1.fuel5.0-mira11"" openstack-nova-objectstore: ""2014.1.fuel5.0-mira11"" openstack-nova-scheduler: ""2014.1.fuel5.0-mira11"" openstack-swift: ""1.13.1.fuel5.0-mira0"" openstack-swift-account: ""1.13.1.fuel5.0-mira0"" openstack-swift-container: ""1.13.1.fuel5.0-mira0"" openstack-swift-object: ""1.13.1.fuel5.0-mira0"" openstack-swift-plugin-swift3: ""1.0.0-0.20120711git.el6"" openstack-swift-proxy: ""1.13.1.fuel5.0-mira0"" openstack-utils: ""2013.1-8.el6"" openvswitch: ""1.10.2-1"" p11-kit: ""0.18.5-2.el6_5.2"" p11-kit-trust: ""0.18.5-2.el6_5.2"" pacemaker: ""1.1.10-14.el6_5.3"" pacemaker-cli: ""1.1.10-14.el6_5.3"" pacemaker-cluster-libs: ""1.1.10-14.el6_5.3"" pacemaker-libs: ""1.1.10-14.el6_5.3"" pam: ""1.1.1-17.el6"" pam_passwdqc: ""1.0.5-6.el6"" pango: ""1.28.1-7.el6_3"" parted: ""2.1-21.el6"" passwd: ""0.77-4.el6_2.2"" patch: ""2.6-6.el6"" pax: ""3.4-10.1.el6"" pcapy: ""0.10.8-2.el6"" pciutils: ""3.1.10-2.el6"" pciutils-libs: ""3.1.10-2.el6"" pcmciautils: ""015-4.2.el6"" pcre: ""7.8-6.el6"" pcs: ""0.9.103-2.el6"" pcs: ""0.9.90-2.el6.centos.2"" percona-toolkit: ""2.2.6-1"" perl: ""5.10.1-136.el6"" perl-CGI: ""3.51-136.el6"" perl-Config-General: ""2.52-1.el6"" perl-DBD-MySQL: ""4.022-1.el6"" perl-DBI: ""1.609-4.el6"" perl-devel: ""5.10.1-136.el6"" perl-Error: ""0.17015-4.el6"" perl-ExtUtils-MakeMaker: ""6.55-136.el6"" perl-ExtUtils-ParseXS: ""2.2003.0-136.el6"" perl-Git: ""1.7.1-3.el6_4.1"" perl-libs: ""5.10.1-136.el6"" perl-LockFile-Simple: ""0.207-2.el6"" perl-Module-Pluggable: ""3.90-136.el6"" perl-Net-Telnet: ""3.03-11.el6"" perl-Pod-Escapes: ""1.04-136.el6"" perl-Pod-Simple: ""3.13-136.el6"" perl-TermReadKey: ""2.30-13.el6"" perl-Test-Harness: ""3.17-136.el6"" perl-Test-Simple: ""0.92-136.el6"" perl-TimeDate: ""1.16-11.1.el6"" perl-Time-HiRes: ""1.9721-136.el6"" perl-version: ""0.77-136.el6"" pexpect: ""2.3-6.el6"" php: ""5.3.3-27.el6_5"" php-bcmath: ""5.3.3-27.el6_5"" php-cli: ""5.3.3-27.el6_5"" php-common: ""5.3.3-27.el6_5"" php-gd: ""5.3.3-27.el6_5"" php-mbstring: ""5.3.3-27.el6_5"" php-mysql: ""5.3.3-27.el6_5"" php-pdo: ""5.3.3-27.el6_5"" php-pgsql: ""5.3.3-27.el6_5"" php-xml: ""5.3.3-27.el6_5"" pinentry: ""0.7.6-6.el6"" pinfo: ""0.6.9-12.el6"" pixman: ""0.26.2-5.1.el6_5"" pkgconfig: ""0.23-9.1.el6"" plymouth: ""0.8.3-27.el6.centos"" plymouth-core-libs: ""0.8.3-27.el6.centos"" plymouth-scripts: ""0.8.3-27.el6.centos"" pm-utils: ""1.2.5-10.el6_5.1"" policycoreutils: ""2.0.83-19.39.el6"" polkit: ""0.96-5.el6_4"" popt: ""1.13-7.el6"" portreserve: ""0.0.4-9.el6"" postfix: ""2.6.6-6.el6_5"" postgresql: ""9.2.5-3.mira1"" postgresql-devel: ""9.2.5-3.mira1"" postgresql-libs: ""9.2.5-3.mira1"" postgresql-server: ""9.2.5-3.mira1"" ppl: ""0.10.2-11.el6"" prelink: ""0.4.6-3.1.el6_4"" procps: ""3.2.8-25.el6"" psacct: ""6.3.2-63.el6_3.3"" psmisc: ""22.6-19.el6_5"" pssh: ""2.3.1-15.2"" pth: ""2.0.7-9.3.el6"" pulseaudio-libs: ""0.9.21-14.el6_3"" puppet: ""3.4.2-1.mira2"" puppetdb: ""1.2.0-1.el6"" puppetdb-terminus: ""1.2.0-1.el6"" puppetlabs-release: ""6-6"" puppet-server: ""3.4.2-1.mira2"" pushy: ""0.5.3-1"" pygobject2: ""2.20.0-5.el6"" pygpgme: ""0.1-18.20090824bzr68.el6"" pyOpenSSL: ""0.13.1-1.el6"" PyPAM: ""0.5.0-12.el6"" pyparsing: ""1.5.6-1.el6"" pyparsing-doc: ""1.5.6-1.el6"" pysendfile: ""2.0.0-3.el6"" pysnmp: ""4.2.4-1.el6"" python: ""2.6.6-52.el6"" python-actdiag: ""0.4.3-1"" python-alembic: ""0.6.2-2.el6"" python-amqp: ""1.4.5-2.mira1"" python-amqplib: ""1.0.2-1.el6"" python-anyjson: ""0.3.3-2.el6"" python-argparse: ""1.2.1-2.el6"" python-babel: ""1.3-3.el6"" python-backports: ""1.0-3.el6"" python-backports-ssl_match_hostname: ""3.4.0.1-1.el6"" python-beaker: ""1.3.1-7.el6"" python-blockdiag: ""1.2.4-1"" python-boto: ""2.5.2-3.el6"" python-bson: ""2.5.2-3.el6"" python-bunch: ""1.0.1-1.el6"" python-ceilometer: ""2014.1.fuel5.1-mira0"" python-ceilometerclient: ""1.0.9.fuel5.0-mira0"" python-ceph: ""0.67.8-16.g69a99e6.mira1"" python-chardet: ""2.0.1-1.el6"" python-cheetah: ""2.4.1-1.el6"" python-cherrypy: ""3.2.2-3.el6"" python-cinder: ""2014.1.fuel5.0-mira4"" python-cinderclient: ""1.0.8.fuel5.0-mira0"" python-cliff: ""1.4.4-1.el6"" python-cliff-tablib: ""1.1-1.2"" python-cloudfiles: ""1.7.9.3-1.el6"" python-cmd2: ""0.6.4-7.el6"" python-configobj: ""4.6.0-3.el6"" python-croniter: ""0.3.4-2.el6"" python-crypto: ""2.6.1-1.el6"" python-d2to1: ""0.2.10-1.el6"" python-daemon: ""1.5.2-1.el6"" python-dateutil: ""1.4.1-6.el6"" python-decorator: ""3.4.0-3.2"" python-deep: ""0.8-1.el6"" python-deltarpm: ""3.5-0.5.20090913git.el6"" python-devel: ""2.6.6-52.el6"" python-django: ""1.5-4.el6"" python-django-appconf: ""0.5-3.el6"" python-django-compressor: ""1.3-2.el6"" python-django-floppyforms: ""1.1-2.el6"" python-django-horizon: ""2014.1.fuel5.0-mira2"" python-django-horizon-doc: ""2014.1.fuel5.0-mira2"" python-django-openstack-auth: ""1.1.5-1.el6"" python-dmidecode: ""3.10.13-3.el6_4"" python-docutils: ""0.6-1.el6"" python-dogpile-cache: ""0.5.0-1.el6"" python-dogpile-core: ""0.4.1-1.el6"" python-ecdsa: ""0.10-1"" python-ethtool: ""0.6-5.el6"" python-eventlet: ""0.14.0-1.el6"" python-fabric: ""1.7.0-1.el6"" python-flask: ""0.10.1-8.mira5"" python-fuelclient: ""0.2-1"" python-funcparserlib: ""0.3.5-1"" python-futures: ""2.1.6-1.el6"" python-fysom: ""1.0.11-1.el6"" python-gevent: ""0.13.8-3.el6"" python-gflags: ""1.4-3.el6"" python-glance: ""2014.1.fuel5.0-mira3"" python-glanceclient: ""0.12.0.fuel5.0-mira0"" python-greenlet: ""0.4.1-1.el6"" python-greenlet-devel: ""0.4.1-1.el6"" python-heatclient: ""0.2.9-1.el6"" python-httplib2: ""0.7.7-1.el6"" python-imaging: ""1.1.6-19.el6"" python-importlib: ""1.0.2-1.el6"" python-iniparse: ""0.3.1-2.1.el6"" python-ipaddr: ""2.1.9-1.el6"" python-iso8601: ""0.1.9-1.el6"" python-itsdangerous: ""0.22-1.el6"" python-iwlib: ""0.1-1.2.el6"" python-jinja2-26: ""2.6-2.el6"" python-jinja2: ""2.7-1.el6"" python-jsonpatch: ""1.2-2.el6"" python-jsonpath-rw: ""1.2.3-1.el6"" python-jsonpointer: ""1.0-2.el6"" python-jsonschema: ""2.3.0-1.el6"" python-keyring: ""0.7-1.el6"" python-keystone: ""2014.1.fuel5.0-mira3"" python-keystoneclient: ""0.7.1.fuel5.0-mira0"" python-keystoneclient-doc: ""0.7.1.fuel5.0-mira0"" python-kombu: ""3.0.16-1.mira1"" python-ldap: ""2.3.10-1.el6"" python-lesscpy: ""0.9j-3.el6"" python-libguestfs: ""1.20.11-2.mira3"" python-libs: ""2.6.6-52.el6"" python-lockfile: ""0.8-3.el6"" python-logutils: ""0.3.3-3.el6"" python-lxml: ""3.2.3-1.el6"" python-mako: ""0.9.1-5.el6"" python-markdown: ""2.0.1-3.1.el6"" python-MarkupSafe: ""0.18-24.2"" python-meld3: ""0.6.7-1.el6"" python-memcached: ""1.53-1.el6"" python-migrate: ""0.8.2-1.el6"" python-msgpack: ""0.1.13-3.el6"" python-muranoclient: ""0.5.fuel5.0-mira8"" python-netaddr: ""0.7.10-2.mira1"" python-netaddr: ""0.7.5-4.el6"" python-netifaces: ""0.8-1.el6"" python-networkx-core: ""1.8.1-12.el6"" python-neutron: ""2014.1.fuel5.0-mira5"" python-neutronclient: ""2.3.4.fuel4.1-mira0"" python-nose: ""1.3.0-2.el6"" python-nose-cover3: ""0.1.0-6.el6"" python-nova: ""2014.1.fuel5.0-mira11"" python-novaclient: ""2.17.0.fuel5.0-mira0"" python-novaclient-doc: ""2.17.0.fuel5.0-mira0"" python-nwdiag: ""0.9.4-1"" python-oauthlib: ""0.6.0-2.el6"" python-ordereddict: ""1.1-2.el6"" python-oslo-config: ""1.2.1-1.el6"" python-oslo-config-doc: ""1.2.1-1.el6"" python-oslo-messaging: ""1.3.0-0.1.a9.el6"" python-oslo-rootwrap: ""1.0.0-1.el6"" python-oslo.vmware: ""0.3-0"" python-osnagios: ""1.1-5.el6"" python-paramiko: ""1.12.0-1"" python-passlib: ""1.5.3-1.el6"" python-paste: ""1.7.5.1-4.20111221hg1498.el6"" python-paste-deploy1.5: ""1.5.0-5.el6"" python-pbr: ""0.7.0-1.el6"" python-pecan: ""0.4.5-3.el6"" python-pip: ""1.4.1-1.el6"" python-ply: ""3.4-4.el6"" python-prettytable: ""0.7.2-1.el6"" python-psutil: ""1.2.1-1.mira1"" python-psycopg2: ""2.5.1-0"" python-py: ""1.4.15-1.el6"" python-pyasn1: ""0.0.12a-1.el6"" python-pycadf: ""0.4.1-2.el6"" python-pycurl: ""7.19.0-8.el6"" python-pygments: ""1.1.1-1.el6"" python-pymongo: ""2.5.2-3.el6"" python-pypcap: ""1.1-15.1"" python-pyudev: ""0.15-1.el6"" python-qpid: ""0.14-11.el6_3"" python-qpid-qmf: ""0.14-14.el6_3"" python-reportlab: ""2.3-3.el6"" python-requests: ""1.2.3-5.el6"" python-rhsm: ""1.1.8-1.el6"" python-routes: ""1.10.3-2.el6"" python-routes1.12: ""1.12.3-4.el6"" python-saharaclient: ""0.6.0.fuel5.0-mira2"" python-saslwrapper: ""0.14-1.el6"" python-seqdiag: ""0.8.2-1"" python-setuptools: ""0.6.10-3.el6"" python-simplegeneric: ""0.8.1-1.el6"" python-simplejson: ""3.3.0-2.el6"" python-singledispatch: ""3.4.0.2-2.el6"" python-six: ""1.5.2-1.el6"" python-sphinx10: ""1.0.8-1.el6"" python-sphinx10-doc: ""1.0.8-1.el6"" python-sqlalchemy: ""0.5.5-3.el6_2"" python-sqlalchemy: ""0.7.9-1.3.mira2"" python-stevedore: ""0.14-1.el6"" python-suds: ""0.4.1-3.el6"" python-swiftclient: ""1.8.0.fuel5.0-mira0"" python-swiftclient-doc: ""1.8.0.fuel5.0-mira0"" python-tablib: ""0.9.11.20120702git752443f-5.el6"" python-taskflow: ""0.1.3-5.el6"" python-tempita: ""0.4-2.el6"" python-testresources: ""0.2.7-4.el6"" python-troveclient: ""1.0.3.fuel5.0-mira0"" python-unittest2: ""0.5.1-3.el6"" python-urlgrabber: ""3.9.1-9.el6"" python-urllib3: ""1.7-4.el6"" python-urwid: ""1.1.1-1.el6"" python-versiontools: ""1.9.1-3.el6"" python-virtualenv: ""1.7.2-1.el6"" python-warlock: ""1.0.1-1.el6"" python-webcolors: ""1.4-1"" python-webob: ""1.2.3-4.el6"" python-webpy: ""0.37-2.el6"" python-websockify: ""0.5.1-1.el6"" python-webtest: ""1.3.4-6.el6"" python-werkzeug: ""0.8.3-2.el6"" python-wsgilog: ""0.3-1"" python-wsgiref: ""0.1.2-6.el6"" python-wsme: ""0.6-2.el6"" python-yaql: ""0.2.2-1.el6.mira2"" pytz: ""2010h-2.el6"" pyxattr: ""0.5.0-1.el6"" PyYAML: ""3.10-3.el6"" qemu: ""1.2.0-24.mira1"" qemu-common: ""1.2.0-24.mira1"" qemu-img: ""1.2.0-24.mira1"" qemu-kvm: ""1.2.0-24.mira1"" ql2100-firmware: ""1.19.38-3.1.el6"" ql2200-firmware: ""2.02.08-3.1.el6"" ql23xx-firmware: ""3.03.27-3.1.el6"" ql2400-firmware: ""7.00.01-1.el6"" ql2500-firmware: ""7.00.01-1.el6"" qpid-cpp-client: ""0.14-22.el6_3"" qpid-cpp-client-ssl: ""0.14-22.el6_3"" qpid-cpp-server: ""0.14-22.el6_3"" qpid-cpp-server-ssl: ""0.14-22.el6_3"" qpid-qmf: ""0.14-14.el6_3"" qpid-tests: ""0.14-1.el6_2"" qpid-tools: ""0.14-6.el6_3"" quota: ""3.17-21.el6_5"" rabbitmq-server: ""3.2.3-1.mira1"" radvd: ""1.6-1.el6"" rbd-fuse: ""0.67.8-16.g69a99e6.mira1"" rdate: ""1.4-16.el6"" readahead: ""1.5.6-2.el6"" readline: ""6.0-4.el6"" redhat-logos: ""60.0.14-12.el6.centos"" redhat-lsb-core: ""4.0-7.el6.centos"" redhat-rpm-config: ""9.0.3-42.el6.centos"" resource-agents: ""3.9.5-56.1"" rfkill: ""0.3-4.el6"" rhino: ""1.7-0.7.r2.2.el6"" ricci: ""0.16.2-69.el6_5.1"" rng-tools: ""2-13.el6_2"" rootfiles: ""8.1-6.1.el6"" rpcbind: ""0.2.0-11.el6"" rpm: ""4.8.0-37.el6"" rpm-build: ""4.8.0-37.el6"" rpm-libs: ""4.8.0-37.el6"" rpm-python: ""4.8.0-37.el6"" rst2pdf: ""0.16-1.el6"" rsync: ""3.0.6-9.el6_4.1"" rsyslog: ""5.8.10-8.el6"" rsyslog-relp: ""5.8.10-8.el6"" rt61pci-firmware: ""1.2-7.el6"" rt73usb-firmware: ""1.8-7.el6"" ruby: ""1.8.7.352-13.el6"" ruby: ""2.1.1-1.1"" ruby21-augeas: ""0.5.0-17.3"" ruby21-facter: ""1.7.0-1.el6"" ruby21-hiera: ""1.3.2-1.el6"" ruby21-mcollective: ""2.4.1-1.el6"" ruby21-mcollective-common: ""2.4.1-1.el6"" ruby21-nailgun-mcagents: ""0.1.0-10"" ruby21-puppet: ""3.4.2-1.mira1"" ruby21-rubygem-activesupport: ""3.0.10-1.el6"" ruby21-rubygem-amq-client: ""0.9.12-1.el6"" ruby21-rubygem-amqp: ""0.9.10-1.el6"" ruby21-rubygem-amq-protocol: ""1.2.0-1.el6"" ruby21-rubygem-astute: ""0.0.2-8"" ruby21-rubygem-eventmachine: ""1.0.3-4.el6"" ruby21-rubygem-i18n: ""0.6.9-1.el6"" ruby21-rubygem-json: ""1.6.1-4.6"" ruby21-rubygem-json_pure: ""1.8.1-1.el6"" ruby21-rubygem-mcollective-client: ""2.4.1-1.el6"" ruby21-rubygem-mime-types: ""2.2-3.el6"" ruby21-rubygem-netaddr: ""1.5.0-2.el6"" ruby21-rubygem-net-ssh: ""2.8.0-1.el6"" ruby21-rubygem-net-ssh-gateway: ""1.2.0-1.el6"" ruby21-rubygem-net-ssh-multi: ""1.2.0-1.el6"" ruby21-rubygem-open4: ""1.3.3-2.el6"" ruby21-rubygem-openstack: ""1.1.2-2.el6"" ruby21-rubygem-Platform: ""0.4.0-1.el6"" ruby21-rubygem-popen4: ""0.1.2-1.1"" ruby21-rubygem-raemon: ""0.3.0-1.el6"" ruby21-rubygem-rest-client: ""1.6.7-2.el6"" ruby21-rubygem-rgen: ""0.6.6-1.el6"" ruby21-rubygem-shadow: ""1.4.1-21.el6"" ruby21-rubygem-stomp: ""1.3.2-1.el6"" ruby21-rubygem-symboltable: ""1.0.2-1"" ruby21-rubygem-systemu: ""2.6.4-1.el6"" ruby-augeas: ""0.5.0-17.3"" ruby-devel: ""1.8.7.352-13.el6"" ruby-extlib: ""0.9.13-5.el6"" rubygem-abstract: ""1.0.0-1.el6"" rubygem-activesupport: ""3.0.10-1.el6"" rubygem-arel: ""2.0.10-1.el6"" rubygem-builder: ""2.1.2-1.el6"" rubygem-bundler: ""1.3.4-1.el6"" rubygem-bunny: ""0.8.0-1.el6"" rubygem-cstruct: ""1.0.1-1.el6"" rubygem-daemons: ""1.0.10-2.el6"" rubygem-erubis: ""2.6.6-1.el6"" rubygem-eventmachine: ""0.12.10-4.el6"" rubygem-eventmachine-doc: ""0.12.10-4.el6"" rubygem-extlib: ""0.9.13-5.el6"" rubygem-extlib-doc: ""0.9.13-5.el6"" rubygem-fastthread: ""1.0.7-2.el6"" rubygem-gem_plugin: ""0.2.3-3.el6"" rubygem-highline: ""1.6.13-1.el6"" rubygem-httpclient: ""2.3.2-5.el6"" rubygem-httpclient-doc: ""2.3.2-5.el6"" rubygem-i18n: ""0.6.4-1.el6"" rubygem-ipaddress: ""0.8.0-3.el6"" rubygem-ipaddress-doc: ""0.8.0-3.el6"" rubygem-json: ""1.7.7-101.el6"" rubygem-json-doc: ""1.7.7-101.el6"" rubygem-json_pure: ""1.7.7-1.el6"" rubygem-json_pure-doc: ""1.7.7-1.el6"" rubygem-mail: ""2.2.19-1.el6"" rubygem-mime-types: ""1.16-mira.5"" rubygem-mime-types-doc: ""1.16-mira.5"" rubygem-mixlib-authentication: ""1.1.4-1.el6"" rubygem-mixlib-cli: ""1.2.2-3.el6"" rubygem-mixlib-cli-doc: ""1.2.2-3.el6"" rubygem-mixlib-config: ""1.1.2-1.el6"" rubygem-mixlib-log: ""1.4.1-1.el6"" rubygem-mixlib-shellout: ""1.0.0-1.el6"" rubygem-moneta: ""0.6.0-1.el6"" rubygem-mongrel: ""1.1.5-3.el6"" rubygem-netaddr: ""1.5.0-2.el6"" rubygem-net-ssh: ""2.2.2-1.el6"" rubygem-net-ssh-gateway: ""1.1.0-1.el6.mira1"" rubygem-net-ssh-multi: ""1.1-1.el6"" rubygem-ohai: ""6.14.0-1.el6"" rubygem-openstack: ""1.1.2-2.el6"" rubygem-polyglot: ""0.3.3-1.el6"" rubygem-rack: ""1.1.0-2.el6"" rubygem-rack-mount: ""0.6.14-1.el6"" rubygem-rack-test: ""0.5.7-1.el6"" rubygem-raemon: ""0.3.0-1.el6"" rubygem-rake: ""0.8.7-2.1.el6"" rubygem-rdoc: ""3.12.2-1.el6"" rubygem-rest-client: ""1.6.1-2.el6"" rubygem-rethtool: ""0.0.3-2.mira1"" rubygems: ""1.3.7-5.el6"" rubygem-stomp: ""1.2.16-1.el6"" rubygem-stomp-doc: ""1.2.16-1.el6"" rubygem-symboltable: ""1.0.2-1"" rubygem-systemu: ""2.5.2-1.el6"" rubygem-thin: ""1.2.8-4.el6"" rubygem-thin-doc: ""1.2.8-4.el6"" rubygem-thor: ""0.14.6-1.el6"" rubygem-treetop: ""1.4.10-1.el6"" rubygem-tzinfo: ""0.3.37-1.el6"" rubygem-uuidtools: ""2.1.2-1.el6"" rubygem-yajl-ruby: ""1.1.0-1.el6"" ruby-irb: ""1.8.7.352-13.el6"" ruby-libs: ""1.8.7.352-13.el6"" ruby-mysql: ""2.8.2-1.el6"" ruby-rdoc: ""1.8.7.352-13.el6"" ruby-rgen: ""0.6.5-1.el6"" ruby-ri: ""1.8.7.352-13.el6"" ruby-shadow: ""1.4.1-13.el6"" sahara: ""2014.1.fuel5.0-mira1"" sahara-dashboard: ""2014.1.fuel5.0-mira0"" samba-client: ""3.6.9-168.el6_5"" samba-common: ""3.6.9-168.el6_5"" samba-winbind: ""3.6.9-168.el6_5"" samba-winbind-clients: ""3.6.9-168.el6_5"" saslwrapper: ""0.14-1.el6"" scapy: ""2.0.0.10-5.el6"" scipy: ""0.7.2-8.el6"" scl-utils: ""20120927-8.el6"" screen: ""4.0.3-16.el6"" scrub: ""2.2-1.el6"" scsi-target-utils: ""1.0.38-13.21b1f2.ceph.el6"" SDL: ""1.2.14-3.el6"" seabios-bin: ""1.7.1-3.el6"" sed: ""4.2.1-10.el6"" selinux-policy: ""3.7.19-231.el6_5.3"" selinux-policy-targeted: ""3.7.19-231.el6_5.3"" send2syslog: ""0.1-1.el6"" setserial: ""2.17-25.el6"" setup: ""2.8.14-20.el6_4.1"" setuptool: ""1.19.9-4.el6"" sg3_utils: ""1.28-5.el6"" sg3_utils-libs: ""1.28-5.el6"" sgabios-bin: ""0.20110622svn-3.el6"" sgpio: ""1.2.0.10-5.el6"" shadow-utils: ""4.1.4.2-13.el6"" shared-mime-info: ""0.70-4.el6"" sheepdog: ""0.2.3-2.el6"" shotgun: ""0.1.0-1"" slang: ""2.2.1-1.el6"" smartmontools: ""5.43-1.el6"" snappy: ""1.0.5-1.el6"" socat: ""1.7.2.2-1.el6"" sos: ""2.2-47.el6.centos.1"" sphinxcontrib-actdiag: ""0.5.1-3"" sphinxcontrib-blockdiag: ""1.2.0-3"" sphinxcontrib-nwdiag: ""0.6.1-3"" sphinxcontrib-seqdiag: ""0.5.1-3"" spice-server: ""0.12.4-6.el6_5.1"" sqlite: ""3.6.20-1.el6"" strace: ""4.5.19-1.17.el6"" subscription-manager: ""1.1.23.1-1.el6"" sudo: ""1.8.6p3-12.el6"" suitesparse: ""3.4.0-8.el6"" supervisor: ""3.0a12-0.12.el6"" sysfsutils: ""2.1.0-7.el6"" syslinux: ""4.02-8.el6"" sysstat: ""9.0.4-22.el6"" system-config-firewall-base: ""1.2.27-5.el6"" system-config-firewall-tui: ""1.2.27-5.el6"" system-config-network-tui: ""1.6.0.el6.2-1.el6"" systemtap-runtime: ""2.3-4.el6_5"" sysvinit-tools: ""2.87-5.dsf.el6"" tar: ""1.23-11.el6"" tcl: ""8.5.7-6.el6"" tcpdump: ""4.0.0-3.20090921gitdf3cb4.2.el6"" tcp_wrappers: ""7.6-57.el6"" tcp_wrappers-libs: ""7.6-57.el6"" tcsh: ""6.17-24.el6"" telnet: ""0.17-47.el6_3.1"" tftp-server: ""0.49-7.el6"" time: ""1.7-37.1.el6"" tinyproxy: ""1.8.2-1.el6"" tk: ""8.5.7-5.el6"" tmpwatch: ""2.9.16-4.el6"" tmux: ""1.6-3.el6"" traceroute: ""2.0.14-2.el6"" tunctl: ""1.5-3.el6"" tzdata: ""2014b-3.24.el6"" tzdata-java: ""2014b-3.24.el6"" udev: ""147-2.51.el6"" unixODBC: ""2.2.14-12.el6_3"" unzip: ""6.0-1.el6"" upstart: ""0.6.5-13.el6_5.3"" urw-fonts: ""2.4-10.el6"" usbutils: ""003-4.el6"" usermode: ""1.102-3.el6"" ustr: ""1.0.4-9.1.el6"" util-linux-ng: ""2.17.2-12.14.el6_5"" uwsgi: ""2.0.3-1.mw.mira1"" uwsgi-plugin-common: ""2.0.3-1.mw.mira1"" uwsgi-plugin-python: ""2.0.3-1.mw.mira1"" v8: ""3.14.5.7-3.el6"" vconfig: ""1.9-8.1.el6"" vgabios: ""0.6c-5.el6"" vim-common: ""7.2.411-1.8.el6"" vim-enhanced: ""7.2.411-1.8.el6"" vim-minimal: ""7.2.411-1.8.el6"" virt-what: ""1.11-1.2.el6"" wget: ""1.12-1.11.el6_5"" whatmask: ""1.2-7.el6"" which: ""2.19-6.el6"" wireless-tools: ""29-5.1.1.el6"" wireshark: ""1.8.10-7.el6_5"" words: ""3.0-17.el6"" wxBase: ""2.8.12-2.el6"" wxGTK: ""2.8.12-2.el6"" wxGTK-gl: ""2.8.12-2.el6"" xdg-utils: ""1.0.2-17.20091016cvs.el6"" xfsprogs: ""3.1.1-14.el6"" xinetd: ""2.3.14-39.el6_4"" xmlrpc-c: ""1.16.24-1210.1840.el6"" xmlrpc-c-client: ""1.16.24-1210.1840.el6"" xorg-x11-drv-ati-firmware: ""7.1.0-3.el6"" xorg-x11-font-utils: ""7.2-11.el6"" xz: ""4.999.9-0.3.beta.20091007git.el6"" xz-libs: ""4.999.9-0.3.beta.20091007git.el6"" xz-lzma-compat: ""4.999.9-0.3.beta.20091007git.el6"" yajl: ""1.0.7-3.el6"" yum: ""3.2.29-40.el6.centos"" yum: ""3.2.29-43.el6.centos"" yum-metadata-parser: ""1.1.2-16.el6"" yum-plugin-fastestmirror: ""1.1.30-17.el6_5"" yum-plugin-security: ""1.1.30-17.el6_5"" yum-utils: ""1.1.30-14.el6"" yum-utils: ""1.1.30-17.el6_5"" zabbix: ""2.2.2-1.el6"" zabbix-agent: ""2.2.2-1.el6"" zabbix-sender: ""2.2.2-1.el6"" zabbix-server: ""2.2.2-1.el6"" zabbix-server-mysql: ""2.2.2-1.el6"" zabbix-server-pgsql: ""2.2.2-1.el6"" zabbix-web: ""2.2.2-1.el6"" zabbix-web-mysql: ""2.2.2-1.el6"" zabbix-web-pgsql: ""2.2.2-1.el6"" zd1211-firmware: ""1.4-4.el6"" zip: ""3.0-1.el6"" zlib: ""1.2.3-29.el6"" zlib-devel: ""1.2.3-29.el6"" ",,2247,0
openstack%2Ffuel-main~master~I596d10833c979cd8941c4771e9f5fdeebe4c9948,openstack/fuel-main,master,I596d10833c979cd8941c4771e9f5fdeebe4c9948,"Add config.yaml to upgrade tarball, update package structure",MERGED,2014-06-18 14:24:36.000000000,2014-06-24 14:25:26.000000000,2014-06-24 14:25:24.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-18 14:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b0ff673f9f4b68a82c7e7e2cf9c5f8bb70c318d6', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}, {'number': 2, 'created': '2014-06-18 14:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/37f5424b8fc478037763a2aaa0c207f02ce9651c', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}, {'number': 3, 'created': '2014-06-18 15:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2c7c24260b018aa751ee582ef47b48d93f1174bf', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}, {'number': 4, 'created': '2014-06-19 09:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/14ae26cb50e7fe39f2b6012d03df37ac9ea7d2fe', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}, {'number': 5, 'created': '2014-06-19 10:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9483aedb8212c5a816bf104e47419dcca814913a', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\nCloses-Bug: #1331552'}, {'number': 6, 'created': '2014-06-19 13:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9295ce589b13d9b1be573734f99986b9ab6e95f6', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}, {'number': 7, 'created': '2014-06-19 13:57:58.000000000', 'files': ['upgrade/module.mk', 'iso/pkg-versions.awk', 'iso/module.mk', 'iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4961b8ea0a823820143a4b00f4d125b7734775ff', 'message': 'Add config.yaml to upgrade tarball, update package structure\n\nChange-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948\n'}]",3,100918,4961b8ea0a823820143a4b00f4d125b7734775ff,48,5,7,8789,,,0,"Add config.yaml to upgrade tarball, update package structure

Change-Id: I596d10833c979cd8941c4771e9f5fdeebe4c9948
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/18/100918/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade/module.mk'],1,b0ff673f9f4b68a82c7e7e2cf9c5f8bb70c318d6,upgrade-make, tar cf $(BUILD_DIR)/upgrade/common-part.tar -C $(BUILD_DIR)/repos/fuellib/deployment --xform s:^puppet/:upgrade/puppet/modules/: puppet tar rf $(BUILD_DIR)/upgrade/common-part.tar -C $(BUILD_DIR)/repos/fuellib/deployment/puppet/osnailyfacter/examples --xform s:^:upgrade/puppet/manifests/: site.pp tar rf $(BUILD_DIR)/upgrade/common-part.tar -C $(BUILD_DIR)/repos/nailgun/fuel_upgrade_system/fuel_upgrade/fuel_upgrade --xform s:^:upgrade/: config.yaml tar cf $(BUILD_DIR)/upgrade/openstack-part.tar -C $(LOCAL_MIRROR) --xform s:^centos/os/x86_64/:upgrade/repos/centos/x86_64/: centos/os/x86_64 tar rf $(BUILD_DIR)/upgrade/openstack-part.tar -C $(LOCAL_MIRROR) --xform s:^ubuntu/:upgrade/repos/ubuntu/x86_64/: ubuntu, tar cf $(BUILD_DIR)/upgrade/common-part.tar -C $(BUILD_DIR)/repos/fuellib/deployment --xform s:^:upgrade/: puppet tar cf $(BUILD_DIR)/upgrade/openstack-part.tar -C $(LOCAL_MIRROR) --xform s:^:upgrade/repos/: centos ubuntu,5,2
openstack%2Fhorizon~master~Ic43d38a2e5eb853a8c214febe9b29537fae58255,openstack/horizon,master,Ic43d38a2e5eb853a8c214febe9b29537fae58255,Add regions module,ABANDONED,2014-06-24 13:16:07.000000000,2014-06-24 14:23:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-24 13:16:07.000000000', 'files': ['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/test/integration_tests/regions/messages.py', 'openstack_dashboard/test/integration_tests/regions/tables.py', 'openstack_dashboard/test/integration_tests/regions/__init__.py', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/integration_tests/pages/basepage.py', 'openstack_dashboard/test/integration_tests/pages/projectpage.py', 'openstack_dashboard/test/integration_tests/tests/test_project_compute_overview.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e0b24c7a1056705d464b4e807ce481c883383074', 'message': 'Add regions module\n\nRegions module should contains basic functionality that should be\nshared among multiple page objects: common tables, forms,\nnotifications etc.. Basically every piece of code that can be reused by\nmultiple classes in a form of a new object should be placed in here.\n\n* To test newly created regions was created simple test class in\n  tests/test_project_compute_overview that verifies basic functionality\n  of some newly created regions.\n\n* I would suggest that already created regions should be moved into this\n  module.\n\n* I would consider region everything that can be reused by at least\n  two page objects and aim for maximal code reusability in the future.\n\nChange-Id: Ic43d38a2e5eb853a8c214febe9b29537fae58255\n'}]",0,102222,e0b24c7a1056705d464b4e807ce481c883383074,4,1,1,11473,,,0,"Add regions module

Regions module should contains basic functionality that should be
shared among multiple page objects: common tables, forms,
notifications etc.. Basically every piece of code that can be reused by
multiple classes in a form of a new object should be placed in here.

* To test newly created regions was created simple test class in
  tests/test_project_compute_overview that verifies basic functionality
  of some newly created regions.

* I would suggest that already created regions should be moved into this
  module.

* I would consider region everything that can be reused by at least
  two page objects and aim for maximal code reusability in the future.

Change-Id: Ic43d38a2e5eb853a8c214febe9b29537fae58255
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/102222/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/test/integration_tests/regions/messages.py', 'openstack_dashboard/test/integration_tests/regions/tables.py', 'openstack_dashboard/test/integration_tests/regions/__init__.py', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/integration_tests/pages/basepage.py', 'openstack_dashboard/test/integration_tests/pages/projectpage.py', 'openstack_dashboard/test/integration_tests/tests/test_project_compute_overview.py']",8,e0b24c7a1056705d464b4e807ce481c883383074,regions,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack_dashboard.test.integration_tests import helpers class TestProjectComputeOverview(helpers.TestCase): """"""This test is more likely for verification that some basic regions functionality works as expected. """""" def test_invalid_date(self): """"""Submiting invalid date should result in visibility of error message """""" self.home_pg.date_form.query(""2000-06-01"", ""1980-06-01"") self.assertTrue(self.home_pg.error_message.is_present(), ""Error message is not present eventhough"" "" submitted date was invalid."") def test_empty_action_table(self): """"""Usage table should be empty after submiting ridiculous date"""""" self.home_pg.date_form.query(""2000-06-01"", ""2000-06-02"") # no error message should not be displayed self.assertFalse(self.home_pg.error_message.is_present(), ""Error message should not be visible."") self.assertFalse(self.home_pg.action_table.rows, ""Table should be empty."") def test_table_data_save_to_csv_action(self): csv_btn = self.home_pg.action_table.actions[0] # not sure about the string comparsion ... action_name = ""Download CSV Summary"" self.assertEqual(action_name, csv_btn.text, ""Action name should be: %s"" % action_name) ",,307,0
openstack%2Fsahara~master~I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c,openstack/sahara,master,I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c,Avoid deleting transient cluster before job is started,MERGED,2014-04-15 14:30:21.000000000,2014-06-24 14:19:44.000000000,2014-04-21 13:37:05.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-04-15 14:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a1ca547a29cb88e17bb1272eb18f40e7121b00e2', 'message': 'Avoid deleting transient cluster before job is started\n\nIn order to run job on a transient cluster client needs to execute\ntwo commands:\n * create cluster with is_transient=true\n * run job on it in a regular manner\n\nWe terminate unneeded transient clusters in a periodic job, which\nterminates cluster if cluster is transient and no job is running on it\nat a time. We also do not terminate cluster if its lifetime is smaller\nthen config parameter min_transient_cluster_active_time. For some\nreason the parameter is set to 0 by default, which could cause\npremature cluster termination if periodic task runs between\ncluster creation and job execution.\n\nChange-Id: I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c\n'}, {'number': 2, 'created': '2014-04-15 20:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e5f29470d58bcf3f8711b52005431a2eb267e751', 'message': 'Avoid deleting transient cluster before job is started\n\nIn order to run job on a transient cluster client needs to execute\ntwo commands:\n * create cluster with is_transient=true\n * run job on it in a regular manner\n\nWe terminate unneeded transient clusters in a periodic job, which\nterminates cluster if cluster is transient and no job is running on it\nat a time. We also do not terminate cluster if its lifetime is smaller\nthen config parameter min_transient_cluster_active_time. For some\nreason the parameter is set to 0 by default, which could cause\npremature cluster termination if periodic task runs between\ncluster creation and job execution.\n\nChange-Id: I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c\n'}, {'number': 3, 'created': '2014-04-16 11:59:40.000000000', 'files': ['sahara/service/periodic.py', 'etc/sahara/sahara.conf.sample', 'sahara/tests/unit/service/test_periodic.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/400d90da07ecabeffca17bf9ca7bbe85339345cf', 'message': 'Avoid deleting transient cluster before job is started\n\nIn order to run job on a transient cluster client needs to execute\ntwo commands:\n * create cluster with is_transient=true\n * run job on it in a regular manner\n\nWe terminate unneeded transient clusters in a periodic job, which\nterminates cluster if cluster is transient and no job is running on it\nat a time. We also do not terminate cluster if its lifetime is smaller\nthen config parameter min_transient_cluster_active_time. For some\nreason the parameter is set to 0 by default, which could cause\npremature cluster termination if periodic task runs between\ncluster creation and job execution.\n\nAlso added unit tests to verify min_transient_cluster_active_time.\n\nChange-Id: I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c\n'}]",0,87660,400d90da07ecabeffca17bf9ca7bbe85339345cf,34,6,3,7109,,,0,"Avoid deleting transient cluster before job is started

In order to run job on a transient cluster client needs to execute
two commands:
 * create cluster with is_transient=true
 * run job on it in a regular manner

We terminate unneeded transient clusters in a periodic job, which
terminates cluster if cluster is transient and no job is running on it
at a time. We also do not terminate cluster if its lifetime is smaller
then config parameter min_transient_cluster_active_time. For some
reason the parameter is set to 0 by default, which could cause
premature cluster termination if periodic task runs between
cluster creation and job execution.

Also added unit tests to verify min_transient_cluster_active_time.

Change-Id: I5330a969ea7cd81ec2759a7fe32bab4a5de3fb4c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/60/87660/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/periodic.py'],1,a1ca547a29cb88e17bb1272eb18f40e7121b00e2,(detached," default=30,"," default=0,",1,1
openstack%2Frelease-tools~master~If1054ae93b832b5923d59e3ef12c719600b6b079,openstack/release-tools,master,If1054ae93b832b5923d59e3ef12c719600b6b079,Fix wait_for_tarball.py reporting whl artifacts,MERGED,2014-06-20 15:03:38.000000000,2014-06-24 14:08:38.000000000,2014-06-24 14:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-06-20 15:03:38.000000000', 'files': ['wait_for_tarball.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/1b97c58cc11efbd40680416e0e514ed361c49ea1', 'message': 'Fix wait_for_tarball.py reporting whl artifacts\n\nSome -tarball jobs now build .whl artifacts, and wait_for_tarball.py\ndisplays a message reporting the first of the job artifacts filename\nas the ""built tarball"". Use the last artifact filename in the\ndisplayed message instead.\n\nChange-Id: If1054ae93b832b5923d59e3ef12c719600b6b079\n'}]",0,101573,1b97c58cc11efbd40680416e0e514ed361c49ea1,10,3,1,308,,,0,"Fix wait_for_tarball.py reporting whl artifacts

Some -tarball jobs now build .whl artifacts, and wait_for_tarball.py
displays a message reporting the first of the job artifacts filename
as the ""built tarball"". Use the last artifact filename in the
displayed message instead.

Change-Id: If1054ae93b832b5923d59e3ef12c719600b6b079
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/73/101573/1 && git format-patch -1 --stdout FETCH_HEAD,['wait_for_tarball.py'],1,1b97c58cc11efbd40680416e0e514ed361c49ea1,fix-wait-for-t, return job_json['artifacts'][-1]['displayPath'], return job_json['artifacts'][0]['displayPath'],1,1
openstack%2Fosprofiler~master~I86112eb0b6f0f01222a4f84985edd74a1881e89a,openstack/osprofiler,master,I86112eb0b6f0f01222a4f84985edd74a1881e89a,Refactor WSGI.middleware and imporve test coverage,MERGED,2014-06-24 13:44:20.000000000,2014-06-24 14:05:43.000000000,2014-06-24 14:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-24 13:44:20.000000000', 'files': ['tests/test_utils.py', 'osprofiler/utils.py', 'osprofiler/web.py', 'tests/test_web.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/145ce108ab2b551698f2706156f047f70381ee8c', 'message': 'Refactor WSGI.middleware and imporve test coverage\n\n*) Move all logic related to secure transport of trace info to osprofiler/utils.py\n*) Add to methods singed_pack, signed_unpack that hides all complexity of packing\ndata, generating hmac, and validating hmac data.\n*) Cover osprofiler/utils.py by separated tests\n*) Remove mess from WSGI middleware and add_trace_id_header\n*) Simplify web tests\n*) Disable possibility to setup empty hmac keys, cause of security reasons\n\nChange-Id: I86112eb0b6f0f01222a4f84985edd74a1881e89a\n'}]",0,102233,145ce108ab2b551698f2706156f047f70381ee8c,7,2,1,6172,,,0,"Refactor WSGI.middleware and imporve test coverage

*) Move all logic related to secure transport of trace info to osprofiler/utils.py
*) Add to methods singed_pack, signed_unpack that hides all complexity of packing
data, generating hmac, and validating hmac data.
*) Cover osprofiler/utils.py by separated tests
*) Remove mess from WSGI middleware and add_trace_id_header
*) Simplify web tests
*) Disable possibility to setup empty hmac keys, cause of security reasons

Change-Id: I86112eb0b6f0f01222a4f84985edd74a1881e89a
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/33/102233/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_utils.py', 'osprofiler/utils.py', 'osprofiler/web.py', 'tests/test_web.py']",4,145ce108ab2b551698f2706156f047f70381ee8c,simplify_code,"class WebTestCase(test.TestCase): def setUp(self): super(WebTestCase, self).setUp() profiler._clean() self.addCleanup(profiler._clean) def test_add_trace_id_header_no_hmac(self): profiler.init(base_id=""y"", parent_id=""z"") headers = {""a"": 10, ""b"": 20} web.add_trace_id_header(headers) self.assertEqual(sorted(headers.keys()), [""a"", ""b""]) def test_add_trace_id_header(self): profiler.init(base_id=""y"", parent_id=""z"", hmac_key=""key"") headers = {""a"": 10, ""b"": 20} web.add_trace_id_header(headers) self.assertEqual(sorted(headers.keys()), sorted([""a"", ""b"", ""X-Trace-Info"", ""X-Trace-HMAC""])) trace_info = utils.signed_unpack(headers[""X-Trace-Info""], headers[""X-Trace-HMAC""], ""key"") self.assertEqual({""parent_id"": 'z', 'base_id': 'y'}, trace_info) @mock.patch(""osprofiler.profiler.get_profiler"") def test_add_trace_id_header_no_profiler(self, mock_get_profiler): mock_get_profiler.return_value = False headers = {""a"": ""a"", ""b"": 1} old_headers = dict(headers) web.add_trace_id_header(headers) self.assertEqual(old_headers, headers) def _test_wsgi_middleware_with_invalid_trace(self, headers, hmac_key, mock_profiler_init, enabled=True): request.headers = headers middleware = web.WsgiMiddleware(""app"", hmac_key, enabled=enabled) self.assertEqual(0, mock_profiler_init.call_count) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_disabled(self, mock_profiler_init): hmac_key = ""secret"" pack = utils.signed_pack({""base_id"": ""1"", ""parent_id"": ""2""}, hmac_key) headers = { ""a"": ""1"", ""b"": ""2"", ""X-Trace-Info"": pack[0], ""X-Trace-HMAC"": pack[1] } self._test_wsgi_middleware_with_invalid_trace(headers, hmac_key, mock_profiler_init, enabled=False) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_no_trace(self, mock_profiler_init): headers = { ""a"": ""1"", ""b"": ""2"" } self._test_wsgi_middleware_with_invalid_trace(headers, ""secret"", mock_profiler_init) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_invalid_trace_headers(self, mock_profiler_init): headers = { ""a"": ""1"", ""b"": ""2"", ""X-Trace-Info"": ""abbababababa"", ""X-Trace-HMAC"": ""abbababababa"" } self._test_wsgi_middleware_with_invalid_trace(headers, ""secret"", mock_profiler_init) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_no_trace_hmac(self, mock_profiler_init): hmac_key = ""secret"" pack = utils.signed_pack({""base_id"": ""1"", ""parent_id"": ""2""}, hmac_key) headers = { ""a"": ""1"", ""b"": ""2"", ""X-Trace-Info"": pack[0] } self._test_wsgi_middleware_with_invalid_trace(headers, hmac_key, mock_profiler_init) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_invalid_hmac(self, mock_profiler_init): hmac_key = ""secret"" pack = utils.signed_pack({""base_id"": ""1"", ""parent_id"": ""2""}, hmac_key) headers = { ""a"": ""1"", ""b"": ""2"", ""X-Trace-Info"": pack[0], ""X-Trace-HMAC"": ""not valid hmac"" } self._test_wsgi_middleware_with_invalid_trace(headers, hmac_key, mock_profiler_init) @mock.patch(""osprofiler.web.profiler.init"") def test_wsgi_middleware_invalid_trace_info(self, mock_profiler_init): hmac_key = ""secret"" pack = utils.signed_pack([{""base_id"": ""1""}, {""parent_id"": ""2""}], hmac_key) headers = { ""a"": ""1"", ""b"": ""2"", ""X-Trace-Info"": pack[0], ""X-Trace-HMAC"": pack[1] } self._test_wsgi_middleware_with_invalid_trace(headers, hmac_key, mock_profiler_init) hmac_key = ""secret"" pack = utils.signed_pack({""base_id"": ""1"", ""parent_id"": ""2""}, hmac_key) ""X-Trace-Info"": pack[0], ""X-Trace-HMAC"": pack[1] } middleware = web.WsgiMiddleware(""app"", hmac_key, enabled=True) mock_profiler_init.assert_called_once_with(""1"", ""2"", hmac_key)","import base64 import json from webob import request as webob_request def test_add_trace_id_header(self): profiler.init(base_id=""y"", parent_id=""z"") headers = {""a"": 10, ""b"": 20} web.add_trace_id_header(headers) self.assertEqual(sorted(headers.keys()), sorted([""a"", ""b"", ""X-Trace-Info""])) trace_info = base64.urlsafe_b64decode(headers[""X-Trace-Info""]) trace_info = json.loads(utils.binary_decode(trace_info)) self.assertEqual({""parent_id"": 'z', 'base_id': 'y'}, trace_info) @mock.patch(""osprofiler.profiler.get_profiler"") def test_add_trace_id_header_no_profiler(self, mock_get_profiler): mock_get_profiler.return_value = False headers = {""a"": ""a"", ""b"": 1} old_headers = dict(headers) web.add_trace_id_header(headers) self.assertEqual(old_headers, headers) def test_wsgi_hmac_no_headers(self): req = webob_request.Request.blank(""/"") m = web.WsgiMiddleware(dummy_app, enabled=True, hmac_key=""secret_password"") m(req) p = profiler.get_profiler() self.assertIsNone(p) def test_wsgi_hmac_headers_init_profiler(self): hmac_key = 'secret_password' profiler.init(base_id=""b"", parent_id=""a"", hmac_key=hmac_key) headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) profiler._clean() self.assertIsNone(profiler.get_profiler()) req = webob_request.Request.blank(""/"", headers=headers) m = web.WsgiMiddleware(dummy_app, enabled=True, hmac_key=hmac_key) m(req) p = profiler.get_profiler() self.assertIsNotNone(p) self.assertEqual('a', p.get_id()) self.assertEqual('b', p.get_base_id()) def test_wsgi_hmac_headers_init_profiler_spaces(self): hmac_key = 'secret_password' profiler.init(base_id=""b"", parent_id=""a"", hmac_key=hmac_key) headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) headers['X-Trace-HMAC'] = ""\t "" + headers['X-Trace-HMAC'] + "" \n"" profiler._clean() self.assertIsNone(profiler.get_profiler()) req = webob_request.Request.blank(""/"", headers=headers) m = web.WsgiMiddleware(dummy_app, enabled=True, hmac_key=hmac_key) m(req) p = profiler.get_profiler() self.assertIsNotNone(p) self.assertEqual('a', p.get_id()) self.assertEqual('b', p.get_base_id()) def test_wsgi_hmac_headers_no_init_profiler(self): profiler.init(base_id=""b"", parent_id=""a"", hmac_key=""hacked_password"") headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) profiler._clean() self.assertIsNone(profiler.get_profiler()) req = webob_request.Request.blank(""/"", headers=headers) m = web.WsgiMiddleware(dummy_app, enabled=True, hmac_key=""secret_password"") m(req) p = profiler.get_profiler() self.assertIsNone(p) def test_hmac_generation(self): profiler.init(base_id=""b"", parent_id=""a"", hmac_key=""secret_password"") headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) self.assertIn('X-Trace-HMAC', headers) self.assertTrue(len(headers['X-Trace-HMAC']) > 0) def test_hmac_no_generation(self): profiler.init(base_id=""b"", parent_id=""a"") headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) self.assertNotIn('X-Trace-HMAC', headers) self.assertIn('X-Trace-Info', headers) self.assertEqual(2, len(headers)) def test_hmac_validation(self): profiler.init(base_id=""b"", parent_id=""a"", hmac_key=""secret_password"") headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) content = headers.get(""X-Trace-Info"") web.validate_hmac(content, headers['X-Trace-HMAC'], ""secret_password"") def test_invalid_hmac(self): profiler.init(base_id=""b"", parent_id=""a"", hmac_key=""secret_password"") headers = { 'Content-Type': 'text/javascript', } web.add_trace_id_header(headers) content = headers.get(""X-Trace-Info"") content += b""_changed"" self.assertRaises(IOError, web.validate_hmac, content, headers['X-Trace-HMAC'], ""secret_password"") def test_hmac_faked(self): headers = { 'Content-Type': 'text/javascript', 'X-Trace-HMAC': 'fake', 'X-Trace-Info': '{}', } content = headers.get(""X-Trace-Info"") self.assertRaises(IOError, web.validate_hmac, content, headers['X-Trace-HMAC'], 'secret_password') def test_wsgi_middleware_no_trace(self): request.headers = {""a"": ""1"", ""b"": ""2""} middleware = web.WsgiMiddleware(""app"", enabled=True) def test_wsgi_middleware_disabled(self): request = mock.MagicMock() request.get_response.return_value = ""yeah!"" request.headers = {""a"": ""1"", ""b"": ""2""} middleware = web.WsgiMiddleware(""app"", enabled=False) self.assertEqual(""yeah!"", middleware(request)) request.get_response.assert_called_once_with(""app"") trace_info = {""base_id"": ""1"", ""parent_id"": ""2""} trace_info = utils.binary_encode(json.dumps(trace_info)) trace_info = base64.urlsafe_b64encode(trace_info) ""X-Trace-Info"": trace_info, } middleware = web.WsgiMiddleware(""app"", enabled=True) mock_profiler_init.assert_called_once_with(""1"", ""2"", None)",281,222
openstack%2Fnova~master~Id52883a4f1fa7d05d61b31674acd1ca57918c3e1,openstack/nova,master,Id52883a4f1fa7d05d61b31674acd1ca57918c3e1,Fix detaching pci device failed,MERGED,2014-05-13 07:30:43.000000000,2014-06-24 14:03:01.000000000,2014-06-24 14:02:58.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 7400}, {'_account_id': 9578}, {'_account_id': 9755}, {'_account_id': 9847}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-05-13 07:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e151c04eb8f8babe6bcbbf889f91867c48d402a', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 2, 'created': '2014-05-13 07:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c81d080801b408ff7df9255836e3f2959d9db522', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 3, 'created': '2014-05-20 06:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4be29c46e62967de9d9cd1243eabbe92b4c1136c', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 4, 'created': '2014-05-21 03:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1debb8e6d21ced3953f2ab6d5d25a3110b89f55', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 5, 'created': '2014-06-12 07:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cc9627e1f6733ed27c905fe34052818026afb39', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 6, 'created': '2014-06-12 07:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aece2d5157002cd29e7c05fd6921e168a45db0af', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 7, 'created': '2014-06-12 09:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f1b7eed90566725ece339a4848439603e634491', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}, {'number': 8, 'created': '2014-06-23 05:53:45.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c75cd9a8b9da86b9d9e7ffd6512fe13b1913fd85', 'message': 'Fix detaching pci device failed\n\nafter booting an instance with flavor has pci device,\nand then resize the instance, it will raise an ""AttributeError"".\nthis because in the method _detach_pci_devices(),\nguest_config.devices will have more device not only pci, like disk.\n\nCloses-bug: #1318891\n\nChange-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1\n'}]",2,93383,c75cd9a8b9da86b9d9e7ffd6512fe13b1913fd85,66,14,8,9755,,,0,"Fix detaching pci device failed

after booting an instance with flavor has pci device,
and then resize the instance, it will raise an ""AttributeError"".
this because in the method _detach_pci_devices(),
guest_config.devices will have more device not only pci, like disk.

Closes-bug: #1318891

Change-Id: Id52883a4f1fa7d05d61b31674acd1ca57918c3e1
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/93383/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_libvirt.py', 'nova/virt/libvirt/driver.py']",2,8e151c04eb8f8babe6bcbbf889f91867c48d402a,bug/1318891," if getattr(d, 'type', None) == 'pci']:", if d.type == 'pci']:,14,5
openstack%2Fnova~master~Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0,openstack/nova,master,Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0,Should not delete active snapshot when instance is terminated,MERGED,2014-06-16 01:21:53.000000000,2014-06-24 14:02:47.000000000,2014-06-24 14:02:44.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2835}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9323}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-16 01:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07d43c2936e75178650b471c0e3c7e7db4ec919b', 'message': 'Active snapshot should not delete after instance is terminated\n\nAfter intance is terminated, we should check the status of\nsnapshot if it is active, we should not delete a snapshot in\nactive status.\n\nChange-Id: Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0\nCloses-Bug: #1329882\n'}, {'number': 2, 'created': '2014-06-19 02:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff427b9e1f8fd241df22c82e8b50e6fd15ea691d', 'message': 'Active snapshot should not delete after instance is terminated\n\nAfter intance is terminated, we should check the status of\nsnapshot if it is active, we should not delete a snapshot in\nactive status.\n\nChange-Id: Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0\nCloses-Bug: #1329882\n'}, {'number': 3, 'created': '2014-06-19 03:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe08a7b3cc81b7ebec17acfad41c5a80dfa6d24b', 'message': 'Active snapshot should not delete after instance is terminated\n\nAfter intance is terminated, we should check the status of\nsnapshot if it is active, we should not delete a snapshot in\nactive status.\n\nChange-Id: Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0\nCloses-Bug: #1329882\n'}, {'number': 4, 'created': '2014-06-19 09:31:08.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c28956a6872b34a93891c985c93aad5e242563b6', 'message': 'Should not delete active snapshot when instance is terminated\n\nThe instance might be deleted when doing snapshot, need to check\nwhether the snapshot is active state before delete it.\n\nChange-Id: Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0\nCloses-Bug: #1329882\n'}]",4,100120,c28956a6872b34a93891c985c93aad5e242563b6,55,16,4,9323,,,0,"Should not delete active snapshot when instance is terminated

The instance might be deleted when doing snapshot, need to check
whether the snapshot is active state before delete it.

Change-Id: Ic12b8dfd05ad7f36831dd073cef746f094d8f2d0
Closes-Bug: #1329882
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/100120/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,07d43c2936e75178650b471c0e3c7e7db4ec919b,bug/1329882," image = image_service.show(context, image_id) if image['status'] != 'active': image_service.delete(context, image_id)"," image_service.delete(context, image_id)",3,1
openstack%2Fnova~master~I75195417e123f135252470cf1322843830556b0a,openstack/nova,master,I75195417e123f135252470cf1322843830556b0a,Catch permission denied exception when update host,MERGED,2014-05-23 08:34:01.000000000,2014-06-24 14:01:57.000000000,2014-06-24 14:01:55.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9223}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-05-23 08:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aafd33030c52392a2996811f761b2cf6049d7ea0', 'message': 'Catch the permission denied exception when getting the instance disk\ninfo.\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\n'}, {'number': 2, 'created': '2014-05-23 08:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07a1ad50775e4df1dc513c518767e42613c71a0f', 'message': 'Catch the permission denied exception when getting the instance disk\ninfo.\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 3, 'created': '2014-05-23 08:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e44bbc8c23889fa830fa3c50f0fc205ada34e7af', 'message': 'Catch the permission denied exception when getting the instance disk\ninfo.\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 4, 'created': '2014-05-23 10:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab404267cebf2fc2fd8239413ea893dcfdf244d2', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 5, 'created': '2014-05-26 01:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b008192327e3056b3c79440789ccaf661ae3eb1', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 6, 'created': '2014-06-12 07:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a289f4fe456ae5ab70b269090ef34188d214b5aa', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 7, 'created': '2014-06-17 18:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45816779c4da53e19815282db6b8ea9d42150e6b', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 8, 'created': '2014-06-17 18:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/599abee3b51da74a308e3fda8190e55befb33ff7', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 9, 'created': '2014-06-18 08:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce5fd8fb078edb6aad9bacae93f148fb75a6f403', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 10, 'created': '2014-06-18 08:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20192848b93e7460b8525b274be19bf7594edcf7', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 11, 'created': '2014-06-18 09:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24959886096104f297555537e4c4831552c5da8f', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 12, 'created': '2014-06-19 08:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/078935069a282d7e4a7a26551c442e81208415d8', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 13, 'created': '2014-06-19 15:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/032be0401a49d3920fd8c80149ce49a05f00320a', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 14, 'created': '2014-06-19 16:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8044efd557509642023bdab17de8a5085701257e', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 15, 'created': '2014-06-20 00:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ff111ff49ba57e0f73451bdee59594e28bc31cc', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}, {'number': 16, 'created': '2014-06-20 15:52:42.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ebecfd496ec8aaef07a401d3c90e2e5da406d16f', 'message': 'Catch permission denied exception when update host\n\nWhen an existing non-openstack instance in the compute node contains\ndisk file which can not be accessed by nova non-root user, resources can\nnot be updated successfully when periodic task is running. Also the\nnova-compute service could not be restared again. We should catch such\nexception.\n\nChange-Id: I75195417e123f135252470cf1322843830556b0a\nCloses-Bug: 1322467\n'}]",16,95105,ebecfd496ec8aaef07a401d3c90e2e5da406d16f,132,15,16,9223,,,0,"Catch permission denied exception when update host

When an existing non-openstack instance in the compute node contains
disk file which can not be accessed by nova non-root user, resources can
not be updated successfully when periodic task is running. Also the
nova-compute service could not be restared again. We should catch such
exception.

Change-Id: I75195417e123f135252470cf1322843830556b0a
Closes-Bug: 1322467
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/95105/16 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,aafd33030c52392a2996811f761b2cf6049d7ea0,bug/1322467," if e.errno == errno.EACCES: LOG.warning(_('Periodic task is updating the host stat, ' 'it is trying to get disk %(i_name)s, ' 'but disk file was not allowed to access ' 'by nova non-root user.'), {'i_name': i_name})",,6,0
openstack%2Frally~master~Ie6b8634c910631e66f94349ef8c1c6dfb33d9fc4,openstack/rally,master,Ie6b8634c910631e66f94349ef8c1c6dfb33d9fc4,Make it simpler to get results,ABANDONED,2014-06-24 13:23:52.000000000,2014-06-24 13:59:44.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-24 13:23:52.000000000', 'files': ['tests_ci/rally-gate.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/39a0a83b87fbe10091fdc5a2bd1dd5c65744eeda', 'message': 'Make it simpler to get results\n\nChange-Id: Ie6b8634c910631e66f94349ef8c1c6dfb33d9fc4\n'}]",0,102226,39a0a83b87fbe10091fdc5a2bd1dd5c65744eeda,4,1,1,6172,,,0,"Make it simpler to get results

Change-Id: Ie6b8634c910631e66f94349ef8c1c6dfb33d9fc4
",git fetch https://review.opendev.org/openstack/rally refs/changes/26/102226/1 && git format-patch -1 --stdout FETCH_HEAD,['tests_ci/rally-gate.sh'],1,39a0a83b87fbe10091fdc5a2bd1dd5c65744eeda,try_something,rally task plot2html --out rally-plot/index.html gzip -9 rally-plot/index.html,rally task plot2html --out rally-plot/results.html gzip -9 rally-plot/results.html,2,2
openstack%2Fpuppet-glance~master~I526c0892d123067362ea1b18cb8c21526a860981,openstack/puppet-glance,master,I526c0892d123067362ea1b18cb8c21526a860981,Glance registry protocol should be configurable,MERGED,2014-06-17 04:01:39.000000000,2014-06-24 13:55:47.000000000,2014-06-24 13:55:47.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 7155}, {'_account_id': 7822}, {'_account_id': 9820}]","[{'number': 1, 'created': '2014-06-17 04:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6354c48ba185bb2f36d2f531d4c0767403a4ecf7', 'message': 'Glance registry protocol should be configurable\n\nChange-Id: I526c0892d123067362ea1b18cb8c21526a860981\nCloses-bug: #1266988\n'}, {'number': 2, 'created': '2014-06-18 02:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/3d335282876b286ba9b52763fbf69a2c5d739327', 'message': 'Glance registry protocol should be configurable\n\nChange-Id: I526c0892d123067362ea1b18cb8c21526a860981\nCloses-bug: #1266988\n'}, {'number': 3, 'created': '2014-06-19 00:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7e6897fb6db3e45c1d132c9b287b9c5ff63a9bf0', 'message': 'Glance registry protocol should be configurable\n\nChange-Id: I526c0892d123067362ea1b18cb8c21526a860981\nCloses-bug: #1266988\n'}, {'number': 4, 'created': '2014-06-24 03:01:06.000000000', 'files': ['manifests/api.pp', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7f439210b1197efc55ec148074a598b1cb1e3816', 'message': 'Glance registry protocol should be configurable\n\nregistry_client_protocol can\'t be configure in puppet now.\nThe default value is ""http"". It should be configurable.\n\nChange-Id: I526c0892d123067362ea1b18cb8c21526a860981\nCloses-bug: #1266988\n'}]",12,100410,7f439210b1197efc55ec148074a598b1cb1e3816,25,7,4,9820,,,0,"Glance registry protocol should be configurable

registry_client_protocol can't be configure in puppet now.
The default value is ""http"". It should be configurable.

Change-Id: I526c0892d123067362ea1b18cb8c21526a860981
Closes-bug: #1266988
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/10/100410/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/api.pp'],1,6354c48ba185bb2f36d2f531d4c0767403a4ecf7,bug1266988,"# [*registry_protocol*] # (optional) The protocol of the Glance registry service. # Default: http # $registry_protocol = 'http', 'DEFAULT/registry_client_protocol': value => $registry_protocol; 'DEFAULT/registry_client_protocol': value => $registry_protocol;",,7,0
openstack%2Foslo-incubator~master~I0e2decd8d4ad58c999b8ecbab2c5e921dc8b1df8,openstack/oslo-incubator,master,I0e2decd8d4ad58c999b8ecbab2c5e921dc8b1df8,Enable test_strutils for Python 3,MERGED,2014-06-24 08:01:32.000000000,2014-06-24 13:53:30.000000000,2014-06-24 13:53:30.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-06-24 08:01:32.000000000', 'files': ['tests/unit/test_strutils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/27755cd417480dc560105408bfc464be9d7f0d80', 'message': 'Enable test_strutils for Python 3\n\ncommon.strutils is compatible with Python 3, and thus test_strutils can\nbe enabled. Also in test_strutils there was implicit  assumption, that\nsys.stdin.encoding is either utf-8 or ascii, so symbols such as \\x80 are\nundecodable. If it happens not to be true, tests are failing.\n\nChange-Id: I0e2decd8d4ad58c999b8ecbab2c5e921dc8b1df8\n'}]",0,102143,27755cd417480dc560105408bfc464be9d7f0d80,8,3,1,10777,,,0,"Enable test_strutils for Python 3

common.strutils is compatible with Python 3, and thus test_strutils can
be enabled. Also in test_strutils there was implicit  assumption, that
sys.stdin.encoding is either utf-8 or ascii, so symbols such as \x80 are
undecodable. If it happens not to be true, tests are failing.

Change-Id: I0e2decd8d4ad58c999b8ecbab2c5e921dc8b1df8
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/43/102143/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_strutils.py', 'tox.ini']",2,27755cd417480dc560105408bfc464be9d7f0d80,python3_strutils, tests.unit.test_strutils \,,6,3
openstack%2Ffuel-web~master~Ifea46654335bf9ea91835880fbf9d6c96b8b63e7,openstack/fuel-web,master,Ifea46654335bf9ea91835880fbf9d6c96b8b63e7,Ensure all nested attributes loaded once,MERGED,2014-06-12 13:30:55.000000000,2014-06-24 13:53:09.000000000,2014-06-24 13:53:09.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-06-12 13:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/68b77ff2ec83427f41b4f51f3faf7894d918ad91', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 2, 'created': '2014-06-18 10:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4a80ef0cbcf69fb6df4d2fae0a2ea0b3a22af7d9', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 3, 'created': '2014-06-18 10:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/385d75e6538b9bb3e0fd8bfb00adb4d7d4612d2a', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 4, 'created': '2014-06-18 10:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e5b62653bf12e460913c00fcba5a52a191e27001', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 5, 'created': '2014-06-18 11:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c8eb497517e646cfe8e957503aee39bee4713cd0', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 6, 'created': '2014-06-18 12:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/890efcefa385606aafb3186051bef8697ecce196', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}, {'number': 7, 'created': '2014-06-24 12:07:02.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/objects/base.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/test/unit/test_objects.py', 'nailgun/nailgun/api/v1/handlers/base.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bff8b1bd05168ea65f6738d5e7ce2d7c62d4f480', 'message': 'Ensure all nested attributes loaded once\n\n- subqueryload_all for each nested attributes ensures that\n  attribute is loaded once\n- minor refactoring of get admin_interface logic in\n  network manager to use sql relations instead of queries each time\n- removed yield_per from eagerload methods\n  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per\n- by deafault collection.eager will use joinedload for each provided field\n\nChange-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7\nCloses-Bug: #1328240\n'}]",4,99661,bff8b1bd05168ea65f6738d5e7ce2d7c62d4f480,59,8,7,8907,,,0,"Ensure all nested attributes loaded once

- subqueryload_all for each nested attributes ensures that
  attribute is loaded once
- minor refactoring of get admin_interface logic in
  network manager to use sql relations instead of queries each time
- removed yield_per from eagerload methods
  see: http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.yield_per
- by deafault collection.eager will use joinedload for each provided field

Change-Id: Ifea46654335bf9ea91835880fbf9d6c96b8b63e7
Closes-Bug: #1328240
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/99661/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/objects/base.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py']",4,68b77ff2ec83427f41b4f51f3faf7894d918ad91,99148, return NetworkManager.get_admin_interface(self)," admin_ng = NetworkManager.get_admin_network_group() for interface in self.interfaces: if admin_ng in interface.assigned_networks_list: return interface for interface in self.interfaces: ip_addr = interface.ip_addr if NetworkManager.is_ip_belongs_to_admin_subnet(ip_addr): return interface logger.warning(u'Cannot find admin interface for node ' 'return first interface: ""%s""' % self.full_name) return self.interfaces[0]",30,28
openstack%2Foslo-incubator~master~I1ae7db935f5f7553824960a01f0827317a016d4d,openstack/oslo-incubator,master,I1ae7db935f5f7553824960a01f0827317a016d4d,Updated from global requirements,MERGED,2014-06-24 07:25:32.000000000,2014-06-24 13:52:54.000000000,2014-06-24 13:52:53.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-06-24 07:25:32.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/bc1bc69af33980246ded50b1924e957dbc4c64aa', 'message': 'Updated from global requirements\n\nChange-Id: I1ae7db935f5f7553824960a01f0827317a016d4d\n'}]",0,102131,bc1bc69af33980246ded50b1924e957dbc4c64aa,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1ae7db935f5f7553824960a01f0827317a016d4d
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/31/102131/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,bc1bc69af33980246ded50b1924e957dbc4c64aa,openstack/requirements,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",2,2
openstack%2Foslo-incubator~master~I98eb3ce09035f2fd486bc1a8fdc8cdd94dd9f743,openstack/oslo-incubator,master,I98eb3ce09035f2fd486bc1a8fdc8cdd94dd9f743,Log the function name of looping call,MERGED,2014-06-10 16:35:34.000000000,2014-06-24 13:50:55.000000000,2014-06-24 13:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 6348}, {'_account_id': 6601}, {'_account_id': 8574}]","[{'number': 1, 'created': '2014-06-10 16:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7efa845b777f1a3bd205077384bf1a7d29ea33b3', 'message': 'Log the function name of looping call\n\nLog the function name of looping call. So that it will be easy to\ndistinguish which one is delayed, when several looping calls are running.\nThat will improves the servicability.\n\nChange-Id: I98eb3ce09035f2fd486bc1a8fdc8cdd94dd9f743\n'}, {'number': 2, 'created': '2014-06-24 08:41:19.000000000', 'files': ['openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/bc48099a1698ca76a189e5804eb8939f2872b79b', 'message': 'Log the function name of looping call\n\nLog the function name of looping call. So that it will be easy to\ndistinguish which one is delayed, when several looping calls are running.\nThat will improves the servicability.\n\nChange-Id: I98eb3ce09035f2fd486bc1a8fdc8cdd94dd9f743\n'}]",5,99152,bc48099a1698ca76a189e5804eb8939f2872b79b,15,6,2,8574,,,0,"Log the function name of looping call

Log the function name of looping call. So that it will be easy to
distinguish which one is delayed, when several looping calls are running.
That will improves the servicability.

Change-Id: I98eb3ce09035f2fd486bc1a8fdc8cdd94dd9f743
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/52/99152/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/loopingcall.py'],1,7efa845b777f1a3bd205077384bf1a7d29ea33b3,loopingcall," LOG.warn(_LW('task %(func_name)s run outlasted ' 'interval by %(delay)s sec'), {'func_name': self.f.func_name, 'delay': -delay})", LOG.warn(_LW('task run outlasted interval by %s sec') % -delay),4,2
openstack%2Ffuel-library~master~I75d8e8f2f000f66b676e61b10e586763b69d12b8,openstack/fuel-library,master,I75d8e8f2f000f66b676e61b10e586763b69d12b8,Remove unused versionlock yum plugin from ks,ABANDONED,2014-06-24 12:15:54.000000000,2014-06-24 13:48:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-24 12:15:54.000000000', 'files': ['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/71925453254c9fdca633ab6eff79e68b4371f906', 'message': 'Remove unused versionlock yum plugin from ks\n\nCloses-bug: #1262200\n\nChange-Id: I75d8e8f2f000f66b676e61b10e586763b69d12b8\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,102207,71925453254c9fdca633ab6eff79e68b4371f906,9,6,1,6926,,,0,"Remove unused versionlock yum plugin from ks

Closes-bug: #1262200

Change-Id: I75d8e8f2f000f66b676e61b10e586763b69d12b8
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/07/102207/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'],1,71925453254c9fdca633ab6eff79e68b4371f906,,,yum-plugin-versionlockyum versionlock puppet yum versionlock kernel yum versionlock iproute2,0,4
openstack%2Fpython-glanceclient~master~Ib0c749dedbfcf07303fcddae4512db61b0f3fd78,openstack/python-glanceclient,master,Ib0c749dedbfcf07303fcddae4512db61b0f3fd78,Prepend '/' to the delete url for the v2 client,MERGED,2014-06-23 12:39:37.000000000,2014-06-24 13:21:00.000000000,2014-06-24 13:21:00.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5557}, {'_account_id': 6549}, {'_account_id': 8533}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 12:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b68bf58cd0558e45fd2b0198c8c7d7e269aa0501', 'message': ""Prepend '/' to the delete url for the v2 client\n\nThe missing slash doesn't affect the operation of delete but does\nmean the curl command logged in debug mode has a bad url.\n\nUpdating tests to match.\n\nChange-Id: Ib0c749dedbfcf07303fcddae4512db61b0f3fd78\nCloses-bug: 1327101\n""}, {'number': 2, 'created': '2014-06-23 14:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b7c2f3508dab875a9ed3be088207a68a99ff0dba', 'message': ""Prepend '/' to the delete url for the v2 client\n\n... and update tests to match.\n\nThe missing slash results in a non-absolute DELETE request\nbeing sent to the API.\nE.g.\nDELETE v2/images/62fac489-23b4-4929-87af-2e7236e8542b HTTP/1.1\n\nThis is actually not valid http/1.1 - rfc2616 specifies that the path must\nbe absolute - and this can cause problems if the API server is fronted\nby something else (see #133161).\n\nIt also means that the curl command logged in debug mode has a\nbad url.\nE.g.\ncurl -i -X DELETE ... http://10.0.0.13:9292v2/images/...\n\nChange-Id: Ib0c749dedbfcf07303fcddae4512db61b0f3fd78\nCloses-bug: #1327101\n""}, {'number': 3, 'created': '2014-06-23 14:23:41.000000000', 'files': ['tests/v2/test_images.py', 'glanceclient/v2/images.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/a945b3d448a9eba1851e99c3961516cbb1dd4f86', 'message': ""Prepend '/' to the delete url for the v2 client\n\n... and update tests to match.\n\nThe missing slash results in a non-absolute DELETE request\nbeing sent to the API.\nE.g.\nDELETE v2/images/62fac489-23b4-4929-87af-2e7236e8542b HTTP/1.1\n\nThis is not strictly valid http/1.1 - rfc2616 specifies that the path must\nbe absolute.\nThis doesn't cause a problem for the API server, but this can cause\nproblems if the API server is fronted by something else (see #133161).\n\nIt also means that the curl command logged in debug mode has a\nbad url.\nE.g.\ncurl -i -X DELETE ... http://10.0.0.13:9292v2/images/...\n\nChange-Id: Ib0c749dedbfcf07303fcddae4512db61b0f3fd78\nCloses-bug: #1327101\n""}]",0,101903,a945b3d448a9eba1851e99c3961516cbb1dd4f86,23,8,3,5557,,,0,"Prepend '/' to the delete url for the v2 client

... and update tests to match.

The missing slash results in a non-absolute DELETE request
being sent to the API.
E.g.
DELETE v2/images/62fac489-23b4-4929-87af-2e7236e8542b HTTP/1.1

This is not strictly valid http/1.1 - rfc2616 specifies that the path must
be absolute.
This doesn't cause a problem for the API server, but this can cause
problems if the API server is fronted by something else (see #133161).

It also means that the curl command logged in debug mode has a
bad url.
E.g.
curl -i -X DELETE ... http://10.0.0.13:9292v2/images/...

Change-Id: Ib0c749dedbfcf07303fcddae4512db61b0f3fd78
Closes-bug: #1327101
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/03/101903/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/v2/test_images.py', 'glanceclient/v2/images.py']",2,b68bf58cd0558e45fd2b0198c8c7d7e269aa0501,master," self.http_client.json_request('DELETE', '/v2/images/%s' % image_id)"," self.http_client.json_request('DELETE', 'v2/images/%s' % image_id)",3,3
openstack%2Fcinder-specs~master~I0c8b707d43f4b01a8230dcfa91430f675b85fbf1,openstack/cinder-specs,master,I0c8b707d43f4b01a8230dcfa91430f675b85fbf1,Add spec for i18n-enablement,MERGED,2014-06-02 21:52:58.000000000,2014-06-24 13:16:38.000000000,2014-06-24 13:16:38.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-06-02 21:52:58.000000000', 'files': ['specs/juno/i18n-enablement.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/79f109dbf44174428df09c65ea57323fdef46acc', 'message': 'Add spec for i18n-enablement\n\nThis commit adds the spec proposing the i18n-enablement\nblueprint for the Juno development cycle.\n\nblueprint: i18n-enablement\n\nChange-Id: I0c8b707d43f4b01a8230dcfa91430f675b85fbf1\n'}]",1,97358,79f109dbf44174428df09c65ea57323fdef46acc,11,4,1,7198,,,0,"Add spec for i18n-enablement

This commit adds the spec proposing the i18n-enablement
blueprint for the Juno development cycle.

blueprint: i18n-enablement

Change-Id: I0c8b707d43f4b01a8230dcfa91430f675b85fbf1
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/58/97358/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/i18n-enablement.rst'],1,79f109dbf44174428df09c65ea57323fdef46acc,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== i18n Enablement for Cinder ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/i18n-enablement This BluePrint/Spec proposes completing the enablement of i18n (internationalization) support for Cinder. Internationalization implementation has been an on-going effort in OpenStack during recent releases. During the Icehouse release, much of the support for internationalization was already merged into Cinder. Specifically the update of Oslo's gettextutils (commit 1553a1e78ec262b044ce99b418103c91b7b580f6) completed much of the process. Removal of the use of str() in exceptions and messages was the other major piece of work that was implemented: (commit cbe1d5f5e22e5f792128643e4cdd6afb2ff2b5bf). To finalize this work in Juno we need to enable ""lazy"" translation. Enablement of lazy translation will allow end users to not only have logs produced in multiple languages, but adds the ability for REST API messages to also be returned in the language chosen by the user. This functionality is important to support the use of OpenStack by the international community. Problem description =================== Currently, Cinder does not have the all the code in place to support lazy translation. The code associated with this blueprint will add the appropriate code and enable translation of REST API responses. Proposed change =============== The code for this change will add 'gettextutils.enable_lazy() to each of the binaries in bin. It will also remove the use of gettextutils.install() in each of the binary files. Instead it will add the explicit import of _() in all files that are not already importing the _() function. The need for the change to explicitly import _() is documented in bug https://bugs.launchpad.net/cinder/+bug/1306275 . Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- There is no additional changes to the REST API other than the fact that the change enables the customer to specify the language they wish REST API responses to be returned in using the Accept-Language option. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- Once merged this feature is immediately available to users. Developer impact ---------------- The developer impacts have already been in place for some time. Developers have been using _() around messages that need translation. Implementation ============== Assignee(s) ----------- Primary assignee: <jsbryant@us.ibm.com> (Jungleboyj) Other contributors: <jecarey@us.ibm.com> Work Items ---------- I am planning to implement this as two patches. The first will be the patch to ensure that _() is being explicitly imported. The dependent patch will then set enable_lazy(). Dependencies ============ None. Testing ======= There will be a tempest test added for Cinder that will ensure that lazy translation is working properly. Documentation Impact ==================== None. References ========== None. ",,147,0
openstack%2Ffuel-web~master~I7fc9aac60c6d5e47fac47e99be0ce21b04872955,openstack/fuel-web,master,I7fc9aac60c6d5e47fac47e99be0ce21b04872955,Add hidden service passwords module to fuelmenu,MERGED,2014-06-19 15:59:58.000000000,2014-06-24 13:14:15.000000000,2014-06-24 13:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-06-19 15:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d3589e5bd2a628081afbb0715b9becff42e108d4', 'message': 'Add hidden service passwords module to fuelmenu\n\nThis change includes a number of new features.\n* Hidden modules now work and save correctly.\n* Hidden modules no longer show up in menu.\n* Fuel version yaml parsing fixed.\n* Fuel version yaml path fixed.\n* Added password generator function.\n* Added service passwords hidden module to configure\n  astute, cobbler, mcollective, and postgres credentials.\n* Added simple password generator for save-only feature\n\nblueprint secure-fuel-master-services\n\nChange-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955\n'}, {'number': 2, 'created': '2014-06-20 06:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a5734eef45499dfd353e9455e781e5efdd803ef4', 'message': 'Add hidden service passwords module to fuelmenu\n\nThis change includes a number of new features.\n* Hidden modules now work and save correctly.\n* Hidden modules no longer show up in menu.\n* Fuel version yaml parsing fixed.\n* Fuel version yaml path fixed.\n* Added password generator function.\n* Added service passwords hidden module to configure\n  astute, cobbler, mcollective, and postgres credentials.\n* Added simple password generator for save-only feature\n\nblueprint secure-fuel-master-services\n\nChange-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955\n'}, {'number': 3, 'created': '2014-06-20 10:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/10aa98f5756173dc7b180fb768833b1013768202', 'message': 'Add hidden service passwords module to fuelmenu\n\nThis change includes a number of new features.\n* Hidden modules now work and save correctly.\n* Hidden modules no longer show up in menu.\n* Fuel version yaml parsing fixed.\n* Fuel version yaml path fixed.\n* Added password generator function.\n* Added service passwords hidden module to configure\n  astute, cobbler, mcollective, and postgres credentials.\n* Added simple password generator for save-only feature\n\nblueprint secure-fuel-master-services\nblueprint access-control-master-node\n\nChange-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955\n'}, {'number': 4, 'created': '2014-06-20 10:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5bf443f4625881e9d0a0fdeddc0a0d545dbef267', 'message': 'Add hidden service passwords module to fuelmenu\n\nThis change includes a number of new features.\n* Hidden modules now work and save correctly.\n* Hidden modules no longer show up in menu.\n* Fuel version yaml parsing fixed.\n* Fuel version yaml path fixed.\n* Added password generator function.\n* Added service passwords hidden module to configure\n  astute, cobbler, mcollective, and postgres credentials.\n* Added simple password generator for save-only feature\n\nblueprint secure-fuel-master-services\nblueprint access-control-master-node\n\nChange-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955\n'}, {'number': 5, 'created': '2014-06-20 11:52:14.000000000', 'files': ['fuelmenu/fuelmenu/fuelmenu.py', 'fuelmenu/fuelmenu/modules/servicepws.py', 'fuelmenu/fuelmenu/settings.yaml', 'fuelmenu/fuelmenu/common/pwgen.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/eadb9dea1a19662780dc64a9002b72f56a397b56', 'message': 'Add hidden service passwords module to fuelmenu\n\nThis change includes a number of new features.\n* Hidden modules now work and save correctly.\n* Hidden modules no longer show up in menu.\n* Fuel version yaml parsing fixed.\n* Fuel version yaml path fixed.\n* Added password generator function.\n* Added service passwords hidden module to configure\n  astute, cobbler, mcollective, and postgres credentials.\n* Added simple password generator for save-only feature\n\nblueprint secure-fuel-master-services\nblueprint access-control-master-node\n\nChange-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955\n'}]",4,101240,eadb9dea1a19662780dc64a9002b72f56a397b56,39,6,5,7195,,,0,"Add hidden service passwords module to fuelmenu

This change includes a number of new features.
* Hidden modules now work and save correctly.
* Hidden modules no longer show up in menu.
* Fuel version yaml parsing fixed.
* Fuel version yaml path fixed.
* Added password generator function.
* Added service passwords hidden module to configure
  astute, cobbler, mcollective, and postgres credentials.
* Added simple password generator for save-only feature

blueprint secure-fuel-master-services
blueprint access-control-master-node

Change-Id: I7fc9aac60c6d5e47fac47e99be0ce21b04872955
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/40/101240/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuelmenu/fuelmenu/fuelmenu.py', 'fuelmenu/fuelmenu/common/pwgen.py', 'fuelmenu/fuelmenu/modules/servicepws.py', 'fuelmenu/fuelmenu/settings.yaml']",4,d3589e5bd2a628081afbb0715b9becff42e108d4,bp/secure-fuel-master-services,astute: password: naily user: naily cobbler: password: cobbler user: cobbler mcollective: password: mcollective user: mcollective postgres: nailgun_dbname: nailgun nailgun_user: nailgun nailgun_password: nailgun ostf_dbname: ostf ostf_user: ostf ostf_password: ostf,,246,8
openstack%2Fcinder-specs~master~I734882582cc73be0a10a8571e130a9a797bbd41d,openstack/cinder-specs,master,I734882582cc73be0a10a8571e130a9a797bbd41d,Add blueprint for configurable ssh host key policy,MERGED,2014-06-17 21:38:02.000000000,2014-06-24 13:13:21.000000000,2014-06-24 13:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 11538}]","[{'number': 1, 'created': '2014-06-17 21:38:02.000000000', 'files': ['specs/juno/configurable-ssh-host-key-policy.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/69167c1f5b6396df3dd2ecc92a8a8178acec15dd', 'message': 'Add blueprint for configurable ssh host key policy\n\nThis spec proposes adding a blueprint to make the way that\nssh host keys are handled configurable so that administrators\ncan choose the level of ssh security they have.\n\nChange-Id: I734882582cc73be0a10a8571e130a9a797bbd41d\nblueprint: configurable-ssh-host-key-policy\n'}]",0,100697,69167c1f5b6396df3dd2ecc92a8a8178acec15dd,10,3,1,7198,,,0,"Add blueprint for configurable ssh host key policy

This spec proposes adding a blueprint to make the way that
ssh host keys are handled configurable so that administrators
can choose the level of ssh security they have.

Change-Id: I734882582cc73be0a10a8571e130a9a797bbd41d
blueprint: configurable-ssh-host-key-policy
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/97/100697/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/configurable-ssh-host-key-policy.rst'],1,69167c1f5b6396df3dd2ecc92a8a8178acec15dd,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Configurable SSH Host Key Policies for Cinder ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/configurable-ssh-host-key-policy To address concerns of weak ssh security in Cinder, the way that ssh host keys are handled by Cinder should be configurable, allowing system administrators to choose how secure they wish their SSH connections to be. Problem description =================== During Icehouse testing and development it was discovered that SSHPool in cinder/utils.py was using the paramiko.AutoAddPolicy() option. This meant that changes to the SSH key on the storage back-end would just be accepted with only a warning being printed. This leaves a security weakness as it is possible for a Man-In-the-Middle (MITM) attack to happen between the Cinder Volume host and the back-end storage. If a MITM attack were to happen, the users data could be compromised. In a worst case scenario, users could be tricked into attaching or even booting spoofed volumes containing malicious code. Proposed change =============== The spec and associated blueprint propose making the way that SSH host keys are handled configurable, allowing system administrators to make a conscious decision about the level of security they need on their system. The solution would require two new configuration items as well as a change to the current default behavior. First, there would need to a 'strict_ssh_host_key_policy' configuration option with possible settings of 'false' (default) or 'true'. When this option is set to 'false' it will automatically accept the host key on the first connection and then will throw an exception if the host key changes in the future. This is where the default behavior changes from the current functionality. In the case that 'strict_ssh_host_key_policy' is set to 'true' then a second option 'ssh_host_keys_file' must be configured. When the strict configuration is used it is assumed that the administrator is going to have pre-configured ssh host keys and any deviation from those expected keys will be handled with an exception. Alternatives ------------ Obviously, we could keep the current functionality but this leaves a security weakness. We could also just require that an ssh host key file be specified, but I feel this is undesirable as it is yet another configuration option that users must deal with. The last option would be to make the functionality fully configurable, making it possible to keep the current functionality, where changes in the host key only cause a warning to be reported, in addition to the new configuration options listed above, but I don't feel leaving the security weakness in place is the right approach if we are making this change. We are actually bringing Cinder's handling of ssh keys in line with what users are used to from the command line, which seems like the most sensible approach. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- This change improves security by handling ssh keys in a manner that will help to avoid the possibility of Man-in-the-Middle attacks. Notifications impact -------------------- None Other end user impact --------------------- As mentioned above, this change will make it so that, by default, the user will see a failure connecting to their back-end storage system in the case the ssh keys on that system change. The user will have the ability to set the level of security they wish to enforce on their volume server using the 'strict_ssh_host_key_policy' and also be able to specify the host keys they wish to use with the 'ssh_host_keys_file' option. Performance Impact ------------------ None Other deployer impact --------------------- Deployers that wish to have a more secure ssh implementation will need to set the 'strict_ssh_host_key_policy' and 'ssh_host_keys_file' configuration options. Developer impact ---------------- Drivers that currently use ssh to connect to their back-end storage systems will need to ensure that their drivers are using this approach for securing their ssh keys. Future driver developers will also need to be consistent with this improved security model. Implementation ============== Assignee(s) ----------- Primary assignee: jsbryant (jsbrant@us.ibm.com or jungleboyj on IRC) Work Items ---------- Initial changes to cinder/utils.py to enable this new functionality. Update existing drivers to properly utilize the functionality. Dependencies ============ None Testing ======= Beyond unit tests, I don't know that there is much more testing that can be done unless there is a way, in Tempest, to simulate bad ssh keys being returned. Documentation Impact ==================== Documentation will need to be updated for the configuration options and explanation of how the functionality is designed to work. References ========== Original bug which started this discussion: https://bugs.launchpad.net/cinder/+bug/1320056 Initial fix for utils.py in the community: https://review.openstack.org/#/c/94165/ Weekly Cinder Meeting discussion on this topic: http://eavesdrop.openstack.org/meetings/cinder/2014/cinder.2014-05-28-16.00.log.html#l-104 ",,167,0
openstack%2Fpuppet-neutron~master~Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7,openstack/puppet-neutron,master,Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7,Add multi-region support,MERGED,2014-06-12 23:40:52.000000000,2014-06-24 13:07:26.000000000,2014-06-24 12:35:56.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7822}, {'_account_id': 9500}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-06-12 23:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b8c6f42953e8664d75547f76331491786aeb5515', 'message': ""Add multi-region support\n\nIf only one region is available then the Neutron CLI will just pick the\nonly one available.  However, if more than one is available, then it\nwill error out about ambiguous region.  This patch extends the base\nprovider code to parse out the nova_region_name when it's parsing out\nthe keystone credentials and define the OS_REGION_NAME environment\nvariable when calling neutron, if the nova_region_name variable exists\nin the config file.\n\nChange-Id: Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7\n""}, {'number': 2, 'created': '2014-06-12 23:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/85eeb688e851cf3b3ad94d2f66d728edf562f7e1', 'message': ""Add multi-region support\n\nIf only one region is available then the Neutron CLI will just pick the\nonly one available.  However, if more than one is available, then it\nwill error out about ambiguous region.  This patch extends the base\nprovider code to parse out the nova_region_name when it's parsing out\nthe keystone credentials and define the OS_REGION_NAME environment\nvariable when calling neutron, if the nova_region_name variable exists\nin the config file.\n\nCloses-Bug: #1329552\nChange-Id: Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7\n""}, {'number': 3, 'created': '2014-06-18 21:59:26.000000000', 'files': ['spec/unit/provider/neutron_spec.rb', 'lib/puppet/provider/neutron.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d1235d762b96e36b67180ee06929e36c81efd617', 'message': ""Add multi-region support\n\nIf only one region is available then the Neutron CLI will just pick the\nonly one available.  However, if more than one is available, then it\nwill error out about ambiguous region.  This patch extends the base\nprovider code to parse out the nova_region_name when it's parsing out\nthe keystone credentials and define the OS_REGION_NAME environment\nvariable when calling neutron, if the nova_region_name variable exists\nin the config file.\n\nCloses-Bug: #1329552\nChange-Id: Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7\n""}]",2,99801,d1235d762b96e36b67180ee06929e36c81efd617,22,10,3,10540,,,0,"Add multi-region support

If only one region is available then the Neutron CLI will just pick the
only one available.  However, if more than one is available, then it
will error out about ambiguous region.  This patch extends the base
provider code to parse out the nova_region_name when it's parsing out
the keystone credentials and define the OS_REGION_NAME environment
variable when calling neutron, if the nova_region_name variable exists
in the config file.

Closes-Bug: #1329552
Change-Id: Ic0d59dcb02a11e93e8fad1e0e2ea830fb0dcccc7
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/01/99801/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/neutron_spec.rb', 'lib/puppet/provider/neutron.rb']",2,b8c6f42953e8664d75547f76331491786aeb5515,(detached, creds = Hash[ auth_keys.map \ if conf['DEFAULT'] and !conf['DEFAULT']['nova_region_name'].nil? creds['nova_region_name'] = conf['DEFAULT']['nova_region_name'] end return creds if q.key?('nova_region_name') authenv[:OS_REGION_NAME] = q['nova_region_name'] end, return Hash[ auth_keys.map \,32,1
openstack%2Fmurano~master~If291e842abe2a8a3e53e94300d4e0091a377eb75,openstack/murano,master,If291e842abe2a8a3e53e94300d4e0091a377eb75,fix db-sync execution in Murano setup script,MERGED,2014-06-23 14:01:26.000000000,2014-06-24 12:56:12.000000000,2014-06-24 12:56:12.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7604}, {'_account_id': 7613}, {'_account_id': 7821}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-06-23 14:01:26.000000000', 'files': ['setup.sh'], 'web_link': 'https://opendev.org/openstack/murano/commit/b20c94f389ca5de1b96ea6e3d2e7109a7cb92836', 'message': 'fix db-sync execution in Murano setup script\n\n- fixed db-sync execution in setup script due to command renaming\n\nChange-Id: If291e842abe2a8a3e53e94300d4e0091a377eb75\n'}]",0,101916,b20c94f389ca5de1b96ea6e3d2e7109a7cb92836,15,7,1,7604,,,0,"fix db-sync execution in Murano setup script

- fixed db-sync execution in setup script due to command renaming

Change-Id: If291e842abe2a8a3e53e94300d4e0091a377eb75
",git fetch https://review.opendev.org/openstack/murano refs/changes/16/101916/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.sh'],1,b20c94f389ca5de1b96ea6e3d2e7109a7cb92836,master,"MANAGE_DB_CMD=""murano-db-manage"" su -c ""$MANAGE_DB_CMD --config-file $daemon_conf upgrade"" -s /bin/bash $DAEMON_USER >> $LOGFILE 2>&1 su -c ""$MANAGE_DB_CMD --config-file $daemon_conf upgrade"" -s /bin/bash $DAEMON_USER >> $LOGFILE 2>&1"," su -c ""$SERVICE_EXEC_PATH --config-file $daemon_conf db-sync"" -s /bin/bash $DAEMON_USER >> $LOGFILE 2>&1 su -c ""$SERVICE_EXEC_PATH --config-file $daemon_conf db-sync"" -s /bin/bash $DAEMON_USER >> $LOGFILE 2>&1",3,2
openstack%2Ffuel-library~master~Ib5ffde6c310703cb408574f013db9accdca555af,openstack/fuel-library,master,Ib5ffde6c310703cb408574f013db9accdca555af,Remove unnecessary usage of yum-plugin-versionlock,MERGED,2014-06-24 12:08:52.000000000,2014-06-24 12:49:12.000000000,2014-06-24 12:44:08.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8777}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 12:08:52.000000000', 'files': ['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d204858549ce3e118935fb2a9ed8a907dd197bb5', 'message': 'Remove unnecessary usage of yum-plugin-versionlock\n\nGet rid of yum-plugin-versionlock in centos.ks for slave nodes.\n\nChange-Id: Ib5ffde6c310703cb408574f013db9accdca555af\nCloses-Bug: #1262200\n'}]",0,102203,d204858549ce3e118935fb2a9ed8a907dd197bb5,13,4,1,8935,,,0,"Remove unnecessary usage of yum-plugin-versionlock

Get rid of yum-plugin-versionlock in centos.ks for slave nodes.

Change-Id: Ib5ffde6c310703cb408574f013db9accdca555af
Closes-Bug: #1262200
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/03/102203/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cobbler/templates/kickstart/centos.ks.erb'],1,d204858549ce3e118935fb2a9ed8a907dd197bb5,master,,yum-plugin-versionlockyum versionlock puppet yum versionlock kernel yum versionlock iproute2,0,4
openstack%2Ffuel-main~stable%2F5.0~I4684a5d7d1d18274ab0f97517fd32a5068ec3c2d,openstack/fuel-main,stable/5.0,I4684a5d7d1d18274ab0f97517fd32a5068ec3c2d,Move to 5.0.1 fuel mirrors,MERGED,2014-06-24 10:27:32.000000000,2014-06-24 12:48:48.000000000,2014-06-24 12:48:48.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-06-24 10:27:32.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1a5995ccdbdffccf9225aa41ef81d8c43d77b777', 'message': 'Move to 5.0.1 fuel mirrors\n\nChange-Id: I4684a5d7d1d18274ab0f97517fd32a5068ec3c2d\nRelated-bug: #1333635\n'}]",0,102176,1a5995ccdbdffccf9225aa41ef81d8c43d77b777,12,5,1,8777,,,0,"Move to 5.0.1 fuel mirrors

Change-Id: I4684a5d7d1d18274ab0f97517fd32a5068ec3c2d
Related-bug: #1333635
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/76/102176/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,1a5995ccdbdffccf9225aa41ef81d8c43d77b777,(detached,PRODUCT_VERSION:=5.0.1,PRODUCT_VERSION:=5.0,1,1
openstack%2Fmurano-deployment~master~I6c2b30ca97a8349421ec22732b235bfd229c309f,openstack/murano-deployment,master,I6c2b30ca97a8349421ec22732b235bfd229c309f,added new parameter for engine tests,MERGED,2014-06-20 12:09:14.000000000,2014-06-24 12:39:07.000000000,2014-06-24 12:39:07.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7604}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-06-20 12:09:14.000000000', 'files': ['murano-ci/scripts/murano-engine-with-deployment-tests.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/bcfaa97754d5e037704ade6f3a39bec7957ee5fa', 'message': ""added new parameter for engine tests\n\n- added parameter 'linux_image' to Murano Engine tests config file\n\nChange-Id: I6c2b30ca97a8349421ec22732b235bfd229c309f\n""}]",0,101506,bcfaa97754d5e037704ade6f3a39bec7957ee5fa,13,5,1,7604,,,0,"added new parameter for engine tests

- added parameter 'linux_image' to Murano Engine tests config file

Change-Id: I6c2b30ca97a8349421ec22732b235bfd229c309f
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/06/101506/1 && git format-patch -1 --stdout FETCH_HEAD,['murano-ci/scripts/murano-engine-with-deployment-tests.sh'],1,bcfaa97754d5e037704ade6f3a39bec7957ee5fa,master," iniset 'murano' 'linux_image' ""$LINUX_IMAGE"" ""$tests_config""",,1,0
openstack%2Ffuel-main~stable%2F5.0~I310fd3bd71c6928ec2713febb986067d2b20a5ce,openstack/fuel-main,stable/5.0,I310fd3bd71c6928ec2713febb986067d2b20a5ce,Fix for sahara test,MERGED,2014-06-24 11:22:23.000000000,2014-06-24 12:37:13.000000000,2014-06-24 12:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 11:22:23.000000000', 'files': ['fuelweb_test/tests/test_services.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3b81d3f77fb727a524f75e158c536eb65da094fa', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\nCloses-Bug: #1333124\n(cherry picked from commit 3f5f6352d43c38867a25998bcc7da5d7ff779bd4)\n'}]",0,102186,3b81d3f77fb727a524f75e158c536eb65da094fa,8,3,1,6719,,,0,"Fix for sahara test

Change-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce
Closes-Bug: #1333124
(cherry picked from commit 3f5f6352d43c38867a25998bcc7da5d7ff779bd4)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/86/102186/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_services.py'],1,3b81d3f77fb727a524f75e158c536eb65da094fa,, disk_mb = 0," settings.SERVTEST_SAVANNA_SERVER_URL,",1,1
openstack%2Fsahara-specs~master~Id508f714002a799f138f825aaf711e00e4343f37,openstack/sahara-specs,master,Id508f714002a799f138f825aaf711e00e4343f37,Remove placeholder,MERGED,2014-06-10 11:59:13.000000000,2014-06-24 12:21:50.000000000,2014-06-24 12:21:50.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-06-10 11:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/b247087b872777d93fd373e977397c0cd46b4dea', 'message': 'Remove placeholder\n\nWe have merged specs for juno now, so, could remove placeholder.\n\nChange-Id: Id508f714002a799f138f825aaf711e00e4343f37\n'}, {'number': 2, 'created': '2014-06-10 19:21:12.000000000', 'files': ['specs/juno/placeholder.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/dd25751957c8bb9a7fee9c6c05b72f86c3ea21f4', 'message': 'Remove placeholder\n\nWe have merged specs for juno now, so, could remove placeholder.\n\nChange-Id: Id508f714002a799f138f825aaf711e00e4343f37\n'}]",1,99021,dd25751957c8bb9a7fee9c6c05b72f86c3ea21f4,17,3,2,6786,,,0,"Remove placeholder

We have merged specs for juno now, so, could remove placeholder.

Change-Id: Id508f714002a799f138f825aaf711e00e4343f37
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/21/99021/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/placeholder.rst'],1,b247087b872777d93fd373e977397c0cd46b4dea,,,../template.rst,0,1
openstack%2Frally~master~I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2,openstack/rally,master,I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2,Benchmark to validate a keystone token N times at service endpoint,MERGED,2014-04-21 10:04:47.000000000,2014-06-24 12:19:44.000000000,2014-06-24 12:19:43.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6116}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9089}, {'_account_id': 10165}]","[{'number': 1, 'created': '2014-04-21 10:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f0769396ec6ce88dd62462f4f88aff1d8de5a885', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 2, 'created': '2014-04-24 07:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8b23f5f726d6108403a35042369f7eee65a2b863', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 3, 'created': '2014-04-24 08:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7aa06cf1550ec37d14cab6b9792da0bd47e1d1ad', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 4, 'created': '2014-04-24 13:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c304169b81623c6203c259a39d244ad239e099d6', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 5, 'created': '2014-04-28 05:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d92911f9e0ac5b69fe8b7fcfa79323ae82fd4e6e', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 6, 'created': '2014-05-05 09:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/03cf3cc9b85c542880fca77a98639c2a352bc368', 'message': 'Benchmark to validate a keystone token N times at service endpoint-WIP\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 7, 'created': '2014-05-05 09:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/816b1a23705c015f0be9ad475515eb602f61fafb', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 8, 'created': '2014-05-07 09:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5ad1b085792c88c053edde98f1297c3a103e8489', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 9, 'created': '2014-05-27 02:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fb56fc97ff9dea99d43439c5e5e3ea710c134352', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 10, 'created': '2014-05-27 03:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1e5c29533fb7afe93b81fb5f2571a5b6a198298', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 11, 'created': '2014-05-30 07:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4ccfc18547857788a24bffb8fb87147b3ba4377c', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 12, 'created': '2014-05-30 09:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6f0dfc1fa168e9a7051e95be182284280d83c5c6', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 13, 'created': '2014-06-03 10:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c85b2f296791a957f60939fb6395771121e58f0a', 'message': 'Benchmark to validate a keystone token N times at service endpoint(WIP)\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 14, 'created': '2014-06-04 09:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/909b01a74dfe4f07bd488421fc5bfc2ccfb25365', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 15, 'created': '2014-06-05 06:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/03b8f0ad5237c8867a1ce94ed98ce164a53fcf7e', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 16, 'created': '2014-06-16 10:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7a58f7313e1a5e1c7aca21cd38cd27639e2f6b1e', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 17, 'created': '2014-06-17 08:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/94106b04cf3bbaf190e868f68660334bd1d8dd8a', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 18, 'created': '2014-06-24 08:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/382652d08b78032e281f40faeab07f0c027e908f', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 19, 'created': '2014-06-24 09:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eac366ad3ec16773e72685dc1b948480c0d825d4', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}, {'number': 20, 'created': '2014-06-24 10:43:58.000000000', 'files': ['doc/samples/tasks/authenticate/token_validate_neutron.yaml', 'doc/samples/tasks/authenticate/token_validate_heat.yaml', 'doc/samples/tasks/authenticate/token_validate_cinder.yaml', 'doc/samples/tasks/authenticate/token_validate_heat.json', 'doc/samples/tasks/authenticate/token_validate_nova.json', 'doc/samples/tasks/authenticate/token_validate_glance.yaml', 'tests/benchmark/scenarios/test_authenticate.py', 'rally-scenarios/rally.yaml', 'doc/samples/tasks/authenticate/token_validate_neutron.json', 'doc/samples/tasks/authenticate/token_validate_glance.json', 'doc/samples/tasks/authenticate/token_validate_cinder.json', 'rally/benchmark/scenarios/authenticate/authenticate.py', 'doc/samples/tasks/authenticate/token_validate_nova.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/3bbeeefcdc29fb9db6749680f829006eadea0b8d', 'message': 'Benchmark to validate a keystone token N times at service endpoint\n\nWith PKI, tokens can be validated at the service endpoint. There might\nbe some caching policies which might affect the validation process.\nThis benchmark can be used to check effect of caching related to tokens.\n\nChange-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2\n'}]",62,89326,3bbeeefcdc29fb9db6749680f829006eadea0b8d,129,9,20,9089,,,0,"Benchmark to validate a keystone token N times at service endpoint

With PKI, tokens can be validated at the service endpoint. There might
be some caching policies which might affect the validation process.
This benchmark can be used to check effect of caching related to tokens.

Change-Id: I6277d8514bbdb1e5dca5032f44ac3d5ff9618cc2
",git fetch https://review.opendev.org/openstack/rally refs/changes/26/89326/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/samples/tasks/authenticate/validate.json', 'rally/benchmark/scenarios/authenticate/authenticate.py']",2,f0769396ec6ce88dd62462f4f88aff1d8de5a885,validate,"from rally.benchmark.scenarios import utils as scenario_utils from rally.benchmark import validation as valid from rally import exceptions @base.scenario() @valid.add_validator(valid.required_parameters(['iteration', 'service'])) def validate(self, service, iteration, **kwargs): """"""This benchmark is written to see the effect of token caching at the service endpoint. :param service: service against which we want to validate the token :param iteration: number of times to validate :param **kwargs: other optional parameters """""" if service == ""glance"": for i in range(0, iteration): self.validate_glance() else: raise exceptions.NoSuchScenario(name=service) @scenario_utils.atomic_action_timer('authenticate.validate_glance') def validate_glance(self): """"""Creation of the client does not ensure validation of the token. We have to access an image to make sure token gets validated. By setting limit to 0 we don't list the images """""" gclient = self.clients(""glance"") for image in gclient.images.list(limit=0): print (image.checksum)",,49,0
openstack%2Fsahara-specs~master~I58e2b1ca9e975dcf414525efe187314747c5d90b,openstack/sahara-specs,master,I58e2b1ca9e975dcf414525efe187314747c5d90b,Move the EDP examples from the sahara-extra repo to sahara,MERGED,2014-06-19 17:56:12.000000000,2014-06-24 12:09:39.000000000,2014-06-24 12:09:39.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7555}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-06-19 17:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/3001f22dd271b21af52923015b4cc7ba4daa4f6e', 'message': 'Move the EDP examples from the sahara-extra repo to sahara\n\nMoving the Sahara EDP examples from the sahara-extra repo to\nthe sahara repo accomplishes several things:\n\n* It eliminates code duplication since the examples are actually\n  used in integration tests\n* It removes an element from the sahara-extra repo, thereby moving\n  us closer to retiring that repo and simplifying our repo structure\n* It puts examples where developers are more likely to find it, and\n  makes it simpler to potentially bundle the examples with a Sahara\n  distribution\n\nChange-Id: I58e2b1ca9e975dcf414525efe187314747c5d90b\n'}, {'number': 2, 'created': '2014-06-19 18:02:11.000000000', 'files': ['specs/juno/edp-move-examples.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/fd0f4ca141f74483242e638ac4126959ea5ab57b', 'message': 'Move the EDP examples from the sahara-extra repo to sahara\n\nMoving the Sahara EDP examples from the sahara-extra repo to\nthe sahara repo accomplishes several things:\n\n* It eliminates code duplication since the examples are actually\n  used in integration tests\n* It removes an element from the sahara-extra repo, thereby moving\n  us closer to retiring that repo and simplifying our repo structure\n* It puts examples where developers are more likely to find it, and\n  makes it simpler to potentially bundle the examples with a Sahara\n  distribution\n\nblueprint edp-move-examples\nChange-Id: I58e2b1ca9e975dcf414525efe187314747c5d90b\n'}]",0,101274,fd0f4ca141f74483242e638ac4126959ea5ab57b,19,4,2,8091,,,0,"Move the EDP examples from the sahara-extra repo to sahara

Moving the Sahara EDP examples from the sahara-extra repo to
the sahara repo accomplishes several things:

* It eliminates code duplication since the examples are actually
  used in integration tests
* It removes an element from the sahara-extra repo, thereby moving
  us closer to retiring that repo and simplifying our repo structure
* It puts examples where developers are more likely to find it, and
  makes it simpler to potentially bundle the examples with a Sahara
  distribution

blueprint edp-move-examples
Change-Id: I58e2b1ca9e975dcf414525efe187314747c5d90b
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/74/101274/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/edp-move-examples.rst'],1,3001f22dd271b21af52923015b4cc7ba4daa4f6e,bp/edp-move-examples,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================== Move the EDP examples from the sahara-extra repo to sahara ========================================================== https://blueprints.launchpad.net/sahara/+spec/edp-move-examples Moving the Sahara EDP examples from the sahara-extra repo to the sahara repo accomplishes several things: * It eliminates code duplication since the examples are actually used in integration tests * It removes an element from the sahara-extra repo, thereby moving us closer to retiring that repo and simplifying our repo structure * It puts examples where developers are more likely to find it, and makes it simpler to potentially bundle the examples with a Sahara distribution Problem description =================== The goal is to create one unified set of EDP jobs that can be used to educate users and developers on how to create/run jobs and can also be used as jobs submitted during integration testing. Proposed change =============== Under the sahara root directory, we should create a new directory:: sahara/edp-examples The directory structure should follow a standard pattern (names are not important per se, this is just an illustration):: subdirectory_for_each_example/ README.rst (what it is, how to compile, etc) script_and_jar_files src_for_jars/ how_to_run_from_node_command_line/ (optional) expected_input_and_output/ (optional) hadoop_1_specific_examples/ subdirectory_for_each_example hadoop_2_specific_examples/ subdirectory_for_each_example The integration tests should be modified to pull job files from the sahara/edp-examples directory. Here are some notes on equivalence for the current script and jar files in ``sahara-extra/edp-examples`` against ``sahara/tests/integration/tests/resources``:: pig-job/example.pig == resources/edp-job.pig pig-job/udf.jar == resources/edp-lib.jar wordcount/edp-java.jar == resources/edp-java/edp-java.jar Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- Examples won't be found in the sahara-extra repo any longer. We should perhaps put a README file there that says ""We have moved"" for a release cycle. Deployer impact --------------- None Developer impact ---------------- None Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- None as yet Work Items ---------- The problem has several components: * Move the examples to the sahara repository * Merge any jobs used by the integration tests into the new examples directory to create one comprehensive set * Provide source code and compilation instructions for any examples that currently lack them * Make the integration tests reference the new directory structure * Delineate which, if any, examples work only with specific Hadoop versions. Most examples work on both Hadoop 1 and Hadoop 2 but some do not. Version-specific examples should be in a subdirectory named for the version Dependencies ============ None Testing ======= Testing will be inherent in the integration tests. The change will be deemed successful if the integration tests run successfully after the merging of the EDP examples and the integration test jobs. Documentation Impact ==================== If our current docs reference the EDP examples, those references should change to the new location. If our current docs do not reference the EDP examples, a reference should be added in the developer and/or user guide. References ========== None ",,159,0
openstack%2Ffuel-web~master~I5f6fe92707b551b20c5140dd339b3e402a774ee7,openstack/fuel-web,master,I5f6fe92707b551b20c5140dd339b3e402a774ee7,Improve get_node_networks in network manager,MERGED,2014-06-10 16:25:36.000000000,2014-06-24 11:57:36.000000000,2014-06-24 11:57:36.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-06-10 16:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7182b4d5fc1dadbe4b7f0fc6e91a0fb428dd19d8', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 2, 'created': '2014-06-11 06:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aac403a14f30ce7adc4412937f4410de421c45cc', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 3, 'created': '2014-06-11 12:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0af289326e73e3acae4db0f12b866f6170609c28', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 4, 'created': '2014-06-16 14:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/30199731bc9ffacfc698dab874d7a79562fd4ace', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 5, 'created': '2014-06-18 10:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1d5519601ab4d4a806ceaad7b776441081f593f6', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 6, 'created': '2014-06-18 10:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f05d02b816cffe3041bf16b9c4c29d3de3020c45', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 7, 'created': '2014-06-18 11:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/996c27742e6224b78e297b215967612fcc13d2d1', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}, {'number': 8, 'created': '2014-06-24 09:45:57.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/objects/serializers/node.py', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fe36b9e232cf59fc055a0e2d3bff8eb609ddb3ea', 'message': 'Improve get_node_networks in network manager\n\nget_node_networks method from network manager\ncauses multiple queries to database on single api request\n\nadding ip_addrs relationship allows to eagerload all required\ndata\nviewonly required to prevent races in several fake tasks\n\nChange-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7\nCloses-Bug: #1328200\n'}]",5,99148,fe36b9e232cf59fc055a0e2d3bff8eb609ddb3ea,69,10,8,8907,,,0,"Improve get_node_networks in network manager

get_node_networks method from network manager
causes multiple queries to database on single api request

adding ip_addrs relationship allows to eagerload all required
data
viewonly required to prevent races in several fake tasks

Change-Id: I5f6fe92707b551b20c5140dd339b3e402a774ee7
Closes-Bug: #1328200
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/48/99148/6 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/objects/serializers/node.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/network/manager.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py']",7,7182b4d5fc1dadbe4b7f0fc6e91a0fb428dd19d8,99148," ip_addrs = relationship(""IPAddr"", viewonly=True) return NetworkManager.get_node_networks(self)", return NetworkManager.get_node_networks(self.id),60,217
openstack%2Freviewstats~master~I5f8eefe3f03d60f68715858915330c9065787c9b,openstack/reviewstats,master,I5f8eefe3f03d60f68715858915330c9065787c9b,add neutron-specs,MERGED,2014-06-13 19:25:52.000000000,2014-06-24 11:54:05.000000000,2014-06-24 11:54:05.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 6854}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-06-13 19:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/60755d3e7263577871f1bac77134e3cdebc8f036', 'message': 'add neutron-specs\n\nChange-Id: I5f8eefe3f03d60f68715858915330c9065787c9b\n'}, {'number': 2, 'created': '2014-06-19 23:12:12.000000000', 'files': ['projects/neutron.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/6fc6abfd1fd63d211e2743fa046e240d264d856a', 'message': 'add neutron-specs\n\nChange-Id: I5f8eefe3f03d60f68715858915330c9065787c9b\n'}]",0,100001,6fc6abfd1fd63d211e2743fa046e240d264d856a,23,7,2,2592,,,0,"add neutron-specs

Change-Id: I5f8eefe3f03d60f68715858915330c9065787c9b
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/01/100001/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/neutron.json'],1,60755d3e7263577871f1bac77134e3cdebc8f036,neutron_cleanup,"{""name"": ""neutron"", ""subprojects"": [""openstack/neutron"", ""openstack/python-neutronclient"", ""openstack/netconn-api"", ""openstack/neutron-specs""], ""core-team"": [""arosen"", ""amotoki"", ""armando-migliaccio"", ""carl-baldwin"", ""emagana"", ""garyk"", ""markmcclain"", ""maru"", ""mestery"", ""nati-ueno"", ""obondarev"", ""rkukura"", ""salvatore-orlando"", ""snaiksat""]}","{""name"": ""neutron"", ""subprojects"": [""openstack/neutron"", ""openstack/python-neutronclient"", ""openstack/netconn-api""], ""core-team"": [""arosen"", ""amotoki"", ""armando-migliaccio"", ""carl-baldwin"", ""emagana"", ""garyk"", ""markmcclain"", ""maru"", ""mestery"", ""nati-ueno"", ""obondarev"", ""rkukura"", ""salvatore-orlando"", ""snaiksat""]}",1,1
openstack%2Freviewstats~master~I6652059d14558ad859c3d31c9134ce561d48c924,openstack/reviewstats,master,I6652059d14558ad859c3d31c9134ce561d48c924,Pretty print projects/neutron.json,MERGED,2014-06-19 23:12:12.000000000,2014-06-24 11:52:50.000000000,2014-06-24 11:52:50.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-06-19 23:12:12.000000000', 'files': ['projects/neutron.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/b06ad7266c951327ac889fd8a00bb368c6a16fb2', 'message': 'Pretty print projects/neutron.json\n\nChange-Id: I6652059d14558ad859c3d31c9134ce561d48c924\n'}]",0,101365,b06ad7266c951327ac889fd8a00bb368c6a16fb2,14,5,1,2592,,,0,"Pretty print projects/neutron.json

Change-Id: I6652059d14558ad859c3d31c9134ce561d48c924
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/65/101365/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/neutron.json'],1,b06ad7266c951327ac889fd8a00bb368c6a16fb2,neutron_cleanup,"{ ""name"": ""neutron"", ""subprojects"": [ ""openstack/neutron"", ""openstack/python-neutronclient"", ""openstack/netconn-api"" ], ""core-team"": [ ""arosen"", ""amotoki"", ""armando-migliaccio"", ""carl-baldwin"", ""emagana"", ""garyk"", ""markmcclain"", ""maru"", ""mestery"", ""nati-ueno"", ""obondarev"", ""rkukura"", ""salvatore-orlando"", ""snaiksat"" ] }","{""name"": ""neutron"", ""subprojects"": [""openstack/neutron"", ""openstack/python-neutronclient"", ""openstack/netconn-api""], ""core-team"": [""arosen"", ""amotoki"", ""armando-migliaccio"", ""carl-baldwin"", ""emagana"", ""garyk"", ""markmcclain"", ""maru"", ""mestery"", ""nati-ueno"", ""obondarev"", ""rkukura"", ""salvatore-orlando"", ""snaiksat""]}",24,1
openstack%2Fsolum~master~I27dfabe396ee7dc68a38d0c294c45c1f8696e5dc,openstack/solum,master,I27dfabe396ee7dc68a38d0c294c45c1f8696e5dc,Sync yamlutils with solumclient changes for empty list,MERGED,2014-06-24 09:59:51.000000000,2014-06-24 11:36:40.000000000,2014-06-24 11:36:40.000000000,"[{'_account_id': 3}, {'_account_id': 8334}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-06-24 09:59:51.000000000', 'files': ['solum/tests/common/test_yamlutils.py', 'solum/common/yamlutils.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/21b8fe01de7cd0e6cd932cfffcc1fce77e137a31', 'message': 'Sync yamlutils with solumclient changes for empty list\n\nChange-Id: I27dfabe396ee7dc68a38d0c294c45c1f8696e5dc\n'}]",0,102166,21b8fe01de7cd0e6cd932cfffcc1fce77e137a31,8,3,1,9548,,,0,"Sync yamlutils with solumclient changes for empty list

Change-Id: I27dfabe396ee7dc68a38d0c294c45c1f8696e5dc
",git fetch https://review.opendev.org/openstack/solum refs/changes/66/102166/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/common/test_yamlutils.py', 'solum/common/yamlutils.py']",2,21b8fe01de7cd0e6cd932cfffcc1fce77e137a31,sync-yamlutils," if not isinstance(yml_dict, dict) and not isinstance(yml_dict, list): raise ValueError('The source is not a YAML mapping or list.') if isinstance(yml_dict, dict) and len(yml_dict) < 1:"," if not isinstance(yml_dict, dict): raise ValueError('The source is not a YAML mapping.') if len(yml_dict) < 1:",7,3
openstack%2Ffuel-library~master~I39572b58e60f6e5b3bcf692fd53bffb1dd98db1b,openstack/fuel-library,master,I39572b58e60f6e5b3bcf692fd53bffb1dd98db1b,Adapt synced sysctl module for Fuel,ABANDONED,2014-06-23 16:08:28.000000000,2014-06-24 11:23:34.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-06-23 16:08:28.000000000', 'files': ['deployment/puppet/sysctl/manifests/value.pp', 'deployment/puppet/osnailyfacter/examples/site.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e6c6848b257d8d4d4d8aa37ef19c9a9f61a96943', 'message': ""Adapt synced sysctl module for Fuel\n\nMove 'path' declaration for 'sysctl' call in upper class.\n\nChange-Id: I39572b58e60f6e5b3bcf692fd53bffb1dd98db1b\nImplements: blueprint merge-openstack-puppet-modules\n""}]",0,101942,e6c6848b257d8d4d4d8aa37ef19c9a9f61a96943,9,3,1,11827,,,0,"Adapt synced sysctl module for Fuel

Move 'path' declaration for 'sysctl' call in upper class.

Change-Id: I39572b58e60f6e5b3bcf692fd53bffb1dd98db1b
Implements: blueprint merge-openstack-puppet-modules
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/42/101942/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/sysctl/manifests/value.pp', 'deployment/puppet/osnailyfacter/examples/site.pp']",2,e6c6848b257d8d4d4d8aa37ef19c9a9f61a96943,bp/merge-openstack-puppet-modules,"Exec { path => [""/bin"", ""/sbin"", ""/usr/bin"", ""/usr/sbin""] } ",,2,1
openstack%2Ffuel-main~master~I310fd3bd71c6928ec2713febb986067d2b20a5ce,openstack/fuel-main,master,I310fd3bd71c6928ec2713febb986067d2b20a5ce,Fix for sahara test,MERGED,2014-06-23 07:56:19.000000000,2014-06-24 11:22:23.000000000,2014-06-23 17:26:12.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-06-23 07:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0099537a025fd66462426f64f20040c5c3089b12', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\n'}, {'number': 2, 'created': '2014-06-23 07:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/539b43daed5c5b4c720147a88e64d66714687707', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\n'}, {'number': 3, 'created': '2014-06-23 07:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4746ff8b28dc434f28a66e7e1a090cdabd6596dd', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\n'}, {'number': 4, 'created': '2014-06-23 08:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9e1152daa48afa6d2db79ba1f3818696d41c6e47', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\nCloses-Bug: #1333124\n'}, {'number': 5, 'created': '2014-06-23 15:01:53.000000000', 'files': ['fuelweb_test/tests/test_services.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3f5f6352d43c38867a25998bcc7da5d7ff779bd4', 'message': 'Fix for sahara test\n\nChange-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce\nCloses-Bug: #1333124\n'}]",1,101819,3f5f6352d43c38867a25998bcc7da5d7ff779bd4,35,5,5,8882,,,0,"Fix for sahara test

Change-Id: I310fd3bd71c6928ec2713febb986067d2b20a5ce
Closes-Bug: #1333124
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/19/101819/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_services.py'],1,0099537a025fd66462426f64f20040c5c3089b12,master,"from fuelweb_test.settings import DEPLOYMENT_MODE_HA from fuelweb_test.settings import SERVTEST_SAVANNA_IMAGE_NAME from fuelweb_test.settings import SERVTEST_SAVANNA_IMAGE_META from fuelweb_test.settings import SERVTEST_MURANO_IMAGE from fuelweb_test.settings import SERVTEST_MURANO_IMAGE_MD5 from fuelweb_test.settings import DEPLOYMENT_MODE_SIMPLE from fuelweb_test.settings import OPENSTACK_RELEASE from fuelweb_test.settings import OPENSTACK_RELEASE_REDHAT from fuelweb_test.settings import SERVTEST_SAVANNA_IMAGE from fuelweb_test.settings import SERVTEST_SAVANNA_IMAGE_MD5 from fuelweb_test.settings import SERVTEST_LOCAL_PATH if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: SERVTEST_SAVANNA_IMAGE, SERVTEST_SAVANNA_IMAGE_MD5, SERVTEST_LOCAL_PATH) SERVTEST_LOCAL_PATH, SERVTEST_SAVANNA_IMAGE, SERVTEST_SAVANNA_IMAGE_NAME, SERVTEST_SAVANNA_IMAGE_META) if OPENSTACK_RELEASE == OPENSTACK_RELEASE_REDHAT: SERVTEST_MURANO_IMAGE, SERVTEST_MURANO_IMAGE_MD5, SERVTEST_LOCAL_PATH) SERVTEST_LOCAL_PATH, SERVTEST_MURANO_IMAGE, SERVTEST_MURANO_IMAGE_NAME, SERVTEST_MURANO_IMAGE_META) disk_mb = 0 mode=DEPLOYMENT_MODE_HA, mode=DEPLOYMENT_MODE_HA,","from fuelweb_test import settings if settings.OPENSTACK_RELEASE == settings.OPENSTACK_RELEASE_REDHAT: settings.SERVTEST_SAVANNA_SERVER_URL, settings.SERVTEST_SAVANNA_IMAGE, settings.SERVTEST_SAVANNA_IMAGE_MD5, settings.SERVTEST_LOCAL_PATH) settings.SERVTEST_LOCAL_PATH, settings.SERVTEST_SAVANNA_IMAGE, settings.SERVTEST_SAVANNA_IMAGE_NAME, settings.SERVTEST_SAVANNA_IMAGE_META) if settings.OPENSTACK_RELEASE == settings.OPENSTACK_RELEASE_REDHAT: settings.SERVTEST_MURANO_IMAGE, settings.SERVTEST_MURANO_IMAGE_MD5, settings.SERVTEST_LOCAL_PATH) settings.SERVTEST_LOCAL_PATH, settings.SERVTEST_MURANO_IMAGE, settings.SERVTEST_MURANO_IMAGE_NAME, settings.SERVTEST_MURANO_IMAGE_META) mode=settings.DEPLOYMENT_MODE_HA, mode=settings.DEPLOYMENT_MODE_HA,",30,20
openstack%2Ffuel-web~master~I28f286e30ad3641351a5fcbf109497af83971352,openstack/fuel-web,master,I28f286e30ad3641351a5fcbf109497af83971352,Set basepython for tox virtual environment creation,MERGED,2014-06-19 20:43:12.000000000,2014-06-24 11:15:37.000000000,2014-06-24 11:15:37.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-19 20:43:12.000000000', 'files': ['nailgun/tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f80da67bdaa23b7c5374f0d6ca74f4f0bc0e353f', 'message': 'Set basepython for tox virtual environment creation\n\nChange-Id: I28f286e30ad3641351a5fcbf109497af83971352\nCloses-bug: #1332330\n'}]",0,101318,f80da67bdaa23b7c5374f0d6ca74f4f0bc0e353f,12,3,1,8829,,,0,"Set basepython for tox virtual environment creation

Change-Id: I28f286e30ad3641351a5fcbf109497af83971352
Closes-bug: #1332330
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/18/101318/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/tox.ini'],1,f80da67bdaa23b7c5374f0d6ca74f4f0bc0e353f,bug/1332330,basepython = python,,1,0
openstack%2Fnova~stable%2Ficehouse~I55742203bdd071c7df90902868e46c2020f799bd,openstack/nova,stable/icehouse,I55742203bdd071c7df90902868e46c2020f799bd,Failure during termination should always leave state as error(),MERGED,2014-06-17 09:49:38.000000000,2014-06-24 11:13:32.000000000,2014-06-24 10:01:48.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5803}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-06-17 09:49:38.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2f40191d0efa783ca879338578097548ee8c84c0', 'message': 'Failure during termination should always leave state as error()\n\nCurrently we have a situation where if an instance fails to delete,\ninstead of having its state reverted, like we do in most places we set\nit to error,deleting. This was intentionally done in\nI5fb1bbd56035792f566a6e076edfe7a69df006ef. We also intentionally ignore\nduplicate requests to delete an instance if its already being deleted\n(I2f97f93bd714e0ea3b6d4fa3ac457ab43eed00e1). The combination of these two\nthings means that if an instance fails to delete for some reason a\ntenant is unable to delete that instance.\n\nIt turns out this is really bad because instances in deleting state\ncount against quota, so the tenant slowly looses usable quota.\n\nTo fix this, upon a failed termination set the vm_state to error and\nrevert the task_state. This is a partial revert of\nI55742203bdd071c7df90902868e46c2020f799bd.\n\nChange-Id: I55742203bdd071c7df90902868e46c2020f799bd\nCloses-Bug: #1329559\n(cherry picked from commit f33a25a3c40722644c774395b38fd7a7ed0246e1)\n'}]",0,100469,2f40191d0efa783ca879338578097548ee8c84c0,19,7,1,5803,,,0,"Failure during termination should always leave state as error()

Currently we have a situation where if an instance fails to delete,
instead of having its state reverted, like we do in most places we set
it to error,deleting. This was intentionally done in
I5fb1bbd56035792f566a6e076edfe7a69df006ef. We also intentionally ignore
duplicate requests to delete an instance if its already being deleted
(I2f97f93bd714e0ea3b6d4fa3ac457ab43eed00e1). The combination of these two
things means that if an instance fails to delete for some reason a
tenant is unable to delete that instance.

It turns out this is really bad because instances in deleting state
count against quota, so the tenant slowly looses usable quota.

To fix this, upon a failed termination set the vm_state to error and
revert the task_state. This is a partial revert of
I55742203bdd071c7df90902868e46c2020f799bd.

Change-Id: I55742203bdd071c7df90902868e46c2020f799bd
Closes-Bug: #1329559
(cherry picked from commit f33a25a3c40722644c774395b38fd7a7ed0246e1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/100469/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,2f40191d0efa783ca879338578097548ee8c84c0,," kwargs=None, vm_state=None): if vm_state: self.assertEqual(instance.vm_state, vm_state) (""terminate_instance"", task_states.DELETING, {'bdms': [], 'reservations': []}, vm_states.ERROR),", kwargs=None):,8,1
openstack%2Fpython-novaclient~master~I949aec52660242249b8cba51d77bfdc1acaf31d2,openstack/python-novaclient,master,I949aec52660242249b8cba51d77bfdc1acaf31d2,"Look for all accessible flavors by default, not just public ones",MERGED,2014-06-06 13:36:03.000000000,2014-06-24 11:07:11.000000000,2014-06-24 11:07:11.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4690}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-06 13:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/667954885fa322feb809f0bfe307ec219aefa832', 'message': ""Look for all accessible flavors by default, not just public ones\n\nThe Nova server will restrict unprivileged user accounts to just\npublic images, while allowing administrator accounts access to\nall. The Nova client shouldn't force the flavor name lookup to\nbe restricted to just public images, since that breaks the ability\nto the flavor name when booting an instance\n\nFixes bug #1327212\n\nChange-Id: I949aec52660242249b8cba51d77bfdc1acaf31d2\n""}, {'number': 2, 'created': '2014-06-13 17:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ae2fb3d54153316695af4a2d542bcc7a6ae8319c', 'message': ""Look for all accessible flavors by default, not just public ones\n\nThe Nova server will restrict unprivileged user accounts to just\npublic images, while allowing administrator accounts access to\nall. The Nova client shouldn't force the flavor name lookup to\nbe restricted to just public images, since that breaks the ability\nto the flavor name when booting an instance\n\nFixes bug #1327212\n\nChange-Id: I949aec52660242249b8cba51d77bfdc1acaf31d2\n""}, {'number': 3, 'created': '2014-06-17 14:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/81f68ca075c9010ac2475a66267f81bd55d5c2c9', 'message': ""Look for all accessible flavors by default, not just public ones\n\nThe Nova server will restrict unprivileged user accounts to just\npublic images, while allowing administrator accounts access to\nall. The Nova client shouldn't force the flavor name lookup to\nbe restricted to just public images, since that breaks the ability\nto the flavor name when booting an instance\n\nFixes bug #1327212\n\nChange-Id: I949aec52660242249b8cba51d77bfdc1acaf31d2\n""}, {'number': 4, 'created': '2014-06-19 11:35:51.000000000', 'files': ['novaclient/tests/v1_1/fakes.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/tests/v3/test_shell.py', 'novaclient/v1_1/shell.py', 'novaclient/v3/shell.py', 'novaclient/tests/v3/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/d17253b29a5b7b422538c6496239cf713be627a3', 'message': ""Look for all accessible flavors by default, not just public ones\n\nThe Nova server will restrict unprivileged user accounts to just\npublic images, while allowing administrator accounts access to\nall. The Nova client shouldn't force the flavor name lookup to\nbe restricted to just public images, since that breaks the ability\nto the flavor name when booting an instance\n\nFixes bug #1327212\n\nChange-Id: I949aec52660242249b8cba51d77bfdc1acaf31d2\n""}]",6,98409,d17253b29a5b7b422538c6496239cf713be627a3,39,6,4,1779,,,0,"Look for all accessible flavors by default, not just public ones

The Nova server will restrict unprivileged user accounts to just
public images, while allowing administrator accounts access to
all. The Nova client shouldn't force the flavor name lookup to
be restricted to just public images, since that breaks the ability
to the flavor name when booting an instance

Fixes bug #1327212

Change-Id: I949aec52660242249b8cba51d77bfdc1acaf31d2
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/09/98409/4 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,667954885fa322feb809f0bfe307ec219aefa832,bug/1327212," flavor = _find_flavor(cs, args.flavor) flavor = _find_flavor(cs, args.flavor) return utils.find_resource(cs.flavors, flavor, is_public=None)"," flavor = _find_flavor_for_admin(cs, args.flavor) flavor = _find_flavor_for_admin(cs, args.flavor)def _find_flavor_for_admin(cs, flavor): """"""Get a flavor for administrator by name, ID, or RAM size."""""" try: return utils.find_resource(cs.flavors, flavor, is_public=None) except exceptions.NotFound: return cs.flavors.find(ram=flavor) return utils.find_resource(cs.flavors, flavor)",3,11
openstack%2Ftripleo-incubator~master~Ib01a96c714ca92ce1e2cb748d96381e863fad4b8,openstack/tripleo-incubator,master,Ib01a96c714ca92ce1e2cb748d96381e863fad4b8,Require and set mode 0600 on heat env caches,MERGED,2014-06-18 18:51:50.000000000,2014-06-24 11:00:04.000000000,2014-06-24 11:00:03.000000000,"[{'_account_id': 3}, {'_account_id': 7582}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 11176}]","[{'number': 1, 'created': '2014-06-18 18:51:50.000000000', 'files': ['scripts/devtest_undercloud.sh', 'scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0e70dd21e88bb0c2a449c9bb6fd47c72ebd254fc', 'message': 'Require and set mode 0600 on heat env caches\n\nWe are storing passwords and other secrets in the heat env files. We\nshould both enforce and set these files permissions to mode 0600.\n\nChange-Id: Ib01a96c714ca92ce1e2cb748d96381e863fad4b8\n'}]",0,100994,0e70dd21e88bb0c2a449c9bb6fd47c72ebd254fc,16,5,1,10035,,,0,"Require and set mode 0600 on heat env caches

We are storing passwords and other secrets in the heat env files. We
should both enforce and set these files permissions to mode 0600.

Change-Id: Ib01a96c714ca92ce1e2cb748d96381e863fad4b8
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/94/100994/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_undercloud.sh', 'scripts/devtest_overcloud.sh']",2,0e70dd21e88bb0c2a449c9bb6fd47c72ebd254fc,feature/heat-env-mode-0600,"### --end if [ ""$(stat -c %a ${HEAT_ENV})"" != ""600"" ]; then echo ""Error: Heat environment cache \""${HEAT_ENV}\"" not set to permissions of 0600."" # We should exit 1 so all the users from before the permissions # requirement dont have their HEAT_ENV files ignored in a nearly silent way exit 1 fi ### --includechmod 0600 ""${HEAT_ENV}""",,18,1
openstack%2Ffuel-web~master~I1d292bd771e7f5a097bf84d8ec878085d3e645c9,openstack/fuel-web,master,I1d292bd771e7f5a097bf84d8ec878085d3e645c9,"Revert ""Changed order of calls to register new nodes""",MERGED,2014-06-24 09:55:32.000000000,2014-06-24 10:56:49.000000000,2014-06-24 10:56:48.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11082}]","[{'number': 1, 'created': '2014-06-24 09:55:32.000000000', 'files': ['bin/agent'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/40000f2c11a9f6bf969e5dbc0144d2f0e218f207', 'message': 'Revert ""Changed order of calls to register new nodes""\n\nCloses-bug: #1333629\nThis reverts commit 779afd8882b119f7fc4eb69b3edd3e9efd63b42d.\n\nChange-Id: I1d292bd771e7f5a097bf84d8ec878085d3e645c9\n'}]",1,102164,40000f2c11a9f6bf969e5dbc0144d2f0e218f207,11,5,1,8749,,,0,"Revert ""Changed order of calls to register new nodes""

Closes-bug: #1333629
This reverts commit 779afd8882b119f7fc4eb69b3edd3e9efd63b42d.

Change-Id: I1d292bd771e7f5a097bf84d8ec878085d3e645c9
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/64/102164/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/agent'],1,40000f2c11a9f6bf969e5dbc0144d2f0e218f207,bg/1305017," put_res = agent.put # nailgun returns 'Invalid MAC specified' for unregistered nodes if [404, 400].include? put_res.status post_res = agent.post if post_res.status == 201 new_id = JSON.parse(post_res.body)[0]['id'] else logger.error post_res.body exit 1 elsif put_res.status == 200 new_id = JSON.parse(put_res.body)['id'] logger.error put_res.body"," unless File.exist?('/etc/nailgun_uid') resp_obj = agent.post # We must not log 409 as error, because sometimes file can disappear after # restart of the node, in this case we made post with registered node if resp_obj.status == 409 resp_obj = agent.put resp_obj = agent.put end unless [201, 200].include? resp_obj.status logger.error resp_obj.body new_id = JSON.parse(resp_obj.body)['id']",12,11
openstack%2Fpython-saharaclient~master~I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea,openstack/python-saharaclient,master,I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea,Don't set json content type for non-json data,MERGED,2014-06-03 23:01:08.000000000,2014-06-24 10:38:03.000000000,2014-06-24 10:38:02.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7428}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-03 23:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/c7dbb12c359675ce2cc0882f0b5dd1f7350169c7', 'message': ""Don't set json content type for non-json data\n\nChange-Id: I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea\nCloses-Bug: #1317259\n""}, {'number': 2, 'created': '2014-06-11 18:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/3a8f02b9d319d200ced74985753bb29e7b70f5d6', 'message': ""Don't set json content type for non-json data\n\n+corresponding unit test on http client added\n\nChange-Id: I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea\nCloses-Bug: #1317259\n""}, {'number': 3, 'created': '2014-06-17 12:26:10.000000000', 'files': ['saharaclient/tests/unit/test_httpclient.py', 'saharaclient/api/base.py', 'saharaclient/api/httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/bcecf35d69a4f5d285ed3f69cb0396cd09845def', 'message': ""Don't set json content type for non-json data\n\n+corresponding unit test on http client added\n\nChange-Id: I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea\nCloses-Bug: #1317259\n""}]",0,97642,bcecf35d69a4f5d285ed3f69cb0396cd09845def,67,11,3,8411,,,0,"Don't set json content type for non-json data

+corresponding unit test on http client added

Change-Id: I8f2eacf595f1c73fea91b426b6c3fe6df4ad7bea
Closes-Bug: #1317259
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/42/97642/1 && git format-patch -1 --stdout FETCH_HEAD,"['saharaclient/api/base.py', 'saharaclient/api/httpclient.py']",2,c7dbb12c359675ce2cc0882f0b5dd1f7350169c7,(detached," def post(self, url, body, json=True): headers = {'x-auth-token': self.token} if json: headers['content-type'] = 'application/json' return requests.post(self.base_url + url, body, headers=headers) def put(self, url, body, json=True): headers = {'x-auth-token': self.token} if json: headers['content-type'] = 'application/json' return requests.put(self.base_url + url, body, headers=headers)"," def post(self, url, body): return requests.post(self.base_url + url, body, headers={'x-auth-token': self.token, 'content-type': 'application/json'}) def put(self, url, body): return requests.put(self.base_url + url, body, headers={'x-auth-token': self.token, 'content-type': 'application/json'})",12,10
openstack%2Fsahara~master~Ifbfa53b94dc55f9d9eac04bba8c6d004764d9095,openstack/sahara,master,Ifbfa53b94dc55f9d9eac04bba8c6d004764d9095,Updated from global requirements,MERGED,2014-06-24 07:26:21.000000000,2014-06-24 10:36:26.000000000,2014-06-24 10:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}]","[{'number': 1, 'created': '2014-06-24 07:26:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/68ce0c6f1bd0af6b6408abb60b1bf7155ca6249b', 'message': 'Updated from global requirements\n\nChange-Id: Ifbfa53b94dc55f9d9eac04bba8c6d004764d9095\n'}]",0,102133,68ce0c6f1bd0af6b6408abb60b1bf7155ca6249b,10,4,1,11131,,,0,"Updated from global requirements

Change-Id: Ifbfa53b94dc55f9d9eac04bba8c6d004764d9095
",git fetch https://review.opendev.org/openstack/sahara refs/changes/33/102133/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,68ce0c6f1bd0af6b6408abb60b1bf7155ca6249b,openstack/requirements,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",1,1
openstack%2Fglance~master~I359633af4bb25cf1866b42d6dad3df658995b7bd,openstack/glance,master,I359633af4bb25cf1866b42d6dad3df658995b7bd,Provide explicit image create value for test_image_paginate case,MERGED,2014-02-20 06:09:32.000000000,2014-06-24 10:33:10.000000000,2014-04-17 06:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 1955}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-02-20 06:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a86b4c7c1ac31a2a2299e0d224cbf95dfd9013de', 'message': 'Provide explicit image create value for test_image_paginate case\n\nAssign an explicit created_at datetime value to image db fixtures,\nit be used to fixes race condition in DB driver test_image_paginate\ncase.\n\nCloses-Bug: #1282400\nChange-Id: I359633af4bb25cf1866b42d6dad3df658995b7bd\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-02-20 06:09:32.000000000', 'files': ['glance/tests/functional/db/base.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1c5797d53a53a990cef3d695f0752742fd213840', 'message': 'Provide explicit image create value for test_image_paginate case\n\nAssign an explicit created_at datetime value to image db fixtures,\nit be used to fixes race condition in DB driver test_image_paginate\ncase.\n\nCloses-Bug: #1282400\nChange-Id: I359633af4bb25cf1866b42d6dad3df658995b7bd\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}]",1,74935,1c5797d53a53a990cef3d695f0752742fd213840,31,7,2,6549,,,0,"Provide explicit image create value for test_image_paginate case

Assign an explicit created_at datetime value to image db fixtures,
it be used to fixes race condition in DB driver test_image_paginate
case.

Closes-Bug: #1282400
Change-Id: I359633af4bb25cf1866b42d6dad3df658995b7bd
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>",git fetch https://review.opendev.org/openstack/glance refs/changes/35/74935/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/functional/db/base.py'],1,a86b4c7c1ac31a2a2299e0d224cbf95dfd9013de,," now = timeutils.utcnow() extra_uuids = [(str(uuid.uuid4()), now + datetime.timedelta(seconds=i * 5)) for i in range(2)] extra_images = [build_image_fixture(id=_id, created_at=_dt, updated_at=_dt) for _id, _dt in extra_uuids] self.assertEqual([i[0] for i in extra_uuids], [i['id'] for i in page])"," extra_uuids = [str(uuid.uuid4()) for i in range(2)] extra_images = [build_image_fixture(id=_id) for _id in extra_uuids] self.assertEqual(extra_uuids, [i['id'] for i in page])",9,3
openstack%2Ftempest~master~If037ebd903bd64a6bcf3e925f38709a4d74bf353,openstack/tempest,master,If037ebd903bd64a6bcf3e925f38709a4d74bf353,Bump baremetal power/assoc/unprovision timeouts,MERGED,2014-06-10 22:38:27.000000000,2014-06-24 10:32:35.000000000,2014-06-24 10:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-10 22:38:27.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e42f0922266da74d4c22f5c4e1856f29df791524', 'message': ""Bump baremetal power/assoc/unprovision timeouts\n\nIncreases the default timeouts for baremetal nodes to complete\ncertain state transitions.  This is required so Ironic can gain\nsupport for waiting on external events (eg, neutron port updates)\nat various times during a node's lifecycle.\n\nChange-Id: If037ebd903bd64a6bcf3e925f38709a4d74bf353\n""}]",0,99226,e42f0922266da74d4c22f5c4e1856f29df791524,17,7,1,1420,,,0,"Bump baremetal power/assoc/unprovision timeouts

Increases the default timeouts for baremetal nodes to complete
certain state transitions.  This is required so Ironic can gain
support for waiting on external events (eg, neutron port updates)
at various times during a node's lifecycle.

Change-Id: If037ebd903bd64a6bcf3e925f38709a4d74bf353
",git fetch https://review.opendev.org/openstack/tempest refs/changes/26/99226/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py']",2,e42f0922266da74d4c22f5c4e1856f29df791524,," default=30, default=60, default=60,"," default=10, default=20, default=20,",6,6
openstack%2Fneutron~master~I9f0a5149d24a4c003409728e50376569c97e7325,openstack/neutron,master,I9f0a5149d24a4c003409728e50376569c97e7325,Don't convert numeric protocol values to int,MERGED,2014-06-18 15:26:33.000000000,2014-06-24 10:29:47.000000000,2014-06-24 10:29:46.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 2062}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10652}]","[{'number': 1, 'created': '2014-06-18 15:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9d95fd48991090af682b0345ba6c40935cacd1d', 'message': ""Don't convert numeric protocol values to int\n\nThey are treated as strings everywhere. Converting them to int causes problems\nwhen using postgresql as the database backend because it doesn't automatically\ncast them back to integer.\n\nChange-Id: I9f0a5149d24a4c003409728e50376569c97e7325\nCloses-bug: 1325406\n""}, {'number': 2, 'created': '2014-06-18 17:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2fdd7adeb3271bf6a786840693f466e23d398952', 'message': ""Don't convert numeric protocol values to int\n\nThey are treated as strings everywhere. Converting them to int causes problems\nwhen using postgresql as the database backend because it doesn't automatically\ncast them back to integer.\n\nChange-Id: I9f0a5149d24a4c003409728e50376569c97e7325\nCloses-bug: 1330490\n""}, {'number': 3, 'created': '2014-06-23 09:18:46.000000000', 'files': ['neutron/tests/unit/test_extension_security_group.py', 'neutron/extensions/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3be62f878e8165cf3bce357a00b8a583773f7d3b', 'message': ""Don't convert numeric protocol values to int\n\nThey are treated as strings everywhere. Converting them to int causes problems\nwhen using postgresql as the database backend because it doesn't automatically\ncast them back to integer.\n\nChange-Id: I9f0a5149d24a4c003409728e50376569c97e7325\nCloses-bug: 1330490\n""}]",2,100942,3be62f878e8165cf3bce357a00b8a583773f7d3b,65,21,3,2062,,,0,"Don't convert numeric protocol values to int

They are treated as strings everywhere. Converting them to int causes problems
when using postgresql as the database backend because it doesn't automatically
cast them back to integer.

Change-Id: I9f0a5149d24a4c003409728e50376569c97e7325
Closes-bug: 1330490
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/100942/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/securitygroup.py'],1,d9d95fd48991090af682b0345ba6c40935cacd1d,bug/1330490, return value, return val,1,1
openstack%2Fhorizon~master~I42ddb39cad62b1be0cad81d4758412a981be461e,openstack/horizon,master,I42ddb39cad62b1be0cad81d4758412a981be461e,"Add missing ""load url from future"" in a container template",MERGED,2014-06-23 07:40:11.000000000,2014-06-24 10:15:17.000000000,2014-06-24 10:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 9981}, {'_account_id': 10247}]","[{'number': 1, 'created': '2014-06-23 07:40:11.000000000', 'files': ['openstack_dashboard/dashboards/project/containers/templates/containers/index.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8c711e8f6b80bebe9ad49eb6a718b2aba0e2b11b', 'message': 'Add missing ""load url from future"" in a container template\n\nThe modified template uses new syntax for the URL template tag,\nbut doesn\'t load the new syntax definition, as required by Django.\nThis leads to errors when trying to render that template.\n\nChange-Id: I42ddb39cad62b1be0cad81d4758412a981be461e\nCloses-bug: #1331271\n'}]",0,101815,8c711e8f6b80bebe9ad49eb6a718b2aba0e2b11b,14,7,1,8648,,,0,"Add missing ""load url from future"" in a container template

The modified template uses new syntax for the URL template tag,
but doesn't load the new syntax definition, as required by Django.
This leads to errors when trying to render that template.

Change-Id: I42ddb39cad62b1be0cad81d4758412a981be461e
Closes-bug: #1331271
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/101815/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/containers/templates/containers/index.html'],1,8c711e8f6b80bebe9ad49eb6a718b2aba0e2b11b,bug/1331271,{% load url from future %} ,,2,0
openstack%2Fsolum~master~Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6,openstack/solum,master,Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6,Add an autoscaling heat template for the build-farm,MERGED,2014-06-03 16:00:34.000000000,2014-06-24 10:08:39.000000000,2014-06-24 10:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9113}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-03 16:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/80326b74a891411209cad4e89ddd8a89a2d0e68b', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 2, 'created': '2014-06-05 14:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/44c90e780628b23c1f6b539f56172dc01946d1b1', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 3, 'created': '2014-06-06 14:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5f7958b8d00f76d8c0a6fb30dca683ca530d6d56', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 4, 'created': '2014-06-07 18:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4e54859e485e2866ae7f0fd54cd428d3de383e08', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 5, 'created': '2014-06-10 15:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1615e1bb8e211f9e2e1b834f8ea00a6b1e5a3268', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 6, 'created': '2014-06-12 09:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/fbd07f3d6627de25ffa261f2bd0ed7eb53e743dc', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 7, 'created': '2014-06-18 11:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c3e4927faf4144d36734117b9efb0354586c35ef', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 8, 'created': '2014-06-20 12:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/298b34877cdc21b358f48ff9556a608cd4bd2cb4', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}, {'number': 9, 'created': '2014-06-23 12:50:22.000000000', 'files': ['etc/solum/templates/infra.yaml'], 'web_link': 'https://opendev.org/openstack/solum/commit/0b253405fa11288e9c76787f7f46a9f85e4526b4', 'message': 'Add an autoscaling heat template for the build-farm\n\nPart of blueprint solum-build-farm\nhttps://blueprints.launchpad.net/solum/+spec/solum-build-farm\n\nChange-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6\n'}]",14,97550,0b253405fa11288e9c76787f7f46a9f85e4526b4,59,10,9,9537,,,0,"Add an autoscaling heat template for the build-farm

Part of blueprint solum-build-farm
https://blueprints.launchpad.net/solum/+spec/solum-build-farm

Change-Id: Ib7f924c9cb3e362ef49fdea31f9f8f5315adeab6
",git fetch https://review.opendev.org/openstack/solum refs/changes/50/97550/9 && git format-patch -1 --stdout FETCH_HEAD,['contrib/build-farm/templates/build-farm.yaml'],1,80326b74a891411209cad4e89ddd8a89a2d0e68b,bp/solum-git-push,"heat_template_version: 2013-05-23 description: > Build farm for Solum. parameters: image: type: string description: glance_id of the build server to start key: type: string description: SSH key to connect to the servers flavor: type: string description: Flavor to use for servers default: m1.small min_size: type: string description: Minimum number of servers that belongs to the farm default: 1 max_size: type: string description: Maximum number of servers that belongs to the farm default: 5 subnet: type: string description: Id of the private sub network for the compute server resources: external_access: type: AWS::EC2::SecurityGroup properties: GroupDescription: Enable access to the application and SSH access SecurityGroupIngress: [ {IpProtocol: tcp, FromPort: ""22"", ToPort: ""22"", CidrIp: ""0.0.0.0/0""}, {IpProtocol: icmp, FromPort: ""-1"", ToPort: ""-1"", CidrIp: ""0.0.0.0/0""}] build_farm_group: type: OS::Heat::AutoScalingGroup properties: min_size: {get_param: min_size} max_size: {get_param: max_size} resource: type: OS::Nova::Server properties: image: {get_param: image} flavor: {get_param: flavor} key_name: {get_param: key} scale_up_policy: type: OS::Heat::ScalingPolicy properties: adjustment_type: change_in_capacity auto_scaling_group_id: {get_resource: build_farm_group} cooldown: 60 scaling_adjustment: 1 scale_down_policy: type: OS::Heat::ScalingPolicy properties: adjustment_type: change_in_capacity auto_scaling_group_id: {get_resource: build_farm_group} cooldown: 60 scaling_adjustment: -1 cpu_alarm_high: type: OS::Ceilometer::Alarm properties: description: Scale-up if the average CPU > 70% for 1 minute meter_name: cpu_util statistic: avg period: 60 evaluation_periods: 1 threshold: 70 alarm_actions: - {get_attr: [scale_up_policy, alarm_url]} matching_metadata: {'metadata.user_metadata.stack': {get_param: ""OS::stack_id""}} comparison_operator: gt cpu_alarm_low: type: OS::Ceilometer::Alarm properties: description: Scale-down if the average CPU < 15% for 10 minutes meter_name: cpu_util statistic: avg period: 600 evaluation_periods: 1 threshold: 15 alarm_actions: - {get_attr: [scale_down_policy, alarm_url]} matching_metadata: {'metadata.user_metadata.stack': {get_param: ""OS::stack_id""}} comparison_operator: lt ",,85,0
openstack%2Fhorizon~master~Ib5e6a917005e99221d34a26154a7edece7efaa82,openstack/horizon,master,Ib5e6a917005e99221d34a26154a7edece7efaa82,Imported Translations from Transifex,MERGED,2014-06-20 06:07:13.000000000,2014-06-24 10:06:26.000000000,2014-06-24 10:06:25.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8090}]","[{'number': 1, 'created': '2014-06-20 06:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/285cbc1bdf4594197f873833f63d1bb203f9f0c4', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82\n'}, {'number': 2, 'created': '2014-06-21 06:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/69ae6145ba9f70ca4d7f45dcf7c0d7f231f4e5de', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82\n'}, {'number': 3, 'created': '2014-06-22 06:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9143b84735b02cc6c592f95ee189377a813f3130', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82\n'}, {'number': 4, 'created': '2014-06-23 06:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/abb24206a27c4dc5801d21ebf4b284ac9a4ac54f', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82\n'}, {'number': 5, 'created': '2014-06-24 06:05:36.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1af0235b7579cedd91258de85552ce5f8d4b1560', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82\n'}]",0,101420,1af0235b7579cedd91258de85552ce5f8d4b1560,24,5,5,11131,,,0,"Imported Translations from Transifex

Change-Id: Ib5e6a917005e99221d34a26154a7edece7efaa82
",git fetch https://review.opendev.org/openstack/horizon refs/changes/20/101420/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,285cbc1bdf4594197f873833f63d1bb203f9f0c4,transifex/translations,"""POT-Creation-Date: 2014-06-19 23:22-0500\n"" ""PO-Revision-Date: 2014-06-20 02:29+0000\n""#: api/swift.py:200 dashboards/project/containers/tables.py:115#: dashboards/admin/aggregates/tables.py:99#: dashboards/project/volumes/volumes/tables.py:248 #: dashboards/project/volumes/volumes/tables.py:277#: dashboards/admin/aggregates/tables.py:26 #: dashboards/admin/aggregates/tables.py:113#: dashboards/admin/aggregates/tables.py:25#: dashboards/admin/aggregates/tables.py:34#: dashboards/admin/aggregates/tables.py:41#: dashboards/admin/aggregates/tables.py:48#: dashboards/admin/aggregates/tables.py:93#: dashboards/admin/aggregates/tables.py:93#: dashboards/admin/aggregates/tables.py:101#: dashboards/project/volumes/volumes/tables.py:285#: dashboards/admin/aggregates/tables.py:103 #: dashboards/admin/aggregates/tables.py:126#: dashboards/admin/aggregates/tables.py:107#: dashboards/admin/aggregates/tables.py:124#: dashboards/admin/aggregates/tables.py:130#: dashboards/admin/aggregates/tables.py:139#: dashboards/project/volumes/volumes/tables.py:251#: dashboards/project/containers/tables.py:306#: dashboards/project/volumes/volumes/tables.py:280#: dashboards/admin/hypervisors/tables.py:70#: dashboards/admin/hypervisors/tables.py:73#: dashboards/admin/hypervisors/tables.py:80#: dashboards/project/volumes/volumes/tables.py:258#: dashboards/project/volumes/volumes/tables.py:296 #: dashboards/project/volumes/volumes/tables.py:309#: dashboards/project/volumes/volumes/tables.py:334#: dashboards/project/containers/tables.py:421#: dashboards/project/volumes/volumes/tables.py:254#: dashboards/project/containers/tables.py:252#: dashboards/project/containers/tables.py:418#: dashboards/project/stacks/forms.py:56#: dashboards/project/containers/tables.py:263#: dashboards/project/containers/tables.py:293#: dashboards/project/containers/tables.py:120 msgid ""Unable to delete container."" msgstr """" #: dashboards/project/containers/tables.py:137#: dashboards/project/containers/tables.py:144#: dashboards/project/containers/tables.py:156#: dashboards/project/containers/tables.py:184#: dashboards/project/containers/tables.py:254#: dashboards/project/containers/tables.py:319#: dashboards/project/containers/tables.py:320 #: dashboards/project/containers/tables.py:425#: dashboards/project/containers/tables.py:342#: dashboards/project/containers/tables.py:355#: dashboards/project/containers/tables.py:403#: dashboards/project/databases/workflows/create_instance.py:167#: dashboards/project/instances/console.py:61#: dashboards/project/volumes/volumes/tables.py:283#: dashboards/project/volumes/volumes/tables.py:308#: dashboards/project/stacks/forms.py:58#: dashboards/project/stacks/forms.py:50#: dashboards/project/stacks/forms.py:51#: dashboards/project/stacks/forms.py:57#: dashboards/project/stacks/forms.py:60#: dashboards/project/stacks/forms.py:67 dashboards/project/stacks/forms.py:69#: dashboards/project/stacks/forms.py:70#: dashboards/project/stacks/forms.py:77 dashboards/project/stacks/forms.py:79#: dashboards/project/stacks/forms.py:80#: dashboards/project/stacks/forms.py:87 dashboards/project/stacks/forms.py:89#: dashboards/project/stacks/forms.py:90#: dashboards/project/stacks/forms.py:96#: dashboards/project/stacks/forms.py:106#: dashboards/project/stacks/forms.py:107#: dashboards/project/stacks/forms.py:116#: dashboards/project/stacks/forms.py:117#: dashboards/project/stacks/forms.py:129#: dashboards/project/stacks/forms.py:131#: dashboards/project/stacks/forms.py:186#: dashboards/project/stacks/forms.py:194#: dashboards/project/stacks/forms.py:201#: dashboards/project/stacks/forms.py:226#: dashboards/project/stacks/forms.py:227#: dashboards/project/stacks/forms.py:229 #: dashboards/project/stacks/forms.py:363#: dashboards/project/stacks/forms.py:232 #: dashboards/project/stacks/forms.py:259 #: dashboards/project/stacks/forms.py:366#: dashboards/project/stacks/forms.py:243#: dashboards/project/stacks/forms.py:260#: dashboards/project/stacks/forms.py:262#: dashboards/project/stacks/forms.py:268#: dashboards/project/stacks/forms.py:269#: dashboards/project/stacks/forms.py:272#: dashboards/project/stacks/forms.py:273#: dashboards/project/stacks/forms.py:286#: dashboards/project/stacks/forms.py:287#: dashboards/project/stacks/forms.py:352#: dashboards/project/stacks/forms.py:361#: dashboards/project/stacks/forms.py:397#: dashboards/project/volumes/volumes/tables.py:355#: dashboards/project/volumes/volumes/forms.py:497 msgid ""Current Size (GB)"" msgstr """" #: dashboards/project/volumes/volumes/forms.py:501 msgid ""New Size (GB)"" msgstr """" #: dashboards/project/volumes/volumes/forms.py:508 msgid ""New size must be greater than current size."" msgstr """" #: dashboards/project/volumes/volumes/forms.py:519msgid ""Extending volume: \""%s\"""" msgstr """" #: dashboards/project/volumes/volumes/forms.py:525#: dashboards/project/volumes/volumes/tables.py:287#: dashboards/project/volumes/volumes/tables.py:290#: dashboards/project/volumes/volumes/tables.py:306#: dashboards/project/volumes/volumes/tables.py:307#: dashboards/project/volumes/volumes/tables.py:336#: dashboards/project/volumes/volumes/tables.py:345","""POT-Creation-Date: 2014-06-18 11:14-0500\n"" ""PO-Revision-Date: 2014-06-18 18:51+0000\n""#: api/swift.py:200#: dashboards/admin/aggregates/tables.py:97#: dashboards/project/volumes/volumes/tables.py:247 #: dashboards/project/volumes/volumes/tables.py:276#: dashboards/admin/aggregates/tables.py:24 #: dashboards/admin/aggregates/tables.py:111#: dashboards/admin/aggregates/tables.py:23#: dashboards/admin/aggregates/tables.py:32#: dashboards/admin/aggregates/tables.py:39#: dashboards/admin/aggregates/tables.py:46#: dashboards/admin/aggregates/tables.py:91#: dashboards/admin/aggregates/tables.py:91#: dashboards/admin/aggregates/tables.py:99#: dashboards/project/volumes/volumes/tables.py:284#: dashboards/admin/aggregates/tables.py:101 #: dashboards/admin/aggregates/tables.py:124#: dashboards/admin/aggregates/tables.py:105#: dashboards/admin/aggregates/tables.py:122#: dashboards/admin/aggregates/tables.py:128#: dashboards/admin/aggregates/tables.py:137#: dashboards/project/volumes/volumes/tables.py:250#: dashboards/project/containers/tables.py:297#: dashboards/project/volumes/volumes/tables.py:279#: dashboards/admin/hypervisors/tables.py:69#: dashboards/admin/hypervisors/tables.py:72#: dashboards/admin/hypervisors/tables.py:79#: dashboards/project/volumes/volumes/tables.py:257#: dashboards/project/volumes/volumes/tables.py:295 #: dashboards/project/volumes/volumes/tables.py:308#: dashboards/project/volumes/volumes/tables.py:333#: dashboards/project/containers/tables.py:412#: dashboards/project/volumes/volumes/tables.py:253#: dashboards/project/containers/tables.py:243#: dashboards/project/containers/tables.py:409#: dashboards/project/stacks/forms.py:54#: dashboards/project/containers/tables.py:254#: dashboards/project/containers/tables.py:284#: dashboards/project/containers/tables.py:128#: dashboards/project/containers/tables.py:135#: dashboards/project/containers/tables.py:147#: dashboards/project/containers/tables.py:175#: dashboards/project/containers/tables.py:245#: dashboards/project/containers/tables.py:310#: dashboards/project/containers/tables.py:311 #: dashboards/project/containers/tables.py:416#: dashboards/project/containers/tables.py:333#: dashboards/project/containers/tables.py:346#: dashboards/project/containers/tables.py:394#: dashboards/project/databases/workflows/create_instance.py:160#: dashboards/project/instances/console.py:62#: dashboards/project/volumes/volumes/tables.py:282#: dashboards/project/volumes/volumes/tables.py:307#: dashboards/project/stacks/forms.py:56#: dashboards/project/stacks/forms.py:48#: dashboards/project/stacks/forms.py:49#: dashboards/project/stacks/forms.py:55#: dashboards/project/stacks/forms.py:58#: dashboards/project/stacks/forms.py:65 dashboards/project/stacks/forms.py:67#: dashboards/project/stacks/forms.py:68#: dashboards/project/stacks/forms.py:75 dashboards/project/stacks/forms.py:77#: dashboards/project/stacks/forms.py:78#: dashboards/project/stacks/forms.py:85 dashboards/project/stacks/forms.py:87#: dashboards/project/stacks/forms.py:88#: dashboards/project/stacks/forms.py:94#: dashboards/project/stacks/forms.py:102#: dashboards/project/stacks/forms.py:105#: dashboards/project/stacks/forms.py:112#: dashboards/project/stacks/forms.py:115#: dashboards/project/stacks/forms.py:127#: dashboards/project/stacks/forms.py:129#: dashboards/project/stacks/forms.py:184#: dashboards/project/stacks/forms.py:192#: dashboards/project/stacks/forms.py:199#: dashboards/project/stacks/forms.py:224#: dashboards/project/stacks/forms.py:225#: dashboards/project/stacks/forms.py:227 #: dashboards/project/stacks/forms.py:361#: dashboards/project/stacks/forms.py:230 #: dashboards/project/stacks/forms.py:257 #: dashboards/project/stacks/forms.py:364#: dashboards/project/stacks/forms.py:241#: dashboards/project/stacks/forms.py:258#: dashboards/project/stacks/forms.py:260#: dashboards/project/stacks/forms.py:266#: dashboards/project/stacks/forms.py:267#: dashboards/project/stacks/forms.py:270#: dashboards/project/stacks/forms.py:271#: dashboards/project/stacks/forms.py:284#: dashboards/project/stacks/forms.py:285#: dashboards/project/stacks/forms.py:350#: dashboards/project/stacks/forms.py:359#: dashboards/project/stacks/forms.py:395#: dashboards/project/volumes/volumes/tables.py:354#: dashboards/project/volumes/volumes/forms.py:497#: dashboards/project/volumes/volumes/forms.py:504 msgid ""New size for extend must be greater than current size."" msgstr ""New size for extend must be greater than current size."" #: dashboards/project/volumes/volumes/forms.py:515msgid ""Successfully extended volume: \""%s\"""" msgstr ""Successfully extended volume: \""%s\"""" #: dashboards/project/volumes/volumes/forms.py:521#: dashboards/project/volumes/volumes/tables.py:286#: dashboards/project/volumes/volumes/tables.py:289#: dashboards/project/volumes/volumes/tables.py:305#: dashboards/project/volumes/volumes/tables.py:306#: dashboards/project/volumes/volumes/tables.py:335#: dashboards/project/volumes/volumes/tables.py:344",2036,1849
openstack%2Fsolum~master~I4cfd4ea3017d8126f0ef91b999a1e2499cbf016a,openstack/solum,master,I4cfd4ea3017d8126f0ef91b999a1e2499cbf016a,Updated from global requirements,MERGED,2014-06-24 07:27:02.000000000,2014-06-24 09:51:47.000000000,2014-06-24 09:51:47.000000000,"[{'_account_id': 3}, {'_account_id': 8334}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-06-24 07:27:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/solum/commit/df359f7a6e3163da129b98f6027d423b743152f2', 'message': 'Updated from global requirements\n\nChange-Id: I4cfd4ea3017d8126f0ef91b999a1e2499cbf016a\n'}]",0,102136,df359f7a6e3163da129b98f6027d423b743152f2,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4cfd4ea3017d8126f0ef91b999a1e2499cbf016a
",git fetch https://review.opendev.org/openstack/solum refs/changes/36/102136/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,df359f7a6e3163da129b98f6027d423b743152f2,openstack/requirements,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",1,1
openstack%2Ftelemetry-specs~master~I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058,openstack/telemetry-specs,master,I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058,spec for grenade ceilometer resource survivability,MERGED,2014-06-17 14:55:53.000000000,2014-06-24 09:51:33.000000000,2014-06-24 09:51:33.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2750}, {'_account_id': 9562}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-17 14:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/2d464c731517953e54316c9eafa505cfec792606', 'message': 'spec for grenade ceilometer resource survivability\n\nThis spec describes planned work to added ceilometer to javelin2\ntests in Grenade.\n\nChange-Id: I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058\n'}, {'number': 2, 'created': '2014-06-17 16:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/4c8af8e2641a8d29e950da616e37e08406cca452', 'message': 'spec for grenade ceilometer resource survivability\n\nThis spec describes planned work to added ceilometer to javelin2\ntests in Grenade.\n\nChange-Id: I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058\n'}, {'number': 3, 'created': '2014-06-19 12:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/47bf9c6998c26c7817458e596e784318e2e562b2', 'message': 'spec for grenade ceilometer resource survivability\n\nThis spec describes planned work to added ceilometer to javelin2\ntests in Grenade.\n\nChange-Id: I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058\n'}, {'number': 4, 'created': '2014-06-23 15:02:17.000000000', 'files': ['specs/juno/grenade-resource-survivability.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/af508f31ef1d066845dc5405c11c859c112b076f', 'message': 'spec for grenade ceilometer resource survivability\n\nThis spec describes planned work to added ceilometer to javelin2\ntests in Grenade.\n\nChange-Id: I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058\n'}]",16,100575,af508f31ef1d066845dc5405c11c859c112b076f,30,5,4,11564,,,0,"spec for grenade ceilometer resource survivability

This spec describes planned work to added ceilometer to javelin2
tests in Grenade.

Change-Id: I2473a87f23ce7e53ef22a4cad3e2cc5f7c51d058
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/75/100575/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/grenade-resource-survivability.rst'],1,2d464c731517953e54316c9eafa505cfec792606,grenade-resource-survivability," .. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== Grenade Resource Survivability ============================== https://blueprints.launchpad.net/ceilometer/+spec/grenade-upgrade-testing Integrated projects are required to participate in the `Grenade`_ upgrade testing harness. In addition to testing the upgrades themselves Grenade has facilities, called javelin, for testing survivability of resources through the upgrade process. Ceilometer needs to participate in this testing. .. _grenade: https://github.com/openstack-dev/grenade Problem description =================== To be certain that Ceilometer is robust across an upgrade it must be possible to process metrics and events from resources that exist before and after the upgrade. Grenade provides a feature named javelin which is designed to allow assertions that confirm resource A, present prior to the upgrade, is present after the upgrade. In the Juno cycle Grenade is being updated to `support javelin2`_ which, unlike the original javelin, should work well and has a declarative syntax for making assertions. A `previous spec`_ describes adding basic Ceilometer support to Grenade. This spec is specifically about adding testing via javelin2. .. _support javelin2: https://review.openstack.org/#/c/96445/ .. _previous spec: https://github.com/openstack/ceilometer-specs/blob/master/specs/juno/grenade-upgrade-testing.rst Proposed change =============== Add support for Ceilometer resource checking to javelin2. This involves two types of changes (detailed below): Adding support for Ceilometer resources in the `javelin code`_ and adding Ceilometer specific entries to the resource definitions. It is important to note that at this time javelin2 does not maintain dynamic state between runs. The ``resources.yaml`` file is the authority for what is expected to exist. If it is important to validate continuity of metrics (beyond mere existence of metrics) some form of state handling will need to be devised. .. _javelin code: https://github.com/openstack/tempest/blob/master/tempest/cmd/javelin.py Alternatives ------------ It may be that Ceilometer resources (i.e. metrics and events) do not map well to the resource model in use in javelin2. If this is the case then it might make to architect some other kind of before and after upgrade test specifically for Ceilometer. Doing so would be a shame, though. Better to make javelin2 more flexible. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Pipeline impact --------------- None. Other end user impact --------------------- None. Performance/Scalability Impacts ------------------------------- While Ceilometer has something of a reputation in this area, because it will already be running in the Grenade environment, no additional impact is expected by adding javelin tests. Other deployer impact --------------------- None. Developer impact ---------------- As Ceilometer features grow or change, adjustments in the javelin2 resource tests may need to be made. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: chdent Other contributors: emilienm Ongoing maintainer: chdent Work Items ---------- * Determine form for javelin2 resources corresponding with Ceilometer entities. Add methods for creating and checking these to ``tempest.cmd.javelin``. * Add representations of Ceilometer resources to ``resources.yaml``. These can (and should?) depend on the servers created elsewhere in the same file. * Explore management of dynamic state pre- and post- upgrade, if necessary. Future lifecycle ================ Ongoing maintenance of the Ceilometer portions of the javelin2 tests will be the responsibility of the Ceilometer project team. Dependencies ============ These changes require `javelin2`_. .. _javelin2: https://blueprints.launchpad.net/tempest/+spec/javelin2 Testing ======= Est quod est. Documentation Impact ==================== None. References ========== * Ceilometer blueprint for `Grenade Upgrade Testing`_. * Javelin 2 `blueprint`_, `spec`_ and `code`_. .. _Grenade Upgrade Testing: https://blueprints.launchpad.net/ceilometer/+spec/grenade-upgrade-testing .. _blueprint: https://blueprints.launchpad.net/tempest/+spec/javelin2 .. _spec: https://review.openstack.org/#/c/96445 .. _code: https://github.com/openstack/tempest/blob/master/tempest/cmd/javelin.py ",,172,0
openstack%2Fhorizon~master~I9ea38d4a4c26acb8b101bb962f9969c69fd7f122,openstack/horizon,master,I9ea38d4a4c26acb8b101bb962f9969c69fd7f122,Updated from global requirements,MERGED,2014-06-17 13:51:53.000000000,2014-06-24 09:50:34.000000000,2014-06-24 09:50:33.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-06-17 13:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/eb4e15d396d98e799fb6a402eacef19affa93e70', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 2, 'created': '2014-06-17 14:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/26c242aeddca849317db4866171717aba9cc7452', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 3, 'created': '2014-06-17 21:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a215f23ec4f3906fd50647e2c828a2f69613481', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 4, 'created': '2014-06-18 00:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7020afef5eb43239deb1791f47e6716c014e464e', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 5, 'created': '2014-06-18 14:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/19d91c9f58c903ff61825abcfa9ed2a7543152a8', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 6, 'created': '2014-06-18 16:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1435c8852e467800f4f0c7aa5cb88727029c6014', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 7, 'created': '2014-06-20 03:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b313e585f56b8d730ad1c85ba4b577bf562296b8', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 8, 'created': '2014-06-20 06:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0101f843b293cf85b84df6cdcfdbb0e22ac35b1', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 9, 'created': '2014-06-23 05:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89d6e56307089187bf5b2b22db51f6cc6ba8ae3b', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}, {'number': 10, 'created': '2014-06-24 07:21:07.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6a2766384fedf496f4e0670d5f4688d9e40be8e7', 'message': 'Updated from global requirements\n\nChange-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122\n'}]",0,100550,6a2766384fedf496f4e0670d5f4688d9e40be8e7,36,5,10,11131,,,0,"Updated from global requirements

Change-Id: I9ea38d4a4c26acb8b101bb962f9969c69fd7f122
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/100550/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,eb4e15d396d98e799fb6a402eacef19affa93e70,openstack/requirements,"hacking>=0.9.2,<0.10sphinx>=1.1.2,!=1.2.0,<1.3","hacking>=0.8.0,<0.9sphinx>=1.1.2,<1.2",5,5
openstack%2Fcinder~master~Ib8462dbbbc33242edbbf02a7c737746d3142d043,openstack/cinder,master,Ib8462dbbbc33242edbbf02a7c737746d3142d043,Remove check_volume_az_zone functor and associated passing,MERGED,2014-06-10 00:05:15.000000000,2014-06-24 09:44:29.000000000,2014-06-24 09:44:29.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-10 00:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7dd19accad5bb66f98d160fb50922c9f41cd4fb4', 'message': 'Remove check_volume_az_zone functor and associated passing\n\nTo make it easier to understand why a volume is being rejected\nwhen its availability zone is not allowed remove the functor\nthat does this check and use the set of valid availability zones\nas the master list of valid zones that can be used (and use this\ninside the task that validates this data).\n\nChange-Id: Ib8462dbbbc33242edbbf02a7c737746d3142d043\n'}, {'number': 2, 'created': '2014-06-23 23:09:18.000000000', 'files': ['cinder/volume/flows/api/create_volume.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a7dc1cda29bb470d3ff8ee00cd8e20ae0f5cc0f', 'message': 'Remove check_volume_az_zone functor and associated passing\n\nTo make it easier to understand why a volume is being rejected\nwhen its availability zone is not allowed remove the functor\nthat does this check and use the set of valid availability zones\nas the master list of valid zones that can be used (and use this\ninside the task that validates this data).\n\nChange-Id: Ib8462dbbbc33242edbbf02a7c737746d3142d043\n'}]",0,98924,6a7dc1cda29bb470d3ff8ee00cd8e20ae0f5cc0f,18,4,2,1297,,,0,"Remove check_volume_az_zone functor and associated passing

To make it easier to understand why a volume is being rejected
when its availability zone is not allowed remove the functor
that does this check and use the set of valid availability zones
as the master list of valid zones that can be used (and use this
inside the task that validates this data).

Change-Id: Ib8462dbbbc33242edbbf02a7c737746d3142d043
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/98924/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/flows/api/create_volume.py', 'cinder/volume/api.py']",2,7dd19accad5bb66f98d160fb50922c9f41cd4fb4,," # Determine the valid availability zones that the volume could be # created in (a task in the flow will/can use this information to # ensure that the availability zone requested is valid). raw_zones = self.list_availability_zones(enable_cache=True) availability_zones = set([az['name'] for az in raw_zones]) if CONF.storage_availability_zone: availability_zones.add(CONF.storage_availability_zone) availability_zones,"," def _valid_availability_zone(self, availability_zone): azs = self.list_availability_zones(enable_cache=True) names = set([az['name'] for az in azs]) if CONF.storage_availability_zone: names.add(CONF.storage_availability_zone) return availability_zone in names def check_volume_az_zone(availability_zone): try: return self._valid_availability_zone(availability_zone) except exception.CinderException: LOG.exception(_(""Unable to query if %s is in the "" ""availability zone set""), availability_zone) return False check_volume_az_zone,",17,28
openstack%2Fhorizon~stable%2Ficehouse~I42808530024bebb01604adbf4828769812856bf3,openstack/horizon,stable/icehouse,I42808530024bebb01604adbf4828769812856bf3,Fix issues with importing the Login form,MERGED,2014-06-23 08:42:40.000000000,2014-06-24 09:41:14.000000000,2014-06-24 09:41:13.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 1955}, {'_account_id': 4128}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6706}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 8344}, {'_account_id': 9981}, {'_account_id': 10242}, {'_account_id': 11885}]","[{'number': 1, 'created': '2014-06-23 08:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/811b0d2f363b5f2b2ce68b868691d22fb3a8ad33', 'message': 'Fix issues with importing the Login form\n\nThe Login form lives in openstack_auth.forms and should be directly\nimported from that file.\n\nChange-Id: I42808530024bebb01604adbf4828769812856bf3\nCloses-Bug: #1332149\n(cherry picked from commit 345ccc9d503e6e55fe46d7813958c0081cc1cffe)\n'}, {'number': 2, 'created': '2014-06-23 17:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5909db18b8b426f160de3707eb1091abaaa6f5e5', 'message': 'Fix issues with importing the Login form\n\nThe Login form lives in openstack_auth.forms and should be directly\nimported from that file.\n\nChange-Id: I42808530024bebb01604adbf4828769812856bf3\nCloses-Bug: #1332149\n'}, {'number': 3, 'created': '2014-06-23 17:18:28.000000000', 'files': ['openstack_dashboard/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/765e6d3c81925c5ed6f6a944eb15e25c6751819f', 'message': 'Fix issues with importing the Login form\n\nThe Login form lives in openstack_auth.forms and should be directly\nimported from that file.\n\nChange-Id: I42808530024bebb01604adbf4828769812856bf3\nCloses-Bug: #1332149\n(cherry picked from commit 345ccc9d503e6e55fe46d7813958c0081cc1cffe)\n'}]",0,101827,765e6d3c81925c5ed6f6a944eb15e25c6751819f,31,15,3,1955,,,0,"Fix issues with importing the Login form

The Login form lives in openstack_auth.forms and should be directly
imported from that file.

Change-Id: I42808530024bebb01604adbf4828769812856bf3
Closes-Bug: #1332149
(cherry picked from commit 345ccc9d503e6e55fe46d7813958c0081cc1cffe)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/101827/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/views.py'],1,811b0d2f363b5f2b2ce68b868691d22fb3a8ad33,fix-bug-1332149,from openstack_auth import forms form = forms.Login(request),from openstack_auth import views form = views.Login(request),2,2
openstack%2Fpython-solumclient~master~Idb2d47b8dd95651c2d7db4dcc6c89f0344b97ccf,openstack/python-solumclient,master,Idb2d47b8dd95651c2d7db4dcc6c89f0344b97ccf,Pass in description during assembly creation,MERGED,2014-06-23 20:55:11.000000000,2014-06-24 09:41:08.000000000,2014-06-24 09:41:07.000000000,"[{'_account_id': 3}, {'_account_id': 8334}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-23 20:55:11.000000000', 'files': ['solumclient/tests/test_solum.py', 'solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/b2c518277677b17be396cb94af5c64a3bbfc3591', 'message': 'Pass in description during assembly creation\n\nChange-Id: Idb2d47b8dd95651c2d7db4dcc6c89f0344b97ccf\nCloses-Bug: #1332313\n'}]",0,102010,b2c518277677b17be396cb94af5c64a3bbfc3591,9,4,1,9095,,,0,"Pass in description during assembly creation

Change-Id: Idb2d47b8dd95651c2d7db4dcc6c89f0344b97ccf
Closes-Bug: #1332313
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/10/102010/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/tests/test_solum.py', 'solumclient/solum.py']",2,b2c518277677b17be396cb94af5c64a3bbfc3591,description," self.parser.add_argument('--description', help=""Assembly description"") description=args.description,",,25,0
openstack%2Fpython-solumclient~master~I987c88f2b4a5c0b464164d75009fa3d6f3452fa9,openstack/python-solumclient,master,I987c88f2b4a5c0b464164d75009fa3d6f3452fa9,Allow an empty yaml list,MERGED,2014-06-24 07:29:38.000000000,2014-06-24 09:39:10.000000000,2014-06-24 09:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 8334}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-24 07:29:38.000000000', 'files': ['solumclient/common/yamlutils.py', 'solumclient/tests/common/test_yamlutils.py', 'solumclient/tests/v1/test_plan.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/69d0eb3320bbc05e7b3d23ef850397379546335e', 'message': 'Allow an empty yaml list\n\nThis allows ""solum app list"" to work with an empty db.\n\nChange-Id: I987c88f2b4a5c0b464164d75009fa3d6f3452fa9\n'}]",0,102137,69d0eb3320bbc05e7b3d23ef850397379546335e,9,4,1,4715,,,0,"Allow an empty yaml list

This allows ""solum app list"" to work with an empty db.

Change-Id: I987c88f2b4a5c0b464164d75009fa3d6f3452fa9
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/37/102137/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/common/yamlutils.py', 'solumclient/tests/common/test_yamlutils.py', 'solumclient/tests/v1/test_plan.py']",3,69d0eb3320bbc05e7b3d23ef850397379546335e,empty_list,"fixtures_list_empty = { '/v1/plans': { 'GET': ( {}, [] ), } } def test_list_empty(self): fake_http_client = fake_client.FakeHTTPClient( fixtures=fixtures_list_empty) api_client = sclient.Client(fake_http_client) mgr = plan.PlanManager(api_client) self.assertEqual([], mgr.list()) ",,23,3
openstack%2Ffuel-web~master~I3a6194383c9d85448b32afeea3dedf807c6069e5,openstack/fuel-web,master,I3a6194383c9d85448b32afeea3dedf807c6069e5,Send json in correct format for nodes/<id>/interfaces,MERGED,2014-06-19 13:00:47.000000000,2014-06-24 09:37:52.000000000,2014-06-24 09:37:52.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-06-19 13:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ff6c2bb32b0084df9626f80a09af38cafa661c92', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}, {'number': 2, 'created': '2014-06-23 15:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/80570c689b519c3297ce0aa132c1ea4085c57715', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}, {'number': 3, 'created': '2014-06-23 19:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/767ab1c7aaaa4346bb86456e1f0ba5f247c33acf', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}, {'number': 4, 'created': '2014-06-23 20:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d83d9f7a60c4c2cf8ea1942e1ad8d68624a21ca4', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}, {'number': 5, 'created': '2014-06-23 20:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7fe22d297e8931b61748dc07bf12a569411b5432', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}, {'number': 6, 'created': '2014-06-24 06:08:59.000000000', 'files': ['fuelclient/fuelclient/objects/node.py', 'fuelclient/tests/base.py', 'fuelclient/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/891f8c8c3d50ac9c675d89f6891d44e2f05896be', 'message': 'Send json in correct format for nodes/<id>/interfaces\n\nFix format for PUT request to nodes/id/interfaces handler\n\nChange-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5\nCloses-Bug: #1331883\n'}]",4,101203,891f8c8c3d50ac9c675d89f6891d44e2f05896be,45,8,6,8907,,,0,"Send json in correct format for nodes/<id>/interfaces

Fix format for PUT request to nodes/id/interfaces handler

Change-Id: I3a6194383c9d85448b32afeea3dedf807c6069e5
Closes-Bug: #1331883
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/03/101203/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/fuelclient/objects/node.py', 'fuelclient/tests/base.py', 'fuelclient/tests/test_client.py']",3,ff6c2bb32b0084df9626f80a09af38cafa661c92,101203," class TestDownloadUploadNodeAttributes(BaseTestCase): def test_upload_download_interfaces(self): cmd = ""node --node-id 1 --network"" self.run_cli_commands((self.download_command(cmd), self.upload_command(cmd))) def test_upload_download_disks(self): cmd = ""node --node-id 1 --disk"" self.run_cli_commands((self.download_command(cmd), self.upload_command(cmd)))","from shutil import rmtree from tempfile import mkdtemp def setUp(self): super(TestFiles, self).setUp() self.temp_directory = mkdtemp() def tearDown(self): rmtree(self.temp_directory) ",24,15
openstack%2Fnova~master~I3332e1bfff8f75c2ba862a2196c7d343530f465f,openstack/nova,master,I3332e1bfff8f75c2ba862a2196c7d343530f465f,Added statement for ... else,MERGED,2014-06-23 10:19:36.000000000,2014-06-24 09:35:11.000000000,2014-06-24 09:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6849}, {'_account_id': 8871}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 10:19:36.000000000', 'files': ['nova/network/security_group/security_group_base.py', 'nova/virt/disk/api.py', 'nova/compute/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d66db815f17217c39522d66dd59e38d122874bc', 'message': 'Added statement for ... else\n\nStatement for ... else was insert where it possible.\n\nChange-Id: I3332e1bfff8f75c2ba862a2196c7d343530f465f\n'}]",0,101849,6d66db815f17217c39522d66dd59e38d122874bc,32,10,1,9569,,,0,"Added statement for ... else

Statement for ... else was insert where it possible.

Change-Id: I3332e1bfff8f75c2ba862a2196c7d343530f465f
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/101849/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/security_group/security_group_base.py', 'nova/compute/api.py', 'nova/virt/disk/api.py', 'nova/db/sqlalchemy/api.py']",4,6d66db815f17217c39522d66dd59e38d122874bc,forelse, else:, found = False found = True if not found:,4,12
openstack%2Fneutron~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/neutron,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-23 23:56:42.000000000,2014-06-24 09:35:00.000000000,2014-06-24 09:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10153}]","[{'number': 1, 'created': '2014-06-23 23:56:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f422f9c00cc82dc052861f2cb5996c6ab3c24479', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102058,f422f9c00cc82dc052861f2cb5996c6ab3c24479,12,5,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/102058/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f422f9c00cc82dc052861f2cb5996c6ab3c24479,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fmurano-deployment~master~Icf3a8347790db7fdf500854b3dc318ba5b58859c,openstack/murano-deployment,master,Icf3a8347790db7fdf500854b3dc318ba5b58859c,Add separate variable for RabbitMQ management port,MERGED,2014-06-23 18:27:38.000000000,2014-06-24 09:33:32.000000000,2014-06-24 09:33:32.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7613}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-06-23 18:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/3a71074eaa46f378b19af2c7b9c784b4cbf3264f', 'message': ""Add separate variable for RabbitMQ management port\n\nRabbitMQ management port differs from older versions to 3.x.\nSo it makes sense to have the separate variable for it, also there's no more\nneed to duplicate RabbitMQ's host at $RABBITMQ_URL variable.\n\nChange-Id: Icf3a8347790db7fdf500854b3dc318ba5b58859c\n""}, {'number': 2, 'created': '2014-06-24 09:09:35.000000000', 'files': ['murano-ci/scripts/murano-dashboard-integration-tests.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/e8288e9968b78acb56c63ed75d5d3e44b1a24af3', 'message': 'Add separate variable for RabbitMQ management port\n\nRabbitMQ management port differs from older versions to 3.x.\nSo it makes sense to have the separate variable for it.\n\nChange-Id: Icf3a8347790db7fdf500854b3dc318ba5b58859c\n'}]",0,101974,e8288e9968b78acb56c63ed75d5d3e44b1a24af3,12,6,2,7604,,,0,"Add separate variable for RabbitMQ management port

RabbitMQ management port differs from older versions to 3.x.
So it makes sense to have the separate variable for it.

Change-Id: Icf3a8347790db7fdf500854b3dc318ba5b58859c
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/74/101974/2 && git format-patch -1 --stdout FETCH_HEAD,"['murano-ci/scripts/murano-dashboard-integration-tests.sh', 'murano-ci/scripts/murano-engine-with-deployment-tests.sh']",2,3a71074eaa46f378b19af2c7b9c784b4cbf3264f,master, $PYTHON_CMD ${CI_ROOT_DIR}/infra/RabbitMQ.py -username murano$BUILD_NUMBER -vhostname murano$BUILD_NUMBER -rabbitmq_url $RABBITMQ_HOST:$RABBITMQ_MGMT_PORT -action create $PYTHON_CMD ${CI_ROOT_DIR}/infra/RabbitMQ.py -username murano$BUILD_NUMBER -vhostname murano$BUILD_NUMBER -rabbitmq_url $RABBITMQ_HOST:$RABBITMQ_MGMT_PORT -action delete, $PYTHON_CMD ${CI_ROOT_DIR}/infra/RabbitMQ.py -username murano$BUILD_NUMBER -vhostname murano$BUILD_NUMBER -rabbitmq_url $RABBITMQ_URL -action create $PYTHON_CMD ${CI_ROOT_DIR}/infra/RabbitMQ.py -username murano$BUILD_NUMBER -vhostname murano$BUILD_NUMBER -rabbitmq_url $RABBITMQ_URL -action delete,4,4
openstack%2Fironic~master~I870724bf48346857b1170463fcc7d22c08aca3bd,openstack/ironic,master,I870724bf48346857b1170463fcc7d22c08aca3bd,Mock pyghmi lib in unit tests if not present,MERGED,2014-05-08 13:00:00.000000000,2014-06-24 09:22:44.000000000,2014-06-24 09:22:43.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 10626}]","[{'number': 1, 'created': '2014-05-08 13:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/35b7043c39925c34e161063ed2e27fd2e4521fc0', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 2, 'created': '2014-05-18 20:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d82f336e70879a5240c88f11d437ae35bf9c290b', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 3, 'created': '2014-06-12 23:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4bd7764037d1f0537c57c201b07f233e36eb596d', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 4, 'created': '2014-06-12 23:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/364251a5d403d09d29a50bbef637f52060774bfa', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 5, 'created': '2014-06-13 15:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd23b1e871fab2827b6ac2b27cd8ff6e2f0219b9', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present. Also\ncorrects pep8 issue in ipminative by grouping the imports.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 6, 'created': '2014-06-13 18:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/01538fc51d02275014aa8ee5186ee1187827eb27', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present. Also\ncorrects pep8 issue in ipminative by grouping the imports.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}, {'number': 7, 'created': '2014-06-23 21:30:50.000000000', 'files': ['requirements.txt', 'ironic/tests/drivers/test_ipminative.py', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ipminative.py', 'ironic/drivers/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2ba774deb6def3ca8bad2131a8dd7ba4f2fac218', 'message': 'Mock pyghmi lib in unit tests if not present\n\nMock the pyghmi library from within ironic/tests/drivers so that\ntest_ipminative.py can import ironic/drivers/ipminative and run the unit\ntests on it, even when the external library is not present. Also\ncorrects pep8 issue in ipminative by grouping the imports.\n\nChange-Id: I870724bf48346857b1170463fcc7d22c08aca3bd\n'}]",6,92819,2ba774deb6def3ca8bad2131a8dd7ba4f2fac218,52,10,7,2889,,,0,"Mock pyghmi lib in unit tests if not present

Mock the pyghmi library from within ironic/tests/drivers so that
test_ipminative.py can import ironic/drivers/ipminative and run the unit
tests on it, even when the external library is not present. Also
corrects pep8 issue in ipminative by grouping the imports.

Change-Id: I870724bf48346857b1170463fcc7d22c08aca3bd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/19/92819/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/test_ipminative.py', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ipminative.py', 'ironic/drivers/pxe.py']",4,35b7043c39925c34e161063ed2e27fd2e4521fc0,removePyghmi," if not importutils.try_import('pyghmi'): raise exception.DriverLoadError( driver=self.__class__.__name__, reason=""Unable to import pyghmi library"")",,34,3
openstack%2Fironic~master~I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9,openstack/ironic,master,I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9,Eliminate races in Conductor _check_deploy_timeouts,MERGED,2014-04-20 06:46:18.000000000,2014-06-24 09:22:37.000000000,2014-06-24 09:22:37.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2889}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-04-20 06:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a525dc77b3edbd09ef0ebe640908cd54b2eec9ee', 'message': ""Re-factor Conductor _check_deploy_timeouts\n\n1) This method is overly indented when 'continue' can be used.\n2) It would be nice to filter on 'provision_state' when grabbing the\n   list of nodes from the DB.\n3) provision_state could have changed by the time we grab the lock and\n   it is not re-checked.\n4) Nodes can be left locked if a node.save() fails or spawning the\nworker or if linking the thread-finished callback fails.\n\nThis patch addresses all of those issues. Tests are also re-factored to\nnot use the DB. Tests are added for all of these missing test cases.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\nCo-Authored-by: Russell Haering <russellhaering@gmail.com>\n""}, {'number': 2, 'created': '2014-04-20 07:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c8dd07cca2d5fccde850ba677ec00ec4e398cb6', 'message': ""Re-factor Conductor _check_deploy_timeouts\n\n1) This method is overly indented when 'continue' can be used.\n2) It would be nice to filter on 'provision_state' when grabbing the\n   list of nodes from the DB.\n3) provision_state could have changed by the time we grab the lock and\n   it is not re-checked.\n4) Nodes can be left locked if a node.save() fails or spawning the\nworker or if linking the thread-finished callback fails.\n\nThis patch addresses all of those issues. Tests are also re-factored to\nnot use the DB. Tests are added for all of these missing test cases.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\nCo-Authored-by: Russell Haering <russellhaering@gmail.com>\n""}, {'number': 3, 'created': '2014-04-20 17:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1bdb96a1ab3b65557f30a8573ab3f7c1e999e394', 'message': ""Re-factor Conductor _check_deploy_timeouts\n\n1) This method is overly indented when 'continue' can be used.\n2) It would be nice to filter on 'provision_state' when grabbing the\n   list of nodes from the DB.\n3) provision_state could have changed by the time we grab the lock and\n   it is not re-checked.\n4) Nodes can be left locked if a node.save() fails or spawning the\nworker or if linking the thread-finished callback fails.\n\nThis patch addresses all of those issues. Tests are also re-factored to\nnot use the DB. Tests are added for all of these missing test cases.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\nCo-Authored-by: Russell Haering <russellhaering@gmail.com>\n""}, {'number': 4, 'created': '2014-04-23 21:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5710d207bd2ca0e440203ce8dc586b671fa4436b', 'message': ""Eliminate races in Conductor _check_deploy_timeouts\n\nRe-check filters after we grab a lock in case things changed.\n\nTests are also re-factored to not use the DB. Tests are added for all\nof these missing test cases.\n\nAlso: 'maintenance' was dropped from the filters in this review:\n\nI646540e334dec05682640c05cedb315e0ee355bc\n\nI don't see any explanation of why it was removed in that patch.\n\nIt seems reasonable that someone could set maintenance on a node that\nis stuck in DEPLOYWAIT. And we would not want to touch it while it is\nin maintenance. So, this patch re-adds it to the filters and makes\nsure to re-check it after having a lock.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\n""}, {'number': 5, 'created': '2014-04-23 22:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3bf24c360946f3bc09b195e12da8294a2db180d6', 'message': ""Eliminate races in Conductor _check_deploy_timeouts\n\nRe-check filters after we grab a lock in case things changed.\n\nTests are also re-factored to not use the DB. Tests are added for all\nof these missing test cases.\n\nAlso: 'maintenance' was dropped from the filters in this review:\n\nI646540e334dec05682640c05cedb315e0ee355bc\n\nI don't see any explanation of why it was removed in that patch.\n\nIt seems reasonable that someone could set maintenance on a node that\nis stuck in DEPLOYWAIT. And we would not want to touch it while it is\nin maintenance. So, this patch re-adds it to the filters and makes\nsure to re-check it after having a lock.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\n""}, {'number': 6, 'created': '2014-06-17 17:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0db4660d549bf1dc6643d5eb64e6ec6289603f28', 'message': ""Eliminate races in Conductor _check_deploy_timeouts\n\nRe-check filters after we grab a lock in case things changed.\n\nTests are also re-factored to not use the DB. Tests are added for all\nof these missing test cases.\n\nAlso: 'maintenance' was dropped from the filters in this review:\n\nI646540e334dec05682640c05cedb315e0ee355bc\n\nI don't see any explanation of why it was removed in that patch.\n\nIt seems reasonable that someone could set maintenance on a node that\nis stuck in DEPLOYWAIT. And we would not want to touch it while it is\nin maintenance. So, this patch re-adds it to the filters and makes\nsure to re-check it after having a lock.\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\n""}, {'number': 7, 'created': '2014-06-21 18:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/133181f84d878b4fda7be8c626c8a8edccf63cd9', 'message': ""Eliminate races in Conductor _check_deploy_timeouts\n\nRe-check filters after we grab a lock in case things changed.\n\nTests are also re-factored to not use the DB. Tests are added for all\nof these missing test cases.\n\nAlso: 'maintenance' was dropped from the filters in this review:\n\nI646540e334dec05682640c05cedb315e0ee355bc\n\nI don't see any explanation of why it was removed in that patch.\n\nIt seems reasonable that someone could set maintenance on a node that\nis stuck in DEPLOYWAIT. And we would not want to touch it while it is\nin maintenance. So, this patch re-adds it to the filters and makes\nsure to re-check it after having a lock.\n\nCloses-Bug: 1332860\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\n""}, {'number': 8, 'created': '2014-06-21 18:17:42.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py', 'ironic/tests/conductor/test_conductor_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/37a9a531f0ea41a88015cc377a9c30e43caa412c', 'message': ""Eliminate races in Conductor _check_deploy_timeouts\n\nRe-check filters after we grab a lock in case things changed.\n\nTests are also re-factored to not use the DB. Tests are added for all\nof these missing test cases.\n\nAlso: 'maintenance' was dropped from the filters in this review:\n\nI646540e334dec05682640c05cedb315e0ee355bc\n\nI don't see any explanation of why it was removed in that patch.\n\nIt seems reasonable that someone could set maintenance on a node that\nis stuck in DEPLOYWAIT. And we would not want to touch it while it is\nin maintenance. So, this patch re-adds it to the filters and makes\nsure to re-check it after having a lock.\n\nAlso: When this was being reviewed, it was caught that\nNoFreeConductorWorker should actually just completely exit the periodic\ntask. That change is included here too while re-factoring this.\n\nCloses-Bug: 1332860\n\nChange-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9\n""}]",12,89223,37a9a531f0ea41a88015cc377a9c30e43caa412c,52,9,8,1030,,,0,"Eliminate races in Conductor _check_deploy_timeouts

Re-check filters after we grab a lock in case things changed.

Tests are also re-factored to not use the DB. Tests are added for all
of these missing test cases.

Also: 'maintenance' was dropped from the filters in this review:

I646540e334dec05682640c05cedb315e0ee355bc

I don't see any explanation of why it was removed in that patch.

It seems reasonable that someone could set maintenance on a node that
is stuck in DEPLOYWAIT. And we would not want to touch it while it is
in maintenance. So, this patch re-adds it to the filters and makes
sure to re-check it after having a lock.

Also: When this was being reviewed, it was caught that
NoFreeConductorWorker should actually just completely exit the periodic
task. That change is included here too while re-factoring this.

Closes-Bug: 1332860

Change-Id: I9e73ca4a1d90bd92bdf83821dae72a30f7b885a9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/23/89223/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py']",2,a525dc77b3edbd09ef0ebe640908cd54b2eec9ee,bug/1332860," filters = {'reserved': False, 'maintenance': False, 'provision_state': states.DEPLOYWAIT} columns = ['uuid', 'driver', 'provision_updated_at'] for (node_uuid, driver, update_time) in node_list: limit = (timeutils.utcnow() - datetime.timedelta( seconds=CONF.conductor.deploy_callback_timeout)) if timeutils.normalize_time(update_time) > limit: continue try: task = task_manager.acquire(context, node_uuid) except (exception.NodeLocked, exception.NodeNotFound): continue thread = None try: node = task.node # NOTE(comstud): Recheck the provision_state now that we # have the lock. We don't need to re-check updated_at unless # we expect the state to have flipped to something else and # then back to DEPLOYWAIT between the call to # get_nodeinfo_list and now. if node.provision_state != states.DEPLOYWAIT: task.release_resources() continue node.provision_state = states.DEPLOYFAIL node.target_provision_state = states.NOSTATE msg = (_('Timeout reached when waiting callback for ' 'node %s') % node_uuid) node.last_error = msg LOG.error(msg) node.save(context) thread = self._spawn_worker(utils.cleanup_after_timeout, task) thread.link(lambda t: task.release_resources()) except exception.NoFreeConductorWorker: task.release_resources() except Exception: with excutils.save_and_reraise_exception(): if thread is not None: # NOTE(comstud): This means that the link() failed # for some reason. Cancel the thread and release # the resources. thread.cancel() task.release_resources()"," filters = {'reserved': False, 'maintenance': False} columns = ['uuid', 'driver', 'provision_state', 'provision_updated_at'] for (node_uuid, driver, state, update_time) in node_list: if state == states.DEPLOYWAIT: limit = (timeutils.utcnow() - datetime.timedelta( seconds=CONF.conductor.deploy_callback_timeout)) if timeutils.normalize_time(update_time) <= limit: try: task = task_manager.TaskManager(context, node_uuid) except (exception.NodeLocked, exception.NodeNotFound): continue node = task.node node.provision_state = states.DEPLOYFAIL node.target_provision_state = states.NOSTATE msg = (_('Timeout reached when waiting callback for ' 'node %s') % node_uuid) node.last_error = msg LOG.error(msg) node.save(task.context) try: thread = self._spawn_worker( utils.cleanup_after_timeout, task) thread.link(lambda t: task.release_resources()) except exception.NoFreeConductorWorker: task.release_resources()",350,101
openstack%2Fironic~master~I53bf2d207b7d15a0673be6a6786c47500b9eb499,openstack/ironic,master,I53bf2d207b7d15a0673be6a6786c47500b9eb499,Add some real-world testing on DiskPartitioner,MERGED,2014-05-21 13:48:01.000000000,2014-06-24 09:22:31.000000000,2014-06-24 09:22:31.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 9315}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-05-21 13:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aab860b0edecefaa500d257633b0330f3a60fe88', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 2, 'created': '2014-05-21 15:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8341cf3f395eb2e2b9c7ff404b1c774617f3c020', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 3, 'created': '2014-05-21 16:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6db64964a9ed11994c249a7bcaa6cc19e6e4185', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 4, 'created': '2014-05-21 16:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/09f2a5b49f48cee9febbbb18c298ad9198bd3e53', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 5, 'created': '2014-05-22 11:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9aa632935416ac8b27d7d5abc3e85574546532e6', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 6, 'created': '2014-05-22 12:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4715b7890372edcc59888a282a752e4e64c21444', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests arecurrently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 7, 'created': '2014-05-27 15:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c4114177840229b82c5c7b27f6878eba7bde7ab', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 8, 'created': '2014-06-16 07:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8604cd402e6cac6d4365055eac924a0ac889ce65', 'message': 'Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n'}, {'number': 9, 'created': '2014-06-16 08:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8ea193119fabc3f0a7a62ed0f7f4cafb9364847b', 'message': ""Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\nAlso these tests do not cover destroy_disk_metadata, as it can't\nbe executed on a file.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n""}, {'number': 10, 'created': '2014-06-19 16:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/97d31b42e770860235d84752d96750a0a1cd036a', 'message': ""Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\nAlso these tests do not cover destroy_disk_metadata, as it can't\nbe executed on a file.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n""}, {'number': 11, 'created': '2014-06-19 18:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/985b672cf286bfdabdb6d944561b72450a9cfb2b', 'message': ""Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\nAlso these tests do not cover destroy_disk_metadata, as it can't\nbe executed on a file.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n""}, {'number': 12, 'created': '2014-06-20 10:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c336438b4907bb2a0b5b864ee9255fc98b9999d7', 'message': ""Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\nAlso these tests do not cover destroy_disk_metadata, as it can't\nbe executed on a file.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n""}, {'number': 13, 'created': '2014-06-23 09:37:27.000000000', 'files': ['ironic/tests/test_disk_partitioner.py', 'ironic/common/disk_partitioner.py', 'ironic/tests/drivers/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc7dfcc543d2517746c66927536ef78846f45b26', 'message': ""Add some real-world testing on DiskPartitioner\n\nThis patch adds some integration tests for DiskPartitioner by using\nit on a temporary file. As a side effect, this patch adds\ndisk_partitioner.list_partitions() helper, which is used by the test,\nbut can by used for anything else later.\n\nThe new tests are currently skipped on gate-ironic-python26, as\nthere is no `parted` utility there.\nAlso these tests do not cover destroy_disk_metadata, as it can't\nbe executed on a file.\n\nChange-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499\nCloses-Bug: #1306153\n""}]",25,94620,fc7dfcc543d2517746c66927536ef78846f45b26,81,9,13,10239,,,0,"Add some real-world testing on DiskPartitioner

This patch adds some integration tests for DiskPartitioner by using
it on a temporary file. As a side effect, this patch adds
disk_partitioner.list_partitions() helper, which is used by the test,
but can by used for anything else later.

The new tests are currently skipped on gate-ironic-python26, as
there is no `parted` utility there.
Also these tests do not cover destroy_disk_metadata, as it can't
be executed on a file.

Change-Id: I53bf2d207b7d15a0673be6a6786c47500b9eb499
Closes-Bug: #1306153
",git fetch https://review.opendev.org/openstack/ironic refs/changes/20/94620/10 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/test_disk_partitioner.py', 'ironic/common/disk_partitioner.py']",2,aab860b0edecefaa500d257633b0330f3a60fe88,bug/1306153," def list_partitions(device): """"""Read partitions from given device. :param device: The device path. :returns: list of dictionaries with keys: start, end, size, filesystem, flags """""" output = utils.execute( 'parted', '-s', '-m', device, 'unit', 'B', 'print')[0] lines = [line for line in output.split('\n') if line.strip()][2:] # Example of line: 1:1048576B:525336575B:524288000B:ext4::boot fields = ('start', 'end', 'size', 'filesystem', 'flags') result = [] for line in lines: # NOTE(dtantsur): 1. Split by : # 2. Drop first column and trailing ; # 3. Strip B postfix from numbers and convert to int # 4. Drop field 5 which I have no idea about line = [int(x[:-1]) if 0 <= i < 3 else x for i, x in enumerate(line.strip(';').split(':')[1:]) if i != 4] result.append(dict(zip(fields, line))) return result",,60,0
openstack%2Fironic~master~Iba8c3ad7053c600487ce4eb829ef57c708d8f154,openstack/ironic,master,Iba8c3ad7053c600487ce4eb829ef57c708d8f154,ipmitool driver raises DriverLoadError,MERGED,2014-06-13 18:02:02.000000000,2014-06-24 09:22:25.000000000,2014-06-24 09:22:24.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-06-13 18:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d470307f3b0924dc42f90430f955728f87716b7d', 'message': ""ipmitool driver raises DriverLoadError\n\nWhen the 'ipmitool' utility is not present in the system path,\nthe IPMITool driver will now raise a DriverLoadError during\ninitialization.\n\nChange-Id: Iba8c3ad7053c600487ce4eb829ef57c708d8f154\n""}, {'number': 2, 'created': '2014-06-17 00:56:33.000000000', 'files': ['ironic/drivers/modules/ipmitool.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f2fcaf3b1d85dbcb0e13c10ce68fab8e7cb6fc1a', 'message': ""ipmitool driver raises DriverLoadError\n\nWhen the 'ipmitool' utility is not present in the system path,\nthe IPMITool driver will now raise a DriverLoadError during\ninitialization.\n\nChange-Id: Iba8c3ad7053c600487ce4eb829ef57c708d8f154\n""}]",0,99977,f2fcaf3b1d85dbcb0e13c10ce68fab8e7cb6fc1a,29,9,2,2889,,,0,"ipmitool driver raises DriverLoadError

When the 'ipmitool' utility is not present in the system path,
the IPMITool driver will now raise a DriverLoadError during
initialization.

Change-Id: Iba8c3ad7053c600487ce4eb829ef57c708d8f154
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/99977/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/ipmitool.py'],1,d470307f3b0924dc42f90430f955728f87716b7d,bug/1320513," raise exception.DriverLoadError( driver=self.__class__.__name__, reason=""Unable to locate usable ipmitool command in "" ""the system path when checking ipmitool version"") raise exception.DriverLoadError( driver=self.__class__.__name__, reason=""Unable to locate usable ipmitool command in "" ""the system path when checking ipmitool version"")", # TODO(deva): raise a DriverLoadError if ipmitool # is not present on the system. pass # TODO(deva): raise DriverLoadError if ipmitool # is not present on the system. pass,8,6
openstack%2Fnova~master~Icf41bb381b7845359e1a8d04faed5925984204d9,openstack/nova,master,Icf41bb381b7845359e1a8d04faed5925984204d9,do not allow deleting an instance more than once,ABANDONED,2014-06-23 10:46:21.000000000,2014-06-24 09:20:16.000000000,,"[{'_account_id': 3}, {'_account_id': 1678}, {'_account_id': 1882}, {'_account_id': 4468}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10612}]","[{'number': 1, 'created': '2014-06-23 10:46:21.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/94d5dd5bb70054e8f54c782a991d14c88c82912c', 'message': 'do not allow deleting an instance more than once\n\ndo not allow delete an instance more than once if vm_state is in soft-delete,\nit will lead to quota_usages error.\n\nChange-Id: Icf41bb381b7845359e1a8d04faed5925984204d9\nCloses-bug: #1333145\n'}]",1,101855,94d5dd5bb70054e8f54c782a991d14c88c82912c,12,10,1,10612,,,0,"do not allow deleting an instance more than once

do not allow delete an instance more than once if vm_state is in soft-delete,
it will lead to quota_usages error.

Change-Id: Icf41bb381b7845359e1a8d04faed5925984204d9
Closes-bug: #1333145
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/101855/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,94d5dd5bb70054e8f54c782a991d14c88c82912c,master," # NOTE(hzxww): if instance vm_state is in soft-delete, we should not # delete it again which will lead to quota_usages error. # more datails: https://bugs.launchpad.net/nova/+bug/1333145 if instance['vm_state'] == 'soft-delete': LOG.debug('Instance %s has already in soft-delete state, can not' 'delete' % instance['uuid']) return ",,9,0
openstack%2Fheat~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/heat,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-24 00:18:03.000000000,2014-06-24 09:03:21.000000000,2014-06-24 09:03:20.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-24 00:18:03.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/9ab75b4a70a338bd88553c6003eae5157214ae61', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102065,9ab75b4a70a338bd88553c6003eae5157214ae61,10,3,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/102065/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9ab75b4a70a338bd88553c6003eae5157214ae61,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Foslo-incubator~master~I49a5bc4f5c572efa34a014b2652bec033bf378ee,openstack/oslo-incubator,master,I49a5bc4f5c572efa34a014b2652bec033bf378ee,mark middlware module as graduating,MERGED,2014-06-23 21:41:05.000000000,2014-06-24 09:03:10.000000000,2014-06-24 09:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-06-23 21:41:05.000000000', 'files': ['MAINTAINERS'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2e1214b74b5448825d3db26e1308a51b468d3d5c', 'message': 'mark middlware module as graduating\n\nCommon middleware code is moving to oslo.middleware library\n\nChange-Id: I49a5bc4f5c572efa34a014b2652bec033bf378ee\n'}]",0,102022,2e1214b74b5448825d3db26e1308a51b468d3d5c,8,3,1,6537,,,0,"mark middlware module as graduating

Common middleware code is moving to oslo.middleware library

Change-Id: I49a5bc4f5c572efa34a014b2652bec033bf378ee
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/22/102022/1 && git format-patch -1 --stdout FETCH_HEAD,['MAINTAINERS'],1,2e1214b74b5448825d3db26e1308a51b468d3d5c,middleware,M: Gordon Chung <gord@live.ca>M: Gordon Chung <gord@live.ca> S: Graduating,M: Gordon Chung <chungg@ca.ibm.com>M: S: Orphan,3,3
openstack%2Ftempest~master~I75406a5f4bed7f82bc67c5ef733c65b77742dbd5,openstack/tempest,master,I75406a5f4bed7f82bc67c5ef733c65b77742dbd5,Sahara: add changes to cli tests,ABANDONED,2014-05-23 10:37:04.000000000,2014-06-24 09:00:53.000000000,,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6786}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8824}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-23 10:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/96b8b22d4ea15bab57cb98d0585c1642e9d100a4', 'message': 'Sahara: missed license editing\n\nLicense in test_sahara.py file uses different number of white spaces\nthan the others licenses. This change was missed in patch\nhttps://review.openstack.org/#/c/90136/. This patch fixes that for\nconsistency.\ntest_sahara.py file has been created in 2014, however in copyrights\nof this file 2013 is written.\n\nChange-Id: I75406a5f4bed7f82bc67c5ef733c65b77742dbd5\n'}, {'number': 2, 'created': '2014-05-23 10:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0fca52fc55a63295d2dd564ffa4cad4cadfe55ca', 'message': 'Sahara: missed license editing\n\nLicense in test_sahara.py file uses different number of white spaces\nthan the others licenses. This change was missed in patch\nhttps://review.openstack.org/#/c/90136/ . This patch fixes that for\nconsistency.\ntest_sahara.py file has been created in 2014, however in copyrights\nof this file 2013 is written.\n\nChange-Id: I75406a5f4bed7f82bc67c5ef733c65b77742dbd5\n'}, {'number': 3, 'created': '2014-05-28 10:58:06.000000000', 'files': ['tempest/cli/simple_read_only/test_sahara.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/57e977d1dd2b66dd3f823336f7dbb0a34ce0a03d', 'message': 'Sahara: add changes to cli tests\n\n1. Two new tests (for help and version) were added\n2. Code that checks nothing was removed from tests\n   For example, there is test for cluster templates.\n   There are lines in this test\n\n       77. result = self.sahara(\'cluster-template-list\')\n       78. cluster_templates = self.parser.listing(result)\n       79. self.assertTableStruct(...)\n\n   ""cluster_templates"" variable is empty list in this case because\n   there are no default cluster templates. Thus L79 looks like\n\n       79. self.assertTableStruct([], [\n            \'name\',\n            \'id\',\n            \'plugin_name\',\n            \'node_groups\',\n            \'description\'\n           ])\n\n   That is why these lines were removed from some tests.\n\nIn addition, date in copyrights was corrected. test_sahara.py file\nhas been created in 2014, however in copyrights of this file 2013\nis written.\n\nChange-Id: I75406a5f4bed7f82bc67c5ef733c65b77742dbd5\n'}]",3,95134,57e977d1dd2b66dd3f823336f7dbb0a34ce0a03d,27,11,3,7428,,,0,"Sahara: add changes to cli tests

1. Two new tests (for help and version) were added
2. Code that checks nothing was removed from tests
   For example, there is test for cluster templates.
   There are lines in this test

       77. result = self.sahara('cluster-template-list')
       78. cluster_templates = self.parser.listing(result)
       79. self.assertTableStruct(...)

   ""cluster_templates"" variable is empty list in this case because
   there are no default cluster templates. Thus L79 looks like

       79. self.assertTableStruct([], [
            'name',
            'id',
            'plugin_name',
            'node_groups',
            'description'
           ])

   That is why these lines were removed from some tests.

In addition, date in copyrights was corrected. test_sahara.py file
has been created in 2014, however in copyrights of this file 2013
is written.

Change-Id: I75406a5f4bed7f82bc67c5ef733c65b77742dbd5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/95134/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_sahara.py'],1,96b8b22d4ea15bab57cb98d0585c1642e9d100a4,,"# Copyright (c) 2014 Mirantis Inc.# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.","# Copyright (c) 2013 Mirantis Inc.# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License.",10,11
openstack%2Frally~master~Icb7d243643a6a0a57d2b1f01879774008491ea0a,openstack/rally,master,Icb7d243643a6a0a57d2b1f01879774008491ea0a,Add unit tests for rest,MERGED,2014-06-17 07:15:38.000000000,2014-06-24 08:57:12.000000000,2014-06-24 08:26:02.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-06-17 07:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6d8020023e9834e64ebece7d1ffd18da2ba232b3', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}, {'number': 2, 'created': '2014-06-17 08:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bded73f207bd45f76a6f018bad339dfaf16ebbfb', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}, {'number': 3, 'created': '2014-06-18 07:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2a3eb536fd25019af72878e6d3b27410812a1492', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}, {'number': 4, 'created': '2014-06-19 11:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e8c24751cd3c4cbd4ee114d67785407d13031b09', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}, {'number': 5, 'created': '2014-06-23 07:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a72a1b937d63f46dc1faa4813faf4f23ff0457df', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}, {'number': 6, 'created': '2014-06-23 14:34:50.000000000', 'files': ['tests/aas/rest/controllers/__init__.py', 'tests/aas/rest/controllers/test_root.py', 'tests/aas/rest/__init__.py', 'rally/aas/rest/types.py', 'tests/aas/rest/base.py', 'tests/aas/rest/test_types.py', 'tests/aas/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/9e189b9228cdb6d0df1769e3625fffa180b6799a', 'message': 'Add unit tests for rest\n\n* add unit tests for rest.types\n* add unit tests for rest.controllers.root\n* add unit tests for rest.controllers.v1.root\n\nChange-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a\n'}]",25,100435,9e189b9228cdb6d0df1769e3625fffa180b6799a,42,6,6,4428,,,0,"Add unit tests for rest

* add unit tests for rest.types
* add unit tests for rest.controllers.root
* add unit tests for rest.controllers.v1.root

Change-Id: Icb7d243643a6a0a57d2b1f01879774008491ea0a
",git fetch https://review.opendev.org/openstack/rally refs/changes/35/100435/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/aas/rest/controllers/__init__.py', 'tests/aas/rest/controllers/test_root.py', 'tests/aas/rest/__init__.py', 'tests/aas/rest/base.py', 'tests/aas/rest/test_types.py', 'tests/aas/__init__.py']",6,6d8020023e9834e64ebece7d1ffd18da2ba232b3,rest-unit-tests,,,323,0
openstack%2Fcinder~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/cinder,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-24 00:06:10.000000000,2014-06-24 08:55:26.000000000,2014-06-24 08:55:26.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 8871}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-24 00:06:10.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8cc6ad0f55de3d387c8ebea4c14d11ee1ad664f6', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102061,8cc6ad0f55de3d387c8ebea4c14d11ee1ad664f6,11,4,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/61/102061/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8cc6ad0f55de3d387c8ebea4c14d11ee1ad664f6,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fkeystone~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/keystone,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-23 23:52:20.000000000,2014-06-24 08:53:21.000000000,2014-06-24 08:53:20.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 23:52:20.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e3f2d35f0fea7852b9e93aa8734a5abea97fa6de', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102055,e3f2d35f0fea7852b9e93aa8734a5abea97fa6de,16,5,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/keystone refs/changes/55/102055/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,e3f2d35f0fea7852b9e93aa8734a5abea97fa6de,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fnova-specs~master~I7bd2354bcf3e49992056b78b95a685b214d3b5d4,openstack/nova-specs,master,I7bd2354bcf3e49992056b78b95a685b214d3b5d4,Proposed blueprint for better V3 diagnostics,MERGED,2014-04-02 10:57:57.000000000,2014-06-24 08:48:03.000000000,2014-06-24 08:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 3185}, {'_account_id': 4393}, {'_account_id': 4912}, {'_account_id': 6062}, {'_account_id': 6735}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8021}, {'_account_id': 9275}, {'_account_id': 9420}, {'_account_id': 11800}]","[{'number': 1, 'created': '2014-04-02 10:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b6ac3d129f4f3ca1168b2665ff95a611e84a0cdf', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 2, 'created': '2014-04-03 08:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/31c984befe621c278cbdbed6aad9c822b367aa16', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 3, 'created': '2014-04-09 11:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3d2932ef4e25ba2b7beeb747c5889e81fcf01acb', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 4, 'created': '2014-04-09 11:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3f64d0d5258b99e6545ba35017bcb3d14132fa8f', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 5, 'created': '2014-04-09 11:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/39fc32daef5940112706419f96ef7d0865f300bf', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 6, 'created': '2014-04-10 08:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/441bc2ff47f9eba6753a3d79c7ed26fe5275ea4c', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 7, 'created': '2014-04-10 18:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/237937ad9daf4438f9207e3121dbcb7fa78965c5', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 8, 'created': '2014-04-13 06:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8919978ea3ba5d9b03a333d375800bac1ec0c586', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 9, 'created': '2014-04-13 13:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a8208f688a71d9c9038307a0f2e4c64226883d30', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 10, 'created': '2014-04-14 05:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d0b564b70cf924a531256f3aeef392987ef26d59', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 11, 'created': '2014-04-14 08:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/23403f7e8b16a6479b5c037c9a1e0c162f8be067', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 12, 'created': '2014-04-16 13:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/98c378e4b3745ff83e8b18a46c574b87452b9416', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 13, 'created': '2014-04-23 11:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dc3a505cc32259a2c78b4e02b41a4ebc77c2b350', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 14, 'created': '2014-04-29 11:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/567d0376bf4341b1a35e4b9a5b995cd8e0073743', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 15, 'created': '2014-04-30 15:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/aaaa89c111b8aa0e36a658776f658dc331b763d2', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 16, 'created': '2014-05-01 11:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fa03cd6a1a98febbdabdc6275ed269a07d49a7db', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nCurrently there is no defined format for VM diagnostics. This BP will ensure\nthat all of the drivers that provide VM diagnostics will have a consistent\nformat.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 17, 'created': '2014-05-08 21:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/67a719559f8bcdef2c1daeb020e61fc4f2d28cb0', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nCurrently there is no defined format for VM diagnostics. This BP will ensure\nthat all of the drivers that provide VM diagnostics will have a consistent\nformat.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 18, 'created': '2014-05-21 13:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/658e82a4eff3e4a846bf818e3aef17686fe54f6c', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nCurrently there is no defined format for VM diagnostics. This BP will ensure\nthat all of the drivers that provide VM diagnostics will have a consistent\nformat.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}, {'number': 19, 'created': '2014-06-19 08:58:57.000000000', 'files': ['specs/juno/v3-diagnostics.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f96acb55e82967627db986f2bcd4e17a148c4e27', 'message': 'Proposed blueprint for better V3 diagnostics\n\nPart of blueprint v3-diagnostics.\n\nCurrently there is no defined format for VM diagnostics. This BP will ensure\nthat all of the drivers that provide VM diagnostics will have a consistent\nformat.\n\nChange-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4\n'}]",152,84691,f96acb55e82967627db986f2bcd4e17a148c4e27,140,20,19,1653,,,0,"Proposed blueprint for better V3 diagnostics

Part of blueprint v3-diagnostics.

Currently there is no defined format for VM diagnostics. This BP will ensure
that all of the drivers that provide VM diagnostics will have a consistent
format.

Change-Id: I7bd2354bcf3e49992056b78b95a685b214d3b5d4
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/91/84691/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/v3-diagnostics.rst'],1,b6ac3d129f4f3ca1168b2665ff95a611e84a0cdf,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== V3 Diagnostics - common output ============================== https://blueprints.launchpad.net/nova/+spec/v3-diagnostics Currently there is no defined format for VM diagnostics. This BP will ensure that all of the drivers that provide VM diagnostics will have a consistent format. Problem description =================== In V2 the VM diagnostics are a 'blob' of data returned by each hypervisor. The goal here is to have a formal definition of what out should be returned, if possible, by the drivers supporting the API. In additition to this a driver will be able to return additional if they choose. Proposed change =============== Introduce a new driver method that will return a predefined structure: get_instance_diagnostics(self, instance) The data returned is defined at: https://wiki.openstack.org/wiki/Nova_VM_Diagnostics Alternatives ------------ Continue with the same format that the V2 has. This is problematic as we are unable to build common user interface that can query VM states, for example in tempest. Data model impact ----------------- None REST API impact --------------- None - this has already been implemented for the V3 API. In this case we will be calling the new API. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- It will make life easier - deployed will be able to get better insight into the state of VM and be able to troubleshoot. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Gary Kotton<gkotton@vmware.com> Other contributors: Bob Ball<bob.ball@citrix.com> Work Items ---------- All work items were completed in Icehouse. - VM diagnostics (v3 API only): https://review.openstack.org/#/c/61753/ - XenAPI: https://review.openstack.org/#/c/66338/ - libvirt: https://review.openstack.org/#/c/66890/ - VMware: https://review.openstack.org/#/c/62240/ Dependencies ============ None Testing ======= Once the API is approved we can add in the tempest tests. Documentation Impact ==================== We can now at least document the fields that are returned and their meaning. The definition of the data returned can be seen at the wiki below. References ========== https://wiki.openstack.org/wiki/Nova_VM_Diagnostics ",,121,0
openstack%2Fpython-blazarclient~master~I5ba103b74dd1ec258c427a84d6ca92192bb6ff56,openstack/python-blazarclient,master,I5ba103b74dd1ec258c427a84d6ca92192bb6ff56,Updated from global requirements,MERGED,2014-06-10 14:40:51.000000000,2014-06-24 08:45:26.000000000,2014-06-24 08:45:26.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7535}, {'_account_id': 9331}]","[{'number': 1, 'created': '2014-06-10 14:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/7373ff5d07ffc56b3d03c69304ebc33101ec5354', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}, {'number': 2, 'created': '2014-06-11 01:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/e9e41575e8a0c541db79b8c5f060e6526f5a40f4', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}, {'number': 3, 'created': '2014-06-16 09:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/f9d509d2e7bd808891c813699e5b2f1fde3f2281', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}, {'number': 4, 'created': '2014-06-17 21:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/30ee50c576d2082ff3dcc2433d3e87cbb9e71a52', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}, {'number': 5, 'created': '2014-06-18 00:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/e2e0d9839216dd388ce20fec44e29f681e3a3be3', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}, {'number': 6, 'created': '2014-06-23 05:35:30.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/ca07062cedbcebcdb2adff07f0fef53f2f4e1b1e', 'message': 'Updated from global requirements\n\nChange-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56\n'}]",0,99102,ca07062cedbcebcdb2adff07f0fef53f2f4e1b1e,26,4,6,11131,,,0,"Updated from global requirements

Change-Id: I5ba103b74dd1ec258c427a84d6ca92192bb6ff56
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/02/99102/6 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7373ff5d07ffc56b3d03c69304ebc33101ec5354,openstack/requirements,"hacking>=0.8.0,<0.10,!=0.9.0","hacking>=0.8.0,<0.9",1,1
openstack%2Fpython-troveclient~master~Idf22d3d9e676138969cbdf3afd4903b8e475c313,openstack/python-troveclient,master,Idf22d3d9e676138969cbdf3afd4903b8e475c313,Add 'slave_of' option for enabling replication,MERGED,2014-06-04 16:00:19.000000000,2014-06-24 08:41:06.000000000,2014-06-24 08:41:06.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9749}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-06-04 16:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/ce9256f4548b9398a35d0aac0067b98a02c1bf28', 'message': ""Add 'slave_of' option for enabling replication\n\nAdd a new create option (--slave_of) that can be used to enable\nreplication and configure the newly created instance as a slave of the\nspecified existing instance.\n\nDocImpact Introduces new option when creating an instance.\n\npartially Implements: blueprint replication-v1\nChange-Id: Idf22d3d9e676138969cbdf3afd4903b8e475c313\n""}, {'number': 2, 'created': '2014-06-05 04:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d58be19a8b87c78ce2910919c0e0c23eb296376b', 'message': ""Add 'slave_of' option for enabling replication\n\nAdd a new create option (--slave_of) that can be used to enable\nreplication and configure the newly created instance as a slave of the\nspecified existing instance.\n\nDocImpact Introduces new option when creating an instance.\n\npartially Implements: blueprint replication-v1\nChange-Id: Idf22d3d9e676138969cbdf3afd4903b8e475c313\n""}, {'number': 3, 'created': '2014-06-09 17:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/7ffe2c0ed9719e0e91ed192713850fdcaed96ccf', 'message': ""Add 'slave_of' option for enabling replication\n\nAdd a new create option (--slave_of) that can be used to enable\nreplication and configure the newly created instance as a slave of the\nspecified existing instance.\n\nDocImpact Introduces new option when creating an instance.\n\npartially Implements: blueprint replication-v1\nChange-Id: Idf22d3d9e676138969cbdf3afd4903b8e475c313\n""}, {'number': 4, 'created': '2014-06-10 12:39:15.000000000', 'files': ['troveclient/v1/shell.py', 'troveclient/v1/instances.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/258b47b2a06915d17079a57a4243a8141ee50d71', 'message': ""Add 'slave_of' option for enabling replication\n\nAdd a new create option (--slave_of) that can be used to enable\nreplication and configure the newly created instance as a slave of the\nspecified existing instance.\n\nDocImpact Introduces new option when creating an instance.\n\npartially Implements: blueprint replication-v1\nChange-Id: Idf22d3d9e676138969cbdf3afd4903b8e475c313\n""}]",17,97840,258b47b2a06915d17079a57a4243a8141ee50d71,66,11,4,9749,,,0,"Add 'slave_of' option for enabling replication

Add a new create option (--slave_of) that can be used to enable
replication and configure the newly created instance as a slave of the
specified existing instance.

DocImpact Introduces new option when creating an instance.

partially Implements: blueprint replication-v1
Change-Id: Idf22d3d9e676138969cbdf3afd4903b8e475c313
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/40/97840/4 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/v1/shell.py', 'troveclient/v1/instances.py']",2,ce9256f4548b9398a35d0aac0067b98a02c1bf28,bp/replication-v1," datastore_version=None, nics=None, configuration=None, slave_of=None): if slave_of: print(""slave_of = %s"" % slave_of) body[""instance""][""slaveOf""] = slave_of"," datastore_version=None, nics=None, configuration=None):",11,2
openstack%2Ftrove~master~Id76b9c033eadef8be7a8538430089d6dd434fd0b,openstack/trove,master,Id76b9c033eadef8be7a8538430089d6dd434fd0b,Imported Translations from Transifex,MERGED,2014-06-15 06:05:32.000000000,2014-06-24 08:37:54.000000000,2014-06-24 08:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-06-15 06:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/585b9edfae41d9567202a590cafef889bc905cf3', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 2, 'created': '2014-06-16 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/efd545680bd5673e286c5334bc80b6b9d8deef7d', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 3, 'created': '2014-06-17 06:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a3bf0728cfadff0d3c3ed3e3e400d0e7df2c7e47', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 4, 'created': '2014-06-18 06:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/13f5ebd7cce41e387736014dc68a7fe1b6590963', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 5, 'created': '2014-06-19 06:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/201b77a69130c45c673d675a25256c2b54aa4069', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 6, 'created': '2014-06-20 06:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7fc982340457c40eeebadffdd9f0a08d1e9ca734', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 7, 'created': '2014-06-21 06:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/90957ef274f9d26f5071f9e45652c9815e878416', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 8, 'created': '2014-06-22 06:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/33f887f6f42abdb58e3c0cfaef560475a7998deb', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 9, 'created': '2014-06-23 06:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/22857bc0927183b8cad6eac116bd27f78b2d91c5', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}, {'number': 10, 'created': '2014-06-24 06:05:53.000000000', 'files': ['trove/locale/trove.pot', 'trove/locale/en_US/LC_MESSAGES/trove.po'], 'web_link': 'https://opendev.org/openstack/trove/commit/46a2f7d377bde1fe1b7b80b3be640eadeb44a4de', 'message': 'Imported Translations from Transifex\n\nChange-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b\n'}]",0,100083,46a2f7d377bde1fe1b7b80b3be640eadeb44a4de,74,7,10,11131,,,0,"Imported Translations from Transifex

Change-Id: Id76b9c033eadef8be7a8538430089d6dd434fd0b
",git fetch https://review.opendev.org/openstack/trove refs/changes/83/100083/4 && git format-patch -1 --stdout FETCH_HEAD,"['trove/locale/trove.pot', 'trove/locale/en_US/LC_MESSAGES/trove.po']",2,585b9edfae41d9567202a590cafef889bc905cf3,transifex/translations,"""POT-Creation-Date: 2014-06-15 06:05+0000\n""#: trove/backup/models.py:306#: trove/backup/models.py:309#: trove/backup/service.py:50#: trove/backup/service.py:51 trove/extensions/mgmt/host/service.py:45""The datastore from which the backup was taken, %(datastore1)s, does not "" ""match the destination datastore of %(datastore2)s""#: trove/guestagent/backup/backupagent.py:135#: trove/guestagent/backup/backupagent.py:144#: trove/guestagent/backup/backupagent.py:151#: trove/guestagent/backup/backupagent.py:175#: trove/guestagent/backup/backupagent.py:177#: trove/guestagent/backup/backupagent.py:181#: trove/guestagent/backup/backupagent.py:185#: trove/instance/models.py:747#: trove/instance/models.py:751#: trove/instance/models.py:901#: trove/instance/models.py:962 trove/instance/models.py:968#: trove/instance/models.py:965","""POT-Creation-Date: 2014-06-14 06:06+0000\n""#: trove/backup/models.py:280#: trove/backup/models.py:283#: trove/backup/service.py:49#: trove/backup/service.py:50 trove/extensions/mgmt/host/service.py:45""The datastore-version from which the backup was taken, %(version1)s, does"" "" not match the destination datastore-version of %(version2)s""#: trove/guestagent/backup/backupagent.py:131#: trove/guestagent/backup/backupagent.py:140#: trove/guestagent/backup/backupagent.py:147#: trove/guestagent/backup/backupagent.py:171#: trove/guestagent/backup/backupagent.py:173#: trove/guestagent/backup/backupagent.py:177#: trove/guestagent/backup/backupagent.py:181#: trove/instance/models.py:752#: trove/instance/models.py:756#: trove/instance/models.py:906#: trove/instance/models.py:967 trove/instance/models.py:973#: trove/instance/models.py:970",39,39
openstack%2Fpython-troveclient~master~Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f,openstack/python-troveclient,master,Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f,Updates root-enable & root-show help messages,MERGED,2014-02-07 01:54:19.000000000,2014-06-24 08:37:48.000000000,2014-06-24 08:37:47.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-02-07 01:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/0f40e7aab9a2c0487719adf1dcc618f8eadce77d', 'message': 'Updates root-show help message\n\nReasons:\n- Current help message makes it feel like current status of root user\n  is fetched, but instead we are also returning True for historical\n  root access enabled.\n\nChanges:\n- Updated the root-show API help message.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 2, 'created': '2014-02-11 02:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d85c38299a037dd63931bbab658944a21674636c', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 3, 'created': '2014-02-11 02:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/309dd1b4bb4fd471bfdd590bc7fa359999ea60c0', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 6, 'created': '2014-02-11 02:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/a0f19e414871ffdce5cba385d70fec4ed9aa5624', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 5, 'created': '2014-02-11 02:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/25b1cea240ca1d9cb5ef5063ddfa62252d470a75', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 4, 'created': '2014-02-11 02:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/36804b8fd1a956b45f35290d5fee6ac2c2afed21', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 7, 'created': '2014-05-24 08:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/20b34e88e2c9f28e754e588f5e4b997c927b583a', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 8, 'created': '2014-06-03 07:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/f2fa60fc6cfe190f4a76acfb01b285f74331c957', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses the password reset information, which it does.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}, {'number': 9, 'created': '2014-06-03 07:08:26.000000000', 'files': ['troveclient/v1/shell.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/8a632221320b91759b7b6018ec6097d4cc404701', 'message': 'Updates root-enable & root-show help messages\n\nReasons:\n- Help message for root-enable does not gives complete information, it\n  misses that API also resets root, on existence.\n- Current help message for root-show makes it feel like current status\n  of root user is fetched, but instead we are also returning True for\n  historical root access enabled.\n\nChanges:\n- Updated the root-enable and root-show API help message.\n- Updated README for updated help messages.\n\nChange-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f\nCloses-Bug: #1277308\n'}]",4,71711,8a632221320b91759b7b6018ec6097d4cc404701,79,9,9,7806,,,0,"Updates root-enable & root-show help messages

Reasons:
- Help message for root-enable does not gives complete information, it
  misses that API also resets root, on existence.
- Current help message for root-show makes it feel like current status
  of root user is fetched, but instead we are also returning True for
  historical root access enabled.

Changes:
- Updated the root-enable and root-show API help message.
- Updated README for updated help messages.

Change-Id: Ide7c331bdfe5437e6966f6cd4f331cb3b22d0c3f
Closes-Bug: #1277308
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/11/71711/9 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/v1/shell.py', 'README.rst']",2,0f40e7aab9a2c0487719adf1dcc618f8eadce77d,bug/1277308, root-show Gets status if root was ever enabled for a instance., root-show Gets root enabled status for a instance.,2,2
openstack%2Fgnocchi~master~I4355da2f1d6d06be9ff773cc77f1e076c245463c,openstack/gnocchi,master,I4355da2f1d6d06be9ff773cc77f1e076c245463c,Remove aggregation method that requires full history retention,ABANDONED,2014-06-22 22:28:12.000000000,2014-06-24 08:31:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 9562}, {'_account_id': 10683}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-22 22:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/03bf61ec8ae976f55e5ad1575cbc79cd533c011f', 'message': ""Remove aggregation method that requires full history retention\n\nAccurately calculating aggregates such as quantiles requires that\nthe full history of measurements is retained.\n\nThis doesn't fit in well with the gnocchi approach of minimal\nretention.\n\nCurrently the computed value for the median aggregate depends on\nthe order in which the measurements are submitted, i.e. permutation\nof the datapoints yields a different result, which is clearly wrong.\n\nFor now, we remove 'median' from the set of supported aggregation\nmethods, until we can figure out how to accomodate history-dependent\naggregation methods.\n\nChange-Id: I4355da2f1d6d06be9ff773cc77f1e076c245463c\n""}, {'number': 2, 'created': '2014-06-23 10:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/13b1fe2717dbaf0931b1c0164b12bdb429b68c16', 'message': ""Remove aggregation method that requires full history retention\n\nAccurately calculating aggregates such as quantiles requires that\nthe full history of measurements is retained.\n\nThis doesn't fit in well with the gnocchi approach of minimal\nretention.\n\nCurrently the computed value for the median aggregate depends on\nthe order in which the measurements are submitted, i.e. permutation\nof the datapoints yields a different result, which is clearly wrong.\n\nFor now, we remove 'median' from the set of supported aggregation\nmethods, until we can figure out how to accomodate history-dependent\naggregation methods.\n\nChange-Id: I4355da2f1d6d06be9ff773cc77f1e076c245463c\n""}, {'number': 3, 'created': '2014-06-23 10:34:05.000000000', 'files': ['gnocchi/storage/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d0c3e3780d6aa8e07bcfd91501c7d996d2fd3004', 'message': ""Remove aggregation method that requires full history retention\n\nAccurately calculating aggregates such as quantiles requires that\nthe full history of measurements is retained.\n\nThis doesn't fit in well with the gnocchi approach of minimal\nretention.\n\nCurrently the computed value for the median aggregate depends on\nthe order in which the measurements are submitted, i.e. permutation\nof the datapoints yields a different result, which is clearly wrong.\n\nFor now, we remove 'median' from the set of supported aggregation\nmethods, until we can figure out how to accomodate history-dependent\naggregation methods.\n\nChange-Id: I4355da2f1d6d06be9ff773cc77f1e076c245463c\n""}]",0,101781,d0c3e3780d6aa8e07bcfd91501c7d996d2fd3004,11,6,3,2284,,,0,"Remove aggregation method that requires full history retention

Accurately calculating aggregates such as quantiles requires that
the full history of measurements is retained.

This doesn't fit in well with the gnocchi approach of minimal
retention.

Currently the computed value for the median aggregate depends on
the order in which the measurements are submitted, i.e. permutation
of the datapoints yields a different result, which is clearly wrong.

For now, we remove 'median' from the set of supported aggregation
methods, until we can figure out how to accomodate history-dependent
aggregation methods.

Change-Id: I4355da2f1d6d06be9ff773cc77f1e076c245463c
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/81/101781/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/__init__.py'],1,03bf61ec8ae976f55e5ad1575cbc79cd533c011f,,"#TODO(eglynn): figure out how to accommodate aggregation methods that # require the entire history of datapoints to be retained # in order to be accurately calculated (e.g. median) AGGREGATION_TYPES = ('mean', 'sum', 'last', 'max', 'min', 'std', 'first')","AGGREGATION_TYPES = ('mean', 'sum', 'last', 'max', 'min', 'std', 'median', 'first')",4,2
openstack%2Fcinder~master~I726b23287c5b710227288d6215538f01dfb0f979,openstack/cinder,master,I726b23287c5b710227288d6215538f01dfb0f979,Fixes cinder volume from image on Windows,MERGED,2014-04-02 16:36:33.000000000,2014-06-24 08:31:58.000000000,2014-06-24 08:31:57.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 3185}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 8543}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-04-02 16:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c90f29457a11e5418c4d4ee489250963985b7df5', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 2, 'created': '2014-04-02 18:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ddc346463149315fcec1f740d3fb19b7df5f28f1', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 3, 'created': '2014-04-02 21:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb73c0fc423c24288bfe5476b528f2c5da531e6f', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 4, 'created': '2014-04-04 15:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/faa71dd8ac5a54b2fc8cfc5d95ccf2594398cca8', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 5, 'created': '2014-04-07 12:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/12b412aa91b12f10275ed896d33e0801271f8897', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 6, 'created': '2014-04-07 16:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c20baa4ecf66f99b3bf2cc84ebd1ebed11804d3', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 7, 'created': '2014-04-08 15:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbc1937e0c345fa0cb8284bbfb09c76bbb22f148', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 8, 'created': '2014-04-10 16:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6304ddef1e1b6299be705dda7d0233effd0d6e01', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 9, 'created': '2014-04-11 10:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/67141fc05d6109dcf10701a6ae5d87583d91be2d', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 10, 'created': '2014-04-17 17:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/af68d05a350361e1e4a128e15c407e318c9103f2', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\nCloses-Bug: #1300906\n'}, {'number': 11, 'created': '2014-04-28 12:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbac46856cf1c7600ee765d020cc944169c61b39', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nTo fix this and avoid disabling the volume or deleting it when\nconverting the image to fixed sized vhd using wmi, the flow of\ncreating a volume from an image must be changed when using Windows.\nSo instead of creating the volume before copying the image to it,\nit is better to skip the first step and let the driver create the\ndisk based on the downloaded image and then import it as an iSCSI\ndisk.\n\nCloses-Bug: #1300906\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\n'}, {'number': 12, 'created': '2014-05-12 13:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3ace510b1bc6bf32ea4e87deb6a3bf726433c69a', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nIn order to be able to modify an iSCSI disk, it must be disabled\nfirst.\n\nCloses-Bug: #1300906\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\n'}, {'number': 13, 'created': '2014-06-18 17:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/63345b62f8cdf6d671e154bf524f456f7f2de396', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nIn order to be able to modify an iSCSI disk, it must be disabled\nfirst.\n\nCloses-Bug: #1300906\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\n'}, {'number': 14, 'created': '2014-06-21 18:01:55.000000000', 'files': ['cinder/tests/test_windows_utils.py', 'cinder/image/image_utils.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/tests/test_windows.py', 'cinder/volume/drivers/windows/constants.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6c03e15e8caa957716eabfee047240622ac3bf5', 'message': 'Fixes cinder volume from image on Windows\n\nWhen creating a volume from an image, after the volume is created,\nqemu-img is supposed to copy the downloaded image to the volume.\nThis fails as the disk is enabled and is not accessible.\n\nAlso, Windows does not support using dynamic vhds as iSCSI disks\nand as qemu-img cannot create fixed vhd images, there must be an\nintermediate conversion before importing the disk.\n\nIn order to be able to modify an iSCSI disk, it must be disabled\nfirst.\n\nCloses-Bug: #1300906\n\nChange-Id: I726b23287c5b710227288d6215538f01dfb0f979\n'}]",2,84789,e6c03e15e8caa957716eabfee047240622ac3bf5,68,9,14,8543,,,0,"Fixes cinder volume from image on Windows

When creating a volume from an image, after the volume is created,
qemu-img is supposed to copy the downloaded image to the volume.
This fails as the disk is enabled and is not accessible.

Also, Windows does not support using dynamic vhds as iSCSI disks
and as qemu-img cannot create fixed vhd images, there must be an
intermediate conversion before importing the disk.

In order to be able to modify an iSCSI disk, it must be disabled
first.

Closes-Bug: #1300906

Change-Id: I726b23287c5b710227288d6215538f01dfb0f979
",git fetch https://review.opendev.org/openstack/cinder refs/changes/89/84789/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/flows/manager/create_volume.py', 'cinder/scheduler/flows/create_volume.py', 'cinder/tests/test_windows_utils.py', 'cinder/image/image_utils.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/tests/test_windows.py', 'cinder/volume/drivers/windows/constants.py']",8,c90f29457a11e5418c4d4ee489250963985b7df5,bug/1300906,WMI_JOB_STATUS_STARTED = 4096 WMI_JOB_STATE_RUNNING = 4 WMI_JOB_STATE_COMPLETED = 7 VHD_TYPE_FIXED = 2 VHD_TYPE_DYNAMIC = 3,,253,21
openstack%2Ftempest~master~I59bf5c6b9823a93748014640430ac90960ad8583,openstack/tempest,master,I59bf5c6b9823a93748014640430ac90960ad8583,Push triage patch to trigger SSH EOFError,ABANDONED,2014-06-06 18:07:01.000000000,2014-06-24 08:29:43.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5263}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-06 18:07:01.000000000', 'files': ['tempest/scenario/test_network_advanced_server_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/bc11779ba2fbe543650cee735742bfd6a2df65d2', 'message': 'Push triage patch to trigger SSH EOFError\n\nThis is the same patch of:\n\nhttps://review.openstack.org/#/c/90427/\n\nBut with a minor tweak to leave the\nServers behind for troubleshooting.\n\n** DO NOT MERGE **\n\nRelated-bug: #1323658\n\nChange-Id: I59bf5c6b9823a93748014640430ac90960ad8583\n'}]",0,98483,bc11779ba2fbe543650cee735742bfd6a2df65d2,27,6,1,748,,,0,"Push triage patch to trigger SSH EOFError

This is the same patch of:

https://review.openstack.org/#/c/90427/

But with a minor tweak to leave the
Servers behind for troubleshooting.

** DO NOT MERGE **

Related-bug: #1323658

Change-Id: I59bf5c6b9823a93748014640430ac90960ad8583
",git fetch https://review.opendev.org/openstack/tempest refs/changes/83/98483/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_advanced_server_ops.py'],1,bc11779ba2fbe543650cee735742bfd6a2df65d2,bug/1323658-triage," # FIXME(armando-migliaccio): skip the cleanup for troubleshooting pass # self.cleanup_resource(resource, self.__class__.__name__) self._wait_server_status_and_check_network_connectivity()"," self.cleanup_resource(resource, self.__class__.__name__)",4,1
openstack%2Foslo.messaging~master~If95ac9a05de0072780db540e959ebde2948f98c3,openstack/oslo.messaging,master,If95ac9a05de0072780db540e959ebde2948f98c3,Encode/decode the auth_token when pack/unpack message,ABANDONED,2014-05-22 14:18:43.000000000,2014-06-24 08:21:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 7063}, {'_account_id': 7148}, {'_account_id': 8784}, {'_account_id': 8871}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-05-22 14:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bad5cd3b229450183deffc516ad3aa61b4653bc1', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 2, 'created': '2014-05-22 14:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9a5c9e1174ec77677c39739e69336884b9aa3713', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 3, 'created': '2014-05-25 10:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/15b892f867dbff3f69964a7b25043c1884bd114b', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 4, 'created': '2014-05-26 03:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ab6360199fa4a8c2a6112c16534ff7732772d9d6', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 5, 'created': '2014-05-26 05:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d6c9e868c409aceaff2345c1486cae91b7895b3c', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 6, 'created': '2014-05-26 07:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/169bec1ec39eaff069976254d55d62459621e4d7', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}, {'number': 7, 'created': '2014-06-16 10:09:23.000000000', 'files': ['oslo/messaging/openstack/common/crypto/__init__.py', 'requirements.txt', 'oslo/messaging/openstack/common/crypto/utils.py', 'openstack-common.conf', 'oslo/messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/30bef52721a6ce07d8862813debf3cf145a35228', 'message': 'Encode/decode the auth_token when pack/unpack message\n\nWhen qpid debug log is enabled, it will print plaintext of auth_token\nwithin log which will expose security leak. Use base64 to encode\nthe messages that exposed to amqp.\n\nChange-Id: If95ac9a05de0072780db540e959ebde2948f98c3\nCloses-Bug: #1319751\n'}]",0,94881,30bef52721a6ce07d8862813debf3cf145a35228,43,9,7,7148,,,0,"Encode/decode the auth_token when pack/unpack message

When qpid debug log is enabled, it will print plaintext of auth_token
within log which will expose security leak. Use base64 to encode
the messages that exposed to amqp.

Change-Id: If95ac9a05de0072780db540e959ebde2948f98c3
Closes-Bug: #1319751
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/81/94881/6 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/amqp.py'],1,bad5cd3b229450183deffc516ad3aa61b4653bc1,amqpmessage,"import base64 encode_keys = ['_context_auth_token', 'new_password'] if 'auth_token' in key and value: context_dict[key[9:]] = base64.b64decode(value) else: context_dict[key[9:]] = value for (key, value) in context_d: if 'auth_token' in key and value: value = base64.b64encode(value) msg.update({'_context_%s' % key: value})"," context_dict[key[9:]] = value msg.update(('_context_%s' % key, value) for (key, value) in context_d)",10,3
openstack%2Frally~master~I1db47c96cf465e6378e783ce5240bb0b46b6c534,openstack/rally,master,I1db47c96cf465e6378e783ce5240bb0b46b6c534,Updated from global requirements,MERGED,2014-06-24 07:27:00.000000000,2014-06-24 08:19:43.000000000,2014-06-24 08:19:43.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-24 07:27:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/ad71a6a8f6015535c51ea7c1eece061760edeb12', 'message': 'Updated from global requirements\n\nChange-Id: I1db47c96cf465e6378e783ce5240bb0b46b6c534\n'}]",0,102135,ad71a6a8f6015535c51ea7c1eece061760edeb12,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I1db47c96cf465e6378e783ce5240bb0b46b6c534
",git fetch https://review.opendev.org/openstack/rally refs/changes/35/102135/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ad71a6a8f6015535c51ea7c1eece061760edeb12,openstack/requirements,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",1,1
openstack%2Ffuel-library~master~I3d6de157d39b843f1f44c880f05100bb95214090,openstack/fuel-library,master,I3d6de157d39b843f1f44c880f05100bb95214090,New RA for galera/pacemaker.,ABANDONED,2014-06-24 07:41:40.000000000,2014-06-24 08:16:37.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-24 07:41:40.000000000', 'files': ['deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/galera/files/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2b91e8280aab6077d633b149fae373aba4c17fb3', 'message': '    New RA for galera/pacemaker.\n\n    Implements: blueprint galera-improvements\n    Closes-Bug: 1297355\n\n    Change-Id: I593d113b430d7607f92ff68ea269e071898a5068\n\nChange-Id: I3d6de157d39b843f1f44c880f05100bb95214090\n'}]",0,102140,2b91e8280aab6077d633b149fae373aba4c17fb3,8,2,1,10489,,,0,"    New RA for galera/pacemaker.

    Implements: blueprint galera-improvements
    Closes-Bug: 1297355

    Change-Id: I593d113b430d7607f92ff68ea269e071898a5068

Change-Id: I3d6de157d39b843f1f44c880f05100bb95214090
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/40/102140/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/galera/manifests/init.pp', 'deployment/puppet/galera/files/ocf/mysql-wss']",2,2b91e8280aab6077d633b149fae373aba4c17fb3,,"# Authors: Bartosz Kupidura (Mirantis): Rewrite RA to support mysql/galera # Sergii Golovatiuk (Mirantis): Rewrite RA to support mysql/galera # Alan Robertson: DB2 Script# Support: openstack@lists.launchpad.net# 2014 Mirantis Inc.OCF_RESKEY_client_binary_default=""/usr/bin/mysql""OCF_RESKEY_master_timeout_default=""300"": ${OCF_RESKEY_master_timeout=${OCF_RESKEY_master_timeout_default}}MYSQL_OPTIONS_LOCAL=""-S $OCF_RESKEY_socket --connect_timeout=10"" MYSQL_OPTIONS_TEST=""$MYSQL_OPTIONS_LOCAL --user=$OCF_RESKEY_test_user --password=$OCF_RESKEY_test_passwd""usage: $0 (start|stop|meta-data|validate-all|monitor)<resource-agent name=""mysql"" version=""0.1""> <version>0.1</version> <longdesc lang=""en""> Resource script for MySQL </longdesc> <shortdesc lang=""en"">Resource script for MySQL</shortdesc> <parameters> <parameter name=""binary"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the MySQL server binary </longdesc> <shortdesc lang=""en"">MySQL server binary</shortdesc> <content type=""string"" default=""${OCF_RESKEY_binary_default}"" /> </parameter> <parameter name=""client_binary"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the MySQL client binary </longdesc> <shortdesc lang=""en"">MySQL client binary</shortdesc> <content type=""string"" default=""${OCF_RESKEY_client_binary_default}"" /> </parameter> <parameter name=""config"" unique=""0"" required=""0""> <longdesc lang=""en""> Configuration file </longdesc> <shortdesc lang=""en"">MySQL config</shortdesc> <content type=""string"" default=""${OCF_RESKEY_config_default}"" /> </parameter> <parameter name=""datadir"" unique=""0"" required=""0""> <longdesc lang=""en""> Directory containing databases </longdesc> <shortdesc lang=""en"">Data directory</shortdesc> <content type=""string"" default=""${OCF_RESKEY_datadir_default}"" /> </parameter> <parameter name=""user"" unique=""0"" required=""0""> <longdesc lang=""en""> User running MySQL daemon </longdesc> <shortdesc lang=""en"">MySQL user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_user_default}"" /> </parameter> <parameter name=""group"" unique=""0"" required=""0""> <longdesc lang=""en""> Group running MySQL daemon (for logfile and directory permissions) </longdesc> <shortdesc lang=""en"">MySQL group</shortdesc> <content type=""string"" default=""${OCF_RESKEY_group_default}""/> </parameter> <parameter name=""pid"" unique=""0"" required=""0""> <longdesc lang=""en""> The pidfile to be used for mysqld. </longdesc> <shortdesc lang=""en"">MySQL pid file</shortdesc> <content type=""string"" default=""${OCF_RESKEY_pid_default}""/> </parameter> <parameter name=""socket"" unique=""0"" required=""0""> <longdesc lang=""en""> The socket to be used for mysqld. </longdesc> <shortdesc lang=""en"">MySQL socket</shortdesc> <content type=""string"" default=""${OCF_RESKEY_socket_default}""/> </parameter> <parameter name=""test_user"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL test user, must have select privilege on 'show status' </longdesc> <shortdesc lang=""en"">MySQL test user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_test_user_default}"" /> </parameter> <parameter name=""test_passwd"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL test user password </longdesc> <shortdesc lang=""en"">MySQL test user password</shortdesc> <content type=""string"" default=""${OCF_RESKEY_test_passwd_default}"" /> </parameter> <parameter name=""additional_parameters"" unique=""0"" required=""0""> <longdesc lang=""en""> Additional parameters which are passed to the mysqld on startup. (e.g. --skip-external-locking or --skip-grant-tables) </longdesc> <shortdesc lang=""en"">Additional parameters to pass to mysqld</shortdesc> <content type=""string"" default=""${OCF_RESKEY_additional_parameters_default}""/> </parameter> <parameter name=""master_timeout"" unique=""0"" required=""0""> <longdesc lang=""en""> How long we should wait for galera master. If master not come up before timeout, RA will choose new master from already running nodes. This value can by changed by crm_attribute: # crm_attribute --name galera_master_timeout --update 500 Remember to remove this after maintenance. USE WITH CAUTION! Remember to change timeout for start operation. Start timeout should be bigger than master_timeout </longdesc> <shortdesc lang=""en"">Galera master timeout</shortdesc> <content type=""integer"" default=""${OCF_RESKEY_master_timeout_default}""/> </parameter> </parameters> <actions> <action name=""start"" timeout=""330"" /> <action name=""stop"" timeout=""120"" /> <action name=""monitor"" timeout=""30"" interval=""20"" depth=""0"" /> <action name=""meta-data"" timeout=""5"" /> <action name=""validate-all"" timeout=""10"" /> </actions>####################################################################### nodes_in_cluster_online() { local NODES NODES=$(crm_node --partition) if [ ! -z ""$NODES"" ]; then echo $NODES echo} nodes_in_cluster() { local NODES #Ubuntu doesn't like \w NODES=$(crm_node --list | awk '/^[a-zA-Z0-9]/ {print $2}') if [ ! -z ""$NODES"" ]; then echo $NODES echo#Validate if GTID have correct format (return 0), else return 1 #valid values are: #XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX:123 - standard cluster-id:commit-id #XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX:-1 - standard non initialized cluster, 00000000-0000-0000-0000-000000000000:-1 validate_gtid() { local status_loglevel=""err"" if [ -z $1 ]; then ocf_log $status_loglevel ""No GTID provided"" echo $1 | grep -q -E '^\w{8}-\w{4}-\w{4}-\w{4}-\w{12}:([[:digit:]]|-1)' rc=$? if [ $rc -ne 0 ]; then ocf_log $status_loglevel ""GTID have wrong format: $1"" return 1 ocf_log info ""GTID OK: $1"" return 0#Get galera GTID from local mysql instance get_galera_gtid() { local rc local status_loglevel=""err"" # Set loglevel to info during probe if ocf_is_probe; then status_loglevel=""info"" fi mysql_status $status_loglevel 1 rc=$? if [ $rc -ne $OCF_SUCCESS ]; then GTID=$(${OCF_RESKEY_binary} --wsrep-recover --log-error=/dev/stdout 2>&1 | grep 'Recovered position' | awk '{print $NF}') else CLUSTER_ID=$($MYSQL $MYSQL_OPTIONS_TEST -s -N \ -e ""SHOW STATUS LIKE 'wsrep_local_state_uuid'"" | awk '{print $NF}') COMMIT_ID=$($MYSQL $MYSQL_OPTIONS_TEST -s -N \ -e ""SHOW STATUS LIKE 'wsrep_last_committed'"" | awk '{print $NF}') GTID=$CLUSTER_ID:$COMMIT_ID fi validate_gtid $GTID rc=$? if [ $rc -eq 0 ]; then echo $GTID else echo 0 fi } #Update gtid attribute for $HOSTNAME update_node_gtid() { local GTID GTID=$(get_galera_gtid) if [ ""$GTID"" != 0 ]; then crm_attribute --node $HOSTNAME --lifetime forever --name gtid --update $GTID else ocf_log err ""Wrong GTID, not updating gtid attribute"" fi } get_master_timeout() { local default=$OCF_RESKEY_master_timeout local rc local timeout=$(crm_attribute --name galera_master_timeout --query -d $default -q) echo $timeout else echo $default fi } #Get gtid attribute for $1 node, ""0"" means no GTID set or wrong format for GTID get_node_gtid() { local rc local GTID GTID=$(crm_attribute --quiet --node $1 --lifetime forever --query --name gtid 2> /dev/null) rc=$? if [ $rc -ne 0 -o -z ""$GTID"" ]; then ocf_log info ""No GTID for $1"" echo 0 validate_gtid $GTID rc=$? if [ $rc -eq 0 ]; then echo $GTID else ocf_log info ""No GTID for $1"" echo 0 ficheck_if_reelection_needed() { local PARTITION_WITH_QUORUM=$(crm_node -q) local RESOURCE_NAME=$(echo $OCF_RESOURCE_INSTANCE | cut -f1 -d"":"") local NODE_COUNT=$(nodes_in_cluster | wc -w) local RUNNING_INSTANCES if [ ""$PARTITION_WITH_QUORUM"" -eq 1 -o ""$NODE_COUNT"" -eq 1 ]; then RUNNING_INSTANCES=$(crm_resource --quiet --locate --resource $RESOURCE_NAME | wc -l 2> /dev/null) rc=$? if [ $rc -eq 0 -a ""$RUNNING_INSTANCES"" -lt 1 ]; then return 1 return 0 } choose_master() { local NODES=$1 local -A TMP for NODE in $NODES do NODE_ID=$(echo $NODE | cksum | awk '{print $1}') TMP[$NODE_ID]=$NODE done MASTER=$(printf -- '%s\n' ""${!TMP[@]}"" | sort | head -1) ocf_log info ""Choosed master: ${TMP[$MASTER]}"" echo ${TMP[$MASTER]} } get_possible_masters() { local NODES=$1 local POSSIBLE_MASTERS local -A TMP local MASTER_GTID local GTID for NODE in $NODES do GTID=$(get_node_gtid $NODE) TMP[$NODE]=$(echo $GTID|cut -d"":"" -f 2) done MASTER_GTID=$(printf -- '%s\n' ""${TMP[@]}"" | sort -r | head -1) for NODE in $NODES do if [ ""$MASTER_GTID"" -eq ${TMP[$NODE]} ]; then POSSIBLE_MASTERS=""$POSSIBLE_MASTERS $NODE"" fi done ocf_log info ""Possible masters: $POSSIBLE_MASTERS"" echo $POSSIBLE_MASTERS } check_if_galera_pc() { local NODES=$1 local MASTERS local last_timeout=$(get_master_timeout) local timeout=$last_timeout local sleeptime=30 local rc ocf_log info ""Checking if galera primary controller"" MASTERS=$(get_possible_masters ""$NODES"") MASTER=$(choose_master ""$MASTERS"") if [ ""$MASTER"" == ""$HOSTNAME"" ]; then return 1 else while [ ""$timeout"" -gt 0 ]; do sleep $sleeptime ocf_log info ""Waiting for master. $timeout seconds to go"" if [ $last_timeout -ne $(get_master_timeout) ]; then last_timeout=$(get_master_timeout) timeout=$last_timeout else timeout=$(($timeout-$sleeptime)) fi check_if_reelection_needed rc=$? if [ $rc -eq 0 ]; then return 0 fi done NODES=$(nodes_in_cluster_online) MASTERS=$(get_possible_masters ""$NODES"") MASTER=$(choose_master ""$MASTERS"") if [ ""$MASTER"" == ""$HOSTNAME"" ]; then return 1 fi fi return 0 } check_binary $OCF_RESKEY_client_binary i=${2:-3} sleeptime=${3:-5} ocf_log info ""PIDFile ${OCF_RESKEY_pid} of MySQL server not found. Sleeping for $sleeptime seconds. $(( i-1 )) retries left"" sleep $sleeptime break local WSREP_CONNECTED local WSREP_LOCAL_STATE local WSREP_READY update_node_gtid WSREP_CONNECTED=$($MYSQL $MYSQL_OPTIONS_TEST -s -N \ -e ""SHOW STATUS LIKE 'wsrep_connected'"" | awk '{print $NF}') rc=$? if [ $rc -ne 0 -o ""$WSREP_CONNECTED"" != ""ON"" ]; then return $OCF_ERR_GENERIC WSREP_LOCAL_STATE=$($MYSQL $MYSQL_OPTIONS_TEST -s -N \ -e ""SHOW STATUS LIKE 'wsrep_local_state'"" | awk '{print $NF}') rc=$? #Synced if [ $rc -eq 0 -a ""$WSREP_LOCAL_STATE"" == 4 ]; then WSREP_READY=$($MYSQL $MYSQL_OPTIONS_TEST -s -N \ -e ""SHOW STATUS LIKE 'wsrep_ready'"" | awk '{print $NF}') rc=$? #Synced but wsrep not ready if [ $rc -ne 0 -o ""$WSREP_READY"" != ""ON"" ]; then return $OCF_ERR_GENERIC fi ocf_log debug ""MySQL monitor succeeded""; return $OCF_SUCCESS local NODES mysql_status info 1 if [ -f /tmp/wsrep-init-file ]; then mysql_extra_params=""--init-file=/tmp/wsrep-init-file"" mysql_extra_params="""" NODES=$(nodes_in_cluster) check_if_reelection_needed rc=$? if [ $rc -eq 1 ]; then check_if_galera_pc ""$NODES"" rc=$? if [ $rc -eq 1 ]; then ocf_log info ""Im galera primary controller, join me!"" mysql_extra_params=""$mysql_extra_params --wsrep-cluster-address=gcomm://"" fi fi #ensure mysql is down killall mysqld mysqld_safe && sleep 15 killall -s KILL mysqld mysqld_safe && sleep 2 ${OCF_RESKEY_binary} \ --pid-file=$OCF_RESKEY_pid \ --socket=$OCF_RESKEY_socket \ --datadir=$OCF_RESKEY_datadir \ --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \ $mysql_extra_params >/dev/null 2>&1 & mysql_status info 1 mysql_status info 1 update_node_gtid","# # # MySQL # # Description: Manages a MySQL database as Linux-HA resource # # Authors: Alan Robertson: DB2 Script# Support: linux-ha@lists.linux-ha.org# # An example usage in /etc/ha.d/haresources: # node1 10.0.0.170 mysql # # See usage() function below for more details... # # OCF instance parameters: # OCF_RESKEY_binary # OCF_RESKEY_client_binary # OCF_RESKEY_config # OCF_RESKEY_datadir # OCF_RESKEY_user # OCF_RESKEY_group # OCF_RESKEY_test_table # OCF_RESKEY_test_user # OCF_RESKEY_test_passwd # OCF_RESKEY_enable_creation # OCF_RESKEY_additional_parameters # OCF_RESKEY_log # OCF_RESKEY_pid # OCF_RESKEY_socket # OCF_RESKEY_replication_user # OCF_RESKEY_replication_passwd # OCF_RESKEY_replication_port # OCF_RESKEY_max_slave_lag # OCF_RESKEY_evict_outdated_slaves # OCF_RESKEY_reader_attribute if [ ""X${HOSTOS}"" = ""XOpenBSD"" ];then OCF_RESKEY_binary_default=""/usr/local/bin/mysqld_safe"" OCF_RESKEY_config_default=""/etc/my.cnf"" OCF_RESKEY_datadir_default=""/var/mysql"" OCF_RESKEY_user_default=""_mysql"" OCF_RESKEY_group_default=""_mysql"" OCF_RESKEY_log_default=""/var/log/mysqld.log"" OCF_RESKEY_pid_default=""/var/mysql/mysqld.pid"" OCF_RESKEY_socket_default=""/var/run/mysql/mysql.sock"" elseOCF_RESKEY_log_default=""/var/log/mysqld.log""fi OCF_RESKEY_client_binary_default=""mysql""OCF_RESKEY_test_table_default=""mysql.user""OCF_RESKEY_enable_creation_default=0OCF_RESKEY_replication_port_default=""3306"" OCF_RESKEY_max_slave_lag_default=""3600"" OCF_RESKEY_evict_outdated_slaves_default=""false"" OCF_RESKEY_reader_attribute_default=""readable"": ${OCF_RESKEY_log=${OCF_RESKEY_log_default}}: ${OCF_RESKEY_test_table=${OCF_RESKEY_test_table_default}}: ${OCF_RESKEY_enable_creation=${OCF_RESKEY_enable_creation_default}} : ${OCF_RESKEY_replication_user=${OCF_RESKEY_replication_user_default}} : ${OCF_RESKEY_replication_passwd=${OCF_RESKEY_replication_passwd_default}} : ${OCF_RESKEY_replication_port=${OCF_RESKEY_replication_port_default}} : ${OCF_RESKEY_max_slave_lag=${OCF_RESKEY_max_slave_lag_default}} : ${OCF_RESKEY_evict_outdated_slaves=${OCF_RESKEY_evict_outdated_slaves_default}} : ${OCF_RESKEY_reader_attribute=${OCF_RESKEY_reader_attribute_default}}MYSQL_OPTIONS_LOCAL=""-S $OCF_RESKEY_socket --connect_timeout=10"" MYSQL_OPTIONS_REPL=""$MYSQL_OPTIONS_LOCAL --user=$OCF_RESKEY_replication_user --password=$OCF_RESKEY_replication_passwd"" MYSQL_OPTIONS_TEST=""$MYSQL_OPTIONS_LOCAL --user=$OCF_RESKEY_test_user --password=$OCF_RESKEY_test_passwd"" MYSQL_TOO_MANY_CONN_ERR=1040 CRM_MASTER=""${HA_SBIN_DIR}/crm_master -l reboot ""CRM_ATTR=""${HA_SBIN_DIR}/crm_attribute -N $HOSTNAME "" INSTANCE_ATTR_NAME=`echo ${OCF_RESOURCE_INSTANCE}| awk -F : '{print $1}'` CRM_ATTR_REPL_INFO=""${HA_SBIN_DIR}/crm_attribute --type crm_config --name ${INSTANCE_ATTR_NAME}_REPL_INFO -s mysql_replication"" usage: $0 (start|stop|validate-all|meta-data|monitor|promote|demote|notify)The 'status' operation reports whether the database is runningThe 'rebuild_cluster' should be called only when restoring cluster from broken state The 'promote' operation makes this mysql server run as master The 'demote' operation makes this mysql server run as slave<resource-agent name=""mysql""> <version>1.0</version> <longdesc lang=""en""> Resource script for MySQL. May manage a standalone MySQL database, a clone set with externally managed replication, or a complete master/slave replication setup. While managing replication, the default behavior is to use uname -n values in the change master to command. Other IPs can be specified manually by adding a node attribute \${INSTANCE_ATTR_NAME}_mysql_master_IP giving the IP to use for replication. For example, if the mysql primitive you are using is p_mysql, the attribute to set will be p_mysql_mysql_master_IP. </longdesc> <shortdesc lang=""en"">Manages a MySQL database instance</shortdesc> <parameters> <parameter name=""binary"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the MySQL server binary </longdesc> <shortdesc lang=""en"">MySQL server binary</shortdesc> <content type=""string"" default=""${OCF_RESKEY_binary_default}"" /> </parameter> <parameter name=""client_binary"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the MySQL client binary </longdesc> <shortdesc lang=""en"">MySQL client binary</shortdesc> <content type=""string"" default=""${OCF_RESKEY_client_binary_default}"" /> </parameter> <parameter name=""config"" unique=""0"" required=""0""> <longdesc lang=""en""> Configuration file </longdesc> <shortdesc lang=""en"">MySQL config</shortdesc> <content type=""string"" default=""${OCF_RESKEY_config_default}"" /> </parameter> <parameter name=""datadir"" unique=""0"" required=""0""> <longdesc lang=""en""> Directory containing databases </longdesc> <shortdesc lang=""en"">MySQL datadir</shortdesc> <content type=""string"" default=""${OCF_RESKEY_datadir_default}"" /> </parameter> <parameter name=""user"" unique=""0"" required=""0""> <longdesc lang=""en""> User running MySQL daemon </longdesc> <shortdesc lang=""en"">MySQL user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_user_default}"" /> </parameter> <parameter name=""group"" unique=""0"" required=""0""> <longdesc lang=""en""> Group running MySQL daemon (for logfile and directory permissions) </longdesc> <shortdesc lang=""en"">MySQL group</shortdesc> <content type=""string"" default=""${OCF_RESKEY_group_default}""/> </parameter> <parameter name=""log"" unique=""0"" required=""0""> <longdesc lang=""en""> The logfile to be used for mysqld. </longdesc> <shortdesc lang=""en"">MySQL log file</shortdesc> <content type=""string"" default=""${OCF_RESKEY_log_default}""/> </parameter> <parameter name=""pid"" unique=""0"" required=""0""> <longdesc lang=""en""> The pidfile to be used for mysqld. </longdesc> <shortdesc lang=""en"">MySQL pid file</shortdesc> <content type=""string"" default=""${OCF_RESKEY_pid_default}""/> </parameter> <parameter name=""socket"" unique=""0"" required=""0""> <longdesc lang=""en""> The socket to be used for mysqld. </longdesc> <shortdesc lang=""en"">MySQL socket</shortdesc> <content type=""string"" default=""${OCF_RESKEY_socket_default}""/> </parameter> <parameter name=""test_table"" unique=""0"" required=""0""> <longdesc lang=""en""> Table to be tested in monitor statement (in database.table notation) </longdesc> <shortdesc lang=""en"">MySQL test table</shortdesc> <content type=""string"" default=""${OCF_RESKEY_test_table_default}"" /> </parameter> <parameter name=""test_user"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL test user, must have select privilege on test_table </longdesc> <shortdesc lang=""en"">MySQL test user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_test_user_default}"" /> </parameter> <parameter name=""test_passwd"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL test user password </longdesc> <shortdesc lang=""en"">MySQL test user password</shortdesc> <content type=""string"" default=""${OCF_RESKEY_test_passwd_default}"" /> </parameter> <parameter name=""enable_creation"" unique=""0"" required=""0""> <longdesc lang=""en""> If the MySQL database does not exist, it will be created </longdesc> <shortdesc lang=""en"">Create the database if it does not exist</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_enable_creation_default}""/> </parameter> <parameter name=""additional_parameters"" unique=""0"" required=""0""> <longdesc lang=""en""> Additional parameters which are passed to the mysqld on startup. (e.g. --skip-external-locking or --skip-grant-tables) </longdesc> <shortdesc lang=""en"">Additional parameters to pass to mysqld</shortdesc> <content type=""string"" default=""${OCF_RESKEY_additional_parameters_default}""/> </parameter> <parameter name=""replication_user"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL replication user. This user is used for starting and stopping MySQL replication, for setting and resetting the master host, and for setting and unsetting read-only mode. Because of that, this user must have SUPER, REPLICATION SLAVE, REPLICATION CLIENT, and PROCESS privileges on all nodes within the cluster. Mandatory if you define a master-slave resource. </longdesc> <shortdesc lang=""en"">MySQL replication user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_replication_user_default}"" /> </parameter> <parameter name=""replication_passwd"" unique=""0"" required=""0""> <longdesc lang=""en""> MySQL replication password. Used for replication client and slave. Mandatory if you define a master-slave resource. </longdesc> <shortdesc lang=""en"">MySQL replication user password</shortdesc> <content type=""string"" default=""${OCF_RESKEY_replication_passwd_default}"" /> </parameter> <parameter name=""replication_port"" unique=""0"" required=""0""> <longdesc lang=""en""> The port on which the Master MySQL instance is listening. </longdesc> <shortdesc lang=""en"">MySQL replication port</shortdesc> <content type=""string"" default=""${OCF_RESKEY_replication_port_default}"" /> </parameter> <parameter name=""max_slave_lag"" unique=""0"" required=""0""> <longdesc lang=""en""> The maximum number of seconds a replication slave is allowed to lag behind its master. Do not set this to zero. What the cluster manager does in case a slave exceeds this maximum lag is determined by the evict_outdated_slaves parameter. </longdesc> <shortdesc lang=""en"">Maximum time (seconds) a MySQL slave is allowed to lag behind a master</shortdesc> <content type=""integer"" default=""${OCF_RESKEY_max_slave_lag_default}""/> </parameter> <parameter name=""evict_outdated_slaves"" unique=""0"" required=""0""> <longdesc lang=""en""> If set to true, any slave which is more than max_slave_lag seconds behind the master has its MySQL instance shut down. If this parameter is set to false in a primitive or clone resource, it is simply ignored. If set to false in a master/slave resource, then exceeding the maximum slave lag will merely push down the master preference so the lagging slave is never promoted to the new master. </longdesc> <shortdesc lang=""en"">Determines whether to shut down badly lagging slaves</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_evict_outdated_slaves_default}"" /> </parameter> <parameter name=""reader_attribute"" unique=""1"" required=""0""> <longdesc lang=""en""> An attribute that the RA can manage to specify whether a node can be read from. This node attribute will be 1 if it's fine to read from the node, and 0 otherwise (for example, when a slave has lagged too far behind the master). A typical example for the use of this attribute would be to tie a set of IP addresses to MySQL slaves that can be read from. This parameter is only meaningful in master/slave set configurations. </longdesc> <shortdesc lang=""en"">Sets the node attribute that determines whether a node is usable for clients to read from.</shortdesc> <content type=""string"" default=""${OCF_RESKEY_reader_attribute_default}"" /> </parameter> </parameters> <actions> <action name=""start"" timeout=""145"" /> <action name=""stop"" timeout=""145"" /> <action name=""status"" timeout=""85"" /> <action name=""monitor"" depth=""0"" timeout=""55"" interval=""20"" /> <action name=""monitor"" role=""Master"" depth=""0"" timeout=""55"" interval=""10"" /> <action name=""monitor"" role=""Slave"" depth=""0"" timeout=""55"" interval=""30"" /> <action name=""promote"" timeout=""120"" /> <action name=""demote"" timeout=""120"" /> <action name=""notify"" timeout=""90"" /> <action name=""validate-all"" timeout=""5"" /> <action name=""meta-data"" timeout=""5"" /> </actions> set_read_only() { # Sets or unsets read-only mode. Accepts one boolean as its # optional argument. If invoked without any arguments, defaults to # enabling read only mode. Should only be set in master/slave # setups. # Returns $OCF_SUCCESS if the operation succeeds, or # $OCF_ERR_GENERIC if it fails. local ro_val if ocf_is_true $1; then ro_val=""on"" ro_val=""off"" ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""SET GLOBAL read_only=${ro_val}"" } get_read_only() { # Check if read-only is set local read_only_state read_only_state=`$MYSQL $MYSQL_OPTIONS_REPL \ -e ""SHOW VARIABLES"" | grep read_only | awk '{print $2}'` if [ ""$read_only_state"" = ""ON"" ]; then return 0 return 1is_slave() { # Determine whether the machine is currently running as a MySQL # slave, as determined per SHOW SLAVE STATUS. Returns 1 if SHOW # SLAVE STATUS creates an empty result set, 0 otherwise. local tmpfile # Check whether this machine should be slave if ! ocf_is_ms || ! get_read_only; then get_slave_info rc=$? if [ $rc -eq 0 ]; then # show slave status is not empty # Is there a master_log_file defined? (master_log_file is deleted # by reset slave if [ ""$master_log_file"" ]; then return 0 else return 1 fi else # ""SHOW SLAVE STATUS"" returns an empty set if instance is not a # replication slave return 1 fi } parse_slave_info() { # Extracts field $1 from result of ""SHOW SLAVE STATUS\G"" from file $2 sed -ne ""s/^.* $1: \(.*\)$/\1/p"" < $2 } get_slave_info() { # Warning: this sets $tmpfile and LEAVE this file! You must delete it after use! local mysql_options if [ ""$master_log_file"" -a ""$master_host"" ]; then # variables are already defined, get_slave_info has been run before return $OCF_SUCCESS tmpfile=`mktemp ${HA_RSCTMP}/check_slave.${OCF_RESOURCE_INSTANCE}.XXXXXX` $MYSQL $MYSQL_OPTIONS_REPL \ -e 'SHOW SLAVE STATUS\G' > $tmpfile if [ -s $tmpfile ]; then master_host=`parse_slave_info Master_Host $tmpfile` master_user=`parse_slave_info Master_User $tmpfile` master_port=`parse_slave_info Master_Port $tmpfile` master_log_file=`parse_slave_info Master_Log_File $tmpfile` master_log_pos=`parse_slave_info Read_Master_Log_Pos $tmpfile` slave_sql=`parse_slave_info Slave_SQL_Running $tmpfile` slave_io=`parse_slave_info Slave_IO_Running $tmpfile` last_errno=`parse_slave_info Last_Errno $tmpfile` secs_behind=`parse_slave_info Seconds_Behind_Master $tmpfile` ocf_log debug ""MySQL instance running as a replication slave"" else # Instance produced an empty ""SHOW SLAVE STATUS"" output -- # instance is not a slave ocf_log err ""check_slave invoked on an instance that is not a replication slave."" return $OCF_ERR_GENERIC fi return $OCF_SUCCESScheck_slave() { # Checks slave status local rc new_master get_slave_info # Did we receive an error other than max_connections? if [ $last_errno -ne 0 -a $last_errno -ne ""$MYSQL_TOO_MANY_CONN_ERR"" ]; then # Whoa. Replication ran into an error. This slave has # diverged from its master. Make sure this resource # doesn't restart in place. ocf_log err ""MySQL instance configured for replication, but replication has failed."" ocf_log err ""See $tmpfile for details"" # Just pull the reader VIP away, killing MySQL here would be pretty evil # on a loaded server set_reader_attr 0 exit $OCF_SUCCESS fi # If we got max_connections, let's remove the vip if [ $last_errno -eq ""$MYSQL_TOO_MANY_CONN_ERR"" ]; then set_reader_attr 0 exit $OCF_SUCCESS fi if [ ""$slave_io"" != 'Yes' ]; then # Not necessarily a bad thing. The master may have # temporarily shut down, and the slave may just be # reconnecting. A warning can't hurt, though. ocf_log warn ""MySQL Slave IO threads currently not running."" # Sanity check, are we at least on the right master new_master=`$CRM_ATTR_REPL_INFO --query -q | cut -d'|' -f1` if [ ""$master_host"" != ""$new_master"" ]; then # Not pointing to the right master, not good, removing the VIPs set_reader_attr 0 exit $OCF_SUCCESS fi fi if [ ""$slave_sql"" != 'Yes' ]; then # We don't have a replication SQL thread running. Not a # good thing. Try to recoved by restarting the SQL thread # and remove reader vip. Prevent MySQL restart. ocf_log err ""MySQL Slave SQL threads currently not running."" ocf_log err ""See $tmpfile for details"" # Remove reader vip set_reader_attr 0 # try to restart slave ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""START SLAVE"" # Return success to prevent a restart exit $OCF_SUCCESS fi if ocf_is_true $OCF_RESKEY_evict_outdated_slaves; then # We're supposed to bail out if we lag too far # behind. Let's check our lag. if [ $secs_behind -gt $OCF_RESKEY_max_slave_lag ]; then ocf_log err ""MySQL Slave is $secs_behind seconds behind master (allowed maximum: $OCF_RESKEY_max_slave_lag)."" ocf_log err ""See $tmpfile for details"" # Remove reader vip set_reader_attr 0 exit $OCF_ERR_INSTALLED fi elif ocf_is_ms; then # Even if we're not set to evict lagging slaves, we can # still use the seconds behind master value to set our # master preference. local master_pref master_pref=$((${OCF_RESKEY_max_slave_lag}-${secs_behind})) if [ $master_pref -lt 0 ]; then # Sanitize a below-zero preference to just zero master_pref=0 fi $CRM_MASTER -v $master_pref fi # is the slave ok to have a VIP on it if [ $secs_behind -gt $OCF_RESKEY_max_slave_lag ]; then set_reader_attr 0 else set_reader_attr 1 fi ocf_log debug ""MySQL instance running as a replication slave"" rm -f $tmpfile # Instance produced an empty ""SHOW SLAVE STATUS"" output -- # instance is not a slave # TODO: Needs to handle when get_slave_info will return too many connections error rm -f $tmpfile ocf_log err ""check_slave invoked on an instance that is not a replication slave."" exit $OCF_ERR_GENERICset_master() { local new_master master_log_file master_log_pos local master_params new_master=`$CRM_ATTR_REPL_INFO --query -q | cut -d'|' -f1` # Keep replication position get_slave_info if [ ""$master_log_file"" -a ""$new_master"" = ""$master_host"" ]; then # master_params="", MASTER_LOG_FILE='$master_log_file', \ # MASTER_LOG_POS=$master_log_pos"" ocf_log info ""Kept master pos for $master_host : $master_log_file:$master_log_pos"" rm -f $tmpfile return else master_log_file=`$CRM_ATTR_REPL_INFO --query -q | cut -d'|' -f2` master_log_pos=`$CRM_ATTR_REPL_INFO --query -q | cut -d'|' -f3` if [ -n ""$master_log_file"" -a -n ""$master_log_pos"" ]; then master_params="", MASTER_LOG_FILE='$master_log_file', \ MASTER_LOG_POS=$master_log_pos"" ocf_log info ""Restored master pos for $new_master : $master_log_file:$master_log_pos"" fi fi # Informs the MySQL server of the master to replicate # from. Accepts one mandatory argument which must contain the host # name of the new master host. The master must either be unchanged # from the laste master the slave replicated from, or freshly # reset with RESET MASTER. ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""CHANGE MASTER TO MASTER_HOST='$new_master', \ MASTER_USER='$OCF_RESKEY_replication_user', \ MASTER_PASSWORD='$OCF_RESKEY_replication_passwd' $master_params"" rm -f $tmpfile } unset_master(){ # Instructs the MySQL server to stop replicating from a master # host. # If we're currently not configured to be replicating from any # host, then there's nothing to do. But we do log a warning as # no-one but the CRM should be touching the MySQL master/slave # configuration. if ! is_slave; then ocf_log warn ""Attempted to unset the replication master on an instance that is not configured as a replication slave"" return $OCF_SUCCESS fi local tmpfile tmpfile=`mktemp ${HA_RSCTMP}/unset_master.${OCF_RESOURCE_INSTANCE}.XXXXXX` # At this point, the master is read only so there should not be much binlogs to transfer # Let's wait for the last bits while true; do $MYSQL $MYSQL_OPTIONS_REPL \ -e 'SHOW PROCESSLIST\G' > $tmpfile if grep -i 'Waiting for master to send event' $tmpfile >/dev/null; then ocf_log info ""MySQL slave has finished reading master binary log"" break fi if grep -i 'Reconnecting after a failed master event read' $tmpfile >/dev/null; then ocf_log info ""Master is down, no more binary logs to come"" break fi if grep -i 'Connecting to master' $tmpfile >/dev/null; then ocf_log info ""Master is down, no more binary logs to come"" break fi if ! grep 'system user' $tmpfile >/dev/null; then ocf_log info ""Slave is not running - not waiting to finish"" break fi sleep 1 done # Now, stop the slave I/O thread and wait for relay log # processing to complete ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""STOP SLAVE IO_THREAD"" if [ $? -gt 0 ]; then ocf_log err ""Error stopping slave IO thread"" exit $OCF_ERR_GENERIC fi while true; do $MYSQL $MYSQL_OPTIONS_REPL \ -e 'SHOW PROCESSLIST\G' > $tmpfile if grep -i 'Has read all relay log' $tmpfile >/dev/null; then ocf_log info ""MySQL slave has finished processing relay log"" break fi if ! grep -q 'system user' $tmpfile; then ocf_log info ""Slave not runnig - not waiting to finish"" break fi ocf_log info ""Waiting for MySQL slave to finish processing relay log"" sleep 1 done rm -f $tmpfile # Now, stop all slave activity and unset the master host ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""STOP SLAVE"" if [ $? -gt 0 ]; then ocf_log err ""Error stopping rest slave threads"" exit $OCF_ERR_GENERIC fi ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""RESET SLAVE;"" if [ $? -gt 0 ]; then ocf_log err ""Failed to reset slave"" exit $OCF_ERR_GENERIC fi } # Start replication as slave start_slave() { ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""START SLAVE"" } # Set the attribute controlling the readers VIP set_reader_attr() { local curr_attr_value curr_attr_value=$(get_reader_attr) if [ ""$curr_attr_value"" -ne ""$1"" ]; then $CRM_ATTR -l reboot --name ${OCF_RESKEY_reader_attribute} -v $1 fi } # get the attribute controlling the readers VIP get_reader_attr() { local attr_value attr_value=`$CRM_ATTR -l reboot --name ${OCF_RESKEY_reader_attribute} --query -q` rc=$? if [ ""$rc"" -eq ""0"" ]; then echo $attr_value else echo -1 fi } rebuild_cluster() { if [ ""$(crm_attribute -t crm_config --name mysqlprimaryinit --query 2> /dev/null | awk -F\= '{print $4}')"" = 'done' ] && [ ! -f /tmp/wsrep-init-file ]; then mysql_status info if [ $? = $OCF_SUCCESS ] ; then WSREP_EPOCH=$(echo 'show status;' | mysql -u root | grep wsrep_protocol_version | awk '{print $2}') WSREP_STATE=$(echo 'show status;' | mysql -u root | grep wsrep_cluster_status | awk '{print $2}') if [ ""$WSREP_STATE"" = 'non-Primary' ]; then WINNER_NODE=$(hostname) MAX_EPOCH=$WSREP_EPOCH crm_attribute -t crm_config --node $(hostname) --name mysqlepoch --update $WSREP_EPOCH # Seems to be more or less legitimate solution explicitly for ""datacenter power switch"" situation: # - first of all, more complex logic does not bring more precise knowledge of which node # should be a master, because it related to such property as an epoch and user may simply # decide to not start node which was online during entire disaster holding ""bad"" data. # - sleeping until majority of quorum is up to continue or just try to rebuild cluster after five # minutes a bit less conditionally ocf_log info ""Waiting up to 300 seconds before trying to assemble the cluster..."" for i in $(seq 1 60); do crm status | grep -q 'partition with quorum' if [ $? -eq 0 ]; then break else if [ $((i % 30)) -eq 0 ]; then ocf_log info ""Galera still waiting for Corosync quorum..."" fi sleep 5 fi done # Allow recently joined nodes to fire up mysql process, 5 seconds from inside start() and 5 seconds for process itself sleep 10 # Check if someone already decided to declare himself master... RAISED_MASTER=$(crm_attribute -t crm_config --name mysqlmaster --query 2> /dev/null | awk -F\= '{print $4}') # ... and if nobody did: CRM_ONLINE_NODES=( $(crm node list | grep -v \(offline\) | sed 's/\://g') ) for node in ""${CRM_ONLINE_NODES[@]}"" ; do CUR_EPOCH=$(crm_attribute -t crm_config --node $node --name mysqlepoch --query 2> /dev/null | awk -F\= '{print $4}') if [ -z ""$CUR_EPOCH"" ] ; then echo ""Skipping comparison with node $node"" else if [ ""$(echo ''$CUR_EPOCH' > '$MAX_EPOCH'' | bc)"" -eq '1' ] ; then WINNER_NODE=$node MAX_EPOCH=$CUR_EPOCH fi fi done if [ ""$RAISED_MASTER"" != '1' ]; then if [ ""$WINNER_NODE"" = ""$(hostname)"" ] ; then crm_attribute -t crm_config --name mysqlmaster --update 1 ocf_log info ""Assuming current node as a new master..."" mysql_stop ${OCF_RESKEY_binary} \ --pid-file=$OCF_RESKEY_pid \ --datadir=$OCF_RESKEY_datadir \ --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \ $mysql_extra_params --wsrep-cluster-address=""gcomm://"" >/dev/null 2>&1 & crm_attribute -t crm_config --name mysqlmaster --delete fi else ocf_log info ""Master flag was already set, skipping our (probably legitimate yet) promotion"" fi else return $OCF_SUCCESS fi} # Stores data for MASTER STATUS from MySQL update_data_master_status() { master_status_file=""${HA_RSCTMP}/master_status.${OCF_RESOURCE_INSTANCE}"" $MYSQL $MYSQL_OPTIONS_REPL -e ""SHOW MASTER STATUS\G"" > $master_status_file } # Returns the specified value from the stored copy of SHOW MASTER STATUS. # should be call after update_data_master_status for tmpfile # Arguments: # $1 The value to get. get_master_status() { awk -v var=""$1"" '$1 == var "":"" {print substr($0, index($0, "":"") + 2)}' ""$master_status_file"" } # Determines what IP address is attached to the current host. The output of the # crm_attribute command looks like this: # scope=nodes name=IP value=10.2.2.161 # If the ${INSTANCE_ATTR_NAME}_MYSQL_MASTER_IP node attribute is not defined, fallback is to uname -n # The ${INSTANCE_ATTR_NAME}_MYSQL_MASTER_IP is the IP address that will be used for the # change master to command. get_local_ip() { local IP IP=`$CRM_ATTR -l forever -n ${INSTANCE_ATTR_NAME}_mysql_master_IP -q -G` if [ ! $? -eq 0 ]; then uname -n else echo $IP fi } ####################################################################### check_binary $OCF_RESKEY_client_binary i=5 sleeptime=5 ocf_log info ""PIDFile ${OCF_RESKEY_pid} of MySQL server not found. Sleeping for $sleeptime seconds. $(( i-1 )) retries left"" sleep $sleeptime break # TODO: check max connections error # If status returned an error, return that immediately if [ $OCF_CHECK_LEVEL -gt 0 -a -n ""$OCF_RESKEY_test_table"" ]; then # Check if this instance is configured as a slave, and if so # check slave status if is_slave; then check_slave fi # Check for test table ocf_run -q $MYSQL $MYSQL_OPTIONS_TEST \ -e ""SELECT COUNT(*) FROM $OCF_RESKEY_test_table"" rc=$? if [ $rc -ne 0 ]; then ocf_log err ""Failed to select from $test_table""; return $OCF_ERR_GENERIC; fi if ocf_is_ms && ! get_read_only; then ocf_log debug ""MySQL monitor succeeded (master)""; return $OCF_RUNNING_MASTER else ocf_log debug ""MySQL monitor succeeded""; return $OCF_SUCCESS if ocf_is_ms; then # Initialize the ReaderVIP attribute, monitor will enable it set_reader_attr 0 fi mysql_status info touch $OCF_RESKEY_log chown $OCF_RESKEY_user:$OCF_RESKEY_group $OCF_RESKEY_log chmod 0640 $OCF_RESKEY_log [ -x /sbin/restorecon ] && /sbin/restorecon $OCF_RESKEY_log if ocf_is_true ""$OCF_RESKEY_enable_creation"" && [ ! -d $OCF_RESKEY_datadir/mysql ] ; then ocf_log info ""Initializing MySQL database: "" $MYSQL_BINDIR/mysql_install_db --datadir=$OCF_RESKEY_datadir rc=$? if [ $rc -ne 0 ] ; then ocf_log err ""Initialization failed: $rc""; exit $OCF_ERR_GENERIC fi chown -R $OCF_RESKEY_user:$OCF_RESKEY_group $OCF_RESKEY_datadir fi # Uncomment to perform permission clensing # - not convinced this should be enabled by default # #chmod 0755 $OCF_RESKEY_datadir #chown -R $OCF_RESKEY_user $OCF_RESKEY_datadir #chgrp -R $OCF_RESKEY_group $OCF_RESKEY_datadir mysql_extra_params= if ocf_is_ms; then mysql_extra_params=""--skip-slave-start"" fi if [ -f /tmp/wsrep-init-file ] ; then killall mysqld mysqld_safe sleep 15 killall -s KILL mysqld mysqld_safe sleep 2 if [ ""$(crm_attribute -t crm_config --name mysqlprimaryinit --query 2> /dev/null | awk -F\= '{print $4}')"" = 'done' ] ; then ${OCF_RESKEY_binary} \ --pid-file=$OCF_RESKEY_pid \ --datadir=$OCF_RESKEY_datadir \ --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \ --init-file=/tmp/wsrep-init-file $mysql_extra_params >/dev/null 2>&1 & else ${OCF_RESKEY_binary} \ --pid-file=$OCF_RESKEY_pid \ --datadir=$OCF_RESKEY_datadir \ --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \ --init-file=/tmp/wsrep-init-file --wsrep-cluster-address=gcomm:// $mysql_extra_params >/dev/null 2>&1 & fi ${OCF_RESKEY_binary} \ --pid-file=$OCF_RESKEY_pid \ --datadir=$OCF_RESKEY_datadir \ --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \ $mysql_extra_params >/dev/null 2>&1 & if ocf_is_ms; then # We're configured as a stateful resource. We must start as # slave by default. At this point we don't know if the CRM has # already promoted a master. So, we simply start in read only # mode. set_read_only on # Now, let's see whether there is a master. We might be a new # node that is just joining the cluster, and the CRM may have # promoted a master before. master_host=`echo $OCF_RESKEY_CRM_meta_notify_master_uname|tr -d "" ""` if [ ""$master_host"" -a ""$master_host"" != ${HOSTNAME} ]; then ocf_log info ""Changing MySQL configuration to replicate from $master_host."" set_master start_slave if [ $? -ne 0 ]; then ocf_log err ""Failed to start slave"" return $OCF_ERR_GENERIC fi else ocf_log info ""No MySQL master present - clearing replication state"" unset_master fi # We also need to set a master preference, otherwise Pacemaker # won't ever promote us in the absence of any explicit # preference set by the administrator. We choose a low # greater-than-zero preference. $CRM_MASTER -v 1 fi # Initial monitor action if [ -n ""$OCF_RESKEY_test_table"" -a -n ""$OCF_RESKEY_test_user"" -a -n ""$OCF_RESKEY_test_passwd"" ]; then OCF_CHECK_LEVEL=10 fi mysql_monitor rc=$? if [ $rc != $OCF_SUCCESS -a $rc != $OCF_RUNNING_MASTER ]; then ocf_log err ""Failed initial monitor action"" return $rc fi sleep 5 rebuild_cluster if ocf_is_ms; then # clear preference for becoming master $CRM_MASTER -D # Remove VIP capability set_reader_attr 0 fi if [ -n ""$OCF_RESKEY_CRM_meta_timeout"" ]; then shutdown_timeout=$((($OCF_RESKEY_CRM_meta_timeout/1000)-5)) fi mysql_status info mysql_status info return $OCF_SUCCESS } mysql_promote() { local master_info if ( ! mysql_status err ); then return $OCF_NOT_RUNNING fi ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""STOP SLAVE"" # Set Master Info in CIB, cluster level attribute update_data_master_status master_info=""$(get_local_ip)|$(get_master_status File)|$(get_master_status Position)"" ${CRM_ATTR_REPL_INFO} -v ""$master_info"" rm -f $tmpfile set_read_only off || return $OCF_ERR_GENERIC # Existing master gets a higher-than-default master preference, so # the cluster manager does not shuffle the master role around # unnecessarily $CRM_MASTER -v $((${OCF_RESKEY_max_slave_lag}+1)) # A master can accept reads set_reader_attr 1mysql_demote() { if ! mysql_status err; then return $OCF_NOT_RUNNING fi # Return master preference to default, so the cluster manager gets # a chance to select a new master $CRM_MASTER -v 1 } mysql_notify() { # If not configured as a Stateful resource, we make no sense of # notifications. if ! ocf_is_ms; then ocf_log info ""This agent makes no use of notifications unless running in master/slave mode."" return $OCF_SUCCESS fi local type_op type_op=""${OCF_RESKEY_CRM_meta_notify_type}-${OCF_RESKEY_CRM_meta_notify_operation}"" ocf_log debug ""Received $type_op notification."" case ""$type_op"" in 'pre-promote') # Nothing to do now here, new replication info not yet published ;; 'post-promote') # The master has completed its promotion. Now is a good # time to check whether our replication slave is working # correctly. master_host=`echo $OCF_RESKEY_CRM_meta_notify_promote_uname|tr -d "" ""` if [ ""$master_host"" = ${HOSTNAME} ]; then ocf_log info ""This will be the new master, ignoring post-promote notification."" else ocf_log info ""Resetting replication"" unset_master if [ $? -ne 0 ]; then return $OCF_ERR_GENERIC fi ocf_log info ""Changing MySQL configuration to replicate from $master_host"" set_master if [ $? -ne 0 ]; then return $OCF_ERR_GENERIC fi start_slave if [ $? -ne 0 ]; then ocf_log err ""Failed to start slave"" return $OCF_ERR_GENERIC fi fi return $OCF_SUCCESS ;; 'pre-demote') demote_host=`echo $OCF_RESKEY_CRM_meta_notify_demote_uname|tr -d "" ""` if [ $demote_host = ${HOSTNAME} ]; then ocf_log info ""post-demote notification for $demote_host"" set_read_only on if [ $? -ne 0 ]; then ocf_log err ""Failed to set read-only""; return $OCF_ERR_GENERIC; fi # Must kill all existing user threads because they are still Read/write # in order for the slaves to complete the read of binlogs local tmpfile tmpfile=`mktemp ${HA_RSCTMP}/threads.${OCF_RESOURCE_INSTANCE}.XXXXXX` $MYSQL $MYSQL_OPTIONS_REPL \ -e ""SHOW PROCESSLIST"" > $tmpfile for thread in `awk '$0 !~ /Binlog Dump|system user|event_scheduler|SHOW PROCESSLIST/ && $0 ~ /^[0-9]/ {print $1}' $tmpfile` do ocf_run $MYSQL $MYSQL_OPTIONS_REPL \ -e ""KILL ${thread}"" done else ocf_log info ""Ignoring post-demote notification execpt for my own demotion."" fi return $OCF_SUCCESS ;; 'post-demote') demote_host=`echo $OCF_RESKEY_CRM_meta_notify_demote_uname|tr -d "" ""` if [ $demote_host = ${HOSTNAME} ]; then ocf_log info ""Ignoring post-demote notification for my own demotion."" return $OCF_SUCCESS fi ocf_log info ""post-demote notification for $demote_host."" # The former master has just been gracefully demoted. unset_master ;; *) return $OCF_SUCCESS ;; esac } ####################################################################### status) exit $LSB_STATUS_STOPPED;; status) mysql_status err;; promote) mysql_promote;; demote) mysql_demote;; notify) mysql_notify;;",405,1037
openstack%2Frally~master~I8307ec33dd93ef055450f58d7cd55bf6b200f249,openstack/rally,master,I8307ec33dd93ef055450f58d7cd55bf6b200f249,Refactor tempest config generator,MERGED,2014-06-20 14:10:31.000000000,2014-06-24 08:14:26.000000000,2014-06-23 22:52:26.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-06-20 14:10:31.000000000', 'files': ['tests/verification/verifiers/test_config.py', 'tests/verification/verifiers/test_tempest.py', 'rally/verification/verifiers/tempest/config.py', 'rally/verification/verifiers/tempest/tempest.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b9a1fab7a0522d26ba2116b9dd6a3874a8a5f987', 'message': ""Refactor tempest config generator\n\nUse `requests` library instead of `urllib2` & `httplib`\nMain profit from `requests` library:\n- `requests` is HTTP for Humans;\n- `requests` is well documented[1];\n- `requests` can save downloaded files by parts, so usage of memory\nis less(useful when downloading big data, for example - some images)\n- `requests` has same name as in Python 2x and Python 3x\n\nUse `inspect.getmembers`[2][3] for discovery of each function for section\ngenerator. Profit : decrease lines of code\n\nAdd checks for existence of subnet in 'network' section.\n\nMove function `_write_config`[4] from class `Tempest`[5] to `TempestConf`.\nReason: this function not related to verifier for Tempest.\n\nFix message for exception when user doesn't have admin role.\n\nMove name of section into kwargs to each section function.\nProfit: less string objects with section names\n\n[1] - http://docs.python-requests.org/en/latest/\n[2] - https://docs.python.org/2/library/inspect.html#types-and-members\n[3] - https://docs.python.org/3.3/library/inspect.html#types-and-members\n[4] - http://git.io/E1zPOQ\n[5] - http://git.io/8Ru-Yw\n\nChange-Id: I8307ec33dd93ef055450f58d7cd55bf6b200f249\n""}]",0,101557,b9a1fab7a0522d26ba2116b9dd6a3874a8a5f987,32,5,1,9545,,,0,"Refactor tempest config generator

Use `requests` library instead of `urllib2` & `httplib`
Main profit from `requests` library:
- `requests` is HTTP for Humans;
- `requests` is well documented[1];
- `requests` can save downloaded files by parts, so usage of memory
is less(useful when downloading big data, for example - some images)
- `requests` has same name as in Python 2x and Python 3x

Use `inspect.getmembers`[2][3] for discovery of each function for section
generator. Profit : decrease lines of code

Add checks for existence of subnet in 'network' section.

Move function `_write_config`[4] from class `Tempest`[5] to `TempestConf`.
Reason: this function not related to verifier for Tempest.

Fix message for exception when user doesn't have admin role.

Move name of section into kwargs to each section function.
Profit: less string objects with section names

[1] - http://docs.python-requests.org/en/latest/
[2] - https://docs.python.org/2/library/inspect.html#types-and-members
[3] - https://docs.python.org/3.3/library/inspect.html#types-and-members
[4] - http://git.io/E1zPOQ
[5] - http://git.io/8Ru-Yw

Change-Id: I8307ec33dd93ef055450f58d7cd55bf6b200f249
",git fetch https://review.opendev.org/openstack/rally refs/changes/57/101557/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/verification/verifiers/test_config.py', 'tests/verification/verifiers/test_tempest.py', 'rally/verification/verifiers/tempest/config.py', 'rally/verification/verifiers/tempest/tempest.py']",4,b9a1fab7a0522d26ba2116b9dd6a3874a8a5f987,a_bit_of_refactoring, config.TempestConf(self.deploy_id).generate(self.config_file)," def _write_config(self, conf): with open(self.config_file, ""w+"") as f: conf.write(f) conf = config.TempestConf(self.deploy_id).generate() self._write_config(conf)",117,104
openstack%2Fhorizon~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/horizon,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-23 23:59:30.000000000,2014-06-24 08:01:56.000000000,2014-06-24 08:01:55.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 4264}, {'_account_id': 6610}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 23:59:30.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1cffe83d1d265421b8aae75e54e3ec13b2215f40', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102059,1cffe83d1d265421b8aae75e54e3ec13b2215f40,12,5,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/102059/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,1cffe83d1d265421b8aae75e54e3ec13b2215f40,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fceilometer~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/ceilometer,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-24 00:26:08.000000000,2014-06-24 08:00:58.000000000,2014-06-24 08:00:58.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-06-24 00:26:08.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f3e3cac23a9a7010b4c4439375871fc326448617', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102066,f3e3cac23a9a7010b4c4439375871fc326448617,8,3,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/66/102066/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f3e3cac23a9a7010b4c4439375871fc326448617,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fsahara~master~Ic57a2184817f9df16451b8fce784585039f92d6f,openstack/sahara,master,Ic57a2184817f9df16451b8fce784585039f92d6f,Small fixes in README migration file,MERGED,2014-06-23 16:27:23.000000000,2014-06-24 08:00:52.000000000,2014-06-24 08:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-06-23 16:27:23.000000000', 'files': ['sahara/db/migration/alembic_migrations/README.md'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f69a429573d4e200db8d0db4f3e7af5514ad749', 'message': 'Small fixes in README migration file\n\n* Rename file to README.md. This needed to correctly display file on github\n* Many style fixes\n\nChange-Id: Ic57a2184817f9df16451b8fce784585039f92d6f\n'}]",0,101949,9f69a429573d4e200db8d0db4f3e7af5514ad749,12,6,1,7710,,,0,"Small fixes in README migration file

* Rename file to README.md. This needed to correctly display file on github
* Many style fixes

Change-Id: Ic57a2184817f9df16451b8fce784585039f92d6f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/49/101949/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/db/migration/alembic_migrations/README.md'],1,9f69a429573d4e200db8d0db4f3e7af5514ad749,fix-typo-migr,"The migrations in `alembic_migrations/versions` contain the changes needed to migrate$ sahara-db-manage --config-file /path/to/sahara.conf upgrade <start version>:<end version> --sql$ sahara-db-manage --config-file /path/to/sahara.conf upgrade --delta <# of revs>$ sahara-db-manage --config-file /path/to/sahara.conf downgrade --delta <# of revs>$ sahara-db-manage --config-file /path/to/sahara.conf revision -m ""description of revision"" --autogenerate$ sahara-db-manage --config-file /path/to/sahara.conf revision -m ""description of revision""$ sahara-db-manage --config-file /path/to/sahara.conf check_migration$ sahara-db-manage --config-file /path/to/sahara.conf history","The migrations in alembic_migrations/versions contain the changes needed to migrate$ sahara-db-manage --config-file /path/to/sahara.conf upgrade \ <start version>:<end version> --sql$ sahara-db-manage --config-file /path/to/sahara.conf upgrade --delta \ <# of revs>$ sahara-db-manage --config-file /path/to/sahara.conf downgrade --delta \ <# of revs>$ sahara-db-manage --config-file /path/to/sahara.conf revision \ -m ""description of revision"" --autogenerate$ sahara-db-manage --config-file /path/to/sahara.conf revision \ -m ""description of revision"" $ sahara-db-manage --config-file /path/to/sahara.conf check_migration $ sahara-db-manage --config-file /path/to/sahara.conf history",8,13
openstack%2Fhorizon~master~Iacefbba64ee0cc534c3129a1c4b28025294c6b08,openstack/horizon,master,Iacefbba64ee0cc534c3129a1c4b28025294c6b08,Do not render port template if device has no port,MERGED,2014-05-20 15:30:20.000000000,2014-06-24 07:58:08.000000000,2014-06-24 07:58:07.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 6825}, {'_account_id': 6914}, {'_account_id': 8411}, {'_account_id': 8648}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9531}, {'_account_id': 9659}]","[{'number': 1, 'created': '2014-05-20 15:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0bb43e66e51fa8eb29be2e706253c4226642fe2f', 'message': 'Do not render port template if device has no port\n\nChange-Id: Iacefbba64ee0cc534c3129a1c4b28025294c6b08\n'}, {'number': 2, 'created': '2014-05-22 01:57:58.000000000', 'files': ['horizon/static/horizon/js/horizon.networktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/78f8ba232199966c048c9aaef33f9f92a74cd8be', 'message': 'Do not render port template if device has no port\n\nChange-Id: Iacefbba64ee0cc534c3129a1c4b28025294c6b08\nCloses-Bug: #1321974\n'}]",0,94403,78f8ba232199966c048c9aaef33f9f92a74cd8be,71,11,2,6763,,,0,"Do not render port template if device has no port

Change-Id: Iacefbba64ee0cc534c3129a1c4b28025294c6b08
Closes-Bug: #1321974
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/94403/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.networktopology.js'],1,0bb43e66e51fa8eb29be2e706253c4226642fe2f,bug/1321974, table2:(ports.length > 0) ? port_tmpl : null, table2:port_tmpl,1,1
openstack%2Fpython-manilaclient~master~Iffab2f59504ee7ec6528860e06a5140ff22f332f,openstack/python-manilaclient,master,Iffab2f59504ee7ec6528860e06a5140ff22f332f,Code cleanup: use oslo's to_slug() instead of slugify(),MERGED,2014-06-18 09:22:27.000000000,2014-06-24 07:48:59.000000000,2014-06-24 07:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 7534}]","[{'number': 1, 'created': '2014-06-18 09:22:27.000000000', 'files': ['manilaclient/base.py', 'manilaclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/07ee1bcb0c3c17032901b6813ab2a13439061495', 'message': ""Code cleanup: use oslo's to_slug() instead of slugify()\n\nThe bash completion code is the sole user of the slugify() function\nin utils, which is substantially similar to to_slug() provided in\nstrutils from oslo. Remove slugify() and use to_slug() instead.\n\nChange-Id: Iffab2f59504ee7ec6528860e06a5140ff22f332f\nCloses-Bug: #1266127\n""}]",0,100831,07ee1bcb0c3c17032901b6813ab2a13439061495,11,5,1,8851,,,0,"Code cleanup: use oslo's to_slug() instead of slugify()

The bash completion code is the sole user of the slugify() function
in utils, which is substantially similar to to_slug() provided in
strutils from oslo. Remove slugify() and use to_slug() instead.

Change-Id: Iffab2f59504ee7ec6528860e06a5140ff22f332f
Closes-Bug: #1266127
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/31/100831/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/base.py', 'manilaclient/utils.py']",2,07ee1bcb0c3c17032901b6813ab2a13439061495,master,,"import re_slugify_strip_re = re.compile(r'[^\w\s-]') _slugify_hyphenate_re = re.compile(r'[-\s]+') # http://code.activestate.com/recipes/ # 577257-slugify-make-a-string-usable-in-a-url-or-filename/ def slugify(value): """""" Normalizes string, converts to lowercase, removes non-alpha characters, and converts spaces to hyphens. From Django's ""django/template/defaultfilters.py"". """""" import unicodedata if not isinstance(value, unicode): value = unicode(value) value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore') value = unicode(_slugify_strip_re.sub('', value).strip().lower()) return _slugify_hyphenate_re.sub('-', value) ",3,22
openstack%2Fsolum~master~Ib88339a2cab36f3c9ca8f716d6928dc1c4e501f2,openstack/solum,master,Ib88339a2cab36f3c9ca8f716d6928dc1c4e501f2,Add tests for common module functions in Plan controller,MERGED,2014-06-20 15:57:33.000000000,2014-06-24 07:47:46.000000000,2014-06-24 07:47:46.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 9095}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-06-20 15:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/a98786b01371fd9777401c574f3080a60a82af77', 'message': 'Add tests for common module functions in Plan controller\n\nChange-Id: Ib88339a2cab36f3c9ca8f716d6928dc1c4e501f2\n'}, {'number': 2, 'created': '2014-06-23 09:39:03.000000000', 'files': ['solum/tests/api/v1/test_plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/2f479c6db1c2231b7407d90ae1356f1c27067b45', 'message': 'Add tests for common module functions in Plan controller\n\nChange-Id: Ib88339a2cab36f3c9ca8f716d6928dc1c4e501f2\n'}]",1,101590,2f479c6db1c2231b7407d90ae1356f1c27067b45,16,5,2,9548,,,0,"Add tests for common module functions in Plan controller

Change-Id: Ib88339a2cab36f3c9ca8f716d6928dc1c4e501f2
",git fetch https://review.opendev.org/openstack/solum refs/changes/90/101590/2 && git format-patch -1 --stdout FETCH_HEAD,['solum/tests/api/v1/test_plan.py'],1,a98786b01371fd9777401c574f3080a60a82af77,test-plan-controller-module-functions,"from solum.api.handlers import plan_handlerclass TestPlanModuleFunctions(base.BaseTestCase): def setUp(self): super(TestPlanModuleFunctions, self).setUp() @mock.patch('pecan.request', new_callable=fakes.FakePecanRequest) def test_yaml_content(self, mock_req): m = fakes.FakePlan() ref_content = plan.yaml_content(m) self.assertEqual(ref_content['uri'], '%s/v1/plans/%s' % (pecan.request.host_url, m.uuid)) @mock.patch('solum.api.controllers.v1.plan.init_plan_v1') def test_init_plan_by_version(self, init_plan_v1): yml_input_plan = {'version': 1, 'name': 'plan1', 'description': 'dsc'} plan.init_plan_by_version(yml_input_plan) init_plan_v1.assert_called_once() @mock.patch('solum.api.controllers.v1.plan.init_plan_v1') def test_init_plan_by_version_missing(self, init_plan_v1): yml_input_plan = {'name': 'plan1', 'description': 'dsc'} self.assertRaises(exception.BadRequest, plan.init_plan_by_version, yml_input_plan) init_plan_v1.assert_called_once() @mock.patch('solum.api.controllers.v1.plan.init_plan_v1') def test_init_plan_by_version_not_existing(self, init_plan_v1): yml_input_plan = {'version': 424242424242424242, 'name': 'plan1', 'description': 'dsc'} self.assertRaises(exception.BadRequest, plan.init_plan_by_version, yml_input_plan) init_plan_v1.assert_called_once() @mock.patch('pecan.request', new_callable=fakes.FakePecanRequest) def test_init_plan_v1(self, mock_req): yml_input_plan = {'version': 1, 'name': 'plan1', 'description': 'dsc'} hand_v1, plan_v1 = plan.init_plan_v1(yml_input_plan) self.assertIsInstance(hand_v1, plan_handler.PlanHandler) self.assertIsInstance(plan_v1, planmodel.Plan) "," def test_yaml_content(self, PlanHandler, resp_mock, request_mock): m = fakes.FakePlan() ref_content = plan.yaml_content(m) self.assertEqual(ref_content['uri'], '%s/v1/plans/%s' % (pecan.request.host_url, m.uuid)) ",42,6
openstack%2Fneutron~stable%2Ficehouse~I71cfe82e57290552fb22637ad929747a6fa22460,openstack/neutron,stable/icehouse,I71cfe82e57290552fb22637ad929747a6fa22460,netaddr<=0.7.10 raises ValueError instead of AddrFormatError,MERGED,2014-06-22 18:57:04.000000000,2014-06-24 07:45:53.000000000,2014-06-24 07:45:52.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 9732}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10257}]","[{'number': 1, 'created': '2014-06-22 18:57:04.000000000', 'files': ['neutron/common/ipv6_utils.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a79749c8b09938b5ec2d94c11bac7a013c03843', 'message': 'netaddr<=0.7.10 raises ValueError instead of AddrFormatError\n\nThis patch is based on Aarons work for the Bug#1308675.\nIt ensures that ValueError is also caught in addition to\nAddrFormatError as in netaddr>=0.7.11 AddrFormatError is raised and\nin netaddr<=0.7.10 ValueError is raised.\n\nChange-Id: I71cfe82e57290552fb22637ad929747a6fa22460\nCloses-bug: #1308675\n(cherry picked from commit 7305ace9f37719f47d55743c0dece7089c063b12)\n'}]",0,101769,2a79749c8b09938b5ec2d94c11bac7a013c03843,18,11,1,10257,,,0,"netaddr<=0.7.10 raises ValueError instead of AddrFormatError

This patch is based on Aarons work for the Bug#1308675.
It ensures that ValueError is also caught in addition to
AddrFormatError as in netaddr>=0.7.11 AddrFormatError is raised and
in netaddr<=0.7.10 ValueError is raised.

Change-Id: I71cfe82e57290552fb22637ad929747a6fa22460
Closes-bug: #1308675
(cherry picked from commit 7305ace9f37719f47d55743c0dece7089c063b12)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/101769/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/ipv6_utils.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py']",2,2a79749c8b09938b5ec2d94c11bac7a013c03843,bug/1308675," except (ValueError, netaddr.AddrFormatError):", except netaddr.AddrFormatError:,2,2
openstack%2Fpython-solumclient~master~I699e60a261c3c492706d8b5918f55d28b1bba10d,openstack/python-solumclient,master,I699e60a261c3c492706d8b5918f55d28b1bba10d,Add the basic pipeline commands,MERGED,2014-06-16 02:00:38.000000000,2014-06-24 07:43:57.000000000,2014-06-24 07:43:56.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-16 02:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/f4ec8e1986b2720762a065941f59d12d355721ba', 'message': 'Add the basic pipeline commands\n\nChange-Id: I699e60a261c3c492706d8b5918f55d28b1bba10d\n'}, {'number': 2, 'created': '2014-06-16 23:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/f636a5bf43ff972282f028c80b253f3607b7ce3b', 'message': 'Add the basic pipeline commands\n\nChange-Id: I699e60a261c3c492706d8b5918f55d28b1bba10d\n'}, {'number': 3, 'created': '2014-06-17 23:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/9e580b1fe9808e156d172f9796ee0b44965f70cb', 'message': 'Add the basic pipeline commands\n\nChange-Id: I699e60a261c3c492706d8b5918f55d28b1bba10d\n'}, {'number': 4, 'created': '2014-06-23 00:42:43.000000000', 'files': ['solumclient/v1/pipeline.py', 'solumclient/tests/test_solum.py', 'solumclient/v1/client.py', 'solumclient/solum.py', 'solumclient/tests/v1/test_pipeline.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/e875d888134a50b9f4d01bcf1b4df14a4f91cddb', 'message': 'Add the basic pipeline commands\n\nChange-Id: I699e60a261c3c492706d8b5918f55d28b1bba10d\n'}]",1,100124,e875d888134a50b9f4d01bcf1b4df14a4f91cddb,28,8,4,4715,,,0,"Add the basic pipeline commands

Change-Id: I699e60a261c3c492706d8b5918f55d28b1bba10d
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/24/100124/3 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/v1/pipeline.py', 'solumclient/v1/client.py', 'solumclient/solum.py', 'solumclient/tests/v1/test_pipeline.py']",4,f4ec8e1986b2720762a065941f59d12d355721ba,100124,"# Copyright 2014 - Rackspace Hosting # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from solumclient.openstack.common.apiclient import exceptions from solumclient.openstack.common.apiclient import fake_client from solumclient.tests import base from solumclient.v1 import pipeline from solumclient.v1 import client as sclient pipeline_list = [ { 'uri': 'http://example.com/v1/pipelines/x1', 'name': 'database', 'type': 'pipeline', 'description': 'A mysql database', 'tags': ['small'], 'project_id': '1dae5a09ef2b4d8cbf3594b0eb4f6b94', 'user_id': '55f41cf46df74320b9486a35f5d28a11', 'component_links': [{ 'href': 'http://example.com:9777/v1/components/x1', 'target_name': 'x1'}], 'operations_uri': 'http://example.com:9777/v1/operations/o1', 'sensors_uri': 'http://example.com:9777/v1/sensors/s1' }, { 'uri': 'http://example.com/v1/pipelines/x2', 'name': 'load_balancer', 'type': 'pipeline', 'description': 'A load balancer', 'tags': ['small'], 'project_id': '1dae5a09ef2b4d8cbf3594b0eb4f6b94', 'user_id': '55f41cf46df74320b9486a35f5d28a11', 'component_links': [{ 'href': 'http://example.com:9777/v1/components/x2', 'target_name': 'x2'}], 'operations_uri': 'http://example.com:9777/v1/operations/o2', 'sensors_uri': 'http://example.com:9777/v1/sensors/s2' } ] pipeline_fixture = { 'uri': 'http://example.com/v1/pipelines/x1', 'name': 'database', 'type': 'pipeline', 'description': 'A mysql database', 'tags': ['small'], 'project_id': '1dae5a09ef2b4d8cbf3594b0eb4f6b94', 'user_id': '55f41cf46df74320b9486a35f5d28a11', 'component_links': [{ 'href': 'http://example.com:9777/v1/components/x1', 'target_name': 'x1'}], 'operations_uri': 'http://example.com:9777/v1/operations/o1', 'sensors_uri': 'http://example.com:9777/v1/sensors/s1' } fixtures_list = { '/v1/pipelines': { 'GET': ( {}, pipeline_list ), } } fixtures_get = { '/v1/pipelines/x1': { 'GET': ( {}, pipeline_fixture ), } } fixtures_create = { '/v1/pipelines': { 'POST': ( {}, pipeline_fixture ), } } fixtures_put = { '/v1/pipelines/x1': { 'PUT': ( {}, pipeline_fixture ), } } class PipelineManagerTest(base.TestCase): def assert_pipeline_object(self, pipeline_obj): self.assertIn('Pipeline', repr(pipeline_obj)) self.assertEqual(pipeline_fixture['uri'], pipeline_obj.uri) self.assertEqual(pipeline_fixture['type'], pipeline_obj.type) self.assertEqual(pipeline_fixture['project_id'], pipeline_obj.project_id) self.assertEqual(pipeline_fixture['user_id'], pipeline_obj.user_id) def test_list_all(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_list) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) pipelines = mgr.list() self.assertEqual(len(pipelines), 2) self.assertIn('Pipeline', repr(pipelines[0])) self.assertEqual(pipeline_list[0]['uri'], pipelines[0].uri) self.assertEqual(pipeline_list[1]['uri'], pipelines[1].uri) def test_find_one(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_list) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) pipelines = mgr.findall(name='database') self.assertEqual(len(pipelines), 1) self.assertIn('Pipeline', repr(pipelines[0])) self.assertEqual(pipeline_list[0]['uri'], pipelines[0].uri) def test_find_one_only(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_list) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) result = mgr.find(name_or_id='database') self.assertEqual(pipeline_list[0]['uri'], result.uri) def test_find_none(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_list) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) self.assertRaises(exceptions.NotFound, mgr.find, name_or_id='what') def test_create(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_create) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) pipeline_obj = mgr.create() self.assert_pipeline_object(pipeline_obj) def test_get(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_get) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) pipeline_obj = mgr.get(pipeline_id='x1') self.assert_pipeline_object(pipeline_obj) def test_put(self): fake_http_client = fake_client.FakeHTTPClient(fixtures=fixtures_put) api_client = sclient.Client(fake_http_client) mgr = pipeline.PipelineManager(api_client) pipeline_obj = mgr.put(pipeline_id='x1') self.assert_pipeline_object(pipeline_obj) ",,285,0
openstack%2Ftempest~master~If7017c6e4d4774c873835f67ea7f6ff9293308ea,openstack/tempest,master,If7017c6e4d4774c873835f67ea7f6ff9293308ea,Missing Swift CLI tests,ABANDONED,2014-06-10 11:16:48.000000000,2014-06-24 07:28:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 6968}, {'_account_id': 8205}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11667}, {'_account_id': 11689}]","[{'number': 1, 'created': '2014-06-10 11:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9e2c6adb920ef20531f2dfe6eee7f2c7e82e5409', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}, {'number': 2, 'created': '2014-06-11 06:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c9fb50f48c4d138e456661b4ddf845f5b92a1cb', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}, {'number': 3, 'created': '2014-06-11 11:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5c772a39802b65d37a61f434ea230b2d04602e7b', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}, {'number': 4, 'created': '2014-06-17 04:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6279893436b35fa212b137331568d9e9eb5c2a5f', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}, {'number': 5, 'created': '2014-06-17 04:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/38437f983c8833a126513c73979f56b6bdf88615', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n4. --retries\n5. --info\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}, {'number': 6, 'created': '2014-06-17 07:15:51.000000000', 'files': ['tempest/cli/simple_read_only/test_swift.py', 'tempest/cli/__init__.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/15e2f913def490adf5b4f1bb6a1c3467fc3c43fb', 'message': 'Missing Swift CLI tests\n\nThis patch adds following missing Swift CLI tests -\n1. list\n2. capabilities\n3. stat\n4. download all\n\nIn addition to this following optional arguments are also verified.\n1. --version\n2. --debug\n3. --help\n4. --retries\n5. --info\n\nPartially implements: blueprint missing-cli-tests-in-tempest\n\nChange-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea\n'}]",17,99005,15e2f913def490adf5b4f1bb6a1c3467fc3c43fb,47,9,6,8205,,,0,"Missing Swift CLI tests

This patch adds following missing Swift CLI tests -
1. list
2. capabilities
3. stat
4. download all

In addition to this following optional arguments are also verified.
1. --version
2. --debug
3. --help
4. --retries
5. --info

Partially implements: blueprint missing-cli-tests-in-tempest

Change-Id: If7017c6e4d4774c873835f67ea7f6ff9293308ea
",git fetch https://review.opendev.org/openstack/tempest refs/changes/05/99005/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/test_swift.py']",2,9e2c6adb920ef20531f2dfe6eee7f2c7e82e5409,bp/missing-cli-tests-in-tempest,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import re import subprocess import testtools import tempest.cli from tempest import config CONF = config.CONF LOG = logging.getLogger(__name__) class SimpleReadOnlySwiftClientTest(tempest.cli.ClientTestBase): """"""Basic, read-only tests for Swift CLI client. Checks return values and output of read-only commands. These tests do not presume any content, nor do they create their own. They only verify the structure of output if present. """""" @classmethod def setUpClass(cls): if not CONF.service_available.swift: msg = (""%s skipped as Swift is not available"" % cls.__name__) raise cls.skipException(msg) super(SimpleReadOnlySwiftClientTest, cls).setUpClass() def test_swift_fake_action(self): self.assertRaises(subprocess.CalledProcessError, self.swift, 'this-does-not-exist') def test_swift_list(self): self.swift('list') def test_swift_capablities(self): self.swift('capabilities') def test_swift_stat(self): self.swift('stat') # Optional arguments: def test_swift_version(self): self.swift('', flags='--version') def test_swift_version(self): self.swift('', flags='--help') def test_swift_debug_list(self): self.swift('list', flags='--debug') ",,70,0
openstack%2Fopenstack-manuals~master~I915b06ffcf398d486fc3a927b5ec3da14c30ebb4,openstack/openstack-manuals,master,I915b06ffcf398d486fc3a927b5ec3da14c30ebb4,Imported Translations from Transifex,MERGED,2014-06-24 06:08:12.000000000,2014-06-24 07:19:34.000000000,2014-06-24 07:19:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 06:08:12.000000000', 'files': ['doc/config-reference/locale/config-reference.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/95a1862df9c8406f2fc9345281666a2b54aed8e6', 'message': 'Imported Translations from Transifex\n\nChange-Id: I915b06ffcf398d486fc3a927b5ec3da14c30ebb4\n'}]",0,102112,95a1862df9c8406f2fc9345281666a2b54aed8e6,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I915b06ffcf398d486fc3a927b5ec3da14c30ebb4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/102112/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/locale/config-reference.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot']",2,95a1862df9c8406f2fc9345281666a2b54aed8e6,transifex/translations,"""POT-Creation-Date: 2014-06-24 06:07+0000\n""#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:37(th) ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:198(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:55(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:115(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:186(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:287(th) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:35(th) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:138(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:41(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:132(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:260(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:318(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:614(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:657(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:869(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:991(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1059(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1180(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1495(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1584(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1625(th)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:42(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:61(emphasis) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:137(th)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:47(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:70(emphasis)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:52(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:81(emphasis)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:6(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:7(para) msgid ""You can manage OpenStack Networking services by using the <systemitem>service</systemitem> command. For example:""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:14(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:17(para)msgid ""Cloud administrators and tenants can use OpenStack Networking to build rich network topologies. Cloud administrators can create network connectivity on behalf of tenants.""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:27(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:28(para) msgid ""After you install and configure Networking, tenants and administrators can perform create-read-update-delete (CRUD) API networking operations by using the Networking API directly or neutron command-line interface (CLI). The neutron CLI is a wrapper around the Networking API. Every Networking API call has a corresponding neutron command."" msgstr """" msgid ""The CLI includes a number of options. For details, see the <link href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack End User Guide</citetitle></link>.""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:41(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:49(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:42(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:54(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:62(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:71(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:82(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:99(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:105(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:112(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:183(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:284(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:113(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:184(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:285(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:130(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:258(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:316(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:612(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:655(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:867(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:989(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1057(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1178(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1582(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1623(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:114(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:185(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:286(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1393(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:120(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:292(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:277(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1090(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:121(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:142(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:218(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:293(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:122(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:219(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:279(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:973(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1092(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:20(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:21(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:25(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:26(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:30(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:31(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:123(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:128(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:239(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:322(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:402(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:265(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:323(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:619(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:662(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:874(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:996(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1064(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1185(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1589(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1630(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:129(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:166(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:266(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:293(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:324(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:337(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:346(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:353(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:368(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:620(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:639(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:663(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:717(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:875(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:881(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:997(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1003(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1065(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1071(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1186(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1230(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1590(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1608(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1631(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1644(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:130(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:241(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:324(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:330(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:131(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:134(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:251(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:334(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:271(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:625(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:887(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1009(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1077(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1199(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1595(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:135(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:152(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:204(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:225(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:252(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:301(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:308(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:329(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:335(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:349(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:136(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:253(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:302(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:309(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:336(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:273(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:627(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:634(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:682(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:688(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:694(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:700(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:706(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:889(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:895(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:920(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:932(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:938(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:945(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:952(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:958(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1011(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1017(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1032(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1079(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1085(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1128(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1201(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1597(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1603(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:137(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:141(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:910(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1022(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:143(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:912(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1024(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1039(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1447(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1653(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:144(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:151(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:348(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:284(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1097(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:153(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:167(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:205(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:260(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:267(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:343(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:350(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:357(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:139(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:164(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:286(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:294(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:338(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:347(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:369(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:640(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:676(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:718(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:882(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1004(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1072(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1099(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1213(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1231(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1609(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1645(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1661(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:154(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:158(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:159(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:160(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:212(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:233(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:161(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:165(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:265(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:355(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:292(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:367(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:638(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:716(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:880(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1002(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1070(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1229(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1607(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:168(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:176(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:191(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:192(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:232(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:315(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:193(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:203(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:226(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1724(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:194(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:224(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:193(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:196(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:206(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:210(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:211(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:213(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:217(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:220(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:226(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:227(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:231(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:234(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:240(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:259(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:266(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:323(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:342(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:356(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:242(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:245(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:924(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:246(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:247(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:926(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:248(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:254(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:258(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:341(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:261(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:268(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:277(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:294(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:295(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:300(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:303(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:307(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:404(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:310(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:314(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:403(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:316(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:317(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:325(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:328(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:544(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:331(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:337(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:344(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:351(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:358(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:367(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:377(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:368(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:373(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:382(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:461(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:591(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:390(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:735(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1247(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1680(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:383(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:462(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:520(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:592(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:391(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:736(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1248(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1681(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:388(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:392(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:397(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:401(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:409(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:411(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:551(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:604(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:608(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:416(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:422(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:426(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:433(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:434(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:439(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:439(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:440(para) ./doc/admin-guide-cloud/networking/section_networking-config-identity.xml:47(para) ./doc/admin-guide-cloud/networking/section_networking-config-identity.xml:61(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:244(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:268(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:278(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:295(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:325(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:331(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:518(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:443(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:451(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:456(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:452(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:467(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:472(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:477(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:482(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:486(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:491(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:496(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:498(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:531(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:606(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:607(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:506(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:508(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:513(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:509(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:519(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:525(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:529(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:531(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:598(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:608(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:616(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:531(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:598(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:608(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:616(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:531(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:598(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:608(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:616(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:534(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:540(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:546(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:543(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:549(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:556(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:560(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:563(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:573(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:581(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:586(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:582(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:597(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:598(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:598(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:601(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:607(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:607(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:614(parameter)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:611(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:627(para) msgid ""Cloud images that distribution vendors offer usually have only one active NIC configured. When you boot with multiple NICs, you must configure additional interfaces on the image or the NICS are not reachable."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:632(para) msgid ""The following Debian/Ubuntu-based example shows how to set up the interfaces within the instance in the <filename>/etc/network/interfaces</filename> file. You must apply this configuration to the image."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:650(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:652(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:657(para) msgid ""Implements Networking security groups, you can configure security group rules directly by using the <placeholder-1/> command. This example enables <placeholder-2/> and <placeholder-3/> access to your VMs.""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:671(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:685(para)#: ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:131(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:259(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:317(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:613(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:656(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:868(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:990(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1058(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1179(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1583(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1624(th) msgid ""Default Value"" msgstr """" ","""POT-Creation-Date: 2014-06-21 06:07+0000\n""#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:37(th) ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:198(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:62(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:126(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:199(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:303(th) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:35(th) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:138(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:41(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:132(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:260(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:318(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:614(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:657(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:869(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:991(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1059(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1180(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1495(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1584(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1625(th)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:42(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:68(emphasis) ./doc/admin-guide-cloud/networking/section_networking_arch.xml:137(th)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:47(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:77(emphasis)#: ./doc/admin-guide-cloud/networking/section_networking_introduction.xml:52(emphasis) ./doc/admin-guide-cloud/networking/section_networking-use.xml:89(emphasis)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:5(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:6(para) msgid ""You can manage OpenStack Networking services using the <systemitem>service</systemitem> command. For example:""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:13(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:16(para)msgid ""You can use Networking in the following ways:""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:22(para) msgid ""Expose the Networking API to cloud tenants, enabling them to build rich network topologies."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:26(para) msgid ""Have the cloud administrator, or an automated administrative tool, create network connectivity on behalf of tenants."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:31(para) msgid ""A tenant or cloud administrator can both perform the following procedures."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:34(title)msgid ""After you install and run Networking, tenants and administrators can perform create-read-update-delete (CRUD) API networking operations by using the Networking API directly or the neutron command-line interface (CLI). The neutron CLI is a wrapper around the Networking API. Every Networking API call has a corresponding neutron command.""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:42(para) msgid ""The CLI includes a number of options. For details, refer to the <link href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack End User Guide</citetitle></link>."" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:48(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:56(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:49(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:61(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:69(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:78(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:90(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:109(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:116(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:123(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:196(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:300(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:124(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:197(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:301(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:130(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:258(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:316(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:612(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:655(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:867(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:989(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1057(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1178(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1582(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1623(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:125(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1393(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:131(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:308(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:277(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1090(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:132(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:154(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:233(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:309(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:133(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:234(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:279(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:973(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1092(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:20(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:21(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:25(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:26(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:30(td) ./doc/admin-guide-cloud/networking/section_networking_pagination_and_sorting_support.xml:31(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:134(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:140(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:255(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:340(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:422(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:265(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:323(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:619(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:662(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:874(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:996(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1064(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1185(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1589(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1630(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:141(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:178(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:266(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:293(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:324(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:337(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:346(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:353(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:368(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:620(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:639(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:663(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:717(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:875(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:881(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:997(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1003(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1065(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1071(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1186(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1230(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1590(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1608(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1631(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1644(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:142(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:257(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:342(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:348(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:143(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:146(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:267(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:352(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:271(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:625(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:887(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1009(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1077(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1199(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1595(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:147(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:164(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:219(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:240(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:268(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:317(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:325(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:347(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:353(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:367(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:148(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:269(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:318(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:326(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:354(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:273(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:627(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:634(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:682(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:688(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:694(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:700(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:706(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:889(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:895(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:920(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:932(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:938(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:945(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:952(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:958(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1011(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1017(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1032(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1079(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1085(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1128(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1201(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1597(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1603(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:149(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:153(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:910(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1022(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:155(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:912(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1024(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1039(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1447(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1653(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:156(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:163(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:366(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:284(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1097(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:165(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:179(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:220(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:276(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:283(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:361(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:368(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:375(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:139(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:164(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:286(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:294(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:338(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:347(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:369(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:640(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:676(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:718(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:882(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1004(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1072(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1099(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1213(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1231(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1609(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1645(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1661(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:166(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:170(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:171(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:172(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:227(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:249(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:173(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:177(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:281(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:373(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:292(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:367(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:638(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:716(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:880(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1002(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1070(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1229(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1607(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:180(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:189(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:198(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:302(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:131(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:259(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:317(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:613(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:656(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:868(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:990(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1058(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1179(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1583(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1624(th) msgid ""Default Value"" msgstr """" #: ./doc/admin-guide-cloud/networking/section_networking-use.xml:204(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:205(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:248(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:332(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:207(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:218(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:241(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1724(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:208(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:239(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:206(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:210(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:221(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:225(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:226(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:228(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:232(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:235(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:241(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:243(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:247(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:250(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:256(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:275(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:282(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:341(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:360(td) ./doc/admin-guide-cloud/networking/section_networking-use.xml:374(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:258(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:261(option) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:924(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:262(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:263(td) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:926(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:264(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:270(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:274(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:359(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:277(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:284(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:293(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:310(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:311(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:316(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:319(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:324(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:424(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:327(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:331(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:423(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:333(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:334(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:343(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:346(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:568(option)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:349(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:355(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:362(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:369(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:376(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:386(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:396(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:387(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:392(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:401(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:482(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:614(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:390(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:735(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1247(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1680(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:402(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:483(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:542(th) ./doc/admin-guide-cloud/networking/section_networking-use.xml:615(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:391(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:736(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1248(th) ./doc/admin-guide-cloud/networking/section_networking_adv_features.xml:1681(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:407(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:411(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:416(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:421(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:430(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:432(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:574(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:627(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:631(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:437(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:443(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:447(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:454(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:455(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:460(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:460(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:461(para) ./doc/admin-guide-cloud/networking/section_networking-config-identity.xml:47(para) ./doc/admin-guide-cloud/networking/section_networking-config-identity.xml:61(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:244(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:268(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:278(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:295(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:325(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:331(para) ./doc/admin-guide-cloud/compute/section_compute-networking-nova.xml:518(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:464(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:472(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:477(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:473(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:488(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:493(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:498(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:503(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:508(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:513(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:518(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:520(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:553(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:629(option) ./doc/admin-guide-cloud/networking/section_networking-use.xml:630(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:528(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:530(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:535(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:531(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:541(th)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:547(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:551(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:553(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:631(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:640(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:553(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:631(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:640(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:553(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:631(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:640(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:557(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:564(replaceable) ./doc/admin-guide-cloud/networking/section_networking-use.xml:569(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:567(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:572(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:579(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:583(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:586(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:596(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:604(title) ./doc/admin-guide-cloud/networking/section_networking-use.xml:609(caption)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:605(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:620(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:621(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:624(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:630(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:630(replaceable)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:638(parameter)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:635(td)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:646(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:653(title)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:655(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:660(para) msgid ""Implements Networking security groups, you can configure security group rules directly by using <placeholder-1/>. This example enables <placeholder-2/> and <placeholder-3/> access to your VMs.""#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:674(para)#: ./doc/admin-guide-cloud/networking/section_networking-use.xml:688(para)",356,360
openstack%2Fcinder~master~I56c9ccbcedd34c83793620561da17c47cb5f551c,openstack/cinder,master,I56c9ccbcedd34c83793620561da17c47cb5f551c,Make rbd driver string encoding checks consistent,MERGED,2014-06-23 22:22:11.000000000,2014-06-24 07:19:27.000000000,2014-06-24 07:19:26.000000000,"[{'_account_id': 3}, {'_account_id': 1107}, {'_account_id': 4355}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9533}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 22:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e497dd8fff73e3f90703a34a5e68ca0dc1b170d3', 'message': 'Make rbd driver string encoding checks consistent\n\nAll string checks should use strutils.safe_encode()\n\nCloses-Bug: 1333446\nChange-Id: I56c9ccbcedd34c83793620561da17c47cb5f551c\n'}, {'number': 2, 'created': '2014-06-24 03:01:51.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/20001f2470fbc7e03a0f2a19d62b6b0ef38e9657', 'message': 'Make rbd driver string encoding checks consistent\n\nAll string checks should use strutils.safe_encode()\n\nCloses-Bug: 1333446\nChange-Id: I56c9ccbcedd34c83793620561da17c47cb5f551c\n'}]",0,102038,20001f2470fbc7e03a0f2a19d62b6b0ef38e9657,17,8,2,6737,,,0,"Make rbd driver string encoding checks consistent

All string checks should use strutils.safe_encode()

Closes-Bug: 1333446
Change-Id: I56c9ccbcedd34c83793620561da17c47cb5f551c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/102038/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/test_rbd.py']",2,e497dd8fff73e3f90703a34a5e68ca0dc1b170d3,bug/1333446,,"class TestUtil(test.TestCase): def test_ascii_str(self): self.assertIsNone(driver.ascii_str(None)) self.assertEqual('foo', driver.ascii_str('foo')) self.assertEqual('foo', driver.ascii_str(u'foo')) self.assertRaises(UnicodeEncodeError, driver.ascii_str, 'foo' + unichr(300)) ",33,42
openstack%2Fnova~master~I22446f08ee078c624970f233875874a67ea423b9,openstack/nova,master,I22446f08ee078c624970f233875874a67ea423b9,Downgrade log level when create network failed,MERGED,2014-03-20 03:03:28.000000000,2014-06-24 07:19:17.000000000,2014-06-24 07:19:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8746}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-03-20 03:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/589e837b3cba6110380f8e4fb278ccca2b6691b2', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed and also it might\nbe caused by quota error, so downgrade the log level\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 2, 'created': '2014-03-20 08:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18c7ea4ddc52119f049ba0128ee7f5b46ff5f07a', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 3, 'created': '2014-03-21 03:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd3769ea8cb23f23fb62e2d6d8da0dbea20bd7b1', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 4, 'created': '2014-03-25 06:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ef53f6a3c89196f9eeff09f16fd74357a6b4293', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 5, 'created': '2014-03-25 09:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db0dfc0ae9da0336a09fe9a108c046981f2274e7', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 6, 'created': '2014-05-04 02:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3feeca95ec92fbadc28cc70585f76b5d25bb7d75', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 7, 'created': '2014-05-08 07:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1839f5a3c89949f5a74d6b8cacfcb9b7e09d56b', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 8, 'created': '2014-05-08 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8e34e6f6181a13ac151ffd31590eef76d75d4b2', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 9, 'created': '2014-06-17 10:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcd8339a205c70f77d7ecf013ed55a48fbfc6754', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 10, 'created': '2014-06-19 06:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46e76203938e1ff1109754ada0c0ccf1d747e853', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 11, 'created': '2014-06-20 05:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9ae0ff948044109f014b8d3b913ceeaba400500', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}, {'number': 12, 'created': '2014-06-23 01:16:12.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15eece2882bc0e5b69ba0e2db32e274c9cf72a84', 'message': 'Downgrade log level when create network failed\n\nWe raised exception when create network failed because of exceed\nquota, downgrade to debug level for those exceptions because\nLOG.exception will generate a stacktrace.\n\nChange-Id: I22446f08ee078c624970f233875874a67ea423b9\n'}]",10,81692,15eece2882bc0e5b69ba0e2db32e274c9cf72a84,166,12,12,6062,,,0,"Downgrade log level when create network failed

We raised exception when create network failed because of exceed
quota, downgrade to debug level for those exceptions because
LOG.exception will generate a stacktrace.

Change-Id: I22446f08ee078c624970f233875874a67ea423b9
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/81692/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,589e837b3cba6110380f8e4fb278ccca2b6691b2,compute_create_network_fail_exception_downgrade," LOG.debug(_('Failed to allocate network(s)'), instance=instance)"," LOG.exception(_('Failed to allocate network(s)'), instance=instance)",2,2
openstack%2Fnova~master~Iecd42239357b96450b6530c0486b27c68995c37f,openstack/nova,master,Iecd42239357b96450b6530c0486b27c68995c37f,Avoid traceback logs from simple tenant usage extension,MERGED,2014-04-08 06:44:01.000000000,2014-06-24 07:19:04.000000000,2014-06-24 07:19:02.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-08 06:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d9863f0bc96d55fa8af74b900982f8797410e85', 'message': 'Avoid traceback logs from simple tenant usage extension\n\nAvoid generating traceback logs when invalid formatted datetime\nparameters are passed to the simple tenant usage\nextension. Exceptions have not been correctly handled by the\nos-simple-tenant usage extension which results in tracebacks\nbeing output to the log files. This patch correctly handles\nexceptions as a result of badly formatted datetime strings.\n\nChange-Id: Iecd42239357b96450b6530c0486b27c68995c37f\nPartial-Bug: 1300972\n'}, {'number': 2, 'created': '2014-06-23 05:59:14.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/exception.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f60c72fac04a97b321a7f2bd0865c1ae81250882', 'message': 'Avoid traceback logs from simple tenant usage extension\n\nAvoid generating traceback logs when invalid formatted datetime\nparameters are passed to the simple tenant usage\nextension. Exceptions have not been correctly handled by the\nos-simple-tenant usage extension which results in tracebacks\nbeing output to the log files. This patch correctly handles\nexceptions as a result of badly formatted datetime strings.\n\nChange-Id: Iecd42239357b96450b6530c0486b27c68995c37f\nPartial-Bug: 1300972\n'}]",8,85937,f60c72fac04a97b321a7f2bd0865c1ae81250882,37,11,2,5292,,,0,"Avoid traceback logs from simple tenant usage extension

Avoid generating traceback logs when invalid formatted datetime
parameters are passed to the simple tenant usage
extension. Exceptions have not been correctly handled by the
os-simple-tenant usage extension which results in tracebacks
being output to the log files. This patch correctly handles
exceptions as a result of badly formatted datetime strings.

Change-Id: Iecd42239357b96450b6530c0486b27c68995c37f
Partial-Bug: 1300972
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/85937/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_simple_tenant_usage.py', 'nova/exception.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py']",3,4d9863f0bc96d55fa8af74b900982f8797410e85,bug/1300972,"def parse_strtime(dstr, fmt): try: return timeutils.parse_strtime(dstr, fmt) except (TypeError, ValueError) as e: raise exception.InvalidStrTime(reason=unicode(e)) value = parse_strtime(dtstr, ""%Y-%m-%dT%H:%M:%S"") value = parse_strtime(dtstr, ""%Y-%m-%dT%H:%M:%S.%f"") except Exception: value = parse_strtime(dtstr, ""%Y-%m-%d %H:%M:%S.%f"") try: (period_start, period_stop, detailed) = self._get_datetime_range( req) except exception.InvalidStrTime as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: (period_start, period_stop, ignore) = self._get_datetime_range( req) except exception.InvalidStrTime as e: raise exc.HTTPBadRequest(explanation=e.format_message()) "," value = timeutils.parse_strtime(dtstr, ""%Y-%m-%dT%H:%M:%S"") value = timeutils.parse_strtime(dtstr, ""%Y-%m-%dT%H:%M:%S.%f"") except Exception: value = timeutils.parse_strtime(dtstr, ""%Y-%m-%d %H:%M:%S.%f"") (period_start, period_stop, detailed) = self._get_datetime_range(req) (period_start, period_stop, ignore) = self._get_datetime_range(req)",57,5
openstack%2Frequirements~master~I99b8f316eff69cf3187c50ccb4c8f728e0454ecb,openstack/requirements,master,I99b8f316eff69cf3187c50ccb4c8f728e0454ecb,block problematic sqla 0.9.5,MERGED,2014-06-23 21:09:02.000000000,2014-06-24 07:18:54.000000000,2014-06-24 07:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-06-23 21:09:02.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/af8ffafd6e4d0ee695cf7e0a8202ee0c02b309a2', 'message': 'block problematic sqla 0.9.5\n\nthis is breaking nova floating ip db code, so has halted the gate.\n\nChange-Id: I99b8f316eff69cf3187c50ccb4c8f728e0454ecb\n'}]",0,102015,af8ffafd6e4d0ee695cf7e0a8202ee0c02b309a2,22,3,1,2750,,,0,"block problematic sqla 0.9.5

this is breaking nova floating ip db code, so has halted the gate.

Change-Id: I99b8f316eff69cf3187c50ccb4c8f728e0454ecb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/15/102015/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,af8ffafd6e4d0ee695cf7e0a8202ee0c02b309a2,sqla,"SQLAlchemy>=0.7.8,!=0.9.5,<=0.9.99","SQLAlchemy>=0.7.8,<=0.9.99",1,1
openstack%2Ffuel-ostf~stable%2F4.1~I0b227e3426c3d8b453986e6545829a11e125ce0b,openstack/fuel-ostf,stable/4.1,I0b227e3426c3d8b453986e6545829a11e125ce0b,Increase the count of ping probes,MERGED,2014-06-18 14:38:03.000000000,2014-06-24 07:18:21.000000000,2014-06-23 15:42:37.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-18 14:38:03.000000000', 'files': ['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_health/nmanager.py', 'fuel_health/tests/sanity/test_sanity_infrastructure.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/50ff19cbcc3da371fa0e52390167873abe7299a4', 'message': ""Increase the count of ping probes\n\nIt's allowed now to get at least 3 answers for no more than 10 requests.\nInterval between connectivity checks is increaced (30 -> 60 sec).\n\nCloses-Bug: #1322102\n\nChange-Id: I0b227e3426c3d8b453986e6545829a11e125ce0b\n(cherry picked from commit baf2746d5867c9e8fe58b743e451518c4c107590)\n""}]",2,100923,50ff19cbcc3da371fa0e52390167873abe7299a4,14,5,1,8787,,,0,"Increase the count of ping probes

It's allowed now to get at least 3 answers for no more than 10 requests.
Interval between connectivity checks is increaced (30 -> 60 sec).

Closes-Bug: #1322102

Change-Id: I0b227e3426c3d8b453986e6545829a11e125ce0b
(cherry picked from commit baf2746d5867c9e8fe58b743e451518c4c107590)
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/23/100923/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/smoke/test_nova_create_instance_with_connectivity.py', 'fuel_health/nmanager.py', 'fuel_health/tests/sanity/test_sanity_infrastructure.py']",3,50ff19cbcc3da371fa0e52390167873abe7299a4,," cmd = ""ping -q -c3 -w10 8.8.8.8 | grep 'received' |"" \"," cmd = ""ping -q -c3 -w3 8.8.8.8 | grep 'received' |"" \",7,7
openstack%2Fblazar~master~I333182267997d708110ac77a4fdef03f640a23c0,openstack/blazar,master,I333182267997d708110ac77a4fdef03f640a23c0,trust_id is properly stored during create_lease,MERGED,2014-06-23 20:46:03.000000000,2014-06-24 07:04:37.000000000,2014-06-24 07:04:37.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7075}, {'_account_id': 7166}, {'_account_id': 7535}, {'_account_id': 9331}]","[{'number': 1, 'created': '2014-06-23 20:46:03.000000000', 'files': ['climate/manager/service.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/edbb317742d7c0dfc1bfec4a24ea9d448d0cb569', 'message': 'trust_id is properly stored during create_lease\n\nThe execution of the start_lease event failed because the trust_id were not\nproperly stored during create_lease. To fix this the trust_id was added\nto the dictionary passed to the DB API.\n\nChange-Id: I333182267997d708110ac77a4fdef03f640a23c0\nCloses-Bug: #1333413\n'}]",0,102004,edbb317742d7c0dfc1bfec4a24ea9d448d0cb569,8,6,1,9331,,,0,"trust_id is properly stored during create_lease

The execution of the start_lease event failed because the trust_id were not
properly stored during create_lease. To fix this the trust_id was added
to the dictionary passed to the DB API.

Change-Id: I333182267997d708110ac77a4fdef03f640a23c0
Closes-Bug: #1333413
",git fetch https://review.opendev.org/openstack/blazar refs/changes/04/102004/1 && git format-patch -1 --stdout FETCH_HEAD,['climate/manager/service.py'],1,edbb317742d7c0dfc1bfec4a24ea9d448d0cb569,bug/1333413, if trust_id: lease_values.update({'trust_id': trust_id}),,2,0
openstack%2Fmanila~master~I07de752e6ca8cd206daeb966a75113239c6d411c,openstack/manila,master,I07de752e6ca8cd206daeb966a75113239c6d411c,Replace usage of unittest module with manila.test,MERGED,2014-06-20 15:48:07.000000000,2014-06-24 06:54:24.000000000,2014-06-24 06:54:24.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-06-20 15:48:07.000000000', 'files': ['manila/tests/network/neutron/test_neutron_plugin.py', 'manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/api/v1/test_share_networks.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/e3928ed16b467fe008b07616d8109d4b6fd3e11d', 'message': 'Replace usage of unittest module with manila.test\n\ntest modules\nmanila.tests.api.v1.test_share_networks\nmanila.tests.network.neutron.test_neutron_api\nmanila.tests.network.neutron.test_neutron_plugin\n\ninherit unittest.TestCase, but all test classes\nshould inherit manila.test.TestCase\n\nAlso moved all predefines from __init__ to setUp\n\nChange-Id: I07de752e6ca8cd206daeb966a75113239c6d411c\n'}]",2,101585,e3928ed16b467fe008b07616d8109d4b6fd3e11d,18,5,1,8851,,,0,"Replace usage of unittest module with manila.test

test modules
manila.tests.api.v1.test_share_networks
manila.tests.network.neutron.test_neutron_api
manila.tests.network.neutron.test_neutron_plugin

inherit unittest.TestCase, but all test classes
should inherit manila.test.TestCase

Also moved all predefines from __init__ to setUp

Change-Id: I07de752e6ca8cd206daeb966a75113239c6d411c
",git fetch https://review.opendev.org/openstack/manila refs/changes/85/101585/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/network/neutron/test_neutron_plugin.py', 'manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/api/v1/test_share_networks.py']",3,e3928ed16b467fe008b07616d8109d4b6fd3e11d,bp/oslo-messaging,"from manila import testclass ShareNetworkAPITest(test.TestCase): def setUp(self): super(ShareNetworkAPITest, self).setUp() self.context = self.req.environ['manila.context'] test_exception = exception.ShareNetworkNotFound( share_network_id=share_nw)","import unittestclass ShareNetworkAPITest(unittest.TestCase): def __init__(self, *args, **kwargs): super(ShareNetworkAPITest, self).__init__(*args, **kwargs) self.context = self.req.environ['manila.context'] test_exception = exception.ShareNetworkNotFound()",15,15
openstack%2Fceilometer~stable%2Fhavana~I2076e67b79448f98124a57b62b5bfed7aa8ae2ad,openstack/ceilometer,stable/havana,I2076e67b79448f98124a57b62b5bfed7aa8ae2ad,enable sql metadata query,ABANDONED,2014-03-14 02:52:28.000000000,2014-06-24 06:52:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 10513}]","[{'number': 1, 'created': '2014-03-14 02:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/01b9238b2c44efab5229aecc2dab0bc773d0a12f', 'message': 'enable sql metadata query\n\nexplode metadata key/values to their own tables/rows (based on type).\nbuild a key string using dot notation similar to other nosql db\nand filter based on that.\n\nBlueprint: sqlalchemy-metadata-query\nRelated-Bug: #1093625\n\nChange-Id: I2076e67b79448f98124a57b62b5bfed7aa8ae2ad\n(cherry picked from commit 1570462507eae1478123de25dbadc64b09c82af3)\n'}, {'number': 2, 'created': '2014-04-04 03:43:15.000000000', 'files': ['tests/test_utils.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/020_add_metadata_tables.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/api/v2/test_list_meters_scenarios.py', 'ceilometer/utils.py', 'doc/source/install/dbreco.rst', 'ceilometer/storage/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2e80ef3255b54950e4b86febfe656e86ea1211e0', 'message': 'enable sql metadata query\n\nexplode metadata key/values to their own tables/rows (based on type).\nbuild a key string using dot notation similar to other nosql db\nand filter based on that.\n\nBlueprint: sqlalchemy-metadata-query\nRelated-Bug: #1093625\n\nChange-Id: I2076e67b79448f98124a57b62b5bfed7aa8ae2ad\n(cherry picked from commit 1570462507eae1478123de25dbadc64b09c82af3)\n'}]",0,80456,2e80ef3255b54950e4b86febfe656e86ea1211e0,26,5,2,10513,,,0,"enable sql metadata query

explode metadata key/values to their own tables/rows (based on type).
build a key string using dot notation similar to other nosql db
and filter based on that.

Blueprint: sqlalchemy-metadata-query
Related-Bug: #1093625

Change-Id: I2076e67b79448f98124a57b62b5bfed7aa8ae2ad
(cherry picked from commit 1570462507eae1478123de25dbadc64b09c82af3)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/56/80456/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_utils.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/020_add_metadata_tables.py', 'ceilometer/storage/impl_sqlalchemy.py', 'tests/api/v2/test_list_meters_scenarios.py', 'ceilometer/storage/sqlalchemy/models.py', 'ceilometer/utils.py', 'doc/source/install/dbreco.rst']",7,01b9238b2c44efab5229aecc2dab0bc773d0a12f,bp/sqlalchemy-metadata-query,MySQL Yes Yes Yes PostgreSQL Yes Yes Yes,"MySQL Yes, except metadata querying Yes Yes PostgreSQL Yes, except metadata querying Yes Yes",239,11
openstack%2Fmistral-extra~master~I9b65b7476bdc7c2daf19690a44a2029b883b804f,openstack/mistral-extra,master,I9b65b7476bdc7c2daf19690a44a2029b883b804f,Fixing create_vm_example.yaml,MERGED,2014-06-24 06:34:31.000000000,2014-06-24 06:40:15.000000000,2014-06-24 06:40:15.000000000,"[{'_account_id': 3}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-24 06:34:31.000000000', 'files': ['examples/create_vm/create_vm_example.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/af0c1ddef74ba75887957363678b519de7e29838', 'message': 'Fixing create_vm_example.yaml\n\n* Removing network_id parameter\n\nChange-Id: I9b65b7476bdc7c2daf19690a44a2029b883b804f\n'}]",0,102119,af0c1ddef74ba75887957363678b519de7e29838,7,2,1,8731,,,0,"Fixing create_vm_example.yaml

* Removing network_id parameter

Change-Id: I9b65b7476bdc7c2daf19690a44a2029b883b804f
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/19/102119/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/create_vm/create_vm_example.yaml'],1,af0c1ddef74ba75887957363678b519de7e29838,fix_create_vm_example,,# - network_id ## network id you want to connect your new instance networks: [uuid: $.network_id] network_id: $.network_id,0,4
openstack%2Fapi-site~master~I2fe57382ceb2faefd7fcc61c3b9f0f6a4a98a469,openstack/api-site,master,I2fe57382ceb2faefd7fcc61c3b9f0f6a4a98a469,Imported Translations from Transifex,MERGED,2014-06-24 06:01:09.000000000,2014-06-24 06:36:41.000000000,2014-06-24 06:36:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 06:01:09.000000000', 'files': ['api-guide/locale/de.po', 'api-quick-start/locale/ja.po', 'api-guide/locale/zh_CN.po', 'api-ref-guides/locale/de.po', 'api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po', 'api-ref-guides/locale/it.po', 'api-guide/locale/hu.po', 'api-quick-start/locale/es.po', 'api-guide/locale/pt.po', 'api-ref-guides/locale/ja.po', 'api-guide/locale/nl_NL.po', 'api-guide/locale/ru.po', 'api-quick-start/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/690bbde9d0dab5da2d818e7689861c050d7b5d38', 'message': 'Imported Translations from Transifex\n\nChange-Id: I2fe57382ceb2faefd7fcc61c3b9f0f6a4a98a469\n'}]",0,102111,690bbde9d0dab5da2d818e7689861c050d7b5d38,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I2fe57382ceb2faefd7fcc61c3b9f0f6a4a98a469
",git fetch https://review.opendev.org/openstack/api-site refs/changes/11/102111/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-guide/locale/de.po', 'api-quick-start/locale/ja.po', 'api-guide/locale/zh_CN.po', 'api-ref-guides/locale/de.po', 'api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po', 'api-ref-guides/locale/it.po', 'api-guide/locale/hu.po', 'api-quick-start/locale/es.po', 'api-guide/locale/pt.po', 'api-ref-guides/locale/ja.po', 'api-guide/locale/nl_NL.po', 'api-guide/locale/ru.po', 'api-quick-start/locale/fr.po']",14,690bbde9d0dab5da2d818e7689861c050d7b5d38,transifex/translations,"""POT-Creation-Date: 2014-06-23 20:49+0200\n""#: ./api-quick-start/src/docbkx/cli-uses.xml6(title) #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml32(emphasis) msgid ""OpenStack command-line clients"" msgstr ""Clients de ligne de commande OpenStack"" #: ./api-quick-start/src/docbkx/cli-uses.xml7(para) msgid """" ""For scripting work, you can use a command-line client like the <systemitem "" ""role=\""client\"">python-novaclient</systemitem> client. This client enables "" ""you to use the Compute API through a command-line interface."" msgstr ""Pour travailler avec des scripts, vous pouvez utiliser un client de ligne de commande comme le client <systemitem role=\""client\"">python-novaclient</systemitem>. Ce client vous permet d'utiliser l'API Compute via une interface de ligne de commande. "" #: ./api-quick-start/src/docbkx/cli-uses.xml11(para) msgid """" ""For information about the command-line clients, see <link "" ""href=\""http://docs.openstack.org/cli-"" ""reference/content/\""><citetitle>OpenStack Command-Line Interface "" ""Reference</citetitle></link>."" msgstr ""Pour plus d'informations sur les clients en ligne de commande, consultez la documentation : <link href=\""http://docs.openstack.org/cli-reference/content/\""><citetitle>OpenStack Command-Line Interface Reference</citetitle></link>."" #: ./api-quick-start/src/docbkx/cli-uses.xml16(title) msgid ""Install the clients"" msgstr ""Installez les clients"" #: ./api-quick-start/src/docbkx/cli-uses.xml17(para) msgid """" ""Use <placeholder-1/> to install the OpenStack clients on a Mac OS X or Linux"" "" system. It is easy and ensures that you get the latest version of the "" ""client from the <link href=\""http://pypi.python.org/pypi\"">Python Package "" ""Index</link>. Also, <placeholder-2/> lets you update or remove a package."" msgstr ""Utilisez <placeholder-1/> pour installer le Client OpenStack sur Mac OS X ou sur les systmes Linux. C'est facile et vous pouvez vous assurer d'obtenir la dernire version du Client en utilisant <link href=\""http://pypi.python.org/pypi\"">l'index de paquets Python</link>. Par ailleurs, <placeholder-2/> vous permet de mettre  jour ou de supprimer le paquet."" #: ./api-quick-start/src/docbkx/cli-uses.xml23(para) msgid ""You must install each client separately."" msgstr ""Vous devez installer chaque client sparment."" #: ./api-quick-start/src/docbkx/cli-uses.xml24(para) msgid ""Run this command to install or update a client package:"" msgstr ""Lancez cette commande pour installer ou mettre  jour les paquets d'un client :"" #: ./api-quick-start/src/docbkx/cli-uses.xml26(replaceable) msgid ""PROJECT"" msgstr ""PROJECT"" #: ./api-quick-start/src/docbkx/cli-uses.xml27(para) msgid ""Where <replaceable>PROJECT</replaceable> is the project name."" msgstr ""Remplacez <replaceable>PROJECT</replaceable> par le nom du composant OpenStack."" #: ./api-quick-start/src/docbkx/cli-uses.xml29(para) msgid ""For example, to install the <placeholder-1/> client, run this command:"" msgstr ""Par exemple, pour installer le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml32(para) msgid ""To update the <placeholder-1/> client, run this command:"" msgstr ""Pour mettre  jour le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml35(para) msgid ""To remove the <placeholder-1/> client, run this command:"" msgstr ""Pour supprimer le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml38(para) msgid """" ""Before you can issue client commands, you must download and source the "" ""<filename>openrc</filename> file to set environment variables."" msgstr ""Avant d'utiliser les clients de ligne de commande, vous devez tlcharger et sourcer le fichier <filename>openrc</filename> pour dfinir les variables d'environnement."" #: ./api-quick-start/src/docbkx/cli-uses.xml41(para) msgid """" ""For complete information about the OpenStack clients, including how to "" ""source the <filename>openrc</filename> file, see <link "" ""href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack "" ""End User Guide</citetitle></link>, <link href=\""http://docs.openstack.org"" ""/user-guide-admin/content/\""><citetitle>OpenStack Admin User "" ""Guide</citetitle></link>, and <link href=\""http://docs.openstack.org/cli-"" ""reference/content/\""><citetitle>OpenStack Command-Line Interface "" ""Reference</citetitle></link>."" msgstr ""Pour obtenir des informations compltes sur les clients OpenStack, y compris sur comment sourcer le fichier <filename>openrc</filename>, vous pouvez consulter les documentations suivantes : <link href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack End User Guide</citetitle></link>, <link href=\""http://docs.openstack.org/user-guide-admin/content/\""><citetitle>OpenStack Admin User Guide</citetitle></link>, and <link href=\""http://docs.openstack.org/cli-reference/content/\""><citetitle>OpenStack Command-Line Interface Reference</citetitle></link>."" #: ./api-quick-start/src/docbkx/cli-uses.xml59(title) msgid ""Launch an instance"" msgstr ""Lancer une instance"" #: ./api-quick-start/src/docbkx/cli-uses.xml60(para) msgid """" ""To launch instances, you must choose a name, an image, and a flavor for your"" "" instance."" msgstr ""Pour lancer des instances, vous devez choisir un nom, une image et un type d'instance."" #: ./api-quick-start/src/docbkx/cli-uses.xml62(para) msgid """" ""To list available images, call the Compute API through the <placeholder-1/> "" ""client, as follows:"" msgstr ""Pour lister les images disponibles, faites un appel sur l'API Compute en utilisant le client <placeholder-1/> :"" #: ./api-quick-start/src/docbkx/cli-uses.xml72(para) msgid ""To list flavors, run this command:"" msgstr ""Pour lister les types d'instances, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml85(para) msgid ""To launch an instance, note the IDs of your desired image and flavor."" msgstr ""Pour lancer une instance, notez les IDs de l'image et du type d'instance que vous souhaitez utiliser. "" #: ./api-quick-start/src/docbkx/cli-uses.xml87(para) msgid """" ""To launch an instance named <literal>my_instance</literal>, run the "" ""<placeholder-1/> command with the image and flavor IDs and the server name, "" ""as follows:"" msgstr ""Pour lancer une instance qui s'appelle <literal>my_instance</literal>, excutez la commande <placeholder-1/> avec l'ID de l'image, celle du type d'instance et le nom du serveur, comme dans l'exemple suivant :"" #: ./api-quick-start/src/docbkx/cli-uses.xml122(para) msgid ""Use the <placeholder-1/> command to view your server:"" msgstr ""Utilisez la commande <placeholder-1/> pour voir votre serveur :"" #: ./api-quick-start/src/docbkx/cli-uses.xml130(para) msgid """" ""To view details for a specified server, use the <placeholder-1/> command. "" ""Include the ID of the server:"" msgstr ""Pour voir les dtails d'un serveur spcifique, utilisez la commande <placeholder-1/>. Incluez l'ID du serveur :"" #: ./api-quick-start/src/docbkx/cli-uses.xml165(para) msgid """" ""For information about the default ports that the OpenStack components use, "" ""see <link href=\""http://docs.openstack.org/trunk/config-reference/content"" ""/firewalls-default-ports.html\""><citetitle>Appendix A. Firewalls and default"" "" ports</citetitle></link> in the <citetitle>OpenStack Configuration "" ""Reference</citetitle>."" msgstr ""Pour obtenir plus d'informations  propos des ports par dfaut utiliss par les composants OpenStack, consultez <link href=\""http://docs.openstack.org/trunk/config-reference/content/firewalls-default-ports.html\""><citetitle>Appendix A. Firewalls and default ports</citetitle></link> in the <citetitle>OpenStack Configuration Reference</citetitle>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml8(title) msgid ""OpenStack API Quick Start"" msgstr ""Dmarrage rapide pour l'API OpenStack"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml10(para) msgid """" ""Although you install each OpenStack service separately, the OpenStack "" ""services work together to meet your cloud needs: Identity, Compute, Image "" ""Service, Block Storage, Networking (neutron), Object Storage, Orchestration,"" "" and Telemetry. With the <link "" ""href=\""http://www.trystack.org/\"">TryStack</link> OpenStack installation, "" ""these services work together in the background of the installation."" msgstr ""Mme si vous installez les services OpenStack sparment, ces derniers fonctionnent ensemble pour rpondre  vos besoins de Cloud computing : Authentification, Compute, Service d'image, Stockage de blocs, Stockage Objets, Orchestration et Tlmtrie. Avec l'installation de <link href=\""http://www.trystack.org/\"">TryStack</link>, ces services fonctionnent ensembles en arrire-plan."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml17(para) msgid """" ""After you authenticate through Identity, you can use the other OpenStack "" ""APIs to create and manage resources in your OpenStack cloud. You can launch "" ""instances from images and assign metadata to instances through the Compute "" ""API or the <placeholder-1/> command-line client."" msgstr ""Aprs vous tes identifi au travers du service d'authentification, vous pouvez utiliser les autres APIs OpenStack pour crer et grer des ressources dans votre Cloud OpenStack. Vous pouvez lancer des instances depuis des images et assigner des mtadonnes aux instances en utilisant l'API Compute ou le client de ligne de commande <placeholder-1/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml22(para) msgid ""To begin sending API requests, use one of the following methods:"" msgstr ""Pour commencer  envoyer des requtes API, utilisez une des mthodes suivantes :"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml26(emphasis) msgid ""cURL"" msgstr ""cURL"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml27(para) msgid """" ""A command-line tool that lets you send HTTP requests and receive responses. "" ""See <xref linkend=\""Compute_API_Quick_Start\""/>."" msgstr ""Un outil de ligne de commande permettant d'envoyer des requtes HTTP et de recevoir des rponses. Retrouvez plus d'informations en consultant : <xref linkend=\""Compute_API_Quick_Start\""/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml34(para) msgid """" ""Each OpenStack project provides a command-line client that enables you to "" ""access its API through easy-to-use commands. See <xref linkend=\""cli-"" ""intro\""/>."" msgstr ""Pour chaque projet OpenStack, il existe un client de ligne de commande permettant d'accder aux API au travers de commandes faciles  utiliser. Retrouvez plus d'informations en consultant : <xref linkend=\""cli-intro\""/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml40(emphasis) msgid ""REST clients"" msgstr ""Clients REST"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml41(para) msgid """" ""Both Mozilla and Google provide browser-based graphical interfaces for REST."" "" For Firefox, see <link href=\""https://addons.mozilla.org/en-"" ""US/firefox/addon/restclient/\"">RESTClient</link>. For Chrome, see <link "" ""href=\""http://code.google.com/p/rest-client/\"">rest-client</link>."" msgstr ""Mozilla et Google fournissent des interfaces graphiques intgres dans le navigateur pour utiliser REST. Sous Firefox, consultez <link href=\""https://addons.mozilla.org/en-US/firefox/addon/restclient/\"">RESTClient</link>. Sous Chrome, consultez <link href=\""http://code.google.com/p/rest-client/\"">rest-client</link>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml49(emphasis) msgid ""OpenStack Python Software Development Kit (SDK)"" msgstr ""Kit de dveloppement logiciel (SDK) OpenStack en Python"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml51(para) msgid """" ""Use this SDK to write Python automation scripts that create and manage "" ""resources in your OpenStack cloud. The SDK implements Python bindings to the"" "" OpenStack API, which enables you to perform automation tasks in Python by "" ""making calls on Python objects rather than making REST calls directly. All "" ""OpenStack command-line tools are implemented by using the Python SDK. See "" ""<link href=\""http://docs.openstack.org/user-"" ""guide/content/ch_sdk.html\"">OpenStack Python SDK</link> in the "" ""<citetitle>OpenStack End User Guide</citetitle>."" msgstr ""Utilisez ce SDK pour crire en Python des scripts d'automatisation pouvant crer et grer vos ressources dans votre Cloud OpenStack. Le SDK implmente des liaisons en Python pour l'API OpenStack. Il permet d'effectuer des tches d'automatisation en Python en faisant des appels Python objet au lieu de faire directement des appels en REST. Tous les clients de ligne de commande OpenStack sont implments  l'aide du SDK Python. Retrouvez plus d'informations dans la documentation <link href=\""http://docs.openstack.org/user-guide/content/ch_sdk.html\"">OpenStack Python SDK</link> qui se trouve dans le <citetitle>OpenStack End User Guide</citetitle>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml0(None)","""POT-Creation-Date: 2014-06-02 23:30+0000\n""#: ./api-quick-start/src/docbkx/cli-uses.xml6(title) #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml32(emphasis) msgid ""OpenStack command-line clients"" msgstr ""Clients de ligne de commande OpenStack"" #: ./api-quick-start/src/docbkx/cli-uses.xml7(para) msgid """" ""For scripting work, you can use a command-line client like the <systemitem "" ""role=\""client\"">python-novaclient</systemitem> client. This client enables "" ""you to use the Compute API through a command-line interface."" msgstr ""Pour travailler avec des scripts, vous pouvez utiliser un client de ligne de commande comme le client <systemitem role=\""client\"">python-novaclient</systemitem>. Ce client vous permet d'utiliser l'API Compute via une interface de ligne de commande. "" #: ./api-quick-start/src/docbkx/cli-uses.xml11(para) msgid """" ""For information about the command-line clients, see <link "" ""href=\""http://docs.openstack.org/cli-"" ""reference/content/\""><citetitle>OpenStack Command-Line Interface "" ""Reference</citetitle></link>."" msgstr ""Pour plus d'informations sur les clients en ligne de commande, consultez la documentation : <link href=\""http://docs.openstack.org/cli-reference/content/\""><citetitle>OpenStack Command-Line Interface Reference</citetitle></link>."" #: ./api-quick-start/src/docbkx/cli-uses.xml16(title) msgid ""Install the clients"" msgstr ""Installez les clients"" #: ./api-quick-start/src/docbkx/cli-uses.xml17(para) msgid """" ""Use <placeholder-1/> to install the OpenStack clients on a Mac OS X or Linux"" "" system. It is easy and ensures that you get the latest version of the "" ""client from the <link href=\""http://pypi.python.org/pypi\"">Python Package "" ""Index</link>. Also, <placeholder-2/> lets you update or remove a package."" msgstr ""Utilisez <placeholder-1/> pour installer le Client OpenStack sur Mac OS X ou sur les systmes Linux. C'est facile et vous pouvez vous assurer d'obtenir la dernire version du Client en utilisant <link href=\""http://pypi.python.org/pypi\"">l'index de paquets Python</link>. Par ailleurs, <placeholder-2/> vous permet de mettre  jour ou de supprimer le paquet."" #: ./api-quick-start/src/docbkx/cli-uses.xml23(para) msgid ""You must install each client separately."" msgstr ""Vous devez installer chaque client sparment."" #: ./api-quick-start/src/docbkx/cli-uses.xml24(para) msgid ""Run this command to install or update a client package:"" msgstr ""Lancez cette commande pour installer ou mettre  jour les paquets d'un client :"" #: ./api-quick-start/src/docbkx/cli-uses.xml26(replaceable) msgid ""PROJECT"" msgstr ""PROJECT"" #: ./api-quick-start/src/docbkx/cli-uses.xml27(para) msgid ""Where <replaceable>PROJECT</replaceable> is the project name."" msgstr ""Remplacez <replaceable>PROJECT</replaceable> par le nom du composant OpenStack."" #: ./api-quick-start/src/docbkx/cli-uses.xml29(para) msgid ""For example, to install the <placeholder-1/> client, run this command:"" msgstr ""Par exemple, pour installer le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml32(para) msgid ""To update the <placeholder-1/> client, run this command:"" msgstr ""Pour mettre  jour le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml35(para) msgid ""To remove the <placeholder-1/> client, run this command:"" msgstr ""Pour supprimer le client <placeholder-1/>, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml38(para) msgid """" ""Before you can issue client commands, you must download and source the "" ""<filename>openrc</filename> file to set environment variables."" msgstr ""Avant d'utiliser les clients de ligne de commande, vous devez tlcharger et sourcer le fichier <filename>openrc</filename> pour dfinir les variables d'environnement."" #: ./api-quick-start/src/docbkx/cli-uses.xml41(para) msgid """" ""For complete information about the OpenStack clients, including how to "" ""source the <filename>openrc</filename> file, see <link "" ""href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack "" ""End User Guide</citetitle></link>, <link href=\""http://docs.openstack.org"" ""/user-guide-admin/content/\""><citetitle>OpenStack Admin User "" ""Guide</citetitle></link>, and <link href=\""http://docs.openstack.org/cli-"" ""reference/content/\""><citetitle>OpenStack Command-Line Interface "" ""Reference</citetitle></link>."" msgstr ""Pour obtenir des informations compltes sur les clients OpenStack, y compris sur comment sourcer le fichier <filename>openrc</filename>, vous pouvez consulter les documentations suivantes : <link href=\""http://docs.openstack.org/user-guide/content/\""><citetitle>OpenStack End User Guide</citetitle></link>, <link href=\""http://docs.openstack.org/user-guide-admin/content/\""><citetitle>OpenStack Admin User Guide</citetitle></link>, and <link href=\""http://docs.openstack.org/cli-reference/content/\""><citetitle>OpenStack Command-Line Interface Reference</citetitle></link>."" #: ./api-quick-start/src/docbkx/cli-uses.xml59(title) msgid ""Launch an instance"" msgstr ""Lancer une instance"" #: ./api-quick-start/src/docbkx/cli-uses.xml60(para) msgid """" ""To launch instances, you must choose a name, an image, and a flavor for your"" "" instance."" msgstr ""Pour lancer des instances, vous devez choisir un nom, une image et un type d'instance."" #: ./api-quick-start/src/docbkx/cli-uses.xml62(para) msgid """" ""To list available images, call the Compute API through the <placeholder-1/> "" ""client, as follows:"" msgstr ""Pour lister les images disponibles, faites un appel sur l'API Compute en utilisant le client <placeholder-1/> :"" #: ./api-quick-start/src/docbkx/cli-uses.xml72(para) msgid ""To list flavors, run this command:"" msgstr ""Pour lister les types d'instances, lancez cette commande :"" #: ./api-quick-start/src/docbkx/cli-uses.xml85(para) msgid ""To launch an instance, note the IDs of your desired image and flavor."" msgstr ""Pour lancer une instance, notez les IDs de l'image et du type d'instance que vous souhaitez utiliser. "" #: ./api-quick-start/src/docbkx/cli-uses.xml87(para) msgid """" ""To launch an instance named <literal>my_instance</literal>, run the "" ""<placeholder-1/> command with the image and flavor IDs and the server name, "" ""as follows:"" msgstr ""Pour lancer une instance qui s'appelle <literal>my_instance</literal>, excutez la commande <placeholder-1/> avec l'ID de l'image, celle du type d'instance et le nom du serveur, comme dans l'exemple suivant :"" #: ./api-quick-start/src/docbkx/cli-uses.xml122(para) msgid ""Use the <placeholder-1/> command to view your server:"" msgstr ""Utilisez la commande <placeholder-1/> pour voir votre serveur :"" #: ./api-quick-start/src/docbkx/cli-uses.xml130(para) msgid """" ""To view details for a specified server, use the <placeholder-1/> command. "" ""Include the ID of the server:"" msgstr ""Pour voir les dtails d'un serveur spcifique, utilisez la commande <placeholder-1/>. Incluez l'ID du serveur :"" #: ./api-quick-start/src/docbkx/cli-uses.xml165(para) msgid """" ""For information about the default ports that the OpenStack components use, "" ""see <link href=\""http://docs.openstack.org/trunk/config-reference/content"" ""/firewalls-default-ports.html\""><citetitle>Appendix A. Firewalls and default"" "" ports</citetitle></link> in the <citetitle>OpenStack Configuration "" ""Reference</citetitle>."" msgstr ""Pour obtenir plus d'informations  propos des ports par dfaut utiliss par les composants OpenStack, consultez <link href=\""http://docs.openstack.org/trunk/config-reference/content/firewalls-default-ports.html\""><citetitle>Appendix A. Firewalls and default ports</citetitle></link> in the <citetitle>OpenStack Configuration Reference</citetitle>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml8(title) msgid ""OpenStack API Quick Start"" msgstr ""Dmarrage rapide pour l'API OpenStack"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml10(para) msgid """" ""Although you install each OpenStack service separately, the OpenStack "" ""services work together to meet your cloud needs: Identity, Compute, Image "" ""Service, Block Storage, Networking (neutron), Object Storage, Orchestration,"" "" and Telemetry. With the <link "" ""href=\""http://www.trystack.org/\"">TryStack</link> OpenStack installation, "" ""these services work together in the background of the installation."" msgstr ""Mme si vous installez les services OpenStack sparment, ces derniers fonctionnent ensemble pour rpondre  vos besoins de Cloud computing : Authentification, Compute, Service d'image, Stockage de blocs, Stockage Objets, Orchestration et Tlmtrie. Avec l'installation de <link href=\""http://www.trystack.org/\"">TryStack</link>, ces services fonctionnent ensembles en arrire-plan."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml17(para) msgid """" ""After you authenticate through Identity, you can use the other OpenStack "" ""APIs to create and manage resources in your OpenStack cloud. You can launch "" ""instances from images and assign metadata to instances through the Compute "" ""API or the <placeholder-1/> command-line client."" msgstr ""Aprs vous tes identifi au travers du service d'authentification, vous pouvez utiliser les autres APIs OpenStack pour crer et grer des ressources dans votre Cloud OpenStack. Vous pouvez lancer des instances depuis des images et assigner des mtadonnes aux instances en utilisant l'API Compute ou le client de ligne de commande <placeholder-1/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml22(para) msgid ""To begin sending API requests, use one of the following methods:"" msgstr ""Pour commencer  envoyer des requtes API, utilisez une des mthodes suivantes :"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml26(emphasis) msgid ""cURL"" msgstr ""cURL"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml27(para) msgid """" ""A command-line tool that lets you send HTTP requests and receive responses. "" ""See <xref linkend=\""Compute_API_Quick_Start\""/>."" msgstr ""Un outil de ligne de commande permettant d'envoyer des requtes HTTP et de recevoir des rponses. Retrouvez plus d'informations en consultant : <xref linkend=\""Compute_API_Quick_Start\""/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml34(para) msgid """" ""Each OpenStack project provides a command-line client that enables you to "" ""access its API through easy-to-use commands. See <xref linkend=\""cli-"" ""intro\""/>."" msgstr ""Pour chaque projet OpenStack, il existe un client de ligne de commande permettant d'accder aux API au travers de commandes faciles  utiliser. Retrouvez plus d'informations en consultant : <xref linkend=\""cli-intro\""/>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml40(emphasis) msgid ""REST clients"" msgstr ""Clients REST"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml41(para) msgid """" ""Both Mozilla and Google provide browser-based graphical interfaces for REST."" "" For Firefox, see <link href=\""https://addons.mozilla.org/en-"" ""US/firefox/addon/restclient/\"">RESTClient</link>. For Chrome, see <link "" ""href=\""http://code.google.com/p/rest-client/\"">rest-client</link>."" msgstr ""Mozilla et Google fournissent des interfaces graphiques intgres dans le navigateur pour utiliser REST. Sous Firefox, consultez <link href=\""https://addons.mozilla.org/en-US/firefox/addon/restclient/\"">RESTClient</link>. Sous Chrome, consultez <link href=\""http://code.google.com/p/rest-client/\"">rest-client</link>."" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml49(emphasis) msgid ""OpenStack Python Software Development Kit (SDK)"" msgstr ""Kit de dveloppement logiciel (SDK) OpenStack en Python"" #: ./api-quick-start/src/docbkx/api-quick-start-onepager.xml51(para) msgid """" ""Use this SDK to write Python automation scripts that create and manage "" ""resources in your OpenStack cloud. The SDK implements Python bindings to the"" "" OpenStack API, which enables you to perform automation tasks in Python by "" ""making calls on Python objects rather than making REST calls directly. All "" ""OpenStack command-line tools are implemented by using the Python SDK. See "" ""<link href=\""http://docs.openstack.org/user-"" ""guide/content/ch_sdk.html\"">OpenStack Python SDK</link> in the "" ""<citetitle>OpenStack End User Guide</citetitle>."" msgstr ""Utilisez ce SDK pour crire en Python des scripts d'automatisation pouvant crer et grer vos ressources dans votre Cloud OpenStack. Le SDK implmente des liaisons en Python pour l'API OpenStack. Il permet d'effectuer des tches d'automatisation en Python en faisant des appels Python objet au lieu de faire directement des appels en REST. Tous les clients de ligne de commande OpenStack sont implments  l'aide du SDK Python. Retrouvez plus d'informations dans la documentation <link href=\""http://docs.openstack.org/user-guide/content/ch_sdk.html\"">OpenStack Python SDK</link> qui se trouve dans le <citetitle>OpenStack End User Guide</citetitle>."" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml0(None)",1657,1657
openstack%2Fopenstack-doc-tools~master~Ie0b3894ab638c3620e5650cf77fdcfa33c2f7b48,openstack/openstack-doc-tools,master,Ie0b3894ab638c3620e5650cf77fdcfa33c2f7b48,Update README,MERGED,2014-06-24 06:15:58.000000000,2014-06-24 06:35:29.000000000,2014-06-24 06:35:29.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-24 06:15:58.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/e11eaf8949f1f553824416e2e37c2322ba4213d5', 'message': 'Update README\n\njsoncheck.py: add public API\n\nChange-Id: Ie0b3894ab638c3620e5650cf77fdcfa33c2f7b48\n'}]",0,102115,e11eaf8949f1f553824416e2e37c2322ba4213d5,7,2,1,11109,,,0,"Update README

jsoncheck.py: add public API

Change-Id: Ie0b3894ab638c3620e5650cf77fdcfa33c2f7b48
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/15/102115/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e11eaf8949f1f553824416e2e37c2322ba4213d5,update_readme,* ``jsoncheck.py``: add public API,,1,0
openstack%2Fpython-novaclient~master~If64a087944586ef5792efe3baa62e455b9bbaa07,openstack/python-novaclient,master,If64a087944586ef5792efe3baa62e455b9bbaa07,"""nova boot"" should not log an error if subsidiary commands fail",MERGED,2014-06-13 11:51:08.000000000,2014-06-24 06:33:11.000000000,2014-06-24 06:33:10.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 10068}, {'_account_id': 11787}]","[{'number': 1, 'created': '2014-06-13 11:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/461f13ec0bd3c11e5aa6e9fa6d63b1b3a5eca388', 'message': '""nova boot"" should not log an error if subsidiary commands fail\n\nFix:\nIntially the cli was raising ""CommadError"" in case the requested flavor or image were not present.\nThis error category was not approrpiate as it signifies an error in the command syntax. When the requested resource (flavour/image) does not exist, a ResourceNotFound error should be raised. So, added a new error category ""ResourceNotFound"" to cater for this scenario and updated the code to raise this new error.\n""nova show <instance_name>"" command has also been updated to raise ""ResourceNotFound"" error when the requested vm for which details have to be displayed does not exist.\nCloses-Bug #1258488\n\nChange-Id: If64a087944586ef5792efe3baa62e455b9bbaa07\n'}, {'number': 2, 'created': '2014-06-17 09:14:22.000000000', 'files': ['novaclient/openstack/common/apiclient/exceptions.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/utils.py', 'novaclient/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/b78c0d4f469a7e257962ede60cff472bf118e3d4', 'message': '""nova boot"" should not log an error if subsidiary commands fail\n\nFix:\nIntially the cli was raising ""CommadError"" in case the requested\nflavor or image were not present.\nThis error category was not approrpiate as it signifies an error\nin the command syntax. When the requested resource (flavour/image)\ndoes not exist, a ResourceNotFound error should be raised. So,\nadded a new error category ""ResourceNotFound"" to cater for this\nscenario and updated the code to raise this new error.\n""nova show <instance_name>"" command has also been updated to raise\n""ResourceNotFound"" error when the requested vm for which details\nhave to be displayed does not exist.\n\nCloses-Bug: #1258488\nChange-Id: If64a087944586ef5792efe3baa62e455b9bbaa07\n'}]",2,99915,b78c0d4f469a7e257962ede60cff472bf118e3d4,18,5,2,11787,,,0,"""nova boot"" should not log an error if subsidiary commands fail

Fix:
Intially the cli was raising ""CommadError"" in case the requested
flavor or image were not present.
This error category was not approrpiate as it signifies an error
in the command syntax. When the requested resource (flavour/image)
does not exist, a ResourceNotFound error should be raised. So,
added a new error category ""ResourceNotFound"" to cater for this
scenario and updated the code to raise this new error.
""nova show <instance_name>"" command has also been updated to raise
""ResourceNotFound"" error when the requested vm for which details
have to be displayed does not exist.

Closes-Bug: #1258488
Change-Id: If64a087944586ef5792efe3baa62e455b9bbaa07
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/15/99915/2 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/openstack/common/apiclient/exceptions.py', 'novaclient/tests/v1_1/test_shell.py', 'novaclient/utils.py', 'novaclient/tests/test_utils.py']",4,461f13ec0bd3c11e5aa6e9fa6d63b1b3a5eca388,master1," self.assertRaises(exceptions.ResourceNotFound, self.assertRaises(exceptions.ResourceNotFound, self.assertRaises(exceptions.ResourceNotFound,"," self.assertRaises(exceptions.CommandError, self.assertRaises(exceptions.CommandError, self.assertRaises(exceptions.CommandError,",10,5
openstack%2Fmistral-extra~master~I41a3e1bf1bc117d1c5230b9c42632ef41d1ba53b,openstack/mistral-extra,master,I41a3e1bf1bc117d1c5230b9c42632ef41d1ba53b,"Fixing access to OpenStack related data in ""create VM"" example",MERGED,2014-06-23 12:35:00.000000000,2014-06-24 06:17:58.000000000,2014-06-24 06:17:57.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8592}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-23 12:35:00.000000000', 'files': ['examples/create_vm/create_vm_example.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/df0f9b6ec52158f01b2418a3c8906099c0241b9f', 'message': 'Fixing access to OpenStack related data in ""create VM"" example\n\nChange-Id: I41a3e1bf1bc117d1c5230b9c42632ef41d1ba53b\n'}]",0,101902,df0f9b6ec52158f01b2418a3c8906099c0241b9f,7,5,1,8731,,,0,"Fixing access to OpenStack related data in ""create VM"" example

Change-Id: I41a3e1bf1bc117d1c5230b9c42632ef41d1ba53b
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/02/101902/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/create_vm/create_vm_example.yaml'],1,df0f9b6ec52158f01b2418a3c8906099c0241b9f,fix_publish_clause_in_examples, url: '{$.nova_url}/{$.openstack.project_id}/servers' X-Auth-Token: $.openstack.auth_token, url: '{$.nova_url}/{$.project_id}/servers' X-Auth-Token: $.auth_token project_id: $.project_id auth_token: $.auth_token,2,4
openstack%2Fcinder~master~I46c4755989fe61e0e654ca6daa3c3af0655071f0,openstack/cinder,master,I46c4755989fe61e0e654ca6daa3c3af0655071f0,VMware:Fix params for copy-image-to-volume,MERGED,2014-06-20 12:57:03.000000000,2014-06-24 06:17:41.000000000,2014-06-24 06:17:40.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-20 12:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c84e19ab37a32293cfe0081ec960163a9f3323a9', 'message': 'VMware:Fix params for copy-image-to-volume\n\nWhile creating a volume from stream-optimized image, the adapter type\nin the image meta-data and the profile in the volume type extra spec\nare ignored. This change fix those missing parameters.\n\nPartial-Bug: #1284284\nCloses-Bug: #1332482\nChange-Id: I46c4755989fe61e0e654ca6daa3c3af0655071f0\n'}, {'number': 2, 'created': '2014-06-23 06:12:37.000000000', 'files': ['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_vmware_vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b07c1a759c8a0cdaaaaaf3e6f1ad7402bf631a44', 'message': 'VMware:Fix params for copy-image-to-volume\n\nWhile creating a volume from stream-optimized image, the adapter type\nin the image meta-data and the profile in the volume type extra spec\nare ignored. This change fix those missing parameters.\n\nPartial-Bug: #1284284\nCloses-Bug: #1332482\nChange-Id: I46c4755989fe61e0e654ca6daa3c3af0655071f0\n'}]",0,101518,b07c1a759c8a0cdaaaaaf3e6f1ad7402bf631a44,18,6,2,9171,,,0,"VMware:Fix params for copy-image-to-volume

While creating a volume from stream-optimized image, the adapter type
in the image meta-data and the profile in the volume type extra spec
are ignored. This change fix those missing parameters.

Partial-Bug: #1284284
Closes-Bug: #1332482
Change-Id: I46c4755989fe61e0e654ca6daa3c3af0655071f0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/18/101518/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_vmware_vmdk.py']",2,c84e19ab37a32293cfe0081ec960163a9f3323a9,img_to_vol_stream_opt," @mock.patch.object(VMDK_DRIVER, '_get_storage_profile_id') def test_copy_image_to_volume_stream_optimized(self, volumeops, get_profile_id, get_profile_id, get_profile_id, adapter_type = 'ide' 'properties': {'vmware_disktype': 'streamOptimized', 'vmware_adaptertype': adapter_type}} profile_id = 'profile-1' get_profile_id.return_value = profile_id get_profile_id.assert_called_once_with(fake_volume) fake_summary.name, profile_id, adapter_type) @mock.patch.object(VMDK_DRIVER, '_get_storage_profile_id') get_profile_id, get_profile_id,"," def test_copy_image_to_volume_stream_optimized(self, volumeops, 'properties': {'vmware_disktype': 'streamOptimized'}} fake_summary.name)",45,19
openstack%2Fnova~master~Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1,openstack/nova,master,Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1,Don't follow HTTP_PROXY when talking to localhost test server,MERGED,2014-06-13 02:27:02.000000000,2014-06-24 06:15:58.000000000,2014-06-24 06:15:56.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6661}, {'_account_id': 7069}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11279}]","[{'number': 1, 'created': '2014-06-13 02:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb0f45d7762a42fc10e752471eefd80e7a83ac3f', 'message': ""Don't follow HTTP_PROXY when talking to localhost test server\n\nChange-Id: Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1\n""}, {'number': 2, 'created': '2014-06-13 05:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58a3b30bcbbcb071ccc37d1a8e9605185c49a2fb', 'message': ""Don't follow HTTP_PROXY when talking to localhost test server\n\nCloses-Bug: #1329614\nChange-Id: Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1\n""}, {'number': 3, 'created': '2014-06-23 04:28:22.000000000', 'files': ['nova/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7e54641fc1f760423c2f1210787903e17ea1cc06', 'message': ""Don't follow HTTP_PROXY when talking to localhost test server\n\nUnlike urllib2, requests honours HTTP_PROXY by default.  This meant\ntest_uri_length_limit's test queries to http://localhost:$port/ would\nhit the wrong localhost when $HTTP_PROXY was another host - resulting in a\nmeaningless test scenario and apparent failures with HTTP status codes\nother than the expected REQUEST_URI_TOO_LARGE (414).\n\nThis change forces requests to go direct for those test queries.\n\nCloses-Bug: #1329614\nChange-Id: Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1\n""}]",1,99823,7e54641fc1f760423c2f1210787903e17ea1cc06,58,13,3,11279,,,0,"Don't follow HTTP_PROXY when talking to localhost test server

Unlike urllib2, requests honours HTTP_PROXY by default.  This meant
test_uri_length_limit's test queries to http://localhost:$port/ would
hit the wrong localhost when $HTTP_PROXY was another host - resulting in a
meaningless test scenario and apparent failures with HTTP status codes
other than the expected REQUEST_URI_TOO_LARGE (414).

This change forces requests to go direct for those test queries.

Closes-Bug: #1329614
Change-Id: Ida3424ca9a750bd2d3f2e81dc7dfacc2a334adf1
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/99823/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/test_wsgi.py'],1,eb0f45d7762a42fc10e752471eefd80e7a83ac3f,uri-length-test-noproxy," resp = requests.get(uri, proxies={""http"": """"}) resp = requests.get(uri, proxies={""http"": """"})", resp = requests.get(uri) resp = requests.get(uri),2,2
openstack%2Ftempest~master~I86aeae6a6337ce60e2b69e207a6e015950b95a36,openstack/tempest,master,I86aeae6a6337ce60e2b69e207a6e015950b95a36,Verify create agent attributes of V2/V3 APIs,MERGED,2014-04-01 05:18:56.000000000,2014-06-24 06:15:47.000000000,2014-06-24 06:15:47.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 6167}, {'_account_id': 7882}, {'_account_id': 9695}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-01 05:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/edae5df51049409c8d2000c741dc1ca394fcc141', 'message': 'Verify create agent attributes of V2/V3 APIs\n\nThis patch adds the JSON schema for Nova V2/V3 create agent APIs\nincludes the attributes to block the backward incompatibility change\nin the future.\n\nThe response body of v2 and v3 API is the below:\n{\n    ""agent"": {\n        ""agent_id"": 1,\n        ""hypervisor"": ""xen"",\n        ""os"": ""linux"",\n        ""architecture"": ""x86"",\n        ""version"": ""7.0"",\n        ""url"": ""xxx://xxx/xxx/xxx1"",\n        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36\n'}, {'number': 4, 'created': '2014-04-03 01:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6bdb61c0dc6db0b3beec56d8aed538e4ac3a1194', 'message': 'Verify create agent attributes of V2/V3 APIs\n\nThis patch adds the JSON schema for Nova V2/V3 create agent APIs\nincludes the attributes to block the backward incompatibility change\nin the future.\n\nThe response body of v2 and v3 API is the below:\n{\n    ""agent"": {\n        ""agent_id"": 1,\n        ""hypervisor"": ""xen"",\n        ""os"": ""linux"",\n        ""architecture"": ""x86"",\n        ""version"": ""7.0"",\n        ""url"": ""xxx://xxx/xxx/xxx1"",\n        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36\n'}, {'number': 3, 'created': '2014-04-03 01:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9efd069a0b1daaa55fe59bf2b172db98a3a789f', 'message': 'Verify create agent attributes of V2/V3 APIs\n\nThis patch adds the JSON schema for Nova V2/V3 create agent APIs\nincludes the attributes to block the backward incompatibility change\nin the future.\n\nThe response body of v2 and v3 API is the below:\n{\n    ""agent"": {\n        ""agent_id"": 1,\n        ""hypervisor"": ""xen"",\n        ""os"": ""linux"",\n        ""architecture"": ""x86"",\n        ""version"": ""7.0"",\n        ""url"": ""xxx://xxx/xxx/xxx1"",\n        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36\n'}, {'number': 2, 'created': '2014-04-03 01:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7fe81e481293233b9a7873f57bad7139ab3ca712', 'message': 'Verify create agent attributes of V2/V3 APIs\n\nThis patch adds the JSON schema for Nova V2/V3 create agent APIs\nincludes the attributes to block the backward incompatibility change\nin the future.\n\nThe response body of v2 and v3 API is the below:\n{\n    ""agent"": {\n        ""agent_id"": 1,\n        ""hypervisor"": ""xen"",\n        ""os"": ""linux"",\n        ""architecture"": ""x86"",\n        ""version"": ""7.0"",\n        ""url"": ""xxx://xxx/xxx/xxx1"",\n        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36\n'}, {'number': 5, 'created': '2014-06-24 02:27:35.000000000', 'files': ['tempest/api_schema/compute/v2/agents.py', 'tempest/api_schema/compute/agents.py', 'tempest/services/compute/json/agents_client.py', 'tempest/api_schema/compute/v3/agents.py', 'tempest/services/compute/v3/json/agents_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/34e98ad7cc8624c2f27d5374360d34917d99466b', 'message': 'Verify create agent attributes of V2/V3 APIs\n\nThis patch adds the JSON schema for Nova V2/V3 create agent APIs\nincludes the attributes to block the backward incompatibility change\nin the future.\n\nThe response body of v2 and v3 API is the below:\n{\n    ""agent"": {\n        ""agent_id"": 1,\n        ""hypervisor"": ""xen"",\n        ""os"": ""linux"",\n        ""architecture"": ""x86"",\n        ""version"": ""7.0"",\n        ""url"": ""xxx://xxx/xxx/xxx1"",\n        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""\n    }\n}\n\nPartially implements blueprint nova-api-attribute-test\n\nChange-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36\n'}]",8,84344,34e98ad7cc8624c2f27d5374360d34917d99466b,50,8,5,7882,,,0,"Verify create agent attributes of V2/V3 APIs

This patch adds the JSON schema for Nova V2/V3 create agent APIs
includes the attributes to block the backward incompatibility change
in the future.

The response body of v2 and v3 API is the below:
{
    ""agent"": {
        ""agent_id"": 1,
        ""hypervisor"": ""xen"",
        ""os"": ""linux"",
        ""architecture"": ""x86"",
        ""version"": ""7.0"",
        ""url"": ""xxx://xxx/xxx/xxx1"",
        ""md5hash"": ""add6bb58e139be103324d04d82d8f546""
    }
}

Partially implements blueprint nova-api-attribute-test

Change-Id: I86aeae6a6337ce60e2b69e207a6e015950b95a36
",git fetch https://review.opendev.org/openstack/tempest refs/changes/44/84344/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api_schema/compute/v2/agents.py', 'tempest/api_schema/compute/agents.py', 'tempest/services/compute/json/agents_client.py', 'tempest/api_schema/compute/v3/agents.py', 'tempest/services/compute/v3/json/agents_client.py']",5,edae5df51049409c8d2000c741dc1ca394fcc141,bp/nova-api-attribute-test,"from tempest.api_schema.compute.v3 import agents as schema body = json.loads(body) self.validate_response(schema.create_agent, resp, body) return resp, body['agent']"," return resp, self._parse_resp(body)",88,2
openstack%2Fmistral~master~I8b92c0a225f2db49d6deca3d06f70271156b7073,openstack/mistral,master,I8b92c0a225f2db49d6deca3d06f70271156b7073,Fixing wrong access to Mistral security context in engine,MERGED,2014-06-23 13:15:52.000000000,2014-06-24 06:09:46.000000000,2014-06-24 06:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-23 13:15:52.000000000', 'files': ['mistral/engine/__init__.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/1933b7d555e9ffd0e4a1fec688268a622bd75f4c', 'message': 'Fixing wrong access to Mistral security context in engine\n\nChange-Id: I8b92c0a225f2db49d6deca3d06f70271156b7073\n'}]",0,101910,1933b7d555e9ffd0e4a1fec688268a622bd75f4c,16,6,1,8731,,,0,"Fixing wrong access to Mistral security context in engine

Change-Id: I8b92c0a225f2db49d6deca3d06f70271156b7073
",git fetch https://review.opendev.org/openstack/mistral refs/changes/10/101910/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/engine/__init__.py'],1,1933b7d555e9ffd0e4a1fec688268a622bd75f4c,fix_auth_ctx_bugs," def _add_variables_to_data_flow_context(cls, df_ctx, execution): data_flow.add_openstack_data_to_context(df_ctx, db_workbook) data_flow.add_execution_to_context(df_ctx, execution) # TODO(rakhmerov): Reavaluate parameter 'context' once it's clear # how to work with trust chains correctly in keystone # (waiting for corresponding changes to be made). def run_delayed_task(context): :param context Mistral authentication context inherited from a caller thread. auth_context.set_ctx(context) cntx = auth_context.ctx() cntx = auth_context.ctx()"," def _add_variables_to_data_flow_context(cls, context, execution): data_flow.add_openstack_data_to_context(context, db_workbook) data_flow.add_execution_to_context(context, execution) def run_delayed_task(): # TODO(m4dcoder): refactor auth context cntx = {} # TODO(m4dcoder): refactor auth context cntx = {}",16,8
openstack%2Fnova~master~Id7c6620704fef504d23cb42c5218251fa9e2dba7,openstack/nova,master,Id7c6620704fef504d23cb42c5218251fa9e2dba7,Determine shared ip from table instead of flag,MERGED,2014-05-15 16:15:58.000000000,2014-06-24 05:19:37.000000000,2014-06-24 05:19:35.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9847}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-15 16:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5857d160ec38a7f4b031af2c96d80c793e67d027', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 2, 'created': '2014-05-15 18:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60c1b86911c8ac6a80dc10d4bc75832752e49b78', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 3, 'created': '2014-05-18 19:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f60d7990ea1b1d4d05d9fab9c86da9be964bba2', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 4, 'created': '2014-05-20 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7791f7cd02b425b7bd3dd9a33730ec63d01614bf', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 5, 'created': '2014-05-20 23:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/093e85edc79dd4a97062c79c8ec258a4ac684448', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 6, 'created': '2014-05-21 04:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/297ee5fd3849da071e24a7d50a4a1feb46f8c6af', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 7, 'created': '2014-05-21 06:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d87181f5aaa827c9b8489a7b4beb4ca1242d7c86', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 8, 'created': '2014-05-30 23:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b636285e48a020c66fce2a7ef3a69cba3a74cc3', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 9, 'created': '2014-06-16 18:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f45fc5b077e8da4464705927194c84f3398a788', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}, {'number': 10, 'created': '2014-06-19 16:24:26.000000000', 'files': ['nova/objects/network.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/tests/network/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e29a80022c305fa5050e83fe7a420d5a57f7a9b4', 'message': 'Determine shared ip from table instead of flag\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7\n'}]",9,93755,e29a80022c305fa5050e83fe7a420d5a57f7a9b4,100,13,10,67,,,0,"Determine shared ip from table instead of flag

Partially-implements blueprint better-support-for-multiple-networks

Change-Id: Id7c6620704fef504d23cb42c5218251fa9e2dba7
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/93755/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/network.py', 'nova/network/manager.py']",2,5857d160ec38a7f4b031af2c96d80c793e67d027,bp/better-support-for-multiple-networks, @staticmethod def _uses_shared_ip(network): shared = network.get('share_address') or CONF.share_dhcp_address return not network.get('multi_host') or shared if self._uses_shared_ip(network_ref): if not self._uses_shared_ip(network):, # NOTE(vish): this is for compatibility if not network_ref.get('multi_host') or CONF.share_dhcp_address: if not CONF.share_dhcp_address:,11,6
openstack%2Fnova~master~Ic9c60071480abc5fced04dab5fc79ea44db1e10d,openstack/nova,master,Ic9c60071480abc5fced04dab5fc79ea44db1e10d,Set reasonable defaults for new network values,MERGED,2014-05-15 16:15:58.000000000,2014-06-24 05:19:23.000000000,2014-06-24 05:19:21.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 8125}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-15 16:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3831c9b428d912047c69509cf91ea146116f6966', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 2, 'created': '2014-05-15 18:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a305308c7e5889eecee87e8c304d6ca2e3157c0d', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 3, 'created': '2014-05-18 19:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b17218f8a7ba15874b88830ff2df035ec39d4d12', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 4, 'created': '2014-05-20 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9652ff3a53be6c1220c12fcc14aea22831829e03', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 5, 'created': '2014-05-20 23:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4af0baa71ee9c80538a0a8334868f8f71ef8865', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 6, 'created': '2014-05-30 23:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1f2fcbb5398ba36ac01c73ac9456a44d56ffe04', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 7, 'created': '2014-06-16 18:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f55452eabf7df21184325fb1cd37a13265a892ef', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}, {'number': 8, 'created': '2014-06-19 16:24:26.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/447641972539f1e13923c6ee5d64169f4229b856', 'message': 'Set reasonable defaults for new network values\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d\n'}]",9,93754,447641972539f1e13923c6ee5d64169f4229b856,100,15,8,67,,,0,"Set reasonable defaults for new network values

Partially-implements blueprint better-support-for-multiple-networks

Change-Id: Ic9c60071480abc5fced04dab5fc79ea44db1e10d
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/93754/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,3831c9b428d912047c69509cf91ea146116f6966,bp/better-support-for-multiple-networks," def fake_create_fixed_ips(self, context, network_id, fixed_cidr=None, extra_reserved=None):"," def fake_create_fixed_ips(self, context, network_id, fixed_cidr=None):",36,5
openstack%2Fswift~master~Idbd918f8e8d3ec5a4110725b949710fb54b4ba9a,openstack/swift,master,Idbd918f8e8d3ec5a4110725b949710fb54b4ba9a,Change assertCalledWith to assert_called_with,MERGED,2014-06-10 15:11:20.000000000,2014-06-24 05:04:07.000000000,2014-06-24 05:04:06.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-06-10 15:11:20.000000000', 'files': ['test/unit/cli/test_recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d32169c9c869b96c1b9db6654b9d8e6f47fc2686', 'message': 'Change assertCalledWith to assert_called_with\n\nIn test_ptime() 2 uses of the former failed to assert with bogus\nvalues used in the assert.  Using assert_called_with() instead\ncorrectly performs the assertion.\n\nChange-Id: Idbd918f8e8d3ec5a4110725b949710fb54b4ba9a\n'}]",0,99124,d32169c9c869b96c1b9db6654b9d8e6f47fc2686,26,5,1,7479,,,0,"Change assertCalledWith to assert_called_with

In test_ptime() 2 uses of the former failed to assert with bogus
values used in the assert.  Using assert_called_with() instead
correctly performs the assertion.

Change-Id: Idbd918f8e8d3ec5a4110725b949710fb54b4ba9a
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/99124/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/cli/test_recon.py'],1,d32169c9c869b96c1b9db6654b9d8e6f47fc2686,trecon, mock_localtime.assert_called_with(1387274400) mock_localtime.assert_called_with(), mock_localtime.assertCalledWith(1387274400) mock_localtime.assertCalledWith(),2,2
openstack%2Fpython-glanceclient~master~Ib1db1a2dca7b5d8cbfe823973e4b571d0f0925c5,openstack/python-glanceclient,master,Ib1db1a2dca7b5d8cbfe823973e4b571d0f0925c5,Change assertTrue(isinstance()) by optimal assert,MERGED,2014-03-06 08:21:57.000000000,2014-06-24 04:01:10.000000000,2014-06-24 04:01:09.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 9569}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-03-06 08:21:57.000000000', 'files': ['tests/test_exc.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ab5c5b5d7c214b17b48add9caeaa36a81e3886f5', 'message': 'Change assertTrue(isinstance()) by optimal assert\n\nassertTrue(isinstance(A, B)) or assertEqual(type(A), B) in tests\nshould be replaced by assertIsInstance(A, B) provided by testtools.\n\nI have searched all the tests, there is only one wrong usage.\n\nChange-Id: Ib1db1a2dca7b5d8cbfe823973e4b571d0f0925c5\nCloses-bug: #1268480\n'}]",0,78542,ab5c5b5d7c214b17b48add9caeaa36a81e3886f5,40,8,1,9101,,,0,"Change assertTrue(isinstance()) by optimal assert

assertTrue(isinstance(A, B)) or assertEqual(type(A), B) in tests
should be replaced by assertIsInstance(A, B) provided by testtools.

I have searched all the tests, there is only one wrong usage.

Change-Id: Ib1db1a2dca7b5d8cbfe823973e4b571d0f0925c5
Closes-bug: #1268480
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/42/78542/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_exc.py'],1,ab5c5b5d7c214b17b48add9caeaa36a81e3886f5,bug/1268480," self.assertIsInstance(out, exc.HTTPBadRequest)"," self.assertTrue(isinstance(out, exc.HTTPBadRequest))",1,1
openstack%2Fnova~master~I7f0a1460b948a852c2d61d24217bbf27a4d85859,openstack/nova,master,I7f0a1460b948a852c2d61d24217bbf27a4d85859,Adds IVS unit tests for new VIF firewall logic,MERGED,2014-04-02 01:12:48.000000000,2014-06-24 04:01:00.000000000,2014-06-24 04:00:57.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 6873}, {'_account_id': 7787}, {'_account_id': 8163}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-02 01:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a09aa71bb9c34a4c27e23312ed32b774d3125a9c', 'message': 'Adds IVS unit tests for new VIF firewall logic\n\nAdds new unit tests for the IVS VIF driver to\ncover the various possible plugging behaviors\nadded by the vif_details based logic introduced\nin change I3bbcfc67036ab7389c82720add0bc0fc627bfee0.\n\nCloses-Bug: #1301087\nChange-Id: I7f0a1460b948a852c2d61d24217bbf27a4d85859\n'}, {'number': 2, 'created': '2014-05-30 22:36:54.000000000', 'files': ['nova/tests/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ddefddd1a64e3eef776a99b77aba003b081f2695', 'message': 'Adds IVS unit tests for new VIF firewall logic\n\nAdds new unit tests for the IVS VIF driver to\ncover the various possible plugging behaviors\nadded by the vif_details based logic introduced\nin change I3bbcfc67036ab7389c82720add0bc0fc627bfee0.\n\nCloses-Bug: #1301087\nChange-Id: I7f0a1460b948a852c2d61d24217bbf27a4d85859\n'}]",0,84597,ddefddd1a64e3eef776a99b77aba003b081f2695,68,17,2,7787,,,0,"Adds IVS unit tests for new VIF firewall logic

Adds new unit tests for the IVS VIF driver to
cover the various possible plugging behaviors
added by the vif_details based logic introduced
in change I3bbcfc67036ab7389c82720add0bc0fc627bfee0.

Closes-Bug: #1301087
Change-Id: I7f0a1460b948a852c2d61d24217bbf27a4d85859
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/84597/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_libvirt_vif.py'],1,a09aa71bb9c34a4c27e23312ed32b774d3125a9c,bug/1301087," vif_ivs_filter_direct = network_model.VIF(id='vif-xxx-yyy-zzz', address='ca:fe:de:ad:be:ef', network=network_ivs, type=network_model.VIF_TYPE_IVS, details={'port_filter': True}, devname='tap-xxx-yyy-zzz', ovs_interfaceid='aaa-bbb-ccc') vif_ivs_filter_hybrid = network_model.VIF(id='vif-xxx-yyy-zzz', address='ca:fe:de:ad:be:ef', network=network_ivs, type=network_model.VIF_TYPE_IVS, details={ 'port_filter': True, 'ovs_hybrid_plug': True}, devname='tap-xxx-yyy-zzz', ovs_interfaceid='aaa-bbb-ccc') def test_ivs_plug_with_nova_firewall(self): d = vif.LibvirtGenericVIFDriver(self._get_conn()) br_want = ""qbr"" + self.vif_ivs['id'] br_want = br_want[:network_model.NIC_NAME_LEN] xml = self._get_instance_xml(d, self.vif_ivs) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""bridge"", ""source"", ""bridge"", self.vif_ivs, br_want, 1) def test_ivs_plug_with_port_filter_direct_no_nova_firewall(self): d = vif.LibvirtGenericVIFDriver(self._get_conn()) br_want = ""qbr"" + self.vif_ivs_filter_hybrid['id'] br_want = br_want[:network_model.NIC_NAME_LEN] self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") xml = self._get_instance_xml(d, self.vif_ivs_filter_hybrid) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""bridge"", ""source"", ""bridge"", self.vif_ivs_filter_hybrid, br_want, 0) def test_ivs_plug_with_port_filter_hybrid_no_nova_firewall(self): d = vif.LibvirtGenericVIFDriver(self._get_conn()) br_want = self.vif_ivs_filter_direct['devname'] self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") xml = self._get_instance_xml(d, self.vif_ivs_filter_direct) node = self._get_node(xml) self._assertTypeAndMacEquals(node, ""ethernet"", ""target"", ""dev"", self.vif_ivs_filter_direct, br_want, 0) ",,46,0
openstack%2Fcinder~master~I788f07c33f76693a13f0d581e687a32c6736a394,openstack/cinder,master,I788f07c33f76693a13f0d581e687a32c6736a394,test_storwize_vdisk_copy_ops fails if green thread context switch,MERGED,2014-06-20 10:08:20.000000000,2014-06-24 03:35:31.000000000,2014-06-24 03:35:30.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 6491}, {'_account_id': 6849}, {'_account_id': 7198}, {'_account_id': 7491}, {'_account_id': 8587}, {'_account_id': 9751}, {'_account_id': 10068}, {'_account_id': 11079}]","[{'number': 1, 'created': '2014-06-20 10:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7598d1f1cff7f4553621c18c6ba7c0f712bc2e2d', 'message': "" StorwizeSVCDriverTestCase.test_storwize_vdisk_copy_ops fails if there is a context switch to another green thread\nReason:\n1. test_storwize_svc._cmd_lsvdiskcopy  is mocked as when first called, sync value is No, when call second time, value will be Yes\n2._check_volume_copy_ops will call _cmd_lsvdiskcopy(). if Sync value is yes, it will call fun: _rm_vdisk_copy_op()\n3.There is loopingcall is running _check_volume_copy_ops()\n4.  self.sleeppatch = mock.patch('eventlet.greenthread.sleep')\n    self.sleeppatch.start() is used to stop the looping call.\n    If remove this, the looping call will make this test case run twice _rm_vdisk_copy_op().\n    But in  _rm_vdisk_copy_op(), the KeyError is not catched which cause test case fail.\n5.KeyError should be catched in\nthe code:\nself.sleeppatch = mock.patch('eventlet.greenthread.sleep')\nself.sleeppatch.start()\n should be removed.\n\nFixes Bug#1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n""}, {'number': 2, 'created': '2014-06-23 05:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0564b0a74fc2c88b8dbce4df70bd38b2f7180f75', 'message': 'test_storwize_vdisk_copy_ops fails if green thread context switch\n\nThere is loopingcall(green thread)will cause _rm_vdisk_copy_op() run\ntwice.On the second time, the exception KeyError is not catched.\n\nFixes Bug#1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n'}, {'number': 3, 'created': '2014-06-23 05:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89fb80bdad1a004c76300a5578643626e74275c0', 'message': 'test_storwize_vdisk_copy_ops fails if green thread context switch\n\nThere is loopingcall(green thread)will cause _rm_vdisk_copy_op() run\ntwice.On the second time, the exception KeyError is not caught.\n\nCloses-Bug: #1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n'}, {'number': 4, 'created': '2014-06-23 07:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4b44176a71036695a00b2baec754500b4952bc3f', 'message': 'test_storwize_vdisk_copy_ops fails if green thread context switch\n\nThere is loopingcall(green thread)will cause _rm_vdisk_copy_op() run\ntwice.On the second time, the exception KeyError is not caught.\n\nCloses-Bug: #1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n'}, {'number': 5, 'created': '2014-06-23 07:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3528e0eedf2b37ce5f7cd53adcb2081472ea1306', 'message': 'test_storwize_vdisk_copy_ops fails if green thread context switch\n\nThere is loopingcall(green thread)will cause _rm_vdisk_copy_op() run\ntwice.On the second time, the exception KeyError is not caught.\n\nCloses-Bug: #1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n'}, {'number': 6, 'created': '2014-06-23 09:34:24.000000000', 'files': ['cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/tests/test_storwize_svc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0edfa2eaab08a0756bf3ec7818cdc9a8a379ba87', 'message': 'test_storwize_vdisk_copy_ops fails if green thread context switch\n\nThere is loopingcall(green thread)will cause _rm_vdisk_copy_op() run\ntwice.On the second time, the exception KeyError is not caught.\n\nCloses-Bug: #1302670\n\nChange-Id: I788f07c33f76693a13f0d581e687a32c6736a394\n'}]",7,101470,0edfa2eaab08a0756bf3ec7818cdc9a8a379ba87,42,10,6,11079,,,0,"test_storwize_vdisk_copy_ops fails if green thread context switch

There is loopingcall(green thread)will cause _rm_vdisk_copy_op() run
twice.On the second time, the exception KeyError is not caught.

Closes-Bug: #1302670

Change-Id: I788f07c33f76693a13f0d581e687a32c6736a394
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/101470/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/tests/test_storwize_svc.py']",2,7598d1f1cff7f4553621c18c6ba7c0f712bc2e2d,master,, self.sleeppatch = mock.patch('eventlet.greenthread.sleep') self.sleeppatch.start() if self.USESIM: self.sleeppatch.stop(),1,5
openstack%2Fpython-keystoneclient~master~Ib8e698d85fd598fa91435538657361a1f695ce89,openstack/python-keystoneclient,master,Ib8e698d85fd598fa91435538657361a1f695ce89,Update keystoneclient code to account for hacking 0.9.2,MERGED,2014-06-16 06:17:25.000000000,2014-06-24 03:27:55.000000000,2014-06-24 03:27:54.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1091}, {'_account_id': 1916}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-06-16 06:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/66fd4cc6143bb5ace27d39ef8639a08679044e84', 'message': ""Update keystoneclient code to account for hacking 0.9.2\n\nFixed most of the errors reported back from hacking 0.9.2.\nSpecifically:\n- E128 continuation line under-indented for visual indent\n- E251 unexpected spaces around keyword / parameter equals\n- E265 block comment should start with '# '\n- H305 imports not grouped correctly\n- H307 like imports should be grouped together\n- H402 one line docstring needs punctuation\n- H904 Wrap long lines in parentheses instead of a backslash\n\nBut opted to ignore the following for now:\n- E122: continuation line missing indentation or outdented\n- H405: multi line docstring summary not separated with an empty line\n\nChange-Id: Ib8e698d85fd598fa91435538657361a1f695ce89\n""}, {'number': 2, 'created': '2014-06-20 02:15:36.000000000', 'files': ['keystoneclient/middleware/memcache_crypt.py', 'keystoneclient/auth/base.py', 'keystoneclient/tests/test_shell.py', 'keystoneclient/httpclient.py', 'keystoneclient/tests/test_keyring.py', 'keystoneclient/v2_0/shell.py', 'keystoneclient/v2_0/users.py', 'keystoneclient/tests/v2_0/fakes.py', 'keystoneclient/auth/identity/base.py', 'keystoneclient/v2_0/tenants.py', 'keystoneclient/tests/test_auth_token_middleware.py', 'keystoneclient/tests/utils.py', 'keystoneclient/middleware/s3_token.py', 'tox.ini', 'keystoneclient/middleware/auth_token.py', 'keystoneclient/tests/v2_0/test_tenants.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1c64e5c1f73b9968002741bb6ac96a2518b2b6f7', 'message': ""Update keystoneclient code to account for hacking 0.9.2\n\nFixed most of the errors reported back from hacking 0.9.2.\nSpecifically:\n- E128 continuation line under-indented for visual indent\n- E251 unexpected spaces around keyword / parameter equals\n- E265 block comment should start with '# '\n- H305 imports not grouped correctly\n- H307 like imports should be grouped together\n- H402 one line docstring needs punctuation\n- H904 Wrap long lines in parentheses instead of a backslash\n\nBut opted to ignore the following for now:\n- E122: continuation line missing indentation or outdented\n- H405: multi line docstring summary not separated with an empty line\n\nChange-Id: Ib8e698d85fd598fa91435538657361a1f695ce89\n""}]",9,100152,1c64e5c1f73b9968002741bb6ac96a2518b2b6f7,48,11,2,6482,,,0,"Update keystoneclient code to account for hacking 0.9.2

Fixed most of the errors reported back from hacking 0.9.2.
Specifically:
- E128 continuation line under-indented for visual indent
- E251 unexpected spaces around keyword / parameter equals
- E265 block comment should start with '# '
- H305 imports not grouped correctly
- H307 like imports should be grouped together
- H402 one line docstring needs punctuation
- H904 Wrap long lines in parentheses instead of a backslash

But opted to ignore the following for now:
- E122: continuation line missing indentation or outdented
- H405: multi line docstring summary not separated with an empty line

Change-Id: Ib8e698d85fd598fa91435538657361a1f695ce89
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/52/100152/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/middleware/memcache_crypt.py', 'keystoneclient/auth/base.py', 'keystoneclient/tests/test_shell.py', 'keystoneclient/httpclient.py', 'keystoneclient/tests/test_keyring.py', 'keystoneclient/common/cms.py', 'keystoneclient/v2_0/shell.py', 'keystoneclient/v2_0/users.py', 'keystoneclient/tests/v2_0/fakes.py', 'keystoneclient/auth/identity/base.py', 'keystoneclient/v2_0/tenants.py', 'keystoneclient/tests/test_auth_token_middleware.py', 'keystoneclient/tests/utils.py', 'keystoneclient/middleware/s3_token.py', 'tox.ini', 'keystoneclient/middleware/auth_token.py', 'keystoneclient/tests/v2_0/test_tenants.py']",17,66fd4cc6143bb5ace27d39ef8639a08679044e84,pass_hacking," # ""extraname"": ""dontoverwrite!"","," #""extraname"": ""dontoverwrite!"",",65,59
openstack%2Fnova~master~I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b,openstack/nova,master,I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b,Don't store duplicate policies for server_group,MERGED,2014-05-29 08:37:30.000000000,2014-06-24 03:26:29.000000000,2014-06-24 03:26:26.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 681}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 8021}, {'_account_id': 8871}, {'_account_id': 8890}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-29 08:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23fe2861e303d04a2a841ce5e3cbec342da11ab6', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nChange-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nCloses-Bug: #1324348\n""}, {'number': 2, 'created': '2014-06-03 02:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e4e202409ee04bb9ca6f673b0641d6ab4e1dce4', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nChange-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nCloses-Bug: #1324348\n""}, {'number': 3, 'created': '2014-06-04 03:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87198ae9641c20300fccc8dae92df8562aba8347', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nChange-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nCloses-Bug: #1324348\n""}, {'number': 4, 'created': '2014-06-17 03:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/128178a8278cd11a135ccfe50d38dbde2d391e6a', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nChange-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nCloses-Bug: #1324348\n""}, {'number': 5, 'created': '2014-06-19 01:23:07.000000000', 'files': ['nova/api/openstack/compute/contrib/server_groups.py', 'nova/tests/api/openstack/compute/contrib/test_server_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/57eef4dd26b1caa487e78fadb0f02f1d5154a508', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe need to deny this usage in server_group creation.\n\nChange-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nCloses-Bug: #1324348\n""}]",11,96397,57eef4dd26b1caa487e78fadb0f02f1d5154a508,91,15,5,8021,,,0,"Don't store duplicate policies for server_group

It doesn't make sense to store same policies in a server_group.
We need to deny this usage in server_group creation.

Change-Id: I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b
Closes-Bug: #1324348
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/96397/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/server_groups.py', 'nova/tests/api/openstack/compute/contrib/test_server_groups.py']",2,23fe2861e303d04a2a841ce5e3cbec342da11ab6,bug/1324348," def test_create_server_group_with_duplicate_policies(self): req = fakes.HTTPRequest.blank('/v2/fake/os-server-groups') sgroup = server_group_template() policies = ['affinity', 'affinity'] sgroup['policies'] = policies res_dict = self.controller.create(req, {'server_group': sgroup}) self.assertEqual(res_dict['server_group']['name'], 'test') self.assertTrue(uuidutils.is_uuid_like(res_dict['server_group']['id'])) self.assertEqual(res_dict['server_group']['policies'], ['affinity']) ",,12,1
openstack%2Fnova~stable%2Ficehouse~Id7181755d3609c0ae91c2402b34f2de02c06a1f0,openstack/nova,stable/icehouse,Id7181755d3609c0ae91c2402b34f2de02c06a1f0,Bump stable/icehouse next version to 2014.1.2,MERGED,2014-06-23 23:11:07.000000000,2014-06-24 03:26:15.000000000,2014-06-24 03:26:13.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-06-23 23:11:07.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/5196cf686be71c407308ec5d44eafe83fae3fef3', 'message': 'Bump stable/icehouse next version to 2014.1.2\n\nChange-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0\n'}]",0,102053,5196cf686be71c407308ec5d44eafe83fae3fef3,14,5,1,1955,,,0,"Bump stable/icehouse next version to 2014.1.2

Change-Id: Id7181755d3609c0ae91c2402b34f2de02c06a1f0
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/102053/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5196cf686be71c407308ec5d44eafe83fae3fef3,,version = 2014.1.2,version = 2014.1.1,1,1
openstack%2Fdevstack~stable%2Ficehouse~I1b87740ab02c4eb0a8df653a35e1f85d40abda51,openstack/devstack,stable/icehouse,I1b87740ab02c4eb0a8df653a35e1f85d40abda51,Upgrade to cirros 0.3.2,ABANDONED,2014-06-06 22:13:30.000000000,2014-06-24 03:13:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 5293}, {'_account_id': 5803}, {'_account_id': 5892}, {'_account_id': 9009}]","[{'number': 1, 'created': '2014-06-06 22:13:30.000000000', 'files': ['tools/xen/README.md', 'lib/tempest', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/87a8e8f57a88ed0f5f856b715d56e3ca5ba13668', 'message': 'Upgrade to cirros 0.3.2\n\nCirros 0.3.2 is fixing the host name setting issue, which\nis required for turning on the tempest instance validation tests.\n\nSince we now have branchles tempest lets make sure we use the same\nversion of cirros on trunk and icehouse.\n\nConflicts:\n\tstackrc\n\nChange-Id: I1b87740ab02c4eb0a8df653a35e1f85d40abda51\nRelated-Bug: #1132686\n(cherry picked from commit 2d4c8da8031d4ca8638befe1c039c6197d3ac08d)\n'}]",0,98545,87a8e8f57a88ed0f5f856b715d56e3ca5ba13668,18,8,1,1849,,,0,"Upgrade to cirros 0.3.2

Cirros 0.3.2 is fixing the host name setting issue, which
is required for turning on the tempest instance validation tests.

Since we now have branchles tempest lets make sure we use the same
version of cirros on trunk and icehouse.

Conflicts:
	stackrc

Change-Id: I1b87740ab02c4eb0a8df653a35e1f85d40abda51
Related-Bug: #1132686
(cherry picked from commit 2d4c8da8031d4ca8638befe1c039c6197d3ac08d)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/45/98545/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/xen/README.md', 'lib/tempest', 'stackrc']",3,87a8e8f57a88ed0f5f856b715d56e3ca5ba13668,(detached,"# http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-rootfs.img.gz#IMAGE_URLS=""http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-disk.img"" # cirros full disk image CIRROS_VERSION=${CIRROS_VERSION:-""0.3.2""} DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-${CIRROS_VERSION}-x86_64-rootfs} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-rootfs.img.gz""};; DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-${CIRROS_VERSION}-x86_64-uec} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-uec.tar.gz""};; DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-${CIRROS_VERSION}-x86_64-uec} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-uec.tar.gz""};;","# http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-rootfs.img.gz#IMAGE_URLS=""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-disk.img"" # cirros full disk image DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-0.3.1-x86_64-rootfs} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-rootfs.img.gz""};; DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-0.3.1-x86_64-uec} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-uec.tar.gz,http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-uec.tar.gz""};; DEFAULT_IMAGE_NAME=${DEFAULT_IMAGE_NAME:-cirros-0.3.1-x86_64-uec} IMAGE_URLS=${IMAGE_URLS:-""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-uec.tar.gz,http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-uec.tar.gz""};;",21,16
openstack%2Fcinder~stable%2Ficehouse~Ia2a72776e649abd82160cb13ad63489cc760b190,openstack/cinder,stable/icehouse,Ia2a72776e649abd82160cb13ad63489cc760b190,Cinder list does not filter admin metadata.,ABANDONED,2014-05-19 17:01:33.000000000,2014-06-24 03:08:26.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1420}, {'_account_id': 2243}, {'_account_id': 8871}, {'_account_id': 9450}, {'_account_id': 9533}, {'_account_id': 10069}, {'_account_id': 10973}]","[{'number': 1, 'created': '2014-05-19 17:01:33.000000000', 'files': ['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/26c3cca1e3e1b9c9d5bf0db8189efdd31c0ae4e0', 'message': ""Cinder list does not filter admin metadata.\n\nFor example, if you want to filter by 'readonly' attribute,\nyou do not get results.\nThis patch adds the admin metadata for filtering.\n\nChange-Id: Ia2a72776e649abd82160cb13ad63489cc760b190\nCloses-Bug: #1311277\n(cherry picked from commit 8f112b270af0965a6f9aafbd83976c1ad22314f8)\n""}]",0,94233,26c3cca1e3e1b9c9d5bf0db8189efdd31c0ae4e0,25,9,1,170,,,0,"Cinder list does not filter admin metadata.

For example, if you want to filter by 'readonly' attribute,
you do not get results.
This patch adds the admin metadata for filtering.

Change-Id: Ia2a72776e649abd82160cb13ad63489cc760b190
Closes-Bug: #1311277
(cherry picked from commit 8f112b270af0965a6f9aafbd83976c1ad22314f8)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/94233/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/api.py', 'cinder/tests/test_db_api.py']",2,26c3cca1e3e1b9c9d5bf0db8189efdd31c0ae4e0,bug/1311277," db.volume_admin_metadata_update(self.ctxt, vol5.id, {""readonly"": ""True""}, False) # metadata filters filters = {'metadata': {'readonly': 'True'}} self._assertEqualsVolumeOrderResult([vol5], filters=filters) ", # metdata filters,13,5
openstack%2Fneutron-specs~master~I1f707e219453dcfe6088f0222e28e8e6a2dddf87,openstack/neutron-specs,master,I1f707e219453dcfe6088f0222e28e8e6a2dddf87,Assign cisco nw profile to multi-tenants in single request,MERGED,2014-05-02 21:43:40.000000000,2014-06-24 02:52:05.000000000,2014-06-24 02:52:05.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 6524}, {'_account_id': 7018}, {'_account_id': 9680}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-05-02 21:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8d889733e10528ea408a6fbde99c118141c7f3f5', 'message': 'Assign cisco nw profile to multi-tenants in single request\n\nin current neutron, user can assign cisco network profile to\nonly one tenant in a request. So user has to send multiple requests\nto assign a cisco network profile to multiple tenants.\nThis fix is going to add the support to assign to multiple tenants\nin a single request\n\nChange-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87\n'}, {'number': 2, 'created': '2014-05-02 22:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5e3aa299eea141cd0049ea868d035b9be14c9be3', 'message': 'Assign cisco nw profile to multi-tenants in single request\n\nCurrently with Cisco N1kv plugin, user can assign cisco network\nprofile to only one tenant in a request. So user has to send\nmultiple requests to assign a cisco network profile to multiple\ntenants.\nThis fix is going to add the support to assign to multiple tenants\nin a single request\n\nChange-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87\n'}, {'number': 3, 'created': '2014-05-05 18:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/860aa959f9ceb2a9ef2e0c05b0004f61667580b9', 'message': 'Assign cisco nw profile to multi-tenants in single request\n\nCurrently with Cisco N1kv plugin, user can assign cisco network\nprofile to only one tenant in a request. So user has to send\nmultiple requests to assign a cisco network profile to multiple\ntenants.\nThis fix is going to add the support to assign to multiple tenants\nin a single request\n\nChange-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87\n'}, {'number': 4, 'created': '2014-06-06 19:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/dc70ff373060cf5ed1318d21b68d9fa67a89c2f8', 'message': 'Assign cisco nw profile to multi-tenants in single request\n\nCurrently with Cisco N1kv plugin, user can assign cisco network\nprofile to only one tenant in a request. So user has to send\nmultiple requests to assign a cisco network profile to multiple\ntenants.\nThis fix is going to add the support to assign to multiple tenants\nin a single request\n\nChange-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87\n'}, {'number': 5, 'created': '2014-06-06 23:08:13.000000000', 'files': ['specs/juno/cisco-network-profile-multi-tenants-support.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b45d686c75f017aa9984c2af2ae7296cfbe5895a', 'message': 'Assign cisco nw profile to multi-tenants in single request\n\nCurrently with Cisco N1kv plugin, user can assign cisco network\nprofile to only one tenant in a request. So user has to send\nmultiple requests to assign a cisco network profile to multiple\ntenants.\nThis fix is going to add the support to assign to multiple tenants\nin a single request\n\nChange-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87\n'}]",19,91910,b45d686c75f017aa9984c2af2ae7296cfbe5895a,43,8,5,9680,,,0,"Assign cisco nw profile to multi-tenants in single request

Currently with Cisco N1kv plugin, user can assign cisco network
profile to only one tenant in a request. So user has to send
multiple requests to assign a cisco network profile to multiple
tenants.
This fix is going to add the support to assign to multiple tenants
in a single request

Change-Id: I1f707e219453dcfe6088f0222e28e8e6a2dddf87
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/10/91910/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/cisco-network-profile-multi-tenants-support.rst'],1,8d889733e10528ea408a6fbde99c118141c7f3f5,cisco-network-profile-multi-tenants-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Ability to assign cisco nw profile to multi-tenants in single request ========================================== https://blueprints.launchpad.net/neutron/+spec/cisco-network-profile-multi-tenants-support Add the support to assign a cisco network profile to multiple tenants in a single request Problem description =================== In current neutron, user is only able to assign cisco network profile to one tenant in a request. So user has to send multiple requests to assign a cisco network profile to multiple tenants. Proposed change =============== The proposed change is to make the create network profile and update network profile functions to take a list of tenant ids, and then update the profile-tenant binding info accordingly. Alternatives ------------ The Alternative way is to send multiple request, assigning to one tenant per request. This alternative is obviously too tedious for users, especially when a user has a lot of tenants to manage. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- There is a corresponding change in python-neutronclient: in cisco network profile create cli, user can add repeated --add-tenant option in cisco network profile update cli, user can add repeated --add-tenant and repeated --remove-tenant option Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: fenzhang Work Items ---------- - modify create and update network profile functions in neutron/plugins/cisco/db/nikv_db_v2.py file - modify network profile attributes in neutron/plugins/cisco/extensions/network_profile.py file Dependencies ============ blueprint in python-neutronclient and horizon: https://blueprints.launchpad.net/horizon/+spec/cisco-network-profile-multi-tenants-support https://blueprints.launchpad.net/python-neutronclient/+spec/cisco-network-profile-multi-tenants-support Testing ======= The UT test cases will be added to cover this change. Documentation Impact ==================== None References ========== None ",,117,0
openstack%2Fzaqar~master~I67cb5a9b2d76625de2932c854d0a696e9118ca6b,openstack/zaqar,master,I67cb5a9b2d76625de2932c854d0a696e9118ca6b,Expose pymongo's SSL cert options,MERGED,2014-06-18 02:15:45.000000000,2014-06-24 02:46:09.000000000,2014-06-24 02:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 10068}, {'_account_id': 10634}]","[{'number': 1, 'created': '2014-06-18 02:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/2271348a03217b45eb80f558efac5a1949ce7301', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and 'ssl_ca_certs' options\nfor maximum security. By default, ssl is not enabled except that ssl parameter was\nincluded in the mongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which means\nuser must provide the 'ssl_ca_certs' if ssl is enabled either by setting ssl=true explicitly\nor adding the ssl parameter in the mongodb uri\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 2, 'created': '2014-06-18 02:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5027e33b5853b9dbd260d4e9e0eb55638984a7fe', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and 'ssl_ca_certs' options\nfor maximum security. By default, ssl is not enabled except that ssl parameter was\nincluded in the mongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which means\nuser must provide the 'ssl_ca_certs' if ssl is enabled either by setting ssl=true explicitly\nor adding the ssl parameter in the mongodb uri\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 3, 'created': '2014-06-18 05:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/16cc26c41bdddb65b978d5932d47308fb92461a0', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and 'ssl_ca_certs' options for maximum security. By default, ssl \nis not enabled except that ssl parameter was included in the \nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which \nmeans user must provide the 'ssl_ca_certs' if ssl is enabled \neither by setting ssl=true explicitly or adding the ssl \nparameter in the mongodb uri\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 4, 'created': '2014-06-18 05:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/74a1264177a2a3c9da50b3c23482ed618036c325', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs'\nand 'ssl_ca_certs' options for maximum security. By default, ssl \nis not enabled except that ssl parameter was included in the \nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which \nmeans user must provide the 'ssl_ca_certs' if ssl is enabled \neither by setting ssl=true explicitly or adding the ssl \nparameter in the mongodb uri\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 5, 'created': '2014-06-18 05:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fc0f185544e4fa2616a81ea5b239e4a6108d2ac9', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and\nssl_ca_certs' options for maximum security. By default, ssl\nis not enabled except that ssl parameter was included in the\nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which\nmeans user must provide the 'ssl_ca_certs' if ssl is enabled\neither by setting ssl=true explicitly or adding the ssl\nparameter in the mongodb uri\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 6, 'created': '2014-06-18 05:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/29e00d29bbe7f14ead27b0d7402a962c8ca1c85e', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and\n'ssl_ca_certs' options for maximum security. By default, ssl\nis not enabled except that ssl parameter was included in the\nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which\nmeans user must provide the 'ssl_ca_certs' if ssl is enabled\neither by setting ssl=true explicitly or adding the ssl\nparameter in the mongodb uri.\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 7, 'created': '2014-06-18 06:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6fac73529a6e077bc15c901e1a6c61491b77ca33', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and\n'ssl_ca_certs' options for maximum security. By default, ssl\nis not enabled except that ssl parameter was included in the\nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which\nmeans user must provide the 'ssl_ca_certs' if ssl is enabled\neither by setting ssl=true explicitly or adding the ssl\nparameter in the mongodb uri.\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 8, 'created': '2014-06-19 02:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c2ed765e815b42af74749ce312c4839986d80635', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl','ssl_keyfile','ssl_certfile','ssl_cert_reqs' and\n'ssl_ca_certs' options for maximum security. By default, ssl\nis not enabled except that ssl parameter was included in the\nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which\nmeans user must provide the 'ssl_ca_certs' if ssl is enabled\neither by setting ssl=true explicitly or adding the ssl\nparameter in the mongodb uri.\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}, {'number': 9, 'created': '2014-06-19 09:28:57.000000000', 'files': ['marconi/queues/storage/mongodb/driver.py', 'marconi/queues/storage/mongodb/options.py', 'etc/marconi.conf.sample'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f1c34373207b5d0dd0f3e75ec8a7765dca53bc3f', 'message': ""Expose pymongo's SSL cert options\n\nExpose 'ssl_keyfile','ssl_certfile','ssl_cert_reqs' and\n'ssl_ca_certs' options for maximum security. By default, ssl\nis not enabled except that ssl parameter was included in the\nmongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which\nmeans user must provide the 'ssl_ca_certs' if ssl is enabled\nby adding the ssl parameter in the mongodb uri.\n\nChange-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b\nCloses-Bug: #1328720\n""}]",23,100746,f1c34373207b5d0dd0f3e75ec8a7765dca53bc3f,53,7,9,10634,,,0,"Expose pymongo's SSL cert options

Expose 'ssl_keyfile','ssl_certfile','ssl_cert_reqs' and
'ssl_ca_certs' options for maximum security. By default, ssl
is not enabled except that ssl parameter was included in the
mongodb uri directly, and ssl_cert_reqs = CERT_REQUIRED which
means user must provide the 'ssl_ca_certs' if ssl is enabled
by adding the ssl parameter in the mongodb uri.

Change-Id: I67cb5a9b2d76625de2932c854d0a696e9118ca6b
Closes-Bug: #1328720
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/46/100746/8 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/storage/sharding.py', 'requirements.txt', 'marconi/queues/storage/mongodb/driver.py', 'marconi/queues/storage/mongodb/options.py', 'requirements-py3.txt', 'tox.ini', 'etc/marconi.conf.sample']",7,2271348a03217b45eb80f558efac5a1949ce7301,bug/1328720,"# If true, create the connection to the server using SSL with # 'ssl_keyfile', 'ssl_certfile', 'ssl_cert_reqs', ssl_ca_certs' # accordingly. (boolean value) #ssl=false # The private keyfile used to identify the local connection # against mongod. If included with the 'certifle' then only # the ssl_certfile is needed. (string value) #ssl_keyfile=<None> # The certificate file used to identify the local connection # against mongod. (string value) #ssl_certfile=<None> # Specifies whether a certificate is required from the other # side of the connection, and whether it will be validated # if provided. It must be one of the three values 'CERT_NONE' # (certificates ignored), 'CERT_OPTIONAL'(not required, but # validated if provided), or 'CERT_REQUIRED'(required and validated). # If the value of this parameter is not 'CERT_NONE', then the # 'ssl_ca_certs' parameter must point to a file of CA certificates. # (string value) #ssl_cert_reqs=CERT_REQUIRED # The ca_certs file contains a set of concatenated certification # authority certificates, which are used to validate certificates # passed from the other end of the connection. (string value) #ssl_ca_certs=<None> ",,90,4
openstack-attic%2Fcompute-api~master~Idd158f47b353e700ee4a84a859b88e3bb1c43a5d,openstack-attic/compute-api,master,Idd158f47b353e700ee4a84a859b88e3bb1c43a5d,Fix: Adding changes made by Diane back into the files,ABANDONED,2014-06-23 19:31:34.000000000,2014-06-24 02:46:06.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-06-23 19:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/db2f6e0b047a4004e1c8b3bd00b5385063f79069', 'message': 'Fix: Adding detailed information about pause, unpause, suspend, and resume a server\n\nCloses-Bug: 1295718\nChange-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d\n'}, {'number': 2, 'created': '2014-06-23 23:02:17.000000000', 'files': ['v2/bk_compute_api_ref_v2.xml'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/0857e97d438472e426e32dc74ed2bdfb5d1ac411', 'message': 'Fix: Adding changes made by Diane back into the files\n\nAuthor: Constanze Kratel\nCloses-Bug: 1295718\nChange-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d\n'}]",0,101983,0857e97d438472e426e32dc74ed2bdfb5d1ac411,9,3,2,10279,,,0,"Fix: Adding changes made by Diane back into the files

Author: Constanze Kratel
Closes-Bug: 1295718
Change-Id: Idd158f47b353e700ee4a84a859b88e3bb1c43a5d
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/83/101983/1 && git format-patch -1 --stdout FETCH_HEAD,"['v2/bk_compute_api_ref_v2.xml', 'v2/section_concepts.xml']",2,db2f6e0b047a4004e1c8b3bd00b5385063f79069,bug/1295718," <para><emphasis role=""bold"">Reboot</emphasis></para> <para>Use this function to perform either a soft or hard reboot of a server. With a soft reboot, the operating system is signaled to restart, which allows for a graceful shutdown of all processes. A hard reboot is the equivalent of power cycling the server. The virtualization platform should ensure that the reboot action has completed successfully even in cases in which the underlying domain/VM is paused or halted/stopped.</para> <para><emphasis role=""bold"">Rebuild</emphasis></para> <para>Use this function to remove all data on the server and replaces it with the specified image. Server ID and IP addresses remain the same.</para> <para><emphasis role=""bold"">Resize</emphasis></para> <para>Use this function to convert an existing server to a different flavor, in essence, scaling the server up or down. The original server is saved for a period of time to allow rollback if there is a problem. All resizes should be tested and explicitly confirmed, at which time the original server is removed. All resizes are automatically confirmed after 24 hours if you do not confirm or revert them.</para> <para><emphasis role=""bold"">Pause</emphasis></para> <para>You can pause a server by making a <xref linkend=""pause""/> request. This request stores the state of the VM in RAM. A paused instance continues to run in a frozen state.</para> <para><emphasis role=""bold"">Suspend</emphasis></para> <para>Administrative users might want to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.</para>"," <para><emphasis role=""bold"">Reboot action</emphasis></para> <para>Performs a soft or hard reboot of a server. With a soft reboot, the operating system is signaled to restart, which allows for a graceful shutdown of all processes. A hard reboot is the equivalent of power cycling the server. The virtualization platform should ensure that the reboot action has completed successfully even in cases in which the underlying domain/VM is paused or halted/stopped.</para> <para><emphasis role=""bold"">Rebuild action</emphasis></para> <para>Removes all data on the server and replaces it with the specified image. Server ID and IP addresses remain the same.</para> <para><emphasis role=""bold"">Resize action</emphasis></para> <para>Converts an existing server to a different flavor, in essence, scaling the server up or down. The original server is saved for a period of time to allow rollback if there is a problem. All resizes should be tested and explicitly confirmed, at which time the original server is removed. All resizes are automatically confirmed after 24 hours if you do not confirm or revert them.</para> <para><emphasis role=""bold"">Pause action</emphasis></para> <para>Pauses a server and causes it to run in a frozen state. To pause a server, make a <link xlink:href=""http://docs.openstack.org/api/openstack-compute/2/content/POST_os-admin-actions-v2_pause__v2__tenant_id__servers__server_id__action_ext-action.html"" >Pause server</link> request. This request stores the state of the VM in RAM.</para> <para><emphasis role=""bold"">Suspend action</emphasis></para> <para>Suspends a server, which stores its VM state on disk, writes all memory to disk, and stops the virtual machine. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances. Administrative users might want to suspend an infrequently used instance or suspend an instance to perform system maintenance.</para> </listitem> <listitem> <para><emphasis role=""bold"">Unpause action</emphasis></para> <para>Unpauses a paused server. To unpause a server, make an <link xlink:href=""http://docs.openstack.org/api/openstack-compute/2/content/POST_os-admin-actions-v2_unpause__v2__tenant_id__servers__server_id__action_ext-action.html"" >Unpause server</link> request.</para>",124,166
openstack%2Fmanila~master~Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb,openstack/manila,master,Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb,Check share net ids when creating share from snapshot,MERGED,2014-06-19 13:07:53.000000000,2014-06-24 02:02:10.000000000,2014-06-24 02:02:10.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-06-19 13:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4f9600277c10cde81f4e7d536db4056af60ad5dd', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 2, 'created': '2014-06-19 14:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a9ebed4e93dc8fbfa102c569b3b38093f1085e4b', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nCloses-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 3, 'created': '2014-06-19 14:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b59caf0e5fdf05f8563032e543ae72c8a5e5b6fd', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nCloses-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 4, 'created': '2014-06-19 14:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/77a006c51219c71e769df4f0a562555eeded2915', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nCloses-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 5, 'created': '2014-06-20 10:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a2b8a2905b0f0456959ae49b5a9f3b7cb0eb1e46', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nFixes-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 6, 'created': '2014-06-20 12:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/651825a13dec8c4ffc6507d0c6958639ddfce7bc', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nFixes-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 7, 'created': '2014-06-23 09:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4448246bf21dd327983e97b3cf6a9e068c79093c', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nPartial-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 8, 'created': '2014-06-23 12:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7fd91a539ffd79e3bfa3f5beda72d1825929bf27', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nPartial-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}, {'number': 9, 'created': '2014-06-23 17:09:29.000000000', 'files': ['manila/tests/api/v1/test_shares.py', 'manila/share/api.py', 'manila/api/v1/shares.py', 'manila/tests/api/contrib/stubs.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/c393d8368687bb1fc188a35dcfec11467fc1f262', 'message': 'Check share net ids when creating share from snapshot\n\nWhen creating share from snapshot if share-network-id passed\nwe need to check if it equals to share-network-id of parent share.\n\nPartial-Bug: #1332080\nChange-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb\n'}]",10,101204,c393d8368687bb1fc188a35dcfec11467fc1f262,38,5,9,7534,,,0,"Check share net ids when creating share from snapshot

When creating share from snapshot if share-network-id passed
we need to check if it equals to share-network-id of parent share.

Partial-Bug: #1332080
Change-Id: Ieca5d74fc060e0f0f66fa06853e5744f2fcc08eb
",git fetch https://review.opendev.org/openstack/manila refs/changes/04/101204/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/api/v1/test_shares.py', 'manila/api/v1/shares.py', 'manila/tests/api/contrib/stubs.py']",3,4f9600277c10cde81f4e7d536db4056af60ad5dd,master," 'share': stub_share('fakeshareid'),",,31,5
openstack%2Fpython-heatclient~master~Ia9c5a82e9bb6a8ac128b723dd9afd124764152d3,openstack/python-heatclient,master,Ia9c5a82e9bb6a8ac128b723dd9afd124764152d3,Set the iso8601 log level to WARN,ABANDONED,2014-06-23 06:46:11.000000000,2014-06-24 01:50:22.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-06-23 06:46:11.000000000', 'files': ['heatclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/367d8a8bf5b85f89b800092e4d5df140f15b61f3', 'message': 'Set the iso8601 log level to WARN\n\nWhen use ""--debug"" parameter in CLI, it may display useless iso8601\ndebug info.\n\nset the iso8601 log level to ""WARN"" to avoid this issue.\n\nChange-Id: Ia9c5a82e9bb6a8ac128b723dd9afd124764152d3\nCloses-bug: #1324470\n'}]",0,101810,367d8a8bf5b85f89b800092e4d5df140f15b61f3,10,3,1,8290,,,0,"Set the iso8601 log level to WARN

When use ""--debug"" parameter in CLI, it may display useless iso8601
debug info.

set the iso8601 log level to ""WARN"" to avoid this issue.

Change-Id: Ia9c5a82e9bb6a8ac128b723dd9afd124764152d3
Closes-bug: #1324470
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/10/101810/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/shell.py'],1,367d8a8bf5b85f89b800092e4d5df140f15b61f3,bug/1324470, if debug: iso_logger = logging.getLogger('iso8601') iso_logger.setLevel('WARN'),,3,0
openstack%2Fpbr~master~I20fbf255c634685e82f7b11987d2725de8280b9d,openstack/pbr,master,I20fbf255c634685e82f7b11987d2725de8280b9d,Restore Monkeypatched Distribution Instance,MERGED,2014-06-23 01:32:54.000000000,2014-06-24 01:19:06.000000000,2014-06-24 01:19:06.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-06-23 01:32:54.000000000', 'files': ['pbr/core.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/b07a50bfddda1cbb10faa64dc096ca9d855c483c', 'message': 'Restore Monkeypatched Distribution Instance\n\npbr is monkeypatching the Distribution intstance in setuptools, which is\nOK I guess, but then it never puts it back how it left it.  As a\nconsequence, whenever pbr installs before another project in a setup.py,\nit breaks setuptools for everything that comes after it.  This patch\nwill restore the Distribution instance.\n\nCloses-Bug: 1324784\n\nChange-Id: I20fbf255c634685e82f7b11987d2725de8280b9d\n'}]",0,101785,b07a50bfddda1cbb10faa64dc096ca9d855c483c,9,4,1,12067,,,0,"Restore Monkeypatched Distribution Instance

pbr is monkeypatching the Distribution intstance in setuptools, which is
OK I guess, but then it never puts it back how it left it.  As a
consequence, whenever pbr installs before another project in a setup.py,
it breaks setuptools for everything that comes after it.  This patch
will restore the Distribution instance.

Closes-Bug: 1324784

Change-Id: I20fbf255c634685e82f7b11987d2725de8280b9d
",git fetch https://review.opendev.org/openstack/pbr refs/changes/85/101785/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/core.py'],1,b07a50bfddda1cbb10faa64dc096ca9d855c483c,bug/1324784,"_saved_core_distribution = core.Distribution def _monkeypatch_distribution(): core.Distribution = dist._get_unpatched(core.Distribution) def _restore_distribution_monkeypatch(): core.Distribution = _saved_core_distribution try: _monkeypatch_distribution() if not value: return if isinstance(value, string_type): path = os.path.abspath(value) else: path = os.path.abspath('setup.cfg') if not os.path.exists(path): raise errors.DistutilsFileError( 'The setup.cfg file %s does not exist.' % path) # Converts the setup.cfg file to setup() arguments try: attrs = util.cfg_to_args(path) except Exception: e = sys.exc_info()[1] raise errors.DistutilsSetupError( 'Error parsing %s: %s: %s' % (path, e.__class__.__name__, e)) # Repeat some of the Distribution initialization code with the newly # provided attrs if attrs: # Skips 'options' and 'licence' support which are rarely used; may # add back in later if demanded for key, val in attrs.items(): if hasattr(dist.metadata, 'set_' + key): getattr(dist.metadata, 'set_' + key)(val) elif hasattr(dist.metadata, key): setattr(dist.metadata, key, val) elif hasattr(dist, key): setattr(dist, key, val) else: msg = 'Unknown distribution option: %s' % repr(key) warnings.warn(msg) # Re-finalize the underlying Distribution core.Distribution.finalize_options(dist) # This bit comes out of distribute/setuptools if isinstance(dist.metadata.version, integer_types + (float,)): # Some people apparently take ""version number"" too literally :) dist.metadata.version = str(dist.metadata.version) # This bit of hackery is necessary so that the Distribution will ignore # normally unsupport command options (namely pre-hooks and post-hooks). # dist.command_options is normally a dict mapping command names to # dicts of their options. Now it will be a defaultdict that returns # IgnoreDicts for the each command's options so we can pass through the # unsupported options ignore = ['pre_hook.*', 'post_hook.*'] dist.command_options = util.DefaultGetDict( lambda: util.IgnoreDict(ignore) ) finally: _restore_distribution_monkeypatch()","core.Distribution = dist._get_unpatched(core.Distribution) if not value: return if isinstance(value, string_type): path = os.path.abspath(value) else: path = os.path.abspath('setup.cfg') if not os.path.exists(path): raise errors.DistutilsFileError( 'The setup.cfg file %s does not exist.' % path) # Converts the setup.cfg file to setup() arguments try: attrs = util.cfg_to_args(path) except Exception: e = sys.exc_info()[1] raise errors.DistutilsSetupError( 'Error parsing %s: %s: %s' % (path, e.__class__.__name__, e)) # Repeat some of the Distribution initialization code with the newly # provided attrs if attrs: # Skips 'options' and 'licence' support which are rarely used; may add # back in later if demanded for key, val in attrs.items(): if hasattr(dist.metadata, 'set_' + key): getattr(dist.metadata, 'set_' + key)(val) elif hasattr(dist.metadata, key): setattr(dist.metadata, key, val) elif hasattr(dist, key): setattr(dist, key, val) else: msg = 'Unknown distribution option: %s' % repr(key) warnings.warn(msg) # Re-finalize the underlying Distribution core.Distribution.finalize_options(dist) # This bit comes out of distribute/setuptools if isinstance(dist.metadata.version, integer_types + (float,)): # Some people apparently take ""version number"" too literally :) dist.metadata.version = str(dist.metadata.version) # This bit of hackery is necessary so that the Distribution will ignore # normally unsupport command options (namely pre-hooks and post-hooks). # dist.command_options is normally a dict mapping command names to dicts of # their options. Now it will be a defaultdict that returns IgnoreDicts for # the each command's options so we can pass through the unsupported options ignore = ['pre_hook.*', 'post_hook.*'] dist.command_options = util.DefaultGetDict(lambda: util.IgnoreDict(ignore))",62,45
openstack-attic%2Fcompute-api~master~I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d,openstack-attic/compute-api,master,I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d,Fix: Adding changes made by Diane back into the files,MERGED,2014-06-20 15:43:36.000000000,2014-06-24 01:11:35.000000000,2014-06-24 01:11:35.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 10279}]","[{'number': 1, 'created': '2014-06-20 15:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/7016f833445f89384693aec22c8f17d9a6b4b4b3', 'message': 'Fix: Updated after code review Closes-Bug: 1295718 Change-Id: Ie128f353c5bcc963fff6e234a949762bfd6c19ac\n\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 2, 'created': '2014-06-23 18:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/e83f87278087607b6a84e0f5b58645f203f17692', 'message': 'Fix: Updated after code review Closes-Bug: 1295718 Change-Id: Ie128f353c5bcc963fff6e234a949762bfd6c19ac\n\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 3, 'created': '2014-06-23 18:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/8921c68b558aec1f75bd70ede03ad1e379f91aa3', 'message': 'Fix: Updated after code review\n\nCloses-Bug: 1295718\n\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 4, 'created': '2014-06-23 19:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/66fdfddfba71bb9460c405b95d9c726ae1562c5b', 'message': 'Fix: Adding detailed information about pause, unpause, suspend, and resume a server\nCloses-Bug: 1295718\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 5, 'created': '2014-06-23 20:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/677e809745e55af7ca61030dc302bd8f9a4cecaa', 'message': 'Fix: Adding detailed information about pause, unpause, suspend, and resume a server\n\nCloses-Bug: 1295718\n\nAuthor: Constanze Kratel <constanze.kratel@rackspace.com>\n\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 6, 'created': '2014-06-23 20:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/9d8221c2524e900295a95e0d4ff326fea3bdae97', 'message': 'Fix: Adding detailed information about pause, unpause, suspend, and resume a server\n\nCloses-Bug: 1295718\n\nAuthor: Constanze Kratel <constanze.kratel@rackspace.com>\n\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}, {'number': 7, 'created': '2014-06-24 00:34:50.000000000', 'files': ['v2/bk_compute_api_ref_v2.xml', 'v2/section_concepts.xml'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/f004b3bc8fc177e5ad0e80108b71ca416bf259c2', 'message': 'Fix: Adding changes made by Diane back into the files\n\nCloses-Bug: 1295718\nAuthor: Constanze Kratel <constanze.kratel@rackspace.com>\nChange-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d\n'}]",3,101584,f004b3bc8fc177e5ad0e80108b71ca416bf259c2,36,5,7,10279,,,0,"Fix: Adding changes made by Diane back into the files

Closes-Bug: 1295718
Author: Constanze Kratel <constanze.kratel@rackspace.com>
Change-Id: I6e0461eb5cca3a5eff47a2ccabd0d1bf7a9a442d
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/84/101584/5 && git format-patch -1 --stdout FETCH_HEAD,"['v2/bk_compute_api_ref_v2.xml', 'v2/section_concepts.xml']",2,7016f833445f89384693aec22c8f17d9a6b4b4b3,bug/1295718, <para>You can pause a server by making a <command>Pause server</command> request. This request stores the state of the VM in RAM. A paused instance continues to run in a frozen state.</para>," <para>You can pause a server by making a <link xlink:href=""http://docs.openstack.org/api/openstack-compute/2/content/POST_os-admin-actions-v2_pause__v2__tenant_id__servers__server_id__action_ext-action.html"" >Pause server</link> request. This request stores the state of the VM in RAM. A paused instance continues to run in a frozen state. You can unpause a server that has been paused by making an <link xlink:href=""http://docs.openstack.org/api/openstack-compute/2/content/POST_os-admin-actions-v2_unpause__v2__tenant_id__servers__server_id__action_ext-action.html"" >Unpause server</link> request. </para>",5,9
openstack%2Fapi-site~master~I862318556ad857620652c4bb0e1469679a53ae86,openstack/api-site,master,I862318556ad857620652c4bb0e1469679a53ae86,Add os-attach extension to cinder,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-24 01:09:25.000000000,,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': ['api-ref/src/wadls/volume-api/src/v2/os-attach.wadl', 'api-ref/src/wadls/volume-api/src/api_samples/os-attach/host-attach-req.xml', 'api-ref/src/wadls/volume-api/src/api_samples/os-attach/host-attach-req.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/574039a1ba4611a2c1dcafb37b58d5d017821ab4', 'message': 'Add os-attach extension to cinder\n\nPartial-Bug: #1193770\n\nChange-Id: I862318556ad857620652c4bb0e1469679a53ae86\nauthor: diane fleming\n'}]",0,89284,574039a1ba4611a2c1dcafb37b58d5d017821ab4,8,3,1,2448,,,0,"Add os-attach extension to cinder

Partial-Bug: #1193770

Change-Id: I862318556ad857620652c4bb0e1469679a53ae86
author: diane fleming
",git fetch https://review.opendev.org/openstack/api-site refs/changes/84/89284/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/volume-api/src/v2/os-attach.wadl', 'api-ref/src/wadls/volume-api/src/api_samples/os-attach/host-attach-req.xml', 'api-ref/src/wadls/volume-api/src/api_samples/os-attach/host-attach-req.json']",3,574039a1ba4611a2c1dcafb37b58d5d017821ab4,1193770,"{ ""host_name"":""my_host"" }",,29,183
openstack%2Fbashate~master~I9423a5ad3496d77e8d13afef4e539ffb3e81015a,openstack/bashate,master,I9423a5ad3496d77e8d13afef4e539ffb3e81015a,discover shell files,MERGED,2014-06-20 11:34:13.000000000,2014-06-24 00:58:59.000000000,2014-06-24 00:58:59.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5371}]","[{'number': 1, 'created': '2014-06-20 11:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/2931ee97797728a34859d859847287be6a1c8614', 'message': 'discover shell files\n\nwhen attempting to integrate bashate into grenade, devstack-gate,\nand devstack via tox, one thing that really stood out was that we\nhave to provide an explicit file list, which ends up more different\nthan you think.\n\nThis changes the bashate behavior to do a discovery when no files\nare passed on the command line. The current set of files that\ndevstack and grenade need are encoded, but I think we should look\nat moving those all to .sh extension in the future, then we can\nremove these extra parts.\n\nChange-Id: I9423a5ad3496d77e8d13afef4e539ffb3e81015a\n'}, {'number': 2, 'created': '2014-06-20 12:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/9d121278133bda64142ca1c189bb741d75481fac', 'message': 'discover shell files\n\nwhen attempting to integrate bashate into grenade, devstack-gate,\nand devstack via tox, one thing that really stood out was that we\nhave to provide an explicit file list, which ends up more different\nthan you think.\n\nThis changes the bashate behavior to do a discovery when no files\nare passed on the command line. The current set of files that\ndevstack and grenade need are encoded, but I think we should look\nat moving those all to .sh extension in the future, then we can\nremove these extra parts.\n\nChange-Id: I9423a5ad3496d77e8d13afef4e539ffb3e81015a\n'}, {'number': 3, 'created': '2014-06-20 22:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/f3efc12be37692a7bd092c3269bb492b4e91abde', 'message': 'discover shell files\n\nwhen attempting to integrate bashate into grenade, devstack-gate,\nand devstack via tox, one thing that really stood out was that we\nhave to provide an explicit file list, which ends up more different\nthan you think.\n\nThis changes the bashate behavior to do a discovery when no files\nare passed on the command line. The current set of files that\ndevstack and grenade need are encoded, but I think we should look\nat moving those all to .sh extension in the future, then we can\nremove these extra parts.\n\nChange-Id: I9423a5ad3496d77e8d13afef4e539ffb3e81015a\n'}, {'number': 4, 'created': '2014-06-23 22:21:13.000000000', 'files': ['bashate/bashate.py'], 'web_link': 'https://opendev.org/openstack/bashate/commit/7c66b1b88d09f0866d7f2a49319b9384abe133b7', 'message': 'discover shell files\n\nwhen attempting to integrate bashate into grenade, devstack-gate,\nand devstack via tox, one thing that really stood out was that we\nhave to provide an explicit file list, which ends up more different\nthan you think.\n\nThis changes the bashate behavior to do a discovery when no files\nare passed on the command line. The current set of files that\ndevstack and grenade need are encoded, but I think we should look\nat moving those all to .sh extension in the future, then we can\nremove these extra parts.\n\nChange-Id: I9423a5ad3496d77e8d13afef4e539ffb3e81015a\n'}]",1,101484,7c66b1b88d09f0866d7f2a49319b9384abe133b7,18,3,4,2750,,,0,"discover shell files

when attempting to integrate bashate into grenade, devstack-gate,
and devstack via tox, one thing that really stood out was that we
have to provide an explicit file list, which ends up more different
than you think.

This changes the bashate behavior to do a discovery when no files
are passed on the command line. The current set of files that
devstack and grenade need are encoded, but I think we should look
at moving those all to .sh extension in the future, then we can
remove these extra parts.

Change-Id: I9423a5ad3496d77e8d13afef4e539ffb3e81015a
",git fetch https://review.opendev.org/openstack/bashate refs/changes/84/101484/3 && git format-patch -1 --stdout FETCH_HEAD,['bash8/bash8.py'],1,2931ee97797728a34859d859847287be6a1c8614,discover,"import fnmatch import osdef discover_files(): """"""Discover likely files if none are passed in on the command line."""""" files = set() # everything that ends in .sh for root, dirs, filenames in os.walk('.'): for filename in fnmatch.filter(filenames, '*.sh'): files.add(os.path.join(root, filename)) # functions and rc files for filename in filenames: if re.search('(^functions|rc$)', filename): files.add(os.path.join(root, filename)) # grenade upgrade scripts for filename in filenames: if re.search('^(prep|stop|upgrade)-', filename): files.add(os.path.join(root, filename)) # devstack specifics (everything in lib that isn't md) for root, dirs, filenames in os.walk('lib'): for filename in filenames: if not re.search('\.md$', filename): files.add(os.path.join(root, filename)) return sorted(files) parser.add_argument('files', metavar='file', nargs='*', files = opts.files if not files: files = discover_files() check_files(files, opts.verbose)"," parser.add_argument('files', metavar='file', nargs='+', check_files(opts.files, opts.verbose)",32,2
openstack%2Fnova~master~I3163bb0fbfa3788cc2211a40acbed83c874a007f,openstack/nova,master,I3163bb0fbfa3788cc2211a40acbed83c874a007f,Log cleanups for nova.virt.libvirt.driver,ABANDONED,2014-06-19 03:25:50.000000000,2014-06-24 00:58:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 03:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e13beaac767edda97bfe0b11aac1df17350e6a22', 'message': 'Log cleanups for nova.virt.libvirt.driver\n\nMore log cleanups:\n - add log hints for info, error and warning levels\n - remove use of % as a string formatter, use the log functionality\n   instead\n - move from LOG.warning to LOG.warn\n\nChange-Id: I3163bb0fbfa3788cc2211a40acbed83c874a007f\n'}, {'number': 2, 'created': '2014-06-23 05:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/111de4d7f9075f32019197dbf7a2848003386df6', 'message': 'Log cleanups for nova.virt.libvirt.driver\n\nMore log cleanups:\n - add log hints for info, error and warning levels\n - remove use of % as a string formatter, use the log functionality\n   instead\n - move from LOG.warning to LOG.warn\n\nChange-Id: I3163bb0fbfa3788cc2211a40acbed83c874a007f\n'}, {'number': 3, 'created': '2014-06-23 06:35:28.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/eb82253ff595cdcd81c7eacf22f66926fc739981', 'message': 'Log cleanups for nova.virt.libvirt.driver\n\nMore log cleanups:\n - add log hints for info, error and warning levels\n - remove use of % as a string formatter, use the log functionality\n   instead\n - move from LOG.warning to LOG.warn\n\nChange-Id: I3163bb0fbfa3788cc2211a40acbed83c874a007f\n'}]",4,101086,eb82253ff595cdcd81c7eacf22f66926fc739981,23,8,3,2271,,,0,"Log cleanups for nova.virt.libvirt.driver

More log cleanups:
 - add log hints for info, error and warning levels
 - remove use of % as a string formatter, use the log functionality
   instead
 - move from LOG.warning to LOG.warn

Change-Id: I3163bb0fbfa3788cc2211a40acbed83c874a007f
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/101086/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,e13beaac767edda97bfe0b11aac1df17350e6a22,log-hints,"from nova.openstack.common.gettextutils import _LE from nova.openstack.common.gettextutils import _LI LOG.warn(_LW('Invalid cachemode %(cache_mode)s specified ' 'for disk type %(disk_type)s.'), _error = _LW(""Connection to libvirt lost: %s"") % reason LOG.warn(_LW('The libvirt driver is not tested on ' '%(type)s/%(arch)s by the OpenStack project and ' 'thus its quality can not be ensured. For more ' 'information, see: https://wiki.openstack.org/wiki/' 'HypervisorSupportMatrix'), LOG.error(_LE('Nova requires libvirt version ' '%(major)i.%(minor)i.%(micro)i or greater.'), LOG.warn(_LW(""URI %(uri)s does not support events: %(error)s""), LOG.debug(""Registering for connection events: %s"", str(self)) LOG.warn(_LW(""URI %(uri)s does not support connection"" "" events: %(error)s""), LOG.warn(_LW(""Cannot destroy instance, operation time "" ""out""), LOG.error(_LE('Error from libvirt during destroy. ' 'Code=%(errcode)s Error=%(e)s'), LOG.error(_LE(""During wait destroy, instance disappeared.""), LOG.info(_LI(""Instance destroyed successfully.""), LOG.info(_LI(""Instance may be started again.""), LOG.info(_LI(""Going to destroy instance again.""), instance=instance) LOG.error(_LE('Error from libvirt during undefine. ' 'Code=%(errcode)s Error=%(e)s'), LOG.warn(_LW(""Instance may be still running, destroy "" ""it again.""), instance=instance) 'Code=%(errcode)s Error=%(e)s'), {'errcode': errcode, 'e': e}, instance=instance) LOG.warn(_LW(""Ignoring Volume Error on vol %(vol_id)s "" ""during delete %(exc)s""), LOG.warn(_LW('Volume %(disk)s possibly unsafe to ' 'remove, please clean up manually'), LOG.warn(_LW(""During detach_volume, instance disappeared."")) LOG.error(_LE('attaching network adapter failed.'), LOG.warn(_LW(""During detach_interface, "" ""instance disappeared.""), LOG.error(_LE('detaching network adapter failed.'), LOG.info(_LI(""Beginning live snapshot process""), LOG.info(_LI(""Beginning cold snapshot process""), LOG.info(_LI(""Snapshot extracted, beginning image upload""), LOG.info(_LI(""Snapshot image upload complete""), LOG.info(_LI(""Instance soft rebooted successfully.""), LOG.warn(_LW(""Failed to soft reboot instance. "" ""Trying hard reboot.""), LOG.info(_LI(""Instance shutdown successfully.""), LOG.info(_LI(""Instance may have been rebooted during soft "" ""reboot, so return now.""), instance=instance) LOG.info(_LI(""Instance rebooted successfully.""), LOG.info(_LI(""Instance spawned successfully.""), LOG.info(_LI('data: %(data)r, fpath: %(fpath)r'), LOG.info(_LI('Truncated console log returned, ' '%d bytes ignored'), remaining, instance=instance) LOG.info(_LI('Truncated console log returned, ' '%d bytes ignored'), LOG.error(_LE(""Error on '%(path)s' while checking "" ""direct I/O: '%(ex)s'""), {'path': dirpath, 'ex': str(e)}) LOG.error(_LE(""Error on '%(path)s' while checking direct I/O: "" ""'%(ex)s'""), {'path': dirpath, 'ex': str(e)}) LOG.warn(_LW('Image %s not found on disk storage. ' 'Continue without injecting data'), LOG.error(_LE('Error injecting data into image ' '%(img_id)s (%(e)s)'), LOG.info(_LI('Creating image'), instance=instance) LOG.info(_LI('Using config drive'), instance=instance) LOG.info(_LI('Creating config drive at %(path)s'), LOG.error(_LE('Creating config drive failed ' 'with error: %s'), LOG.warn(_LW('File injection into a boot from volume ' 'instance is not supported'), instance=instance) LOG.warn(_LW(""Instance disappeared while detaching "" ""a PCI device from it."")) LOG.error(_LE('Attaching PCI devices %(dev)s to %(dom)s failed.'), {'dev': pci_devs, 'dom': dom.ID()}) LOG.warn(_LW('Cannot update service status on host: %s,' 'since it is not registered.'), CONF.host) except Exception: LOG.warn(_LW('Cannot update service status on host: %s,' 'due to an unexpected exception.'), CONF.host, LOG.info(_LI('Configuring timezone for windows instance to ' 'localtime'), instance=instance) LOG.debug('End to_xml xml=%(xml)s', {'xml': xml}, instance=instance) LOG.error(_LE(""An error occurred while trying to define "" ""a domain with xml: %s""), xml) LOG.error(_LE(""An error occurred while trying to launch a "" ""defined domain with xml: %s""), LOG.error(_LE(""An error occurred while enabling hairpin "" ""mode on domain with xml: %s""), domain.XMLDesc(0)) LOG.error(_LE('Neutron Reported failure on event ' '%(event)s for instance %(uuid)s'), LOG.warn(_LW('Timeout waiting for vif plugging callback for ' 'instance %(uuid)s'), {'uuid': instance['uuid']}) LOG.info(_LI(""libvirt can't find a domain with id: %s""), dom_id) LOG.warn(_LW(""Cannot get the number of cpu, because this "" ""function is not implemented for this platform. "")) LOG.warn(_LW(""couldn't obtain the vpu count from "" ""domain id: %(id)s, exception: %(ex)s""), {""id"": dom_id, ""ex"": e}) LOG.info(_LI(""libvirt can't find a domain with id: %s""), dom_id) LOG.info(_LI(""libvirt can't find a domain with id: %s""), domain_id) LOG.error(_LE('Hostname has changed from %(old)s ' 'to %(new)s. A restart is required to take effect.'), {'old': self._hypervisor_hostname, 'new': hostname}) LOG.info(_LI('Getting block stats failed, device might have ' 'been detached. Instance=%(instance_name)s ' 'Disk=%(disk)s Code=%(errcode)s Error=%(e)s'), LOG.info(_LI('Could not find domain in libvirt for instance %s. ' 'Cannot get block stats for device'), instance_name) LOG.info(_LI('Instance launched has CPU info: %s'), cpu_info) m = _LE(""CPU doesn't have compatibility.\n\n%(ret)s\n\nRefer to %(u)s"") LOG.error(_LE(""Live Migration failure: %s""), e, LOG.warn(_LW('plug_vifs() failed %(cnt)d. Retry up to ' '%(max_retry)d.'), LOG.warn(_LW('Error from libvirt while getting description of ' '%(instance_name)s: [Error Code %(error_code)s] ' '%(ex)s'), {'instance_name': instance_name, 'error_code': error_code, 'ex': ex}) LOG.warn(_LW('Periodic task is updating the host stat, ' 'it is trying to get disk %(i_name)s, ' 'but disk file was removed by concurrent ' 'operations such as resize.'), LOG.info(_LI(""Instance running successfully.""), instance=instance) LOG.info(_LI('Deleting instance files %s'), target, LOG.error(_LE('Failed to cleanup directory %(target)s: ' '%(e)s'), {'target': target, 'e': e}, LOG.info(_LI('Deletion of %s failed'), target, instance=instance) LOG.info(_LI('Deletion of %s complete'), target, instance=instance)"," LOG.warn(_('Invalid cachemode %(cache_mode)s specified ' 'for disk type %(disk_type)s.'), _error = _(""Connection to libvirt lost: %s"") % reason LOG.warning(_('The libvirt driver is not tested on ' '%(type)s/%(arch)s by the OpenStack project and ' 'thus its quality can not be ensured. For more ' 'information, see: https://wiki.openstack.org/wiki/' 'HypervisorSupportMatrix'), LOG.error(_('Nova requires libvirt version ' '%(major)i.%(minor)i.%(micro)i or greater.'), LOG.warn(_(""URI %(uri)s does not support events: %(error)s""), LOG.debug(""Registering for connection events: %s"", str(self)) LOG.warn(_(""URI %(uri)s does not support connection"" "" events: %(error)s""), LOG.warn(_(""Cannot destroy instance, operation time out""), LOG.error(_('Error from libvirt during destroy. ' 'Code=%(errcode)s Error=%(e)s'), LOG.error(_(""During wait destroy, instance disappeared.""), LOG.info(_(""Instance destroyed successfully.""), LOG.info(_(""Instance may be started again.""), LOG.info(_(""Going to destroy instance again.""), instance=instance) LOG.error(_('Error from libvirt during undefine. ' 'Code=%(errcode)s Error=%(e)s') % LOG.warn(_(""Instance may be still running, destroy "" ""it again.""), instance=instance) 'Code=%(errcode)s Error=%(e)s') % {'errcode': errcode, 'e': e}, instance=instance) LOG.warn(_(""Ignoring Volume Error on vol %(vol_id)s "" ""during delete %(exc)s""), LOG.warning(_('Volume %(disk)s possibly unsafe to ' 'remove, please clean up manually'), LOG.warn(_(""During detach_volume, instance disappeared."")) LOG.error(_('attaching network adapter failed.'), LOG.warn(_(""During detach_interface, "" ""instance disappeared.""), LOG.error(_('detaching network adapter failed.'), LOG.info(_(""Beginning live snapshot process""), LOG.info(_(""Beginning cold snapshot process""), LOG.info(_(""Snapshot extracted, beginning image upload""), LOG.info(_(""Snapshot image upload complete""), LOG.info(_(""Instance soft rebooted successfully.""), LOG.warn(_(""Failed to soft reboot instance. "" ""Trying hard reboot.""), LOG.info(_(""Instance shutdown successfully.""), LOG.info(_(""Instance may have been rebooted during soft "" ""reboot, so return now.""), instance=instance) LOG.info(_(""Instance rebooted successfully.""), LOG.info(_(""Instance spawned successfully.""), LOG.info(_('data: %(data)r, fpath: %(fpath)r'), LOG.info(_('Truncated console log returned, %d bytes ' 'ignored'), remaining, instance=instance) LOG.info(_('Truncated console log returned, %d bytes ignored'), LOG.error(_(""Error on '%(path)s' while checking "" ""direct I/O: '%(ex)s'"") % {'path': dirpath, 'ex': str(e)}) LOG.error(_(""Error on '%(path)s' while checking direct I/O: "" ""'%(ex)s'"") % {'path': dirpath, 'ex': str(e)}) LOG.warning(_('Image %s not found on disk storage. ' 'Continue without injecting data'), LOG.error(_('Error injecting data into image ' '%(img_id)s (%(e)s)'), LOG.info(_('Creating image'), instance=instance) LOG.info(_('Using config drive'), instance=instance) LOG.info(_('Creating config drive at %(path)s'), LOG.error(_('Creating config drive failed ' 'with error: %s'), LOG.warn(_('File injection into a boot from volume ' 'instance is not supported'), instance=instance) LOG.warn(_(""Instance disappeared while detaching "" ""a PCI device from it."")) LOG.error(_('Attaching PCI devices %(dev)s to %(dom)s failed.') % {'dev': pci_devs, 'dom': dom.ID()}) LOG.warn(_('Cannot update service status on host: %s,' 'since it is not registered.') % CONF.host) except Exception: LOG.warn(_('Cannot update service status on host: %s,' 'due to an unexpected exception.') % CONF.host, LOG.info(_('Configuring timezone for windows instance to ' 'localtime'), instance=instance) LOG.debug('End to_xml xml=%(xml)s', {'xml': xml}, instance=instance) LOG.error(_(""An error occurred while trying to define a domain"" "" with xml: %s"") % xml) LOG.error(_(""An error occurred while trying to launch a "" ""defined domain with xml: %s"") % LOG.error(_(""An error occurred while enabling hairpin "" ""mode on domain with xml: %s"") % domain.XMLDesc(0)) LOG.error(_('Neutron Reported failure on event ' '%(event)s for instance %(uuid)s'), LOG.warn(_('Timeout waiting for vif plugging callback for ' 'instance %(uuid)s'), {'uuid': instance['uuid']}) LOG.info(_(""libvirt can't find a domain with id: %s"") % dom_id) LOG.warn(_(""Cannot get the number of cpu, because this "" ""function is not implemented for this platform. "")) LOG.warn(_(""couldn't obtain the vpu count from domain id:"" "" %(id)s, exception: %(ex)s"") % {""id"": dom_id, ""ex"": e}) LOG.info(_(""libvirt can't find a domain with id: %s"") % dom_id) LOG.info(_(""libvirt can't find a domain with id: %s"") % domain_id) LOG.error(_('Hostname has changed from %(old)s ' 'to %(new)s. A restart is required to take effect.' ) % {'old': self._hypervisor_hostname, 'new': hostname}) LOG.info(_('Getting block stats failed, device might have ' 'been detached. Instance=%(instance_name)s ' 'Disk=%(disk)s Code=%(errcode)s Error=%(e)s'), LOG.info(_('Could not find domain in libvirt for instance %s. ' 'Cannot get block stats for device'), instance_name) LOG.info(_('Instance launched has CPU info:\n%s') % cpu_info) m = _(""CPU doesn't have compatibility.\n\n%(ret)s\n\nRefer to %(u)s"") LOG.error(_(""Live Migration failure: %s""), e, LOG.warn(_('plug_vifs() failed %(cnt)d. Retry up to ' '%(max_retry)d.'), msg = (_('Error from libvirt while getting description of ' '%(instance_name)s: [Error Code %(error_code)s] ' '%(ex)s') % {'instance_name': instance_name, 'error_code': error_code, 'ex': ex}) LOG.warn(msg) LOG.warning(_('Periodic task is updating the host stat, ' 'it is trying to get disk %(i_name)s, ' 'but disk file was removed by concurrent ' 'operations such as resize.'), LOG.info(_(""Instance running successfully.""), instance=instance) LOG.info(_('Deleting instance files %s'), target, LOG.error(_('Failed to cleanup directory %(target)s: ' '%(e)s'), {'target': target, 'e': e}, LOG.info(_('Deletion of %s failed'), target, instance=instance) LOG.info(_('Deletion of %s complete'), target, instance=instance)",138,133
openstack%2Fnova~master~Id02893f69a606ab39d84d264434cbf98f0c0211a,openstack/nova,master,Id02893f69a606ab39d84d264434cbf98f0c0211a,Log cleanups for nova.virt.libvirt.imagebackend,ABANDONED,2014-06-19 03:25:50.000000000,2014-06-24 00:58:04.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 03:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c715ce656a42b282ee67c10ea2fd6441a35cb28a', 'message': 'Log cleanups for nova.virt.libvirt.imagebackend\n\nMore log cleanups:\n     - add log hints for error logging level\n\nChange-Id: Id02893f69a606ab39d84d264434cbf98f0c0211a\n'}, {'number': 2, 'created': '2014-06-23 05:54:10.000000000', 'files': ['nova/virt/libvirt/imagebackend.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ae6584df6f19956c16ca29fe524f51cf04f97950', 'message': 'Log cleanups for nova.virt.libvirt.imagebackend\n\nMore log cleanups:\n     - add log hints for error logging level\n\nChange-Id: Id02893f69a606ab39d84d264434cbf98f0c0211a\n'}]",0,101085,ae6584df6f19956c16ca29fe524f51cf04f97950,17,7,2,2271,,,0,"Log cleanups for nova.virt.libvirt.imagebackend

More log cleanups:
     - add log hints for error logging level

Change-Id: Id02893f69a606ab39d84d264434cbf98f0c0211a
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/101085/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/imagebackend.py'],1,c715ce656a42b282ee67c10ea2fd6441a35cb28a,log-hints,"from nova.openstack.common.gettextutils import _LE LOG.error(_LE('Unable to preallocate_images=%(imgs)s at path: ' '%(path)s'), {'imgs': CONF.preallocate_images, 'path': self.path}) msg = _LE('%(base)s virtual size %(base_size)s ' 'larger than flavor root disk size %(size)s')"," LOG.error(_('Unable to preallocate_images=%(imgs)s at path: ' '%(path)s'), {'imgs': CONF.preallocate_images, 'path': self.path}) msg = _('%(base)s virtual size %(base_size)s ' 'larger than flavor root disk size %(size)s')",6,5
openstack%2Fbashate~master~I781c1b642eb15fc7e2914791d5b77e8a4752db79,openstack/bashate,master,I781c1b642eb15fc7e2914791d5b77e8a4752db79,don't use fileinput loop,MERGED,2014-06-20 11:34:13.000000000,2014-06-24 00:54:23.000000000,2014-06-24 00:54:23.000000000,"[{'_account_id': 3}, {'_account_id': 5371}]","[{'number': 1, 'created': '2014-06-20 11:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/6a7719dd00c35af904d793adb88353d1303ab8e3', 'message': ""don't use fileinput loop\n\nthere are issues where the state of a previous file will not get\nreset correctly if we implicitly use the fileinput loop. To avoid\nthis break the looping over the file list out one level.\n\nChange-Id: I781c1b642eb15fc7e2914791d5b77e8a4752db79\n""}, {'number': 2, 'created': '2014-06-20 12:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/53bfcdc9de22302c5b32956f3ae9ec6c3655d444', 'message': ""don't use fileinput loop\n\nthere are issues where the state of a previous file will not get\nreset correctly if we implicitly use the fileinput loop. To avoid\nthis break the looping over the file list out one level.\n\nWe also need to change the tests as this now requires that we always\nsend down an array instead of a string.\n\nChange-Id: I781c1b642eb15fc7e2914791d5b77e8a4752db79\n""}, {'number': 3, 'created': '2014-06-20 22:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/199a5104b16be7531b9d0c70a564871c1c8b0cdd', 'message': ""don't use fileinput loop\n\nthere are issues where the state of a previous file will not get\nreset correctly if we implicitly use the fileinput loop. To avoid\nthis break the looping over the file list out one level.\n\nWe also need to change the tests as this now requires that we always\nsend down an array instead of a string.\n\nChange-Id: I781c1b642eb15fc7e2914791d5b77e8a4752db79\n""}, {'number': 4, 'created': '2014-06-23 22:20:44.000000000', 'files': ['bashate/bashate.py', 'bashate/tests/test_bashate.py'], 'web_link': 'https://opendev.org/openstack/bashate/commit/d395de616b5154dfe21e0d0d3228342b0fbd935e', 'message': ""don't use fileinput loop\n\nthere are issues where the state of a previous file will not get\nreset correctly if we implicitly use the fileinput loop. To avoid\nthis break the looping over the file list out one level.\n\nWe also need to change the tests as this now requires that we always\nsend down an array instead of a string.\n\nChange-Id: I781c1b642eb15fc7e2914791d5b77e8a4752db79\n""}]",2,101483,d395de616b5154dfe21e0d0d3228342b0fbd935e,17,2,4,2750,,,0,"don't use fileinput loop

there are issues where the state of a previous file will not get
reset correctly if we implicitly use the fileinput loop. To avoid
this break the looping over the file list out one level.

We also need to change the tests as this now requires that we always
send down an array instead of a string.

Change-Id: I781c1b642eb15fc7e2914791d5b77e8a4752db79
",git fetch https://review.opendev.org/openstack/bashate refs/changes/83/101483/1 && git format-patch -1 --stdout FETCH_HEAD,['bash8/bash8.py'],1,6a7719dd00c35af904d793adb88353d1303ab8e3,discover," for fname in files: for line in fileinput.input(fname): if fileinput.isfirstline(): # if in_multiline when the new file starts then we didn't # find the end of a heredoc in the last file. if in_multiline: print_error('E012: heredoc did not end before EOF', multiline_line, filename=prev_file, filelineno=multiline_start) in_multiline = False # last line of a previous file should always end with a # newline if prev_file and not prev_line.endswith('\n'): print_error('E004: file did not end with a newline', prev_line, filename=prev_file, filelineno=prev_lineno) prev_file = fileinput.filename() if verbose: print(""Running bash8 on %s"" % fileinput.filename()) # NOTE(sdague): multiline processing of heredocs is interesting if not in_multiline: logical_line = line token = starts_multiline(line) if token: in_multiline = True multiline_start = fileinput.filelineno() multiline_line = line continue else: logical_line = logical_line + line if not end_of_multiline(line, token): continue else: in_multiline = False check_no_trailing_whitespace(logical_line) check_indents(logical_line) check_for_do(logical_line) check_if_then(logical_line) check_function_decl(logical_line) prev_line = logical_line prev_lineno = fileinput.filelineno()"," for line in fileinput.input(files): if fileinput.isfirstline(): # if in_multiline when the new file starts then we didn't # find the end of a heredoc in the last file. if in_multiline: print_error('E012: heredoc did not end before EOF', multiline_line, filename=prev_file, filelineno=multiline_start) in_multiline = False # last line of a previous file should always end with a # newline if prev_file and not prev_line.endswith('\n'): print_error('E004: file did not end with a newline', prev_line, filename=prev_file, filelineno=prev_lineno) prev_file = fileinput.filename() if verbose: print(""Running bash8 on %s"" % fileinput.filename()) # NOTE(sdague): multiline processing of heredocs is interesting if not in_multiline: logical_line = line token = starts_multiline(line) if token: in_multiline = True multiline_start = fileinput.filelineno() multiline_line = line continue else: logical_line = logical_line + line if not end_of_multiline(line, token): continue else: in_multiline = False check_no_trailing_whitespace(logical_line) check_indents(logical_line) check_for_do(logical_line) check_if_then(logical_line) check_function_decl(logical_line) prev_line = logical_line prev_lineno = fileinput.filelineno()",40,39
openstack%2Ftripleo-image-elements~master~I6b8ecb46f6b9b381e92a16df4c829d1a7aecd2c4,openstack/tripleo-image-elements,master,I6b8ecb46f6b9b381e92a16df4c829d1a7aecd2c4,Enable ip nonlocal binds,MERGED,2014-06-19 19:49:55.000000000,2014-06-24 00:45:43.000000000,2014-06-24 00:45:43.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7471}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-06-19 19:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a676508fec73c33c995a6dec00c840527055c50c', 'message': 'Enable ip nonlocal binds\n\nWe require nonlocal binds enabled for our HAProxy VIPs to work.\n\nChange-Id: I6b8ecb46f6b9b381e92a16df4c829d1a7aecd2c4\n'}, {'number': 2, 'created': '2014-06-22 21:08:50.000000000', 'files': ['elements/haproxy/os-refresh-config/configure.d/75-haproxy-nonlocal-bind'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/78eede16f710e2caaad87c459ff1af104834cefe', 'message': 'Enable ip nonlocal binds\n\nWe require nonlocal binds enabled for our HAProxy VIPs to work.\n\nChange-Id: I6b8ecb46f6b9b381e92a16df4c829d1a7aecd2c4\n'}]",0,101305,78eede16f710e2caaad87c459ff1af104834cefe,17,5,2,10035,,,0,"Enable ip nonlocal binds

We require nonlocal binds enabled for our HAProxy VIPs to work.

Change-Id: I6b8ecb46f6b9b381e92a16df4c829d1a7aecd2c4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/05/101305/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/os-refresh-config/post-configure.d/15-nonlocal-bind'],1,a676508fec73c33c995a6dec00c840527055c50c,feature/haproxy-nonlocal-bind,#!/bin/bash set -eu set -o pipefail sysctl-set-value net.ipv4.ip_nonlocal_bind 1 ,,6,0
openstack%2Fpuppet-neutron~master~Id70420a871edc352f80c0446e89dbcde94e5c490,openstack/puppet-neutron,master,Id70420a871edc352f80c0446e89dbcde94e5c490,Configure OVS Agent when using ML2 plugin,MERGED,2014-04-28 20:01:23.000000000,2014-06-23 23:42:54.000000000,2014-06-10 17:26:04.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 2265}, {'_account_id': 3153}, {'_account_id': 4128}, {'_account_id': 5241}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 7102}, {'_account_id': 7156}, {'_account_id': 7468}, {'_account_id': 7616}, {'_account_id': 7822}, {'_account_id': 10536}, {'_account_id': 10540}, {'_account_id': 11623}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/dce7fe60db5ce14833d6eba94f6bbcdc49b462d0', 'message': ""WIP - Configure OVS Agent in ML2 config\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nCurrently, neutron::agents::ovs is only able to configure OVS\nconfiguration file. This patch aims to discuss about a new design of the\nagents and find a way to keep backward compatibility with old model\n(without ML2).\n\nDO NOT MERGE IT.\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 2, 'created': '2014-05-22 20:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/76c848f8d4eda8d188ff1f299dd65d1cbca7beb4', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 3, 'created': '2014-05-25 20:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/4c00f25edfe4908b86d8711f06a86e29e33f9efb', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 4, 'created': '2014-05-28 08:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1429c3acf1e6f861e97dfd9f7798b84dba997fda', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 5, 'created': '2014-05-29 16:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e2736f8735e06a6ce7b5b25ac87f4e29b19c4736', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 6, 'created': '2014-05-29 16:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1bb1f7f088f4b7e98a554e6b75dcb2de0df437b0', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 7, 'created': '2014-06-04 06:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/94f546b46f0ed7c536275aee530459e1fd5b551a', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n(cherry picked from commit 1bb1f7f088f4b7e98a554e6b75dcb2de0df437b0)\n""}, {'number': 8, 'created': '2014-06-04 12:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/bb4f757e245b0fd11c3a513454c8f5f2f2147740', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490""}, {'number': 9, 'created': '2014-06-09 08:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/25eb75c63b101169b90d4af79d5a70843c96142e', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}, {'number': 10, 'created': '2014-06-10 12:59:09.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'manifests/plugins/ml2.pp', 'spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/069d086b0d636fe6432a11ea97af28c1f2b38582', 'message': ""Configure OVS Agent when using ML2 plugin\n\nWhen running ML2 plugin, Neutron does not read the OVS plugin\nconfiguration file, so the Agents can't work (mount tunnels, configure\nL2, etc).\nTo make it work, you need to move the configuration in ML2 configuration\nfile.\n\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: Id70420a871edc352f80c0446e89dbcde94e5c490\n""}]",8,82353,069d086b0d636fe6432a11ea97af28c1f2b38582,61,16,10,3153,,,0,"Configure OVS Agent when using ML2 plugin

When running ML2 plugin, Neutron does not read the OVS plugin
configuration file, so the Agents can't work (mount tunnels, configure
L2, etc).
To make it work, you need to move the configuration in ML2 configuration
file.

Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
Change-Id: Id70420a871edc352f80c0446e89dbcde94e5c490
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/53/82353/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_ovsml2_spec.rb', 'manifests/agents/ovsml2.pp']",2,dce7fe60db5ce14833d6eba94f6bbcdc49b462d0,ml2-ovs,"# == Class: neutron::agents::ovsml2 # # Setups OVS neutron agent when using ML2 plugin # # === Parameters # # [*firewall_driver*] # (optional) Firewall driver for realizing neutron security group function. # Defaults to 'neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver'. # class neutron::agents::ovsml2 ( $package_ensure = 'present', $enabled = true, $bridge_uplinks = [], $bridge_mappings = [], $integration_bridge = 'br-int', $enable_tunneling = false, $tunnel_types = [], $local_ip = false, $tunnel_bridge = 'br-tun', $vxlan_udp_port = 4789, $polling_interval = 2, $firewall_driver = 'neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver' ) { include neutron::params require vswitch::ovs if $enable_tunneling and ! $local_ip { fail('Local ip for ovs agent must be set when tunneling is enabled') } Neutron_config<||> ~> Service['neutron-plugin-ovs-service'] Neutron_plugin_ovs<||> ~> Service['neutron-plugin-ovs-service'] if ($bridge_mappings != []) { # bridge_mappings are used to describe external networks that are # *directly* attached to this machine. # (This has nothing to do with VM-VM comms over neutron virtual networks.) # Typically, the network node - running L3 agent - will want one external # network (often this is on the control node) and the other nodes (all the # compute nodes) will want none at all. The only other reason you will # want to add networks here is if you're using provider networks, in which # case you will name the network with bridge_mappings and add the server's # interfaces that are attached to that network with bridge_uplinks. # (The bridge names can be nearly anything, they just have to match between # mappings and uplinks; they're what the OVS switches will get named.) # Set config for bridges that we're going to create # The OVS neutron plugin will talk in terms of the networks in the bridge_mappings $br_map_str = join($bridge_mappings, ',') neutron_plugin_ml2 { 'OVS/bridge_mappings': value => $br_map_str; } neutron::plugins::ovs::bridge{ $bridge_mappings: before => Service['neutron-plugin-ovs-service'], } neutron::plugins::ovs::port{ $bridge_uplinks: before => Service['neutron-plugin-ovs-service'], } } neutron_plugin_ml2 { 'AGENT/polling_interval': value => $polling_interval; 'OVS/integration_bridge': value => $integration_bridge; } if ($firewall_driver) { neutron_plugin_ml2 { 'SECURITYGROUP/firewall_driver': value => $firewall_driver } } else { neutron_plugin_ml2 { 'SECURITYGROUP/firewall_driver': ensure => absent } } vs_bridge { $integration_bridge: ensure => present, before => Service['neutron-plugin-ovs-service'], } if $enable_tunneling { vs_bridge { $tunnel_bridge: ensure => present, before => Service['neutron-plugin-ovs-service'], } neutron_plugin_ml2 { 'OVS/enable_tunneling': value => true; 'OVS/tunnel_bridge': value => $tunnel_bridge; 'OVS/local_ip': value => $local_ip; } if size($tunnel_types) > 0 { neutron_plugin_ml2 { 'agent/tunnel_types': value => join($tunnel_types, ','); } } if 'vxlan' in $tunnel_types { validate_vxlan_udp_port($vxlan_udp_port) neutron_plugin_ml2 { 'agent/vxlan_udp_port': value => $vxlan_udp_port; } } } else { neutron_plugin_ml2 { 'OVS/enable_tunneling': value => false; 'OVS/tunnel_bridge': ensure => absent; 'OVS/local_ip': ensure => absent; } } if $::neutron::params::ovs_agent_package { Package['neutron-plugin-ovs-agent'] -> Neutron_plugin_ovs<||> package { 'neutron-plugin-ovs-agent': ensure => $package_ensure, name => $::neutron::params::ovs_agent_package, } } else { # Some platforms (RedHat) do not provide a separate # neutron plugin ovs agent package. The configuration file for # the ovs agent is provided by the neutron ovs plugin package. Package['neutron-plugin-ovs'] -> Neutron_plugin_ovs<||> Package['neutron-plugin-ovs'] -> Service['ovs-cleanup-service'] if ! defined(Package['neutron-plugin-ovs']) { package { 'neutron-plugin-ovs': ensure => $package_ensure, name => $::neutron::params::ovs_server_package, } } } if $enabled { $service_ensure = 'running' } else { $service_ensure = 'stopped' } service { 'neutron-plugin-ovs-service': ensure => $service_ensure, name => $::neutron::params::ovs_agent_service, enable => $enabled, require => Class['neutron'], } if $::neutron::params::ovs_cleanup_service { service {'ovs-cleanup-service': ensure => $service_ensure, name => $::neutron::params::ovs_cleanup_service, enable => $enabled, } } } ",,333,0
openstack%2Ftripleo-image-elements~master~I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd,openstack/tripleo-image-elements,master,I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd,Update openstack services to listen on stunnel connect port,MERGED,2013-12-11 11:07:53.000000000,2014-06-23 23:35:44.000000000,2014-06-23 23:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 8907}, {'_account_id': 10035}, {'_account_id': 11176}]","[{'number': 1, 'created': '2013-12-11 11:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8f21c6415fb5cb946cb8df41f4739f7b1b566aa9', 'message': 'Update openstack services to listen on local ip only if haproxy is used\n\nIf haproxy which uses virtual ip is used, openstack services should not\nlisten on all addresses (0.0.0.0) but only on local ip address so that\nhaproxy can be bound to the virtual ip address.\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}, {'number': 2, 'created': '2014-05-28 13:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/15eeba8da13c5de33afdf9468080b8687db1c381', 'message': 'Update openstack services to listen on stunnel connect port\n\nIf haproxy+stunnel is used, openstack services should not listen\non all addresses (0.0.0.0) but only on address where stunnel is\nconnected to.\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}, {'number': 3, 'created': '2014-06-09 13:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/95e81a20aa5497df5c0a935116765d6fac2e0328', 'message': 'Update openstack services to listen on stunnel connect port\n\nIf haproxy+stunnel is used, openstack services should not listen\non all addresses (0.0.0.0) but only on address where stunnel is\nconnected to.\n\nIf haproxy is used but stunnel not, services should bind to local-ipv4\naddress.\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}, {'number': 4, 'created': '2014-06-10 20:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/37e119c7f6e8a7f44219664523d528d827e003a3', 'message': 'Update openstack services to listen on stunnel connect port\n\nIf haproxy+stunnel is used, openstack services should not listen\non all addresses (0.0.0.0) but only on address where stunnel is\nconnected to.\n\nIf haproxy is used but stunnel not, services should bind to local-ipv4\naddress.\n\nRelated-to: blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}, {'number': 5, 'created': '2014-06-16 07:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0e4c9831d71759c4ce43d4e6b0fc81248c487de6', 'message': 'Update openstack services to listen on stunnel connect port\n\nIf haproxy+stunnel is used, openstack services should not listen\non all addresses (0.0.0.0) but only on address where stunnel is\nconnected to.\n\nIf haproxy is used but stunnel not, services should bind to local-ipv4\naddress.\n\nRelated-to: blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}, {'number': 6, 'created': '2014-06-18 21:53:42.000000000', 'files': ['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf', 'elements/glance/os-config-applier/etc/glance/glance-registry.conf', 'elements/keystone/os-apply-config/etc/keystone/keystone.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/swift-proxy/os-config-applier/etc/swift/proxy-server.conf', 'elements/glance/os-config-applier/etc/glance/glance-api.conf', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf', 'elements/trove-api/os-apply-config/etc/trove/trove.conf', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/heat/os-config-applier/etc/heat/heat.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4e233ff117c7117238e5322b4e5dd9d2f26a0899', 'message': 'Update openstack services to listen on stunnel connect port\n\nIf haproxy+stunnel is used, openstack services should not listen\non all addresses (0.0.0.0) but only on address where stunnel is\nconnected to.\n\nIf haproxy is used but stunnel not, services should bind to local-ipv4\naddress.\n\nRelated-to: blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd\n'}]",9,61376,4e233ff117c7117238e5322b4e5dd9d2f26a0899,73,9,6,7582,,,0,"Update openstack services to listen on stunnel connect port

If haproxy+stunnel is used, openstack services should not listen
on all addresses (0.0.0.0) but only on address where stunnel is
connected to.

If haproxy is used but stunnel not, services should bind to local-ipv4
address.

Related-to: blueprint tripleo-icehouse-ha-production-configuration

Change-Id: I2aca62a8da61221d67f7a99bc33a6e4ebfa53acd
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/76/61376/6 && git format-patch -1 --stdout FETCH_HEAD,"['elements/glance/os-config-applier/etc/glance/glance-registry.conf', 'elements/swift-proxy/os-config-applier/etc/swift/proxy-server.conf', 'elements/glance/os-config-applier/etc/glance/glance-api.conf', 'elements/keystone/os-config-applier/etc/keystone/keystone.conf', 'elements/neutron/os-config-applier/etc/neutron/neutron.conf', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/cinder/os-config-applier/etc/cinder/cinder.conf', 'elements/heat/os-config-applier/etc/heat/heat.conf']",8,8f21c6415fb5cb946cb8df41f4739f7b1b566aa9,bp/tripleo-icehouse-ha-production-configuration,{{#haproxy}} bind_host = {{local-ipv4}} {{/haproxy}},,37,3
openstack%2Fcookbook-openstack-dashboard~master~Icd1492911f910dfdbee685194ca870748b421776,openstack/cookbook-openstack-dashboard,master,Icd1492911f910dfdbee685194ca870748b421776,Make auth API version configurable in the usual way,MERGED,2014-06-17 15:45:32.000000000,2014-06-23 22:51:56.000000000,2014-06-23 22:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 9884}, {'_account_id': 10110}]","[{'number': 1, 'created': '2014-06-17 15:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/9f11375a6a8abe0cabbb80a6b5e93bc930827858', 'message': 'Make auth API version configurable in the usual way\n\nThe expectation that overriding node[openstack][api][auth][version]\nwould set this value for the dashboard, too, can now be met.\n\nChange-Id: Icd1492911f910dfdbee685194ca870748b421776\n'}, {'number': 2, 'created': '2014-06-23 08:29:14.000000000', 'files': ['attributes/default.rb', 'spec/server_spec.rb', 'recipes/server.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/08ced6c681a482ffbaab7f9f0cee907cce25819e', 'message': 'Make auth API version configurable in the usual way\n\nThe expectation that overriding node[openstack][api][auth][version]\nwould set this value for the dashboard, too, can now be met.\n\nChange-Id: Icd1492911f910dfdbee685194ca870748b421776\n'}]",2,100600,08ced6c681a482ffbaab7f9f0cee907cce25819e,15,5,2,10110,,,0,"Make auth API version configurable in the usual way

The expectation that overriding node[openstack][api][auth][version]
would set this value for the dashboard, too, can now be met.

Change-Id: Icd1492911f910dfdbee685194ca870748b421776
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/00/100600/2 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/server_spec.rb', 'recipes/server.rb']",3,9f11375a6a8abe0cabbb80a6b5e93bc930827858,fix_api_auth_version,"auth_admin_uri = auth_uri_transform identity_admin_endpoint.to_s, node['openstack']['dashboard']['api']['auth']['version']auth_uri = auth_uri_transform identity_endpoint.to_s, node['openstack']['dashboard']['api']['auth']['version']","auth_admin_uri = ::URI.decode identity_admin_endpoint.to_sauth_uri = ::URI.decode identity_endpoint.to_s case node['openstack']['dashboard']['identity_api_version'] when 2.0 auth_version = 'v2.0' when 3 auth_version = 'v3.0' end auth_admin_uri = auth_uri_transform auth_admin_uri, auth_version auth_uri = auth_uri_transform auth_uri, auth_version",24,16
openstack%2Ftripleo-specs~master~I7e08a69aca594e24fc742d0e5151bfbe129628f0,openstack/tripleo-specs,master,I7e08a69aca594e24fc742d0e5151bfbe129628f0,Add blueprint link to haproxy_configuration.rst,MERGED,2014-05-30 08:58:19.000000000,2014-06-23 22:48:14.000000000,2014-06-23 20:26:58.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6928}, {'_account_id': 7537}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-05-30 08:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4aa524c77e30a844db602289bf1d4626d087abb3', 'message': 'Add blueprint link to haproxy_configuration.rst\n\nChanges:\n - add link to launchpad blueprint\n - fixed some typos\n\nChange-Id: I7e08a69aca594e24fc742d0e5151bfbe129628f0\n'}, {'number': 2, 'created': '2014-05-30 09:15:43.000000000', 'files': ['specs/juno/haproxy_configuration.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ad715270d11f5226e0099a020e11563192b8fc06', 'message': 'Add blueprint link to haproxy_configuration.rst\n\nChanges:\n - add link to launchpad blueprint\n - fixed some typos\n\nChange-Id: I7e08a69aca594e24fc742d0e5151bfbe129628f0\n'}]",2,96693,ad715270d11f5226e0099a020e11563192b8fc06,17,5,2,8907,,,0,"Add blueprint link to haproxy_configuration.rst

Changes:
 - add link to launchpad blueprint
 - fixed some typos

Change-Id: I7e08a69aca594e24fc742d0e5151bfbe129628f0
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/93/96693/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/haproxy_configuration.rst'],1,4aa524c77e30a844db602289bf1d4626d087abb3,haproxy,Blueprint: https://blueprints.launchpad.net/tripleo/+spec/haproxy-configuration bind 127.0.0.1:80* build overcloud-control image with haproxy elementCI testing dependencies:, bind 127.0.0.1:8800* build overcloud-controler image with haproxy elementCI testing dependendcies:,5,3
openstack%2Fcookbook-openstack-ops-database~master~I2207b3925a8a99b6e58f808b3c2110a5ff865774,openstack/cookbook-openstack-ops-database,master,I2207b3925a8a99b6e58f808b3c2110a5ff865774,updated database cookbook dependency in metadata,ABANDONED,2014-06-23 22:27:45.000000000,2014-06-23 22:44:53.000000000,,"[{'_account_id': 3}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-23 22:27:45.000000000', 'files': ['metadata.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/5dfc274c43cbb94e1bc52b712703e704d163e0f0', 'message': 'updated database cookbook dependency in metadata\n\nChange-Id: I2207b3925a8a99b6e58f808b3c2110a5ff865774\n'}]",0,102039,5dfc274c43cbb94e1bc52b712703e704d163e0f0,5,2,1,12044,,,0,"updated database cookbook dependency in metadata

Change-Id: I2207b3925a8a99b6e58f808b3c2110a5ff865774
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/39/102039/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.rb'],1,5dfc274c43cbb94e1bc52b712703e704d163e0f0,update-mysql-database-recipe,"depends 'database', '~> 2.2'","depends 'database', '>= 2.0.0'",1,1
openstack%2Fbarbican-specs~master~I726a55344f38eb9797991acd0d4caec004aecdd6,openstack/barbican-specs,master,I726a55344f38eb9797991acd0d4caec004aecdd6,Initial blueprint for content type enforcement,MERGED,2014-06-17 16:48:49.000000000,2014-06-23 22:40:48.000000000,2014-06-23 22:40:48.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8004}]","[{'number': 1, 'created': '2014-06-17 16:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/5c3a4f4f6f48d0be53d6328f7d10369ed978f0b3', 'message': 'Initial blueprint for content type enforcement\n\nChange-Id: I726a55344f38eb9797991acd0d4caec004aecdd6\n'}, {'number': 2, 'created': '2014-06-19 18:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/f974d870c57a434e8eb860d7de00cb928bdec0c3', 'message': 'Initial blueprint for content type enforcement\n\nUpdated to address comments.\n\nChange-Id: I726a55344f38eb9797991acd0d4caec004aecdd6\n'}, {'number': 3, 'created': '2014-06-19 21:29:43.000000000', 'files': ['specs/juno/barbican-enforce-content-type.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/74bf5f6366fec50595068d2aaf4ebd3ccbd0ddcb', 'message': 'Initial blueprint for content type enforcement\n\nUpdated to address comments.\n\nChange-Id: I726a55344f38eb9797991acd0d4caec004aecdd6\n'}]",12,100625,74bf5f6366fec50595068d2aaf4ebd3ccbd0ddcb,22,5,3,9234,,,0,"Initial blueprint for content type enforcement

Updated to address comments.

Change-Id: I726a55344f38eb9797991acd0d4caec004aecdd6
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/25/100625/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/barbican-enforce-content-type.rst'],1,5c3a4f4f6f48d0be53d6328f7d10369ed978f0b3,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Enforce content type on barbican REST API ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/barbican-enforce-content-type Before barbican moved from falcon to pecan, content types were coerced to application/json. This meant that a user could use a tool such as curl, omit the content type, and the call would succeed. After moving to pecan, the default content-type changed to application/x-www-form-urlencoded. This meant that a curl request without a content type specified would end up coming into barbican as a urlencoded string and would fail during JSONifying. Problem Description =================== As a result of the move from falcon to pecan, the default content type for requests has changed from application/json to application/xxx-www-form-urlencoded. That means that calls without a content-type which used to work with the falcon implementation will now fail with the pecan implementation. If a caller sets their content-type header to application/json then everything works as expected. However, if a caller omits the content-type header then it now defaults to application/xxx-www-form-urlencoded. This means that pecan will URLencode the request body, and that causes barbican to fail when it tries to JSONify it. Proposed Change =============== The proposed change is to check the content-type header and reject any request that does not specify the correct value via pecan abort with HTTP 415. Alternatives ------------ There are alternatives to the proposed change: * Change the content-type header to application/json. This would resolve the problem described above, but could have unintended consequences as the user's input data would be changed from what they provided/expected. * Detect the situation where the default was taken for content-type and compensate by: * URL-decoding the string * cleanup any padding characters that may have been added Data model impact ----------------- None. REST API impact --------------- Each API that barbican provides that accepts a request body will have to have it content-type header set to ""application/json"". Security impact --------------- None. Notifications & Audit Impact ---------------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ Each REST call will now incur a check of the content-type. Calls without the correct content-type will fail with pecan.abort and HTTP 415. Other deployer impact --------------------- None. Developer impact ---------------- Developers who use a tool such as curl will need to ensure that they pass content-type:application/json in their HTTP headers, otherwise they will fail with HTTP 415. Implementation ============== Assignee(s) ----------- Primary assignee: sheyman Other contributors: john-wood-w arunkant-uws Work Items ---------- There are 3 work items required for this change: * updating the barbican code to detect incorrect content types and pecan abort with HTTP 415 * updating the barbican documentation to describe this change and provide recovery action * updating the barbican tests to validate the behavior of the new code. This includes unit and functional tests. Dependencies ============ None. Testing ======= The following test scenarios will be needed for each of the barbican REST APIs: * invoke API with no content type in header Expected behavior: fails with HTTP 415 * invoke API with content type of ""text/plain"" Expected behavior: fails with HTTP 415 * invoke API with content type of ""application/jsontypo"" Expected behavior: fails with HTTP 415 * invoke API with content type of ""applicationtypo/json"" Expected behavior: fails with HTTP 415 * invoke API with content type of ""application/json"" Expected behavior: API succeeds Documentation Impact ==================== Documentation will need to specify that the content-type header is now required, and must be ""application/json"". Omitted content-type, or content-type other than ""application/json"" will result in an HTTP 415. References ========== The following bugs and proposed fixes led to the creation of this blueprint: * https://review.openstack.org/#/c/97554 * https://review.openstack.org/#/c/99423 * https://bugs.launchpad.net/barbican/+bug/1321555 * https://bugs.launchpad.net/barbican/+bug/1320276 ",,179,0
openstack%2Fnova~master~I40a12cc1463b9902b946af8a999fc8e26299c2cf,openstack/nova,master,I40a12cc1463b9902b946af8a999fc8e26299c2cf,"Revert ""Fix resource cleanup in NetworkManager.allocate_fixed_ip""",ABANDONED,2014-06-23 20:30:19.000000000,2014-06-23 22:19:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 20:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29aaff3128775a6711727da2f61f7f7084e431f1', 'message': 'Revert ""Fix resource cleanup in NetworkManager.allocate_fixed_ip""\n\nThis reverts commit 077e3c770ebeebd037ce882863a6b5dcefd644cf.\n\nSomething broke related to fixed IPs on 6/23 and looking at what\'s merged this is suspect.\n\nChange-Id: I40a12cc1463b9902b946af8a999fc8e26299c2cf\nCloses-Bug: #1333410\n'}, {'number': 2, 'created': '2014-06-23 20:30:42.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/464db939fc6c6bdd25a86e070b8d0ab2ca8c328d', 'message': 'Revert ""Fix resource cleanup in NetworkManager.allocate_fixed_ip""\n\nThis reverts commit 077e3c770ebeebd037ce882863a6b5dcefd644cf.\n\nSomething broke related to fixed IPs on 6/23 and looking at\nwhat\'s merged this is suspect.\n\nCloses-Bug: #1333410\n\nChange-Id: I40a12cc1463b9902b946af8a999fc8e26299c2cf\n'}]",0,102002,464db939fc6c6bdd25a86e070b8d0ab2ca8c328d,11,8,2,6873,,,0,"Revert ""Fix resource cleanup in NetworkManager.allocate_fixed_ip""

This reverts commit 077e3c770ebeebd037ce882863a6b5dcefd644cf.

Something broke related to fixed IPs on 6/23 and looking at
what's merged this is suspect.

Closes-Bug: #1333410

Change-Id: I40a12cc1463b9902b946af8a999fc8e26299c2cf
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/102002/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,29aaff3128775a6711727da2f61f7f7084e431f1,bug/1328539,,"import contextlibfrom nova.objects import virtual_interface as vif_obj @mock.patch('nova.objects.instance.Instance.get_by_uuid') @mock.patch('nova.objects.virtual_interface.VirtualInterface' '.get_by_instance_and_network') @mock.patch('nova.objects.fixed_ip.FixedIP.disassociate') @mock.patch('nova.objects.fixed_ip.FixedIP.associate') @mock.patch('nova.objects.fixed_ip.FixedIP.save') def test_allocate_fixed_ip_cleanup(self, mock_fixedip_save, mock_fixedip_associate, mock_fixedip_disassociate, mock_vif_get, mock_instance_get): address = netaddr.IPAddress('1.2.3.4') fip = fixed_ip_obj.FixedIP(instance_uuid='fake-uuid', address=address, virtual_interface_id=1) mock_fixedip_associate.return_value = fip instance = instance_obj.Instance(context=self.context) instance.create() mock_instance_get.return_value = instance mock_vif_get.return_value = vif_obj.VirtualInterface( instance_uuid='fake-uuid', id=1) with contextlib.nested( mock.patch.object(self.network, '_setup_network_on_host'), mock.patch.object(self.network, 'instance_dns_manager'), mock.patch.object(self.network, '_do_trigger_security_group_members_refresh_for_instance') ) as (mock_setup_network, mock_dns_manager, mock_ignored): mock_setup_network.side_effect = test.TestingException self.assertRaises(test.TestingException, self.network.allocate_fixed_ip, self.context, instance.uuid, {'cidr': '24', 'id': 1, 'uuid': 'nosuch'}, address=address) mock_dns_manager.delete_entry.assert_has_calls([ mock.call(instance.display_name, ''), mock.call(instance.uuid, '') ]) mock_fixedip_disassociate.assert_called_once() ",1,76
openstack%2Fneutron-specs~master~I3305f174a793a53bdccc723c89ff6588797b33c8,openstack/neutron-specs,master,I3305f174a793a53bdccc723c89ff6588797b33c8,Specification for http pool config parameter in cisco n1kv plugin,ABANDONED,2014-04-26 01:32:42.000000000,2014-06-23 22:15:45.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7018}, {'_account_id': 8940}]","[{'number': 1, 'created': '2014-04-26 01:32:42.000000000', 'files': ['specs/juno/n1kv-http-requests-pool.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3ec5077b301e5830dd13be9294d535b434b95837', 'message': 'Specification for http pool config parameter in cisco n1kv plugin\n\nChange-Id: I3305f174a793a53bdccc723c89ff6588797b33c8\n'}]",2,90510,3ec5077b301e5830dd13be9294d535b434b95837,8,7,1,7018,,,0,"Specification for http pool config parameter in cisco n1kv plugin

Change-Id: I3305f174a793a53bdccc723c89ff6588797b33c8
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/10/90510/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/n1kv-http-requests-pool.rst'],1,3ec5077b301e5830dd13be9294d535b434b95837,bp/n1kv-http-requests-pool,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================================== Control active number of REST calls to the controller in Cisco N1kv plugin ========================================================================== https://blueprints.launchpad.net/neutron/+spec/n1kv-http-requests-pool Plugin should be able to control the total number of HTTP connections it can use to connect and perform requests to the controller. Problem description =================== Currently the plugin does not have a way to control the total number of active HTTP connections it maintains with the controller. Proposed change =============== The proposed change is to add a config parameter to cisco_plugins.ini which specifies the maximum number of HTTP connections the plugin can initiate with the controller. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: abhraut Other contributors: sopatwar Work Items ---------- - Add a config paramter to cisco_plugins.ini - Use GreenPool to manage the total number of active HTTP connections based on the config parameter. - Modify the existing client calls to use this pool. Dependencies ============ None Testing ======= Unit tests will be added to test the new config parameter and its effects on code. Documentation Impact ==================== None References ========== None ,,113,0
openstack%2Ffuel-library~master~I5c0cbd1dbffaf34649a32de34fb93c4de20d09f0,openstack/fuel-library,master,I5c0cbd1dbffaf34649a32de34fb93c4de20d09f0,Add swift roles into cluster_ha,MERGED,2014-06-23 21:12:35.000000000,2014-06-23 22:07:46.000000000,2014-06-23 22:07:46.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-23 21:12:35.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8ec900a2bc96a463a72405a674e41f52fc0d3e14', 'message': 'Add swift roles into cluster_ha\n\nthe swift roles used to be in cluster_ha_full, but the file was removed in\nI964beb280a1e6453cd8864dbfa356da12dbbadcd . In order to ensure that the code\n is not lost as it is used in some custom cases we will add it into cluster_ha.\n\nThere is no expectation to test or maintain this at this time, this is only to\nensure that the code is not lost or becomes hard to find.\n\nChange-Id: I5c0cbd1dbffaf34649a32de34fb93c4de20d09f0\n'}]",0,102016,8ec900a2bc96a463a72405a674e41f52fc0d3e14,12,3,1,8797,,,0,"Add swift roles into cluster_ha

the swift roles used to be in cluster_ha_full, but the file was removed in
I964beb280a1e6453cd8864dbfa356da12dbbadcd . In order to ensure that the code
 is not lost as it is used in some custom cases we will add it into cluster_ha.

There is no expectation to test or maintain this at this time, this is only to
ensure that the code is not lost or becomes hard to find.

Change-Id: I5c0cbd1dbffaf34649a32de34fb93c4de20d09f0
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/16/102016/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'],1,8ec900a2bc96a463a72405a674e41f52fc0d3e14,keep_swift_roles," # Definition of the first OpenStack Swift node. /storage/ : { class { 'operatingsystem::checksupported': stage => 'setup' } $swift_zone = $node[0]['swift_zone'] class { 'openstack::swift::storage_node': storage_type => $swift_loopback, loopback_size => '5243780', storage_mnt_base_dir => $swift_partition, storage_devices => $mountpoints, swift_zone => $swift_zone, swift_local_net_ip => $swift_local_net_ip, master_swift_proxy_ip => $master_swift_proxy_ip, cinder => $cinder, cinder_iscsi_bind_addr => $cinder_iscsi_bind_addr, cinder_volume_group => ""cinder"", manage_volumes => $cinder ? { false => $manage_volumes, default =>$is_cinder_node }, db_host => $::fuel_settings['management_vip'], service_endpoint => $::fuel_settings['management_vip'], cinder_rate_limits => $cinder_rate_limits, queue_provider => $::queue_provider, rabbit_nodes => $controller_nodes, rabbit_password => $rabbit_hash[password], rabbit_user => $rabbit_hash[user], rabbit_ha_virtual_ip => $::fuel_settings['management_vip'], qpid_password => $rabbit_hash[password], qpid_user => $rabbit_hash[user], qpid_nodes => [$::fuel_settings['management_vip']], sync_rings => ! $primary_proxy, syslog_log_level => $syslog_log_level, debug => $debug, verbose => $verbose, syslog_log_facility_cinder => $syslog_log_facility_cinder, } } # Definition of OpenStack Swift proxy nodes. /swift-proxy/ : { class { 'operatingsystem::checksupported': stage => 'first' } if $primary_proxy { ring_devices {'all': storages => $swift_storages } } class { 'openstack::swift::proxy': swift_user_password => $swift_hash[user_password], swift_proxies => $swift_proxies, primary_proxy => $primary_proxy, controller_node_address => $::fuel_settings['management_vip'], swift_local_net_ip => $swift_local_net_ip, master_swift_proxy_ip => $master_swift_proxy_ip, syslog_log_level => $syslog_log_level, debug => $debug, verbose => $verbose, } } ",,65,0
openstack%2Fosprofiler~master~Iead71cee468d78aa52aad66e23e0acffa2df4a52,openstack/osprofiler,master,Iead71cee468d78aa52aad66e23e0acffa2df4a52,Improve test coverage,MERGED,2014-06-23 21:46:18.000000000,2014-06-23 21:59:03.000000000,2014-06-23 21:59:03.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-23 21:46:18.000000000', 'files': ['tests/test_web.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/009474164a1af4f6eddc167dce93fd194a151a3c', 'message': 'Improve test coverage\n\nChange-Id: Iead71cee468d78aa52aad66e23e0acffa2df4a52\n'}]",0,102024,009474164a1af4f6eddc167dce93fd194a151a3c,7,2,1,6172,,,0,"Improve test coverage

Change-Id: Iead71cee468d78aa52aad66e23e0acffa2df4a52
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/24/102024/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_web.py'],1,009474164a1af4f6eddc167dce93fd194a151a3c,simplify_code," def test_factory(self): mock_app = mock.MagicMock() local_conf = {""enabled"": True, ""hmac_key"": ""123""} factory = web.WsgiMiddleware.factory(None, **local_conf) wsgi = factory(mock_app) self.assertEqual(wsgi.application, mock_app) self.assertEqual(wsgi.name, ""wsgi"") self.assertTrue(wsgi.enabled) self.assertEqual(wsgi.hmac_key, local_conf[""hmac_key""]) ",,12,0
openstack%2Fzaqar~master~I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c,openstack/zaqar,master,I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c,Correct the rtype in the function docstrings,MERGED,2014-06-18 06:56:37.000000000,2014-06-23 21:14:59.000000000,2014-06-23 21:14:58.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 8092}, {'_account_id': 10634}, {'_account_id': 10777}]","[{'number': 1, 'created': '2014-06-18 06:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d3b8f09674d3636d3a07127637ba4f45412f78a9', 'message': 'Correct the rtype in the function docstrings\n\nFix the non-existing rtype in the storage/sharding.py\nfunction docstrings.\n\nChange-Id: I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c\n'}, {'number': 2, 'created': '2014-06-23 03:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6c3efcb10035dccd1a5129f8ce36020cbf416844', 'message': 'Correct the rtype in the function docstrings\n\nFix the non-existing rtype in the storage/sharding.py\nfunction docstrings.\n\nChange-Id: I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c\n'}, {'number': 3, 'created': '2014-06-23 08:55:04.000000000', 'files': ['marconi/queues/storage/pooling.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6bb1f9e7658af3a27c7a53efb6e09fa95950493e', 'message': 'Correct the rtype in the function docstrings\n\nFix the non-existing rtype in the storage/pooling.py\nfunction docstrings.\n\nChange-Id: I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c\n'}]",2,100793,6bb1f9e7658af3a27c7a53efb6e09fa95950493e,26,7,3,10634,,,0,"Correct the rtype in the function docstrings

Fix the non-existing rtype in the storage/pooling.py
function docstrings.

Change-Id: I9a78ac07f50f05c085e13e2f2d301cc0e9ae856c
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/93/100793/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/queues/storage/sharding.py'],1,d3b8f09674d3636d3a07127637ba4f45412f78a9,bug/doc-sharding, :rtype: marconi.queues.storage.base.DataDriverBase, :rtype: marconi.queues.storage.base.DataDriver,1,1
openstack%2Fkeystone~master~I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a,openstack/keystone,master,I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a,Enforce required parameters for V3 Regions,ABANDONED,2014-02-26 05:30:57.000000000,2014-06-23 21:07:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7}, {'_account_id': 5046}, {'_account_id': 6771}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-02-26 05:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a693ce4589e27a7064f47967cd95ae9cb5ad665d', 'message': ""Enforce required attribs when creating V3 Regions\n\nThere is not check in keystone/catalog/controller.py to ensure Regions\nhave the required parameters for processing a create request. Currently,\nthe request will failout in the backend code when trying to create a\nregion without supplying the 'description'.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n""}, {'number': 2, 'created': '2014-02-26 05:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9fe1d6d6ca494dc077d8ab5543b3d58d7508e41d', 'message': 'Enforce required parameters for regions\n\nWhen creating regions without \'description\' specified in the request,\nit is possible to recieve an exception from the backend, such as a MySQL\nerror \'Column ""impersonation"" cannot be null\'. This check should be\nhandled in the controllers so that the behavior is consistent across all\nbackends.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n'}, {'number': 3, 'created': '2014-03-11 05:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5c597a3db035d50def639c6c640ec4dc5bf34704', 'message': 'Enforce required parameters for V3 Regions\n\nWhen creating regions without \'description\' specified in the request,\nit is possible to recieve an exception from the backend, such as a MySQL\nerror \'Column ""impersonation"" cannot be null\'. This check should be\nhandled in the controllers so that the behavior is consistent across all\nbackends.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n'}, {'number': 4, 'created': '2014-03-11 05:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6e9dce6a6198520a18ff4215825a78bc6e5f6fc7', 'message': 'Enforce required parameters for V3 Regions\n\nWhen creating regions without \'description\' specified in the request,\nit is possible to recieve an exception from the backend, such as a MySQL\nerror \'Column ""impersonation"" cannot be null\'. This check should be\nhandled in the controllers so that the behavior is consistent across all\nbackends.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n'}, {'number': 5, 'created': '2014-03-19 15:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/80b743ee0bf89eddb44a5dbafbbc1c1bfba71765', 'message': 'Enforce required parameters for V3 Regions\n\nWhen creating regions without \'description\' specified in the request,\nit is possible to receive an exception from the backend, such as a MySQL\nerror \'Column ""impersonation"" cannot be null\'. This check should be\nhandled in the controllers so that the behavior is consistent across all\nbackends.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n'}, {'number': 6, 'created': '2014-04-22 14:00:55.000000000', 'files': ['keystone/catalog/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/40e2f2818cc9abb293896fb7c620bbf7e055a23e', 'message': 'Enforce required parameters for V3 Regions\n\nWhen creating regions without \'description\' specified in the request,\nit is possible to receive an exception from the backend, such as a MySQL\nerror \'Column ""impersonation"" cannot be null\'. This check should be\nhandled in the controllers so that the behavior is consistent across all\nbackends.\n\nChange-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a\nCloses-bug: 1284972\n'}]",6,76444,40e2f2818cc9abb293896fb7c620bbf7e055a23e,47,6,6,5046,,,0,"Enforce required parameters for V3 Regions

When creating regions without 'description' specified in the request,
it is possible to receive an exception from the backend, such as a MySQL
error 'Column ""impersonation"" cannot be null'. This check should be
handled in the controllers so that the behavior is consistent across all
backends.

Change-Id: I38b4fe31afd2e4b3165bd0344e3954a0722c1c8a
Closes-bug: 1284972
",git fetch https://review.opendev.org/openstack/keystone refs/changes/44/76444/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/catalog/controllers.py'],1,a693ce4589e27a7064f47967cd95ae9cb5ad665d,bug/1284972," _mutable_parameters = frozenset(['parent_region_id', 'description']) _public_parameters = frozenset(['id', 'parent_region_id', 'description']) _required_parameters = frozenset(['description']) RegionV3.check_immutable_params(region) RegionV3.check_required_params(region)",,6,0
openstack%2Ffuel-docs~stable%2F4.1~I7b9a21450e14295363eb18dd97dc75648fb3d9ac,openstack/fuel-docs,stable/4.1,I7b9a21450e14295363eb18dd97dc75648fb3d9ac,Fix Google Tag Manager script,MERGED,2014-06-23 21:00:30.000000000,2014-06-23 21:04:36.000000000,2014-06-23 21:03:38.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-23 21:00:30.000000000', 'files': ['_templates/mirantis/layout.html'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/725d060f8965ce80cdc14c3f9dd9d2f733474c33', 'message': 'Fix Google Tag Manager script\n\nChange-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac\n(cherry picked from commit 43c5ed735d94b3a462c594efcea060d04b2475cb)\n'}]",0,102013,725d060f8965ce80cdc14c3f9dd9d2f733474c33,8,3,1,9977,,,0,"Fix Google Tag Manager script

Change-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac
(cherry picked from commit 43c5ed735d94b3a462c594efcea060d04b2475cb)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/13/102013/1 && git format-patch -1 --stdout FETCH_HEAD,['_templates/mirantis/layout.html'],1,725d060f8965ce80cdc14c3f9dd9d2f733474c33,,"<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],","<script>(function(w,d,s,l,i){wl=wl||[];wl.push( {'gtm.start': new Date().getTime(),event:'gtm.js'} );var f=d.getElementsByTagName(s)0,",2,3
openstack%2Ffuel-docs~stable%2F5.0~I7b9a21450e14295363eb18dd97dc75648fb3d9ac,openstack/fuel-docs,stable/5.0,I7b9a21450e14295363eb18dd97dc75648fb3d9ac,Fix Google Tag Manager script,MERGED,2014-06-23 21:00:11.000000000,2014-06-23 21:03:26.000000000,2014-06-23 21:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-23 21:00:11.000000000', 'files': ['_templates/mirantis/layout.html'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/12607de0b9d6f8a0cbbb8106e44e09baff390f69', 'message': 'Fix Google Tag Manager script\n\nChange-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac\n(cherry picked from commit 43c5ed735d94b3a462c594efcea060d04b2475cb)\n'}]",0,102012,12607de0b9d6f8a0cbbb8106e44e09baff390f69,8,3,1,9977,,,0,"Fix Google Tag Manager script

Change-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac
(cherry picked from commit 43c5ed735d94b3a462c594efcea060d04b2475cb)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/12/102012/1 && git format-patch -1 --stdout FETCH_HEAD,['_templates/mirantis/layout.html'],1,12607de0b9d6f8a0cbbb8106e44e09baff390f69,,"<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],","<script>(function(w,d,s,l,i){wl=wl||[];wl.push( {'gtm.start': new Date().getTime(),event:'gtm.js'} );var f=d.getElementsByTagName(s)0,",2,3
openstack%2Ffuel-docs~master~I7b9a21450e14295363eb18dd97dc75648fb3d9ac,openstack/fuel-docs,master,I7b9a21450e14295363eb18dd97dc75648fb3d9ac,Fix Google Tag Manager script,MERGED,2014-06-23 10:30:15.000000000,2014-06-23 21:00:30.000000000,2014-06-23 18:26:37.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10822}]","[{'number': 1, 'created': '2014-06-23 10:30:15.000000000', 'files': ['_templates/mirantis/layout.html'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/43c5ed735d94b3a462c594efcea060d04b2475cb', 'message': 'Fix Google Tag Manager script\n\nChange-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac\n'}]",0,101851,43c5ed735d94b3a462c594efcea060d04b2475cb,12,4,1,9977,,,0,"Fix Google Tag Manager script

Change-Id: I7b9a21450e14295363eb18dd97dc75648fb3d9ac
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/51/101851/1 && git format-patch -1 --stdout FETCH_HEAD,['_templates/mirantis/layout.html'],1,43c5ed735d94b3a462c594efcea060d04b2475cb,googletag,"<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],","<script>(function(w,d,s,l,i){wl=wl||[];wl.push( {'gtm.start': new Date().getTime(),event:'gtm.js'} );var f=d.getElementsByTagName(s)0,",2,3
openstack%2Fopenstack-manuals~master~If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00,openstack/openstack-manuals,master,If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00,Add note for boot with multiple NICs in cloud-admin guide,MERGED,2014-06-21 07:25:30.000000000,2014-06-23 20:54:12.000000000,2014-06-23 20:54:11.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 7718}, {'_account_id': 7923}, {'_account_id': 9051}]","[{'number': 1, 'created': '2014-06-21 07:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/30a37d19ed6f2828c3c4f1d62994bd871e2f139a', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 2, 'created': '2014-06-21 13:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1eab07372fde4e22071d80df7611146a475d947b', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 3, 'created': '2014-06-21 13:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fbcf761306c67dc388c2c82b770a32bf992f05fc', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 4, 'created': '2014-06-22 01:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0dca87dfb3d801b957ad1115dc4aa835947070de', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 5, 'created': '2014-06-23 02:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bbad0345ef9b7817f469f88771ce8cdb45929789', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 6, 'created': '2014-06-23 18:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/caaabc2293d7aae4ca6bfefe268802128b650459', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 7, 'created': '2014-06-23 19:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f21517b3749fc6acaa7647c825e5f7063a15068e', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}, {'number': 8, 'created': '2014-06-23 20:23:54.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking-use.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8526bc6b15fc6b80b49068464ae268ead711dddf', 'message': 'Add note for boot with multiple NICs in cloud-admin guide\n\nThis ensures that the cloud-admins get\nmore clarity when booting an instance\nwith multiple NICs\n\nChange-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00\nCloses-bug: #1332098\n'}]",4,101697,8526bc6b15fc6b80b49068464ae268ead711dddf,32,7,8,7718,,,0,"Add note for boot with multiple NICs in cloud-admin guide

This ensures that the cloud-admins get
more clarity when booting an instance
with multiple NICs

Change-Id: If5ff5bc106e24cd35cd6f435bbd6b26b12a1de00
Closes-bug: #1332098
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/101697/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/networking/section_networking-use.xml'],1,30a37d19ed6f2828c3c4f1d62994bd871e2f139a,bug/1332098," <note> <para>The default cloud-images have only one active nic configured,so when booting with multiple NICs make sure to configure the additional interfaces on the image otherwise they will not be reachable. Here is an example on how to setup the interfaces within the instance (this is the configuration that needs to be applied inside the image):</para> <para><filename>/etc/network/interfaces</filename></para> <programlisting language=""bash""># The loopback network interface auto lo iface lo inet loopback auto eth0 iface eth0 inet dhcp auto eth1 iface eth1 inet dhcp</programlisting> </note>",,20,0
openstack%2Foperations-guide~master~I877da195528ea4bf6ec7fe9d207cc7c1dc884c66,openstack/operations-guide,master,I877da195528ea4bf6ec7fe9d207cc7c1dc884c66,Publish to /openstack-ops,MERGED,2014-06-23 20:06:06.000000000,2014-06-23 20:50:14.000000000,2014-06-23 20:50:14.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-23 20:06:06.000000000', 'files': ['doc/openstack-ops/pom.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/5de35c21f1ca6260cd47bb1f6c28138df5f96dad', 'message': 'Publish to /openstack-ops\n\nDo not publish OPS guide to /trunk/openstack-ops but directly to\n/openstack-ops.\n\nChange-Id: I877da195528ea4bf6ec7fe9d207cc7c1dc884c66\n'}]",0,101993,5de35c21f1ca6260cd47bb1f6c28138df5f96dad,11,4,1,6547,,,0,"Publish to /openstack-ops

Do not publish OPS guide to /trunk/openstack-ops but directly to
/openstack-ops.

Change-Id: I877da195528ea4bf6ec7fe9d207cc7c1dc884c66
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/93/101993/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/pom.xml'],1,5de35c21f1ca6260cd47bb1f6c28138df5f96dad,no-trunk, <webhelpDirname>openstack-ops</webhelpDirname> <pdfFilenameBase>openstack-ops-manual</pdfFilenameBase> <canonicalUrlBase>http://docs.openstack.org/openstack-ops/content/</canonicalUrlBase>, <!-- <pdfUrl>../openstack-ops-manual-${operating.system}-${release.path.name}.pdf</pdfUrl> --> <webhelpDirname>${release.path.name}/openstack-ops</webhelpDirname> <pdfFilenameBase>openstack-ops-manual-${release.path.name}</pdfFilenameBase> <canonicalUrlBase>http://docs.openstack.org/${release.path.name}/openstack-ops/content/</canonicalUrlBase>,3,4
openstack%2Fnova~master~Idfa1f4015acb10dc14fcec448257bcfe6971fc99,openstack/nova,master,Idfa1f4015acb10dc14fcec448257bcfe6971fc99,Fix resource cleanup in NetworkManager.allocate_fixed_ip,MERGED,2014-06-10 14:09:52.000000000,2014-06-23 20:30:20.000000000,2014-06-23 14:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-06-10 14:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66a400c8dc89a2e70902471fcf68bd78a933bf89', 'message': ""Fix resource cleanup in NetworkManager.allocate_fixed_ip\n\nNetworkManager.allocate_fixed_ip isn't cleaning up the resources it allocates in\nthe event of a failure. This means that if, for example, _setup_network_on_host\nfails, the instance will still have a fixed IP allocated to it. Every attempt to\nspawn the instance will result in another fixed ip being allocated.\n\nResolves bug 1328539\n\nChange-Id: Idfa1f4015acb10dc14fcec448257bcfe6971fc99\n""}, {'number': 2, 'created': '2014-06-11 08:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4b345fc1ff61fadd6ed9fac21dc82a314767e9e', 'message': ""Fix resource cleanup in NetworkManager.allocate_fixed_ip\n\nNetworkManager.allocate_fixed_ip isn't cleaning up the resources it\nallocates in the event of a failure. This means that if, for example,\n_setup_network_on_host fails, the instance will still have a fixed IP\nallocated to it. Every attempt to spawn the instance will result in\nanother fixed ip being allocated.\n\nResolves bug 1328539\n\nChange-Id: Idfa1f4015acb10dc14fcec448257bcfe6971fc99\n""}, {'number': 3, 'created': '2014-06-12 08:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5208970e988e02d661b43241bcb779246896027', 'message': ""Fix resource cleanup in NetworkManager.allocate_fixed_ip\n\nNetworkManager.allocate_fixed_ip isn't cleaning up the resources it\nallocates in the event of a failure. This means that if, for example,\n_setup_network_on_host fails, the instance will still have a fixed IP\nallocated to it. Every attempt to spawn the instance will result in\nanother fixed ip being allocated.\n\nCloses-Bug: #1328539\n\nChange-Id: Idfa1f4015acb10dc14fcec448257bcfe6971fc99\n""}, {'number': 4, 'created': '2014-06-20 14:59:23.000000000', 'files': ['nova/network/manager.py', 'nova/tests/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/077e3c770ebeebd037ce882863a6b5dcefd644cf', 'message': ""Fix resource cleanup in NetworkManager.allocate_fixed_ip\n\nNetworkManager.allocate_fixed_ip isn't cleaning up the resources it\nallocates in the event of a failure. This means that if, for example,\n_setup_network_on_host fails, the instance will still have a fixed IP\nallocated to it. Every attempt to spawn the instance will result in\nanother fixed ip being allocated.\n\nCloses-Bug: #1328539\n\nChange-Id: Idfa1f4015acb10dc14fcec448257bcfe6971fc99\n""}]",6,99065,077e3c770ebeebd037ce882863a6b5dcefd644cf,60,13,4,9555,,,0,"Fix resource cleanup in NetworkManager.allocate_fixed_ip

NetworkManager.allocate_fixed_ip isn't cleaning up the resources it
allocates in the event of a failure. This means that if, for example,
_setup_network_on_host fails, the instance will still have a fixed IP
allocated to it. Every attempt to spawn the instance will result in
another fixed ip being allocated.

Closes-Bug: #1328539

Change-Id: Idfa1f4015acb10dc14fcec448257bcfe6971fc99
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/99065/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/network/test_manager.py']",2,66a400c8dc89a2e70902471fcf68bd78a933bf89,bug/1328539,"import contextlibfrom nova.objects import virtual_interface as vif_obj @mock.patch('nova.objects.instance.Instance.get_by_uuid') @mock.patch('nova.objects.virtual_interface.VirtualInterface.get_by_instance_and_network') @mock.patch('nova.objects.fixed_ip.FixedIP.disassociate') @mock.patch('nova.objects.fixed_ip.FixedIP.associate') @mock.patch('nova.objects.fixed_ip.FixedIP.save') def test_allocate_fixed_ip_cleanup(self, mock_fixedip_save, mock_fixedip_associate, mock_fixedip_disassociate, mock_vif_get, mock_instance_get): address=netaddr.IPAddress('1.2.3.4') fip = fixed_ip_obj.FixedIP(instance_uuid='fake-uuid', address=address, virtual_interface_id=1) mock_fixedip_associate.return_value = fip instance = instance_obj.Instance(context=self.context) instance.create() mock_instance_get.return_value = instance mock_vif_get.return_value = vif_obj.VirtualInterface( instance_uuid='fake-uuid', id=1) with contextlib.nested( mock.patch.object(self.network, '_setup_network_on_host'), mock.patch.object(self.network, 'instance_dns_manager'), mock.patch.object(self.network, '_do_trigger_security_group_members_refresh_for_instance'), ) as (mock_setup_network, mock_dns_manager, _): mock_setup_network.side_effect = test.TestingException self.assertRaises(test.TestingException, self.network.allocate_fixed_ip, self.context, instance.uuid, {'cidr': '24', 'id': 1}, address=address) mock_dns_manager.delete_entry.assert_has_calls([ mock.call(instance.display_name, ''), mock.call(instance.uuid, '') ]) mock_fixedip_disassociate.assert_called_once()",,74,1
openstack%2Fpuppet-neutron~master~Iba6c2978a4e08f7a9b9b204e8a9ca15210459489,openstack/puppet-neutron,master,Iba6c2978a4e08f7a9b9b204e8a9ca15210459489,Update declaration of integration bridge,ABANDONED,2014-06-23 02:55:30.000000000,2014-06-23 20:26:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-23 02:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/dfdea675a3258b1e8bb74152ca1bf12cabf3de59', 'message': ""Update declaration of integration bridge\n\nThis allows the integration bridge to be declared with dependencies\ncorrectly mapped even if the ovs agent package is not installed (e.g. on\na node that's just neutron-server and not OVS agent).\n\nChange-Id: Iba6c2978a4e08f7a9b9b204e8a9ca15210459489\n""}, {'number': 2, 'created': '2014-06-23 03:18:12.000000000', 'files': ['manifests/agents/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1c706eb422ace0beb84eec658d6dfa8379b74f6f', 'message': ""Update declaration of integration bridge\n\nThis allows the integration bridge to be declared with dependencies\ncorrectly mapped even if the ovs agent package is not installed (e.g. on\na node that's just neutron-server and not OVS agent).\n\nChange-Id: Iba6c2978a4e08f7a9b9b204e8a9ca15210459489\n""}]",0,101790,1c706eb422ace0beb84eec658d6dfa8379b74f6f,7,1,2,10086,,,0,"Update declaration of integration bridge

This allows the integration bridge to be declared with dependencies
correctly mapped even if the ovs agent package is not installed (e.g. on
a node that's just neutron-server and not OVS agent).

Change-Id: Iba6c2978a4e08f7a9b9b204e8a9ca15210459489
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/90/101790/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/agents/ovs.pp'],1,dfdea675a3258b1e8bb74152ca1bf12cabf3de59,bug/1298146-update, neutron::plugins::ovs::bridge { $integration_bridge: }," vs_bridge { $integration_bridge: ensure => present, before => Service['neutron-plugin-ovs-service'], }",1,4
openstack%2Fhorizon~master~I64eb83794082a9a5f8ef20a69d7ba9da548cdd4f,openstack/horizon,master,I64eb83794082a9a5f8ef20a69d7ba9da548cdd4f,Add SESSION_COOKIE_HTTPONLY to the example config,ABANDONED,2014-06-19 17:22:18.000000000,2014-06-23 20:17:59.000000000,,"[{'_account_id': 3}, {'_account_id': 9500}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-06-19 17:22:18.000000000', 'files': ['openstack_dashboard/local/local_settings.py.example'], 'web_link': 'https://opendev.org/openstack/horizon/commit/12ac592f7f119cae60f90eea1fd50e006df48124', 'message': 'Add SESSION_COOKIE_HTTPONLY to the example config\n\nChange-Id: I64eb83794082a9a5f8ef20a69d7ba9da548cdd4f\n'}]",0,101259,12ac592f7f119cae60f90eea1fd50e006df48124,7,3,1,9500,,,0,"Add SESSION_COOKIE_HTTPONLY to the example config

Change-Id: I64eb83794082a9a5f8ef20a69d7ba9da548cdd4f
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/101259/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/local/local_settings.py.example'],1,12ac592f7f119cae60f90eea1fd50e006df48124,add_session_cookie_httponly,#SESSION_COOKIE_HTTPONLY = True,,1,0
openstack%2Fkeystone-specs~master~I5d23b3397ee56b2054e28d233baa7218437134e7,openstack/keystone-specs,master,I5d23b3397ee56b2054e28d233baa7218437134e7,Always use a hash based Public ID for cross backend identifiers,MERGED,2014-06-17 11:13:25.000000000,2014-06-23 20:07:53.000000000,2014-06-23 20:07:52.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9094}, {'_account_id': 9098}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-06-17 11:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/27ca18618d534e135b2edc00a3dcc9ca967fa852', 'message': 'Always use sha1 for cross backend unique identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use the sha1 hash Public ID generator\nalgorithm\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\nBlueprint: multi-backend-uuids\n'}, {'number': 2, 'created': '2014-06-17 11:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/66ee45a42486391085fba30c6b2e5b2ff4299a69', 'message': 'Always use sha1 for cross backend unique identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use the sha1 hash Public ID generator\nalgorithm\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 3, 'created': '2014-06-17 11:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/3e5e16a7ecffd76d0f8cec2adbfa8e5fe46c54ca', 'message': 'Always use sha1 for cross backend unique identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use the sha1 hash Public ID generator\nalgorithm.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 4, 'created': '2014-06-19 20:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8aa26f4377762ff5294cdabbcad9fa54dbacd89d', 'message': 'Always use a hash based Public ID for cross backend identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use a hash Public ID generator\nalgorithm.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 5, 'created': '2014-06-19 22:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/5dfda0be2068e4ee67c5b4e9e901c01420a28ef8', 'message': 'Always use a hash based Public ID for cross backend identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use a hash Public ID generator\nalgorithm.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 6, 'created': '2014-06-20 13:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4ae4d3d5ad5ad12ab8a18d4be3fcef65d85f70f6', 'message': 'Always use a hash based Public ID for cross backend identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use a hash Public ID generator\nalgorithm.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 7, 'created': '2014-06-22 04:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/ca5e55e8590e9a760d05597adef141ca332a985e', 'message': 'Always use a hash based Public ID for cross backend identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use a hash Public ID generator\nalgorithm.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}, {'number': 8, 'created': '2014-06-22 04:15:02.000000000', 'files': ['specs/juno/multi-backend-uuids.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d29d014dab35b651e2c9b36423423ffa2b3d4362', 'message': 'Always use a hash based Public ID for cross backend identifiers\n\nThis change updates the specification for cross backend unique\nidentifiers to always use a hash Public ID generator\nalgorithm.\n\nMinor typo fixes included in this patchset.\n\nChange-Id: I5d23b3397ee56b2054e28d233baa7218437134e7\n'}]",8,100497,d29d014dab35b651e2c9b36423423ffa2b3d4362,54,12,8,5707,,,0,"Always use a hash based Public ID for cross backend identifiers

This change updates the specification for cross backend unique
identifiers to always use a hash Public ID generator
algorithm.

Minor typo fixes included in this patchset.

Change-Id: I5d23b3397ee56b2054e28d233baa7218437134e7
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/97/100497/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/multi-backend-uuids.rst'],1,27ca18618d534e135b2edc00a3dcc9ca967fa852,multi-backend-uuids," While the obvious choice is simply another regular uuid4 hex string, it is proposed that using a hash algorithm that means that Public IDs are regeneratable from the underlying local identifier components, has a number of advantages: Keystone. It should be noted, however, that if the assignments table was also lost, then such a facility could only be part of recovery. There are also several complexities that are created by creating an identity mapping layer: - In the codebase today the controllers generate the UUID ID for an entity they are creating, and pass this to the manager/driver layer. All our unit the ID. Now that the manager layer is dynamically building a Public ID mapping table, it seems inappropriate that the controller layer thinks it is in control of ID generation. The proposal is, therefore, to remove the ID generation from the User and Group controllers, and let the identity manager carry out this role. Note that this only affects the controller-manager interface, not the driver interface itself. This change, while only affecting a few lines of production code, will result in a large set of mechanical changes to our unit tests. - If the underlying driver supports UUIDs (for example the current SQL backend), then there seems little advantage in to taking a hash of the UUID. The proposal therefore is to use the local UUID as the Public ID for such drivers, and load a null mapping into the mapping table.An earlier version of this proposal also suggested providing an option of the algorithm for Public ID generation, e.g. choosing between a regular UUID and a hash. This was dropped as there was little advantage to the use of regular UUIDs "," The default generator is proposed as simply a regular uuid4 hex string, similar to how entities are normally identified. It has also been suggested that an option should be provided for such a Public ID to be regeneratable from the underlying local identifier components, using a hash algorithm. Use of a regeneratable ID will support the following use cases: Keystone. This will be supported, although its usefulness needs to be tempered with the fact that if the assignments table was also lost, then such a facility could only be part of recovery. There are also several complexities that are created by supporting multiple generators: - In the codebase today the controllers generate the ID for an entity they are creating, and pass this to the manager/driver layer. All our unit the ID. It would seem inappropriate to expose the controller layer to whatever generator algorithm was in use. While irrelevant for the usual RO LDAP or federation case (since Keystone never gets to create entities), for RW LDAP situations where the entities might be created by Keystone or out-of-band via LDAP, one would want the use-cases listed above for hashing to be valid for all entities, not just those that were not created by Keystone. The proposal is, therefore, to remove the ID generation from the User and Group controllers, and let the identity manager carry out this role. Note that this only affects the controller-manager interface, not the driver interface itself. - If the underlying driver supports uuids (for example the current SQL backend), does it make sense to hash the uuid just because the algorithm has been specified as hashing? Today, this might seem overkill, although perhaps in the future we might not wish to treat the identifiers of a separate Keystone IDP as a valid Public ID? The proposal is to ignore the hashing algorithm if the underlying driver is uuid based (i.e. SQL). - One potential advantage of hashing is that it can be quicker to determine if you have a mapping stored already - i.e. you create the Public ID by hashing and do a PK lookup, as opposed to search the table for an entry that matches the three pieces of local identity information. However, such a PK look up would only work if the generation algorithm setting is immutable (i.e. there ""aren't"" old entries in the mapping table that use the standard uuid generator). Although this could be mitigated by catching the attempt to create a second mapping to a different Public ID, for now it is recommended that this option for PK lookup is left as a future performance improvement.",27,39
openstack%2Ftripleo-ci~master~Ie94bf4b1946f04a98359161cfce65fbadcc1ee8a,openstack/tripleo-ci,master,Ie94bf4b1946f04a98359161cfce65fbadcc1ee8a,Add sbin to PATH when loging hostinfo,MERGED,2014-06-12 12:27:45.000000000,2014-06-23 19:55:17.000000000,2014-06-23 19:55:17.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8532}, {'_account_id': 9268}]","[{'number': 1, 'created': '2014-06-12 12:27:45.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/efc1eea02af83ef76a6d9169f709501fa13c97db', 'message': ""Add sbin to PATH when loging hostinfo\n\nsbin isn't on the PATH on Fedora non tty sessions, this leads to\nbash: line 7: ip: command not found\n\nChange-Id: Ie94bf4b1946f04a98359161cfce65fbadcc1ee8a\n""}]",0,99642,efc1eea02af83ef76a6d9169f709501fa13c97db,16,6,1,1926,,,0,"Add sbin to PATH when loging hostinfo

sbin isn't on the PATH on Fedora non tty sessions, this leads to
bash: line 7: ip: command not found

Change-Id: Ie94bf4b1946f04a98359161cfce65fbadcc1ee8a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/42/99642/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,efc1eea02af83ef76a6d9169f709501fa13c97db,fix/long-lines, export PATH=$PATH:/sbin,,1,0
openstack%2Fpython-barbicanclient~master~I8ef178b0338fe430a64c30bfe193406aabf3caf1,openstack/python-barbicanclient,master,I8ef178b0338fe430a64c30bfe193406aabf3caf1,Add Keystone V3 compliant session/auth plugin support,MERGED,2014-03-13 00:16:20.000000000,2014-06-23 19:52:05.000000000,2014-06-11 05:36:42.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 994}, {'_account_id': 1091}, {'_account_id': 1501}, {'_account_id': 1916}, {'_account_id': 7191}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-03-13 00:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/aec1538d86b6731cd9584dfba47572a0ce6d2526', 'message': 'Added Keystone V3 auth plug-in to support Keystone V3 authentication. Added\nthe relevant options to enable Keystone V3 auth for CLI.\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 2, 'created': '2014-03-17 23:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/f33244d17b64da8f07cc248c2ba0b7b5329df1ce', 'message': 'Added Keystone V3 auth plug-in to support Keystone V3 authentication. Added\nthe relevant options to enable Keystone V3 auth for CLI.\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 3, 'created': '2014-04-30 22:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/4ae39f586d9e2cfde5440b8aff8c42654ad0f8e6', 'message': 'Added Keystone V3 auth plug-in to support Keystone V3 authentication. Added\nthe relevant options to enable Keystone V3 auth for CLI.\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 4, 'created': '2014-05-11 02:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/29613b5f74d271531aa0f146d0e120cf45d27e96', 'message': 'Added Keystone V3 auth plug-in to support Keystone V3 authentication. Added\nthe relevant options to enable Keystone V3 auth for CLI.\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 5, 'created': '2014-05-23 14:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/5ebca94f1be6c9a678401e8724ce703b81be792b', 'message': 'Added Keystone V3 auth plug-in to support Keystone V3 authentication. Added\nthe relevant options to enable Keystone V3 auth for CLI.\n\nAdded support for Kestone V3 specific command line arguments\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 6, 'created': '2014-05-28 22:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/ec1897bded7763479811c10b25c66a7e188c6798', 'message': 'Add Keystone V3 compliant session/auth plugin support\n\nBarbican client uses Keystone V2 client via a Barbican auth\nplugin. It also uses a regular requests.Session(). This commit\nadds support for keystone session and replaces the heavy\nkeystone client with a lighter V2/V3 Password auth plugin. This\nchange is backwards compatible; it supports existing callers\nand keystone session/plugin support.\nOn the testing front, this commit also introduces httpretty along\nwith a keystoneclient fixture. The keystoneclient fixture could\neventually be called directly from keystoneclient module instead\nof copying it over here. Testing the keystone session/plugin\nsupport is done mainly using httpretty\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 7, 'created': '2014-06-03 00:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/3ee7be53f3d05f64a3379a3ae41bf8daa7f5a786', 'message': 'Add Keystone V3 compliant session/auth plugin support\n\nBarbican client uses Keystone V2 client via a Barbican auth\nplugin. It also uses a regular requests.Session(). This commit\nadds support for keystone session and replaces the heavy\nkeystone client with a lighter V2/V3 Password auth plugin. This\nchange is backwards compatible; it supports existing callers\nand keystone session/plugin support.\nOn the testing front, this commit also introduces httpretty along\nwith a keystoneclient fixture. The keystoneclient fixture could\neventually be called directly from keystoneclient module instead\nof copying it over here. Testing the keystone session/plugin\nsupport is done mainly using httpretty\n\nRefactored Client.__init__ for better readability\n\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 8, 'created': '2014-06-09 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/1818f343c091d483a8b9bbaaadb3b8a3da1e4229', 'message': 'Add Keystone V3 compliant session/auth plugin support\n\nBarbican client uses Keystone V2 client via a Barbican auth\nplugin. It also uses a regular requests.Session(). This commit\nadds support for keystone session and replaces the heavy\nkeystone client with a lighter V2/V3 Password auth plugin. This\nchange is backwards compatible; it supports existing callers\nand keystone session/plugin support.\nOn the testing front, this commit also introduces httpretty along\nwith a keystoneclient fixture. The keystoneclient fixture could\neventually be called directly from keystoneclient module instead\nof copying it over here. Testing the keystone session/plugin\nsupport is done mainly using httpretty\n\nPatches:\n 7: Refactored Client.__init__ for better readability\n 8: Fixing pep8/py33 errors w.r.t new tox.ini changes\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}, {'number': 9, 'created': '2014-06-09 19:11:07.000000000', 'files': ['requirements.txt', 'barbicanclient/client.py', 'test-requirements.txt', 'barbicanclient/test/keystone_client_fixtures.py', 'barbicanclient/test/test_barbican.py', 'barbicanclient/common/auth.py', 'barbicanclient/test/common/test_auth.py', 'barbicanclient/barbican.py', 'barbicanclient/openstack/common/timeutils.py', 'barbicanclient/test/test_client.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/01d23227b0fa2b17038dfb3710e700b553778e15', 'message': 'Add Keystone V3 compliant session/auth plugin support\n\nBarbican client uses Keystone V2 client via a Barbican auth\nplugin. It also uses a regular requests.Session(). This commit\nadds support for keystone session and replaces the heavy\nkeystone client with a lighter V2/V3 Password auth plugin. This\nchange is backwards compatible; it supports existing callers\nand keystone session/plugin support.\nOn the testing front, this commit also introduces httpretty along\nwith a keystoneclient fixture. The keystoneclient fixture could\neventually be called directly from keystoneclient module instead\nof copying it over here. Testing the keystone session/plugin\nsupport is done mainly using httpretty\n\nPatches:\n 7: Refactored Client.__init__ for better readability\n 8: Fixing pep8/py33 errors w.r.t new tox.ini changes\nDocImpact\n\nbp/barbican-client-has-to-be-keystone-v3.0-complaint\n\nChange-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1\n'}]",40,80124,01d23227b0fa2b17038dfb3710e700b553778e15,69,13,9,1916,,,0,"Add Keystone V3 compliant session/auth plugin support

Barbican client uses Keystone V2 client via a Barbican auth
plugin. It also uses a regular requests.Session(). This commit
adds support for keystone session and replaces the heavy
keystone client with a lighter V2/V3 Password auth plugin. This
change is backwards compatible; it supports existing callers
and keystone session/plugin support.
On the testing front, this commit also introduces httpretty along
with a keystoneclient fixture. The keystoneclient fixture could
eventually be called directly from keystoneclient module instead
of copying it over here. Testing the keystone session/plugin
support is done mainly using httpretty

Patches:
 7: Refactored Client.__init__ for better readability
 8: Fixing pep8/py33 errors w.r.t new tox.ini changes
DocImpact

bp/barbican-client-has-to-be-keystone-v3.0-complaint

Change-Id: I8ef178b0338fe430a64c30bfe193406aabf3caf1
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/24/80124/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/common/auth.py', 'barbicanclient/barbican.py']",2,aec1538d86b6731cd9584dfba47572a0ce6d2526,keystone_v3," parser.add_argument('--os-user-id', metavar='<auth-user-id>', default=client.env('OS_USER_ID'), help='Defaults to env[OS_USER_ID].') parser.add_argument('--os-user-domain-id', metavar='<auth-user-domain-id>', default=client.env('OS_USER_DOMAIN_ID'), help='Defaults to env[OS_USER_DOMAIN_ID].') parser.add_argument('--os-user-domain-name', metavar='<auth-user-domain-name>', default=client.env('OS_USER_DOMAIN_NAME'), help='Defaults to env[OS_USER_DOMAIN_NAME].') parser.add_argument('--os-project-id', metavar='<auth-project-id>', default=client.env('OS_PROJECT__ID'), help='Another way to specify tenant ID. ' 'This option is mutually exclusive with ' ' --os-tenant-id. ' 'Defaults to env[OS_PROJECT_ID].') parser.add_argument('--os-project-name', metavar='<auth-project-name>', default=client.env('OS_PROJECT_NAME'), help='Another way to specify tenant name. ' 'This option is mutually exclusive with ' ' --os-tenant-name. ' 'Defaults to env[OS_PROJECT_NAME].') parser.add_argument('--os-project-domain-id', metavar='<auth-project-domain-id>', default=client.env('OS_PROJECT_DOMAIN_ID'), help='Defaults to env[OS_PROJECT_DOMAIN_ID].') parser.add_argument('--os-project-domain-name', metavar='<auth-project-domain-name>', default=client.env('OS_PROJECT_DOMAIN_NAME'), help='Defaults to env[OS_PROJECT_DOMAIN_NAME].') parser.add_argument('--os-cert', metavar='<certificate>', default=client.env('OS_CERT'), help='Defaults to env[OS_CERT].') parser.add_argument('--os-key', metavar='<key>', default=client.env('OS_KEY'), help='Defaults to env[OS_KEY].') parser.add_argument('--os-cacert', metavar='<ca-certificate>', default=client.env('OS_CACERT', default=None), help='Specify a CA bundle file to use in ' 'verifying a TLS (https) server certificate. ' 'Defaults to env[OS_CACERT].') self._keystone = auth.KeystoneAuth( user_id=args.os_user_id, user_domain_id=args.os_user_domain_id, user_domain_name=args.os_user_domain_name, tenant_id=args.os_tenant_id, project_name=args.os_project_name, project_id=args.os_project_id, project_domain_name=args.os_project_domain_name, project_domain_id=args.os_project_domain_id, insecure=args.insecure, cacert=args.os_cacert, cert=args.os_cert, key=args.os_key", self._keystone = auth.KeystoneAuthV2( insecure=args.insecure,164,14
openstack%2Fdevstack~stable%2Fhavana~Ifbd336b83f6b2beb23996b599ec820232c13efdd,openstack/devstack,stable/havana,Ifbd336b83f6b2beb23996b599ec820232c13efdd,Add support for django_openstack_auth,MERGED,2014-06-23 11:29:54.000000000,2014-06-23 19:51:25.000000000,2014-06-23 19:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6610}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 11:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/577dabdc5749cf7874457e973de9d00846abd93b', 'message': 'Add support for django_openstack_auth\n\nIt would be useful for development, reviewing and testing to add\nsupport for django_openstack_auth to devstack.\n\nThis change adds the integration tests to the openstack_auth\nlist of test: https://review.openstack.org/#/c/86528/\n\nChange-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd\nCloses-Bug: #1262121\n(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)\n'}, {'number': 2, 'created': '2014-06-23 12:20:15.000000000', 'files': ['AUTHORS', 'stackrc', 'lib/horizon', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a88be173e7feed076054b59079e7b93e4df0445c', 'message': 'Add support for django_openstack_auth\n\nIt would be useful for development, reviewing and testing to add\nsupport for django_openstack_auth to devstack.\n\nThis change adds the integration tests to the openstack_auth\nlist of test: https://review.openstack.org/#/c/86528/\n\n(Use setup_install instead)\n\nChange-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd\nCloses-Bug: #1262121\n(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)\n'}]",0,101863,a88be173e7feed076054b59079e7b93e4df0445c,16,5,2,2750,,,0,"Add support for django_openstack_auth

It would be useful for development, reviewing and testing to add
support for django_openstack_auth to devstack.

This change adds the integration tests to the openstack_auth
list of test: https://review.openstack.org/#/c/86528/

(Use setup_install instead)

Change-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd
Closes-Bug: #1262121
(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/63/101863/2 && git format-patch -1 --stdout FETCH_HEAD,"['AUTHORS', 'stackrc', 'lib/horizon', 'stack.sh']",4,577dabdc5749cf7874457e973de9d00846abd93b,, # django openstack_auth install_django_openstack_auth,,14,0
openstack%2Fkeystone-specs~master~I77d3fdaeb934e9c74551780f4ae83755cc91390d,openstack/keystone-specs,master,I77d3fdaeb934e9c74551780f4ae83755cc91390d,Spec to define cross-keystone federation,ABANDONED,2014-06-23 19:49:58.000000000,2014-06-23 19:50:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-23 19:49:58.000000000', 'files': ['specs/juno/keystone-to-keystone-federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/52514bd1e5fdc855d61bde8dc249f3285615c5a2', 'message': 'Spec to define cross-keystone federation\n\nChange-Id: I77d3fdaeb934e9c74551780f4ae83755cc91390d\n'}]",0,101987,52514bd1e5fdc855d61bde8dc249f3285615c5a2,4,1,1,1228,,,0,"Spec to define cross-keystone federation

Change-Id: I77d3fdaeb934e9c74551780f4ae83755cc91390d
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/87/101987/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/keystone-to-keystone-federation.rst'],1,52514bd1e5fdc855d61bde8dc249f3285615c5a2,master,"CERN has one OpenStack cloud set-up within their dataproviders (""CSP""), should their cloud not have enough bandwidthACME has one OpenStack cloud set-up within their data**Use case 3: Multiple in-house openstack implementations:** ACME has severall OpenStack clouds setup, and each one maintains its own set of assignments. They would like to enable identity federation across their multiple clouds so that an identity accessing each cloud doesn't need to maintain several tokens and credentials. potential burst relationship between two clouds, ""ACME"" would trust ""BETA"" as a service provider, and ""BETA"" would trust ""ACME"" as an identity provider. That will allow ""ACME"" to burst into ""BETA"" cloud but not the other way around.real-life example, ACME might want to buy some resources from a CSP, BETA, whereas ACME doesn't want BETA to use their resources. Of course, the2. ACME's keystone mentioned in the above use cases above should have knowledge of what services and endpoints BETA offers so that it could build adequate token scope across both OpenStack clouds. This can be done in a variety of ways. One idea is to allow ACME to poll BETA for a list of provided services and endpoints. provider. (If we are using PKI tokens, the SignerInfo field in CMS should tell us where it is coming from. http://tools.ietf.org/html/rfc5652#section-5.3so that the revocation is all encompassing. We can do this by leveraging the existing revocation events.Another alternative would be to allow a different token per cloud-setup, however that token would be obtained through identity provider federation to enable the same set of credentials across both. The client must be smart about where the tokens work, and must be able to handle multiple tokens. In the case of service provider federation, local refers to the local Keystone and remote refers to the service provider the identity is federating to. The mapping is used to ensure the proper federation assertion that is expected by the service provider. In some cases, the service provider may not be another keystone. ","CERN has one OpenStack cloud set-up (""internal cloud"") within their dataproviders (""CSP""), should their internal cloud not have enough bandwidthACME has one OpenStack cloud set-up (""internal cloud"") within their datatwo way trust between ""ACME"" and ""BETA"", ""ACME"" would need to set-up ""BETA"" as a trusted service provider and a trusted identity provider. ""BETA"" would have to set-up ""ACME"" as a trusted service provider and a trusted identity provider as well.real-life example, CERN might want to buy some resources from Rackspace, whereas CERN doesn't want Rackspace to use their resources. Of course, the2. The ""internal cloud"" Keystone mentioned in the two use cases above should have knowledge of what services and endpoints the trusted service providers offer so that it could build adequate token scope across multiple OpenStack clouds. This can be done in a variety of ways. One idea is to have a feed provided by Keystone that indicates what services and endpoints are accessible to authenticated identities. provider.so that the revocation is all encompassing.",37,17
openstack%2Fsolum-specs~master~I105de3b8eec98102a07aaebb8b7e1e4e87b0129d,openstack/solum-specs,master,I105de3b8eec98102a07aaebb8b7e1e4e87b0129d,Setup of the spec repo with default template info,ABANDONED,2014-06-18 20:42:18.000000000,2014-06-23 19:35:20.000000000,,"[{'_account_id': 4715}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-06-18 20:42:18.000000000', 'files': ['.gitignore', 'tests/test_titles.py', '.gitreview', 'specs/template.rst', 'setup.py', 'doc/source/conf.py', 'README.md', 'doc/source/index.rst', 'requirements.txt', '.testr.conf', 'setup.cfg', 'tox.ini', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/6bf472d0961ffdc42b8f7dd61f06184647a82dc5', 'message': 'Setup of the spec repo with default template info\n\nChange-Id: I105de3b8eec98102a07aaebb8b7e1e4e87b0129d\n'}]",0,101015,6bf472d0961ffdc42b8f7dd61f06184647a82dc5,4,2,1,668,,,0,"Setup of the spec repo with default template info

Change-Id: I105de3b8eec98102a07aaebb8b7e1e4e87b0129d
",git fetch https://review.opendev.org/openstack/solum-specs refs/changes/15/101015/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'tests/test_titles.py', '.gitreview', 'specs/template.rst', 'setup.py', 'doc/source/conf.py', 'README.md', 'doc/source/index.rst', 'requirements.txt', '.testr.conf', 'setup.cfg', 'tox.ini', 'tests/__init__.py']",13,6bf472d0961ffdc42b8f7dd61f06184647a82dc5,master,,,827,3
openstack%2Fnova~master~I8398bceb8771d9c180bcd6cbafbf1f3e839f9307,openstack/nova,master,I8398bceb8771d9c180bcd6cbafbf1f3e839f9307,VMware: remove unused code in vm_util.py,MERGED,2014-06-20 01:00:37.000000000,2014-06-23 19:28:19.000000000,2014-06-23 18:39:53.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 01:00:37.000000000', 'files': ['nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6dd8398827fa627881f303ec63e9145a498c05af', 'message': 'VMware: remove unused code in vm_util.py\n\nRemove a few functions not used anymore and not tested. This increases\nthe code coverage and decreases the time devs scrolls through the file.\n\nChange-Id: I8398bceb8771d9c180bcd6cbafbf1f3e839f9307\n'}]",3,101382,6dd8398827fa627881f303ec63e9145a498c05af,31,11,1,8759,,,0,"VMware: remove unused code in vm_util.py

Remove a few functions not used anymore and not tested. This increases
the code coverage and decreases the time devs scrolls through the file.

Change-Id: I8398bceb8771d9c180bcd6cbafbf1f3e839f9307
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/101382/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/vm_util.py'],1,6dd8398827fa627881f303ec63e9145a498c05af,remove_unused_func,,"def get_rdm_create_spec(client_factory, device, adapter_type=""lsiLogic"", disk_type=""rdmp""): """"""Builds the RDM virtual disk create spec."""""" create_vmdk_spec = client_factory.create('ns0:DeviceBackedVirtualDiskSpec') create_vmdk_spec.adapterType = get_vmdk_adapter_type(adapter_type) create_vmdk_spec.diskType = disk_type create_vmdk_spec.device = device return create_vmdk_spec def get_dummy_vm_create_spec(client_factory, name, data_store_name): """"""Builds the dummy VM create spec."""""" config_spec = client_factory.create('ns0:VirtualMachineConfigSpec') config_spec.name = name config_spec.guestId = ""otherGuest"" vm_file_info = client_factory.create('ns0:VirtualMachineFileInfo') vm_file_info.vmPathName = ""["" + data_store_name + ""]"" config_spec.files = vm_file_info tools_info = client_factory.create('ns0:ToolsConfigInfo') tools_info.afterPowerOn = True tools_info.afterResume = True tools_info.beforeGuestStandby = True tools_info.beforeGuestShutdown = True tools_info.beforeGuestReboot = True config_spec.tools = tools_info config_spec.numCPUs = 1 config_spec.memoryMB = 4 controller_key = -101 controller_spec = create_controller_spec(client_factory, controller_key) disk_spec = create_virtual_disk_spec(client_factory, 1024, controller_key) device_config_spec = [controller_spec, disk_spec] config_spec.deviceChange = device_config_spec return config_spec def get_cluster_ref_from_name(session, cluster_name): """"""Get reference to the cluster with the name specified."""""" cls = session._call_method(vim_util, ""get_objects"", ""ClusterComputeResource"", [""name""]) return _get_object_from_results(session, cls, cluster_name, _get_object_for_value) ",0,50
openstack%2Fdiskimage-builder~master~I39dbd3f4004052fcccb4131dc838759f4c82312a,openstack/diskimage-builder,master,I39dbd3f4004052fcccb4131dc838759f4c82312a,Drop ending slash from DIB_CLOUD_IMAGES,MERGED,2014-06-23 06:24:10.000000000,2014-06-23 19:22:31.000000000,2014-06-23 19:22:30.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-06-23 06:24:10.000000000', 'files': ['elements/ubuntu/root.d/10-cache-ubuntu-tarball'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cf9870729d13afceae934fbcb17e698563afa8f6', 'message': ""Drop ending slash from DIB_CLOUD_IMAGES\n\nThe DIB_CLOUD_IMAGES variable in ubuntu's root.d is already used\neverywhere with a /, so we can safely drop it from the default\nvalue.\n\nChange-Id: I39dbd3f4004052fcccb4131dc838759f4c82312a\n""}]",0,101808,cf9870729d13afceae934fbcb17e698563afa8f6,9,3,1,9369,,,0,"Drop ending slash from DIB_CLOUD_IMAGES

The DIB_CLOUD_IMAGES variable in ubuntu's root.d is already used
everywhere with a /, so we can safely drop it from the default
value.

Change-Id: I39dbd3f4004052fcccb4131dc838759f4c82312a
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/08/101808/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ubuntu/root.d/10-cache-ubuntu-tarball'],1,cf9870729d13afceae934fbcb17e698563afa8f6,no-double-slash-in-ubuntu,DIB_CLOUD_IMAGES=${DIB_CLOUD_IMAGES:-http://cloud-images.ubuntu.com},DIB_CLOUD_IMAGES=${DIB_CLOUD_IMAGES:-http://cloud-images.ubuntu.com/},1,1
openstack%2Ftripleo-image-elements~master~Ic510d59a7665aa5b9931db5d20375c69c614a915,openstack/tripleo-image-elements,master,Ic510d59a7665aa5b9931db5d20375c69c614a915,Allow services ports configuration,ABANDONED,2014-05-07 09:26:22.000000000,2014-06-23 19:18:12.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7582}, {'_account_id': 8449}, {'_account_id': 8907}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-07 09:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3ffc14f5579901c7361ee26a686170d414a93724', 'message': 'Remove hardcoded ports for api endpoints\n\nendpoints for glance, neutron, ec2, ironic in nova.conf\nshould be Heat-configurable\n\nIt is required to be consistent with keystone endpoints,\nwhich in HA configuration will be managed by haproxy, and listen on\nnon-default ports.\n\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 2, 'created': '2014-05-08 12:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/190beb65dac50936e1f5b0fd8f3f447b0073a1eb', 'message': 'Remove hardcoded ports for api endpoints\n\nendpoints for glance, neutron, ec2, ironic in nova.conf\nshould be Heat-configurable\n\nIt is required to be consistent with keystone endpoints,\nwhich in HA configuration will be managed by haproxy, and listen on\nnon-default ports.\n\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 3, 'created': '2014-05-12 14:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6c9da5f75f788d17f3fdf13a51680b4cc43142a7', 'message': 'Remove hardcoded services ports in conf files\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged confs for:\n- cinder-api\n- glance-api\n- glance-registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat-api\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 4, 'created': '2014-05-13 07:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ef95090308dea6ed6c0f5f522c7d09d5acbcd5ef', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- cinder-api\n- glance-api\n- glance-registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat-api\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 5, 'created': '2014-05-13 15:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/28b6745b60e607c87ee7915ebd12ec261c7b28a7', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- cinder-api\n- glance-api\n- glance-registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat api, cfn, cloudwatch\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 6, 'created': '2014-05-14 10:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/38cbc2070b63318d97f6fc10f03aacf30b412d42', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- glance api, registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat api, cfn, cloudwatch\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 7, 'created': '2014-05-14 11:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d36b6d4854d4a84eec26405b8e2c936f429103c9', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- glance api, registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat api, cfn, cloudwatch\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 8, 'created': '2014-05-20 14:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cdb5fcfc9f8c2159616cb46b49f30d16b54b44cb', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- glance api, registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat api, cfn, cloudwatch\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}, {'number': 9, 'created': '2014-05-21 15:29:29.000000000', 'files': ['elements/horizon/files/horizon.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/horizon/os-refresh-config/pre-configure.d/97-horizon-fedora-iptables', 'elements/horizon/files/ssl.conf', 'elements/horizon/install.d/horizon-source-install/100-horizon', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/heat/os-config-applier/etc/heat/heat.conf', 'elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf', 'elements/glance/os-config-applier/etc/glance/glance-registry.conf', 'elements/horizon/files/ports.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/glance/os-config-applier/etc/glance/glance-api.conf', 'elements/glance/os-config-applier/etc/glance/glance-cache.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5a8a6844843f62df1d590440436fa0e11b992e54', 'message': 'Allow services ports configuration\n\nAdd possibility to specify ports for services to listen on\n\nThis is required to provide load balancing for services\n\nChanged config files:\n- glance api, registry\n- neutron-api\n- cinder-api\n- ceilometer-api\n- ironic-api\n- nova ec2, osapi, metadata\n- heat api, cfn, cloudwatch\n- horizon apache configuration\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915\n'}]",2,92550,5a8a6844843f62df1d590440436fa0e11b992e54,50,6,9,8907,,,0,"Allow services ports configuration

Add possibility to specify ports for services to listen on

This is required to provide load balancing for services

Changed config files:
- glance api, registry
- neutron-api
- cinder-api
- ceilometer-api
- ironic-api
- nova ec2, osapi, metadata
- heat api, cfn, cloudwatch
- horizon apache configuration

Related to blueprint tripleo-icehouse-ha-production-configuration
Change-Id: Ic510d59a7665aa5b9931db5d20375c69c614a915
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/50/92550/9 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova/os-apply-config/etc/nova/nova.conf'],1,3ffc14f5579901c7361ee26a686170d414a93724,bp/tripleo-icehouse-ha-production-configuration,{{#nova.ec2_proxy_port}} ec2_url=http://{{nova.host}}:{{nova.ec2_proxy_port}}/services/Cloud {{/nova.ec2_proxy_port}} {{^nova.ec2_proxy_port}}{{/nova.ec2_proxy_port}}{{#glance.proxy_port}} glance_api_servers={{glance.host}}:{{glance.proxy_port}} {{/glance.proxy_port}} {{^glance.proxy_port}} glance_api_servers={{glance.host}}:{{9292}} {{/glance.proxy_port}}{{#neutron.proxy_port}} neutron_url=http://{{neutron.host}}:{{neutron.proxy_port}} {{/neutron.proxy_port}} {{^neutron.proxy_port}}{{/neutron.proxy_port}}{{#ironic.proxy_port}} api_endpoint = http://localhost:{{ironic.proxy_port}}/v1 {{/ironic.proxy_port}} {{^ironic.proxy_port}}{{#ironic.proxy_port}},glance_api_servers={{glance.host}}:9292,21,1
openstack%2Ffuel-library~master~Iffded4a5398488c4c00b3e69bf0c2ed77e3a39c4,openstack/fuel-library,master,Iffded4a5398488c4c00b3e69bf0c2ed77e3a39c4,Remove unused puppet module squid,MERGED,2014-06-19 10:29:34.000000000,2014-06-23 19:09:36.000000000,2014-06-23 19:09:36.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-19 10:29:34.000000000', 'files': ['deployment/puppet/squid/manifests/backup.pp', 'deployment/puppet/squid/manifests/params.pp', 'deployment/puppet/squid/manifests/disable.pp', 'deployment/puppet/squid/manifests/puppi.pp', 'deployment/puppet/squid/manifests/absent.pp', 'deployment/puppet/squid/README', 'deployment/puppet/squid/manifests/monitor.pp', 'deployment/puppet/squid/manifests/debug.pp', 'deployment/puppet/squid/Modulefile', 'deployment/puppet/squid/manifests/disableboot.pp', 'deployment/puppet/squid/templates/variables_squid.erb', 'deployment/puppet/squid/.project', 'deployment/puppet/squid/manifests/conf.pp', 'deployment/puppet/squid/templates/squid.conf.erb', 'deployment/puppet/squid/manifests/firewall.pp', 'deployment/puppet/squid/manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a125982a031b4726a13ca3e7e2871bbd0730c991', 'message': 'Remove unused puppet module squid\n\nChange-Id: Iffded4a5398488c4c00b3e69bf0c2ed77e3a39c4\nImplements: blueprint merge-openstack-puppet-modules\n'}]",0,101167,a125982a031b4726a13ca3e7e2871bbd0730c991,16,6,1,11827,,,0,"Remove unused puppet module squid

Change-Id: Iffded4a5398488c4c00b3e69bf0c2ed77e3a39c4
Implements: blueprint merge-openstack-puppet-modules
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/67/101167/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/squid/manifests/backup.pp', 'deployment/puppet/squid/manifests/params.pp', 'deployment/puppet/squid/manifests/disable.pp', 'deployment/puppet/squid/manifests/puppi.pp', 'deployment/puppet/squid/manifests/absent.pp', 'deployment/puppet/squid/README', 'deployment/puppet/squid/manifests/monitor.pp', 'deployment/puppet/squid/manifests/debug.pp', 'deployment/puppet/squid/Modulefile', 'deployment/puppet/squid/manifests/disableboot.pp', 'deployment/puppet/squid/templates/variables_squid.erb', 'deployment/puppet/squid/.project', 'deployment/puppet/squid/manifests/conf.pp', 'deployment/puppet/squid/templates/squid.conf.erb', 'deployment/puppet/squid/manifests/firewall.pp', 'deployment/puppet/squid/manifests/init.pp']",16,a125982a031b4726a13ca3e7e2871bbd0730c991,bp/merge-openstack-puppet-modules,,"# # Class: squid # # Manages squid. # Include it to install and run squid # It defines package, service, main configuration file. # # Usage: # include squid # class squid { # Load the variables used in this module. Check the params.pp file require squid::params # Re-sets variables needed in templates (to get default values) $squid_server = $squid::params::server # Basic Package - Service - Configuration file management package { ""squid"": name => ""${squid::params::packagename}"", ensure => present, } service { ""squid"": name => ""${squid::params::servicename}"", ensure => running, enable => true, hasrestart => true, hasstatus => ""${squid::params::hasstatus}"", pattern => ""${squid::params::processname}"", require => Package[""squid""], subscribe => File[""squid.conf""], } file { ""squid.conf"": path => ""${squid::params::configfile}"", mode => ""${squid::params::configfile_mode}"", owner => ""${squid::params::configfile_owner}"", group => ""${squid::params::configfile_group}"", ensure => present, require => Package[""squid""], notify => Service[""squid""], content => template(""squid/squid.conf.erb""), } file { ""cache_dir"": path => ""${squid::params::cache_dir}"", mode => '0755', owner => ""${squid::params::processuser}"", group => ""${squid::params::configfile_group}"", ensure => directory, } file { ""cache_log_dir"": path => ""${squid::params::cache_log_dir}"", mode => '0640', owner => ""${squid::params::processuser}"", group => ""${squid::params::processuser}"", ensure => directory, } # Include OS specific subclasses, if necessary case $operatingsystem { default: { } } # Include extended classes if $puppi == ""yes"" { include squid::puppi } if $backup == ""yes"" { include squid::backup } if $monitor == ""yes"" { include squid::monitor } if $firewall == ""yes"" { include squid::firewall } # Include project specific monitor class if $my_project is set if $my_project { include ""squid::${my_project}"" } # Include debug class is debugging is enabled ($debug=yes) if ( $debug == ""yes"" ) or ( $debug == true ) { include squid::debug } } ",0,5684
openstack%2Ffuel-library~master~I8cfe97c3d5e877ad430575d9a7d80651eb4dc319,openstack/fuel-library,master,I8cfe97c3d5e877ad430575d9a7d80651eb4dc319,Sync puppet ssh module to v2.3.6 from upstream,MERGED,2014-06-18 10:55:45.000000000,2014-06-23 19:06:13.000000000,2014-06-23 19:06:12.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-18 10:55:45.000000000', 'files': ['deployment/puppet/ssh/Rakefile', 'deployment/puppet/ssh/spec/classes/client_spec.rb', 'deployment/puppet/ssh/manifests/site.pp', 'deployment/puppet/ssh/manifests/server/install.pp', 'deployment/puppet/ssh/manifests/params.pp', 'deployment/puppet/ssh/.project', 'deployment/puppet/ssh/manifests/hostkeys.pp', 'deployment/puppet/ssh/spec/spec_helper.rb', 'deployment/puppet/ssh/templates/sshd_config.erb', 'deployment/puppet/ssh/Modulefile', 'deployment/puppet/ssh/manifests/client/install.pp', 'deployment/puppet/ssh/manifests/knownhosts.pp', 'deployment/puppet/ssh/manifests/init.pp', 'deployment/puppet/ssh/.gemfile', 'deployment/puppet/ssh/files/ssh_config', 'deployment/puppet/ssh/README.markdown', 'deployment/puppet/ssh/manifests/server/service.pp', 'deployment/puppet/ssh/tests/server.pp', 'deployment/puppet/ssh/manifests/server/configline.pp', 'deployment/puppet/ssh/.travis.yml', 'deployment/puppet/ssh/lib/puppet/parser/functions/ipaddresses.rb', 'deployment/puppet/ssh/.gitignore', 'deployment/puppet/ssh/manifests/client.pp', 'deployment/puppet/ssh/manifests/server/host_key.pp', 'deployment/puppet/ssh/manifests/server.pp', 'deployment/puppet/ssh/manifests/client/config.pp', 'deployment/puppet/ssh/templates/ssh_config.erb', 'deployment/puppet/ssh/tests/init.pp', 'deployment/puppet/ssh/spec/classes/server_spec.rb', 'deployment/puppet/ssh/.fixtures.yml', 'deployment/puppet/ssh/manifests/server/config.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fc6f30481e643596f27e7225084ef2b6c5fd320a', 'message': 'Sync puppet ssh module to v2.3.6 from upstream\n\nv2.3.6: 23f46577e5bcf07b3859a5690102187f8930c8b5\n\nChange-Id: I8cfe97c3d5e877ad430575d9a7d80651eb4dc319\nImplements: blueprint merge-openstack-puppet-modules\n'}]",0,100850,fc6f30481e643596f27e7225084ef2b6c5fd320a,16,6,1,11827,,,0,"Sync puppet ssh module to v2.3.6 from upstream

v2.3.6: 23f46577e5bcf07b3859a5690102187f8930c8b5

Change-Id: I8cfe97c3d5e877ad430575d9a7d80651eb4dc319
Implements: blueprint merge-openstack-puppet-modules
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/50/100850/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/ssh/Rakefile', 'deployment/puppet/ssh/spec/classes/client_spec.rb', 'deployment/puppet/ssh/manifests/site.pp', 'deployment/puppet/ssh/manifests/server/install.pp', 'deployment/puppet/ssh/manifests/params.pp', 'deployment/puppet/ssh/.project', 'deployment/puppet/ssh/manifests/hostkeys.pp', 'deployment/puppet/ssh/spec/spec_helper.rb', 'deployment/puppet/ssh/templates/sshd_config.erb', 'deployment/puppet/ssh/Modulefile', 'deployment/puppet/ssh/manifests/client/install.pp', 'deployment/puppet/ssh/manifests/knownhosts.pp', 'deployment/puppet/ssh/manifests/init.pp', 'deployment/puppet/ssh/.gemfile', 'deployment/puppet/ssh/files/ssh_config', 'deployment/puppet/ssh/README.markdown', 'deployment/puppet/ssh/manifests/server/service.pp', 'deployment/puppet/ssh/tests/server.pp', 'deployment/puppet/ssh/manifests/server/configline.pp', 'deployment/puppet/ssh/.travis.yml', 'deployment/puppet/ssh/lib/puppet/parser/functions/ipaddresses.rb', 'deployment/puppet/ssh/.gitignore', 'deployment/puppet/ssh/manifests/client.pp', 'deployment/puppet/ssh/manifests/server/host_key.pp', 'deployment/puppet/ssh/manifests/server.pp', 'deployment/puppet/ssh/manifests/client/config.pp', 'deployment/puppet/ssh/templates/ssh_config.erb', 'deployment/puppet/ssh/tests/init.pp', 'deployment/puppet/ssh/spec/classes/server_spec.rb', 'deployment/puppet/ssh/.fixtures.yml', 'deployment/puppet/ssh/manifests/server/config.pp']",31,fc6f30481e643596f27e7225084ef2b6c5fd320a,bp/merge-openstack-puppet-modules," file { $ssh::params::sshd_config: ensure => present, owner => 0, group => 0, mode => '0600', content => template(""${module_name}/sshd_config.erb""), require => Class['ssh::server::install'], notify => Class['ssh::server::service'], }"," file { $ssh::params::sshd_config: ensure => present, owner => ""root"", group => ""root"", mode => 0600, replace => false, source => ""puppet:///modules/${module_name}/sshd_config"", require => Class[""ssh::server::install""], notify => Class[""ssh::server::service""], }",769,208
openstack%2Fapi-site~master~I3b1532faf4108fc08cd7695b2d8e5e90786c2a2e,openstack/api-site,master,I3b1532faf4108fc08cd7695b2d8e5e90786c2a2e,Add 'bootable' field to volume show response,MERGED,2014-06-23 02:09:46.000000000,2014-06-23 18:51:49.000000000,2014-06-23 18:51:48.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-06-23 02:09:46.000000000', 'files': ['api-ref/src/wadls/volume-api/src/v1/api_samples/volume_show.xml', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_show_response.json', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_show_response.xml', 'api-ref/src/wadls/volume-api/src/v1/api_samples/volume_show.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/5b0932cd1e31237912d623ff155aa49c705bd011', 'message': ""Add 'bootable' field to volume show response\n\nThe cinder volume data model shows a 'bootable' field as type boolean\nand apparently it's coming back on the cinder API response when getting\na volume, but it's not in the API docs. This patch add the missing\n'bootable' field to the sample response.\n\nChange-Id: I3b1532faf4108fc08cd7695b2d8e5e90786c2a2e\nCloses-bug: 1329762\n""}]",0,101787,5b0932cd1e31237912d623ff155aa49c705bd011,8,3,1,4428,,,0,"Add 'bootable' field to volume show response

The cinder volume data model shows a 'bootable' field as type boolean
and apparently it's coming back on the cinder API response when getting
a volume, but it's not in the API docs. This patch add the missing
'bootable' field to the sample response.

Change-Id: I3b1532faf4108fc08cd7695b2d8e5e90786c2a2e
Closes-bug: 1329762
",git fetch https://review.opendev.org/openstack/api-site refs/changes/87/101787/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/volume-api/src/v1/api_samples/volume_show.xml', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_show_response.json', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_show_response.xml', 'api-ref/src/wadls/volume-api/src/v1/api_samples/volume_show.json']",4,5b0932cd1e31237912d623ff155aa49c705bd011,bug/1329762," ""bootable"": ""false"",} ",},6,3
openstack%2Fnova~master~I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca,openstack/nova,master,I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca,Fix bug in TestObjectVersions,MERGED,2014-06-21 01:15:06.000000000,2014-06-23 18:45:12.000000000,2014-06-23 18:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-21 01:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e971dabe3b42130d677bdbdfcd4f5b59aba3eaf5', 'message': 'Fix bug in TestObjectVersions\n\nThe object version hash trap test was incorrectly hashing over\nNone instead of the list of object fields. This patch fixes\nthat and updates the hashes accordingly.\n\nChange-Id: I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca\n'}, {'number': 2, 'created': '2014-06-21 18:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8c3872a5f74152ea6d36f4c7fadce9aeb58dd25', 'message': 'Fix bug in TestObjectVersions\n\nThe object version hash trap test was incorrectly hashing over\nNone instead of the list of object fields. This patch fixes\nthat and updates the hashes accordingly.\n\nChange-Id: I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca\n'}, {'number': 3, 'created': '2014-06-23 15:39:12.000000000', 'files': ['nova/tests/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0457a262c413e4538db4e33a906687bca41ef67f', 'message': 'Fix bug in TestObjectVersions\n\nThe object version hash trap test was incorrectly hashing over\nNone instead of the list of object fields. This patch fixes\nthat and updates the hashes accordingly.\n\nChange-Id: I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca\n'}]",2,101678,0457a262c413e4538db4e33a906687bca41ef67f,51,11,3,4393,,,0,"Fix bug in TestObjectVersions

The object version hash trap test was incorrectly hashing over
None instead of the list of object fields. This patch fixes
that and updates the hashes accordingly.

Change-Id: I217b65e7dfee7b77c5ab7b0b7c8bf06cafe8bcca
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/101678/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/objects/test_objects.py'],1,e971dabe3b42130d677bdbdfcd4f5b59aba3eaf5,fix_objver_test," 'Aggregate': '1.1-f5d477be06150529a9b2d27cc49030b5', 'AggregateList': '1.1-3e67b6a4840b19c797504cc6056b27ff', 'BlockDeviceMapping': '1.1-9968ffe513e7672484b0f528b034cd0f', 'BlockDeviceMappingList': '1.2-d6d7df540ca149dda78b22b4b10bdef3', 'ComputeNode': '1.3-b3b8935a99ca48621dc9ba271d5ed668', 'ComputeNodeList': '1.2-ff59187056eaa96f6fd3fb70693d818c', 'DNSDomain': '1.0-5bdc288d7c3b723ce86ede998fd5c9ba', 'DNSDomainList': '1.0-6e3cc498d89dd7e90f9beb021644221c', 'EC2InstanceMapping': '1.0-627baaf4b12c9067200979bdc4558a99', 'EC2VolumeMapping': '1.0-2f8c3bf077c65a425294ec2b361c9143', 'FixedIP': '1.1-082fb26772ce2db783ce4934edca4652', 'FixedIPList': '1.1-8ea5cfca611598f1242fd4095e49e58b', 'Flavor': '1.0-e23dacfb3f5695497bc7911e11158912', 'FlavorList': '1.0-d559595f55936a6d602721c3bdff6fff', 'FloatingIP': '1.1-27eb68b7c9c620dd5f0561b5a3be0e82', 'FloatingIPList': '1.2-1b77acb3523d16e3282624f51fee60d8', 'Instance': '1.13-c9cfd71ddc9d6e7e7c72879f4d5982ee', 'InstanceAction': '1.1-6b1d0a6dbd522b5a83c20757ec659663', 'InstanceActionEvent': '1.1-f144eaa9fb22f248fc41ed8401a3a1be', 'InstanceActionEventList': '1.0-937f4ed414ff2354de416834b948fbd6', 'InstanceActionList': '1.0-d46ade45deeba63c55821e22c164bd1b', 'InstanceExternalEvent': '1.0-f1134523654407a875fd59b80f759ee7', 'InstanceFault': '1.2-313438e37e9d358f3566c85f6ddb2d3e', 'InstanceFaultList': '1.1-bd578be60d045629ca7b3ce1a2493ae4', 'InstanceGroup': '1.6-c032430832b3cbaf92c99088e4b2fdc8', 'InstanceGroupList': '1.2-bebd07052779ae3b47311efe85428a8b', 'InstanceInfoCache': '1.5-ef64b604498bfa505a8c93747a9d8b2f', 'InstanceList': '1.6-78800140a5f9818ab00f8c052437655f', 'KeyPair': '1.1-3410f51950d052d861c11946a6ae621a', 'KeyPairList': '1.0-854cfff138dac9d5925c89cf805d1a70', 'Migration': '1.1-67c47726c2c71422058cd9d149d6d3ed', 'MigrationList': '1.1-6ca2ebb822ebfe1a660bace824b378c6', 'MyObj': '1.6-9039bc29de1c08943771407697c83076', 'Network': '1.1-20ff4f72acf5db4724035dd6ee41bda9', 'NetworkList': '1.1-16510568c6e64cb8b358cb2b11333196', 'PciDevice': '1.1-523c46f960d93f78db55f0280b09441e', 'PciDeviceList': '1.0-5da7b4748a5a2594bae2cd0bd211cca2', 'Quotas': '1.0-1933ffdc585c205445331fe842567eb3', 'QuotasNoOp': '1.0-187356d5a8b8e4a3505148ea4e96cfcb', 'SecurityGroup': '1.1-bba0e72865e0953793e796571692453b', 'SecurityGroupList': '1.0-9513387aabf08c2a7961ac4da4315ed4', 'SecurityGroupRule': '1.0-fdd020bdd7eb8bac744ad6f9a4ef8165', 'SecurityGroupRuleList': '1.0-af4deeea8699ee90fb217f77d711d781', 'Service': '1.2-5a3df338c669e1148251431370b440ef', 'ServiceList': '1.0-ae64b4922df28d7cd11c59cddddf926c', 'TestSubclassedObject': '1.6-1629421d83f474b7fadc41d3fc0e4998', 'VirtualInterface': '1.0-10fdac4c704102b6d57d6936d6d790d2', 'VirtualInterfaceList': '1.0-dc9e9d5bce522d28f96092c49119b3e0', } fields.sort()"," 'Aggregate': '1.1-2aaadeab57bbdbc735d6a9f224db65a2', 'AggregateList': '1.1-feb0613d03ca8ef1b227f2f8e97b9ea2', 'BlockDeviceMapping': '1.1-9ada5b2c4fbab59dd5e24660c9a33d24', 'BlockDeviceMappingList': '1.2-e3b43f9b9c09233e3834d3623d0fd10f', 'ComputeNode': '1.3-da78709c570978659b94e069383f599b', 'ComputeNodeList': '1.2-3275ea285c786fbc755b4472772a9528', 'DNSDomain': '1.0-54455ffc071515a2052a70a37d674435', 'DNSDomainList': '1.0-7d1165619956062314f5f2c4d1bb61ba', 'EC2InstanceMapping': '1.0-c9ebf3e641800d1f453ef9f19b159971', 'EC2VolumeMapping': '1.0-f376082f497bba08583119ef7cbbb07e', 'FixedIP': '1.1-70b8c86daf93913c7bb11afc901dda76', 'FixedIPList': '1.1-cbe7d8ff7eea9d3aecb7d537e1007742', 'Flavor': '1.0-2956744a9d1edd729bf8bf0dcc98c235', 'FlavorList': '1.0-07d83f9f303186954879949adf0ee60d', 'FloatingIP': '1.1-e7c74bf87bda4370aba6d46253d2f8e6', 'FloatingIPList': '1.2-2b48d645da4c9a6af48c167df5307a87', 'Instance': '1.13-33b01aa5bae61817ffd70761aa516b03', 'InstanceAction': '1.1-6b21abed7121856422cd6160df4f4676', 'InstanceActionEvent': '1.1-28326849b2dddc4dc457aa23ad8fb872', 'InstanceActionEventList': '1.0-bb682bc2ed8c83a35eb9223538ff3f67', 'InstanceActionList': '1.0-74baedb998446293a65803cbbbc0e2d4', 'InstanceExternalEvent': '1.0-4e160b099f6bf7e9dd17260e6bcee8cd', 'InstanceFault': '1.2-92d8b198ad742abc3ea8848e4d1fbfc9', 'InstanceFaultList': '1.1-133cb518163665211f25d01662c35c05', 'InstanceGroup': '1.6-c1cbdd4ed694b71f2373810c240f0dca', 'InstanceGroupList': '1.2-28db742d254c466d8961a3bc5146fa74', 'InstanceInfoCache': '1.5-b457ac4ba2d7522069fb559eef6096d2', 'InstanceList': '1.6-72ffa5e0fcb980988d3fcae6cbb3f671', 'KeyPair': '1.1-e8c19c3025f15c6d5c38b6f9f621dd4b', 'KeyPairList': '1.0-3e5aaf43f81e7f6cea40618786e39d66', 'Migration': '1.1-eeb2164ef6fd182ea0d5659b8ed71053', 'MigrationList': '1.1-d58aaa2a66678aec20d9f99c46447f4d', 'MyObj': '1.6-5e9f181288c104ae0d1aad6f8c0d40b9', 'Network': '1.1-a0912fc5edc85e388a22822fcdab0621', 'NetworkList': '1.1-e4fb6d4583852c039e97a61579a73261', 'PciDevice': '1.1-cbc31f0131195987e796d8fed792e173', 'PciDeviceList': '1.0-f406a5539bcead291eb7597ec4456451', 'Quotas': '1.0-801745b38394a6593c44655b72613910', 'QuotasNoOp': '1.0-4e160b099f6bf7e9dd17260e6bcee8cd', 'SecurityGroup': '1.1-2083f9d56244f057b7d57dc00f1ce5d8', 'SecurityGroupList': '1.0-12d752b3d2b83367e230caa515508fd5', 'SecurityGroupRule': '1.0-1e6302339f8746343383af323bfd0ba2', 'SecurityGroupRuleList': '1.0-c28e2a23dd778993ff7fe481967882f9', 'Service': '1.2-5214a2ea4e1883de79286bcb05015d3d', 'ServiceList': '1.0-08441b0ab42f016140e24a12e93cd25c', 'TestSubclassedObject': '1.6-5e9f181288c104ae0d1aad6f8c0d40b9', 'VirtualInterface': '1.0-513adc400c9c4dfcbd0a638a0a415183', 'VirtualInterfaceList': '1.0-15f2f3e0517805f585b402ab1547ba92', } fields = fields.sort()",50,51
openstack%2Fnova~master~Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f,openstack/nova,master,Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f,Drop support for conductor 1.x rpc interface,MERGED,2014-03-31 21:11:15.000000000,2014-06-23 18:44:49.000000000,2014-06-23 18:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 8163}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-03-31 21:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/275d3ad5ef2fe88363c0e5ab37d050fdf128f894', 'message': 'Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n'}, {'number': 2, 'created': '2014-04-01 13:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a3997038c5ddbe04151e4ccc624fdb335f86186', 'message': ""Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nNote that this patch is blocked by CI until the partial/rolling\nupgrade test is updated to test Icehouse->Juno.  Until then it's\ntesting Havana->Juno, which is broken by this change (intentionally).\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n""}, {'number': 3, 'created': '2014-04-11 15:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9229652a0c6f4f183af088dc6cf4724de546cf1d', 'message': ""Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nNote that this patch is blocked by CI until the partial/rolling\nupgrade test is updated to test Icehouse->Juno.  Until then it's\ntesting Havana->Juno, which is broken by this change (intentionally).\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n""}, {'number': 4, 'created': '2014-04-14 15:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/510770a0005469d356776506addfbf5f9f26a1ed', 'message': ""Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nNote that this patch is blocked by CI until the partial/rolling\nupgrade test is updated to test Icehouse->Juno.  Until then it's\ntesting Havana->Juno, which is broken by this change (intentionally).\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n""}, {'number': 5, 'created': '2014-04-21 14:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa053b6c056ad09329749acab7a850777db467f6', 'message': ""Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nNote that this patch is blocked by CI until the partial/rolling\nupgrade test is updated to test Icehouse->Juno.  Until then it's\ntesting Havana->Juno, which is broken by this change (intentionally).\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n""}, {'number': 6, 'created': '2014-06-17 18:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72ee7b3c70ca73ba6c17b9ed389ebe54d03c89f6', 'message': ""Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nNote that this patch is blocked by CI until the partial/rolling\nupgrade test is updated to test Icehouse->Juno.  Until then it's\ntesting Havana->Juno, which is broken by this change (intentionally).\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n""}, {'number': 7, 'created': '2014-06-18 17:49:55.000000000', 'files': ['nova/conductor/api.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/47f6ffad8291c7383d79cd987d06cb5753dad729', 'message': 'Drop support for conductor 1.x rpc interface\n\nIn commit 330ce897c14f66a39426e716f02a620453035c15, a part of\nIcehouse, we added support for the 2.x interface.  Now that Juno\ndevelopment is open, we can drop support for the old API, 1.x.\n\nFor more information on this change, see:\n\n    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates\n\nUpgradeImpact\n\nChange-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f\n'}]",14,84254,47f6ffad8291c7383d79cd987d06cb5753dad729,86,13,7,1561,,,0,"Drop support for conductor 1.x rpc interface

In commit 330ce897c14f66a39426e716f02a620453035c15, a part of
Icehouse, we added support for the 2.x interface.  Now that Juno
development is open, we can drop support for the old API, 1.x.

For more information on this change, see:

    https://wiki.openstack.org/wiki/RpcMajorVersionUpdates

UpgradeImpact

Change-Id: Id7e605d493a53eaaa2a9afa0c99ac721f590ca3f
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/84254/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conductor/api.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py']",3,275d3ad5ef2fe88363c0e5ab37d050fdf128f894,bp/compute-manager-objects-juno," target = messaging.Target(version='2.0') updates, service): columns_to_join): def instance_get_all_by_host(self, context, host, node, columns_to_join): bw_in, bw_out, last_ctr_in, last_ctr_out, last_refreshed, update_cells): def block_device_mapping_update_or_create(self, context, values, create): legacy): sort_dir, columns_to_join, use_slave): def instance_get_active_by_window(self, context, begin, end, project_id, host): def instance_get_active_by_window_joined(self, context, begin, end, project_id, host): # and can be removed in v3.0 of the RPC API. wr_bytes, instance, last_refreshed, update_totals): def service_get_all_by(self, context, topic, host, binary): # FIXME(comstud) Potentially remove this on bump to v3.0 def compute_node_update(self, context, node, values): def task_log_get(self, context, task_name, begin, end, host, state): task_items, message): errors, message): def notify_usage_exists(self, context, instance, current_period, ignore_missing_network_data, system_metadata, extra_usage_info):","from nova.objects import migration as migration_obj target = messaging.Target(version='1.64') self.additional_endpoints.append(_ConductorManagerV2Proxy(self)) updates, service=None): # NOTE(russellb): This method is now deprecated and can be removed in # version 2.0 of the RPC API @messaging.expected_exceptions(exception.InstanceNotFound) def instance_get(self, context, instance_id): return jsonutils.to_primitive( self.db.instance_get(context, instance_id)) columns_to_join=None): # NOTE(hanlind): This method can be removed in v2.0 of the RPC API. def instance_get_all(self, context): return jsonutils.to_primitive(self.db.instance_get_all(context)) def instance_get_all_by_host(self, context, host, node=None, columns_to_join=None): # NOTE(comstud): This method is now deprecated and can be removed in # version v2.0 of the RPC API @messaging.expected_exceptions(exception.MigrationNotFound) def migration_get(self, context, migration_id): migration_ref = self.db.migration_get(context.elevated(), migration_id) return jsonutils.to_primitive(migration_ref) # NOTE(comstud): This method is now deprecated and can be removed in # version v2.0 of the RPC API def migration_get_unconfirmed_by_dest_compute(self, context, confirm_window, dest_compute): migrations = self.db.migration_get_unconfirmed_by_dest_compute( context, confirm_window, dest_compute) return jsonutils.to_primitive(migrations) # NOTE(comstud): This method can be removed in v2.0 of the RPC API. def migration_create(self, context, instance, values): values.update({'instance_uuid': instance['uuid'], 'source_compute': instance['host'], 'source_node': instance['node']}) migration_ref = self.db.migration_create(context.elevated(), values) return jsonutils.to_primitive(migration_ref) # NOTE(russellb): This method is now deprecated and can be removed in # version 2.0 of the RPC API @messaging.expected_exceptions(exception.MigrationNotFound) def migration_update(self, context, migration, status): migration_ref = self.db.migration_update(context.elevated(), migration['id'], {'status': status}) return jsonutils.to_primitive(migration_ref) # NOTE(russellb): This method is now deprecated and can be removed in # version 2.0 of the RPC API @messaging.expected_exceptions(exception.AggregateNotFound) def aggregate_get(self, context, aggregate_id): aggregate = self.db.aggregate_get(context.elevated(), aggregate_id) return jsonutils.to_primitive(aggregate) # NOTE(russellb): This method is now deprecated and can be removed in # version 2.0 of the RPC API def aggregate_get_by_host(self, context, host, key=None): aggregates = self.db.aggregate_get_by_host(context.elevated(), host, key) return jsonutils.to_primitive(aggregates) # NOTE(danms): This method is now deprecated and can be removed in # version 2.0 of the RPC API def aggregate_metadata_add(self, context, aggregate, metadata, set_delete=False): new_metadata = self.db.aggregate_metadata_add(context.elevated(), aggregate['id'], metadata, set_delete) return jsonutils.to_primitive(new_metadata) # NOTE(danms): This method is now deprecated and can be removed in # version 2.0 of the RPC API @messaging.expected_exceptions(exception.AggregateMetadataNotFound) def aggregate_metadata_delete(self, context, aggregate, key): self.db.aggregate_metadata_delete(context.elevated(), aggregate['id'], key) bw_in=None, bw_out=None, last_ctr_in=None, last_ctr_out=None, last_refreshed=None, update_cells=True): # NOTE(russellb) This method can be removed in 2.0 of this API. It is # deprecated in favor of the method in the base API. def get_backdoor_port(self, context): return self.backdoor_port # NOTE(danms): This method can be removed in version 2.0 of this API. def security_group_get_by_instance(self, context, instance): group = self.db.security_group_get_by_instance(context, instance['uuid']) return jsonutils.to_primitive(group) # NOTE(danms): This method can be removed in version 2.0 of this API. def security_group_rule_get_by_security_group(self, context, secgroup): rules = self.db.security_group_rule_get_by_security_group( context, secgroup['id']) return jsonutils.to_primitive(rules, max_depth=4) def block_device_mapping_update_or_create(self, context, values, create=None): legacy=True): # NOTE(russellb) This method can be removed in 2.0 of this API. It is # deprecated in favor of the method in the base API. def block_device_mapping_destroy(self, context, bdms=None, instance=None, volume_id=None, device_name=None): if bdms is not None: for bdm in bdms: self.db.block_device_mapping_destroy(context, bdm['id']) # NOTE(comstud): bdm['id'] will be different in API cell, # so we must try to destroy by device_name or volume_id. # We need an instance_uuid in order to do this properly, # too. # I hope to clean a lot of this up in the object # implementation. instance_uuid = (bdm['instance_uuid'] or (instance and instance['uuid'])) if not instance_uuid: continue # Better to be safe than sorry. device_name is not # NULLable, however it could be an empty string. if bdm['device_name']: self.cells_rpcapi.bdm_destroy_at_top( context, instance_uuid, device_name=bdm['device_name']) elif bdm['volume_id']: self.cells_rpcapi.bdm_destroy_at_top( context, instance_uuid, volume_id=bdm['volume_id']) elif instance is not None and volume_id is not None: self.db.block_device_mapping_destroy_by_instance_and_volume( context, instance['uuid'], volume_id) self.cells_rpcapi.bdm_destroy_at_top( context, instance['uuid'], volume_id=volume_id) elif instance is not None and device_name is not None: self.db.block_device_mapping_destroy_by_instance_and_device( context, instance['uuid'], device_name) self.cells_rpcapi.bdm_destroy_at_top( context, instance['uuid'], device_name=device_name) else: # NOTE(danms): This shouldn't happen raise exception.Invalid(_(""Invalid block_device_mapping_destroy"" "" invocation"")) sort_dir, columns_to_join=None, use_slave=False): # NOTE(hanlind): This method can be removed in v2.0 of the RPC API. def instance_get_all_hung_in_rebooting(self, context, timeout): result = self.db.instance_get_all_hung_in_rebooting(context, timeout) return jsonutils.to_primitive(result) def instance_get_active_by_window(self, context, begin, end=None, project_id=None, host=None): def instance_get_active_by_window_joined(self, context, begin, end=None, project_id=None, host=None): # NOTE(hanlind): This method is now deprecated and can be removed in # version v2.0 of the RPC API. def instance_info_cache_update(self, context, instance, values): self.db.instance_info_cache_update(context, instance['uuid'], values) # NOTE(danms): This method is now deprecated and can be removed in # version v2.0 of the RPC API. def instance_type_get(self, context, instance_type_id): result = self.db.flavor_get(context, instance_type_id) return jsonutils.to_primitive(result) # NOTE(kerrin): This method can be removed in v2.0 of the RPC API. def vol_get_usage_by_time(self, context, start_time): result = self.db.vol_get_usage_by_time(context, start_time) return jsonutils.to_primitive(result) # and can be removed in v2.0 of the RPC API. wr_bytes, instance, last_refreshed=None, update_totals=False): def service_get_all_by(self, context, topic=None, host=None, binary=None): # FIXME(comstud) Potentially remove this on bump to v2.0 def compute_node_update(self, context, node, values, prune_stats=False): # NOTE(belliott) prune_stats is no longer relevant and will be # ignored if isinstance(values.get('stats'), dict): # NOTE(danms): In Icehouse, the 'stats' was changed from a dict # to a JSON string. If we get a dict-based value, convert it to # JSON, which the lower layers now expect. This can be removed # in version 2.0 of the RPC API values['stats'] = jsonutils.dumps(values['stats']) def task_log_get(self, context, task_name, begin, end, host, state=None): task_items=None, message=None): errors, message=None): def notify_usage_exists(self, context, instance, current_period=False, ignore_missing_network_data=True, system_metadata=None, extra_usage_info=None): # NOTE(danms): This method is now deprecated and can be removed in # version v2.0 of the RPC API def compute_stop(self, context, instance, do_cast=True): # NOTE(mriedem): Clients using an interface before 1.43 will be sending # dicts so we need to handle that here since compute/api::stop() # requires an object. if isinstance(instance, dict): instance = instance_obj.Instance._from_db_object( context, instance_obj.Instance(), instance) self.compute_api.stop(context, instance, do_cast) # NOTE(comstud): This method is now deprecated and can be removed in # version v2.0 of the RPC API def compute_confirm_resize(self, context, instance, migration_ref): if isinstance(instance, dict): attrs = ['metadata', 'system_metadata', 'info_cache', 'security_groups'] instance = instance_obj.Instance._from_db_object( context, instance_obj.Instance(), instance, expected_attrs=attrs) if isinstance(migration_ref, dict): migration_ref = migration_obj.Migration._from_db_object( context.elevated(), migration_ref) self.compute_api.confirm_resize(context, instance, migration=migration_ref) # NOTE(danms): This method is now deprecated and can be removed in # v2.0 of the RPC API def compute_reboot(self, context, instance, reboot_type): self.compute_api.reboot(context, instance, reboot_type) class _ConductorManagerV2Proxy(object): target = messaging.Target(version='2.0') def __init__(self, manager): self.manager = manager def instance_update(self, context, instance_uuid, updates, service): return self.manager.instance_update(context, instance_uuid, updates, service) def instance_get_by_uuid(self, context, instance_uuid, columns_to_join): return self.manager.instance_get_by_uuid(context, instance_uuid, columns_to_join) def migration_get_in_progress_by_host_and_node(self, context, host, node): return self.manager.migration_get_in_progress_by_host_and_node(context, host, node) def aggregate_host_add(self, context, aggregate, host): return self.manager.aggregate_host_add(context, aggregate, host) def aggregate_host_delete(self, context, aggregate, host): return self.manager.aggregate_host_delete(context, aggregate, host) def aggregate_metadata_get_by_host(self, context, host, key): return self.manager.aggregate_metadata_get_by_host(context, host, key) def bw_usage_update(self, context, uuid, mac, start_period, bw_in, bw_out, last_ctr_in, last_ctr_out, last_refreshed, update_cells): return self.manager.bw_usage_update(context, uuid, mac, start_period, bw_in, bw_out, last_ctr_in, last_ctr_out, last_refreshed, update_cells) def provider_fw_rule_get_all(self, context): return self.manager.provider_fw_rule_get_all(context) def agent_build_get_by_triple(self, context, hypervisor, os, architecture): return self.manager.agent_build_get_by_triple(context, hypervisor, os, architecture) def block_device_mapping_update_or_create(self, context, values, create): return self.manager.block_device_mapping_update_or_create(context, values, create) def block_device_mapping_get_all_by_instance(self, context, instance, legacy): return self.manager.block_device_mapping_get_all_by_instance(context, instance, legacy) def instance_get_all_by_filters(self, context, filters, sort_key, sort_dir, columns_to_join, use_slave): return self.manager.instance_get_all_by_filters(context, filters, sort_key, sort_dir, columns_to_join, use_slave) def instance_get_active_by_window_joined(self, context, begin, end, project_id, host): return self.manager.instance_get_active_by_window_joined(context, begin, end, project_id, host) def instance_destroy(self, context, instance): return self.manager.instance_destroy(context, instance) def instance_info_cache_delete(self, context, instance): return self.manager.instance_info_cache_delete(context, instance) def vol_get_usage_by_time(self, context, start_time): return self.manager.vol_get_usage_by_time(context, start_time) def vol_usage_update(self, context, vol_id, rd_req, rd_bytes, wr_req, wr_bytes, instance, last_refreshed, update_totals): return self.manager.vol_usage_update(context, vol_id, rd_req, rd_bytes, wr_req, wr_bytes, instance, last_refreshed, update_totals) def service_get_all_by(self, context, topic, host, binary): return self.manager.service_get_all_by(context, topic, host, binary) def instance_get_all_by_host(self, context, host, node, columns_to_join): return self.manager.instance_get_all_by_host(context, host, node, columns_to_join) def instance_fault_create(self, context, values): return self.manager.instance_fault_create(context, values) def action_event_start(self, context, values): return self.manager.action_event_start(context, values) def action_event_finish(self, context, values): return self.manager.action_event_finish(context, values) def service_create(self, context, values): return self.manager.service_create(context, values) def service_destroy(self, context, service_id): return self.manager.service_destroy(context, service_id) def compute_node_create(self, context, values): return self.manager.compute_node_create(context, values) def compute_node_update(self, context, node, values): return self.manager.compute_node_update(context, node, values) def compute_node_delete(self, context, node): return self.manager.compute_node_delete(context, node) def service_update(self, context, service, values): return self.manager.service_update(context, service, values) def task_log_get(self, context, task_name, begin, end, host, state): return self.manager.task_log_get(context, task_name, begin, end, host, state) def task_log_begin_task(self, context, task_name, begin, end, host, task_items, message): return self.manager.task_log_begin_task(context, task_name, begin, end, host, task_items, message) def task_log_end_task(self, context, task_name, begin, end, host, errors, message): return self.manager.task_log_end_task(context, task_name, begin, end, host, errors, message) def notify_usage_exists(self, context, instance, current_period, ignore_missing_network_data, system_metadata, extra_usage_info): return self.manager.notify_usage_exists(context, instance, current_period, ignore_missing_network_data, system_metadata, extra_usage_info) def security_groups_trigger_handler(self, context, event, args): return self.manager.security_groups_trigger_handler(context, event, args) def security_groups_trigger_members_refresh(self, context, group_ids): return self.manager.security_groups_trigger_members_refresh(context, group_ids) def network_migrate_instance_start(self, context, instance, migration): return self.manager.network_migrate_instance_start(context, instance, migration) def network_migrate_instance_finish(self, context, instance, migration): return self.manager.network_migrate_instance_finish(context, instance, migration) def quota_commit(self, context, reservations, project_id, user_id): return self.manager.quota_commit(context, reservations, project_id, user_id) def quota_rollback(self, context, reservations, project_id, user_id): return self.manager.quota_rollback(context, reservations, project_id, user_id) def get_ec2_ids(self, context, instance): return self.manager.get_ec2_ids(context, instance) def compute_unrescue(self, context, instance): return self.manager.compute_unrescue(context, instance) def object_class_action(self, context, objname, objmethod, objver, args, kwargs): return self.manager.object_class_action(context, objname, objmethod, objver, args, kwargs) def object_action(self, context, objinst, objmethod, args, kwargs): return self.manager.object_action(context, objinst, objmethod, args, kwargs) def object_backport(self, context, objinst, target_version): return self.manager.object_backport(context, objinst, target_version)",76,646
openstack%2Fcinder~master~I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64,openstack/cinder,master,I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64,glusterfs: Honor mount options when restarting cinder service,MERGED,2014-04-11 13:01:11.000000000,2014-06-23 18:40:25.000000000,2014-06-23 18:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2417}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 8874}, {'_account_id': 9067}, {'_account_id': 9366}, {'_account_id': 9751}, {'_account_id': 10725}, {'_account_id': 10796}, {'_account_id': 11651}]","[{'number': 1, 'created': '2014-04-11 13:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3025c02999b9c369f4e7e0b5247c14580840314b', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\nSigned-off-by: Deepak C Shetty <deepakcs@redhat.com>\n'}, {'number': 2, 'created': '2014-04-11 13:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00395b179ecfabb630ba60f9751c81eecf72a080', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\nSigned-off-by: Deepak C Shetty <deepakcs@redhat.com>\n'}, {'number': 3, 'created': '2014-04-24 12:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/765aeb4620d600ddedc2123f1cfdc08cc1c86197', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 4, 'created': '2014-04-24 13:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c0002a5c8c427e23a8b121245d73cb1c6c05107', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 5, 'created': '2014-04-25 12:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f5c99a31a3e2c8bdc8c0870ce03dd336ff961d4', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 6, 'created': '2014-04-28 05:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f174e0e7e6038e0c03517aa2a10e4a7fc063f6b', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 7, 'created': '2014-04-29 15:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0210c5df16691714f329fe113c7ef0cc3d39a610', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 8, 'created': '2014-05-06 12:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb230d320e8f3d8af88a050136391ffa9469499f', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 9, 'created': '2014-05-30 13:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2433959eb64756f09feea0847284446254172693', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 10, 'created': '2014-06-04 09:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/46553fa7159b44fc28c7e55580a3a09cbcb0d226', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}, {'number': 11, 'created': '2014-06-16 15:55:44.000000000', 'files': ['cinder/volume/drivers/glusterfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/df31f2ac5894e01444877b0f307ab738e74404a5', 'message': 'glusterfs: Honor mount options when restarting cinder service\n\nWhen restarting cinder service (cinder-volume specifically),\nensure that the gluster mounts are unmounted and remounted so\nthat any new mount options added to the shares config file\nis taken effect, post service restart.\n\nChange-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64\n'}]",52,86888,df31f2ac5894e01444877b0f307ab738e74404a5,93,15,11,10796,,,0,"glusterfs: Honor mount options when restarting cinder service

When restarting cinder service (cinder-volume specifically),
ensure that the gluster mounts are unmounted and remounted so
that any new mount options added to the shares config file
is taken effect, post service restart.

Change-Id: I9fe3442cd4899770b4c9ea4a73a7fe62967f2c64
",git fetch https://review.opendev.org/openstack/cinder refs/changes/88/86888/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/glusterfs.py', 'etc/cinder/rootwrap.d/volume.filters', 'cinder/volume/drivers/nfs.py']",3,3025c02999b9c369f4e7e0b5247c14580840314b,honor-mount-options," def _do_umount(self, cmd, ensure, share): """"""Finalize umount command. :param cmd: command to do the actual umount :param ensure: boolean to allow remounting a share with a warning :param share: description of the share for error reporting """""" try: self._execute(*cmd, run_as_root=True) except putils.ProcessExecutionError as exc: if ensure and 'not mounted' in exc.stderr: LOG.warn(_(""%s is already umounted""), share) else: raise ",,33,0
openstack%2Fcinder~master~I872eb477351c5406d07bbf5b748ebde2d878120a,openstack/cinder,master,I872eb477351c5406d07bbf5b748ebde2d878120a,GlusterFS: Various unit test improvements,MERGED,2014-05-19 15:28:41.000000000,2014-06-23 18:40:18.000000000,2014-06-23 18:40:17.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 11521}]","[{'number': 1, 'created': '2014-05-19 15:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/54a45531938c845caa34a43ad9945ae2955116a0', 'message': 'GlusterFS: Various unit test improvements.\n\nFixed bug that ""_ensure_share_writable"" was not mocked and therefore ""GlusterfsException"" was thrown earlier than expected with an unexpected error message.\n\nTo better guard against situations like this, I\'ve added a helper method ""assertRaisesAndMessageMatches"" to test for the thrown exception AND its message.\n\nAdded ""mox.VerifyAll()"" where it was missing and cleaned up unused mocks.\n\nFixed test for ""create_volume_from_snapshot"" (which actually tested ""create_cloned_volume"").\n\nAdded tests for driver function ""copy_volume_to_image"".\n\nOverall, code coverage for volume/drivers/glusterfs.py improved from 74% to 82%.\n\nChange-Id: I872eb477351c5406d07bbf5b748ebde2d878120a\n'}, {'number': 2, 'created': '2014-06-02 15:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5bc934978efc0f9fb4756635dc9e56f3acb6414b', 'message': 'GlusterFS: Various unit test improvements\n\nFixed bug that ""_ensure_share_writable"" was not mocked and therefore\n""GlusterfsException"" was thrown earlier than expected with an unexpected\nerror message.\n\nTo better guard against situations like this, I\'ve added a helper method\n""assertRaisesAndMessageMatches"" to test for the thrown exception AND its\nmessage.\n\nAdded ""mox.VerifyAll()"" where it was missing and cleaned up unused\nmocks.\n\nFixed test for ""create_volume_from_snapshot"" (which actually tested\n""create_cloned_volume"").\n\nAdded tests for driver function ""copy_volume_to_image"".\n\nOverall, code coverage for volume/drivers/glusterfs.py improved from 74%\nto 82%.\n\nChange-Id: I872eb477351c5406d07bbf5b748ebde2d878120a\n'}, {'number': 3, 'created': '2014-06-19 17:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d73a65c56ccd0cad0db55b795f706f7649faab12', 'message': 'GlusterFS: Various unit test improvements\n\nFixed bug that ""_ensure_share_writable"" was not mocked and therefore\n""GlusterfsException"" was thrown earlier than expected with an unexpected\nerror message.\n\nTo better guard against situations like this, I\'ve added a helper method\n""assertRaisesAndMessageMatches"" to test for the thrown exception AND its\nmessage.\n\nAdded ""mox.VerifyAll()"" where it was missing and cleaned up unused\nmocks.\n\nFixed test for ""create_volume_from_snapshot"" (which actually tested\n""create_cloned_volume"").\n\nAdded tests for driver function ""copy_volume_to_image"".\n\nOverall, code coverage for volume/drivers/glusterfs.py improved from 74%\nto 82%.\n\nChange-Id: I872eb477351c5406d07bbf5b748ebde2d878120a\n'}, {'number': 4, 'created': '2014-06-20 13:52:18.000000000', 'files': ['cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4bac3b360d7eb27cd1ac0cb8bd7821cc0a401e01', 'message': 'GlusterFS: Various unit test improvements\n\nFixed bug that ""_ensure_share_writable"" was not mocked and therefore\n""GlusterfsException"" was thrown earlier than expected with an unexpected\nerror message.\n\nTo better guard against situations like this, I\'ve added a helper method\n""assertRaisesAndMessageMatches"" to test for the thrown exception AND its\nmessage.\n\nAdded ""mox.VerifyAll()"" where it was missing and cleaned up unused\nmocks.\n\nFixed test for ""create_volume_from_snapshot"" (which actually tested\n""create_cloned_volume"").\n\nAdded tests for driver function ""copy_volume_to_image"".\n\nOverall, code coverage for volume/drivers/glusterfs.py improved from 74%\nto 82%.\n\nChange-Id: I872eb477351c5406d07bbf5b748ebde2d878120a\n'}]",6,94211,4bac3b360d7eb27cd1ac0cb8bd7821cc0a401e01,52,7,4,11521,,,0,"GlusterFS: Various unit test improvements

Fixed bug that ""_ensure_share_writable"" was not mocked and therefore
""GlusterfsException"" was thrown earlier than expected with an unexpected
error message.

To better guard against situations like this, I've added a helper method
""assertRaisesAndMessageMatches"" to test for the thrown exception AND its
message.

Added ""mox.VerifyAll()"" where it was missing and cleaned up unused
mocks.

Fixed test for ""create_volume_from_snapshot"" (which actually tested
""create_cloned_volume"").

Added tests for driver function ""copy_volume_to_image"".

Overall, code coverage for volume/drivers/glusterfs.py improved from 74%
to 82%.

Change-Id: I872eb477351c5406d07bbf5b748ebde2d878120a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/94211/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_glusterfs.py'],1,54a45531938c845caa34a43ad9945ae2955116a0,glusterfs_unit_test_various_fixes,"import time import traceback def assertRaisesAndMessageMatches( self, excClass, msg, callableObj, *args, **kwargs): """"""Ensure that the specified exception was raised and its message includes the string 'msg'. """""" caught = False try: callableObj(*args, **kwargs) except Exception as exc: caught = True self.assertEqual(excClass, type(exc), 'Wrong exception caught: %s Stacktrace: %s' % (exc, traceback.print_exc())) self.assertIn(msg, str(exc)) if not caught: self.fail('Expected raised exception but nothing caught.') mox.VerifyAll() mox.VerifyAll() drv.configuration.glusterfs_shares_config = None self.assertRaisesAndMessageMatches(exception.GlusterfsException, 'no Gluster config file configured', drv.do_setup, IsA(context.RequestContext)) self.assertRaisesAndMessageMatches(exception.GlusterfsException, 'mount.glusterfs is not installed', drv.do_setup, IsA(context.RequestContext)) mox.VerifyAll() # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) mox.VerifyAll() # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_99p = snap_ref_progress.copy() snap_ref_progress_99p['progress'] = '99%' snap_ref_progress_99p['status'] = 'error' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_99p) self.assertRaisesAndMessageMatches( exception.GlusterfsException, 'Nova returned ""error"" status while creating snapshot.', drv.create_snapshot, snap_ref) mox.VerifyAll() # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) mox.VerifyAll() # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) mox.VerifyAll() volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') mox.StubOutWithMock(drv, '_ensure_share_writable') drv._ensure_share_writable(volume_dir) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) 'file_to_merge': None, snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['status'] = 'error_deleting' snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) self.assertRaisesAndMessageMatches(exception.GlusterfsException, 'Unable to delete snapshot', drv.delete_snapshot, snap_ref) mox.VerifyAll() mox.VerifyAll() mox.VerifyAll() 'volume': src_volume, 'status': 'available'} new_volume = DumbVolume() new_volume['size'] = snap_ref['size'] mox.StubOutWithMock(drv, '_ensure_shares_mounted') mox.StubOutWithMock(drv, '_find_share') mox.StubOutWithMock(drv, '_do_create_volume') mox.StubOutWithMock(drv, '_copy_volume_from_snapshot') drv._ensure_shares_mounted() drv._find_share(new_volume['size']).AndReturn(self.TEST_EXPORT1) drv._do_create_volume(new_volume) new_volume, new_volume['size']) drv.create_volume_from_snapshot(new_volume, snap_ref) mox.VerifyAll() mox.VerifyAll() mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) mox.VerifyAll() mox.StubOutWithMock(drv, '_qemu_img_info') drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) mox.VerifyAll() mox.VerifyAll() mox.VerifyAll() mox.VerifyAll() def test_copy_volume_to_image_raw_image(self): drv = self._driver volume = self._simple_volume() volume_path = '%s/%s' % (self.TEST_MNT_POINT, volume['name']) with contextlib.nested( mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_local_volume_dir'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(image_utils, 'upload_volume') ) as (mock_get_active_image_from_info, mock_local_volume_dir, mock_qemu_img_info, mock_upload_volume): mock_get_active_image_from_info.return_value = volume['name'] mock_local_volume_dir.return_value = self.TEST_MNT_POINT qemu_img_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume['name'] img_info = imageutils.QemuImgInfo(qemu_img_output) mock_qemu_img_info.return_value = img_info upload_path = volume_path drv.copy_volume_to_image(mock.ANY, volume, mock.ANY, mock.ANY) mock_get_active_image_from_info.assert_called_once_with(volume) mock_local_volume_dir.assert_called_once_with(volume) mock_qemu_img_info.assert_called_once_with(volume_path) mock_upload_volume.assert_called_once_with( mock.ANY, mock.ANY, mock.ANY, upload_path) def test_copy_volume_to_image_qcow2_image(self): """"""Upload a qcow2 image file which has to be converted to raw first."""""" drv = self._driver volume = self._simple_volume() volume_path = '%s/%s' % (self.TEST_MNT_POINT, volume['name']) image_meta = {'id': '10958016-e196-42e3-9e7f-5d8927ae3099'} with contextlib.nested( mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_local_volume_dir'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(image_utils, 'convert_image'), mock.patch.object(image_utils, 'upload_volume'), mock.patch.object(drv, '_execute') ) as (mock_get_active_image_from_info, mock_local_volume_dir, mock_qemu_img_info, mock_convert_image, mock_upload_volume, mock_execute): mock_get_active_image_from_info.return_value = volume['name'] mock_local_volume_dir.return_value = self.TEST_MNT_POINT qemu_img_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume['name'] img_info = imageutils.QemuImgInfo(qemu_img_output) mock_qemu_img_info.return_value = img_info upload_path = '%s/%s.temp_image.%s' % (self.TEST_MNT_POINT, volume['id'], image_meta['id']) drv.copy_volume_to_image(mock.ANY, volume, mock.ANY, image_meta) mock_get_active_image_from_info.assert_called_once_with(volume) mock_local_volume_dir.assert_called_with(volume) mock_qemu_img_info.assert_called_once_with(volume_path) mock_convert_image.assert_called_once_with( volume_path, upload_path, 'raw') mock_upload_volume.assert_called_once_with( mock.ANY, mock.ANY, mock.ANY, upload_path) mock_execute.assert_called_once_with('rm', '-f', upload_path) def test_copy_volume_to_image_snapshot_exists(self): """"""Upload an active snapshot which has to be converted to raw first."""""" drv = self._driver volume = self._simple_volume() volume_path = '%s/volume-%s' % (self.TEST_MNT_POINT, self.VOLUME_UUID) volume_filename = 'volume-%s' % self.VOLUME_UUID image_meta = {'id': '10958016-e196-42e3-9e7f-5d8927ae3099'} with contextlib.nested( mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_local_volume_dir'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(image_utils, 'convert_image'), mock.patch.object(image_utils, 'upload_volume'), mock.patch.object(drv, '_execute') ) as (mock_get_active_image_from_info, mock_local_volume_dir, mock_qemu_img_info, mock_convert_image, mock_upload_volume, mock_execute): mock_get_active_image_from_info.return_value = volume['name'] mock_local_volume_dir.return_value = self.TEST_MNT_POINT qemu_img_output = """"""image: volume-%s.%s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (self.VOLUME_UUID, self.SNAP_UUID, volume_filename) img_info = imageutils.QemuImgInfo(qemu_img_output) mock_qemu_img_info.return_value = img_info upload_path = '%s/%s.temp_image.%s' % (self.TEST_MNT_POINT, volume['id'], image_meta['id']) drv.copy_volume_to_image(mock.ANY, volume, mock.ANY, image_meta) mock_get_active_image_from_info.assert_called_once_with(volume) mock_local_volume_dir.assert_called_with(volume) mock_qemu_img_info.assert_called_once_with(volume_path) mock_convert_image.assert_called_once_with( volume_path, upload_path, 'raw') mock_upload_volume.assert_called_once_with( mock.ANY, mock.ANY, mock.ANY, upload_path) mock_execute.assert_called_once_with('rm', '-f', upload_path)"," CONF.set_override(""glusterfs_shares_config"", self.TEST_SHARES_CONFIG_FILE) self.assertRaises(exception.GlusterfsException, drv.do_setup, IsA(context.RequestContext)) self.assertRaises(exception.GlusterfsException, drv.do_setup, IsA(context.RequestContext)) volume_file = 'volume-%s' % self.VOLUME_UUID volume_path = '%s/%s/%s' % (self.TEST_MNT_POINT_BASE, drv._get_hash_str(self.TEST_EXPORT1), volume_file) volume_file = 'volume-%s' % src_vref['id'] volume_path = '%s/%s/%s' % (self.TEST_MNT_POINT_BASE, drv._get_hash_str(self.TEST_EXPORT1), volume_file) src_info_path = '%s.info' % volume_path snap_info = {'active': volume_file, snap_ref['id']: volume_path + '-clone'} drv._read_info_file(src_info_path).AndReturn(snap_info) snap_ref['status'] = 'creating' snap_ref['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) info_path = '%s.info' % volume_path snap_ref['status'] = 'creating' snap_ref['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '99%' snap_ref['status'] = 'error' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_info = {'active': snap_file, self.SNAP_UUID: snap_file} drv._write_info_file(info_path, snap_info) self.assertRaises(exception.GlusterfsException, drv.create_snapshot, snap_ref) mox.StubOutWithMock(os.path, 'exists') os.path.exists(snap_path).AndReturn(True) snap_ref['status'] = 'deleting' snap_ref['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) mox.StubOutWithMock(os.path, 'exists') os.path.exists(snap_path).AndReturn(True) snap_ref['status'] = 'deleting' snap_ref['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) mox.StubOutWithMock(drv, '_write_info_file') mox.StubOutWithMock(os.path, 'exists') os.path.exists(snap_path).AndReturn(True) 'file_to_merge': volume_file, snap_ref['status'] = 'deleting' snap_ref['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) snap_ref['status'] = 'error_deleting' snap_ref['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref) drv._write_info_file(info_path, snap_info) drv._execute('rm', '-f', volume_path, run_as_root=True) self.assertRaises(exception.GlusterfsException, drv.delete_snapshot, snap_ref) mox.StubOutWithMock(drv, '_execute') drv._local_volume_dir(volume).AndReturn(vol_dir) volume = self._simple_volume('c1073000-0000-0000-0000-0000000c1073') mox.StubOutWithMock(drv, '_create_snapshot') mox.StubOutWithMock(drv, '_copy_volume_from_snapshot') mox.StubOutWithMock(drv, '_delete_snapshot') 'volume': src_volume} volume_ref = {'id': volume['id'], 'size': volume['size'], 'status': volume['status'], 'provider_location': volume['provider_location'], 'name': 'volume-' + volume['id']} drv._create_snapshot(snap_ref) volume_ref, src_volume['size']) drv._delete_snapshot(snap_ref) drv.create_cloned_volume(volume, src_volume) mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') mox.StubOutWithMock(drv, '_read_info_file') drv._read_info_file(IgnoreArg(), empty_if_missing=True).AndReturn({}) drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(drv, '_read_info_file') drv._read_info_file(IgnoreArg(), empty_if_missing=True).AndReturn( {'active': 'file2'}) drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') base_driver.VolumeDriver.backup_volume(IgnoreArg(), IgnoreArg(), IgnoreArg()) mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') drv._read_info_file(IgnoreArg(), empty_if_missing=True).AndReturn( {'id1': 'file1', 'id2': 'file2', 'active': 'file2'}) base_driver.VolumeDriver.backup_volume(IgnoreArg(), IgnoreArg(), IgnoreArg()) mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') mox.StubOutWithMock(drv, '_read_info_file') drv._read_info_file(IgnoreArg(), empty_if_missing=True).AndReturn({}) base_driver.VolumeDriver.backup_volume(IgnoreArg(), IgnoreArg(), IgnoreArg()) ",306,140
openstack%2Fnova~master~I88f8d31074d7547649c242a023b18143a0092fea,openstack/nova,master,I88f8d31074d7547649c242a023b18143a0092fea,Correct the variable name in trusted filter,MERGED,2014-06-23 03:39:51.000000000,2014-06-23 18:40:08.000000000,2014-06-23 18:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 03:39:51.000000000', 'files': ['nova/scheduler/filters/trusted_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3a0a5398453a9496b82a4c9e7ed17a4210cf7bbb', 'message': 'Correct the variable name in trusted filter\n\nRename instance to instance_type to avoid misunderstanding\n\nChange-Id: I88f8d31074d7547649c242a023b18143a0092fea\n'}]",0,101793,3a0a5398453a9496b82a4c9e7ed17a4210cf7bbb,13,8,1,9407,,,0,"Correct the variable name in trusted filter

Rename instance to instance_type to avoid misunderstanding

Change-Id: I88f8d31074d7547649c242a023b18143a0092fea
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/101793/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/trusted_filter.py'],1,3a0a5398453a9496b82a4c9e7ed17a4210cf7bbb,typo," instance_type = filter_properties.get('instance_type', {}) extra = instance_type.get('extra_specs', {})"," instance = filter_properties.get('instance_type', {}) extra = instance.get('extra_specs', {})",2,2
openstack%2Fkeystone~master~I87a7478949114163f0614b1a6d8b249e14afe0df,openstack/keystone,master,I87a7478949114163f0614b1a6d8b249e14afe0df,Make gen_pki.sh & debug_helper.sh bash8 compliant,MERGED,2014-05-13 14:04:33.000000000,2014-06-23 18:39:44.000000000,2014-06-23 18:39:44.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-05-13 14:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0217a435716eeef59453db6b7e48724c95703822', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 2, 'created': '2014-05-13 14:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/faaa9c5794c339ef03de70baebdb5308ceabd884', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 3, 'created': '2014-05-13 21:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f72676f1ab73747540ca7b9d891e2ddef2da27a', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 4, 'created': '2014-06-02 19:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5e5415738d329f824a0f087217e42881de02113c', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 5, 'created': '2014-06-13 15:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e18e31a5a0d8aef4dc845aae712ad28ba272dd2d', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 6, 'created': '2014-06-23 15:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8f1d9ff9959adfbb39a431cdbe80ddcf4cb7df5', 'message': 'Make gen_pki.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}, {'number': 7, 'created': '2014-06-23 15:42:56.000000000', 'files': ['test-requirements.txt', 'examples/pki/gen_pki.sh', 'tools/debug_helper.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/491b29bed84db2156f2b0eec01c929cb9d8b13b6', 'message': 'Make gen_pki.sh & debug_helper.sh bash8 compliant\n\nNow that bash8 is available on PyPI we can use it to clean up the bash\nscripts in Keystone. This also uses bash8 in tox. For now we can add\nfiles to the tox check manually as we make them compliant.\n\nChange-Id: I87a7478949114163f0614b1a6d8b249e14afe0df\n'}]",3,93438,491b29bed84db2156f2b0eec01c929cb9d8b13b6,42,7,7,5046,,,0,"Make gen_pki.sh & debug_helper.sh bash8 compliant

Now that bash8 is available on PyPI we can use it to clean up the bash
scripts in Keystone. This also uses bash8 in tox. For now we can add
files to the tox check manually as we make them compliant.

Change-Id: I87a7478949114163f0614b1a6d8b249e14afe0df
",git fetch https://review.opendev.org/openstack/keystone refs/changes/38/93438/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/pki/gen_pki.sh'],1,0217a435716eeef59453db6b7e48724c95703822,bash8-cleanup," rm -rf $CERTS_DIR/*.pem rm -rf $PRIVATE_DIR/*.pem rm -rf *.conf > /dev/null 2>&1 rm -rf index* > /dev/null 2>&1 rm -rf *.crt > /dev/null 2>&1 rm -rf newcerts > /dev/null 2>&1 rm -rf *.pem > /dev/null 2>&1 rm -rf serial* > /dev/null 2>&1 echo ' echo ' echo ' echo ' touch index.txt echo '10' > serial generate_ca_conf mkdir newcerts if [ $1 != 0 ] ; then echo ""Failed! rc=${1}"" echo 'Bailing ...' cleanup exit $1 else echo 'Done' fi echo 'Generating New CA Certificate ...' openssl req -x509 -newkey rsa:2048 -days 21360 -out $CERTS_DIR/cacert.pem -keyout $PRIVATE_DIR/cakey.pem -outform PEM -config ca.conf -nodes check_error $? echo 'Generating SSL Certificate Request ...' generate_ssl_req_conf openssl req -newkey rsa:2048 -keyout $PRIVATE_DIR/ssl_key.pem -keyform PEM -out ssl_req.pem -outform PEM -config ssl_req.conf -nodes check_error $? #openssl req -in req.pem -text -noout echo 'Generating CMS Signing Certificate Request ...' generate_cms_signing_req_conf openssl req -newkey rsa:2048 -keyout $PRIVATE_DIR/signing_key.pem -keyform PEM -out cms_signing_req.pem -outform PEM -config cms_signing_req.conf -nodes check_error $? #openssl req -in req.pem -text -noout generate_signing_conf echo 'Issuing SSL Certificate ...' openssl ca -in ssl_req.pem -config signing.conf -batch check_error $? openssl x509 -in $CURRENT_DIR/newcerts/10.pem -out $CERTS_DIR/ssl_cert.pem check_error $? echo 'Issuing CMS Signing Certificate ...' openssl ca -in cms_signing_req.pem -config signing.conf -batch check_error $? openssl x509 -in $CURRENT_DIR/newcerts/11.pem -out $CERTS_DIR/signing_cert.pem check_error $? cp $CERTS_DIR/ssl_cert.pem $CERTS_DIR/middleware.pem cat $PRIVATE_DIR/ssl_key.pem >> $CERTS_DIR/middleware.pem echo 'Checking openssl availability ...' which openssl check_error $? for json_file in ""${CMS_DIR}/auth_token_revoked.json"" ""${CMS_DIR}/auth_token_unscoped.json"" ""${CMS_DIR}/auth_token_scoped.json"" ""${CMS_DIR}/revocation_list.json""; do openssl cms -sign -in $json_file -nosmimecap -signer $CERTS_DIR/signing_cert.pem -inkey $PRIVATE_DIR/signing_key.pem -outform PEM -nodetach -nocerts -noattr -out ${json_file/.json/.pem} done"," rm -rf $CERTS_DIR/*.pem rm -rf $PRIVATE_DIR/*.pem rm -rf *.conf > /dev/null 2>&1 rm -rf index* > /dev/null 2>&1 rm -rf *.crt > /dev/null 2>&1 rm -rf newcerts > /dev/null 2>&1 rm -rf *.pem > /dev/null 2>&1 rm -rf serial* > /dev/null 2>&1 echo ' echo ' echo ' echo ' touch index.txt echo '10' > serial generate_ca_conf mkdir newcerts if [ $1 != 0 ] ; then echo ""Failed! rc=${1}"" echo 'Bailing ...' cleanup exit $1 else echo 'Done' fi echo 'Generating New CA Certificate ...' openssl req -x509 -newkey rsa:2048 -days 21360 -out $CERTS_DIR/cacert.pem -keyout $PRIVATE_DIR/cakey.pem -outform PEM -config ca.conf -nodes check_error $? echo 'Generating SSL Certificate Request ...' generate_ssl_req_conf openssl req -newkey rsa:2048 -keyout $PRIVATE_DIR/ssl_key.pem -keyform PEM -out ssl_req.pem -outform PEM -config ssl_req.conf -nodes check_error $? #openssl req -in req.pem -text -noout echo 'Generating CMS Signing Certificate Request ...' generate_cms_signing_req_conf openssl req -newkey rsa:2048 -keyout $PRIVATE_DIR/signing_key.pem -keyform PEM -out cms_signing_req.pem -outform PEM -config cms_signing_req.conf -nodes check_error $? #openssl req -in req.pem -text -noout generate_signing_conf echo 'Issuing SSL Certificate ...' openssl ca -in ssl_req.pem -config signing.conf -batch check_error $? openssl x509 -in $CURRENT_DIR/newcerts/10.pem -out $CERTS_DIR/ssl_cert.pem check_error $? echo 'Issuing CMS Signing Certificate ...' openssl ca -in cms_signing_req.pem -config signing.conf -batch check_error $? openssl x509 -in $CURRENT_DIR/newcerts/11.pem -out $CERTS_DIR/signing_cert.pem check_error $? cp $CERTS_DIR/ssl_cert.pem $CERTS_DIR/middleware.pem cat $PRIVATE_DIR/ssl_key.pem >> $CERTS_DIR/middleware.pem echo 'Checking openssl availability ...' which openssl check_error $? for json_file in ""${CMS_DIR}/auth_token_revoked.json"" ""${CMS_DIR}/auth_token_unscoped.json"" ""${CMS_DIR}/auth_token_scoped.json"" ""${CMS_DIR}/revocation_list.json"" do openssl cms -sign -in $json_file -nosmimecap -signer $CERTS_DIR/signing_cert.pem -inkey $PRIVATE_DIR/signing_key.pem -outform PEM -nodetach -nocerts -noattr -out ${json_file/.json/.pem} done",56,57
openstack%2Foslo.i18n~master~I33f358912802fb1bd49ed377d974af9e213b9257,openstack/oslo.i18n,master,I33f358912802fb1bd49ed377d974af9e213b9257,Remove Babel version workaround code,MERGED,2014-06-06 22:12:10.000000000,2014-06-23 18:39:42.000000000,2014-06-23 18:39:42.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6486}, {'_account_id': 6601}, {'_account_id': 6928}, {'_account_id': 9107}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-06-06 22:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/aba7a7d4f2c7ec70e737559ea5344667b6e7eccb', 'message': 'Remove Babel version workaround code\n\nSince Babel>=1.3 is required, code to work with earlier versions\ncan be removed and the logic made clearer.\n\nChange-Id: I33f358912802fb1bd49ed377d974af9e213b9257\n'}, {'number': 2, 'created': '2014-06-11 20:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/47b37e4edfa29f4c7e6b5acda419559615252a35', 'message': 'Remove Babel version workaround code\n\nSince Babel>=1.3 is required, code to work with earlier versions\ncan be removed and the logic made clearer.\n\nChange-Id: I33f358912802fb1bd49ed377d974af9e213b9257\n'}, {'number': 3, 'created': '2014-06-11 20:46:47.000000000', 'files': ['oslo/i18n/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/324a99cd7969d9081dd74b4decdb4f61a6eae6e1', 'message': 'Remove Babel version workaround code\n\nSince Babel>=1.3 is required, code to work with earlier versions\ncan be removed and the logic made clearer.\n\nChange-Id: I33f358912802fb1bd49ed377d974af9e213b9257\n'}]",0,98542,324a99cd7969d9081dd74b4decdb4f61a6eae6e1,34,14,3,6486,,,0,"Remove Babel version workaround code

Since Babel>=1.3 is required, code to work with earlier versions
can be removed and the logic made clearer.

Change-Id: I33f358912802fb1bd49ed377d974af9e213b9257
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/42/98542/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo/i18n/gettextutils.py'],1,aba7a7d4f2c7ec70e737559ea5344667b6e7eccb,bp/graduate-oslo-i18n," for i in localedata.locale_identifiers(): # In Babel 1.3, locale_identifiers() doesn't list some OpenStack supported # locales (e.g. 'zh_CN', and 'zh_TW') so we add the locales explicitly if # necessary so that they are listed as supported."," # NOTE(luisg): Babel <1.0 used a function called list(), which was # renamed to locale_identifiers() in >=1.0, the requirements master list # requires >=0.9.6, uncapped, so defensively work with both. We can remove # this check when the master list updates to >=1.0, and update all projects list_identifiers = (getattr(localedata, 'list', None) or getattr(localedata, 'locale_identifiers')) locale_identifiers = list_identifiers() for i in locale_identifiers: # NOTE(luisg): Babel>=1.0,<1.3 has a bug where some OpenStack supported # locales (e.g. 'zh_CN', and 'zh_TW') aren't supported even though they # are perfectly legitimate locales: # https://github.com/mitsuhiko/babel/issues/37 # In Babel 1.3 they fixed the bug and they support these locales, but # they are still not explicitly ""listed"" by locale_identifiers(). # That is why we add the locales here explicitly if necessary so that # they are listed as supported.",4,16
openstack%2Fcinder~stable%2Fhavana~Id6a69644505ca10811db458ea90ed10f643054b2,openstack/cinder,stable/havana,Id6a69644505ca10811db458ea90ed10f643054b2,Returns thin pool free space calculated from actual usage,MERGED,2013-12-09 21:38:47.000000000,2014-06-23 18:39:35.000000000,2014-06-23 18:39:34.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6796}, {'_account_id': 7198}, {'_account_id': 7236}, {'_account_id': 8574}]","[{'number': 1, 'created': '2013-12-09 21:38:47.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c6a854f6adbad0efb9ca137bd5d7baaf5f1fb5a', 'message': 'Returns thin pool free space calculated from actual usage\n\nThis change adds a hidden method which calculates the thin\npool free space from the data_percent LVM options and reports it\naccordingly in _update_volume_stats()\n\nChange-Id: Id6a69644505ca10811db458ea90ed10f643054b2\nCloses-Bug: 1249782\n(cherry picked from commit 1679acd53d1f0c330edf583afe8b347a7304499c)\n'}]",0,60948,4c6a854f6adbad0efb9ca137bd5d7baaf5f1fb5a,18,9,1,4523,,,0,"Returns thin pool free space calculated from actual usage

This change adds a hidden method which calculates the thin
pool free space from the data_percent LVM options and reports it
accordingly in _update_volume_stats()

Change-Id: Id6a69644505ca10811db458ea90ed10f643054b2
Closes-Bug: 1249782
(cherry picked from commit 1679acd53d1f0c330edf583afe8b347a7304499c)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/48/60948/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py', 'cinder/volume/drivers/lvm.py']",3,4c6a854f6adbad0efb9ca137bd5d7baaf5f1fb5a,bug/1249782, if self.configuration.lvm_type == 'thin': data['total_capacity_gb'] = float(self.vg.vg_thin_pool_size) data['free_capacity_gb'] = float(self.vg.vg_thin_pool_free_space),,52,0
openstack%2Fcinder~stable%2Fhavana~Id461445780c1574db316ede0c0194736e71640d0,openstack/cinder,stable/havana,Id461445780c1574db316ede0c0194736e71640d0,LVM: Create thin pools of adequate size,MERGED,2013-12-09 21:31:38.000000000,2014-06-23 18:39:27.000000000,2014-06-23 18:39:27.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 8574}, {'_account_id': 9236}, {'_account_id': 10725}]","[{'number': 1, 'created': '2013-12-09 21:31:38.000000000', 'files': ['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0553eb601fd8a1d0d365d8a4858a771efb034442', 'message': ""LVM: Create thin pools of adequate size\n\nThin pools in LVM are quite different from volume groups or logical\nvolumes and their differences must be taken into account when providing\nthin LVM support in Cinder.\n\nWhen you create a thin pool, LVM actually creates 4 block devices.  You\ncan see this after thin pool creation with the following command:\n\n    $ dmsetup ls\n\n    volumes--1-volumes--1--pool       (253:4)\n    volumes--1-volumes--1--pool-tpool (253:3)\n    volumes--1-volumes--1--pool_tdata (253:2)\n    volumes--1-volumes--1--pool_tmeta (253:1)\n\nIn the above command, a thin pool named 'volumes-1-pool' was created in\nthe 'volumes-1' volume group.  Despite this, the 'lvs' command will only\nshow one logical volume for the thin pool, which can be misleading if\nyou aren't aware of how thin pools are implemented.\n\nWhen you create a thin pool, you specify on the command line a size for\nthe pool.  LVM will interpret this size as the amount of space requested\nto store data blocks only.  In order to allow volume sharing and\nsnapshots, some amount of metadata must be reserved in addition to the\ndata request.  This amount is calculated by LVM internally and varies\ndepending on volume size and chunksize.  This is why one cannot simply\nallocate 100% of a volume group to a thin pool - there must be some\nremaining space for metadata or you will not be able to create volumes\nand snapshots that are pool-backed.\n\nThis patch allocates 95% of a volume group's free space to the thin\npool.  By doing this, we allow LVM to successfully allocate a region for\nmetadata.  Additionally, any free space remaining will by dynamically\nused by either data or metadata if capacity should become scarce.\n\nThe 95/5 split seems like a sane default.  This split can easily (and\nprobably should) be made user-configurable in the future if the user\nexpects an abnormal amount of volume sharing.\n\nChange-Id: Id461445780c1574db316ede0c0194736e71640d0\nCloses-Bug: #1245909\n(cherry picked from commit d72914f739b1467ad849dd47fddd321965fed928)\n""}]",13,60947,0553eb601fd8a1d0d365d8a4858a771efb034442,74,9,1,9236,,,0,"LVM: Create thin pools of adequate size

Thin pools in LVM are quite different from volume groups or logical
volumes and their differences must be taken into account when providing
thin LVM support in Cinder.

When you create a thin pool, LVM actually creates 4 block devices.  You
can see this after thin pool creation with the following command:

    $ dmsetup ls

    volumes--1-volumes--1--pool       (253:4)
    volumes--1-volumes--1--pool-tpool (253:3)
    volumes--1-volumes--1--pool_tdata (253:2)
    volumes--1-volumes--1--pool_tmeta (253:1)

In the above command, a thin pool named 'volumes-1-pool' was created in
the 'volumes-1' volume group.  Despite this, the 'lvs' command will only
show one logical volume for the thin pool, which can be misleading if
you aren't aware of how thin pools are implemented.

When you create a thin pool, you specify on the command line a size for
the pool.  LVM will interpret this size as the amount of space requested
to store data blocks only.  In order to allow volume sharing and
snapshots, some amount of metadata must be reserved in addition to the
data request.  This amount is calculated by LVM internally and varies
depending on volume size and chunksize.  This is why one cannot simply
allocate 100% of a volume group to a thin pool - there must be some
remaining space for metadata or you will not be able to create volumes
and snapshots that are pool-backed.

This patch allocates 95% of a volume group's free space to the thin
pool.  By doing this, we allow LVM to successfully allocate a region for
metadata.  Additionally, any free space remaining will by dynamically
used by either data or metadata if capacity should become scarce.

The 95/5 split seems like a sane default.  This split can easily (and
probably should) be made user-configurable in the future if the user
expects an abnormal amount of volume sharing.

Change-Id: Id461445780c1574db316ede0c0194736e71640d0
Closes-Bug: #1245909
(cherry picked from commit d72914f739b1467ad849dd47fddd321965fed928)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/47/60947/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/tests/brick/test_brick_lvm.py']",2,0553eb601fd8a1d0d365d8a4858a771efb034442,," def test_thin_pool_creation(self): # The size of fake-volumes volume group is 10g, so the calculated thin # pool size should be 9.5g (95% of 10g). self.assertEqual(""9.5g"", self.vg.create_thin_pool()) # Passing a size parameter should result in a thin pool of that exact # size. for size in (""1g"", ""1.2g"", ""1.75g""): self.assertEqual(size, self.vg.create_thin_pool(size_str=size)) ",,40,9
openstack%2Fneutron~master~I801d967e8e3c0260593f289097d17270ef0b391e,openstack/neutron,master,I801d967e8e3c0260593f289097d17270ef0b391e,Improve vxlan type driver initialization performance,MERGED,2014-06-04 12:45:08.000000000,2014-06-23 18:39:03.000000000,2014-06-23 18:39:02.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6788}, {'_account_id': 6849}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7805}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11114}]","[{'number': 1, 'created': '2014-06-04 12:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44b96003813291e9b5e97f225a49f9cb40b3cfca', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 2, 'created': '2014-06-04 14:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e44c82e1bc653d866a147c5e68481620ccb0d340', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 3, 'created': '2014-06-04 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a555ddd037eb695a2f6c8951ca758500edec59c0', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 4, 'created': '2014-06-04 15:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cacdd1cea9e0d3ccedb72e42ba76109f4df7e1f', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 5, 'created': '2014-06-06 10:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/428e8960d6bea4dda0be66bd6dca8d333c6ce9df', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements.\nAlso optimize deleting logic.\n\nProposed patch gives ~2x performance gain in comparison with\noriginal code on Mysql and Postgesql backends\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 6, 'created': '2014-06-09 14:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9831f0ed43be2344c593b0ecf36dd0913ea52534', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements.\nAlso optimize deleting logic.\n\nProposed patch gives ~2x performance gain in comparison with\noriginal code on Mysql and Postgesql backends\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 7, 'created': '2014-06-10 09:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b46dc7a9fc6d0165a9d0103dbf624f3564e34d6', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements.\nAlso optimize deleting logic.\n\nProposed patch gives ~2x performance gain in comparison with\noriginal code on Mysql and Postgesql backends\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}, {'number': 8, 'created': '2014-06-11 10:14:17.000000000', 'files': ['neutron/plugins/ml2/drivers/type_vxlan.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e2fce563ab250d4bfe000dd2a2dbc00f094141b', 'message': 'Improve vxlan type driver initialization performance\n\nVxlan type driver may take long time to initialize\nvxlan allocation table. Optimize db performance by issuing\nraw sql inserts coalesced into bulk statements.\nAlso optimize deleting logic.\n\nProposed patch gives ~2x performance gain in comparison with\noriginal code on Mysql and Postgesql backends\n\nChange-Id: I801d967e8e3c0260593f289097d17270ef0b391e\nPartial-Bug: #1324875\n'}]",47,97774,6e2fce563ab250d4bfe000dd2a2dbc00f094141b,184,30,8,6072,,,0,"Improve vxlan type driver initialization performance

Vxlan type driver may take long time to initialize
vxlan allocation table. Optimize db performance by issuing
raw sql inserts coalesced into bulk statements.
Also optimize deleting logic.

Proposed patch gives ~2x performance gain in comparison with
original code on Mysql and Postgesql backends

Change-Id: I801d967e8e3c0260593f289097d17270ef0b391e
Partial-Bug: #1324875
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/97774/7 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/type_vxlan.py'],1,44b96003813291e9b5e97f225a49f9cb40b3cfca,bug/1324875-slow-vxlan-init," sorted_vnis = sorted(vxlan_vnis) # based on some testing with UTs (sqlite), # bulk size of 15-20 is the value from which # benefit doesn't increase. bulk_size = 20 for vni_list in [sorted_vnis[i:i + bulk_size] for i in range(0, len(sorted_vnis), bulk_size)]: # TODO(enikanorov): have to be db backend-specific here # as not all dbs support 0 for boolean columns bulk = "","".join(""(%s, 0)"" % str(vni) for vni in vni_list) session.execute(""INSERT INTO ml2_vxlan_allocations"" ""(vxlan_vni, allocated) VALUES %s"" % bulk)", # add missing allocatable tunnels to table for vxlan_vni in sorted(vxlan_vnis): alloc = VxlanAllocation(vxlan_vni=vxlan_vni) session.add(alloc),12,4
openstack%2Fneutron~master~I9abfac17a74d298f1a17a0931fc98ac00234ac0b,openstack/neutron,master,I9abfac17a74d298f1a17a0931fc98ac00234ac0b,changes ovs agent_id init to use hostname instead of mac,MERGED,2014-05-23 10:59:14.000000000,2014-06-23 18:38:54.000000000,2014-06-23 18:38:53.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7729}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 11604}, {'_account_id': 11825}]","[{'number': 1, 'created': '2014-05-23 10:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a8f634ee26784a57570eb64406b7bb46306dac8', 'message': 'impements blueprint https://blueprints.launchpad.net/neutron/+spec/hostname-based-ovs-agent-id\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch the proposal is to change the  generation of the  agent_id to use the hostname instead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents the hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved as it will be easier to identify which node the log is from if log aggregation is preformed across a cluster.\n\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 2, 'created': '2014-05-28 13:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6f6ca16672491d7edd4eb53ea2ddac9f1a911db', 'message': 'changes ovs agent_id init to use hostname instead of mac.\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch the proposal is to change the  generation of the  agent_id to use the hostname instead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents the hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved as it will be easier to identify which node the log is from if log aggregation is preformed across a cluster.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 3, 'created': '2014-05-28 14:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90e922ec85c814f53712c9c829b49fd8c374ee2a', 'message': 'changes ovs agent_id init to use hostname instead of mac.\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 4, 'created': '2014-05-30 09:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f1f866dae06405aef36e26b1b4de941d9693a59', 'message': 'changes ovs agent_id init to use hostname instead of mac.\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 5, 'created': '2014-05-30 11:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/028bd1ad6dd76d2e3bbf1f260202686ba7be23e0', 'message': 'changes ovs agent_id init to use hostname instead of mac\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 6, 'created': '2014-06-03 17:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f803e6173a4ab557c180b7511e27d401e5b1654', 'message': 'changes ovs agent_id init to use hostname instead of mac.\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 7, 'created': '2014-06-04 08:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f8a99d99bf882eac211e424f458640dfb07f0be', 'message': 'changes ovs agent_id init to use hostname instead of mac\n\nTo enable reuse of the ovs agent with the Intel DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrive from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n'}, {'number': 8, 'created': '2014-06-10 11:04:32.000000000', 'files': ['neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/744c1bd2f1ae1caf3cd6d0c07d61b034a21204bc', 'message': ""changes ovs agent_id init to use hostname instead of mac\n\nIn the Open vSwitch agent,\nthe Agent id is currently based off the mac address of the br-int.\nUserspace only Open vSwitch derivatives such as Intel's DPDK\nAccelerated Open vSwitch do not currently create a tap device in the kernel\nto back the ovs bridges local port.\nThis limitation prevents reuse of the OpenVSwitch agent between both switches.\n\nTo enable reuse of the ovs agent with Intel's DPDK Accelerated Open vSwitch,\nthe proposal is to change the  generation of the  agent_id to use the hostname,\ninstead of the mac address of the br-int.\n\nFor several plugins such as the nec,mlnx,hyperv and onconvergence agents\nthe hostname is used to create the agent id.\nUsing the hostname will normalise the agent_id between these 5 neutron agents,\nadditionally log readability will also be improved,\nif log aggregation is preformed across a cluster\nas it will be easier to identify which node the log is from.\n\nthe hostname is retrived from cfg.CONF.host\n\nCloses-Bug: #1323259\nChange-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b\n""}]",14,95138,744c1bd2f1ae1caf3cd6d0c07d61b034a21204bc,176,24,8,11604,,,0,"changes ovs agent_id init to use hostname instead of mac

In the Open vSwitch agent,
the Agent id is currently based off the mac address of the br-int.
Userspace only Open vSwitch derivatives such as Intel's DPDK
Accelerated Open vSwitch do not currently create a tap device in the kernel
to back the ovs bridges local port.
This limitation prevents reuse of the OpenVSwitch agent between both switches.

To enable reuse of the ovs agent with Intel's DPDK Accelerated Open vSwitch,
the proposal is to change the  generation of the  agent_id to use the hostname,
instead of the mac address of the br-int.

For several plugins such as the nec,mlnx,hyperv and onconvergence agents
the hostname is used to create the agent id.
Using the hostname will normalise the agent_id between these 5 neutron agents,
additionally log readability will also be improved,
if log aggregation is preformed across a cluster
as it will be easier to identify which node the log is from.

the hostname is retrived from cfg.CONF.host

Closes-Bug: #1323259
Change-Id: I9abfac17a74d298f1a17a0931fc98ac00234ac0b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/95138/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py']",2,2a8f634ee26784a57570eb64406b7bb46306dac8,feat-ovs-agent-id,," mock.call.get_local_port_mac(),",2,3
openstack%2Ffuel-ostf~master~I47c1d1b7b764f64e75bb59ae2a513f78da897d15,openstack/fuel-ostf,master,I47c1d1b7b764f64e75bb59ae2a513f78da897d15,Fixed small issue with bad style of code,MERGED,2014-06-23 15:43:56.000000000,2014-06-23 18:32:11.000000000,2014-06-23 18:32:10.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8824}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-23 15:43:56.000000000', 'files': ['fuel_health/murano.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/4d2efa822344b6ca022ec4086b6f083c07d90e14', 'message': 'Fixed small issue with bad style of code\n\nChange-Id: I47c1d1b7b764f64e75bb59ae2a513f78da897d15\n'}]",0,101937,4d2efa822344b6ca022ec4086b6f083c07d90e14,10,5,1,7227,,,0,"Fixed small issue with bad style of code

Change-Id: I47c1d1b7b764f64e75bb59ae2a513f78da897d15
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/37/101937/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/murano.py'],1,4d2efa822344b6ca022ec4086b6f083c07d90e14,, tag = 'murano_image_info' for image in self.compute_client.images.list():, for image in self.compute_client.images.list(): tag = 'murano_image_info',3,1
openstack%2Fzaqar~master~I10e592bbafadac22cded158f4083515b76a58fca,openstack/zaqar,master,I10e592bbafadac22cded158f4083515b76a58fca,Sync with oslo-incubator,MERGED,2014-06-19 20:19:37.000000000,2014-06-23 18:31:49.000000000,2014-06-23 18:31:49.000000000,"[{'_account_id': 3}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 10777}]","[{'number': 1, 'created': '2014-06-19 20:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0f3fcf828ca42e1b207fee1879f676cd61e3b36d', 'message': 'Sync with oslo-incubator\n\nIn particular, pick up the bug fix for memory cache\nbackend. Also includes some improved code comments\nand config option help strings, and a few other\ntweaks.\n\nChange-Id: I10e592bbafadac22cded158f4083515b76a58fca\n'}, {'number': 2, 'created': '2014-06-19 20:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/62d42feddb3edd42eb3251a36dd3a2f7a1c2b0af', 'message': 'Sync with oslo-incubator\n\nIn particular, pick up the bug fix for memory cache\nbackend. Also includes some improved code comments\nand config option help strings, and a few other\ntweaks.\n\nChange-Id: I10e592bbafadac22cded158f4083515b76a58fca\n'}, {'number': 3, 'created': '2014-06-20 14:16:18.000000000', 'files': ['marconi/openstack/common/excutils.py', 'marconi/openstack/common/cache/backends.py', 'marconi/openstack/common/lockutils.py', 'marconi/openstack/common/config/generator.py', 'marconi/openstack/common/fileutils.py', 'marconi/openstack/common/cache/_backends/memory.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/feff6157969bcd65e696fb4b7c7c934554a199d0', 'message': 'Sync with oslo-incubator\n\nIn particular, pick up the bug fix for memory cache\nbackend. Also includes some improved code comments\nand config option help strings, and a few other\ntweaks.\n\nChange-Id: I10e592bbafadac22cded158f4083515b76a58fca\n'}]",1,101312,feff6157969bcd65e696fb4b7c7c934554a199d0,19,4,3,6427,,,0,"Sync with oslo-incubator

In particular, pick up the bug fix for memory cache
backend. Also includes some improved code comments
and config option help strings, and a few other
tweaks.

Change-Id: I10e592bbafadac22cded158f4083515b76a58fca
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/12/101312/3 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/openstack/common/excutils.py', 'marconi/openstack/common/cache/backends.py', 'marconi/openstack/common/lockutils.py', 'marconi/openstack/common/config/generator.py', 'marconi/openstack/common/fileutils.py', 'marconi/openstack/common/cache/_backends/memory.py']",6,0f3fcf828ca42e1b207fee1879f676cd61e3b36d,oslo, self._keys_expires[value[0]].remove(key), self._keys_expires[value[0]].remove(value[1]),80,67
openstack%2Fneutron~master~I922e842b54add786723ecb7763d6b4f330794794,openstack/neutron,master,I922e842b54add786723ecb7763d6b4f330794794,Add test cases for plugins/ml2/plugin.py,MERGED,2014-06-10 15:34:36.000000000,2014-06-23 18:31:21.000000000,2014-06-23 18:31:20.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9093}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-10 15:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a4b7803e7f274cb28bc4125670c7eef517f39e7', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 2, 'created': '2014-06-10 19:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abe7bde0b83268e082211df3c0e0b886d576684e', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 3, 'created': '2014-06-12 20:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/881772041aaffe22ad5c91008c480de0cb376843', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 4, 'created': '2014-06-12 20:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecf61f709c9b756850d803bb2a74bbf7db59f2a3', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 5, 'created': '2014-06-13 21:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f89142e32862027bf0e3cdac29365ab5fb081595', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 6, 'created': '2014-06-13 21:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c373702bf799a409edf864774fc31e019f5537e1', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 7, 'created': '2014-06-16 13:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d589cd9f8b661d3b65b8258451718acdaa64d475', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 8, 'created': '2014-06-16 18:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e782beeb0c1c7171dd7099487afeef05c4c9fc02', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 9, 'created': '2014-06-17 01:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08bd7f97b9e1fe72f4f60ef1e6af7496784ab651', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 10, 'created': '2014-06-17 19:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26bb5c7e6fa51b652999d424fbd55a91790636a6', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 11, 'created': '2014-06-19 05:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea6f380fa30a0cede464bb579a63e0932504bc40', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}, {'number': 12, 'created': '2014-06-20 21:38:26.000000000', 'files': ['neutron/tests/unit/ml2/test_ml2_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cd29b7a9ebadd0eecf60aa10251ed4d8e51d4cc', 'message': 'Add test cases for plugins/ml2/plugin.py\n\nTest cases which generate MechanismDriverError failures and\nvalidate correct behavior.\n\nPartial-Bug: 1236127\nChange-Id: I922e842b54add786723ecb7763d6b4f330794794\n'}]",32,99129,4cd29b7a9ebadd0eecf60aa10251ed4d8e51d4cc,199,25,12,9093,,,0,"Add test cases for plugins/ml2/plugin.py

Test cases which generate MechanismDriverError failures and
validate correct behavior.

Partial-Bug: 1236127
Change-Id: I922e842b54add786723ecb7763d6b4f330794794
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/99129/10 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/ml2/test_ml2_plugin.py'],1,1a4b7803e7f274cb28bc4125670c7eef517f39e7,bug/1236127," def test_create_network_faulty(self): def mock_create_network_postcommit(self, context): raise ml2_exc.MechanismDriverError( method='create_network_postcommit') with mock.patch.object(mech_test.TestMechanismDriver, 'create_network_postcommit', new=mock_create_network_postcommit): data = {'network': {'name': 'net1', 'tenant_id': 'tenant_one'}} req = self.new_create_request('networks', data) network = self.deserialize(self.fmt, req.get_response(self.api)) res = req.get_response(self.api) self.assertEqual(res.status_int, 500) def test_delete_network_faulty(self): def mock_delete_network_postcommit(self, context): raise ml2_exc.MechanismDriverError( method='delete_network_postcommit') with mock.patch.object(mech_test.TestMechanismDriver, 'delete_network_postcommit', new=mock_delete_network_postcommit): with mock.patch.object(mech_logger.LoggerMechanismDriver, 'delete_network_postcommit') as dnp: data = {'network': {'name': 'net1', 'tenant_id': 'tenant_one'}} network_req = self.new_create_request('networks', data) network = self.deserialize( self.fmt, network_req.get_response(self.api)) req = self.new_delete_request('networks', network['network']['id']) res = req.get_response(self.api) self.assertEqual(res.status_int, 204) # Test if other mechanism driver was called self.assertTrue(dnp.called) def test_create_subnet_faulty(self): def mock_create_subnet_postcommit(self, context): raise ml2_exc.MechanismDriverError( method='create_subnet_postcommit') with mock.patch.object(mech_test.TestMechanismDriver, 'create_subnet_postcommit', new=mock_create_subnet_postcommit): with self.network() as network: data = {'subnet': {'network_id': network['network']['id'], 'cidr': '10.0.20.0/24', 'ip_version': '4', 'name': 'subnet1', 'tenant_id': network['network']['tenant_id'], 'gateway_ip': '10.0.2.1'}} req = self.new_create_request('subnets', data) subnet = self.deserialize(self.fmt, req.get_response(self.api)) res = req.get_response(self.api) self.assertEqual(res.status_int, 500) def test_delete_subnet_faulty(self): def mock_delete_subnet_postcommit(self, context): raise ml2_exc.MechanismDriverError( method='delete_subnet_postcommit') with mock.patch.object(mech_test.TestMechanismDriver, 'delete_subnet_postcommit', new=mock_delete_subnet_postcommit): with self.network() as network: data = {'subnet': {'network_id': network['network']['id'], 'cidr': '10.0.20.0/24', 'ip_version': '4', 'name': 'subnet1', 'tenant_id': network['network']['tenant_id'], 'gateway_ip': '10.0.2.1'}} subnet_req = self.new_create_request('subnets', data) subnet = self.deserialize( self.fmt, subnet_req.get_response(self.api)) req = self.new_delete_request('subnets', subnet['subnet']['id']) res = req.get_response(self.api) self.assertEqual(res.status_int, 204) def test_create_port_faulty(self): def mock_create_port_postcommit(self, context): raise ml2_exc.MechanismDriverError( method='create_port_postcommit') with mock.patch.object(mech_test.TestMechanismDriver, 'create_port_postcommit', new=mock_create_port_postcommit): with self.network() as network: data = {'port': {'network_id': network['network']['id'], 'tenant_id': network['network']['tenant_id'], 'name': 'port1', 'admin_state_up': 1, 'fixed_ips': []}} req = self.new_create_request('ports', data) port = self.deserialize( self.fmt, req.get_response(self.api)) res = req.get_response(self.api) self.assertEqual(res.status_int, 500) ",,122,0
openstack%2Fcinder~master~Iecaf111f96f93b4e24bd81edd6aa82829113b4bb,openstack/cinder,master,Iecaf111f96f93b4e24bd81edd6aa82829113b4bb,Update _resize_volume_file() to support appropriate permissions,MERGED,2014-06-23 14:14:11.000000000,2014-06-23 18:31:13.000000000,2014-06-23 18:31:12.000000000,"[{'_account_id': 3}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 9067}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 14:14:11.000000000', 'files': ['cinder/volume/drivers/ibm/ibmnas.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea56cf255ac956d23eba5bb4f6e7312b944eb5fb', 'message': 'Update _resize_volume_file() to support appropriate permissions\n\nibmnas driver inherits _set_rw_permissions_for_all() from nfs.py\nwhich sets 666 to the volumes. Changes are expected to be made in\nnfs.py such that it sets 600 or 660 permissions, by doing so\nibmnas driver fails performing the operation _resize_volume_file()\n\nAdding run_as_root in resize_volume operation.\n\nChange-Id: Iecaf111f96f93b4e24bd81edd6aa82829113b4bb\nCloses-Bug: #1333252\n'}]",0,101919,ea56cf255ac956d23eba5bb4f6e7312b944eb5fb,10,5,1,9204,,,0,"Update _resize_volume_file() to support appropriate permissions

ibmnas driver inherits _set_rw_permissions_for_all() from nfs.py
which sets 666 to the volumes. Changes are expected to be made in
nfs.py such that it sets 600 or 660 permissions, by doing so
ibmnas driver fails performing the operation _resize_volume_file()

Adding run_as_root in resize_volume operation.

Change-Id: Iecaf111f96f93b4e24bd81edd6aa82829113b4bb
Closes-Bug: #1333252
",git fetch https://review.opendev.org/openstack/cinder refs/changes/19/101919/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/ibmnas.py'],1,ea56cf255ac956d23eba5bb4f6e7312b944eb5fb,master," image_utils.resize_image(path, new_size, run_as_root=True)"," image_utils.resize_image(path, new_size)",1,1
openstack%2Fneutron~stable%2Ficehouse~Iddcb6a43d60d5c9f472912efdecbb2aaa9b7ea4a,openstack/neutron,stable/icehouse,Iddcb6a43d60d5c9f472912efdecbb2aaa9b7ea4a,Brocade mechanism driver should be derived from ML2 plugin base class,MERGED,2014-06-21 00:41:21.000000000,2014-06-23 18:31:04.000000000,2014-06-23 18:31:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 9732}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-06-21 00:41:21.000000000', 'files': ['neutron/plugins/ml2/drivers/brocade/mechanism_brocade.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/45281bb6f910268a4fecb9fbe71a941d5e6864f5', 'message': 'Brocade mechanism driver should be derived from ML2 plugin base class\n\nChange-Id: Iddcb6a43d60d5c9f472912efdecbb2aaa9b7ea4a\nFixes-bug: #1327001\n(cherry picked from commit 99840ff808c290bedd4a9832b3ec880e8909412a)\n'}]",0,101676,45281bb6f910268a4fecb9fbe71a941d5e6864f5,16,10,1,5217,,,0,"Brocade mechanism driver should be derived from ML2 plugin base class

Change-Id: Iddcb6a43d60d5c9f472912efdecbb2aaa9b7ea4a
Fixes-bug: #1327001
(cherry picked from commit 99840ff808c290bedd4a9832b3ec880e8909412a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/101676/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/brocade/mechanism_brocade.py'],1,45281bb6f910268a4fecb9fbe71a941d5e6864f5,,from neutron.plugins.ml2 import driver_apiclass BrocadeMechanism(driver_api.MechanismDriver):,class BrocadeMechanism():,2,1
openstack%2Fosprofiler~master~Ibb93866591c791787560a14d677d2eeb20f07006,openstack/osprofiler,master,Ibb93866591c791787560a14d677d2eeb20f07006,Base64 encode the 'X-Trace-Info' header,MERGED,2014-06-17 21:16:04.000000000,2014-06-23 18:28:31.000000000,2014-06-23 18:28:31.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-06-17 21:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/91ecc545c7ea126f3678e93e13f0037fac377d05', 'message': ""Base64 encode the 'X-Trace-Info' header\n\nInstead of sending the trace information via\na json string formatted header send it as a\nbase64 encoded string. This is more compliant\nwith how headers are typically sent (not as a\nraw json string).\n\nChange-Id: Ibb93866591c791787560a14d677d2eeb20f07006\n""}, {'number': 2, 'created': '2014-06-18 23:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/f506530088cbf090da2a1f48c9bd2fb2e41fb321', 'message': ""Base64 encode the 'X-Trace-Info' header\n\nInstead of sending the trace information via\na json string formatted header send it as a\nbase64 encoded string. This is more compliant\nwith how headers are typically sent (not as a\nraw json string).\n\nChange-Id: Ibb93866591c791787560a14d677d2eeb20f07006\n""}, {'number': 3, 'created': '2014-06-19 00:01:47.000000000', 'files': ['osprofiler/web.py', 'tests/test_web.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/dd098fa16b4c8b1f9d4ee66add3a488864f99c1f', 'message': ""Base64 encode the 'X-Trace-Info' header\n\nInstead of sending the trace information via\na json string formatted header send it as a\nbase64 encoded string. This is more compliant\nwith how headers are typically sent (not as a\nraw json string).\n\nChange-Id: Ibb93866591c791787560a14d677d2eeb20f07006\n""}]",2,100688,dd098fa16b4c8b1f9d4ee66add3a488864f99c1f,16,2,3,1297,,,0,"Base64 encode the 'X-Trace-Info' header

Instead of sending the trace information via
a json string formatted header send it as a
base64 encoded string. This is more compliant
with how headers are typically sent (not as a
raw json string).

Change-Id: Ibb93866591c791787560a14d677d2eeb20f07006
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/88/100688/1 && git format-patch -1 --stdout FETCH_HEAD,"['osprofiler/web.py', 'tests/test_web.py']",2,91ecc545c7ea126f3678e93e13f0037fac377d05,tests,"import base64 def test_add_trace_id_header(self): profiler.init(base_id=""y"", parent_id=""z"") trace_info = base64.urlsafe_b64decode(headers[""X-Trace-Info""]) trace_info = json.loads(utils.binary_decode(trace_info)) self.assertEqual({""parent_id"": 'z', 'base_id': 'y'}, trace_info) trace_info = utils.binary_encode(json.dumps(trace_info)) trace_info = base64.urlsafe_b64encode(trace_info) ""X-Trace-Info"": trace_info,"," @mock.patch(""osprofiler.web.utils.binary_encode"") @mock.patch(""osprofiler.web.json.dumps"") @mock.patch(""osprofiler.web.profiler.get_profiler"") def test_add_trace_id_header(self, mock_get_profiler, mock_dumps, mock_b64encode): mock_dumps.return_value = ""dump"" mock_b64encode.return_value = ""b64"" p = mock.MagicMock() p.get_base_id.return_value = 1 p.get_id.return_value = 2 p.hmac_key = None mock_get_profiler.return_value = p self.assertEqual(headers[""X-Trace-Info""], ""b64"") mock_b64encode.assert_called_once_with(""dump"") mock_dumps.assert_called_once_with({""base_id"": 1, ""parent_id"": 2}) ""X-Trace-Info"": utils.binary_encode(json.dumps(trace_info))",34,38
openstack%2Ffuel-main~stable%2F4.1~I0dfcb1d461748fe6b0698f125201b730d63e41d4,openstack/fuel-main,stable/4.1,I0dfcb1d461748fe6b0698f125201b730d63e41d4,Confirm disk re-partitioning before proceeding,MERGED,2014-06-06 14:29:55.000000000,2014-06-23 18:25:26.000000000,2014-06-23 18:25:25.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-06-06 14:29:55.000000000', 'files': ['iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/180f6397eceb3e1b1b96cea419e80d4909d73ca9', 'message': 'Confirm disk re-partitioning before proceeding\n\nAsk for a confirmation before Fuel installation on a drive with\nexisting partition table.\n\nNew kickstart kernel parameter:\n  - ""forceformat"" - (yes/no) defaul is ""no"". Set to ""yes"" if you\n                    want to format chosen drive automatically.\n\nFor example, if you add ""installdrive=sda forceformat=yes"" to the\nkernel parameters line in Grub menu, then ""sda"" drive will be\nformatted automatically and Fuel will be installed on it.\n\nChange-Id: I0dfcb1d461748fe6b0698f125201b730d63e41d4\nCloses-bug: #1325068\n'}]",0,98430,180f6397eceb3e1b1b96cea419e80d4909d73ca9,20,7,1,9387,,,0,"Confirm disk re-partitioning before proceeding

Ask for a confirmation before Fuel installation on a drive with
existing partition table.

New kickstart kernel parameter:
  - ""forceformat"" - (yes/no) defaul is ""no"". Set to ""yes"" if you
                    want to format chosen drive automatically.

For example, if you add ""installdrive=sda forceformat=yes"" to the
kernel parameters line in Grub menu, then ""sda"" drive will be
formatted automatically and Fuel will be installed on it.

Change-Id: I0dfcb1d461748fe6b0698f125201b730d63e41d4
Closes-bug: #1325068
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/30/98430/1 && git format-patch -1 --stdout FETCH_HEAD,['iso/ks.template'],1,180f6397eceb3e1b1b96cea419e80d4909d73ca9,,"installdrive=""undefined"" forceformat=""no"" for I in `cat /proc/cmdline`; do case ""$I"" in *=*) eval $I;; esac ; done tgtdrive=""${installdrive}"" function confirm_format { check_drive=""$1"" local confirm_format=""no"" if [[ ""$forceformat"" == ""yes"" ]] ; then return 0 fi if parted -s /dev/$check_drive print &>/dev/null ; then echo echo ""$check_drive drive contains partition table:"" parted -s /dev/$check_drive print echo read -p ""Are you sure you want to erase ALL data on disk $check_drive? (y/N)"" confirm_format if [[ ""$confirm_format"" == ""y"" ]] || [[ ""$forceformat"" == ""yes"" ]]; then return 0 else return 1 fi else return 0 fi } format_confirmed=""no"" echo '* the installation target? *' if [[ ""$drive"" == ""$tgtdrive"" ]] && match=""yes"" ; then if confirm_format $tgtdrive ; then format_confirmed=""yes"" break else tgtdrive=""undefined"" read -p ""You may select another disk. Press Enter to continue."" _ fi fiif [ ""$format_confirmed"" != ""yes"" ] ; then exec < /dev/tty3 > /dev/tty3 2>&1 chvt 3 if ! confirm_format $tgtdrive ; then clear echo echo '********************************************************************' echo '* E R R O R *' echo '* *' echo '* Disk $tgtdrive contains active partition(s). *' echo '* Installation cannot continue without confirmation. *' echo '* *' echo '********************************************************************' echo read -p ""Press Enter to restart: "" _ reboot fi chvt 1 fi ","tgtdrive=""undefined"" echo '* installation target? *' [[ ""$drive"" == ""$tgtdrive"" ]] && match=""yes"" && break",62,3
openstack%2Fdevstack~master~I5b83209702313a31e8d3f8fdc605f34175ceb13c,openstack/devstack,master,I5b83209702313a31e8d3f8fdc605f34175ceb13c,Add support for using git clean,ABANDONED,2014-04-08 15:24:50.000000000,2014-06-23 18:20:35.000000000,,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-08 15:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e2c746c39d71bac9d72f9853ca3350ba53a1bd68', 'message': 'Use git clean -fdx instead of find\n\nChange-Id: I5b83209702313a31e8d3f8fdc605f34175ceb13c\n'}, {'number': 2, 'created': '2014-04-09 16:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7963fddc5e32787759405a1968ff4b1beec9f32e', 'message': 'Use git clean -fdx instead of find\n\nThere are cases where you are switching branches - and files that were\ntracked in one branch and deleted in a more recent branch become\nuntracked, and will linger and cause issues\n\nChange-Id: I5b83209702313a31e8d3f8fdc605f34175ceb13c\n'}, {'number': 3, 'created': '2014-05-19 17:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a282c82586048815a943f1145940973a6895b785', 'message': 'Add support for using git clean\n\nThere are cases where you are switching branches - and files that were\ntracked in one branch and deleted in a more recent branch become\nuntracked, and will linger and cause issues\n\nChange-Id: I5b83209702313a31e8d3f8fdc605f34175ceb13c\n'}, {'number': 4, 'created': '2014-05-19 17:26:12.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7965ccc4c5d099622b5c143d4df278a86d5196a', 'message': 'Add support for using git clean\n\nThere are cases where you are switching branches - and files that were\ntracked in one branch and deleted in a more recent branch become\nuntracked, and will linger and cause issues\n\nChange-Id: I5b83209702313a31e8d3f8fdc605f34175ceb13c\n'}]",0,86060,b7965ccc4c5d099622b5c143d4df278a86d5196a,34,6,4,4656,,,0,"Add support for using git clean

There are cases where you are switching branches - and files that were
tracked in one branch and deleted in a more recent branch become
untracked, and will linger and cause issues

Change-Id: I5b83209702313a31e8d3f8fdc605f34175ceb13c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/86060/3 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,e2c746c39d71bac9d72f9853ca3350ba53a1bd68,git_clean, git clean -fdx, find $GIT_DEST -name '*.pyc' -delete,1,1
openstack%2Fhorizon~master~I8779666c053a4835e22038a39a530fe5fc84b6a3,openstack/horizon,master,I8779666c053a4835e22038a39a530fe5fc84b6a3,"Disable broken unit test (related to ""Change Password"")",MERGED,2014-06-23 11:05:41.000000000,2014-06-23 18:18:50.000000000,2014-06-23 18:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 7386}, {'_account_id': 8577}, {'_account_id': 8871}, {'_account_id': 9981}, {'_account_id': 10242}, {'_account_id': 10247}]","[{'number': 1, 'created': '2014-06-23 11:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/24cca46216d0754f62562185e1543f5f7e9782ca', 'message': 'Disable broken unit test (related to ""Change Password"")\n\nThe new django_openstack_auth 1.1.6 library surfaced a defect in this\ntest, whereby the test client does not properly log out the user. This\nonly affects the test, the functionality otherwise works fine.\n\nThis temporarily disables the test in order to repair the gate, while\nwaiting to replace it with a new unit test more reduced in scope and/or\nan integration test.\n\nChange-Id: I8779666c053a4835e22038a39a530fe5fc84b6a3\nPartial-Bug: #133314\n'}, {'number': 2, 'created': '2014-06-23 11:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1fbc8e174e736960d3898a850161f829ddca6e32', 'message': 'Disable broken unit test (related to ""Change Password"")\n\nThe new django_openstack_auth 1.1.6 library surfaced a defect in this\ntest, whereby the test client does not properly log out the user. This\nonly affects the test, the functionality otherwise works fine.\n\nThis temporarily disables the test in order to repair the gate, while\nwaiting to replace it with a new unit test more reduced in scope and/or\nan integration test.\n\nChange-Id: I8779666c053a4835e22038a39a530fe5fc84b6a3\nPartial-Bug: #1333144\n'}, {'number': 3, 'created': '2014-06-23 13:16:02.000000000', 'files': ['openstack_dashboard/dashboards/settings/password/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5455b8f6f595633513b6521449ebc1985d5b9070', 'message': 'Disable broken unit test (related to ""Change Password"")\n\nThe new django_openstack_auth 1.1.6 library surfaced a defect in this\ntest, whereby the test client does not properly log out the user. This\nonly affects the test, the functionality otherwise works fine.\n\nThis temporarily disables the test in order to repair the gate, while\nwaiting to replace it with a new unit test more reduced in scope and/or\nan integration test.\n\nChange-Id: I8779666c053a4835e22038a39a530fe5fc84b6a3\nPartial-Bug: #1333144\n'}]",1,101857,5455b8f6f595633513b6521449ebc1985d5b9070,23,10,3,4978,,,0,"Disable broken unit test (related to ""Change Password"")

The new django_openstack_auth 1.1.6 library surfaced a defect in this
test, whereby the test client does not properly log out the user. This
only affects the test, the functionality otherwise works fine.

This temporarily disables the test in order to repair the gate, while
waiting to replace it with a new unit test more reduced in scope and/or
an integration test.

Change-Id: I8779666c053a4835e22038a39a530fe5fc84b6a3
Partial-Bug: #1333144
",git fetch https://review.opendev.org/openstack/horizon refs/changes/57/101857/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/settings/password/tests.py'],1,24cca46216d0754f62562185e1543f5f7e9782ca,bug/1333144," # TODO(jpichon): Temporarily disabled, see LP bug 1333144 def change_password_shows_message_on_login_page(self):", def test_change_password_shows_message_on_login_page(self):,2,1
openstack%2Fopenstack-manuals~master~I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453,openstack/openstack-manuals,master,I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453,Update the usage of unscoped extra specs,MERGED,2014-06-20 20:05:37.000000000,2014-06-23 18:15:38.000000000,2014-06-23 18:15:37.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-06-20 20:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9fb94e5411120dc3eeb5bd56d6b4b2f9bbb0c737', 'message': 'Update the usage of unscoped extra specs\n\nAlthough the unscoped extra specs are supported in\nAggregateInstanceExtraSpecsFilter and ComputeCapabilitiesFilter, it\nshould be not encouraged, since it will cause conflict.\n\nChange-Id: I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453\nClose-Bug: 1330962\n'}, {'number': 2, 'created': '2014-06-21 19:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/211bfa966ef6dd16492a891c2d4689d5cb09894e', 'message': 'Update the usage of unscoped extra specs\n\nAlthough the unscoped extra specs are supported in\nAggregateInstanceExtraSpecsFilter and ComputeCapabilitiesFilter, it\nshould be not encouraged, since it will cause conflict.\n\nChange-Id: I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453\nClose-Bug: 1330962\n'}, {'number': 3, 'created': '2014-06-22 14:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c52c13d6ebb93d8430fb1675a48ccd3304cb7e2b', 'message': 'Update the usage of unscoped extra specs\n\nAlthough the unscoped extra specs are supported in\nAggregateInstanceExtraSpecsFilter and ComputeCapabilitiesFilter, it\nshould be not encouraged, since it will cause conflict.\n\nChange-Id: I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453\nClose-Bug: 1330962\n'}, {'number': 4, 'created': '2014-06-23 17:03:35.000000000', 'files': ['doc/config-reference/compute/section_compute-scheduler.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7e7cb4d0ec13229be12a1532968e4940a0525d5d', 'message': 'Update the usage of unscoped extra specs\n\nAlthough the unscoped extra specs are supported in\nAggregateInstanceExtraSpecsFilter and ComputeCapabilitiesFilter, it\nshould be not encouraged, since it will cause conflict.\n\nCloses-Bug: 1330962\nChange-Id: I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453\n'}]",0,101640,7e7cb4d0ec13229be12a1532968e4940a0525d5d,19,4,4,4573,,,0,"Update the usage of unscoped extra specs

Although the unscoped extra specs are supported in
AggregateInstanceExtraSpecsFilter and ComputeCapabilitiesFilter, it
should be not encouraged, since it will cause conflict.

Closes-Bug: 1330962
Change-Id: I2b35bf85f0c2e8c8c386bf0c4bed1e6c21cea453
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/101640/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_compute-scheduler.xml'],1,9fb94e5411120dc3eeb5bd56d6b4b2f9bbb0c737,bug/1330962," aggregate. Works with specifications that are scoped with Works with non-scoped specifications also for backward compatibility, but is highly discouraged since it will conflict with <link linkend=""computecapabilitiesfilter""> ComputeCapabilitiesFilter</link> filter when both filters are enabled. 'capabilities', it is ignored by this filter. If no namespace is present, it is treated as the key to be matched, but this is for backward compatibity only and is highly discouraged because it will conflict with <link linkend=""aggregateinstanceextraspecsfilter""> AggregateInstanceExtraSpecsFilter</link> filter when both filters are enabled.</para>"," aggregate. Works with specifications that are unscoped, or are scoped with 'capabilities', it is ignored by this filter.</para>",13,3
openstack%2Fnova~master~I7fa69ea91e517121aba0ee22a71b0594591ae308,openstack/nova,master,I7fa69ea91e517121aba0ee22a71b0594591ae308,Ensure changes to api.QUOTA_SYNC_FUNCTIONS are restored.,MERGED,2014-06-12 21:40:29.000000000,2014-06-23 18:07:56.000000000,2014-06-23 15:56:07.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-06-12 21:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a791d4e6c07426cfa81c31e3e0b944f03da04ac', 'message': '- Add tearDown() to QuotaReserveSqlAlchemyTestCase which restores\nthe original callables within nova.db.sqlalchemy.api.QUOTA_SYNC_FUNCTIONS\nso that subsequent tests have the original functions present.\n\nChange-Id: I7fa69ea91e517121aba0ee22a71b0594591ae308\nCloses-Bug: #1329482\n'}, {'number': 2, 'created': '2014-06-12 23:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/acb3e32d6cf6ace37302db7a120927f205c2e02c', 'message': '- Add tearDown() to QuotaReserveSqlAlchemyTestCase which restores\nthe original callables within nova.db.sqlalchemy.api.QUOTA_SYNC_FUNCTIONS\nso that subsequent tests have the original functions present.\n\nChange-Id: I7fa69ea91e517121aba0ee22a71b0594591ae308\nCloses-Bug: #1329482\n'}, {'number': 3, 'created': '2014-06-12 23:34:55.000000000', 'files': ['nova/tests/test_quota.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7168fcfe2d110eeca730e2ed966a5b5435b226b8', 'message': 'Ensure changes to api.QUOTA_SYNC_FUNCTIONS are restored.\n\nAdd a local callable restore_sync_functions() that is\nestablished as an addCleanup() fixture callable,\nmaking use of a copy of the QUOTA_SYNC_FUNCTIONS\ndictionary to restore its previous contents in-place.\n\nChange-Id: I7fa69ea91e517121aba0ee22a71b0594591ae308\nCloses-Bug: #1329482\n'}]",3,99772,7168fcfe2d110eeca730e2ed966a5b5435b226b8,57,13,3,11816,,,0,"Ensure changes to api.QUOTA_SYNC_FUNCTIONS are restored.

Add a local callable restore_sync_functions() that is
established as an addCleanup() fixture callable,
making use of a copy of the QUOTA_SYNC_FUNCTIONS
dictionary to restore its previous contents in-place.

Change-Id: I7fa69ea91e517121aba0ee22a71b0594591ae308
Closes-Bug: #1329482
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/99772/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/test_quota.py'],1,0a791d4e6c07426cfa81c31e3e0b944f03da04ac,bug/1329482," self._existing_quota_sync_func_dict = dict( sqa_api.QUOTA_SYNC_FUNCTIONS) def tearDown(self): sqa_api.QUOTA_SYNC_FUNCTIONS.update( self._existing_quota_sync_func_dict) del self._existing_quota_sync_func_dict super(QuotaReserveSqlAlchemyTestCase, self).tearDown() ",,9,0
openstack%2Ftraining-guides~master~Ied3d94a2e065eccffd538d8a909c510d8b94074d,openstack/training-guides,master,Ied3d94a2e065eccffd538d8a909c510d8b94074d,cleanup of training cluster - fix bug 1332667,MERGED,2014-06-20 19:24:57.000000000,2014-06-23 18:07:51.000000000,2014-06-23 18:07:51.000000000,"[{'_account_id': 3}, {'_account_id': 6923}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-06-20 19:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/021caf83a51edfc3b549eccb58e5e29957a44346', 'message': 'cleanup of training cluster - fix bug 1332667\n\nreworded and streamlined for ease of understanding\nchanged bottom paragraphs for clarity and streamlining\n\nChange-Id: Ied3d94a2e065eccffd538d8a909c510d8b94074d\n'}, {'number': 2, 'created': '2014-06-23 17:32:25.000000000', 'files': ['doc/training-guides/lab000-virtualbox-basics.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/0cfeac6c643100154351160e2a636fbce4be7938', 'message': 'cleanup of training cluster - fix bug 1332667\n\nreworded and streamlined for ease of understanding\nchanged bottom paragraphs for clarity and streamlining\n\nChange-Id: Ied3d94a2e065eccffd538d8a909c510d8b94074d\n'}]",1,101631,0cfeac6c643100154351160e2a636fbce4be7938,12,3,2,9382,,,0,"cleanup of training cluster - fix bug 1332667

reworded and streamlined for ease of understanding
changed bottom paragraphs for clarity and streamlining

Change-Id: Ied3d94a2e065eccffd538d8a909c510d8b94074d
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/31/101631/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/lab000-virtualbox-basics.xml'],1,021caf83a51edfc3b549eccb58e5e29957a44346,bug/1332667," <para>Shutting down your Virtual Machine may lead to malfunctioning OpenStack Services. Do not directly shutdown your VM, in case your VM's don't have Internet connectivity.</para> command to verify internet access.</para> <para>If its not connected, restart the networking <para>This should reconnect the network a majority of the time. If you still cannot connect, there may another issue, or internet access is unavailable.</para> <para>Congratulations! You are now setup with the infrastructure for deploying OpenStack. Just make sure that the Ubuntu Server is installed on the above setup Virtual Box instances. In the"," <para>Well there are a few warnings that I must give you out of experience due to common habits that most people may have.</para> <para>Sometimes shutting down your Virtual Machine may lead to the malfunctioning of OpenStack Services. Try not to directly shutdown your VM, in case your VM's don't get Internet.</para> command to see whether Internet is on.</para> <para>If its not connected, restart networking <para>This should reconnect your network about 99% of the time. If you are really unlucky you must be having some other problems or your Internet connection itself is not functioning.</para> <para>Congrats, you are ready with the infrastructure for deploying OpenStack. Just make sure that you have installed Ubuntu Server on the above setup Virtual Box instances. In the",11,16
openstack%2Ffuel-web~master~I51c6add75679f1a9285f4986a07fe516ebead2ec,openstack/fuel-web,master,I51c6add75679f1a9285f4986a07fe516ebead2ec,Add Fuel development quick-start guide,MERGED,2014-06-21 01:00:29.000000000,2014-06-23 17:59:46.000000000,2014-06-23 17:59:45.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8787}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-06-21 01:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0584466953a430f84290f0afbb97f64358096dbf', 'message': 'Add Fuel development quick-start guide\n\nThis update adds a quick-start guide to\nthe fuel development documentation, and\nfixes a broken link in the Nailgun\ndevelopment guide.\n\nChange-Id: I51c6add75679f1a9285f4986a07fe516ebead2ec\nCloses-Bug: #1332655\nImplements: blueprint fuel-web-docs-dev-env-restructure\n'}, {'number': 2, 'created': '2014-06-21 01:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/68aa2d1377c91ded2046c39625790b36370f5c30', 'message': 'Add Fuel development quick-start guide\n\nThis update adds a quick-start guide to\nthe fuel development documentation, and\nfixes a broken link in the Nailgun\ndevelopment guide.\n\nChange-Id: I51c6add75679f1a9285f4986a07fe516ebead2ec\nCloses-Bug: #1332655\nImplements: blueprint fuel-web-docs-dev-env-restructure\n'}, {'number': 3, 'created': '2014-06-21 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8a8b5f500e771c72331b9be5620ff2eb2733aeb0', 'message': 'Add Fuel development quick-start guide\n\nThis update adds a quick-start guide to\nthe fuel development documentation, and\nfixes a broken link in the Nailgun\ndevelopment guide.\n\nChange-Id: I51c6add75679f1a9285f4986a07fe516ebead2ec\nCloses-Bug: #1332655\nImplements: blueprint fuel-web-docs-dev-env-restructure\n'}, {'number': 4, 'created': '2014-06-21 05:22:30.000000000', 'files': ['docs/develop/nailgun/development/env.rst', 'docs/develop.rst', 'docs/develop/quick_start.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1a567bb214855ba7b60a7e00be9f70a1b2990e99', 'message': 'Add Fuel development quick-start guide\n\nThis update adds a quick-start guide to\nthe fuel development documentation, and\nfixes a broken link in the Nailgun\ndevelopment guide.\n\nChange-Id: I51c6add75679f1a9285f4986a07fe516ebead2ec\nCloses-Bug: #1332655\nImplements: blueprint fuel-web-docs-dev-env-restructure\n'}]",5,101677,1a567bb214855ba7b60a7e00be9f70a1b2990e99,35,7,4,9788,,,0,"Add Fuel development quick-start guide

This update adds a quick-start guide to
the fuel development documentation, and
fixes a broken link in the Nailgun
development guide.

Change-Id: I51c6add75679f1a9285f4986a07fe516ebead2ec
Closes-Bug: #1332655
Implements: blueprint fuel-web-docs-dev-env-restructure
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/77/101677/4 && git format-patch -1 --stdout FETCH_HEAD,"['docs/develop/nailgun/development/env.rst', 'docs/develop.rst', 'docs/develop/quick_start.rst']",3,0584466953a430f84290f0afbb97f64358096dbf,bp/fuel-web-docs-dev-env-restructure,"Fuel Development Quick-Start ============================ If you are interested in contributing to Fuel or modifying Fuel for your own purposes, this short guide should get you pointed to all the information you need to get started. If you are new to contributing to OpenStack, be sure to read through the How To Contribute page on the OpenStack wiki first. See: `How to contribute <https://wiki.openstack.org/wiki/How_To_Contribute>`_. For this walk-through, lets use the example of modifying an option to the new environment wizard in Fuel (example here: `https://review.openstack.org/#/c/90687/1 <https://review.openstack.org/#/c/90687/1>`_). This enhancement required modification to three files in the fuel-web repository:: fuel-web/nailgun/static/i18n/translation.json fuel-web/nailgun/static/js/views/dialogs.js fuel-web/nailgun/static/templates/dialogs/create_cluster_wizard/storage.html In order to add, test and commit the code necessary to implement this feature, these steps were followed: #. Create a Fuel development environment by following the instructions fround here: :doc:`Fuel Development Environment </develop/env>`. #. In your development environment, prepare your environment for Nailgun unit tests and Web UI tests by following the instructions found here: :doc:`Nailgun Dev Environment </develop/nailgun/development/env>`. Be sure to run the tests noted in each section to ensure your environment confirms to a known good baseline. #. Branch your fuel-web checkout (see `Gerrit Workflow <https://wiki.openstack.org/wiki/GerritWorkflow>`_ for more information on the gerrit workflow):: cd fuel-web git checkout -b vcenter-wizard-fix #. Modify the necessary files (refer to :doc:`Fuel Architecture </develop/architecture>` to understand how the components of Fuel work together). #. Test your Nailgun changes:: cd fuel-web ./run_tests.sh --no-jslint --no-webui ./run_tests.sh --flake8 ./run_tests.sh --jslint ./run_tests.sh --webui #. You should also test Nailgun in fake UI mode by following the steps found here: :ref:`running-nailgun-in-fake-mode` #. When all tests pass you should commit your code, which will subject it to further testing via Jenkins and Fuel CI. Be sure to include a good commit message, guidlines can be found here: `Git Commit Messages <https://wiki.openstack.org/wiki/GitCommitMessages>`_.:: git commit -a git review #. Frequently, the review process will suggest changes be made before your code can be merged. In that case, make your changes locally, test the changes, and then re-submit for review by following these steps:: git commit -a --amend git review #. Now that your code has been committed, you should change your Fuel ISO makefile to point to your specific commit. As noted in the :doc:`Fuel Development documentation </develop/env>`, when you build a Fuel ISO it pulls down the additional repositories rather than using your local repos. Even though you have a local clone of fuel-web holding the branch you just worked on, the build script will be pulling code from git for the sub-components (Nailgun, Astute, OSTF) based on the repository and commit specified in environment variables when calling make iso, or as found in config.mk. You will need to know the gerrit commit ID and patch number. For this example we are looking at https://review.openstack.org/#/c/90687/1 with the gerrit ID 90687, patch 1. In this instance, you would build the ISO with:: cd fuel-main NAILGUN_GERRIT_COMMIT?=refs/changes/32/90687/1 make iso #. Once your ISO build is complete, you can test it. If you have access to hardware that can run the KVM hypervisor, you can follow the instructions found in the :doc:`Devops Guide </devops>` to create a robust testing environment. Otherwise you can test the ISO with Virtualbox (the download link can be found at `https://software.mirantis.com/ <https://software.mirantis.com/>`_) #. Once your code has been merged you can return your local repo to the master branch so you can start fresh on your next commit by following these steps:: cd fuel-web git remote update git checkout master git pull ",,114,1
openstack%2Fzaqar~master~I3dc02382951badc75566dfb404e3432933d2fb2e,openstack/zaqar,master,I3dc02382951badc75566dfb404e3432933d2fb2e,Updated from global requirements,ABANDONED,2014-06-20 03:33:50.000000000,2014-06-23 17:45:59.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-20 03:33:50.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ec3c928facc08702fe0afa5888744ba0217cd704', 'message': 'Updated from global requirements\n\nChange-Id: I3dc02382951badc75566dfb404e3432933d2fb2e\n'}]",0,101402,ec3c928facc08702fe0afa5888744ba0217cd704,4,1,1,11131,,,0,"Updated from global requirements

Change-Id: I3dc02382951badc75566dfb404e3432933d2fb2e
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/02/101402/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'test-requirements-py3.txt']",2,ec3c928facc08702fe0afa5888744ba0217cd704,openstack/requirements,"httpretty>=0.8.0,!=0.8.1,!=0.8.2",httpretty>=0.8.0,2,2
openstack%2Fnova~master~I3308be33f60c4add3e2e78b75f238059a9b3d876,openstack/nova,master,I3308be33f60c4add3e2e78b75f238059a9b3d876,Deprecate neutron_* configuration settings,MERGED,2014-06-03 10:46:28.000000000,2014-06-23 17:33:28.000000000,2014-06-17 19:51:40.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-03 10:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d23c135d5595983efe174fa8c2a6535a56a99d13', 'message': ""Deprecate neutron_* configuration settings\n\nCreate a new section in the configuration file called 'neytron'.\nMove all of the neutron_* configuration settings to this section.\n\nDocImpact\n\nChange-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876\n""}, {'number': 2, 'created': '2014-06-03 10:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ddaa3123c424b462c49f738e12dfe11ad695620', 'message': ""Deprecate neutron_* configuration settings\n\nCreate a new section in the configuration file called 'neutron'.\nMove all of the neutron_* configuration settings to this section.\n\nDocImpact\n\nChange-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876\n""}, {'number': 3, 'created': '2014-06-03 18:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bc70faf3c1fa82f80a98dd2c5f08db8f7670804', 'message': ""Deprecate neutron_* configuration settings\n\nCreate a new section in the configuration file called 'neutron'.\nMove all of the neutron_* configuration settings to this section.\n\nDocImpact\n\nThe table below has the changes:\n\n+---------------------------------+-------------------------+\n| 'DEFAULT' Section               | 'neutron' Section       |\n|---------------------------------|-------------------------|\n| neutron_url                     | url                     |\n| neutron_url_timeout             | url_timeout             |\n| neutron_admin_username          | admin_username          |\n| neutron_admin_password          | admin_password          |\n| neutron_admin_tenant_id         | admin_tenant_id         |\n| neutron_admin_tenant_name       | admin_tenant_name       |\n| neutron_region_name             | region_name             |\n| neutron_admin_auth_url          | admin_auth_url          |\n| neutron_api_insecure            | api_insecure            |\n| neutron_auth_strategy           | auth_strategy           |\n| neutron_region_name             | region_name             |\n| neutron_ovs_bridge              | ovs_bridge              |\n| neutron_extension_sync_interval | extension_sync_interval |\n| neutron_ca_certificates_file    | ca_certificates_file    |\n+---------------------------------+-----------------------=-+\n\nUpgradeImpact\nThe changes are backward compatible.\n\nChange-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876\n""}, {'number': 4, 'created': '2014-06-16 07:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32b63b8c86a71da3cd0b377ab44e69b4bceb0232', 'message': ""Deprecate neutron_* configuration settings\n\nCreate a new section in the configuration file called 'neutron'.\nMove all of the neutron_* configuration settings to this section.\n\nDocImpact\n\nThe table below has the changes:\n\n+---------------------------------+-------------------------+\n| 'DEFAULT' Section               | 'neutron' Section       |\n|---------------------------------|-------------------------|\n| neutron_url                     | url                     |\n| neutron_url_timeout             | url_timeout             |\n| neutron_admin_username          | admin_username          |\n| neutron_admin_password          | admin_password          |\n| neutron_admin_tenant_id         | admin_tenant_id         |\n| neutron_admin_tenant_name       | admin_tenant_name       |\n| neutron_region_name             | region_name             |\n| neutron_admin_auth_url          | admin_auth_url          |\n| neutron_api_insecure            | api_insecure            |\n| neutron_auth_strategy           | auth_strategy           |\n| neutron_region_name             | region_name             |\n| neutron_ovs_bridge              | ovs_bridge              |\n| neutron_extension_sync_interval | extension_sync_interval |\n| neutron_ca_certificates_file    | ca_certificates_file    |\n+---------------------------------+-----------------------=-+\n\nUpgradeImpact\nThe changes are backward compatible.\n\nChange-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876\n""}, {'number': 5, 'created': '2014-06-16 07:50:41.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'nova/network/neutronv2/__init__.py', 'nova/tests/integrated/v3/test_attach_interfaces.py', 'nova/tests/integrated/test_api_samples.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5cacad3508570ce70b1f9ef620e0508169687fda', 'message': ""Deprecate neutron_* configuration settings\n\nCreate a new section in the configuration file called 'neutron'.\nMove all of the neutron_* configuration settings to this section.\n\nDocImpact\n\nThe table below has the changes:\n\n+---------------------------------+-------------------------+\n| 'DEFAULT' Section               | 'neutron' Section       |\n|---------------------------------|-------------------------|\n| neutron_url                     | url                     |\n| neutron_url_timeout             | url_timeout             |\n| neutron_admin_username          | admin_username          |\n| neutron_admin_password          | admin_password          |\n| neutron_admin_tenant_id         | admin_tenant_id         |\n| neutron_admin_tenant_name       | admin_tenant_name       |\n| neutron_region_name             | region_name             |\n| neutron_admin_auth_url          | admin_auth_url          |\n| neutron_api_insecure            | api_insecure            |\n| neutron_auth_strategy           | auth_strategy           |\n| neutron_region_name             | region_name             |\n| neutron_ovs_bridge              | ovs_bridge              |\n| neutron_extension_sync_interval | extension_sync_interval |\n| neutron_ca_certificates_file    | ca_certificates_file    |\n+---------------------------------+-----------------------=-+\n\nUpgradeImpact\nThe changes are backward compatible.\n\nChange-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876\n""}]",4,97461,5cacad3508570ce70b1f9ef620e0508169687fda,54,10,5,1653,,,0,"Deprecate neutron_* configuration settings

Create a new section in the configuration file called 'neutron'.
Move all of the neutron_* configuration settings to this section.

DocImpact

The table below has the changes:

+---------------------------------+-------------------------+
| 'DEFAULT' Section               | 'neutron' Section       |
|---------------------------------|-------------------------|
| neutron_url                     | url                     |
| neutron_url_timeout             | url_timeout             |
| neutron_admin_username          | admin_username          |
| neutron_admin_password          | admin_password          |
| neutron_admin_tenant_id         | admin_tenant_id         |
| neutron_admin_tenant_name       | admin_tenant_name       |
| neutron_region_name             | region_name             |
| neutron_admin_auth_url          | admin_auth_url          |
| neutron_api_insecure            | api_insecure            |
| neutron_auth_strategy           | auth_strategy           |
| neutron_region_name             | region_name             |
| neutron_ovs_bridge              | ovs_bridge              |
| neutron_extension_sync_interval | extension_sync_interval |
| neutron_ca_certificates_file    | ca_certificates_file    |
+---------------------------------+-----------------------=-+

UpgradeImpact
The changes are backward compatible.

Change-Id: I3308be33f60c4add3e2e78b75f238059a9b3d876
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/97461/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/api/openstack/compute/contrib/test_attach_interfaces.py', 'nova/tests/api/openstack/compute/plugins/v3/test_attach_interfaces.py', 'nova/network/neutronv2/__init__.py', 'nova/tests/integrated/v3/test_attach_interfaces.py', 'nova/tests/integrated/test_api_samples.py']",7,d23c135d5595983efe174fa8c2a6535a56a99d13,neutron-conf," self.flags(auth_strategy=None, group='neutron') self.flags(url='http://anyhost/', group='neutron') self.flags(url_timeout=30, group='neutron')", self.flags(neutron_auth_strategy=None) self.flags(neutron_url='http://anyhost/') self.flags(neutron_url_timeout=30),106,80
openstack%2Fdevstack~stable%2Ficehouse~Ifbd336b83f6b2beb23996b599ec820232c13efdd,openstack/devstack,stable/icehouse,Ifbd336b83f6b2beb23996b599ec820232c13efdd,Add support for django_openstack_auth,MERGED,2014-06-23 11:29:36.000000000,2014-06-23 17:31:32.000000000,2014-06-23 17:31:31.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-06-23 11:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ef90002c41556a91464c289803245dc5ceba414c', 'message': 'Add support for django_openstack_auth\n\nIt would be useful for development, reviewing and testing to add\nsupport for django_openstack_auth to devstack.\n\nThis change adds the integration tests to the openstack_auth\nlist of test: https://review.openstack.org/#/c/86528/\n\nChange-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd\nCloses-Bug: #1262121\n(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)\n'}, {'number': 2, 'created': '2014-06-23 12:19:15.000000000', 'files': ['AUTHORS', 'stackrc', 'lib/horizon', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ea796c0598feeca099d3f57effe4abfb9cb05199', 'message': 'Add support for django_openstack_auth\n\nIt would be useful for development, reviewing and testing to add\nsupport for django_openstack_auth to devstack.\n\nThis change adds the integration tests to the openstack_auth\nlist of test: https://review.openstack.org/#/c/86528/\n\n(Use setup_install instead)\n\nChange-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd\nCloses-Bug: #1262121\n(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)\n'}]",0,101862,ea796c0598feeca099d3f57effe4abfb9cb05199,9,3,2,2750,,,0,"Add support for django_openstack_auth

It would be useful for development, reviewing and testing to add
support for django_openstack_auth to devstack.

This change adds the integration tests to the openstack_auth
list of test: https://review.openstack.org/#/c/86528/

(Use setup_install instead)

Change-Id: Ifbd336b83f6b2beb23996b599ec820232c13efdd
Closes-Bug: #1262121
(cherry picked from commit e385d1e0309a4fc5d414277260702a7c0fff6ad0)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/101862/1 && git format-patch -1 --stdout FETCH_HEAD,"['AUTHORS', 'stackrc', 'lib/horizon', 'stack.sh']",4,ef90002c41556a91464c289803245dc5ceba414c,, # django openstack_auth install_django_openstack_auth,,14,0
openstack%2Ffuel-web~master~I3b9810fe0d2000a65b3539e88cde9f50d634a54f,openstack/fuel-web,master,I3b9810fe0d2000a65b3539e88cde9f50d634a54f,"Lodash upgraded to the latest version, 2.4.1",ABANDONED,2014-06-23 10:01:32.000000000,2014-06-23 16:59:58.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-06-23 10:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1890b90635422ea9ec8d9e73a634729beafea206', 'message': 'Lodash upgraded to the latest version, 2.4.1\n\nChange-Id: I3b9810fe0d2000a65b3539e88cde9f50d634a54f\nCloses-bug: https://bugs.launchpad.net/fuel/+bug/1281076\n'}, {'number': 2, 'created': '2014-06-23 13:46:15.000000000', 'files': ['nailgun/bower.json'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/075d99c5cd0041b384ac3b5553fd038927ee8e9c', 'message': 'Lodash upgraded to the latest version, 2.4.1\n\nChange-Id: I3b9810fe0d2000a65b3539e88cde9f50d634a54f\nCloses-bug: https://bugs.launchpad.net/fuel/+bug/1281076\n'}]",2,101843,075d99c5cd0041b384ac3b5553fd038927ee8e9c,17,6,2,9091,,,0,"Lodash upgraded to the latest version, 2.4.1

Change-Id: I3b9810fe0d2000a65b3539e88cde9f50d634a54f
Closes-bug: https://bugs.launchpad.net/fuel/+bug/1281076
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/43/101843/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/bower.json'],1,1890b90635422ea9ec8d9e73a634729beafea206,lodash_upgrade," ""lodash"": ""2.4.1"","," ""lodash"": ""1.1.1"",",1,1
openstack%2Fdevstack~master~Ic24f76429f7c2bc41be2bfcc79afb128ec9305c0,openstack/devstack,master,Ic24f76429f7c2bc41be2bfcc79afb128ec9305c0,Adds spport for two config parameters,ABANDONED,2014-06-20 22:03:42.000000000,2014-06-23 16:56:05.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 22:03:42.000000000', 'files': ['lib/neutron_plugins/ibm'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b9819e6db0cee4ff690963e4d9840dd350da3c89', 'message': 'Adds spport for two config parameters\n\nAdds support for two configuration paramters, namely\nthe admin userid and password for the SDN-VE controller.\n\nChange-Id: Ic24f76429f7c2bc41be2bfcc79afb128ec9305c0\n'}]",0,101661,b9819e6db0cee4ff690963e4d9840dd350da3c89,6,3,1,1923,,,0,"Adds spport for two config parameters

Adds support for two configuration paramters, namely
the admin userid and password for the SDN-VE controller.

Change-Id: Ic24f76429f7c2bc41be2bfcc79afb128ec9305c0
",git fetch https://review.opendev.org/openstack/devstack refs/changes/61/101661/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ibm'],1,b9819e6db0cee4ff690963e4d9840dd350da3c89,config_params," if [[ ""$SDNVE_USERID"" != """" ]]; then iniset /$Q_PLUGIN_CONF_FILE sdnve userid $SDNVE_USERID fi if [[ ""$SDNVE_PASSWORD"" != """" ]]; then iniset /$Q_PLUGIN_CONF_FILE sdnve password $SDNVE_PASSWORD fi ",,8,0
openstack%2Fmistral-dashboard~master~I356c8cdc8ef005ccf907b39d7cf480cf1f000127,openstack/mistral-dashboard,master,I356c8cdc8ef005ccf907b39d7cf480cf1f000127,Readme updates,MERGED,2014-06-23 16:41:31.000000000,2014-06-23 16:51:42.000000000,2014-06-23 16:51:42.000000000,"[{'_account_id': 3}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-23 16:41:31.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/92209c349fc36f1fd2fa09a426ff5489e1d2a9b4', 'message': 'Readme updates\n\nChange-Id: I356c8cdc8ef005ccf907b39d7cf480cf1f000127\n'}]",0,101952,92209c349fc36f1fd2fa09a426ff5489e1d2a9b4,7,2,1,10127,,,0,"Readme updates

Change-Id: I356c8cdc8ef005ccf907b39d7cf480cf1f000127
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/52/101952/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,92209c349fc36f1fd2fa09a426ff5489e1d2a9b4,bp/mistral-ui,"Since Mistral only supports Identity v3, you must ensure that the dashboard points the proper OPENSTACK_KEYSTONE_URL in ``local_settings.py`` file::Register Mistral service and Mistral endpoints on Keystone (required if Mistral and Horizon dashboard run on a different boxes)::","Since Mistral only supports Identity v3, you may need to edit the ``local_settings.py`` file to point to proper OPENSTACK_KEYSTONE_URL::Depending on your setup, you may also need to add a service and endpoints to keystone::",4,4
openstack%2Fpuppet-openstack-specs~master~I5c388b5b655437a58a81a51ad19d698a46235c61,openstack/puppet-openstack-specs,master,I5c388b5b655437a58a81a51ad19d698a46235c61,Simplification of specifications,ABANDONED,2014-05-29 22:50:35.000000000,2014-06-23 16:47:32.000000000,,"[{'_account_id': 3}, {'_account_id': 2265}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-05-29 22:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/d13cd0871320a1839a9e6912aca15132a96f27a9', 'message': ""Simplification of specifications\n\nThis comment mostly removed text from the\ninitial commit of template.rst.\n\nThe purpose of removing text is to simplify the\nrequirements for creating templates while we learn how\nto do it. We can always add more process later.\n\n- creates a section for template guidelines and makes it\nseparate from text that is part of the template\n\n- removes requirements for blueprint. I thought we were doing\nthis instead of blueprints. Can we try either one or the other,\nbut not both?\n\n- changes deployer to developer, I don't understand the difference\nbetween a end-user and deployer for our purposes.\n\n- removed data model impact section - this does not seem relevnet to\nus. We are not building a schema\n\n- changes deployer impact to make it more relevent for our use cases.\n\n- removes developer impact section - I an not sure what would go there.\n\n- removes irrelevent dep language\n\n- removes testing section - right now, we are really only doing unit testing.\nAs our testing ability increases, it makes sense to add this back, but for\nnow, it is not relevent.\n\n- removes docs section - there is no docs team for the modules\n\nChange-Id: I5c388b5b655437a58a81a51ad19d698a46235c61\n""}, {'number': 2, 'created': '2014-05-30 03:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/7a3c665f4e9aed4f31e6a69afc463d61bec4ad9f', 'message': 'Simplification of specifications\n\nThis comment mostly removed text from the\ninitial commit of template.rst.\n\nThe purpose of removing text is to simplify the\nrequirements for creating templates while we learn how\nto do it. We can always add more process later.\n\n- creates a section for template guidelines and makes it\nseparate from text that is part of the template\n\n- changes end user to deployer\n\n- removed data model impact section - this does not seem relevnet to\nus. We are not building a schema\n\n- changes deployer impact to make it more relevent for our use cases.\n\n- removes developer impact section - I an not sure what would go there.\n\n- removes irrelevent dep language\n\n- removes testing section - right now, we are really only doing unit testing.\nAs our testing ability increases, it makes sense to add this back, but for\nnow, it is not relevent.\n\n- removes docs section - there is no docs team for the modules\n\nChange-Id: I5c388b5b655437a58a81a51ad19d698a46235c61\n'}, {'number': 3, 'created': '2014-05-30 03:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/71d5a14665c02aa8763bb12075eed30bdde8c4df', 'message': 'Simplification of specifications\n\nThis comment mostly removed text from the\ninitial commit of template.rst.\n\nThe purpose of removing text is to simplify the\nrequirements for creating templates while we learn how\nto do it. We can always add more process later.\n\n- creates a section for template guidelines and makes it\nseparate from text that is part of the template\n\n- changes end user to deployer\n\n- removed data model impact section - this does not seem relevnet to\nus. We are not building a schema\n\n- changes deployer impact to make it more relevent for our use cases.\n\n- removes developer impact section - I an not sure what would go there.\n\n- removes irrelevent dep language\n\n- removes testing section - right now, we are really only doing unit testing.\nAs our testing ability increases, it makes sense to add this back, but for\nnow, it is not relevent.\n\n- removes docs section - there is no docs team for the modules\n\nChange-Id: I5c388b5b655437a58a81a51ad19d698a46235c61\n'}, {'number': 4, 'created': '2014-05-30 03:36:47.000000000', 'files': ['specs/template.rst', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/13807b861d114d8cde455fec2bd4839d2bee36e6', 'message': 'Simplification of specifications\n\nThis comment mostly removed text from the\ninitial commit of template.rst.\n\nThe purpose of removing text is to simplify the\nrequirements for creating templates while we learn how\nto do it. We can always add more process later.\n\n- creates a section for template guidelines and moves it to README\n\n- changes end user to deployer\n\n- removed data model impact section - this does not seem relevnet to\nus. We are not building a schema\n\n- changes deployer impact to make it more relevent for our use cases.\n\n- removes developer impact section - I an not sure what would go there.\n\n- removes irrelevent dep language\n\n- removes testing section - right now, we are really only doing unit testing.\nAs our testing ability increases, it makes sense to add this back, but for\nnow, it is not relevent.\n\n- removes docs section - there is no docs team for the modules\n\nChange-Id: I5c388b5b655437a58a81a51ad19d698a46235c61\n'}]",12,96627,13807b861d114d8cde455fec2bd4839d2bee36e6,18,4,4,2265,,,0,"Simplification of specifications

This comment mostly removed text from the
initial commit of template.rst.

The purpose of removing text is to simplify the
requirements for creating templates while we learn how
to do it. We can always add more process later.

- creates a section for template guidelines and moves it to README

- changes end user to deployer

- removed data model impact section - this does not seem relevnet to
us. We are not building a schema

- changes deployer impact to make it more relevent for our use cases.

- removes developer impact section - I an not sure what would go there.

- removes irrelevent dep language

- removes testing section - right now, we are really only doing unit testing.
As our testing ability increases, it makes sense to add this back, but for
now, it is not relevent.

- removes docs section - there is no docs team for the modules

Change-Id: I5c388b5b655437a58a81a51ad19d698a46235c61
",git fetch https://review.opendev.org/openstack/puppet-openstack-specs refs/changes/27/96627/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/template.rst'],1,d13cd0871320a1839a9e6912aca15132a96f27a9,bp/s,"General Guidelines for create a spec========================================== Example Spec - The title of your spec ========================================== Introduction paragraph -- why are we doing anything? A single paragraph of prose that operators can understand. actors in each use case: End User vs DeveloperDiscuss things that will affect how people use the module to deploy Openstack. * Is this a change that takes immediate effect after its merged, or is it any plans to deprecate configuration values or features.* Include specific references to specs or tickets, or patches.","Example Spec - The title of your blueprintInclude the URL of your launchpad blueprint: https://blueprints.launchpad.net/puppet-[projectname]/+spec/example Introduction paragraph -- why are we doing anything? A single paragraph of prose that operators can understand. actors in each use case: End User vs DeployerData model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change. * How will the initial set of new data objects be generated, for example if you need to take into account existing instances, or modify other existing data describe how that will work. * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted . End user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-novaclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition but if it calls conductor or another service the load is multiplied by the number of nodes in the system. * Scheduler filters get called once per host for every instance being created, so any latency they introduce is linear with the size of the system. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries (whether direct or via conductor) can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it* If this change is a new binary, how would it be deployed? any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on Puppet OpenStack, such as.* Include specific references to specs and/or blueprints in nova, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Nova (such as the glance v2 API when we previously only required v1), document that fact. Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) ",13,126
openstack%2Fmistral-dashboard~master~I1960a69b486b9a8a41740da48a3ecee109148740,openstack/mistral-dashboard,master,I1960a69b486b9a8a41740da48a3ecee109148740,Make use of /executions endpoint API,MERGED,2014-06-23 09:27:19.000000000,2014-06-23 16:47:03.000000000,2014-06-23 16:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-23 09:27:19.000000000', 'files': ['mistraldashboard/executions/views.py'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/9c122b312df8559a8cda233a606febae44c76c0f', 'message': 'Make use of /executions endpoint API\n\nChange-Id: I1960a69b486b9a8a41740da48a3ecee109148740\nImplements: blueprint mistral-ui\n'}]",0,101835,9c122b312df8559a8cda233a606febae44c76c0f,12,8,1,10127,,,0,"Make use of /executions endpoint API

Change-Id: I1960a69b486b9a8a41740da48a3ecee109148740
Implements: blueprint mistral-ui
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/35/101835/1 && git format-patch -1 --stdout FETCH_HEAD,['mistraldashboard/executions/views.py'],1,9c122b312df8559a8cda233a606febae44c76c0f,bp/mistral-ui," return client.executions.list(None) return client.tasks.list(None, self.kwargs['execution_id'])"," return [item for wb in client.workbooks.list() for item in client.executions.list(wb.name)] return [item for wb in client.workbooks.list() for item in client.tasks.list(wb.name, self.kwargs['execution_id'])]",2,5
openstack%2Fmistral-dashboard~master~If3fb4eddec26c5817cb0971eb7c4fe2ebb5641f3,openstack/mistral-dashboard,master,If3fb4eddec26c5817cb0971eb7c4fe2ebb5641f3,Horizon plugin system compatibility,MERGED,2014-06-23 07:56:31.000000000,2014-06-23 16:46:52.000000000,2014-06-23 16:46:52.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-23 07:56:31.000000000', 'files': ['mistraldashboard/workbooks/views.py', 'README.rst', 'mistraldashboard/dashboards/mistral/workbooks/__init__.py', 'mistraldashboard/executions/__init__.py', 'mistraldashboard/local/__init__.py', 'requirements.txt', 'mistraldashboard/dashboards/mistral/__init__.py', 'mistraldashboard/executions/tables.py', 'mistraldashboard/workbooks/urls.py', 'mistraldashboard/api.py', 'mistraldashboard/workbooks/tables.py', 'mistraldashboard/workbooks/templates/workbooks/index.html', 'mistraldashboard/workbooks/templates/workbooks/_execute.html', 'mistraldashboard/workbooks/forms.py', 'mistraldashboard/executions/templates/executions/index.html', 'mistraldashboard/local/local_settings.py.example', 'mistraldashboard/models.py', 'mistraldashboard/settings.py', 'mistraldashboard/executions/views.py', 'mistraldashboard/workbooks/__init__.py', 'mistraldashboard/executions/templates/executions/_label.html', 'mistraldashboard/workbooks/templates/workbooks/execute.html', 'mistraldashboard/dashboard.py', '_50_mistral.py.example', 'mistraldashboard/workbooks/panel.py', 'mistraldashboard/executions/urls.py', 'mistraldashboard/dashboards/mistral/executions/__init__.py', 'mistraldashboard/executions/panel.py'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/744309b2e1b46ee6f588ce4909713e3990ce1f8c', 'message': 'Horizon plugin system compatibility\n\n- added enabled script\n- removed horizon from requirements\n- updated README\n- refactor folder structure\n\nChange-Id: If3fb4eddec26c5817cb0971eb7c4fe2ebb5641f3\nImplements: blueprint mistral-ui\n'}]",5,101820,744309b2e1b46ee6f588ce4909713e3990ce1f8c,10,8,1,10127,,,0,"Horizon plugin system compatibility

- added enabled script
- removed horizon from requirements
- updated README
- refactor folder structure

Change-Id: If3fb4eddec26c5817cb0971eb7c4fe2ebb5641f3
Implements: blueprint mistral-ui
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/20/101820/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistraldashboard/workbooks/views.py', 'README.rst', 'mistraldashboard/dashboards/mistral/workbooks/__init__.py', 'mistraldashboard/executions/__init__.py', 'mistraldashboard/local/__init__.py', 'requirements.txt', 'mistraldashboard/dashboards/mistral/__init__.py', 'mistraldashboard/executions/tables.py', 'mistraldashboard/workbooks/urls.py', 'mistraldashboard/api.py', 'mistraldashboard/workbooks/tables.py', 'mistraldashboard/workbooks/templates/workbooks/index.html', 'mistraldashboard/workbooks/templates/workbooks/_execute.html', 'mistraldashboard/workbooks/forms.py', 'mistraldashboard/executions/templates/executions/index.html', 'mistraldashboard/local/local_settings.py.example', 'mistraldashboard/models.py', 'mistraldashboard/settings.py', 'mistraldashboard/executions/views.py', 'mistraldashboard/workbooks/__init__.py', 'mistraldashboard/executions/templates/executions/_label.html', 'mistraldashboard/workbooks/templates/workbooks/execute.html', 'mistraldashboard/dashboard.py', '_50_mistral.py.example', 'mistraldashboard/workbooks/panel.py', 'mistraldashboard/executions/urls.py', 'mistraldashboard/dashboards/mistral/executions/__init__.py', 'mistraldashboard/executions/panel.py']",28,744309b2e1b46ee6f588ce4909713e3990ce1f8c,bp/mistral-ui,from mistraldashboard import dashboard,from mistraldashboard.dashboards.mistral import dashboard,41,780
openstack%2Fbarbican~master~I7d80011e18584bf515b112ac1edebf93b792b9bc,openstack/barbican,master,I7d80011e18584bf515b112ac1edebf93b792b9bc,fix for - JSONErrorHook is not setting content type to JSON,MERGED,2014-06-16 16:51:01.000000000,2014-06-23 16:44:31.000000000,2014-06-23 16:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 8004}, {'_account_id': 9234}]","[{'number': 1, 'created': '2014-06-16 16:51:01.000000000', 'files': ['barbican/api/app.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/07697cfb52eb458900c54195cf3c365832330bf9', 'message': 'fix for - JSONErrorHook is not setting content type to JSON\n\nCloses-bug #1330541\n\nChange-Id: I7d80011e18584bf515b112ac1edebf93b792b9bc\n'}]",1,100295,07697cfb52eb458900c54195cf3c365832330bf9,16,7,1,994,,,0,"fix for - JSONErrorHook is not setting content type to JSON

Closes-bug #1330541

Change-Id: I7d80011e18584bf515b112ac1edebf93b792b9bc
",git fetch https://review.opendev.org/openstack/barbican refs/changes/95/100295/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/app.py', 'barbican/tests/api/test_resources.py']",2,07697cfb52eb458900c54195cf3c365832330bf9,bug/1330541," #Error response should have json content type self.assertEqual(resp.content_type, ""application/json"") #Error response should have json content type self.assertEqual(resp.content_type, ""application/json"") #Error response should have json content type self.assertEqual(resp.content_type, ""application/json"")",,7,0
openstack%2Fpython-blazarclient~master~Iebe931b09bec23425488ce2d854fd3e1534a3b71,openstack/python-blazarclient,master,Iebe931b09bec23425488ce2d854fd3e1534a3b71,Add test coverage for base client modules,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-23 16:43:30.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7166}, {'_account_id': 7535}, {'_account_id': 10200}]","[{'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': ['climateclient/tests/test_client.py', 'climateclient/tests/test_command.py', 'climateclient/tests/test_base.py', 'climateclient/tests/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/b49432a79db95d86367a82a160b5e8e224bf445e', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/dc944bcda0d8d59d65e2ab1628c903d45b44c6de', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/cea39de789f3907571baf9b0fb56c3b5ef341195', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/9e0fa27f106ab7009915ad28ad6302a31836eb42', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/55d820355b8fdc0ffbfd5a258e8ab5edeba41e69', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-blazarclient/commit/607e515cbfb4eb21e56793a893e479bb5a65f4d1', 'message': 'Add test coverage for base client modules\n\nAdd tests for base client modules such as climateclient/base.py,\nclimateclient/client.py, etc.\n\nChange-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71\n'}]",0,73574,b49432a79db95d86367a82a160b5e8e224bf445e,33,5,6,7535,,,0,"Add test coverage for base client modules

Add tests for base client modules such as climateclient/base.py,
climateclient/client.py, etc.

Change-Id: Iebe931b09bec23425488ce2d854fd3e1534a3b71
",git fetch https://review.opendev.org/openstack/python-blazarclient refs/changes/74/73574/6 && git format-patch -1 --stdout FETCH_HEAD,"['climateclient/tests/test_client.py', 'climateclient/tests/test_command.py', 'climateclient/tests/test_base.py', 'climateclient/tests/test_shell.py']",4,b49432a79db95d86367a82a160b5e8e224bf445e,test_0,"# Copyright (c) 2014 Mirantis Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import re import six import sys import fixtures #note(n.s.): you may need it later #import mock import testtools #note(n.s.): you may need it later #from climateclient import client as climate_client #from climateclient import exception from climateclient import shell from climateclient import tests FAKE_ENV = {'OS_USERNAME': 'username', 'OS_PASSWORD': 'password', 'OS_TENANT_NAME': 'tenant_name', 'OS_AUTH_URL': 'http://no.where'} class ClimateShellTestCase(tests.TestCase): def make_env(self, exclude=None, fake_env=FAKE_ENV): env = dict((k, v) for k, v in fake_env.items() if k != exclude) self.useFixture(fixtures.MonkeyPatch('os.environ', env)) def setUp(self): super(ClimateShellTestCase, self).setUp() #Create shell for non-specific tests self.climate_shell = shell.ClimateShell() def shell(self, argstr, exitcodes=(0,)): orig = sys.stdout orig_stderr = sys.stderr try: sys.stdout = six.StringIO() sys.stderr = six.StringIO() _shell = shell.ClimateShell() _shell.initialize_app(argstr.split()) except SystemExit: exc_type, exc_value, exc_traceback = sys.exc_info() self.assertIn(exc_value.code, exitcodes) finally: stdout = sys.stdout.getvalue() sys.stdout.close() sys.stdout = orig stderr = sys.stderr.getvalue() sys.stderr.close() sys.stderr = orig_stderr return (stdout, stderr) def test_help_unknown_command(self): self.assertRaises(ValueError, self.shell, 'bash-completion') @testtools.skip('lol') def test_bash_completion(self): stdout, stderr = self.shell('bash-completion') # just check we have some output required = [ '.*--matching', '.*--wrap', '.*help', '.*secgroup-delete-rule', '.*--priority'] for r in required: self.assertThat((stdout + stderr), testtools.matchers.MatchesRegex( r, re.DOTALL | re.MULTILINE)) @testtools.skip('lol') def test_authenticate_user(self): obj = shell.ClimateShell() obj.initialize_app('list-leases') obj.options.os_token = 'aaaa-bbbb-cccc' obj.options.os_cacert = 'cert' obj.authenticate_user() ",,378,0
openstack%2Fnova~master~Ic468cd57688b370a18cacfc6e0844a8201eb9ab3,openstack/nova,master,Ic468cd57688b370a18cacfc6e0844a8201eb9ab3,Target host in evacuate can't be the original one,MERGED,2014-02-11 04:16:15.000000000,2014-06-23 16:39:12.000000000,2014-06-23 16:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 7040}, {'_account_id': 7730}, {'_account_id': 8021}, {'_account_id': 8163}, {'_account_id': 8276}, {'_account_id': 8328}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9275}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-02-11 04:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90cb9a0930671510776b2e303281a8b3519aef25', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 2, 'created': '2014-02-12 06:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6537f1f42d17002ca033fb340d6c01ad6e5cb8d0', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 3, 'created': '2014-02-14 08:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0b140c90fbe2e06d2510a37a1d4c0dbabeb4b1f', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 4, 'created': '2014-02-17 09:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cad09ec2eb8b57760465066b198801ac7a0f9eaa', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 5, 'created': '2014-02-17 11:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/909ebd4884efbdf4ee45a60c21457374ac58bc97', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 6, 'created': '2014-02-25 03:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b68108dc18c49c726a89ecc2f4f400c820ff9524', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 7, 'created': '2014-02-25 07:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/beaf50627821b5e233abaab7c411269bbe231e73', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 8, 'created': '2014-03-24 06:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19264684cf3b8c0667f5a86f1d98dce788348092', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 9, 'created': '2014-04-29 01:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7759c928172df65ec74287709ce4d5095b0d5962', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nSo we need to add protections here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 10, 'created': '2014-06-18 07:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f6a2cba4ddb32073d359e6783f6972a25e7c828', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nIf no protection, the API response is still right, but the vm_state will be changed to ERROR after nova-compute started, due to the 'InstanceExists' exception raised from 'rebuild_instance()'.\n \nSo we need to add verification here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 11, 'created': '2014-06-18 07:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f261e9126522e059c99d3919d9ecc485dcf3b87', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nIf no protection, the API response is still right,\nbut the vm_state will be changed to ERROR after nova-compute started,\ndue to the 'InstanceExists' exception raised from 'rebuild_instance()'.\n \nSo we need to add verification here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}, {'number': 12, 'created': '2014-06-23 01:55:08.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_evacuate.py', 'nova/tests/integrated/v3/test_evacuate.py', 'nova/tests/integrated/test_api_samples.py', 'nova/api/openstack/compute/contrib/evacuate.py', 'nova/tests/api/openstack/compute/plugins/v3/test_evacuate.py', 'nova/api/openstack/compute/plugins/v3/evacuate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/951bae39e704b04414ebb711b425631cf2d46be5', 'message': ""Target host in evacuate can't be the original one\n\n'Evacuate' function aims to help administrator/operator to evacuate\nservers if this compute node fails.\n\nIf no protection, the API returns a successful response,\nbut the vm_state will be changed to ERROR after nova-compute started,\ndue to the 'InstanceExists' exception raised from 'rebuild_instance()'.\n\nSo we need to add verification here, the target host should not be the\noriginal host.\n\nChange-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3\nCloses-Bug: #1271821\n""}]",20,72554,951bae39e704b04414ebb711b425631cf2d46be5,212,23,12,8021,,,0,"Target host in evacuate can't be the original one

'Evacuate' function aims to help administrator/operator to evacuate
servers if this compute node fails.

If no protection, the API returns a successful response,
but the vm_state will be changed to ERROR after nova-compute started,
due to the 'InstanceExists' exception raised from 'rebuild_instance()'.

So we need to add verification here, the target host should not be the
original host.

Change-Id: Ic468cd57688b370a18cacfc6e0844a8201eb9ab3
Closes-Bug: #1271821
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/72554/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/evacuate.py', 'nova/api/openstack/compute/plugins/v3/evacuate.py', 'nova/compute/api.py']",3,90cb9a0930671510776b2e303281a8b3519aef25,bug/1271821," if inst_host is host: msg = (_(""The target host can't be the original one."")) LOG.error(msg) raise exception.InvalidInput(reason=msg)",,8,0
openstack%2Fcinder~master~I49e858b8536e30572b6231f209a35578460fff96,openstack/cinder,master,I49e858b8536e30572b6231f209a35578460fff96,"GlusterFS tests: Mock out compute, don't load novaclient",MERGED,2014-06-19 17:02:13.000000000,2014-06-23 16:32:23.000000000,2014-06-23 16:32:23.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 9751}, {'_account_id': 10796}]","[{'number': 1, 'created': '2014-06-19 17:02:13.000000000', 'files': ['cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0072d5352c27dbaef4a95325ebf9e7af96f2991', 'message': ""GlusterFS tests: Mock out compute, don't load novaclient\n\nMock out the compute library for these tests, which prevents loading\nthe novaclient library.\n\nThis makes these tests more reliable, as currently the novaclient\nlib interferes with our mocking of os.path.exists in these tests\nin some test configurations.\n\nThis should also make the GlusterFS tests slightly more efficient\nsince they were previously loading the novaclient python library\nbut did not really need to.\n\nChange-Id: I49e858b8536e30572b6231f209a35578460fff96\n""}]",0,101252,e0072d5352c27dbaef4a95325ebf9e7af96f2991,12,5,1,4523,,,0,"GlusterFS tests: Mock out compute, don't load novaclient

Mock out the compute library for these tests, which prevents loading
the novaclient library.

This makes these tests more reliable, as currently the novaclient
lib interferes with our mocking of os.path.exists in these tests
in some test configurations.

This should also make the GlusterFS tests slightly more efficient
since they were previously loading the novaclient python library
but did not really need to.

Change-Id: I49e858b8536e30572b6231f209a35578460fff96
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/101252/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_glusterfs.py'],1,e0072d5352c27dbaef4a95325ebf9e7af96f2991,glusterfs_tests,from cinder import compute compute.API = mock.MagicMock(),,2,0
openstack%2Ffuel-web~master~If90709756ccb6022641b915e47a5c7af4fe1fc1c,openstack/fuel-web,master,If90709756ccb6022641b915e47a5c7af4fe1fc1c,change assert(Not)Equals to assert(Not)Equal,MERGED,2014-05-15 20:18:13.000000000,2014-06-23 16:27:44.000000000,2014-06-23 16:27:43.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8787}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-05-15 20:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/73dd55dd7dbf494caf065ad7a360559dba22da20', 'message': 'change assertEquals to assertEqual\n\nAccording to http://docs.python.org/2/library/unittest.html\nassertEquals is a deprecated alias of assertEqual.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\n'}, {'number': 2, 'created': '2014-05-15 21:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/39385585f471ecd92e14403b9e3bcec0c9756132', 'message': 'change assertEquals to assertEqual\n\nAccording to http://docs.python.org/2/library/unittest.html\nassertEquals is a deprecated alias of assertEqual.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\n'}, {'number': 3, 'created': '2014-05-29 19:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0cbc97754fbcbe23c94eff8563235825488be069', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\n'}, {'number': 4, 'created': '2014-05-29 21:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/34eb7ae4ed07850aa05a21eb063fe84c7bbda094', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\n'}, {'number': 5, 'created': '2014-06-06 06:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4f6c027f74752b6f82a7681ecd8403cbbce20e05', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\n'}, {'number': 6, 'created': '2014-06-13 12:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3c1babc863da6299446eb61bc61796d0f4bd479e', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\nCloses-Bug: #1329757\n'}, {'number': 7, 'created': '2014-06-17 15:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/31454907c3c7ed437a552fe32e1bdbdd1bc2aeb2', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\nCloses-Bug: #1329757\n'}, {'number': 8, 'created': '2014-06-23 07:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a40282d91cb5692ec878587793b3e72e0a5adc9c', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\nCloses-Bug: #1329757\n'}, {'number': 9, 'created': '2014-06-23 13:23:46.000000000', 'files': ['nailgun/nailgun/test/unit/test_assignment_validator.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_supervisor_client.py', 'nailgun/nailgun/test/unit/test_network_check.py', 'nailgun/nailgun/test/integration/test_node_allocation_stats_handler.py', 'nailgun/nailgun/test/integration/test_attributes.py', 'nailgun/nailgun/test/integration/test_cluster_collection_handlers.py', 'nailgun/nailgun/test/integration/test_network_configuration.py', 'nailgun/nailgun/test/integration/test_cluster_scaling.py', 'nailgun/nailgun/test/unit/test_release_collection_handlers.py', 'nailgun/nailgun/test/integration/test_db_refresh.py', 'shotgun/shotgun/test/test_driver.py', 'nailgun/nailgun/test/unit/test_node_assignment_handler.py', 'nailgun/nailgun/test/unit/test_task_handler.py', 'nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/test/integration/test_charset_issues.py', 'nailgun/nailgun/test/integration/test_provisioning_serializer.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/test/integration/test_deployment_error_handling.py', 'nailgun/nailgun/test/integration/test_provisioning.py', 'nailgun/nailgun/test/integration/test_redhat.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py', 'nailgun/nailgun/test/integration/test_verify_networks_task_manager.py', 'nailgun/nailgun/test/integration/test_reset_environment.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/test/unit/test_rpc_receiver.py', 'nailgun/nailgun/test/unit/test_redhat.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py', 'nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_orchestrator_handlers.py', 'nailgun/nailgun/test/integration/test_rpc_consumer.py', 'nailgun/nailgun/test/integration/test_network_models.py', 'nailgun/nailgun/test/integration/test_capacity_handler.py', 'nailgun/nailgun/test/integration/test_notification.py', 'fuel_upgrade_system/fuel_update_downloader/fuel_update_downloader/tests/test_utils.py', 'nailgun/nailgun/test/integration/test_node_nic_handlers_w_bonding.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_node_handler.py', 'nailgun/nailgun/test/integration/test_node_nic_assignment.py', 'shotgun/shotgun/test/test_config.py', 'nailgun/nailgun/test/integration/test_node_collection_handlers.py', 'nailgun/nailgun/test/integration/test_stop_deployment.py', 'nailgun/nailgun/test/unit/test_task_helpers.py', 'nailgun/nailgun/test/unit/test_node_nic_handler.py', 'nailgun/nailgun/test/integration/test_changes_model.py', 'nailgun/nailgun/test/unit/test_node_deletion.py', 'nailgun/nailgun/test/integration/test_horizon_url.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_utils.py', 'nailgun/nailgun/test/integration/test_network_validation.py', 'nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/unit/test_notification_handler.py', 'nailgun/nailgun/test/unit/test_notification_collection_handler.py', 'nailgun/nailgun/test/integration/test_node_nic_collection_handler.py', 'nailgun/nailgun/test/unit/test_logs_handlers.py', 'nailgun/nailgun/test/unit/test_task.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f78b4a0854e10b48668fb92308ace0820d1a8fe0', 'message': 'change assert(Not)Equals to assert(Not)Equal\n\nAccording to http://docs.python.org/2/library/unittest.html\nassert(Not)Equals is a deprecated alias of assert(Not)Equal.\n\nChange-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c\nCloses-Bug: #1329757\n'}]",0,93797,f78b4a0854e10b48668fb92308ace0820d1a8fe0,72,5,9,167,,,0,"change assert(Not)Equals to assert(Not)Equal

According to http://docs.python.org/2/library/unittest.html
assert(Not)Equals is a deprecated alias of assert(Not)Equal.

Change-Id: If90709756ccb6022641b915e47a5c7af4fe1fc1c
Closes-Bug: #1329757
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/97/93797/9 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_assignment_validator.py', 'nailgun/nailgun/test/integration/test_node_allocation_stats_handler.py', 'nailgun/nailgun/test/integration/test_attributes.py', 'nailgun/nailgun/test/integration/test_cluster_collection_handlers.py', 'nailgun/nailgun/test/integration/test_network_configuration.py', 'nailgun/nailgun/test/integration/test_cluster_scaling.py', 'nailgun/nailgun/test/unit/test_release_collection_handlers.py', 'nailgun/nailgun/test/integration/test_db_refresh.py', 'shotgun/shotgun/test/test_driver.py', 'nailgun/nailgun/test/unit/test_node_assignment_handler.py', 'nailgun/nailgun/test/unit/test_task_handler.py', 'nailgun/nailgun/test/integration/test_network_manager.py', 'nailgun/nailgun/test/integration/test_charset_issues.py', 'nailgun/nailgun/test/integration/test_provisioning_serializer.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/test/integration/test_deployment_error_handling.py', 'nailgun/nailgun/test/integration/test_provisioning.py', 'nailgun/nailgun/test/integration/test_redhat.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/test/integration/test_verify_networks_task_manager.py', 'nailgun/nailgun/test/integration/test_reset_environment.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/test/unit/test_rpc_receiver.py', 'nailgun/nailgun/test/unit/test_redhat.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py', 'nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_orchestrator_handlers.py', 'nailgun/nailgun/test/integration/test_rpc_consumer.py', 'nailgun/nailgun/test/integration/test_network_models.py', 'nailgun/nailgun/test/integration/test_capacity_handler.py', 'nailgun/nailgun/test/integration/test_notification.py', 'fuel_upgrade_system/fuel_update_downloader/fuel_update_downloader/tests/test_utils.py', 'nailgun/nailgun/test/integration/test_node_nic_handlers_w_bonding.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_node_handler.py', 'nailgun/nailgun/test/integration/test_node_nic_assignment.py', 'shotgun/shotgun/test/test_config.py', 'nailgun/nailgun/test/integration/test_node_collection_handlers.py', 'nailgun/nailgun/test/integration/test_stop_deployment.py', 'nailgun/nailgun/test/unit/test_task_helpers.py', 'nailgun/nailgun/test/unit/test_node_nic_handler.py', 'nailgun/nailgun/test/integration/test_changes_model.py', 'nailgun/nailgun/test/unit/test_node_deletion.py', 'nailgun/nailgun/test/integration/test_horizon_url.py', 'nailgun/nailgun/test/integration/test_network_validation.py', 'nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/unit/test_notification_handler.py', 'nailgun/nailgun/test/unit/test_notification_collection_handler.py', 'nailgun/nailgun/test/integration/test_node_nic_collection_handler.py', 'nailgun/nailgun/test/unit/test_logs_handlers.py', 'nailgun/nailgun/test/unit/test_task.py']",51,73dd55dd7dbf494caf065ad7a360559dba22da20,replace_assertEquals_with_assertEqual," self.assertEqual(node.status, 'error') self.assertEqual(node.error_type, error_type) self.assertEqual(node.progress, 0) self.assertEqual(node.status, 'discover') self.assertEqual(self.cluster.status, 'error') self.assertEqual(self.cluster.status, 'error') self.assertEqual(self.cluster.status, 'error') self.assertEqual(self.cluster.status, 'operational') self.assertEqual(self.cluster.status, 'operational') self.assertEqual(node.status, 'ready') self.assertEqual(node.progress, 100) self.assertEqual(self.cluster.status, 'error') self.assertEqual(task.status, 'error') self.assertEqual(node.status, 'error') self.assertEqual(node.progress, 0) self.assertEqual(self.cluster.status, 'new') self.assertEqual(self.node.status, status) self.assertEqual(self.node.error_type, error_type) self.assertEqual(check_mock.call_count, 1) self.assertEqual(check_mock.call_count, 1)"," self.assertEquals(node.status, 'error') self.assertEquals(node.error_type, error_type) self.assertEquals(node.progress, 0) self.assertEquals(node.status, 'discover') self.assertEquals(self.cluster.status, 'error') self.assertEquals(self.cluster.status, 'error') self.assertEquals(self.cluster.status, 'error') self.assertEquals(self.cluster.status, 'operational') self.assertEquals(self.cluster.status, 'operational') self.assertEquals(node.status, 'ready') self.assertEquals(node.progress, 100) self.assertEquals(self.cluster.status, 'error') self.assertEquals(task.status, 'error') self.assertEquals(node.status, 'error') self.assertEquals(node.progress, 0) self.assertEquals(self.cluster.status, 'new') self.assertEquals(self.node.status, status) self.assertEquals(self.node.error_type, error_type) self.assertEquals(check_mock.call_count, 1) self.assertEquals(check_mock.call_count, 1)",788,788
openstack%2Foslotest~master~I274a4144edf4efe9ed786e220e40003fda6f99e0,openstack/oslotest,master,I274a4144edf4efe9ed786e220e40003fda6f99e0,Add API documentation,MERGED,2014-06-09 19:15:36.000000000,2014-06-23 16:27:22.000000000,2014-06-23 16:27:21.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 8041}]","[{'number': 1, 'created': '2014-06-09 19:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/8c83b03e2b4d6c1f82f916595b6018893b28fc0d', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}, {'number': 2, 'created': '2014-06-13 20:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/5881e99c1f2b6791c8ba5bc5cfd8fde922ef43f5', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nCloses-bug: #1329952\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}, {'number': 3, 'created': '2014-06-14 17:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/23a71cc84f60f0eee050aba100b102d862b02dee', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nRemove the nearly useless usage.rst file.\n\nCloses-bug: #1329952\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}, {'number': 4, 'created': '2014-06-23 15:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/43cdec7f4bdd97ce6e9dc24758ee65524118ca07', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nRemove the nearly useless usage.rst file.\n\nCloses-bug: #1329952\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}, {'number': 5, 'created': '2014-06-23 15:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/91157dbea01095cb5b70913dec6c1bab4c0cb1c8', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nRemove the nearly useless usage.rst file.\n\nTurn on the pbr flag to treat doc build warnings as errors.\n\nCloses-bug: #1329952\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}, {'number': 6, 'created': '2014-06-23 15:19:33.000000000', 'files': ['doc/source/index.rst', 'doc/source/api.rst', 'doc/source/usage.rst', 'setup.cfg', 'oslotest/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/aec9e529fd72924cb8f3f149d35a6b9ce0581c81', 'message': ""Add API documentation\n\nAdd docstrings and sphinx structure to expose them through the developer\ndocs for the library.\n\nAlso add a 'docs' target in tox.ini to make building the documentation\nlocally easier.\n\nRemove the nearly useless usage.rst file.\n\nTurn on the pbr flag to treat doc build warnings as errors.\n\nCloses-bug: #1329952\n\nChange-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0\n""}]",4,98861,aec9e529fd72924cb8f3f149d35a6b9ce0581c81,30,5,6,2472,,,0,"Add API documentation

Add docstrings and sphinx structure to expose them through the developer
docs for the library.

Also add a 'docs' target in tox.ini to make building the documentation
locally easier.

Remove the nearly useless usage.rst file.

Turn on the pbr flag to treat doc build warnings as errors.

Closes-bug: #1329952

Change-Id: I274a4144edf4efe9ed786e220e40003fda6f99e0
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/61/98861/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/api.rst', 'oslotest/base.py', 'tox.ini']",4,8c83b03e2b4d6c1f82f916595b6018893b28fc0d,improve-dev-docs,[testenv:docs] commands = python setup.py build_sphinx ,,66,0
openstack%2Fnova~master~I5871ea17a8035a0aaa8f3b38624715bff1034198,openstack/nova,master,I5871ea17a8035a0aaa8f3b38624715bff1034198,scheduler: ignore extra specs with 'hw_' prefix in caps filter,ABANDONED,2014-06-20 10:18:39.000000000,2014-06-23 16:19:00.000000000,,"[{'_account_id': 3}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 10:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f084965ac1f8320bdfce47c6fe41d4fb10c9b86', 'message': 'scheduler: ignore extra specs with \'hw_\' prefix in caps filter\n\nThe \'compute_capabilities_filter\' will process anything in the\nflavour extra specs which doesn\'t have a "":"" in the name. In\nimage properties there is an established standard practice of\nusing \'hw_\' as a prefix for configuration items which control\nguest hardware characteristics. It is desirable to be able to\nuse the same names between image properties and flavor extra\nspecs in many of these cases. Making the compute capabilities\nfilter ignore anything with a \'hw_\' prefix lets us have such\nconsistent naming. In the unlikely event that someone does\nneed the filter to match on names with a \'hw_\' prefix, this\ncan still be done using the capabilties scope. eg setting\nthe flavor extra spec key to \'capabilities:hw_foo\'\n\nChange-Id: I5871ea17a8035a0aaa8f3b38624715bff1034198\n'}, {'number': 2, 'created': '2014-06-20 11:18:34.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/compute_capabilities_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cff00963d8056d2e3d561453eae5908951ef37aa', 'message': 'scheduler: ignore extra specs with \'hw_\' prefix in caps filter\n\nThe \'compute_capabilities_filter\' will process anything in the\nflavour extra specs which doesn\'t have a "":"" in the name. In\nimage properties there is an established standard practice of\nusing \'hw_\' as a prefix for configuration items which control\nguest hardware characteristics. It is desirable to be able to\nuse the same names between image properties and flavor extra\nspecs in many of these cases. Making the compute capabilities\nfilter ignore anything with a \'hw_\' prefix lets us have such\nconsistent naming. In the unlikely event that someone does\nneed the filter to match on names with a \'hw_\' prefix, this\ncan still be done using the capabilties scope. eg setting\nthe flavor extra spec key to \'capabilities:hw_foo\'\n\nChange-Id: I5871ea17a8035a0aaa8f3b38624715bff1034198\n'}]",0,101472,cff00963d8056d2e3d561453eae5908951ef37aa,17,7,2,1779,,,0,"scheduler: ignore extra specs with 'hw_' prefix in caps filter

The 'compute_capabilities_filter' will process anything in the
flavour extra specs which doesn't have a "":"" in the name. In
image properties there is an established standard practice of
using 'hw_' as a prefix for configuration items which control
guest hardware characteristics. It is desirable to be able to
use the same names between image properties and flavor extra
specs in many of these cases. Making the compute capabilities
filter ignore anything with a 'hw_' prefix lets us have such
consistent naming. In the unlikely event that someone does
need the filter to match on names with a 'hw_' prefix, this
can still be done using the capabilties scope. eg setting
the flavor extra spec key to 'capabilities:hw_foo'

Change-Id: I5871ea17a8035a0aaa8f3b38624715bff1034198
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/101472/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/compute_capabilities_filter.py']",2,4f084965ac1f8320bdfce47c6fe41d4fb10c9b86,compute-filter," # or a hardware config parameter if key.startswith(""hw_""): continue",,19,0
openstack%2Fos-apply-config~master~Ib38f89fab93355b9f0c37e048b1980d4b7fb522b,openstack/os-apply-config,master,Ib38f89fab93355b9f0c37e048b1980d4b7fb522b,Updated from global requirements,MERGED,2014-06-10 14:39:03.000000000,2014-06-23 16:13:45.000000000,2014-06-23 16:13:45.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 4190}]","[{'number': 1, 'created': '2014-06-10 14:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/cd4faa69eb48861136395e671283c245a38d07e2', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}, {'number': 2, 'created': '2014-06-11 01:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/076ba55e108fdabd5ea5b77df3d41fac7d59b6e3', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}, {'number': 3, 'created': '2014-06-13 22:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/4e5e022f68ea52713f45baa57157d05a5812f0fc', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}, {'number': 4, 'created': '2014-06-16 09:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/0a62a4c23e083fd09477423fc714229e22eec155', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}, {'number': 5, 'created': '2014-06-18 00:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/0ac10fcde7c4648594a5ce197a10504897f441c0', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}, {'number': 6, 'created': '2014-06-20 03:38:04.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/f300bd39b524872659cc895b11f606d68efc1746', 'message': 'Updated from global requirements\n\nChange-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b\n'}]",0,99083,f300bd39b524872659cc895b11f606d68efc1746,31,3,6,11131,,,0,"Updated from global requirements

Change-Id: Ib38f89fab93355b9f0c37e048b1980d4b7fb522b
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/83/99083/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cd4faa69eb48861136395e671283c245a38d07e2,openstack/requirements,"hacking>=0.8.0,<0.10,!=0.9.0","hacking>=0.8.0,<0.9",1,1
openstack%2Foslo.messaging~master~I92e7c01dd87d634b741bbcaea92f48730fdd555e,openstack/oslo.messaging,master,I92e7c01dd87d634b741bbcaea92f48730fdd555e,Ensures listener queues exist in fake driver,MERGED,2014-06-18 12:51:07.000000000,2014-06-23 16:04:24.000000000,2014-06-23 16:04:24.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 8041}]","[{'number': 1, 'created': '2014-06-18 12:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/36abe7fcf03d0aa93abf3273281cca4d7fbef72c', 'message': 'Ensure listerner queue exists in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message go to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nPartial closes #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}, {'number': 2, 'created': '2014-06-18 12:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9492a63bb9b6997064ecdc5f133424ae527ca710', 'message': 'Ensures listener queues exist in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message goes to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nPartial closes #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}, {'number': 3, 'created': '2014-06-18 12:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/29e79b28bff23f1198ef223cbfd41a38436fc419', 'message': 'Ensures listener queues exist in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message goes to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nPartial closes bug #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}, {'number': 4, 'created': '2014-06-18 12:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f6ced592b28b51b2fd1ffefe329c9e72f6693fa5', 'message': 'Ensures listener queues exist in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message goes to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nPartial closes bug #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}, {'number': 5, 'created': '2014-06-20 10:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a0078bf9c1ebc98a8b1467662c95994bc36a6ecd', 'message': 'Ensures listener queues exist in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message goes to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nCloses bug #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}, {'number': 6, 'created': '2014-06-23 07:10:38.000000000', 'files': ['oslo/messaging/_drivers/impl_fake.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e582da68f4c5edd3e4a3cdb62819c210c72dcfad', 'message': 'Ensures listener queues exist in fake driver\n\nThe fanout queues of the fake driver are created at the first executor\npoll, but if we use eventlet executor and the fake driver, when the sender\ndelivers a fanout message before the first poll, the message goes to the\ntopic queue instead of the server fanout queue.\n\nThe changes fixes that by ensuring the all queues exists when the\nlistener is created.\n\nCloses bug #1331453\n\nChange-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e\n'}]",0,100889,e582da68f4c5edd3e4a3cdb62819c210c72dcfad,28,5,6,2813,,,0,"Ensures listener queues exist in fake driver

The fanout queues of the fake driver are created at the first executor
poll, but if we use eventlet executor and the fake driver, when the sender
delivers a fanout message before the first poll, the message goes to the
topic queue instead of the server fanout queue.

The changes fixes that by ensuring the all queues exists when the
listener is created.

Closes bug #1331453

Change-Id: I92e7c01dd87d634b741bbcaea92f48730fdd555e
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/89/100889/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_fake.py'],1,36abe7fcf03d0aa93abf3273281cca4d7fbef72c,bug/1331453," # NOTE(sileht): Ensure that all needed queues exists event the listener # have not been polled yet for target in self._targets: exchange = self._exchange_manager.get_exchange(target.exchange) if target.server: exchange.get_server_queue(target.topic, target.server) else: exchange.get_topic_queue(target.topic) def get_topic_queue(self, topic): def get_server_queue(self, topic, server): queues = [self.get_server_queue(topic, server)] else: queues = [self.get_topic_queue(topic)] queue = self.get_server_queue(target.topic, target.server) else: queue = self.get_topic_queue(target.topic)"," def _get_topic_queue(self, topic): def _get_server_queue(self, topic, server): queues = [self._get_server_queue(topic, server)] else: queues = [self._get_topic_queue(topic)] queue = self._get_server_queue(target.topic, target.server) else: queue = self._get_topic_queue(target.topic)",15,6
openstack%2Fpython-openstackclient~master~I23923d580f57ab6c12622f10d9f278c44c863feb,openstack/python-openstackclient,master,I23923d580f57ab6c12622f10d9f278c44c863feb,sync oslo bits,MERGED,2014-06-20 20:17:11.000000000,2014-06-23 16:02:09.000000000,2014-06-23 16:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-06-20 20:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/52e8c3b6306acdc2cea82f36e02feafbac54ea20', 'message': 'sync oslo bits\n\nupdate gettextutils.py, strutils.py, install_venv_common.py\nremove iniparsers.py\n\noslo-incubator commit 1223cf\n\nChange-Id: I23923d580f57ab6c12622f10d9f278c44c863feb\n'}, {'number': 2, 'created': '2014-06-20 20:18:38.000000000', 'files': ['openstackclient/openstack/common/__init__.py', 'openstackclient/openstack/common/gettextutils.py', 'openstackclient/openstack/common/strutils.py', 'openstack-common.conf', 'tools/install_venv_common.py', 'openstackclient/openstack/common/iniparser.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a36898370537cdb610f9fd012eea2439ba642f21', 'message': 'sync oslo bits\n\nupdate gettextutils.py, strutils.py, install_venv_common.py\nremove iniparsers.py\n\noslo-incubator commit 1223cf\n\nChange-Id: I23923d580f57ab6c12622f10d9f278c44c863feb\n'}]",0,101642,a36898370537cdb610f9fd012eea2439ba642f21,14,3,2,6482,,,0,"sync oslo bits

update gettextutils.py, strutils.py, install_venv_common.py
remove iniparsers.py

oslo-incubator commit 1223cf

Change-Id: I23923d580f57ab6c12622f10d9f278c44c863feb
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/42/101642/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/openstack/common/__init__.py', 'openstackclient/openstack/common/gettextutils.py', 'openstackclient/openstack/common/strutils.py', 'tools/install_venv_common.py', 'openstackclient/openstack/common/iniparser.py']",5,52e8c3b6306acdc2cea82f36e02feafbac54ea20,sync_oslo,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2012 OpenStack LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class ParseError(Exception): def __init__(self, message, lineno, line): self.msg = message self.line = line self.lineno = lineno def __str__(self): return 'at line %d, %s: %r' % (self.lineno, self.msg, self.line) class BaseParser(object): lineno = 0 parse_exc = ParseError def _assignment(self, key, value): self.assignment(key, value) return None, [] def _get_section(self, line): if line[-1] != ']': return self.error_no_section_end_bracket(line) if len(line) <= 2: return self.error_no_section_name(line) return line[1:-1] def _split_key_value(self, line): colon = line.find(':') equal = line.find('=') if colon < 0 and equal < 0: return self.error_invalid_assignment(line) if colon < 0 or (equal >= 0 and equal < colon): key, value = line[:equal], line[equal + 1:] else: key, value = line[:colon], line[colon + 1:] value = value.strip() if ((value and value[0] == value[-1]) and (value[0] == ""\"""" or value[0] == ""'"")): value = value[1:-1] return key.strip(), [value] def parse(self, lineiter): key = None value = [] for line in lineiter: self.lineno += 1 line = line.rstrip() if not line: # Blank line, ends multi-line values if key: key, value = self._assignment(key, value) continue elif line[0] in (' ', '\t'): # Continuation of previous assignment if key is None: self.error_unexpected_continuation(line) else: value.append(line.lstrip()) continue if key: # Flush previous assignment, if any key, value = self._assignment(key, value) if line[0] == '[': # Section start section = self._get_section(line) if section: self.new_section(section) elif line[0] in '#;': self.comment(line[1:].lstrip()) else: key, value = self._split_key_value(line) if not key: return self.error_empty_key(line) if key: # Flush previous assignment, if any self._assignment(key, value) def assignment(self, key, value): """"""Called when a full assignment is parsed"""""" raise NotImplementedError() def new_section(self, section): """"""Called when a new section is started"""""" raise NotImplementedError() def comment(self, comment): """"""Called when a comment is parsed"""""" pass def error_invalid_assignment(self, line): raise self.parse_exc(""No ':' or '=' found in assignment"", self.lineno, line) def error_empty_key(self, line): raise self.parse_exc('Key cannot be empty', self.lineno, line) def error_unexpected_continuation(self, line): raise self.parse_exc('Unexpected continuation line', self.lineno, line) def error_no_section_end_bracket(self, line): raise self.parse_exc('Invalid section (must end with ])', self.lineno, line) def error_no_section_name(self, line): raise self.parse_exc('Empty section name', self.lineno, line) ",159,253
openstack%2Fhorizon~stable%2Ficehouse~Iacd2e003769f832bdf9f287dd6c827fd0d8584a6,openstack/horizon,stable/icehouse,Iacd2e003769f832bdf9f287dd6c827fd0d8584a6,Updated from global requirements,MERGED,2014-06-22 15:25:00.000000000,2014-06-23 16:01:15.000000000,2014-06-23 16:01:15.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-06-22 15:25:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d9ed5c40e202929111982ea081345a6548f3ffaa', 'message': 'Updated from global requirements\n\nChange-Id: Iacd2e003769f832bdf9f287dd6c827fd0d8584a6\n'}]",0,101761,d9ed5c40e202929111982ea081345a6548f3ffaa,9,3,1,11131,,,0,"Updated from global requirements

Change-Id: Iacd2e003769f832bdf9f287dd6c827fd0d8584a6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/61/101761/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d9ed5c40e202929111982ea081345a6548f3ffaa,openstack/requirements,"django_openstack_auth>=1.1.4,!=1.1.6",django_openstack_auth>=1.1.4,1,1
openstack%2Foslo.vmware~master~Id190aad9a4fd2dd7bf962f001f88b6a0884c18a1,openstack/oslo.vmware,master,Id190aad9a4fd2dd7bf962f001f88b6a0884c18a1,Sync excutils from Oslo,MERGED,2014-06-20 22:03:17.000000000,2014-06-23 16:01:09.000000000,2014-06-23 16:01:08.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-06-20 22:03:17.000000000', 'files': ['oslo/vmware/rw_handles.py', 'oslo/vmware/api.py', 'openstack-common.conf', 'oslo/vmware/openstack/common/excutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/df06729fdb01520b58bded87630aa891c9d16d80', 'message': 'Sync excutils from Oslo\n\nThis patch adds the excutils module to openstack-common.conf,\nsync excutils from oslo-incubator and uses save_and_reraise_exception\nwhere it is relevant.\n\nChange-Id: Id190aad9a4fd2dd7bf962f001f88b6a0884c18a1\n'}]",0,101660,df06729fdb01520b58bded87630aa891c9d16d80,10,3,1,8759,,,0,"Sync excutils from Oslo

This patch adds the excutils module to openstack-common.conf,
sync excutils from oslo-incubator and uses save_and_reraise_exception
where it is relevant.

Change-Id: Id190aad9a4fd2dd7bf962f001f88b6a0884c18a1
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/60/101660/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/vmware/rw_handles.py', 'oslo/vmware/api.py', 'openstack-common.conf', 'oslo/vmware/openstack/common/excutils.py']",4,df06729fdb01520b58bded87630aa891c9d16d80,excutils,"# Copyright 2011 OpenStack Foundation. # Copyright 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exception related utilities. """""" import logging import sys import time import traceback import six from oslo.vmware.openstack.common.gettextutils import _LE class save_and_reraise_exception(object): """"""Save current exception, run some code and then re-raise. In some cases the exception context can be cleared, resulting in None being attempted to be re-raised after an exception handler is run. This can happen when eventlet switches greenthreads or when running an exception handler, code raises and catches an exception. In both cases the exception context will be cleared. To work around this, we save the exception state, run handler code, and then re-raise the original exception. If another exception occurs, the saved exception is logged and the new exception is re-raised. In some cases the caller may not want to re-raise the exception, and for those circumstances this context provides a reraise flag that can be used to suppress the exception. For example:: except Exception: with save_and_reraise_exception() as ctxt: decide_if_need_reraise() if not should_be_reraised: ctxt.reraise = False If another exception occurs and reraise flag is False, the saved exception will not be logged. If the caller wants to raise new exception during exception handling he/she sets reraise to False initially with an ability to set it back to True if needed:: except Exception: with save_and_reraise_exception(reraise=False) as ctxt: [if statements to determine whether to raise a new exception] # Not raising a new exception, so reraise ctxt.reraise = True """""" def __init__(self, reraise=True): self.reraise = reraise def __enter__(self): self.type_, self.value, self.tb, = sys.exc_info() return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type is not None: if self.reraise: logging.error(_LE('Original exception being dropped: %s'), traceback.format_exception(self.type_, self.value, self.tb)) return False if self.reraise: six.reraise(self.type_, self.value, self.tb) def forever_retry_uncaught_exceptions(infunc): def inner_func(*args, **kwargs): last_log_time = 0 last_exc_message = None exc_count = 0 while True: try: return infunc(*args, **kwargs) except Exception as exc: this_exc_message = six.u(str(exc)) if this_exc_message == last_exc_message: exc_count += 1 else: exc_count = 1 # Do not log any more frequently than once a minute unless # the exception message changes cur_time = int(time.time()) if (cur_time - last_log_time > 60 or this_exc_message != last_exc_message): logging.exception( _LE('Unexpected exception occurred %d time(s)... ' 'retrying.') % exc_count) last_log_time = cur_time last_exc_message = this_exc_message exc_count = 0 # This should be a very rare event. In case it isn't, do # a sleep. time.sleep(1) return inner_func ",,171,50
openstack%2Fneutron~stable%2Ficehouse~I3df821fd72471f8bd84366e3b5a1cc7e3489156c,openstack/neutron,stable/icehouse,I3df821fd72471f8bd84366e3b5a1cc7e3489156c,ofagent: Fix VLAN usage for TYPE_FLAT and TYPE_VLAN,MERGED,2014-06-16 23:31:42.000000000,2014-06-23 16:01:02.000000000,2014-06-23 16:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 9732}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-06-16 23:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1e25e690370f5c7327276891720901e1e13448b', 'message': 'ofagent: Fix VLAN usage for TYPE_FLAT and TYPE_VLAN\n\nwhile ofagent uses OF1.3, the current coding incorrectly uses\nOF1.0 terms in some places.  namely, _local_vlan_for_flat uses\n0xffff to mean ""no VLAN"".  it should use OFPVID_NONE and\npop_vlan/push_vlan appropriately.  the same problem exists for\nreclaim_local_vlan.\n\nCloses-Bug: 1301144\nChange-Id: I3df821fd72471f8bd84366e3b5a1cc7e3489156c\n(cherry picked from commit 35b0e003e59232d63b8dbd0da511ee8e3877335e)\n'}, {'number': 2, 'created': '2014-06-23 06:15:36.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/fake_oflib.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1da7abde2e5354c2bcd088d2de25254742ea01fe', 'message': 'ofagent: Fix VLAN usage for TYPE_FLAT and TYPE_VLAN\n\nwhile ofagent uses OF1.3, the current coding incorrectly uses\nOF1.0 terms in some places.  namely, _local_vlan_for_flat uses\n0xffff to mean ""no VLAN"".  it should use OFPVID_NONE and\npop_vlan/push_vlan appropriately.  the same problem exists for\nreclaim_local_vlan.\n\nCloses-Bug: 1301144\nChange-Id: I3df821fd72471f8bd84366e3b5a1cc7e3489156c\n(cherry picked from commit 35b0e003e59232d63b8dbd0da511ee8e3877335e)\n'}]",0,100380,1da7abde2e5354c2bcd088d2de25254742ea01fe,27,9,2,8344,,,0,"ofagent: Fix VLAN usage for TYPE_FLAT and TYPE_VLAN

while ofagent uses OF1.3, the current coding incorrectly uses
OF1.0 terms in some places.  namely, _local_vlan_for_flat uses
0xffff to mean ""no VLAN"".  it should use OFPVID_NONE and
pop_vlan/push_vlan appropriately.  the same problem exists for
reclaim_local_vlan.

Closes-Bug: 1301144
Change-Id: I3df821fd72471f8bd84366e3b5a1cc7e3489156c
(cherry picked from commit 35b0e003e59232d63b8dbd0da511ee8e3877335e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/100380/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/fake_oflib.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py']",3,d1e25e690370f5c7327276891720901e1e13448b,bug/1301144," def _mk_test_dp(name): ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') dp = mock.Mock() dp.ofproto = ofp dp.ofproto_parser = ofpp dp.__repr__ = lambda _self: name return dp def _mk_test_br(name): dp = _mk_test_dp(name) br = mock.Mock() br.datapath = dp br.ofproto = dp.ofproto br.ofparser = dp.ofproto_parser return br self.agent.tun_br = _mk_test_br('tun_br') self.agent.phys_brs['phys-net1'] = _mk_test_br('phys_br1') self.agent.phys_ofports['phys-net1'] = 777 self.agent.int_ofports['phys-net1'] = 666 self.agent.int_br.datapath = _mk_test_dp('int_br') self.agent.tun_br.datapath, def test__provision_local_vlan_outbound(self): with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._provision_local_vlan_outbound(888, 999, 'phys-net1') ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.phys_brs['phys-net1'].datapath, instructions=[ ofpp.OFPInstructionActions( ofp.OFPIT_APPLY_ACTIONS, [ ofpp.OFPActionSetField(vlan_vid=999), ofpp.OFPActionOutput(ofp.OFPP_NORMAL, 0), ] ) ], match=ofpp.OFPMatch( in_port=777, vlan_vid=888 | ofp.OFPVID_PRESENT ), priority=4) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__provision_local_vlan_inbound(self): with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._provision_local_vlan_inbound(888, 999, 'phys-net1') ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.int_br.datapath, instructions=[ ofpp.OFPInstructionActions( ofp.OFPIT_APPLY_ACTIONS, [ ofpp.OFPActionSetField( vlan_vid=888 | ofp.OFPVID_PRESENT ), ofpp.OFPActionOutput(ofp.OFPP_NORMAL, 0), ] ) ], match=ofpp.OFPMatch(in_port=666, vlan_vid=999), priority=3) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__reclaim_local_vlan_outbound(self): lvm = mock.Mock() lvm.network_type = p_const.TYPE_VLAN lvm.segmentation_id = 555 lvm.vlan = 444 lvm.physical_network = 'phys-net1' with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._reclaim_local_vlan_outbound(lvm) ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.phys_brs['phys-net1'].datapath, command=ofp.OFPFC_DELETE, match=ofpp.OFPMatch( in_port=777, vlan_vid=444 | ofp.OFPVID_PRESENT ), out_group=ofp.OFPG_ANY, out_port=ofp.OFPP_ANY, table_id=ofp.OFPTT_ALL) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__reclaim_local_vlan_inbound(self): lvm = mock.Mock() lvm.network_type = p_const.TYPE_VLAN lvm.segmentation_id = 555 lvm.vlan = 444 lvm.physical_network = 'phys-net1' with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._reclaim_local_vlan_inbound(lvm) ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.int_br.datapath, command=ofp.OFPFC_DELETE, match=ofpp.OFPMatch( in_port=666, vlan_vid=555 | ofp.OFPVID_PRESENT ), out_group=ofp.OFPG_ANY, out_port=ofp.OFPP_ANY, table_id=ofp.OFPTT_ALL) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__provision_local_vlan_outbound_flat(self): ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._provision_local_vlan_outbound(888, ofp.OFPVID_NONE, 'phys-net1') expected_msg = ofpp.OFPFlowMod( self.agent.phys_brs['phys-net1'].datapath, instructions=[ ofpp.OFPInstructionActions( ofp.OFPIT_APPLY_ACTIONS, [ ofpp.OFPActionPopVlan(), ofpp.OFPActionOutput(ofp.OFPP_NORMAL, 0), ] ) ], match=ofpp.OFPMatch( in_port=777, vlan_vid=888 | ofp.OFPVID_PRESENT ), priority=4) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__provision_local_vlan_inbound_flat(self): ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._provision_local_vlan_inbound(888, ofp.OFPVID_NONE, 'phys-net1') expected_msg = ofpp.OFPFlowMod( self.agent.int_br.datapath, instructions=[ ofpp.OFPInstructionActions( ofp.OFPIT_APPLY_ACTIONS, [ ofpp.OFPActionPushVlan(), ofpp.OFPActionSetField( vlan_vid=888 | ofp.OFPVID_PRESENT ), ofpp.OFPActionOutput(ofp.OFPP_NORMAL, 0), ] ) ], match=ofpp.OFPMatch(in_port=666, vlan_vid=ofp.OFPVID_NONE), priority=3) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__reclaim_local_vlan_outbound_flat(self): lvm = mock.Mock() lvm.network_type = p_const.TYPE_FLAT lvm.segmentation_id = 555 lvm.vlan = 444 lvm.physical_network = 'phys-net1' with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._reclaim_local_vlan_outbound(lvm) ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.phys_brs['phys-net1'].datapath, command=ofp.OFPFC_DELETE, match=ofpp.OFPMatch( in_port=777, vlan_vid=444 | ofp.OFPVID_PRESENT ), out_group=ofp.OFPG_ANY, out_port=ofp.OFPP_ANY, table_id=ofp.OFPTT_ALL) sendmsg.assert_has_calls([mock.call(expected_msg)]) def test__reclaim_local_vlan_inbound_flat(self): lvm = mock.Mock() lvm.network_type = p_const.TYPE_FLAT lvm.segmentation_id = 555 lvm.vlan = 444 lvm.physical_network = 'phys-net1' with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._reclaim_local_vlan_inbound(lvm) ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( self.agent.int_br.datapath, command=ofp.OFPFC_DELETE, match=ofpp.OFPMatch( in_port=666, vlan_vid=ofp.OFPVID_NONE ), out_group=ofp.OFPG_ANY, out_port=ofp.OFPP_ANY, table_id=ofp.OFPTT_ALL) sendmsg.assert_has_calls([mock.call(expected_msg)]) "," self.agent.tun_br = mock.Mock() self.agent.tun_br.ofparser = importutils.import_module( 'ryu.ofproto.ofproto_v1_3_parser') self.agent.tun_br.datapath = 'tun_br' 'tun_br',",288,80
openstack%2Fdiskimage-builder~master~I2748a9db7f8ee456698187a9646bc7cda2256fe7,openstack/diskimage-builder,master,I2748a9db7f8ee456698187a9646bc7cda2256fe7,map-services: add openvswitch,MERGED,2014-05-30 12:42:29.000000000,2014-06-23 16:00:55.000000000,2014-06-23 16:00:54.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 4330}, {'_account_id': 7144}, {'_account_id': 8532}, {'_account_id': 9268}, {'_account_id': 10277}]","[{'number': 1, 'created': '2014-05-30 12:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5795c7592b4de3f39ddf3724522862fc68ae03d2', 'message': 'map-services: add openvswitch\n\nOVS service is called:\n - openvswitch-switch on Debian/Ubuntu\n - openvswitch on RHEL/Fedora\n\nChange-Id: I2748a9db7f8ee456698187a9646bc7cda2256fe7\n'}, {'number': 2, 'created': '2014-06-09 09:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0b9be1908502fb4a51a66e268ea4814ee0e7fb5b', 'message': 'map-services: add openvswitch\n\nOVS service is called:\n - openvswitch-switch on Debian/Ubuntu\n - openvswitch on RHEL/Fedora\n\nThis changes is needed to get the neutron element to work\non Debian/Ubutnu with systemd:\n  I6e3df30dc3a6918f3a949a7dac47289ede5c3d1f\n\nChange-Id: I2748a9db7f8ee456698187a9646bc7cda2256fe7\n'}, {'number': 3, 'created': '2014-06-09 09:18:02.000000000', 'files': ['elements/redhat-common/bin/map-services'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1de9612dad8c128fbf4f83e832cc3b4dc0ca29b3', 'message': 'map-services: add openvswitch\n\nOVS service is called:\n - openvswitch-switch on Debian/Ubuntu\n - openvswitch on RHEL/Fedora\n\nThis changes is needed to get the neutron element to work\non Debian/Ubuntu with systemd:\n  I6e3df30dc3a6918f3a949a7dac47289ede5c3d1f\n\nChange-Id: I2748a9db7f8ee456698187a9646bc7cda2256fe7\n'}]",0,96749,1de9612dad8c128fbf4f83e832cc3b4dc0ca29b3,27,7,3,9268,,,0,"map-services: add openvswitch

OVS service is called:
 - openvswitch-switch on Debian/Ubuntu
 - openvswitch on RHEL/Fedora

This changes is needed to get the neutron element to work
on Debian/Ubuntu with systemd:
  I6e3df30dc3a6918f3a949a7dac47289ede5c3d1f

Change-Id: I2748a9db7f8ee456698187a9646bc7cda2256fe7
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/49/96749/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/redhat-common/bin/map-services'],1,5795c7592b4de3f39ddf3724522862fc68ae03d2,ovs_service," 'openvswitch-switch': 'openvswitch',",,1,0
openstack%2Fneutron~master~I7d528afc3051e423e4a405ba1bdc0cb4cc5a9071,openstack/neutron,master,I7d528afc3051e423e4a405ba1bdc0cb4cc5a9071,Updated from global requirements,MERGED,2014-06-23 05:31:03.000000000,2014-06-23 15:57:49.000000000,2014-06-23 15:57:48.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-23 05:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ae56343fba63ce91564ad24000f214a338b3ede', 'message': 'Updated from global requirements\n\nChange-Id: I7d528afc3051e423e4a405ba1bdc0cb4cc5a9071\n'}, {'number': 2, 'created': '2014-06-23 12:17:25.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/40d9965d1d6b449de2deb853eb20c431700e145f', 'message': 'Updated from global requirements\n\nChange-Id: I7d528afc3051e423e4a405ba1bdc0cb4cc5a9071\n'}]",0,101801,40d9965d1d6b449de2deb853eb20c431700e145f,28,11,2,11131,,,0,"Updated from global requirements

Change-Id: I7d528afc3051e423e4a405ba1bdc0cb4cc5a9071
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/101801/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,4ae56343fba63ce91564ad24000f214a338b3ede,openstack/requirements,cliff>=1.6.0,cliff>=1.4.3,1,1
openstack%2Ffuel-main~master~Ide4e0fb3734004025e8e3bdb38c4aa4eaf18f158,openstack/fuel-main,master,Ide4e0fb3734004025e8e3bdb38c4aa4eaf18f158,Added deployment flexible way for failover tests,MERGED,2014-06-09 11:04:46.000000000,2014-06-23 15:57:08.000000000,2014-06-23 15:57:08.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-06-09 11:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b27a1be2025ebdf869569aa3e37eb1463263d6ac', 'message': 'Added deployment flexible way for failover tests\n\nChange-Id: Ide4e0fb3734004025e8e3bdb38c4aa4eaf18f158\n'}, {'number': 2, 'created': '2014-06-09 11:07:35.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f42e320a708f50d02d48e311dd4e156ff4fe36b0', 'message': 'Added deployment flexible way for failover tests\n\nChange-Id: Ide4e0fb3734004025e8e3bdb38c4aa4eaf18f158\n'}]",1,98740,f42e320a708f50d02d48e311dd4e156ff4fe36b0,20,5,2,8882,,,0,"Added deployment flexible way for failover tests

Change-Id: Ide4e0fb3734004025e8e3bdb38c4aa4eaf18f158
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/40/98740/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_failover.py', 'fuelweb_test/settings.py']",2,b27a1be2025ebdf869569aa3e37eb1463263d6ac,cherry_master," NEUTRON_FAILOVER = os.environ.get('NEUTRON_FAILOVER', 'false') == 'true' NEUTRON_SEGMENT_TYPE = os.environ.get('NEUTRON_SEGMENT_TYPE', NEUTRON_SEGMENT[""vlan""]) ",,16,1
openstack%2Fpython-manilaclient~master~I42ea803d761b2510c959dc1578a20ff155670283,openstack/python-manilaclient,master,I42ea803d761b2510c959dc1578a20ff155670283,Replace json with jsonutils from common code,MERGED,2014-06-18 08:29:09.000000000,2014-06-23 15:56:33.000000000,2014-06-23 15:56:33.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 7534}]","[{'number': 1, 'created': '2014-06-18 08:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/24f231a9138993d7523ddc7b35c65beb45a2d386', 'message': 'Replace json with jsonutils from common code\n\nWe should use common code where possible.\nThis change is intended to remove direct usage of json\nmodule and start use jsonutils from manilaclient.openstack.common\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I42ea803d761b2510c959dc1578a20ff155670283\n'}, {'number': 2, 'created': '2014-06-18 08:36:23.000000000', 'files': ['requirements.txt', 'manilaclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/efd072b45d4c3e039ebba16c06427a7c4a5ac788', 'message': ""Replace json with jsonutils from common code\n\nWe should use common code where possible.\nThis change is intended to remove direct usage of json\nmodule and start use jsonutils from manilaclient.openstack.common\n\nAlso added lost dependency 'iso8601', that is used by jsonutils\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I42ea803d761b2510c959dc1578a20ff155670283\n""}]",0,100818,efd072b45d4c3e039ebba16c06427a7c4a5ac788,13,5,2,8851,,,0,"Replace json with jsonutils from common code

We should use common code where possible.
This change is intended to remove direct usage of json
module and start use jsonutils from manilaclient.openstack.common

Also added lost dependency 'iso8601', that is used by jsonutils

Partially implements: blueprint use-common-code

Change-Id: I42ea803d761b2510c959dc1578a20ff155670283
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/18/100818/2 && git format-patch -1 --stdout FETCH_HEAD,['manilaclient/client.py'],1,24f231a9138993d7523ddc7b35c65beb45a2d386,bp/use-common-code,from manilaclient.openstack.common import jsonutils kwargs['data'] = jsonutils.dumps(kwargs['body']) body = jsonutils.loads(resp.text),try: import json except ImportError: import simplejson as json kwargs['data'] = json.dumps(kwargs['body']) body = json.loads(resp.text),3,7
openstack%2Fceilometer~master~I15696b1b09286270de237084869d4a2d4418be8d,openstack/ceilometer,master,I15696b1b09286270de237084869d4a2d4418be8d,Handle non-ascii character in meter name,MERGED,2014-06-23 13:03:04.000000000,2014-06-23 15:56:19.000000000,2014-06-23 15:56:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-23 13:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/32ddeb84fdfa4003a0dc99cccf96690fd2f698aa', 'message': ""Handle non-ascii character in meter name\n\nIn Ceilometer, meter's name is user supplied, thus can contain non ascii\ncharacters. This patch encode Unicode objects to UTF-8 before returning the\nthe meter to the client.\n\nChange-Id: I15696b1b09286270de237084869d4a2d4418be8d\nCloses-Bug: 1333177\n""}, {'number': 2, 'created': '2014-06-23 13:40:49.000000000', 'files': ['ceilometer/tests/api/v2/test_list_meters_scenarios.py', 'ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1fcdca09d351c9b86aa9371242be50d853ba256b', 'message': ""Handle non-ascii character in meter name\n\nIn Ceilometer, meter's name is user supplied, thus can contain non ascii\ncharacters. This patch encode Unicode objects to UTF-8 before returning the\nthe meter to the client.\n\nChange-Id: I15696b1b09286270de237084869d4a2d4418be8d\nCloses-Bug: 1333177\n""}]",1,101907,1fcdca09d351c9b86aa9371242be50d853ba256b,13,6,2,7350,,,0,"Handle non-ascii character in meter name

In Ceilometer, meter's name is user supplied, thus can contain non ascii
characters. This patch encode Unicode objects to UTF-8 before returning the
the meter to the client.

Change-Id: I15696b1b09286270de237084869d4a2d4418be8d
Closes-Bug: 1333177
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/07/101907/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/api/v2/test_list_meters_scenarios.py', 'ceilometer/api/controllers/v2.py']",2,32ddeb84fdfa4003a0dc99cccf96690fd2f698aa,bug/1333177," meter_id = '%s+%s' % (kwargs['resource_id'], kwargs['name']) # meter_id is of type Unicode but base64.encodestring() only accepts # strings. See bug #1333177 meter_id = base64.encodestring(meter_id.encode('utf-8'))"," meter_id = base64.encodestring('%s+%s' % (kwargs['resource_id'], kwargs['name']))",21,8
openstack%2Fmanila~master~Ic652e24a1fbc447f452049310257555589f4059e,openstack/manila,master,Ic652e24a1fbc447f452049310257555589f4059e,Fix tempest test's rare concurrent issue,MERGED,2014-06-19 11:23:43.000000000,2014-06-23 15:47:22.000000000,2014-06-23 15:47:22.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-06-19 11:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a20994528496d50edda1429ffb52ba97579ea13a', 'message': ""Fix tempest test's rare concurrent issue\n\nIn changed test list of services is requested two times,\nthere is possible rare situation when between first and second\nrequests heartbeat of service update can happen.\n\nChange-Id: Ic652e24a1fbc447f452049310257555589f4059e\n""}, {'number': 2, 'created': '2014-06-19 14:37:53.000000000', 'files': ['contrib/tempest/tempest/api/share/admin/test_services_negative.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/0c0d0b48ef4daaf5342a9f3096c7810144dc17b0', 'message': ""Fix tempest test's rare concurrent issue\n\nIn changed test list of services is requested two times,\nthere is possible rare situation when between first and second\nrequests heartbeat of service update can happen.\n\nChange-Id: Ic652e24a1fbc447f452049310257555589f4059e\n""}]",1,101174,0c0d0b48ef4daaf5342a9f3096c7810144dc17b0,16,5,2,8851,,,0,"Fix tempest test's rare concurrent issue

In changed test list of services is requested two times,
there is possible rare situation when between first and second
requests heartbeat of service update can happen.

Change-Id: Ic652e24a1fbc447f452049310257555589f4059e
",git fetch https://review.opendev.org/openstack/manila refs/changes/74/101174/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/admin/test_services_negative.py'],1,a20994528496d50edda1429ffb52ba97579ea13a,tempest," # ""update_at"" field could be updated before second request, # so do not take it in account. for service in list(set(services + services_fake)): service[""updated_at""] = ""removed_possible_difference""",,5,0
openstack%2Fcinder~stable%2Ficehouse~Idf71d3f627575fee09610afc115658d233df4b68,openstack/cinder,stable/icehouse,Idf71d3f627575fee09610afc115658d233df4b68,Remove race condition for volume detach,ABANDONED,2014-06-23 04:55:07.000000000,2014-06-23 15:41:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 8912}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 04:55:07.000000000', 'files': ['cinder/tests/test_volume.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/439a93ef64184d8547ef76815000e5b5581d51b8', 'message': 'Remove race condition for volume detach\n\nMake check and set for volume detach atomic to remove race\ncondition.\n\nChange-Id: Idf71d3f627575fee09610afc115658d233df4b68\nCloses-Bug: 1238093\n'}]",2,101797,439a93ef64184d8547ef76815000e5b5581d51b8,9,6,1,8912,,,0,"Remove race condition for volume detach

Make check and set for volume detach atomic to remove race
condition.

Change-Id: Idf71d3f627575fee09610afc115658d233df4b68
Closes-Bug: 1238093
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/101797/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_volume.py', 'cinder/volume/api.py']",2,439a93ef64184d8547ef76815000e5b5581d51b8,bug/1238093,"from cinder.volume import manager def check_detach(self, context, volume): @manager.locked_volume_operation self.check_detach(context, volume)"," def check_detach(self, volume):",6,1
openstack%2Fmagnetodb~master~I8e9a311498874f98f1a767814860f7c18b5b573e,openstack/magnetodb,master,I8e9a311498874f98f1a767814860f7c18b5b573e,Add tempest tests for streaming API,MERGED,2014-06-23 08:27:20.000000000,2014-06-23 15:38:19.000000000,2014-06-23 15:38:19.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8601}, {'_account_id': 8863}]","[{'number': 1, 'created': '2014-06-23 08:27:20.000000000', 'files': ['tempest/api/keyvalue/stable/rest/test_streaming.py', 'magnetodb/api/stream_wsgi.py', 'tempest/clients.py', 'tempest/config.py', 'tempest/api/keyvalue/rest_base/base.py', 'tempest/services/keyvalue/json/magnetodb_streaming_client.py', 'etc/magnetodb-streaming-api.conf', 'tempest/tempest.conf'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/0c093aaa62ad389c1b9b4f81f954a8b0638c0fad', 'message': 'Add tempest tests for streaming API\n\nAdd tempest client for streaming API\nAdd tests\n\nChange-Id: I8e9a311498874f98f1a767814860f7c18b5b573e\n'}]",0,101823,0c093aaa62ad389c1b9b4f81f954a8b0638c0fad,9,4,1,8491,,,0,"Add tempest tests for streaming API

Add tempest client for streaming API
Add tests

Change-Id: I8e9a311498874f98f1a767814860f7c18b5b573e
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/23/101823/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/keyvalue/stable/rest/test_streaming.py', 'magnetodb/api/stream_wsgi.py', 'tempest/clients.py', 'tempest/config.py', 'tempest/api/keyvalue/rest_base/base.py', 'tempest/services/keyvalue/json/magnetodb_streaming_client.py', 'etc/magnetodb-streaming-api.conf', 'tempest/tempest.conf']",8,0c093aaa62ad389c1b9b4f81f954a8b0638c0fad,streaming-api-tempest-tests, [magnetodb_streaming] service_type = kv-streaming,,140,3
openstack%2Fcongress~master~Ia8eb98349cf3a24df6b7952801a66e94853357d2,openstack/congress,master,Ia8eb98349cf3a24df6b7952801a66e94853357d2,Remove legacy API server,MERGED,2014-06-20 23:27:16.000000000,2014-06-23 15:35:10.000000000,2014-06-23 15:35:10.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-06-20 23:27:16.000000000', 'files': ['scripts/run_api_server', 'congress/server/server.py', 'congress/server/ad_sync.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/2ec2c3ac89cbf2bb341254f54e3d9d8d32b2cc51', 'message': 'Remove legacy API server\n\nA new API server following an updated design will be introduced in a\nfollowing commit.\n\nChange-Id: Ia8eb98349cf3a24df6b7952801a66e94853357d2\n'}]",0,101671,2ec2c3ac89cbf2bb341254f54e3d9d8d32b2cc51,9,2,1,9253,,,0,"Remove legacy API server

A new API server following an updated design will be introduced in a
following commit.

Change-Id: Ia8eb98349cf3a24df6b7952801a66e94853357d2
",git fetch https://review.opendev.org/openstack/congress refs/changes/71/101671/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/run_api_server', 'congress/server/server.py', 'congress/server/ad_sync.py']",3,2ec2c3ac89cbf2bb341254f54e3d9d8d32b2cc51,,,"#!/usr/bin/env python # Copyright (c) 2013 VMware, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import argparse import ldap import sys import time import uuid import ovs.daemon import ovs.vlog vlog = ovs.vlog.Vlog(__name__) #NOTE: LDAP filters: http://tinyurl.com/la9jw7m LDAP_URI = 'ldap://ad-server:389' BASE_DN = 'dc=corp,dc=example,dc=com' BIND_USER = 'cn=administrator,cn=Users' + ',' + BASE_DN BIND_PW = 'p@ssw0rd' class UserGroupDataModel(object): """"""An in-memory data model. """""" def __init__(self): self.items = {} # {uuid: (user, group)} self.by_user = {} # {user: {group:uuid}} def get_items(self): """"""Get items in model. Returns: A dict of {id, item} for all items in model. """""" return self.items def get_item(self, id_): """"""Retrieve item with id id_ from model. Args: id_: The ID of the item to retrieve. Returns: The matching item or None if item with id_ does not exist. """""" return self.items.get(id_) def update_from_ad(self): """"""Fetch user group info from AD and update model. Raises: ldap.INVALID_CREDENTIALS XXX: probably a bunch of ther ldap exceptions """""" # TODO(pjb): rewrite to be scalable, robust #vlog.dbg('Updating users from AD') l = ldap.initialize(LDAP_URI) l.simple_bind_s(BIND_USER, BIND_PW) ret = l.search_s('cn=Users,%s' % BASE_DN, ldap.SCOPE_SUBTREE, '(&(objectCategory=person)(objectClass=user))') user_dns = [(u[1]['sAMAccountName'][0], u[0]) for u in ret] users_to_del = set(self.by_user.keys()) - set([u[0] for u in user_dns]) for user in users_to_del: num_groups = len(self.by_user[user]) vlog.info(""User '%s' deleted (was in %s group%s)"" % (user, num_groups, '' if num_groups == 1 else 's')) ids = self.by_user.pop(user).values() for i in ids: del self.items[i] for user, dn in user_dns: filter_ = '(member:1.2.840.113556.1.4.1941:= %s)' % dn ret = l.search_s('cn=Users,%s' % BASE_DN, ldap.SCOPE_SUBTREE, filter_) new_groups = set([r[1]['cn'][0] for r in ret]) old_groups = set(self.by_user.get(user, {}).keys()) membership_to_del = old_groups - new_groups membership_to_add = new_groups - old_groups for group in membership_to_del: id_ = self.by_user[user].pop(group) vlog.info(""User '%s' removed from group '%s' (%s)"" % (user, group, id_)) del self.items[id_] for group in membership_to_add: new_id = str(uuid.uuid4()) self.by_user.setdefault(user, {})[group] = new_id vlog.info(""User '%s' added to group '%s' (%s)"" % (user, group, new_id)) self.items[new_id] = (user, group) def main(): parser = argparse.ArgumentParser() ovs.vlog.add_args(parser) args = parser.parse_args() ovs.vlog.handle_args(args) model = UserGroupDataModel() vlog.info(""Starting AD sync service"") while True: model.update_from_ad() time.sleep(3) if __name__ == '__main__': try: main() except SystemExit: # Let system.exit() calls complete normally raise except Exception: vlog.exception(""traceback"") sys.exit(ovs.daemon.RESTART_EXIT_CODE) ",0,298
openstack%2Ffuel-library~stable%2F5.0~I57dedea5245bc309474f2e127e88d86b35660f4f,openstack/fuel-library,stable/5.0,I57dedea5245bc309474f2e127e88d86b35660f4f,Fixed default parameters for Nova and Neutron,ABANDONED,2014-06-18 13:49:01.000000000,2014-06-23 15:31:41.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 5950}, {'_account_id': 6072}, {'_account_id': 6849}, {'_account_id': 7227}, {'_account_id': 8259}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10301}]","[{'number': 1, 'created': '2014-06-18 13:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6a85fea926a393af5fd8137d9ab6c1c798505041', 'message': 'Fixed default parameters for Nova and Neutron\n\nDefault values of performance-critical parameters\nchanged to more comfortable for production environments.\n\nChange-Id: I57dedea5245bc309474f2e127e88d86b35660f4f\nCloses-Bug: #1324914\n'}, {'number': 2, 'created': '2014-06-18 13:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7f7434da137d0b371db65116f4a71bc1cb0e1684', 'message': 'Fixed default parameters for Nova and Neutron\n\nDefault values of performance-critical parameters\nchanged to more comfortable for production environments.\n\nChange-Id: I57dedea5245bc309474f2e127e88d86b35660f4f\nCloses-Bug: #1324914\n'}, {'number': 3, 'created': '2014-06-19 12:31:45.000000000', 'files': ['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/neutron/manifests/server.pp', 'deployment/puppet/nova/manifests/api.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/414eb4d3e9a53e9a3fdd59f1708550c52528406f', 'message': 'Fixed default parameters for Nova and Neutron\n\nDefault values of performance-critical parameters\nchanged to more comfortable for production environments.\n\nChange-Id: I57dedea5245bc309474f2e127e88d86b35660f4f\nCloses-Bug: #1324914\n'}]",8,100909,414eb4d3e9a53e9a3fdd59f1708550c52528406f,32,12,3,7227,,,0,"Fixed default parameters for Nova and Neutron

Default values of performance-critical parameters
changed to more comfortable for production environments.

Change-Id: I57dedea5245bc309474f2e127e88d86b35660f4f
Closes-Bug: #1324914
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/09/100909/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/neutron/manifests/server.pp', 'deployment/puppet/nova/manifests/api.pp']",3,6a85fea926a393af5fd8137d9ab6c1c798505041,(detached," $api_workers = min($::processorcount * 5 + 0, 100 + 0),"," $api_workers = $::processorcount,",4,2
openstack%2Ftripleo-image-elements~master~Iec08a458c747f4415a961022c56f66fe0a1f60b4,openstack/tripleo-image-elements,master,Iec08a458c747f4415a961022c56f66fe0a1f60b4,Explicitly specify mysql node address,MERGED,2014-06-04 12:46:28.000000000,2014-06-23 15:28:21.000000000,2014-06-23 15:28:21.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-06-04 12:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/077839dba849291e539b297cb76cdea9bea0a486', 'message': 'Explicitly specify mysql node address\n\nIf node address is not explicitly specified, mysql galera may sometimes\nuse virtual IP as ""source"" IP when joining to cluster. It fails because this\nvirtual IP is not on list of IPs of cluster nodes (wsrep_cluster_address).\n\nChange-Id: Iec08a458c747f4415a961022c56f66fe0a1f60b4\n'}, {'number': 2, 'created': '2014-06-05 06:58:43.000000000', 'files': ['elements/mysql-common/os-config-applier/mnt/state/etc/mysql/conf.d/cluster.cnf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e537ea6869ecab1a20ddb14934fd3dea0c323686', 'message': 'Explicitly specify mysql node address\n\nIf node address is not explicitly specified, mysql galera may sometimes\nuse virtual IP as ""source"" IP when joining to cluster. It fails because this\nvirtual IP is not on list of IPs of cluster nodes (wsrep_cluster_address).\n\nChange-Id: Iec08a458c747f4415a961022c56f66fe0a1f60b4\n'}]",0,97775,e537ea6869ecab1a20ddb14934fd3dea0c323686,25,6,2,7582,,,0,"Explicitly specify mysql node address

If node address is not explicitly specified, mysql galera may sometimes
use virtual IP as ""source"" IP when joining to cluster. It fails because this
virtual IP is not on list of IPs of cluster nodes (wsrep_cluster_address).

Change-Id: Iec08a458c747f4415a961022c56f66fe0a1f60b4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/75/97775/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-common/os-config-applier/mnt/state/etc/mysql/conf.d/cluster.cnf'],1,077839dba849291e539b297cb76cdea9bea0a486,,"# Node's network address, this address should be also included in # wsrep_cluster_address addresses list wsrep_node_address={{#local-ipv4}} ",,4,0
openstack%2Ftripleo-image-elements~master~I5186fb7abf8706f198ff10ced3e245b871edb2a1,openstack/tripleo-image-elements,master,I5186fb7abf8706f198ff10ced3e245b871edb2a1,Enable collectl on systemd OSes.,MERGED,2014-05-08 15:01:49.000000000,2014-06-23 15:25:50.000000000,2014-06-23 15:25:49.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 8449}, {'_account_id': 8532}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-05-08 15:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b32afc5086c19c85a533139d6da601ca773c476b', 'message': 'Enable collectl on systemd OSes.\n\nWe now ensure that the collectl systemd service is enabled on OSes that\nrequire such things.\n\nChange-Id: I5186fb7abf8706f198ff10ced3e245b871edb2a1\n'}, {'number': 2, 'created': '2014-06-19 18:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6bd80e33388c9b3f132dac776a5bd1bd0baa90fe', 'message': 'Enable collectl on systemd OSes.\n\nWe now ensure that the collectl systemd service is enabled on OSes that\nrequire such things.\n\nChange-Id: I5186fb7abf8706f198ff10ced3e245b871edb2a1\n'}, {'number': 3, 'created': '2014-06-23 02:20:21.000000000', 'files': ['elements/collectl/install.d/85-collectl'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6a876c4565aab59e401374de5110abe110f499c2', 'message': 'Enable collectl on systemd OSes.\n\nWe now ensure that the collectl systemd service is enabled on OSes that\nrequire such things.\n\nChange-Id: I5186fb7abf8706f198ff10ced3e245b871edb2a1\n'}]",3,92853,6a876c4565aab59e401374de5110abe110f499c2,30,7,3,6449,,,0,"Enable collectl on systemd OSes.

We now ensure that the collectl systemd service is enabled on OSes that
require such things.

Change-Id: I5186fb7abf8706f198ff10ced3e245b871edb2a1
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/53/92853/3 && git format-patch -1 --stdout FETCH_HEAD,['elements/collectl/install.d/85-collectl'],1,b32afc5086c19c85a533139d6da601ca773c476b,enable-collectl-on-systemd,"if [ ""$DIB_INIT_SYSTEM"" == ""systemd"" ] ; then systemctl enable collectl.service fi ",,4,0
openstack%2Fcongress~master~Icf0d5a9e511bbb11bd2f4e2ef27c4c50511151b7,openstack/congress,master,Icf0d5a9e511bbb11bd2f4e2ef27c4c50511151b7,Move API specific code to api subdirectory,MERGED,2014-06-20 23:27:16.000000000,2014-06-23 15:23:20.000000000,2014-06-23 15:23:20.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-06-20 23:27:16.000000000', 'files': ['scripts/run_api_server', 'congress/api/wsgi.py', 'congress/api/webservice.py', 'congress/server/server.py', 'congress/api/__init__.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f4919d7929ab63cac6572a39ae030b1a3aa330aa', 'message': ""Move API specific code to api subdirectory\n\nThe API will be a thread within the server, not the server itself.\nBecause of this, it doesn't make sense for the API to live at the\nserver path.\n\nChange-Id: Icf0d5a9e511bbb11bd2f4e2ef27c4c50511151b7\n""}]",0,101670,f4919d7929ab63cac6572a39ae030b1a3aa330aa,9,2,1,9253,,,0,"Move API specific code to api subdirectory

The API will be a thread within the server, not the server itself.
Because of this, it doesn't make sense for the API to live at the
server path.

Change-Id: Icf0d5a9e511bbb11bd2f4e2ef27c4c50511151b7
",git fetch https://review.opendev.org/openstack/congress refs/changes/70/101670/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/run_api_server', 'congress/api/wsgi.py', 'congress/api/webservice.py', 'congress/server/server.py', 'congress/api/__init__.py']",5,f4919d7929ab63cac6572a39ae030b1a3aa330aa,,,,9,9
openstack%2Ftripleo-image-elements~master~Ia5cbb7b4a3caf59f47b7c6fb259c964989f1d0d4,openstack/tripleo-image-elements,master,Ia5cbb7b4a3caf59f47b7c6fb259c964989f1d0d4,MySQL Element: Make userhandle an optional paramater,MERGED,2014-06-10 21:39:41.000000000,2014-06-23 15:22:00.000000000,2014-06-23 15:21:59.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 7537}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-06-10 21:39:41.000000000', 'files': ['elements/mysql-common/os-refresh-config/post-configure.d/50-mysql-users'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0d8916a94ac809bd52ce1007fddc74aceb8927ca', 'message': 'MySQL Element: Make userhandle an optional paramater\n\nThis updates the code to reflect the README.md documentation\n\nChange-Id: Ia5cbb7b4a3caf59f47b7c6fb259c964989f1d0d4\n'}]",0,99214,0d8916a94ac809bd52ce1007fddc74aceb8927ca,14,4,1,741,,,0,"MySQL Element: Make userhandle an optional paramater

This updates the code to reflect the README.md documentation

Change-Id: Ia5cbb7b4a3caf59f47b7c6fb259c964989f1d0d4
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/14/99214/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-common/os-refresh-config/post-configure.d/50-mysql-users'],1,0d8916a94ac809bd52ce1007fddc74aceb8927ca,," if 'userhandle' in dbvalue: # Inform Heat of new password for this user cmd = ['/opt/aws/bin/cfn-signal', '-i', dbvalue['username'], '-s', 'true', '--data', password, dbvalue['userhandle']] if opts.noop: print cmd else: subprocess.check_call(cmd)"," # Inform Heat of new password for this user cmd = ['/opt/aws/bin/cfn-signal', '-i', dbvalue['username'], '-s', 'true', '--data', password, dbvalue['userhandle']] if opts.noop: print cmd else: subprocess.check_call(cmd)",9,7
openstack%2Fmistral~master~I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa,openstack/mistral,master,I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa,Trigger doesn't use task,ABANDONED,2014-06-17 00:24:33.000000000,2014-06-23 15:18:18.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-17 00:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/27b878e6f1929cbccdec17456d4f72b668436a7b', 'message': ""Trigger doesn't use task\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa\n""}, {'number': 2, 'created': '2014-06-18 00:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/59926db7a27c3848298170238f65bfcaaa820c39', 'message': ""Trigger doesn't use task\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa\n""}, {'number': 3, 'created': '2014-06-20 04:52:40.000000000', 'files': ['mistral/tests/resources/test_rest.yaml', 'mistral/workbook/workbook.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e36a78032b12c22166d1481e2a50d3c29cf44fb7', 'message': ""Trigger doesn't use task\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa\n""}]",0,100392,e36a78032b12c22166d1481e2a50d3c29cf44fb7,14,7,3,9432,,,0,"Trigger doesn't use task

Partially implements: blueprint mistral-workflow-start-task

Change-Id: I4b98d24226cc73dc1cd53bcd3d0f0c282c59e9aa
",git fetch https://review.opendev.org/openstack/mistral refs/changes/92/100392/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/resources/test_rest.yaml', 'mistral/workbook/workbook.py']",2,27b878e6f1929cbccdec17456d4f72b668436a7b,bp/mistral-workflow-start-task,," def get_trigger_task_name(self, trigger_name): trigger = self._data[""triggers""].get(trigger_name) return trigger.get('tasks') if trigger else """"",0,4
openstack%2Fsolum~master~I365ae2b4da7b47ce505fd7bc790ebafefe41f131,openstack/solum,master,I365ae2b4da7b47ce505fd7bc790ebafefe41f131,Add yaml safe dumper,MERGED,2014-06-20 12:23:38.000000000,2014-06-23 15:17:26.000000000,2014-06-23 15:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-20 12:23:38.000000000', 'files': ['solum/tests/common/test_yamlutils.py', 'solum/common/yamlutils.py', 'solum/api/controllers/v1/plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/efbd53d78404cf9ed5bfece90c830351c57bbccc', 'message': 'Add yaml safe dumper\n\nCloses-Bug: #1332177\nChange-Id: I365ae2b4da7b47ce505fd7bc790ebafefe41f131\n'}]",0,101512,efbd53d78404cf9ed5bfece90c830351c57bbccc,13,4,1,9548,,,0,"Add yaml safe dumper

Closes-Bug: #1332177
Change-Id: I365ae2b4da7b47ce505fd7bc790ebafefe41f131
",git fetch https://review.opendev.org/openstack/solum refs/changes/12/101512/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/common/test_yamlutils.py', 'solum/common/yamlutils.py', 'solum/api/controllers/v1/plan.py']",3,efbd53d78404cf9ed5bfece90c830351c57bbccc,add-yaml-safe-dumper, plan_yml = yamlutils.dump(yaml_content(handler.get(self._id))) updated_plan_yml = yamlutils.dump(yaml_content(handler.update( plan_yml = yamlutils.dump([yaml_content(obj) for obj in handler.get_all() if obj and obj.raw_content]), plan_yml = yaml.dump(yaml_content(handler.get(self._id))) updated_plan_yml = yaml.dump(yaml_content(handler.update( plan_yml = yaml.dump([yaml_content(obj) for obj in handler.get_all() if obj and obj.raw_content]),27,5
openstack%2Fgovernance~master~Ib4525b8d45d8cc78b6c7beddc0e157478f747c52,openstack/governance,master,Ib4525b8d45d8cc78b6c7beddc0e157478f747c52,Adds openstack/training-guides repo to Documentation program,MERGED,2014-06-11 15:41:02.000000000,2014-06-23 15:17:12.000000000,2014-06-23 15:17:11.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1247}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-11 15:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/ed92aee210e080f4ecf19031e6670cb2dc519565', 'message': 'Adds openstack/training-guides to Documentation program\n\nChange-Id: Ib4525b8d45d8cc78b6c7beddc0e157478f747c52\n'}, {'number': 2, 'created': '2014-06-11 15:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/b98df2261f3c885896a40b4e916f92069d53540a', 'message': 'Adds openstack/training-guides repo to Documentation program\n\nChange-Id: Ib4525b8d45d8cc78b6c7beddc0e157478f747c52\n'}, {'number': 3, 'created': '2014-06-23 13:58:33.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/9c67092d8e64710cb23c4d437391710422593e32', 'message': 'Adds openstack/training-guides repo to Documentation program\n\nChange-Id: Ib4525b8d45d8cc78b6c7beddc0e157478f747c52\n'}]",0,99408,9c67092d8e64710cb23c4d437391710422593e32,27,10,3,964,,,0,"Adds openstack/training-guides repo to Documentation program

Change-Id: Ib4525b8d45d8cc78b6c7beddc0e157478f747c52
",git fetch https://review.opendev.org/openstack/governance refs/changes/08/99408/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,ed92aee210e080f4ecf19031e6670cb2dc519565,training-guides-doc-program, - repo: openstack/training-guides,,1,0
openstack%2Fsolum~master~I1fcb5b8ef50fc5c99e2d29e4df390bb3d5130bad,openstack/solum,master,I1fcb5b8ef50fc5c99e2d29e4df390bb3d5130bad,Add use of wrap_pecan_exception decorator in trigger controller,MERGED,2014-06-20 14:56:07.000000000,2014-06-23 15:16:39.000000000,2014-06-23 15:16:39.000000000,"[{'_account_id': 3}, {'_account_id': 8334}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-20 14:56:07.000000000', 'files': ['solum/api/controllers/v1/pub/trigger.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/49dffc095856d862ffa276d3c6b54339c5d75665', 'message': 'Add use of wrap_pecan_exception decorator in trigger controller\n\nChange-Id: I1fcb5b8ef50fc5c99e2d29e4df390bb3d5130bad\n'}]",0,101571,49dffc095856d862ffa276d3c6b54339c5d75665,14,5,1,9548,,,0,"Add use of wrap_pecan_exception decorator in trigger controller

Change-Id: I1fcb5b8ef50fc5c99e2d29e4df390bb3d5130bad
",git fetch https://review.opendev.org/openstack/solum refs/changes/71/101571/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/api/controllers/v1/pub/trigger.py'],1,49dffc095856d862ffa276d3c6b54339c5d75665,add-wrap-pecan-exception-in-trigger, @exception.wrap_pecan_controller_exception handler.trigger_workflow(trigger_id) pecan.response.status = 202, try: handler.trigger_workflow(trigger_id) pecan.response.status = 202 except exception.ResourceNotFound as excp: pecan.response.status = excp.code pecan.response.body = excp.message,3,6
openstack%2Fpython-mistralclient~master~If034adebe4bcf39fef0e26b48023a6f8d215896f,openstack/python-mistralclient,master,If034adebe4bcf39fef0e26b48023a6f8d215896f,Modify API to make use of /executions endpoint,MERGED,2014-06-23 08:21:34.000000000,2014-06-23 15:14:06.000000000,2014-06-23 15:14:06.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-23 08:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/d3b7585313538104fd723d7eab149bdbbcdc97a9', 'message': 'Modify API to make use of /executions endpoint\n\nChange-Id: If034adebe4bcf39fef0e26b48023a6f8d215896f\n'}, {'number': 2, 'created': '2014-06-23 09:25:10.000000000', 'files': ['mistralclient/api/tasks.py', 'mistralclient/tests/test_tasks.py', 'mistralclient/api/executions.py', 'mistralclient/tests/test_executions.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/1973461321ec1acdb2dc7cff7a4b26b64b433a40', 'message': 'Modify API to make use of /executions endpoint\n\nChange-Id: If034adebe4bcf39fef0e26b48023a6f8d215896f\n'}]",0,101822,1973461321ec1acdb2dc7cff7a4b26b64b433a40,12,8,2,10127,,,0,"Modify API to make use of /executions endpoint

Change-Id: If034adebe4bcf39fef0e26b48023a6f8d215896f
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/22/101822/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/api/tasks.py', 'mistralclient/tests/test_tasks.py', 'mistralclient/api/executions.py', 'mistralclient/commands/tasks.py']",4,d3b7585313538104fd723d7eab149bdbbcdc97a9,bp/mistral-ui," .list(parsed_args.execution, parsed_args.workbook)]"," .list(parsed_args.workbook, parsed_args.execution)]",19,14
openstack%2Fpython-openstackclient~master~Ic8d5fd5a19095aa0e83cb75252482e2d26440151,openstack/python-openstackclient,master,Ic8d5fd5a19095aa0e83cb75252482e2d26440151,Add list users of group,ABANDONED,2014-04-09 14:25:32.000000000,2014-06-23 15:07:00.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8736}, {'_account_id': 9550}]","[{'number': 1, 'created': '2014-04-09 14:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c2badf025b0ebf34326d2b0e1a7cd5dd8fa1cf4c', 'message': 'Add list users of group\n\nAdd the --user option to group list command, this option allows to show\nlist of members of this group. With this option group must be specified\n\nCloses-Bug: #1207621\n\nChange-Id: Ic8d5fd5a19095aa0e83cb75252482e2d26440151\n'}, {'number': 2, 'created': '2014-04-09 14:35:08.000000000', 'files': ['openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v3/test_group.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d843714bc9865273925c7667a8aafba09caa15aa', 'message': 'Add list users of group\n\nAdd the --user option to group list command, this option allows to show\nlist of members of this group. With this option group must be specified\n\nCloses-Bug: #1207621\n\nChange-Id: Ic8d5fd5a19095aa0e83cb75252482e2d26440151\n'}]",0,86349,d843714bc9865273925c7667a8aafba09caa15aa,14,4,2,9550,,,0,"Add list users of group

Add the --user option to group list command, this option allows to show
list of members of this group. With this option group must be specified

Closes-Bug: #1207621

Change-Id: Ic8d5fd5a19095aa0e83cb75252482e2d26440151
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/49/86349/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v3/test_group.py']",2,c2badf025b0ebf34326d2b0e1a7cd5dd8fa1cf4c,list-users-in-group,"# Copyright 2014 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import copy from openstackclient.identity.v3 import group from openstackclient.tests import fakes from openstackclient.tests.identity.v3 import fakes as identity_fakes class TestGroup(identity_fakes.TestIdentityv3): def setUp(self): super(TestGroup, self).setUp() self.users_mock = self.app.client_manager.identity.users self.users_mock.reset_mock() self.groups_mock = self.app.client_manager.identity.groups self.groups_mock.reset_mock() class TestGroupList(TestGroup): def setUp(self): super(TestGroupList, self).setUp() self.users_mock.list.return_value = [ fakes.FakeResource( None, copy.deepcopy(identity_fakes.USER), loaded=True, ), ] self.groups_mock.get.return_value = fakes.FakeResource( None, copy.deepcopy(identity_fakes.GROUP), loaded=True, ) self.cmd = group.ListGroup(self.app, None) def test_group_list_users(self): arglist = [ '--user', identity_fakes.group_id, ] verifylist = [ ('user', True), ('group', identity_fakes.group_id), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) columns, data = self.cmd.take_action(parsed_args) kwargs = { 'group': self.groups_mock.get(), } self.users_mock.list.assert_called_with( **kwargs ) collist = ('ID', 'Name', 'Group') self.assertEqual(columns, collist) datalist = (( identity_fakes.user_id, identity_fakes.user_name, identity_fakes.group_name ), ) self.assertEqual(tuple(data), datalist) ",,111,0
openstack%2Fmistral-extra~master~Iff13051b4b8e6b61b7e9d3198729496cd321609a,openstack/mistral-extra,master,Iff13051b4b8e6b61b7e9d3198729496cd321609a,"Fixing ""publish"" clause in example workbooks",MERGED,2014-06-23 12:30:22.000000000,2014-06-23 15:06:57.000000000,2014-06-23 15:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8592}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-23 12:30:22.000000000', 'files': ['examples/create_vm/create_vm_example.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/5d08f3cf726f9a952d2ece7d7c535c1cfb5fe19b', 'message': 'Fixing ""publish"" clause in example workbooks\n\nChange-Id: Iff13051b4b8e6b61b7e9d3198729496cd321609a\n'}]",0,101899,5d08f3cf726f9a952d2ece7d7c535c1cfb5fe19b,7,5,1,8731,,,0,"Fixing ""publish"" clause in example workbooks

Change-Id: Iff13051b4b8e6b61b7e9d3198729496cd321609a
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/99/101899/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/create_vm/create_vm_example.yaml'],1,5d08f3cf726f9a952d2ece7d7c535c1cfb5fe19b,fix_publish_clause_in_examples, vm_id: $.vm_id, vm_id: vm_id,1,1
openstack%2Fpython-openstackclient~master~I4c9addb46819a1b3e4ac646c1177161b2521f85b,openstack/python-openstackclient,master,I4c9addb46819a1b3e4ac646c1177161b2521f85b,Add list of user groups,ABANDONED,2014-04-08 15:58:02.000000000,2014-06-23 15:06:48.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 8871}, {'_account_id': 9550}]","[{'number': 1, 'created': '2014-04-08 15:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e8a4d42ad03700029b0b733ca7c40f42aa17c87b', 'message': 'Add list of user groups\n\nAdd the --group option to user list command, this option allows to show\ngroups which user is member of. With this option user must be specified\n\nFix Bug #1207620\n\nChange-Id: I4c9addb46819a1b3e4ac646c1177161b2521f85b\n'}, {'number': 2, 'created': '2014-04-08 16:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6d4e2410bc452277d52c060e5c3e2ec41d9cddf3', 'message': 'Add list of user groups\n\nAdd the --group option to user list command, this option allows to show\ngroups which user is member of. With this option user must be specified\n\nFix Bug #1207620\n\nChange-Id: I4c9addb46819a1b3e4ac646c1177161b2521f85b\n'}, {'number': 3, 'created': '2014-04-08 16:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/75b419b1c1351dbd90b866f0f6936f72568db54a', 'message': 'Add list of user groups\n\nAdd the --group option to user list command, this option allows to show\ngroups which user is member of. With this option user must be specified\n\nCloses-Bug: #1207620\n\nChange-Id: I4c9addb46819a1b3e4ac646c1177161b2521f85b\n'}, {'number': 4, 'created': '2014-04-28 15:53:44.000000000', 'files': ['openstackclient/tests/identity/v3/test_user.py', 'openstackclient/identity/v3/user.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bdc2109b0dc14b62087f5d827e21d6ecfa071ca2', 'message': 'Add list of user groups\n\nAdd the --group option to user list command, this option allows to show\ngroups which user is member of. With this option user must be specified\n\nCloses-Bug: #1207620\n\nChange-Id: I4c9addb46819a1b3e4ac646c1177161b2521f85b\n'}]",7,86078,bdc2109b0dc14b62087f5d827e21d6ecfa071ca2,39,6,4,9550,,,0,"Add list of user groups

Add the --group option to user list command, this option allows to show
groups which user is member of. With this option user must be specified

Closes-Bug: #1207620

Change-Id: I4c9addb46819a1b3e4ac646c1177161b2521f85b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/78/86078/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/identity/v3/test_user.py', 'openstackclient/identity/v3/user.py']",2,e8a4d42ad03700029b0b733ca7c40f42aa17c87b,list-users-groups," '--group', action='store_true', default=False, help='List the groups <user> is member of', ) parser.add_argument( elif parsed_args.group: # List groups user is member of columns = ('ID', 'Name', 'User') # User is required here, bail if it is not supplied if not parsed_args.user: sys.stderr.write('Error: User must be specified') return ([], []) user = utils.find_resource( identity_client.users, parsed_args.user, ) data = identity_client.groups.list( user=user ) for user_group in data: user_group.user = user.name ",,69,0
openstack%2Fceilometer~stable%2Fhavana~Ia1bfa1bd24989681db1d2f385defc12e69a01f8d,openstack/ceilometer,stable/havana,Ia1bfa1bd24989681db1d2f385defc12e69a01f8d,remove token from notifier middleware,MERGED,2014-06-23 05:21:37.000000000,2014-06-23 14:57:07.000000000,2014-06-23 14:57:06.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-06-23 05:21:37.000000000', 'files': ['ceilometer/openstack/common/middleware/notifier.py', 'ceilometer/openstack/common/middleware/audit.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/264f3b0d9640edeac743f339786e0a3b22c0f6c2', 'message': 'remove token from notifier middleware\n\noslo-incubator sync to address the security bug\nin middleware (as below).\n\nnotifier middleware is capturing token and sending it to MQ. this\nis not advisable so we should filter it out.\n\nChange-Id: Ia1bfa1bd24989681db1d2f385defc12e69a01f8d\nCloses-Bug: #1321080\n'}]",0,101799,264f3b0d9640edeac743f339786e0a3b22c0f6c2,7,2,1,7473,,,0,"remove token from notifier middleware

oslo-incubator sync to address the security bug
in middleware (as below).

notifier middleware is capturing token and sending it to MQ. this
is not advisable so we should filter it out.

Change-Id: Ia1bfa1bd24989681db1d2f385defc12e69a01f8d
Closes-Bug: #1321080
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/99/101799/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/middleware/notifier.py', 'ceilometer/openstack/common/middleware/audit.py']",2,264f3b0d9640edeac743f339786e0a3b22c0f6c2,bug/1321080/oslo-incubator-sync,# Copyright (c) 2013 OpenStack Foundation,# Copyright (c) 2013 OpenStack LLC.,2,2
openstack%2Fpython-openstackclient~master~Ia54da66d13b2667375a8a85c97ced25fd97b6b25,openstack/python-openstackclient,master,Ia54da66d13b2667375a8a85c97ced25fd97b6b25,Updated from global requirements,MERGED,2014-06-23 05:34:51.000000000,2014-06-23 14:57:00.000000000,2014-06-23 14:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2014-06-23 05:34:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/eeebd0db8ca47032c292222513a518a21a909847', 'message': 'Updated from global requirements\n\nChange-Id: Ia54da66d13b2667375a8a85c97ced25fd97b6b25\n'}]",0,101802,eeebd0db8ca47032c292222513a518a21a909847,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ia54da66d13b2667375a8a85c97ced25fd97b6b25
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/02/101802/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,eeebd0db8ca47032c292222513a518a21a909847,openstack/requirements,cliff>=1.6.0,cliff>=1.4.3,1,1
openstack%2Fapi-site~master~I214521ab42ccc37e16c259f4f9e698522313f6a1,openstack/api-site,master,I214521ab42ccc37e16c259f4f9e698522313f6a1,"Enhance descriptions for pause, unpause, suspend, and resume servers",MERGED,2014-06-20 03:07:44.000000000,2014-06-23 14:56:16.000000000,2014-06-23 14:56:15.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-06-20 03:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/1d89107764ec17b866de6edbf191bed6da5a34b1', 'message': 'adding description for pause, unpause, suspend and resume servers\n\nChange-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1\n'}, {'number': 2, 'created': '2014-06-23 01:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/dee320fcf098128e318ad37ca91e55915bf6908a', 'message': 'adding description for pause, unpause, suspend and resume servers\n\nChange-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1\n'}, {'number': 3, 'created': '2014-06-23 01:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/029d59084546110b5cc9b69a3105871f8944bfc9', 'message': 'Describe pause, unpause, suspend and resume servers\n\nCloses-bug: 1295718\n\nChange-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1\n'}, {'number': 4, 'created': '2014-06-23 01:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/78e1857222dba1215581ef19268d4dc564d0aea1', 'message': 'Describe pause, unpause, suspend and resume servers\n\nCloses-Bug: #1295718\n\nChange-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1\n'}, {'number': 5, 'created': '2014-06-23 01:59:33.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/ext/os-admin-actions.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/6ce5a4cef5aade37b58213db790a0ab0cd815b19', 'message': 'Enhance descriptions for pause, unpause, suspend, and resume servers\n\nCloses-Bug: #1295718\n\nChange-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1\n'}]",5,101399,6ce5a4cef5aade37b58213db790a0ab0cd815b19,20,4,5,10279,,,0,"Enhance descriptions for pause, unpause, suspend, and resume servers

Closes-Bug: #1295718

Change-Id: I214521ab42ccc37e16c259f4f9e698522313f6a1
",git fetch https://review.opendev.org/openstack/api-site refs/changes/99/101399/3 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2/ext/os-admin-actions.wadl'],1,1d89107764ec17b866de6edbf191bed6da5a34b1,constanzeworking1," to PAUSED. Running this operation stores the state of the VM in RAM. A paused instance continues to run in a frozen state. A server instance can be unpaused by running the Unpause Server operation.</para> status to SUSPENDED. Administrative users may choose to suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.</para>", to PAUSED.</para> status to SUSPENDED.</para>,5,2
openstack%2Fpython-solumclient~master~Ib873dacee37d97f3d50d1be237e20619b2217397,openstack/python-solumclient,master,Ib873dacee37d97f3d50d1be237e20619b2217397,Add yaml safe loader and dumper,MERGED,2014-06-20 16:25:40.000000000,2014-06-23 14:55:32.000000000,2014-06-23 14:55:32.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-20 16:25:40.000000000', 'files': ['solumclient/v1/plan.py', 'solumclient/common/yamlutils.py', 'solumclient/tests/common/test_yamlutils.py', 'solumclient/tests/v1/test_plan.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/53d3888e35d92846800f40ac3129e59319cc6193', 'message': 'Add yaml safe loader and dumper\n\nCloses-Bug: #1332610\nChange-Id: Ib873dacee37d97f3d50d1be237e20619b2217397\n'}]",0,101597,53d3888e35d92846800f40ac3129e59319cc6193,16,4,1,9548,,,0,"Add yaml safe loader and dumper

Closes-Bug: #1332610
Change-Id: Ib873dacee37d97f3d50d1be237e20619b2217397
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/97/101597/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/v1/plan.py', 'solumclient/common/yamlutils.py', 'solumclient/tests/common/test_yamlutils.py', 'solumclient/tests/v1/test_plan.py']",4,53d3888e35d92846800f40ac3129e59319cc6193,bug/1332610," plan.PlanManager(api_client) # NOTE(stannie): will re-enable this test once # https://bugs.launchpad.net/solum/+bug/1331093 is committed. # FakeHTTPClient doesn't manage YAML properly but since this method # will use the json content-type once implemented in the API, this can # stay temporary disabled."," mgr = plan.PlanManager(api_client) plans = mgr.list() self.assertEqual(2, len(plans)) self.assertEqual(plan_list[0]['name'], plans[0]['name']) self.assertEqual(plan_list[1]['name'], plans[1]['name']) self.assertEqual(plan_list[0]['artifacts'][0]['name'], plans[0]['artifacts'][0]['name']) self.assertEqual(plan_list[1]['artifacts'][0]['name'], plans[1]['artifacts'][0]['name']) self.assertEqual(plan_list[0]['services'][0]['name'], plans[0]['services'][0]['name']) self.assertEqual(plan_list[1]['services'][0]['name'], plans[1]['services'][0]['name'])",108,26
openstack%2Fnova~master~Ibe9211fb944bb64f722e2417725e29506b17ee30,openstack/nova,master,Ibe9211fb944bb64f722e2417725e29506b17ee30,Object-ify APIv3 flavor_extraspecs extension,MERGED,2014-06-18 17:55:25.000000000,2014-06-23 14:54:10.000000000,2014-06-23 14:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-18 17:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed281fb76ac9076d6286cde400a4c09ad2354c61', 'message': 'Object-ify APIv3 flavor_extraspecs extension\n\nThis makes the APIv3 flavor_extraspecs extension use the Flavor\nobject instead of going direct to the database.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ibe9211fb944bb64f722e2417725e29506b17ee30\n'}, {'number': 2, 'created': '2014-06-18 18:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63b1c92ca897b24e31e5799ff02d3ef323a8aa1d', 'message': 'Object-ify APIv3 flavor_extraspecs extension\n\nThis makes the APIv3 flavor_extraspecs extension use the Flavor\nobject instead of going direct to the database.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ibe9211fb944bb64f722e2417725e29506b17ee30\n'}, {'number': 3, 'created': '2014-06-19 15:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9973ca7ea6466fadbfe1966906ae269186d96bae', 'message': 'Object-ify APIv3 flavor_extraspecs extension\n\nThis makes the APIv3 flavor_extraspecs extension use the Flavor\nobject instead of going direct to the database.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ibe9211fb944bb64f722e2417725e29506b17ee30\n'}, {'number': 4, 'created': '2014-06-20 16:57:16.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors_extra_specs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d854435a0e9b1f5954b9c5d963f94d7e9643554', 'message': 'Object-ify APIv3 flavor_extraspecs extension\n\nThis makes the APIv3 flavor_extraspecs extension use the Flavor\nobject instead of going direct to the database.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ibe9211fb944bb64f722e2417725e29506b17ee30\n'}]",12,100973,1d854435a0e9b1f5954b9c5d963f94d7e9643554,39,11,4,4393,,,0,"Object-ify APIv3 flavor_extraspecs extension

This makes the APIv3 flavor_extraspecs extension use the Flavor
object instead of going direct to the database.

Related to blueprint compute-manager-objects-juno

Change-Id: Ibe9211fb944bb64f722e2417725e29506b17ee30
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/100973/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/api/openstack/compute/plugins/v3/test_flavors_extra_specs.py']",2,ed281fb76ac9076d6286cde400a4c09ad2354c61,bp/compute-manager-objects-juno,"from nova.tests.objects import test_flavor flavor = dict(test_flavor.fake_flavor, extra_specs={'key1': 'value1'}) with mock.patch('nova.db.flavor_get_by_flavor_id') as mock_get: mock_get.return_value = flavor res_dict = self.controller.index(req, 1) flavor = dict(test_flavor.fake_flavor, extra_specs={'key5': 'value5'}) with mock.patch('nova.db.flavor_get_by_flavor_id') as mock_get: mock_get.return_value = flavor res_dict = self.controller.show(req, 1, 'key5') flavor = dict(test_flavor.fake_flavor, extra_specs={'key5': 'value5'}) with mock.patch('nova.db.flavor_get_by_flavor_id') as mock_get: mock_get.return_value = flavor self.assertRaises(webob.exc.HTTPNotFound, self.controller.show, req, 1, 'key6') flavor = dict(test_flavor.fake_flavor, extra_specs={'key5': 'value5'}) with mock.patch('nova.db.flavor_get_by_flavor_id') as mock_get: mock_get.return_value = flavor self.controller.delete(req, 1, 'key5')"," self.stubs.Set(nova.db, 'flavor_extra_specs_get', return_flavor_extra_specs) res_dict = self.controller.index(req, 1) self.stubs.Set(nova.db, 'flavor_extra_specs_get_item', return_flavor_extra_specs_item) res_dict = self.controller.show(req, 1, 'key5') self.stubs.Set(nova.db, 'flavor_extra_specs_get', return_empty_flavor_extra_specs) self.assertRaises(webob.exc.HTTPNotFound, self.controller.show, req, 1, 'key6') self.stubs.Set(nova.db, 'flavor_extra_specs_delete', delete_flavor_extra_specs) self.controller.delete(req, 1, 'key5')",50,26
openstack%2Fnova~master~I28bcc24382f1e993b98b3f7342fed53c9ae85cbf,openstack/nova,master,I28bcc24382f1e993b98b3f7342fed53c9ae85cbf,Object-ify APIv2 flavorextraspecs extension,MERGED,2014-06-18 16:50:38.000000000,2014-06-23 14:53:57.000000000,2014-06-23 14:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-18 16:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1561cf22487ad8bf143b70fa72d814c27f75eb84', 'message': 'Object-ify APIv2 flavorextraspecs extension\n\nThis makes the flavorextraspecs extension use the Flavor object.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf\n'}, {'number': 2, 'created': '2014-06-18 17:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4ff3a663e28e10868232dc0434fe3ae65994a5d', 'message': 'Object-ify APIv2 flavorextraspecs extension\n\nThis makes the flavorextraspecs extension use the Flavor object.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf\n'}, {'number': 3, 'created': '2014-06-18 18:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87c0c6f206bc1238873681097ed7f25f26c2c7bb', 'message': 'Object-ify APIv2 flavorextraspecs extension\n\nThis makes the flavorextraspecs extension use the Flavor object.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf\n'}, {'number': 4, 'created': '2014-06-19 15:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0ffb3e17b7dc0222621f942b900e3216e536d33', 'message': 'Object-ify APIv2 flavorextraspecs extension\n\nThis makes the flavorextraspecs extension use the Flavor object.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf\n'}, {'number': 5, 'created': '2014-06-20 16:57:16.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c1484ec0366bcb60210281472ea61f3d2abad7b', 'message': 'Object-ify APIv2 flavorextraspecs extension\n\nThis makes the flavorextraspecs extension use the Flavor object.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf\n'}]",8,100960,0c1484ec0366bcb60210281472ea61f3d2abad7b,46,12,5,4393,,,0,"Object-ify APIv2 flavorextraspecs extension

This makes the flavorextraspecs extension use the Flavor object.

Related to blueprint compute-manager-objects-juno

Change-Id: I28bcc24382f1e993b98b3f7342fed53c9ae85cbf
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/100960/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py']",2,1561cf22487ad8bf143b70fa72d814c27f75eb84,bp/compute-manager-objects-juno,"from nova import objects flavor = objects.Flavor.get_by_flavor_id(context, flavor_id) return dict(extra_specs=flavor.extra_specs) flavor = objects.Flavor.get_by_flavor_id(context, flavor_id) flavor.extra_specs = dict(flavor.extra_specs, **specs) try: flavor.save() flavor = objects.Flavor.get_by_flavor_id(context, flavor_id) flavor.extra_specs = body try: flavor.save() flavor = objects.Flavor.get_by_flavor_id(context, flavor_id) return {id: flavor.extra_specs[id]} except (exception.FlavorNotFound, KeyError) as e: flavor = objects.Flavor.get_by_flavor_id(context, flavor_id) del flavor.extra_specs[id] flavor.save() except exception.FlavorNotFound as e: except KeyError: msg = _(""Flavor %(flavor_id)s has no extra specs with "" ""key %(key)s."") % dict(flavor_id=flavor_id, key=id) raise exc.HTTPNotFound(explanation=msg)","from nova import db extra_specs = db.flavor_extra_specs_get(context, flavor_id) return dict(extra_specs=extra_specs) try: db.flavor_extra_specs_update_or_create(context, flavor_id, specs) try: db.flavor_extra_specs_update_or_create(context, flavor_id, body) extra_spec = db.flavor_extra_specs_get_item(context, flavor_id, id) return extra_spec except exception.FlavorExtraSpecsNotFound: db.flavor_extra_specs_delete(context, flavor_id, id) except exception.FlavorExtraSpecsNotFound as e:",37,24
openstack%2Foslo-incubator~master~I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d,openstack/oslo-incubator,master,I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d,Use oslo.messaging to publish log errors,MERGED,2014-06-17 09:10:56.000000000,2014-06-23 14:51:23.000000000,2014-06-23 14:51:23.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 8041}, {'_account_id': 9107}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-06-17 09:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/21a79e8372426f85c15254979adb3b230e4231fb', 'message': 'Use oslo.messaging to publish log errors\n\nIf oslo.messaging is available, use its PublishErrorsHandler instead of\nthe one from log_handler which relies on oslo notifier.\n\nChange-Id: I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d\nCloses-Bug: #1330878\n'}, {'number': 2, 'created': '2014-06-17 11:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/139b3167562acc730aa8207b3ec11b7beb8a871f', 'message': 'Use oslo.messaging to publish log errors\n\nIf oslo.messaging is available, use its PublishErrorsHandler instead of\nthe one from log_handler which relies on oslo notifier.\n\nChange-Id: I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d\nCloses-Bug: #1330878\n'}, {'number': 3, 'created': '2014-06-18 08:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d2190b0d2b014b0e52ca450cbe6e767a5a67e38c', 'message': ""Use oslo.messaging to publish log errors\n\nFallback to oslo.messaging PublishErrorsHandler if it's available\ninstead of the one from log_handler which relies on oslo notifier.\n\nChange-Id: I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d\nCloses-Bug: #1330878\n""}, {'number': 4, 'created': '2014-06-23 14:11:21.000000000', 'files': ['openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/109e325eec054aefe4fcef4b928a46a6d7247e05', 'message': 'Use oslo.messaging to publish log errors\n\nIf log_handler is not available, fallback to oslo.messaging PublishErrorsHandler\nto not require oslo notifier.\n\nChange-Id: I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d\nCloses-Bug: #1330878\n'}]",1,100457,109e325eec054aefe4fcef4b928a46a6d7247e05,32,14,4,7385,,,0,"Use oslo.messaging to publish log errors

If log_handler is not available, fallback to oslo.messaging PublishErrorsHandler
to not require oslo notifier.

Change-Id: I28f421ddc4779dfddc8ecf40b709de06cf9dfc6d
Closes-Bug: #1330878
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/57/100457/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/log.py'],1,21a79e8372426f85c15254979adb3b230e4231fb,bug/1330878," try: handler = importutils.import_object( ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", logging.ERROR) except ImportError: handler = importutils.import_object( ""openstack.common.log_handler.PublishErrorsHandler"", logging.ERROR)"," handler = importutils.import_object( ""openstack.common.log_handler.PublishErrorsHandler"", logging.ERROR)",8,3
openstack%2Fnova~master~Ic4439e05b9c0b8274e54768cbd7949aced45cc69,openstack/nova,master,Ic4439e05b9c0b8274e54768cbd7949aced45cc69,Fix Flavor object extra_specs and projects handling,MERGED,2014-06-18 16:50:38.000000000,2014-06-23 14:47:29.000000000,2014-06-23 14:47:27.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-18 16:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a26ce2151e4ded0c65b0adae91c5d154f94569c6', 'message': ""Fix Flavor object extra_specs and projects handling\n\nThe Flavor.save() method was not properly handling extra_specs\nand projects when deletions occur, and was doing a read/edit/save\ncycle, which could involve some stale data.\n\nThis patch keeps the object-y interface to adding/removing things\nfrom those lists, but ensures that they're added/removed individually\non the backend. The save() method is strange on Flavor, in that only\nthese two sets of data are actually mutable. Because of this, it's\nfairly convenient to make that method no longer remotable and\nbreak the actions into two new remotable methods that take fine-\ngrained lists of add/remove tasks.\n\nNote that Flavor was not used over RPC in any previous release,\nso the remotability change doesn't really affect anything. However,\nif a client were to issue a remoted save() call, it would still work\nand would still have the same (broken) behavior as before, where\ndeletes don't propagate and we just always add/update every key.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ic4439e05b9c0b8274e54768cbd7949aced45cc69\n""}, {'number': 2, 'created': '2014-06-18 17:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55e729abda26a3d3bd119e08b16fa849bf7c9ae3', 'message': ""Fix Flavor object extra_specs and projects handling\n\nThe Flavor.save() method was not properly handling extra_specs\nand projects when deletions occur, and was doing a read/edit/save\ncycle, which could involve some stale data.\n\nThis patch keeps the object-y interface to adding/removing things\nfrom those lists, but ensures that they're added/removed individually\non the backend. The save() method is strange on Flavor, in that only\nthese two sets of data are actually mutable. Because of this, it's\nfairly convenient to make that method no longer remotable and\nbreak the actions into two new remotable methods that take fine-\ngrained lists of add/remove tasks.\n\nNote that Flavor was not used over RPC in any previous release,\nso the remotability change doesn't really affect anything. However,\nif a client were to issue a remoted save() call, it would still work\nand would still have the same (broken) behavior as before, where\ndeletes don't propagate and we just always add/update every key.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ic4439e05b9c0b8274e54768cbd7949aced45cc69\n""}, {'number': 3, 'created': '2014-06-18 18:44:02.000000000', 'files': ['nova/tests/objects/test_flavor.py', 'nova/tests/objects/test_objects.py', 'nova/objects/flavor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4115b522b3bfcb119ac9ad53a47edab5fee7ad48', 'message': ""Fix Flavor object extra_specs and projects handling\n\nThe Flavor.save() method was not properly handling extra_specs\nand projects when deletions occur, and was doing a read/edit/save\ncycle, which could involve some stale data.\n\nThis patch keeps the object-y interface to adding/removing things\nfrom those lists, but ensures that they're added/removed individually\non the backend. The save() method is strange on Flavor, in that only\nthese two sets of data are actually mutable. Because of this, it's\nfairly convenient to make that method no longer remotable and\nbreak the actions into two new remotable methods that take fine-\ngrained lists of add/remove tasks.\n\nNote that Flavor was not used over RPC in any previous release,\nso the remotability change doesn't really affect anything. However,\nif a client were to issue a remoted save() call, it would still work\nand would still have the same (broken) behavior as before, where\ndeletes don't propagate and we just always add/update every key.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: Ic4439e05b9c0b8274e54768cbd7949aced45cc69\n""}]",2,100959,4115b522b3bfcb119ac9ad53a47edab5fee7ad48,22,7,3,4393,,,0,"Fix Flavor object extra_specs and projects handling

The Flavor.save() method was not properly handling extra_specs
and projects when deletions occur, and was doing a read/edit/save
cycle, which could involve some stale data.

This patch keeps the object-y interface to adding/removing things
from those lists, but ensures that they're added/removed individually
on the backend. The save() method is strange on Flavor, in that only
these two sets of data are actually mutable. Because of this, it's
fairly convenient to make that method no longer remotable and
break the actions into two new remotable methods that take fine-
grained lists of add/remove tasks.

Note that Flavor was not used over RPC in any previous release,
so the remotability change doesn't really affect anything. However,
if a client were to issue a remoted save() call, it would still work
and would still have the same (broken) behavior as before, where
deletes don't propagate and we just always add/update every key.

Related to blueprint compute-manager-objects-juno

Change-Id: Ic4439e05b9c0b8274e54768cbd7949aced45cc69
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/100959/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/objects/test_flavor.py', 'nova/objects/flavor.py']",2,a26ce2151e4ded0c65b0adae91c5d154f94569c6,bp/compute-manager-objects-juno," # Version 1.0: Initial version # Version 1.1: Added save_projects(), save_extra_specs(), removed # remoteable from save() VERSION = '1.1' def __init__(self, *args, **kwargs): super(Flavor, self).__init__(*args, **kwargs) self._orig_extra_specs = {} self._orig_projects = {} def obj_reset_changes(self, fields=None): super(Flavor, self).obj_reset_changes(fields=fields) if fields is None or 'extra_specs' in fields: self._orig_extra_specs = (dict(self.extra_specs) if self.obj_attr_is_set('extra_specs') else {}) if fields is None or 'projects' in fields: self._orig_projects = (list(self.projects) if self.obj_attr_is_set('projects') else []) @classmethod def _obj_from_primitive(cls, context, objver, primitive): self = super(Flavor, cls)._obj_from_primitive(context, objver, primitive) changes = self.obj_what_changed() if 'extra_specs' not in changes: # This call left extra_specs ""clean"" so update our tracker self._orig_extra_specs = (dict(self.extra_specs) if self.obj_attr_is_set('extra_specs') else {}) if 'projects' not in changes: # This call left projects ""clean"" so update our tracker self._orig_projects = (list(self.projects) if self.obj_attr_is_set('projects') else []) return self def save_projects(self, context, to_add=None, to_delete=None): """"""Add or delete projects. :param:to_add: A list of projects to add :param:to_delete: A list of projects to remove """""" to_add = to_add if to_add is not None else [] to_delete = to_delete if to_delete is not None else [] for project_id in to_add: db.flavor_access_add(context, self.flavorid, project_id) for project_id in to_delete: db.flavor_access_remove(context, self.flavorid, project_id) self.obj_reset_changes(['projects']) @base.remotable def save_extra_specs(self, context, to_add=None, to_delete=None): """"""Add or delete extra_specs. :param:to_add: A dict of new keys to add/update :param:to_delete: A list of keys to remove """""" to_add = to_add if to_add is not None else [] to_delete = to_delete if to_delete is not None else [] db.flavor_extra_specs_update_or_create(context, self.flavorid, to_add) for key in to_delete: db.flavor_extra_specs_delete(context, self.flavorid, key) self.obj_reset_changes(['extra_specs']) def save(self): context = self._context if extra_specs is not None: deleted_keys = (set(self._orig_extra_specs.keys()) - set(extra_specs.keys())) added_keys = self.extra_specs else: added_keys = deleted_keys = None if projects is not None: deleted_projects = set(self._orig_projects) - set(projects) added_projects = set(projects) - set(self._orig_projects) else: added_projects = deleted_projects = None # NOTE(danms): The first remotable method we call will reset # our of the original values for projects and extra_specs. Thus, # we collect the added/deleted lists for both above and /then/ # call these methods to update them. if added_keys or deleted_keys: self.save_extra_specs(context, self.extra_specs, deleted_keys) if added_projects or deleted_projects: self.save_projects(context, added_projects, deleted_projects)"," VERSION = '1.0' def save(self, context): if extra_specs: db.flavor_extra_specs_update_or_create(context, self.flavorid, extra_specs) # NOTE(danms): This could be much simpler and more efficient # with a smarter flavor_access_update() method in db_api. if projects is not None: current_projects = [x['project_id'] for x in db.flavor_access_get_by_flavor_id( context, self.flavorid)] for project_id in projects: if project_id not in current_projects: db.flavor_access_add(context, self.flavorid, project_id) else: current_projects.remove(project_id) for condemned_project_id in current_projects: db.flavor_access_remove(context, self.flavorid, condemned_project_id) self.obj_reset_changes()",122,36
openstack%2Fpython-cinderclient~master~I2ffb49112d39ad96b91a4173526502a5201666c6,openstack/python-cinderclient,master,I2ffb49112d39ad96b91a4173526502a5201666c6,Fix Volume.extend and Volume.update_readonly_flag methods,MERGED,2014-03-17 10:51:52.000000000,2014-06-23 14:45:52.000000000,2014-06-23 14:45:52.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 9718}, {'_account_id': 9779}]","[{'number': 1, 'created': '2014-03-17 10:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3f52cbbc75d1c17d235c4a3812583bbcf820ee43', 'message': ""Fix Volume.extend method\n\nCorrect VolumeManager method signature called from Volume.extend method for\nv1 and v1 api's.\n\nChange-Id: I2ffb49112d39ad96b91a4173526502a5201666c6\nCloses-Bug: #1293423\n""}, {'number': 2, 'created': '2014-03-18 14:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/026f1deb45e6680963f35ed031a302c9a6a155db', 'message': ""Fix Volume.extend and Volume.update_readonly_flag methods\n\nCorrect VolumeManager method signature called from Volume.extend and\nVolume.update_readonly_flag methods for v1 and v2 api's.\n\nChange-Id: I2ffb49112d39ad96b91a4173526502a5201666c6\nCloses-Bug: #1293423\n""}, {'number': 3, 'created': '2014-03-18 15:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/fe93586fda7bb5b44d713feac18ba7795eb98c1d', 'message': ""Fix Volume.extend and Volume.update_readonly_flag methods\n\nCorrect VolumeManager method signature called from Volume.extend and\nVolume.update_readonly_flag methods for v1 and v2 api's.\n\nChange-Id: I2ffb49112d39ad96b91a4173526502a5201666c6\nCloses-Bug: #1293423, #1294178\n""}, {'number': 4, 'created': '2014-03-18 15:35:29.000000000', 'files': ['cinderclient/v2/volumes.py', 'cinderclient/v1/volumes.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d3236f568ecac1c038770ec04abd6f27e8148713', 'message': ""Fix Volume.extend and Volume.update_readonly_flag methods\n\nCorrect VolumeManager method signature called from Volume.extend and\nVolume.update_readonly_flag methods for v1 and v2 api's.\n\nChange-Id: I2ffb49112d39ad96b91a4173526502a5201666c6\nCloses-Bug: #1293423\nCloses-Bug: #1294178\n""}]",2,80944,d3236f568ecac1c038770ec04abd6f27e8148713,39,5,4,9718,,,0,"Fix Volume.extend and Volume.update_readonly_flag methods

Correct VolumeManager method signature called from Volume.extend and
Volume.update_readonly_flag methods for v1 and v2 api's.

Change-Id: I2ffb49112d39ad96b91a4173526502a5201666c6
Closes-Bug: #1293423
Closes-Bug: #1294178
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/44/80944/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v1/volumes.py', 'cinderclient/v2/volumes.py']",2,3f52cbbc75d1c17d235c4a3812583bbcf820ee43,bug/1293423," self.manager.extend(self, new_size)"," self.manager.extend(self, volume, new_size)",2,2
openstack%2Fheat~master~I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d,openstack/heat,master,I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d,Hide warning for old style attribute schema test,MERGED,2014-05-30 12:59:50.000000000,2014-06-23 14:45:45.000000000,2014-06-23 14:45:44.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8435}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 10018}]","[{'number': 1, 'created': '2014-05-30 12:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/215665aa1891d3e7e9cada719cfe357611ecbcd4', 'message': 'Hide warning for old style attribute schema test\n\nChange-Id: I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d\n'}, {'number': 2, 'created': '2014-06-02 06:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5cc4014f5e6faeb27ff00f7f3907bd001ba0b28b', 'message': 'Hide warning for old style attribute schema test\n\nChange-Id: I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d\n'}, {'number': 3, 'created': '2014-06-18 08:58:45.000000000', 'files': ['heat/tests/test_attributes.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4660f0957120065b1dbb96dd30aa7a967fe7fa03', 'message': 'Hide warning for old style attribute schema test\n\nChange-Id: I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d\n'}]",0,96755,4660f0957120065b1dbb96dd30aa7a967fe7fa03,38,10,3,6577,,,0,"Hide warning for old style attribute schema test

Change-Id: I6a3d0464bffe65f8ef7ab9006882cbeaa03cc20d
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/96755/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_attributes.py'],1,215665aa1891d3e7e9cada719cfe357611ecbcd4,,"import mock with mock.patch('heat.engine.attributes.warnings'): s = 'Test description.' self.assertIsInstance(attributes.Schema.from_attribute(s), attributes.Schema) self.assertEqual('Test description.', attributes.Schema.from_attribute(s).description)"," s = 'Test description.' self.assertIsInstance(attributes.Schema.from_attribute(s), attributes.Schema) self.assertEqual('Test description.', attributes.Schema.from_attribute(s).description)",7,5
openstack%2Fdesignate~master~I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876,openstack/designate,master,I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876,Unify Storage vs Rest of World fixture creation,MERGED,2014-06-21 11:37:35.000000000,2014-06-23 14:31:21.000000000,2014-06-23 14:31:20.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-06-21 11:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f6a1ac01517090f57468ff9b37fe77af26da47c3', 'message': 'WIP: Unify Storage vs Rest of World fixture creation\n\nChange-Id: I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876\n'}, {'number': 2, 'created': '2014-06-23 13:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/9c4dee02acb7723caa9cd87a34a19a26e318aeb8', 'message': 'Unify Storage vs Rest of World fixture creation\n\nChange-Id: I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876\n'}, {'number': 3, 'created': '2014-06-23 13:25:06.000000000', 'files': ['designate/tests/__init__.py', 'designate/tests/test_backend/test_ipa.py', 'designate/tests/test_api/test_v2/__init__.py', 'designate/tests/test_notification_handler/test_neutron.py', 'designate/tests/test_backend/__init__.py', 'designate/tests/test_storage/__init__.py', 'designate/tests/test_backend/test_powerdns.py', 'designate/tests/test_notification_handler/test_nova.py', 'designate/tests/test_api/test_service.py', 'designate/tests/test_central/test_service.py', 'designate/tests/test_api/test_v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/e45995b3f5f5f717127e3a615e6f0a32e58cc81f', 'message': 'Unify Storage vs Rest of World fixture creation\n\nChange-Id: I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876\n'}]",0,101700,e45995b3f5f5f717127e3a615e6f0a32e58cc81f,13,5,3,741,,,0,"Unify Storage vs Rest of World fixture creation

Change-Id: I1b8d602d1baf3ebf5f75c35f3e04efadaa0aa876
",git fetch https://review.opendev.org/openstack/designate refs/changes/00/101700/3 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/__init__.py', 'designate/tests/test_backend/test_ipa.py', 'designate/tests/test_api/test_v2/__init__.py', 'designate/tests/test_notification_handler/test_neutron.py', 'designate/tests/test_backend/__init__.py', 'designate/tests/test_storage/__init__.py', 'designate/tests/test_backend/test_powerdns.py', 'designate/tests/test_notification_handler/test_nova.py', 'designate/tests/test_api/test_service.py', 'designate/tests/test_central/test_service.py', 'designate/tests/test_api/test_v1/__init__.py']",11,f6a1ac01517090f57468ff9b37fe77af26da47c3,101632,, self.central_service = self.start_service('central') ,82,126
openstack%2Foslo-incubator~master~I957ab273ddc61b02763d6b60b21d11ed4e73d472,openstack/oslo-incubator,master,I957ab273ddc61b02763d6b60b21d11ed4e73d472,pep8: fixed multiple violations,MERGED,2014-06-20 21:22:22.000000000,2014-06-23 14:18:40.000000000,2014-06-23 14:18:40.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-06-20 21:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b7c06008df3f00956580e26f1ae77aa59f7e51e6', 'message': ""pep8: fixed multiple violations\n\nFixed violations:\n* E128 continuation line under-indented for visual indent\n* E251 unexpected spaces around keyword / parameter equals\n* E265 block comment should start with '# '\n* E713 test for membership should be 'not in'\n* F402 import shadowed by loop variable\n* H305  imports not grouped correctly\n* H307  like imports should be grouped together'\n* H402  one line docstring needs punctuation'\n* H703  Multiple positional placeholders\n\nAlso enabled H803 check that didn't have any violations.\n\nChange-Id: I957ab273ddc61b02763d6b60b21d11ed4e73d472\n""}, {'number': 2, 'created': '2014-06-20 21:34:26.000000000', 'files': ['openstack/common/versionutils.py', 'tests/unit/rpc/test_fake.py', 'openstack/common/apiclient/fake_client.py', 'openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'tests/unit/test_funcutils.py', 'tests/unit/rpc/test_kombu.py', 'openstack/common/fixture/mockpatch.py', 'tests/unit/middleware/test_notifier.py', 'openstack/common/apiclient/base.py', 'tests/testmods/i18n_opt.py', 'tests/unit/rpc/test_matchmaker_redis.py', 'openstack/common/fixture/moxstubout.py', 'openstack/common/test.py', 'openstack/common/db/sqlalchemy/session.py', 'tests/unit/db/sqlalchemy/test_options.py', 'tests/unit/rpc/common.py', 'openstack/common/quota.py', 'openstack/common/log.py', 'tests/unit/scheduler/test_host_filters.py', 'openstack/common/rpc/matchmaker.py', 'tests/unit/test_lockutils.py', 'tests/unit/test_xmlutils.py', 'openstack/common/db/sqlalchemy/migration_cli/manager.py', 'tests/unit/fixture/test_mockpatch.py', 'tests/unit/rpc/amqp.py', 'openstack/common/lockutils.py', 'tools/colorizer.py', 'openstack/common/middleware/sizelimit.py', 'tests/unit/apiclient/test_auth.py', 'tests/unit/rpc/test_common.py', 'tests/unit/rpc/test_qpid.py', 'openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'openstack/common/units.py', 'openstack/common/gettextutils.py', 'tests/unit/test_jsonutils.py', 'openstack/common/apiclient/exceptions.py', 'tests/unit/test_periodic.py', 'openstack/common/rpc/impl_zmq.py', 'tests/unit/test_log.py', 'tests/unit/rpc/test_kombu_ssl.py', 'tox.ini', 'openstack/common/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/de4adbc41419cfff9b154f463778da923f52cb6c', 'message': ""pep8: fixed multiple violations\n\nFixed violations:\n* E128 continuation line under-indented for visual indent\n* E251 unexpected spaces around keyword / parameter equals\n* E265 block comment should start with '# '\n* E713 test for membership should be 'not in'\n* F402 import shadowed by loop variable\n* H305  imports not grouped correctly\n* H307  like imports should be grouped together'\n* H402  one line docstring needs punctuation'\n* H703  Multiple positional placeholders\n\nAlso enabled H803 check that didn't have any violations.\n\nChange-Id: I957ab273ddc61b02763d6b60b21d11ed4e73d472\n""}]",0,101656,de4adbc41419cfff9b154f463778da923f52cb6c,14,4,2,9656,,,0,"pep8: fixed multiple violations

Fixed violations:
* E128 continuation line under-indented for visual indent
* E251 unexpected spaces around keyword / parameter equals
* E265 block comment should start with '# '
* E713 test for membership should be 'not in'
* F402 import shadowed by loop variable
* H305  imports not grouped correctly
* H307  like imports should be grouped together'
* H402  one line docstring needs punctuation'
* H703  Multiple positional placeholders

Also enabled H803 check that didn't have any violations.

Change-Id: I957ab273ddc61b02763d6b60b21d11ed4e73d472
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/56/101656/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/versionutils.py', 'tests/unit/rpc/test_fake.py', 'openstack/common/apiclient/fake_client.py', 'openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'tests/unit/test_funcutils.py', 'tests/unit/rpc/test_kombu.py', 'openstack/common/fixture/mockpatch.py', 'tests/unit/middleware/test_notifier.py', 'openstack/common/apiclient/base.py', 'tests/testmods/i18n_opt.py', 'tests/unit/rpc/test_matchmaker_redis.py', 'openstack/common/fixture/moxstubout.py', 'openstack/common/test.py', 'openstack/common/db/sqlalchemy/session.py', 'tests/unit/db/sqlalchemy/test_options.py', 'tests/unit/rpc/common.py', 'openstack/common/quota.py', 'openstack/common/log.py', 'tests/unit/scheduler/test_host_filters.py', 'openstack/common/rpc/matchmaker.py', 'tests/unit/test_lockutils.py', 'tests/unit/test_xmlutils.py', 'openstack/common/db/sqlalchemy/migration_cli/manager.py', 'tests/unit/fixture/test_mockpatch.py', 'tests/unit/rpc/amqp.py', 'openstack/common/lockutils.py', 'tools/colorizer.py', 'openstack/common/middleware/sizelimit.py', 'tests/unit/apiclient/test_auth.py', 'tests/unit/rpc/test_common.py', 'tests/unit/rpc/test_qpid.py', 'openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'openstack/common/units.py', 'openstack/common/gettextutils.py', 'tests/unit/test_jsonutils.py', 'openstack/common/apiclient/exceptions.py', 'tests/unit/test_periodic.py', 'openstack/common/rpc/impl_zmq.py', 'tests/unit/test_log.py', 'tests/unit/rpc/test_kombu_ssl.py', 'tox.ini', 'openstack/common/db/sqlalchemy/test_migrations.py']",42,b7c06008df3f00956580e26f1ae77aa59f7e51e6,more_pep8_checks," LOG.error(_LE(""Failed to migrate to version %(version)s "" ""on engine %(engine)s"") % {'version': version, 'engine': engine})"," LOG.error(_LE(""Failed to migrate to version %s on engine %s"") % (version, engine))",118,110
openstack%2Fsahara-image-elements~stable%2Ficehouse~I7a24244d98207856609b5f5ad62c4196f15d1399,openstack/sahara-image-elements,stable/icehouse,I7a24244d98207856609b5f5ad62c4196f15d1399,Use stable apache urls in spark elements,MERGED,2014-06-20 14:32:05.000000000,2014-06-23 14:14:33.000000000,2014-06-23 11:47:07.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7732}]","[{'number': 1, 'created': '2014-06-20 14:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/5434020df641e6e0ea2a139554f13ed0018822db', 'message': 'Use stable apache urls in spark elements\n\nBackport from master branch (https://review.openstack.org/#/c/96506/)\n\nChange-Id: I7a24244d98207856609b5f5ad62c4196f15d1399\n'}, {'number': 2, 'created': '2014-06-23 07:40:02.000000000', 'files': ['elements/spark/install.d/60-spark'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d18337c5424e71015c3d161b010eea93701c1361', 'message': 'Use stable apache urls in spark elements\n\nBackport from master branch (https://review.openstack.org/#/c/96506/)\n\nChange-Id: I7a24244d98207856609b5f5ad62c4196f15d1399\n'}]",0,101564,d18337c5424e71015c3d161b010eea93701c1361,18,4,2,7732,,,0,"Use stable apache urls in spark elements

Backport from master branch (https://review.openstack.org/#/c/96506/)

Change-Id: I7a24244d98207856609b5f5ad62c4196f15d1399
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/64/101564/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/spark/install.d/60-spark'],1,5434020df641e6e0ea2a139554f13ed0018822db,stable/icehouse," # INFO on hadoop versions: http://spark.apache.org/docs/latest/hadoop-third-party-distributions.html SPARK_DOWNLOAD_URL=""http://archive.apache.org/dist/spark/spark-$DIB_SPARK_VERSION/spark-$DIB_SPARK_VERSION-bin-$SPARK_HADOOP_DL.tgz"""," # INFO on hadoop versions: http://spark.incubator.apache.org/docs/latest/hadoop-third-party-distributions.html SPARK_DOWNLOAD_URL=""http://www.apache.org/dist/incubator/spark/spark-$DIB_SPARK_VERSION-incubating/spark-$DIB_SPARK_VERSION-incubating-bin-$SPARK_HADOOP_DL.tgz""",2,2
openstack%2Freviewstats~master~Ic7ab187c96ed47d365e1f1cdf115868b0abbe3e4,openstack/reviewstats,master,Ic7ab187c96ed47d365e1f1cdf115868b0abbe3e4,Add oomichi to nova-core,MERGED,2014-06-23 13:46:16.000000000,2014-06-23 14:08:40.000000000,2014-06-23 14:08:40.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2014-06-23 13:46:16.000000000', 'files': ['projects/nova.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/12efc41a701f58630a1b4a493ef3cdde608f1270', 'message': 'Add oomichi to nova-core\n\nChange-Id: Ic7ab187c96ed47d365e1f1cdf115868b0abbe3e4\n'}]",0,101914,12efc41a701f58630a1b4a493ef3cdde608f1270,7,2,1,1561,,,0,"Add oomichi to nova-core

Change-Id: Ic7ab187c96ed47d365e1f1cdf115868b0abbe3e4
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/14/101914/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/nova.json'],1,12efc41a701f58630a1b4a493ef3cdde608f1270,," ""oomichi"",",,1,0
openstack%2Ffuel-main~master~I4d3a73db9ae808f1e4cd566b84592eaebc1dd421,openstack/fuel-main,master,I4d3a73db9ae808f1e4cd566b84592eaebc1dd421,Fix yum config for some containers,MERGED,2014-06-23 09:20:01.000000000,2014-06-23 13:55:06.000000000,2014-06-23 13:55:06.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-06-23 09:20:01.000000000', 'files': ['docker/rsync/Dockerfile', 'docker/ostf/Dockerfile'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e86c2ccb890f259067d42f79941273a50df27a7b', 'message': 'Fix yum config for some containers\n\nCorrects issue where yum reconfig was missing\na semicolon, writing an incorrect yum repo.\n\nChange-Id: I4d3a73db9ae808f1e4cd566b84592eaebc1dd421\nCloses-Bug: #1333147\n'}]",0,101833,e86c2ccb890f259067d42f79941273a50df27a7b,13,7,1,7195,,,0,"Fix yum config for some containers

Corrects issue where yum reconfig was missing
a semicolon, writing an incorrect yum repo.

Change-Id: I4d3a73db9ae808f1e4cd566b84592eaebc1dd421
Closes-Bug: #1333147
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/101833/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/rsync/Dockerfile', 'docker/ostf/Dockerfile']",2,e86c2ccb890f259067d42f79941273a50df27a7b,bug/1333147,"RUN echo -e ""[nailgun]\nname=Nailgun Local Repo\nbaseurl=file:/var/www/nailgun/centos/fuelweb/x86_64\ngpgcheck=0"" > /etc/yum.repos.d/nailgun.repo; yum clean all; chmod +x /usr/local/bin/start.sh","RUN echo -e ""[nailgun]\nname=Nailgun Local Repo\nbaseurl=file:/var/www/nailgun/centos/fuelweb/x86_64\ngpgcheck=0"" > /etc/yum.repos.d/nailgun.repo yum clean all; chmod +x /usr/local/bin/start.sh",2,2
openstack%2Ftripleo-image-elements~master~Ib13b842b8c396a4d9bdd4743622420abe3b9b4ce,openstack/tripleo-image-elements,master,Ib13b842b8c396a4d9bdd4743622420abe3b9b4ce,Manage virtual ip with pacemaker,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-23 13:52:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1605}, {'_account_id': 7582}, {'_account_id': 8449}, {'_account_id': 8907}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': ['elements/pacemaker/README.md', 'elements/pacemaker/os-refresh-config/post-configure.d/17-virtual-ip'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/aa31551717f86028e3fec4c0d8e28a002e8e5106', 'message': 'Manage virtual ip with pacemaker\n\nEndpoints to openstack services should be configured to use\nvirtual ip, that will be used by haproxy to\nload balance requests to services\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: Ib13b842b8c396a4d9bdd4743622420abe3b9b4ce\n'}]",5,87873,aa31551717f86028e3fec4c0d8e28a002e8e5106,15,5,1,8907,,,0,"Manage virtual ip with pacemaker

Endpoints to openstack services should be configured to use
virtual ip, that will be used by haproxy to
load balance requests to services

Related to blueprint tripleo-icehouse-ha-production-configuration

Change-Id: Ib13b842b8c396a4d9bdd4743622420abe3b9b4ce
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/73/87873/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/pacemaker/README.md', 'elements/pacemaker/os-refresh-config/post-configure.d/17-virtual-ip']",2,aa31551717f86028e3fec4c0d8e28a002e8e5106,bp/tripleo-icehouse-ha-production-configuration,#!/bin/bash set -eu VIRTUAL_IP=$(os-apply-config --key virtual-ipv4 --type netaddress --key-default 0) if [ $VIRTUAL_IP != 0 ]; then crm configure primitive virtual-ip ocf:heartbeat:IPaddr params ip=$VIRTUAL_IP op monitor interval=10s fi ,,18,0
openstack%2Ftripleo-image-elements~master~Ibaadd51e6acd559e008b8aefabfc8df9877a94d7,openstack/tripleo-image-elements,master,Ibaadd51e6acd559e008b8aefabfc8df9877a94d7,Add haproxy stats to listen on 9000 port,ABANDONED,2014-05-14 15:23:53.000000000,2014-06-23 13:52:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7582}, {'_account_id': 8449}, {'_account_id': 8907}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-05-14 15:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cab876981a26e68f6e3e1684ff37b3eab46f284e', 'message': 'Add haproxy stats to listen on 9000 port\n\nHaproxy statistics very helps in debuging and troubleshooting\n\nAlso it enables addition of haproxy element to the cluster,\nso it can be tested with metadata on ci\n\nChange-Id: Ibaadd51e6acd559e008b8aefabfc8df9877a94d7\n'}, {'number': 2, 'created': '2014-05-15 08:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/18b7c659746aaae9bf0eafed05c4dfdd0052f6f1', 'message': 'Add haproxy stats to listen on 9000 port\n\nHaproxy statistics very helps in debuging and troubleshooting\n\nAlso it enables addition of haproxy element to the cluster,\nso it can be tested with metadata on ci\n\nChange-Id: Ibaadd51e6acd559e008b8aefabfc8df9877a94d7\n'}, {'number': 3, 'created': '2014-05-15 13:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/36be75d64933894cc75a9b3ae60f41e55cdfef26', 'message': 'Add haproxy stats to listen on 9000 port\n\nHaproxy statistics very helps in debuging and troubleshooting\n\nAlso it enables addition of haproxy element to the image,\nso it can be tested with metadata on ci\n\nChange-Id: Ibaadd51e6acd559e008b8aefabfc8df9877a94d7\n'}, {'number': 4, 'created': '2014-05-16 09:14:59.000000000', 'files': ['elements/haproxy/os-config-applier/etc/haproxy/haproxy.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fd06c586c2983d828b9a3857bc732fafc7cb66dd', 'message': 'Add haproxy stats to listen on 9000 port\n\nHaproxy statistics very helps in debuging and troubleshooting\n\ni think it is more reliable to add haproxy element to overcloud image\nbefore changes to tripleo-heat-templates will be merged, so we can test them on ci\n\nBut in order to do so, we need to provide haproxy with some configuration\n\nhaproxy fails to start with config : no <listen> line. Nothing to do !\n\n\nChange-Id: Ibaadd51e6acd559e008b8aefabfc8df9877a94d7\n'}]",5,93580,fd06c586c2983d828b9a3857bc732fafc7cb66dd,31,6,4,8907,,,0,"Add haproxy stats to listen on 9000 port

Haproxy statistics very helps in debuging and troubleshooting

i think it is more reliable to add haproxy element to overcloud image
before changes to tripleo-heat-templates will be merged, so we can test them on ci

But in order to do so, we need to provide haproxy with some configuration

haproxy fails to start with config : no <listen> line. Nothing to do !


Change-Id: Ibaadd51e6acd559e008b8aefabfc8df9877a94d7
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/80/93580/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/haproxy/os-config-applier/etc/haproxy/haproxy.cfg'],1,cab876981a26e68f6e3e1684ff37b3eab46f284e,haproxy_stats, log {{local-ip}} local0 stats socket /var/lib/haproxy/statslisten stats {{local-ip}}:9000 mode http stats enable stats uri /stats stats realm HAProxy\ Statistics stats auth admin:password ,,9,0
openstack%2Fpython-glanceclient~master~I251ce8c82c70ce7dbb674842980093f4bc48d5b1,openstack/python-glanceclient,master,I251ce8c82c70ce7dbb674842980093f4bc48d5b1,Fixes uri path in v2 images delete,ABANDONED,2014-06-23 12:28:51.000000000,2014-06-23 13:45:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-23 12:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/282510bd3304c295443ca0f99c669486ea28ac03', 'message': 'Fixes uri path in v2 images delete\n\nAdding missing / in front of the v2 on v2/images.py\n\nFixes Bug: #1333161\n\nChange-Id: I251ce8c82c70ce7dbb674842980093f4bc48d5b1\n'}, {'number': 2, 'created': '2014-06-23 12:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/74d2977e5781bb0e36f216e351cf5bb7ff9bac9b', 'message': 'Fixes uri path in v2 images delete\n\nAdding missing / in front of the v2 on v2/images.py\n\nFixes Bug: 1333161\n\nChange-Id: I251ce8c82c70ce7dbb674842980093f4bc48d5b1\n'}, {'number': 3, 'created': '2014-06-23 12:30:14.000000000', 'files': ['glanceclient/v2/images.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/6b6821c2ad9c928e8193474d4847d2d0197fed52', 'message': 'Fixes uri path in v2 images delete\n\nAdding missing / in front of the v2 on v2/images.py\nCloses bug #1333161\n\nChange-Id: I251ce8c82c70ce7dbb674842980093f4bc48d5b1\n'}]",0,101895,6b6821c2ad9c928e8193474d4847d2d0197fed52,10,3,3,5202,,,0,"Fixes uri path in v2 images delete

Adding missing / in front of the v2 on v2/images.py
Closes bug #1333161

Change-Id: I251ce8c82c70ce7dbb674842980093f4bc48d5b1
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/95/101895/3 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/v2/images.py'],1,282510bd3304c295443ca0f99c669486ea28ac03,master," self.http_client.json_request('DELETE', '/v2/images/%s' % image_id)"," self.http_client.json_request('DELETE', 'v2/images/%s' % image_id)",1,1
openstack%2Ffuel-web~master~I53dc938efef39ba7bd82deec6bc8bb2e48466530,openstack/fuel-web,master,I53dc938efef39ba7bd82deec6bc8bb2e48466530,Don't install package dependencies for flake8,MERGED,2014-06-20 14:02:59.000000000,2014-06-23 13:44:08.000000000,2014-06-23 13:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8053}, {'_account_id': 8749}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-20 14:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1bfcea60694e6d8beaa0b6316fed8f042dc4d73c', 'message': ""Don't install package dependencies for flake8\n\nChange-Id: I53dc938efef39ba7bd82deec6bc8bb2e48466530\n""}, {'number': 2, 'created': '2014-06-20 17:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/672df137cb229390fdbe18bd28e8a1cbac0611d5', 'message': ""Don't install package dependencies for flake8\n\nUse hacking==0.7.\n\nChange-Id: I53dc938efef39ba7bd82deec6bc8bb2e48466530\n""}, {'number': 3, 'created': '2014-06-20 20:05:51.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/tox.ini', 'shotgun/tox.ini', 'network_checker/tox.ini', 'fuel_upgrade_system/fuel_update_downloader/tox.ini', 'nailgun/tox.ini', 'fuelclient/tox.ini', 'fuelmenu/tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b7f0904c9c79239138a6bdff9fa605980321db89', 'message': ""Don't install package dependencies for flake8\n\nUse hacking==0.7.\n\nChange-Id: I53dc938efef39ba7bd82deec6bc8bb2e48466530\n""}]",0,101554,b7f0904c9c79239138a6bdff9fa605980321db89,31,5,3,9977,,,0,"Don't install package dependencies for flake8

Use hacking==0.7.

Change-Id: I53dc938efef39ba7bd82deec6bc8bb2e48466530
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/54/101554/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/tox.ini', 'shotgun/tox.ini', 'network_checker/tox.ini', 'fuel_upgrade_system/fuel_update_downloader/tox.ini', 'fuelclient/tox.ini', 'nailgun/tox.ini', 'fuelmenu/tox.ini']",7,1bfcea60694e6d8beaa0b6316fed8f042dc4d73c,tox_support,deps = flake8,,7,0
openstack%2Fdevstack~master~Idfa78e93abd80273dadcf37007a024bb6a783a48,openstack/devstack,master,Idfa78e93abd80273dadcf37007a024bb6a783a48,Use Keystone's default token format if not set,MERGED,2014-06-19 21:57:25.000000000,2014-06-23 13:43:30.000000000,2014-06-23 13:43:30.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 21:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1412e8ae15ff76f34d85e6138a7418f8bf6b0fd4', 'message': ""Use Keystone's default token format if not set\n\nDevstack was setting its own default for Keystone's token format, so when\nKeystone's default token format changed then devstack needed to be updated.\nWith this change, devstack will only override Keystone's token format if\nKEYSTONE_TOKEN_FORMAT is set explicitly. PKI setup is assumed to be needed\nunless the KEYSTONE_TOKEN_FORMAT is set to UUID.\n\nChange-Id: Idfa78e93abd80273dadcf37007a024bb6a783a48\n(cherry picked from commit 18644ceabed8248c4ae87a51dcda6a32a92bc51b)\n""}, {'number': 2, 'created': '2014-06-19 21:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8c4ed640bf1b4ecb9f0883dd2e9c0a573b1a1979', 'message': ""Use Keystone's default token format if not set\n\nDevstack was setting its own default for Keystone's token format, so\nwhen Keystone's default token format changed then devstack needed to\nbe updated. With this change, devstack will only override Keystone's\ntoken format if KEYSTONE_TOKEN_FORMAT is set explicitly. PKI setup\nis assumed to be needed unless the KEYSTONE_TOKEN_FORMAT is set to\nUUID.\n\nChange-Id: Idfa78e93abd80273dadcf37007a024bb6a783a48\n""}, {'number': 3, 'created': '2014-06-19 21:59:18.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e1fce856dfafe60c477a8ba956eaa9fa160c6c4', 'message': ""Use Keystone's default token format if not set\n\nDevstack was setting its own default for Keystone's token format, so\nwhen Keystone's default token format changed then devstack needed to\nbe updated. With this change, devstack will only override Keystone's\ntoken format if KEYSTONE_TOKEN_FORMAT is set explicitly. PKI setup\nis assumed to be needed unless the KEYSTONE_TOKEN_FORMAT is set to\nUUID.\n\nChange-Id: Idfa78e93abd80273dadcf37007a024bb6a783a48\n""}]",0,101347,1e1fce856dfafe60c477a8ba956eaa9fa160c6c4,24,7,3,6486,,,0,"Use Keystone's default token format if not set

Devstack was setting its own default for Keystone's token format, so
when Keystone's default token format changed then devstack needed to
be updated. With this change, devstack will only override Keystone's
token format if KEYSTONE_TOKEN_FORMAT is set explicitly. PKI setup
is assumed to be needed unless the KEYSTONE_TOKEN_FORMAT is set to
UUID.

Change-Id: Idfa78e93abd80273dadcf37007a024bb6a783a48
",git fetch https://review.opendev.org/openstack/devstack refs/changes/47/101347/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,1412e8ae15ff76f34d85e6138a7418f8bf6b0fd4,keystone_pkiz_provider,"KEYSTONE_TOKEN_FORMAT=$(echo ${KEYSTONE_TOKEN_FORMAT} | tr '[:upper:]' '[:lower:]') if [[ ""$KEYSTONE_TOKEN_FORMAT"" != """" ]]; then iniset $KEYSTONE_CONF token provider keystone.token.providers.$KEYSTONE_TOKEN_FORMAT.Provider if [[ ""$KEYSTONE_TOKEN_FORMAT"" != ""uuid"" ]]; then","KEYSTONE_TOKEN_FORMAT=${KEYSTONE_TOKEN_FORMAT:-PKIZ} if [[ ""$KEYSTONE_TOKEN_FORMAT"" = ""UUID"" ]]; then iniset $KEYSTONE_CONF token provider keystone.token.providers.uuid.Provider elif [[ ""$KEYSTONE_TOKEN_FORMAT"" = ""PKI"" ]]; then iniset $KEYSTONE_CONF token provider keystone.token.providers.pki.Provider if [[ ""$KEYSTONE_TOKEN_FORMAT"" == ""PKI"" || ""$KEYSTONE_TOKEN_FORMAT"" == ""PKIZ"" ]]; then",5,7
openstack%2Fdevstack~stable%2Ficehouse~I608847a34143b5c6a1708c180186dd88a32dd44b,openstack/devstack,stable/icehouse,I608847a34143b5c6a1708c180186dd88a32dd44b,Fix unsubstituted filename creation,MERGED,2014-06-20 14:15:07.000000000,2014-06-23 13:43:17.000000000,2014-06-23 13:43:16.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 9009}]","[{'number': 1, 'created': '2014-06-20 14:15:07.000000000', 'files': ['lib/config', 'tests/test_config.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e2738d365ad315f1a9439c618d0db6b854d86cd7', 'message': ""Fix unsubstituted filename creation\n\nSince merge_config_file() tries to create an unsubstituted config file,\nstack.sh fails due to permission denied in the file creation when you\nuse '[[post-config|/$Q_PLUGIN_CONF_FILE]]' and the file does not exist.\n\nThis patch deletes unnecessary 'touch' command, because the file will\nbe made by 'iniset' function in the next command line with evaled\nstring from 'configfile'.\n\nThis patch also fixes merge_config_group() to use evaled 'configfile'\nwhen it checks the directory of the config file exists.\n\nChange-Id: I608847a34143b5c6a1708c180186dd88a32dd44b\nCloses-bug: #1294213\n(cherry picked from commit 410f5c0016a9d3b1fbd42b95ce1402a1c614e3d3)\n""}]",0,101559,e2738d365ad315f1a9439c618d0db6b854d86cd7,10,3,1,1894,,,0,"Fix unsubstituted filename creation

Since merge_config_file() tries to create an unsubstituted config file,
stack.sh fails due to permission denied in the file creation when you
use '[[post-config|/$Q_PLUGIN_CONF_FILE]]' and the file does not exist.

This patch deletes unnecessary 'touch' command, because the file will
be made by 'iniset' function in the next command line with evaled
string from 'configfile'.

This patch also fixes merge_config_group() to use evaled 'configfile'
when it checks the directory of the config file exists.

Change-Id: I608847a34143b5c6a1708c180186dd88a32dd44b
Closes-bug: #1294213
(cherry picked from commit 410f5c0016a9d3b1fbd42b95ce1402a1c614e3d3)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/59/101559/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/config', 'tests/test_config.sh']",2,e2738d365ad315f1a9439c618d0db6b854d86cd7,,"function setup_test4 { mkdir -p test-etc cat >test-etc/test4.conf <<EOF [fff] # original comment type=original EOF TEST4_DIR=""test-etc"" TEST4_FILE=""test4.conf"" } [[test4|\$TEST4_DIR/\$TEST4_FILE]] [fff] type=new EOFecho -n ""merge_config_group test4 variable filename: "" setup_test4 merge_config_group test.conf test4 VAL=$(cat test-etc/test4.conf) EXPECT_VAL=""[fff] # original comment type=new"" check_result ""$VAL"" ""$EXPECT_VAL"" echo -n ""merge_config_group test4 variable filename (not exist): "" setup_test4 rm test-etc/test4.conf merge_config_group test.conf test4 VAL=$(cat test-etc/test4.conf) EXPECT_VAL="" [fff] type = new"" check_result ""$VAL"" ""$EXPECT_VAL"" rm -rf test-etc",EOF ,36,4
openstack%2Fheat~master~I7bd7657031e00d2db9376dbf587253a3b3be5a9d,openstack/heat,master,I7bd7657031e00d2db9376dbf587253a3b3be5a9d,Remove heat_keystoneclient roles filtering workaround,MERGED,2014-06-19 09:29:42.000000000,2014-06-23 13:43:10.000000000,2014-06-23 13:43:09.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-06-19 09:29:42.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/52e2204c88473f67b723f0808caf2308474cd9c8', 'message': 'Remove heat_keystoneclient roles filtering workaround\n\nThe currently required version of keystoneclient contains the logic\nto filter by name so remove the interim workaround\n\nChange-Id: I7bd7657031e00d2db9376dbf587253a3b3be5a9d\n'}]",0,101145,52e2204c88473f67b723f0808caf2308474cd9c8,16,4,1,4328,,,0,"Remove heat_keystoneclient roles filtering workaround

The currently required version of keystoneclient contains the logic
to filter by name so remove the interim workaround

Change-Id: I7bd7657031e00d2db9376dbf587253a3b3be5a9d
",git fetch https://review.opendev.org/openstack/heat refs/changes/45/101145/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,52e2204c88473f67b723f0808caf2308474cd9c8,hkc_roles_filter, self.mock_ks_v3_client.roles.list( name='heat_stack_user').AndReturn(self._mock_roles_list()) self.mock_ks_v3_client.roles.list( name='heat_stack_user').AndReturn([]) mock_role = self.m.CreateMockAnything() mock_role.id = '4546' mock_role.name = heat_stack_user mock_roles_list.append(mock_role) self.mock_admin_client.roles.list( name='heat_stack_user').AndReturn(self._mock_roles_list()) self.mock_ks_v3_client.roles.list( name='heat_stack_user').AndReturn(self._mock_roles_list()) self.mock_admin_client.roles.list(name='heat_stack_user').AndReturn([])," self.mock_ks_v3_client.roles.list().AndReturn(self._mock_roles_list()) mock_roles_list = self._mock_roles_list(heat_stack_user='badrole') self.mock_ks_v3_client.roles.list().AndReturn(mock_roles_list) for r_id, r_name in (('1234', 'blah'), ('4546', heat_stack_user)): mock_role = self.m.CreateMockAnything() mock_role.id = r_id mock_role.name = r_name mock_roles_list.append(mock_role) self.mock_admin_client.roles.list().AndReturn(self._mock_roles_list()) self.mock_ks_v3_client.roles.list().AndReturn(self._mock_roles_list()) mock_roles_list = self._mock_roles_list(heat_stack_user='badrole') self.mock_admin_client.roles.list().AndReturn(mock_roles_list)",21,28
openstack%2Fheat~master~Iac5c2f8105dc88af5cae6937a68e1422694afe24,openstack/heat,master,Iac5c2f8105dc88af5cae6937a68e1422694afe24,Remove unused generate_request_id,MERGED,2014-06-12 07:00:13.000000000,2014-06-23 13:43:02.000000000,2014-06-23 13:43:02.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7236}, {'_account_id': 7239}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8435}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-12 07:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/87e0e21d5366b7ac12f176284de7cf579b8c6ee4', 'message': 'Remove unused generate_request_id\n\nThe heat.common.context module has an unused function to generate\nthe request id, this is now handled by the underlying oslo module\nso can now be removed.\n\nChange-Id: Iac5c2f8105dc88af5cae6937a68e1422694afe24\n'}, {'number': 2, 'created': '2014-06-23 11:23:05.000000000', 'files': ['heat/common/context.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b18c419f649be2c3c96b27ef739f44a19504f5fc', 'message': 'Remove unused generate_request_id\n\nThe heat.common.context module has an unused function to generate\nthe request id, this is now handled by the underlying oslo module\nso can now be removed.\n\nChange-Id: Iac5c2f8105dc88af5cae6937a68e1422694afe24\n'}]",0,99583,b18c419f649be2c3c96b27ef739f44a19504f5fc,28,11,2,4328,,,0,"Remove unused generate_request_id

The heat.common.context module has an unused function to generate
the request id, this is now handled by the underlying oslo module
so can now be removed.

Change-Id: Iac5c2f8105dc88af5cae6937a68e1422694afe24
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/99583/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/context.py'],1,87e0e21d5366b7ac12f176284de7cf579b8c6ee4,unused_reqid,,import uuid def generate_request_id(): return 'req-' + str(uuid.uuid4()) ,0,6
openstack%2Fdevstack~master~Ide5f7d980a294c7a9f8a3decaed0939f1c239934,openstack/devstack,master,Ide5f7d980a294c7a9f8a3decaed0939f1c239934,Move static docs into master branch,MERGED,2014-06-20 23:05:20.000000000,2014-06-23 13:42:55.000000000,2014-06-23 13:42:55.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 23:05:20.000000000', 'files': ['docs/source/plugins.html', 'docs/source/openrc.html', '.gitignore', 'docs/source/assets/images/header_bg.png', 'docs/source/contributing.html', 'docs/source/index.html', 'docs/source/assets/images/logo.png', 'docs/source/assets/images/devstack.png', 'docs/source/assets/js/jquery-1.7.1.min.js', 'docs/source/assets/css/bootstrap.css', 'docs/source/local.conf.html', 'docs/source/guides/single-vm.html', 'docs/source/assets/js/bootstrap.js', 'docs/source/guides/usb-boot.html', 'docs/source/guides/single-machine.html', 'docs/source/assets/css/local.css', 'docs/source/changes.html', 'docs/source/assets/images/small_logo.png', 'docs/source/guides/multinode-lab.html', 'docs/source/assets/js/bootstrap.min.js', 'docs/source/guides/pxe-boot.html', 'docs/source/assets/images/quickstart.png', 'docs/source/exerciserc.html', 'docs/source/faq.html', 'docs/source/guides/ramdisk.html', 'docs/source/stackrc.html', 'docs/source/configuration.html', 'docs/source/localrc.html', 'docs/source/eucarc.html', 'docs/source/overview.html', 'tools/build_docs.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/54b973233904f8870bf2d4dc6a5dfedb031531fb', 'message': 'Move static docs into master branch\n\nThe hand-maintained static HTML docs for DevStack have been in a\nGitHub gh-pages branch; move them into the master branch in\npreparation for hosting them in openstack.org infrastructure.\n\nBy default tools/build_docs.sh now builds the static HTML output\ninto docs/html.\n\nChange-Id: Ide5f7d980a294c7a9f8a3decaed0939f1c239934\n'}]",0,101668,54b973233904f8870bf2d4dc6a5dfedb031531fb,10,3,1,970,,,0,"Move static docs into master branch

The hand-maintained static HTML docs for DevStack have been in a
GitHub gh-pages branch; move them into the master branch in
preparation for hosting them in openstack.org infrastructure.

By default tools/build_docs.sh now builds the static HTML output
into docs/html.

Change-Id: Ide5f7d980a294c7a9f8a3decaed0939f1c239934
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/101668/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/source/plugins.html', 'docs/source/openrc.html', '.gitignore', 'docs/source/assets/images/header_bg.png', 'docs/source/contributing.html', 'docs/source/index.html', 'docs/source/assets/images/logo.png', 'docs/source/assets/images/devstack.png', 'docs/source/assets/js/jquery-1.7.1.min.js', 'docs/source/assets/css/bootstrap.css', 'docs/source/local.conf.html', 'docs/source/guides/single-vm.html', 'docs/source/assets/js/bootstrap.js', 'docs/source/guides/usb-boot.html', 'docs/source/guides/single-machine.html', 'docs/source/assets/css/local.css', 'docs/source/changes.html', 'docs/source/assets/images/small_logo.png', 'docs/source/guides/multinode-lab.html', 'docs/source/assets/js/bootstrap.min.js', 'docs/source/guides/pxe-boot.html', 'docs/source/assets/images/quickstart.png', 'docs/source/exerciserc.html', 'docs/source/faq.html', 'docs/source/guides/ramdisk.html', 'docs/source/stackrc.html', 'docs/source/configuration.html', 'docs/source/localrc.html', 'docs/source/eucarc.html', 'docs/source/overview.html', 'tools/build_docs.sh']",31,54b973233904f8870bf2d4dc6a5dfedb031531fb,move-docs-into-repo,"# - Install shocco if not found on PATH and INSTALL_SHOCCO is set# - Re-creates ``docs/html`` directory from existing repo + new generated script docs## build_docs.sh [-o <out-dir>] [-g] [master|<repo> [<branch>]] ## <repo> The DevStack repository to clone (default is DevStack github repo)## <branch> The DevStack branch to check out (default is master; ignored if ## repo is not specified)## -o <out-dir> Write the static HTML output to <out-dir> ## (Note that <out-dir> will be deleted and re-created to ensure it is clean) ## -g Update the old gh-pages repo (set PUSH=1 to actualy push up to RCB)DOCS_SOURCE=docs/source HTML_BUILD=docs/html make || exitwhile getopts go: c; do g) GH_UPDATE=1 o) HTML_BUILD=$OPTARG if [[ -n ""$1"" ]]; then master=""master"" if [[ ""${master/#$1}"" != ""master"" ]]; then # Partial match on ""master"" REPO_BRANCH=${2:-$MASTER_BRANCH} TMP_ROOT=$(mktemp -d work-docs-XXXX) if [[ -n ""$REPO_BRANCH"" ]]; then git checkout $REPO_BRANCH fi# Assumption is we are now in the DevStack workspace to be processed # Clean up build dir rm -rf $HTML_BUILD mkdir -p $HTML_BUILD # Get fully qualified dirs FQ_DOCS_SOURCE=$(cd $DOCS_SOURCE && pwd) FQ_HTML_BUILD=$(cd $HTML_BUILD && pwd) # Get repo static cp -pr $FQ_DOCS_SOURCE/* $FQ_HTML_BUILD mkdir -p $FQ_HTML_BUILD/`dirname $f`; $SHOCCO $f > $FQ_HTML_BUILD/$f.htmlfor f in $(find functions functions-common lib samples -type f -name \*); do mkdir -p $FQ_HTML_BUILD/`dirname $f`; $SHOCCO $f > $FQ_HTML_BUILD/$f.htmlecho ""$FILES"" >docs/files if [[ -n $GH_UPDATE ]]; then GH_ROOT=$(mktemp -d work-gh-XXXX) cd $GH_ROOT # Pull the latest docs branch from devstack.org repo git clone -b gh-pages $GH_PAGES_REPO gh-docs # Get the generated files cp -pr $FQ_HTML_BUILD/* gh-docs # Collect the new generated pages (cd gh-docs; find . -name \*.html -print0 | xargs -0 git add) # Push our changes back up to the docs branch if ! git diff-index HEAD --quiet; then git commit -a -m ""Update script docs"" if [[ -n $PUSH ]]; then git push fi echo rm -rf $TMP_ROOT echo ""Built docs in $HTML_BUILD""","# - Install shocco if not found on PATH# - Re-creates ``docs`` directory from existing repo + new generated script docs## build_docs.sh [[-b branch] [-p] repo] | . ## -b branch The DevStack branch to check out (default is master; ignored if ## repo is not specified) ## -p Push the resulting docs tree to the source repo; fatal error if ## repo is not specified ## repo The DevStack repository to clone (default is DevStack github repo) makewhile getopts b:p c; do b) MASTER_BRANCH=$OPTARG p) PUSH_REPO=1# Sanity check the args if [[ ""$1"" == ""."" ]]; then REPO="""" if [[ -n $PUSH_REPO ]]; then echo ""Push not allowed from an active workspace"" unset PUSH_REPO fi else if [[ -z ""$1"" ]]; then TMP_ROOT=$(mktemp -d devstack-docs-XXXX) git checkout $MASTER_BRANCH# Assumption is we are now in the DevStack repo workspace to be processed # Pull the latest docs branch from devstack.org repo if ! [ -d docs ]; then git clone -b gh-pages $GH_PAGES_REPO docs fi mkdir -p docs/`dirname $f`; $SHOCCO $f > docs/$f.htmlfor f in $(find functions lib samples -type f -name \*); do mkdir -p docs/`dirname $f`; $SHOCCO $f > docs/$f.htmlecho ""$FILES"" >docs-files # Switch to the gh_pages repo cd docs # Collect the new generated pages find . -name \*.html -print0 | xargs -0 git add # Push our changes back up to the docs branch if ! git diff-index HEAD --quiet; then git commit -a -m ""Update script docs"" if [[ -n $PUSH ]]; then git push rm -rf $TMP_ROOT echo ""Built docs in $TMP_ROOT""",5822,58
openstack%2Fheat~master~Ia7c04a8edb55fb5e2ef27a10da72804d4af75991,openstack/heat,master,Ia7c04a8edb55fb5e2ef27a10da72804d4af75991,Hide deprecate warnings for metadata tests,MERGED,2014-06-18 09:22:26.000000000,2014-06-23 13:42:48.000000000,2014-06-23 13:42:48.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 10018}]","[{'number': 1, 'created': '2014-06-18 09:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b09d17b5e88c34b7484a00efd77bd1e7d3f82b2', 'message': 'Remove redundant assert for metadata\n\nattribute metadata is deprecated, testing it in MetadataTest\nis enough, testing it everywhere is redundant.\n\nthis patch removes the redundant assert, and hides the deprecate\nwarning.\n\nChange-Id: Ia7c04a8edb55fb5e2ef27a10da72804d4af75991\n'}, {'number': 2, 'created': '2014-06-19 07:11:06.000000000', 'files': ['heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4a33879c7fc687738b243d122bc32c025293329a', 'message': 'Hide deprecate warnings for metadata tests\n\nattribute metadata is deprecated, the deprecate\nwarnings in tests should be hidden\n\nChange-Id: Ia7c04a8edb55fb5e2ef27a10da72804d4af75991\n'}]",3,100830,4a33879c7fc687738b243d122bc32c025293329a,23,6,2,10018,,,0,"Hide deprecate warnings for metadata tests

attribute metadata is deprecated, the deprecate
warnings in tests should be hidden

Change-Id: Ia7c04a8edb55fb5e2ef27a10da72804d4af75991
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/100830/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_resource.py'],1,8b09d17b5e88c34b7484a00efd77bd1e7d3f82b2,redundant-assert," with mock.patch('heat.engine.resource.warnings'): self.assertEqual({'Test': 'Initial metadata'}, self.res.metadata_get()) self.assertEqual({'Test': 'Initial metadata'}, self.res.metadata) with mock.patch('heat.engine.resource.warnings'): test_data = {'Test': 'Newly-written data'} self.res.metadata_set(test_data) self.assertEqual(test_data, self.res.metadata_get()) self.assertEqual(test_data, self.res.metadata) with mock.patch('heat.engine.resource.warnings'): test_data = {'Test': 'Newly-written data'} self.res.metadata = test_data self.assertEqual(test_data, self.res.metadata_get()) self.assertEqual(test_data, self.res.metadata)"," self.assertEqual({}, res.metadata) self.assertEqual({}, res.metadata) self.assertEqual({""os_distro"": ""test-distro""}, res.metadata) self.assertEqual({'Test': 'Initial metadata'}, self.res.metadata_get()) self.assertEqual({'Test': 'Initial metadata'}, self.res.metadata) test_data = {'Test': 'Newly-written data'} self.res.metadata_set(test_data) self.assertEqual(test_data, self.res.metadata_get()) test_data = {'Test': 'Newly-written data'} self.res.metadata = test_data self.assertEqual(test_data, self.res.metadata_get()) self.assertEqual(test_data, self.res.metadata)",14,12
openstack%2Fironic~master~I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5,openstack/ironic,master,I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5,PXE to pass hints to ImageCache on how much space to reclaim,MERGED,2014-05-20 13:50:25.000000000,2014-06-23 13:41:32.000000000,2014-06-23 13:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-05-20 13:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/65215751c61c8d871c08a48ac472049205f1532e', 'message': ""PXE to pass hints to ImageCache on how much space is required to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to ImageCache,\nso that it tries to reclaim exactly required amount of disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 2, 'created': '2014-05-20 13:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/370cfdb85680abd1008e226cca07d0f90bd875e5', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 3, 'created': '2014-05-20 13:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d60e01ae3e99129558c6b461616cc56800696fdf', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 4, 'created': '2014-05-20 14:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a95f5835f734000d2a1d50816560305aba7b934e', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 5, 'created': '2014-05-20 16:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7100ce6766783d0c20462645865e1ab8b35c2f69', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 6, 'created': '2014-05-21 17:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b6a4d7b87e810a4614c6745658427fce9d227eb4', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 7, 'created': '2014-05-28 09:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c7aabcb371f015cd7b4440a1127a18e32890a327', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nNote that this amount is calculated as total size of images multiplied\nby two as an attempt to account for images converting to war format.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 8, 'created': '2014-05-30 15:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1cd6ddcf9e9d1e66947fc5e4861542a54bdd580e', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nNote that this amount is calculated as total size of images multiplied\nby two as an attempt to account for images converting to raw format.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}, {'number': 9, 'created': '2014-06-23 12:09:58.000000000', 'files': ['ironic/drivers/modules/image_cache.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_image_cache.py', 'ironic/tests/drivers/test_pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/581ffa98d2fe56e2919b06f2caec3043fd745339', 'message': ""PXE to pass hints to ImageCache on how much space to reclaim\n\nAfter previous patch PXE triggers cache clean up, if there's not enough\ndisk space for deployment. However, standard clean up may reclaim too\nlittle space, due to configuration. This patch implements hints to\nImageCache, so that it tries to reclaim exactly required amount\nof disk space.\n\nNote that this amount is calculated as total size of images multiplied\nby two as an attempt to account for images converting to raw format.\n\nChange-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5\nCloses-Bug: #1316168\n""}]",18,94371,581ffa98d2fe56e2919b06f2caec3043fd745339,79,11,9,10239,,,0,"PXE to pass hints to ImageCache on how much space to reclaim

After previous patch PXE triggers cache clean up, if there's not enough
disk space for deployment. However, standard clean up may reclaim too
little space, due to configuration. This patch implements hints to
ImageCache, so that it tries to reclaim exactly required amount
of disk space.

Note that this amount is calculated as total size of images multiplied
by two as an attempt to account for images converting to raw format.

Change-Id: I8f95b7e6334a37e9e6e98278a5b61a9ace7221b5
Closes-Bug: #1316168
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/94371/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/image_cache.py', 'ironic/tests/drivers/test_image_cache.py']",2,65215751c61c8d871c08a48ac472049205f1532e,bug/1316168," mock_clean_size.assert_called_once_with(mock.ANY, None) def test_clean_up_old_with_amount(self, mock_clean_size): files = [os.path.join(self.master_dir, str(i)) for i in range(2)] for filename in files: open(filename, 'wb').write('X') new_current_time = time.time() + 900 with mock.patch.object(time, 'time', lambda: new_current_time): self.cache.clean_up(amount=1) self.assertFalse(mock_clean_size.called) # Exactly one file is expected to be deleted self.assertTrue(any(os.path.exists(f) for f in files)) self.assertFalse(all(os.path.exists(f) for f in files)) @mock.patch.object(image_cache.ImageCache, '_clean_up_ensure_cache_size') mock_clean_size.assert_called_once_with([], None) mock_clean_ttl.side_effect = lambda *xx: xx mock_clean_ttl.assert_called_once_with(mock.ANY, None) @mock.patch.object(image_cache.ImageCache, '_clean_up_too_old') def test_clean_up_ensure_cache_size_with_amount(self, mock_clean_ttl): mock_clean_ttl.side_effect = lambda *xx: xx # NOTE(dtantsur): Cache size in test is 10 bytes, we create 6 files # with 3 bytes each and set amount to be 15, 5 files are to be deleted files = [os.path.join(self.master_dir, str(i)) for i in range(6)] for filename in files: with open(filename, 'w') as fp: fp.write('123') # NOTE(dtantsur): Make 1 file 'newer' to check that # old ones are deleted first new_current_time = time.time() + 100 os.utime(files[0], (new_current_time, new_current_time)) with mock.patch.object(time, 'time', lambda: new_current_time): self.cache.clean_up(amount=15) self.assertTrue(os.path.exists(files[0])) for filename in files[5:]: self.assertFalse(os.path.exists(filename)) mock_clean_ttl.assert_called_once_with(mock.ANY, 15) mock_clean_ttl.side_effect = lambda *xx: xx mock_clean_ttl.assert_called_once_with(mock.ANY, None) @mock.patch.object(image_cache.LOG, 'warn') @mock.patch.object(image_cache.ImageCache, '_clean_up_too_old') @mock.patch.object(image_cache.ImageCache, '_clean_up_ensure_cache_size') def test_clean_up_amount_not_satisfied(self, mock_clean_size, mock_clean_ttl, mock_log): mock_clean_ttl.side_effect = lambda *xx: xx mock_clean_size.side_effect = lambda listing, amount: amount self.cache.clean_up(amount=15) self.assertTrue(mock_log.called)", mock_clean_size.assert_called_once_with([]) mock_clean_ttl.side_effect = lambda listing: listing mock_clean_ttl.side_effect = lambda listing: listing,97,13
openstack%2Fmurano-deployment~master~Ifbd6198d0bc1783d910d3abe6915448edb9b140b,openstack/murano-deployment,master,Ifbd6198d0bc1783d910d3abe6915448edb9b140b,fix db-sync calling in configure_api script,MERGED,2014-06-23 13:15:10.000000000,2014-06-23 13:19:33.000000000,2014-06-23 13:19:33.000000000,"[{'_account_id': 3}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-06-23 13:15:10.000000000', 'files': ['murano-ci/infra/configure_api.sh'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/0f59e959585cd51ff756496c3bc5d778fbac2dc5', 'message': 'fix db-sync calling in configure_api script\n\n- fixed db-sync calling in configure_api script due to command renaming\n\nChange-Id: Ifbd6198d0bc1783d910d3abe6915448edb9b140b\n'}]",0,101909,0f59e959585cd51ff756496c3bc5d778fbac2dc5,7,2,1,7604,,,0,"fix db-sync calling in configure_api script

- fixed db-sync calling in configure_api script due to command renaming

Change-Id: Ifbd6198d0bc1783d910d3abe6915448edb9b140b
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/09/101909/1 && git format-patch -1 --stdout FETCH_HEAD,['murano-ci/infra/configure_api.sh'],1,0f59e959585cd51ff756496c3bc5d778fbac2dc5,master,"MANAGE_DB_CMD=$(which murano-db-manage) su -c ""$MANAGE_DB_CMD --config-file $DAEMON_CONF upgrade"" -s /bin/bash $DAEMON_USER echo ""\""$MANAGE_DB_CMD --config-file $DAEMON_CONF upgrade\"" fails!"""," su -c ""$MANAGE_CMD --config-file $DAEMON_CONF db-sync"" -s /bin/bash $DAEMON_USER echo ""\""$MANAGE_CMD --config-file $DAEMON_CONF db-sync\"" fails!""",3,2
openstack%2Fdesignate~master~I948a42b7f3dbc1d484200e86b3f8d0b85769ad08,openstack/designate,master,I948a42b7f3dbc1d484200e86b3f8d0b85769ad08,Switch to oslo.db and fix cmd.manage,MERGED,2014-06-05 14:28:13.000000000,2014-06-23 13:14:03.000000000,2014-06-23 13:14:03.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 7491}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-06-05 14:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/7bf2830ecedc39c5a9360bbf71f97e8bd2c471a8', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 2, 'created': '2014-06-18 18:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/6d893e567a75547dff5d6eb99dfc0e01bd911f49', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 3, 'created': '2014-06-19 09:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c6df2e50504f6fe207ad659894ae0527424b7438', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 4, 'created': '2014-06-19 12:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bfcec63138d914d59fe01162233954c0eb8cc21b', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 5, 'created': '2014-06-19 12:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5d69236d2f5af90eff74344b5206e9ef186f3233', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 6, 'created': '2014-06-19 13:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/84669f836b1656bdc75d4e3d26931777f9e0616d', 'message': ""Switch to oslo.db\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 7, 'created': '2014-06-19 18:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/541fd77e73faff40a67417c6277c619fe42e8966', 'message': ""Switch to oslo.db and fix cmd.manage\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nAlso fixes problems with arguments in cmd.manage\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 8, 'created': '2014-06-19 21:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5a650887f1b64ac7be50f734801eb18c72ff2f6b', 'message': ""Switch to oslo.db and fix cmd.manage\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nAlso fixes problems with arguments in cmd.manage\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 9, 'created': '2014-06-19 22:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/7008cae5e226ad1929fa6b6ee4ee09f76635ef1f', 'message': ""Switch to oslo.db and fix cmd.manage\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nAlso fixes problems with arguments in cmd.manage\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}, {'number': 10, 'created': '2014-06-20 13:28:04.000000000', 'files': ['designate/openstack/common/db/sqlalchemy/test_base.py', 'designate/tests/__init__.py', 'designate/openstack/common/db/sqlalchemy/models.py', 'designate/tests/test_backend/test_powerdns.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/manage/powerdns.py', 'designate/openstack/common/db/__init__.py', 'designate/manage/database.py', 'designate/openstack/common/db/sqlalchemy/migration.py', 'doc/source/install/ubuntu.rst', 'requirements.txt', 'doc/source/examples/basic-config-sample.conf', 'designate/openstack/common/db/sqlalchemy/session.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'doc/source/examples/config-mysql-pdns.conf', 'openstack-common.conf', 'designate/openstack/common/db/sqlalchemy/provision.py', 'designate/openstack/common/db/sqlalchemy/utils.py', 'designate/sqlalchemy/session.py', 'doc/source/backends/powerdns.rst', 'doc/source/configuration.rst', 'designate/sqlalchemy/models.py', 'etc/designate/designate.conf.sample', 'designate/openstack/common/db/exception.py', 'contrib/devstack/lib/designate_plugins/backend-powerdns', 'designate/openstack/common/db/sqlalchemy/__init__.py', 'designate/storage/impl_sqlalchemy/models.py', 'designate/openstack/common/db/sqlalchemy/test_migrations.py', 'doc/source/getting-started.rst', 'contrib/devstack/lib/designate', 'designate/cmd/manage.py', 'designate/openstack/common/db/api.py', 'designate/openstack/common/db/options.py', 'designate/backend/impl_powerdns/models.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/9d5d70e7f16d4ec344d5663a0e38d278cd543ef3', 'message': ""Switch to oslo.db and fix cmd.manage\n\nThis change doesn't remove all of the d.sqla.* modules for compat so we don't\nneed to change more things then needed. Things like multiple engines etc are\nsupported via a _FACADE dict in d.sqla.session and other things we need as\nwell.\n\nWe remove d.o.common.db code since it is not needed anymore and technically\nreplaced by oslo.db.\n\nNotably the *biggest* change is changing database_connection to connection.\n\nAlso fixes problems with arguments in cmd.manage\n\nChange-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08\n""}]",15,98122,9d5d70e7f16d4ec344d5663a0e38d278cd543ef3,57,5,10,395,,,0,"Switch to oslo.db and fix cmd.manage

This change doesn't remove all of the d.sqla.* modules for compat so we don't
need to change more things then needed. Things like multiple engines etc are
supported via a _FACADE dict in d.sqla.session and other things we need as
well.

We remove d.o.common.db code since it is not needed anymore and technically
replaced by oslo.db.

Notably the *biggest* change is changing database_connection to connection.

Also fixes problems with arguments in cmd.manage

Change-Id: I948a42b7f3dbc1d484200e86b3f8d0b85769ad08
",git fetch https://review.opendev.org/openstack/designate refs/changes/22/98122/5 && git format-patch -1 --stdout FETCH_HEAD,"['designate/openstack/common/db/sqlalchemy/test_base.py', 'designate/tests/__init__.py', 'designate/openstack/common/db/sqlalchemy/models.py', 'designate/tests/test_backend/test_powerdns.py', 'designate/backend/impl_powerdns/__init__.py', 'designate/manage/powerdns.py', 'designate/openstack/common/db/__init__.py', 'designate/manage/database.py', 'designate/openstack/common/db/sqlalchemy/migration.py', 'requirements.txt', 'doc/source/examples/basic-config-sample.conf', 'designate/openstack/common/db/sqlalchemy/session.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'doc/source/examples/config-mysql-pdns.conf', 'openstack-common.conf', 'designate/openstack/common/db/sqlalchemy/provision.py', 'designate/openstack/common/db/sqlalchemy/utils.py', 'designate/sqlalchemy/session.py', 'doc/source/backends/powerdns.rst', 'doc/source/configuration.rst', 'designate/sqlalchemy/models.py', 'etc/designate/designate.conf.sample', 'designate/openstack/common/db/exception.py', 'designate/openstack/common/db/sqlalchemy/__init__.py', 'designate/storage/impl_sqlalchemy/models.py', 'designate/openstack/common/db/sqlalchemy/test_migrations.py', 'contrib/devstack/lib/designate', 'designate/openstack/common/db/api.py', 'designate/openstack/common/db/options.py', 'designate/backend/impl_powerdns/models.py']",30,7bf2830ecedc39c5a9360bbf71f97e8bd2c471a8,oslo.db,from designate.sqlalchemy import modelsclass Base(models.Base):,from designate.sqlalchemy.models import Base as CommonBaseclass Base(CommonBase):,78,3229
openstack%2Fneutron~master~Iff957b0ed18a92c79a6dcb7098f416eae1e2e5b6,openstack/neutron,master,Iff957b0ed18a92c79a6dcb7098f416eae1e2e5b6,VMWare: optimize disassociate_floatingips() db operations,ABANDONED,2014-06-19 14:29:32.000000000,2014-06-23 12:55:35.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-19 14:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee0edc7b1998422cb487f692c1662d7eb8a0de4f', 'message': 'VMWare: optimize disassociate_floatingips() db operations\n\nPreviously, the method fetched floating IPs from db, then called to\nsuper() which also fetched them again and returned. Instead of fetching\nfloating IPs in VMWare plugin, reuse the set of routers returned from\nsuper().\n\nRelated-Bug: 1330955\nChange-Id: Iff957b0ed18a92c79a6dcb7098f416eae1e2e5b6\n'}, {'number': 2, 'created': '2014-06-20 15:10:12.000000000', 'files': ['neutron/plugins/vmware/plugins/base.py', 'neutron/plugins/vmware/plugins/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf25dd20ffe6f7e08273db95e74a12e7d68a15f2', 'message': 'VMWare: optimize disassociate_floatingips() db operations\n\nPreviously, the method fetched floating IPs from db, then called to\nsuper() which also fetched them again and returned. Instead of fetching\nfloating IPs in VMWare plugin, reuse the set of routers returned from\nsuper().\n\nRelated-Bug: 1330955\nChange-Id: Iff957b0ed18a92c79a6dcb7098f416eae1e2e5b6\n'}]",0,101218,cf25dd20ffe6f7e08273db95e74a12e7d68a15f2,34,16,2,9656,,,0,"VMWare: optimize disassociate_floatingips() db operations

Previously, the method fetched floating IPs from db, then called to
super() which also fetched them again and returned. Instead of fetching
floating IPs in VMWare plugin, reuse the set of routers returned from
super().

Related-Bug: 1330955
Change-Id: Iff957b0ed18a92c79a6dcb7098f416eae1e2e5b6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/101218/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/vmware/plugins/base.py', 'neutron/plugins/vmware/plugins/service.py']",2,ee0edc7b1998422cb487f692c1662d7eb8a0de4f,bug/1330955," routers = super(NsxAdvancedPlugin, self).disassociate_floatingips( context, port_id)"," routers = set() try: fip_qry = context.session.query(l3_db.FloatingIP) fip_dbs = fip_qry.filter_by(fixed_port_id=port_id) for fip_db in fip_dbs: routers.add(fip_db.router_id) except sa_exc.NoResultFound: pass super(NsxAdvancedPlugin, self).disassociate_floatingips(context, port_id)",4,12
openstack%2Fneutron~master~I94beb2180703a323d6751df9b31602f6f88eb340,openstack/neutron,master,I94beb2180703a323d6751df9b31602f6f88eb340,Imported Translations from Transifex,MERGED,2014-06-22 06:08:51.000000000,2014-06-23 12:16:46.000000000,2014-06-23 08:25:49.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-22 06:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be654e3935ade267ba4d02022127b2cbd7c0eae7', 'message': 'Imported Translations from Transifex\n\nChange-Id: I94beb2180703a323d6751df9b31602f6f88eb340\n'}, {'number': 2, 'created': '2014-06-23 06:08:40.000000000', 'files': ['neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ade573d711e35b011a261ebee897ee392e45cd5', 'message': 'Imported Translations from Transifex\n\nChange-Id: I94beb2180703a323d6751df9b31602f6f88eb340\n'}]",0,101733,0ade573d711e35b011a261ebee897ee392e45cd5,29,12,2,11131,,,0,"Imported Translations from Transifex

Change-Id: I94beb2180703a323d6751df9b31602f6f88eb340
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/101733/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot']",2,be654e3935ade267ba4d02022127b2cbd7c0eae7,transifex/translations,"""Project-Id-Version: neutron 2014.2.dev132.g2dfe3f8\n""""POT-Creation-Date: 2014-06-22 06:08+0000\n""""consistent with Neutron. (0 to disable)""#: neutron/plugins/bigswitch/servermanager.py:554 #, python-format msgid ""Consistency watchdog disabled by polling interval setting of %s."" msgstr """" #: neutron/plugins/bigswitch/servermanager.py:566#: neutron/plugins/cisco/common/config.py:84 msgid ""Number of threads to use to make HTTP requests"" msgstr """" #: neutron/plugins/cisco/common/config.py:137#: neutron/plugins/cisco/n1kv/n1kv_client.py:228#: neutron/plugins/cisco/n1kv/n1kv_client.py:253#: neutron/plugins/cisco/n1kv/n1kv_client.py:298#: neutron/plugins/cisco/n1kv/n1kv_client.py:438#: neutron/plugins/cisco/n1kv/n1kv_client.py:448#: neutron/plugins/cisco/n1kv/n1kv_client.py:456","""Project-Id-Version: neutron 2014.2.dev124.g431937c\n""""POT-Creation-Date: 2014-06-21 06:08+0000\n""""consistent with Neutron""#: neutron/plugins/bigswitch/servermanager.py:562#: neutron/plugins/cisco/common/config.py:135#: neutron/plugins/cisco/n1kv/n1kv_client.py:224#: neutron/plugins/cisco/n1kv/n1kv_client.py:249#: neutron/plugins/cisco/n1kv/n1kv_client.py:294#: neutron/plugins/cisco/n1kv/n1kv_client.py:434#: neutron/plugins/cisco/n1kv/n1kv_client.py:443#: neutron/plugins/cisco/n1kv/n1kv_client.py:451",39,21
openstack%2Frequirements~master~I11c20997d6b7ce37943b55c759845a3e655c84d3,openstack/requirements,master,I11c20997d6b7ce37943b55c759845a3e655c84d3,Add retrying to global-requirements,MERGED,2014-06-19 18:42:32.000000000,2014-06-23 12:15:11.000000000,2014-06-23 12:15:10.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 6786}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-19 18:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f904db5259b13ab0e505b9bc931babc42019c006', 'message': 'Add retrying to global-requirements\n\nRetrying is an Apache 2.0 licensed general-purpose retrying library,\nwritten in Python, to simplify the task of adding retry behavior.\n\nChange-Id: I11c20997d6b7ce37943b55c759845a3e655c84d3\n'}, {'number': 2, 'created': '2014-06-19 19:16:32.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1b20d2775d2b6284962ed125495548273ba5cb0f', 'message': 'Add retrying to global-requirements\n\nRetrying is an Apache 2.0 licensed general-purpose retrying library,\nwritten in Python, to simplify the task of adding retry behavior.\n\nRetrying would be useful for the following projects:\n- glance\n- oslo\n- nova\n- certainly more...\n\nUseful in the context of:\n- session timeout\n- retry on specific exception\n- etc.\n\nChange-Id: I11c20997d6b7ce37943b55c759845a3e655c84d3\n'}]",0,101287,1b20d2775d2b6284962ed125495548273ba5cb0f,23,7,2,8759,,,0,"Add retrying to global-requirements

Retrying is an Apache 2.0 licensed general-purpose retrying library,
written in Python, to simplify the task of adding retry behavior.

Retrying would be useful for the following projects:
- glance
- oslo
- nova
- certainly more...

Useful in the context of:
- session timeout
- retry on specific exception
- etc.

Change-Id: I11c20997d6b7ce37943b55c759845a3e655c84d3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/87/101287/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,f904db5259b13ab0e505b9bc931babc42019c006,add-retrying,retrying>=1.2.1 # Apache-2.0,,1,0
openstack%2Ffuel-web~master~I9e108be401984c2cc42cab63a895c82af9e83610,openstack/fuel-web,master,I9e108be401984c2cc42cab63a895c82af9e83610,Fix removing of nodes via CLI without env-id,MERGED,2014-06-17 19:50:18.000000000,2014-06-23 12:09:13.000000000,2014-06-23 12:09:13.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-17 19:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd009c4ebb140140ad7f8703293d0d1a06b388f0', 'message': ""Fix removing of nodes via CLI without env-id\n\nRemoving of nodes from environment using Fuel CLI\nfails when 'env-id' parameter isn't specified.\nAlso it shouldn't try to remove node which isn't\nassigned to some environment.\n\nChange-Id: I9e108be401984c2cc42cab63a895c82af9e83610\nCloses-bug: #1330412\n""}, {'number': 2, 'created': '2014-06-20 08:01:04.000000000', 'files': ['fuelclient/fuelclient/cli/actions/node.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/930c54c6b7016eab421169ecb12d027ac9e484d1', 'message': ""Fix removing of nodes via CLI without env-id\n\nRemoving of nodes from environment using Fuel CLI\nfails when 'env-id' parameter isn't specified.\nAlso it shouldn't try to remove node which isn't\nassigned to some environment.\n\nChange-Id: I9e108be401984c2cc42cab63a895c82af9e83610\nCloses-bug: #1330412\n""}]",0,100660,930c54c6b7016eab421169ecb12d027ac9e484d1,20,6,2,11081,,,0,"Fix removing of nodes via CLI without env-id

Removing of nodes from environment using Fuel CLI
fails when 'env-id' parameter isn't specified.
Also it shouldn't try to remove node which isn't
assigned to some environment.

Change-Id: I9e108be401984c2cc42cab63a895c82af9e83610
Closes-bug: #1330412
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/60/100660/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelclient/fuelclient/cli/actions/node.py'],1,dd009c4ebb140140ad7f8703293d0d1a06b388f0,bug/1330412," list_of_nodes = [ n.id for n in _nodes] if env_id: Environment(env_id).unassign(list_of_nodes) self.serializer.print_to_output( {}, ""Nodes with ids {0} were removed "" ""from environment with id {1}."" .format(list_of_nodes, env_id) ) else: self.serializer.print_to_output( ""Nodes with ids {0} aren't added to "" ""any environment."" .format(list_of_nodes) )"," list_of_nodes = list(_nodes) Environment(env_id).unassign(list_of_nodes) self.serializer.print_to_output( ""Nodes with ids {0} were removed "" ""from environment with id {1}."" .format(list_of_nodes, env_id) )",15,7
openstack%2Fmistral~master~Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5,openstack/mistral,master,Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5,Add project_id to the workbook and filter by it,MERGED,2014-06-10 12:04:08.000000000,2014-06-23 11:59:21.000000000,2014-06-23 11:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-06-10 12:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5042a17bc0847e255e244962487418affa593512', 'message': 'Add project_id to the workbook and filter by it\n\nThis does not yet implement ""scope"", just project filtering\non workbooks.\n\nPartial blueprint mistral-multitenancy\n\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 2, 'created': '2014-06-11 02:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8196d039302eeb3c80593871faf724c844d78ab8', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 3, 'created': '2014-06-11 04:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/897a43d63185c213d8bed3345b2262ac55c0daf5', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 4, 'created': '2014-06-11 06:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2a2be350cf271e7eae66ce26ecf78a591f35d299', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 5, 'created': '2014-06-11 06:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ae5c8eb5a7e4240f06434986596bcf3476c5da32', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 6, 'created': '2014-06-11 12:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4ac3a1c9322cce884bbcf14556dd1a9523e22830', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 7, 'created': '2014-06-12 00:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/98c381d034d0f9e9e4b314e77526e960c47bd3a3', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 8, 'created': '2014-06-16 09:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d0a33756cb406bd62fe87c4246e23ba86f7dd547', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 9, 'created': '2014-06-16 13:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b329abe3ccb1b86573f1763feb99d772f909ab7a', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 10, 'created': '2014-06-17 01:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/df82c91ba18a9d059438c55cd08b8b18f335c6f6', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 11, 'created': '2014-06-18 11:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d381df70c8e0304feb8aebb9c4466663c4d008ae', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 12, 'created': '2014-06-19 12:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2325b2f086f126c3dc53ed3f538f08437721db47', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}, {'number': 13, 'created': '2014-06-23 05:47:31.000000000', 'files': ['mistral/api/controllers/v1/workbook.py', 'mistral/tests/unit/db/test_sqlalchemy_db_api.py', 'mistral/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/98cd7076c9333bd5ec75864e6315196e1d8136fc', 'message': 'Add project_id to the workbook and filter by it\n\nPartial blueprint mistral-multitenancy\nChange-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5\n'}]",7,99023,98cd7076c9333bd5ec75864e6315196e1d8136fc,61,7,13,4715,,,0,"Add project_id to the workbook and filter by it

Partial blueprint mistral-multitenancy
Change-Id: Ic815751e735f3d73d078d0eea0a89c61a1ef4fd5
",git fetch https://review.opendev.org/openstack/mistral refs/changes/23/99023/2 && git format-patch -1 --stdout FETCH_HEAD,['mistral/db/sqlalchemy/api.py'],1,5042a17bc0847e255e244962487418affa593512,bp/mistral-multitenancy,"from mistral import context workbook['project_id'] = context.ctx().project_id return query.filter_by(project_id=context.ctx().project_id, **kwargs).all() return query.filter_by(name=workbook_name, project_id=context.ctx().project_id).first()", return query.filter_by(**kwargs).all() return query.filter_by(name=workbook_name).first(),6,2
openstack%2Fmistral~master~I6e76c7e28f475bb815f9184041bc8b848249d419,openstack/mistral,master,I6e76c7e28f475bb815f9184041bc8b848249d419,Make sure the context is correctly passed through the rpc,MERGED,2014-06-19 12:37:24.000000000,2014-06-23 11:59:15.000000000,2014-06-23 11:59:15.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-19 12:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e784b71c5536effb96ef06e13fa306e34c988556', 'message': 'Make sure the context is correctly passed through the rpc\n\nThis adds a rpc context serializer to pass the context to the engine and\nexecutor.\n\nChange-Id: I6e76c7e28f475bb815f9184041bc8b848249d419\n'}, {'number': 2, 'created': '2014-06-23 05:47:31.000000000', 'files': ['mistral/context.py', 'mistral/engine/executor.py', 'mistral/cmd/launch.py', 'mistral/engine/drivers/default/engine.py', 'mistral/engine/__init__.py', 'mistral/engine/drivers/default/executor.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/60d90e5660d00971c47dcf2debeeb9a7d4952bd0', 'message': 'Make sure the context is correctly passed through the rpc\n\nThis adds a rpc context serializer to pass the context to the engine and\nexecutor.\n\nChange-Id: I6e76c7e28f475bb815f9184041bc8b848249d419\n'}]",0,101195,60d90e5660d00971c47dcf2debeeb9a7d4952bd0,18,7,2,4715,,,0,"Make sure the context is correctly passed through the rpc

This adds a rpc context serializer to pass the context to the engine and
executor.

Change-Id: I6e76c7e28f475bb815f9184041bc8b848249d419
",git fetch https://review.opendev.org/openstack/mistral refs/changes/95/101195/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/context.py', 'mistral/engine/executor.py', 'mistral/cmd/launch.py', 'mistral/engine/drivers/default/engine.py', 'mistral/engine/__init__.py', 'mistral/engine/drivers/default/executor.py']",6,e784b71c5536effb96ef06e13fa306e34c988556,bp/mistral-multitenancy, :type cntx: MistralContext, :type cntx: dict,63,22
openstack%2Fmistral~master~I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee,openstack/mistral,master,I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee,Make OpenStack related data available in actions,MERGED,2014-06-18 13:35:41.000000000,2014-06-23 11:51:45.000000000,2014-06-23 11:51:44.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 9537}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-18 13:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c4899fe25a00309b9ed192cb09608beaa4c005b8', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in actions\n   without explicitly defining parameters such as auth_token and project_id\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}, {'number': 2, 'created': '2014-06-19 13:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f83c0c73f9c1844b4c6d1150b6e5c82ddffbc774', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in actions\n   without explicitly defining parameters such as auth_token and project_id\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}, {'number': 3, 'created': '2014-06-20 09:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/031aa3023a2cb029e6c053668ec63be8b00b39a0', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in action DSL\n   without explicitly defining parameters such as auth_token and project_id\n * Make Openstack data accessible via action_context parameter\n   for new Actions\n\nTODO:\n  * Unit tests\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}, {'number': 4, 'created': '2014-06-20 13:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/086bd288cf70cd0e0869557bd6f68371362bcb61', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in action DSL\n   without explicitly defining parameters such as auth_token and project_id\n * Make Openstack data accessible via action_context parameter\n   for new Actions\n\n  * Unit tests\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}, {'number': 5, 'created': '2014-06-23 07:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/76a5942196ff24366af8f516e0b73ce9c8d2061e', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in action DSL\n   without explicitly defining parameters such as auth_token and project_id\n * Make Openstack data accessible via action_context parameter\n   for new Actions\n * Unit tests\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}, {'number': 6, 'created': '2014-06-23 09:59:20.000000000', 'files': ['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/unit/engine/default/test_executor.py', 'mistral/engine/data_flow.py', 'mistral/actions/action_factory.py', 'functionaltests/api/v1/demo.yaml', 'mistral/tests/unit/actions/test_action_factory.py', 'mistral/engine/__init__.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e50d1eaa9fc211e451ab0baa62e9cbab693f112b', 'message': 'Make OpenStack related data available in actions\n\n * Make OpenStack related data accessible via context in action DSL\n   without explicitly defining parameters such as auth_token and project_id\n * Make Openstack data accessible via action_context parameter\n   for new Actions\n * Unit tests\n\nImplements blueprint: mistral-openstack-data-accessible-by-default\n\nChange-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee\n'}]",15,100904,e50d1eaa9fc211e451ab0baa62e9cbab693f112b,54,9,6,7700,,,0,"Make OpenStack related data available in actions

 * Make OpenStack related data accessible via context in action DSL
   without explicitly defining parameters such as auth_token and project_id
 * Make Openstack data accessible via action_context parameter
   for new Actions
 * Unit tests

Implements blueprint: mistral-openstack-data-accessible-by-default

Change-Id: I9b6802d90c0ac17e0494d2025897ce5cdd02f4ee
",git fetch https://review.opendev.org/openstack/mistral refs/changes/04/100904/5 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/unit/engine/default/test_executor.py', 'mistral/engine/data_flow.py', 'mistral/actions/action_factory.py', 'mistral/tests/unit/actions/test_action_factory.py', 'mistral/engine/__init__.py']",6,c4899fe25a00309b9ed192cb09608beaa4c005b8,bp/mistral-openstack-data-accessible-by-default," data_flow.add_openstack_data_to_context(context, db_workbook)"," data_flow.add_token_to_context(context, db_workbook)",13,7
openstack%2Fmistral~master~I7e81b822270ab8e61d2580280a28692af69edb87,openstack/mistral,master,I7e81b822270ab8e61d2580280a28692af69edb87,Define workflow start task in DSL,ABANDONED,2014-06-17 00:24:33.000000000,2014-06-23 11:46:01.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}, {'_account_id': 9537}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-17 00:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4cc56f8b120abd3928346360ad8a728097bff7bf', 'message': ""Define workflow start task in DSL\n\nRemoved task from the model\nIntroduced start in DSL and used it\n\nTODO (coming changes):\n* remove task from start_workflow_execution signature\n  (it's just ignored currently)\n* more unittest adjustments\n* adjust mistral-extra, python-mistralclient, and mistral-dashboard\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: I7e81b822270ab8e61d2580280a28692af69edb87\n""}, {'number': 2, 'created': '2014-06-20 04:52:40.000000000', 'files': ['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/resources/control_flow/one_async_task.yaml', 'mistral/tests/resources/data_flow/task_with_two_dependencies.yaml', 'mistral/tests/resources/control_flow/one_std_task.yaml', 'mistral/tests/resources/data_flow/two_subsequent_tasks.yaml', 'mistral/tests/resources/retry_task/retry_task.yaml', 'mistral/tests/resources/test_rest.yaml', 'mistral/tests/unit/engine/test_transport.py', 'mistral/tests/resources/data_flow/three_subsequent_tasks.yaml', 'mistral/workbook/workflow.py', 'mistral/tests/resources/control_flow/direct_flow.yaml', 'mistral/tests/resources/data_flow/two_dependent_tasks.yaml', 'mistral/tests/resources/control_flow/require_flow.yaml', 'functionaltests/api/v1/demo.yaml', 'mistral/db/sqlalchemy/models.py', 'mistral/engine/__init__.py', 'mistral/tests/resources/control_flow/no_namespaces.yaml', 'mistral/tests/resources/retry_task/delay_retry_task.yaml', 'mistral/tests/api/v1/controllers/test_workbook_definition.py', 'mistral/tests/resources/retry_task/sync_task.yaml', 'mistral/engine/data_flow.py', 'mistral/tests/resources/retry_task/two_tasks.yaml', 'mistral/engine/workflow.py', 'mistral/tests/unit/db/test_sqlalchemy_db_api.py', 'mistral/tests/unit/workbook/test_workbook.py', 'mistral/tests/resources/control_flow/one_sync_task.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2c7c8c1d3f830e235f7b707b09e8294b995def52', 'message': ""Define workflow start task in DSL\n\nRemoved task from the model\nIntroduced start in DSL and used it\n\nTODO (coming changes):\n* remove task from start_workflow_execution signature\n  (it's just ignored currently)\n* more unittest adjustments\n* adjust mistral-extra, python-mistralclient, and mistral-dashboard\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: I7e81b822270ab8e61d2580280a28692af69edb87\n""}]",1,100390,2c7c8c1d3f830e235f7b707b09e8294b995def52,15,9,2,9432,,,0,"Define workflow start task in DSL

Removed task from the model
Introduced start in DSL and used it

TODO (coming changes):
* remove task from start_workflow_execution signature
  (it's just ignored currently)
* more unittest adjustments
* adjust mistral-extra, python-mistralclient, and mistral-dashboard

Partially implements: blueprint mistral-workflow-start-task

Change-Id: I7e81b822270ab8e61d2580280a28692af69edb87
",git fetch https://review.opendev.org/openstack/mistral refs/changes/90/100390/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/resources/control_flow/one_async_task.yaml', 'mistral/tests/resources/data_flow/task_with_two_dependencies.yaml', 'mistral/tests/resources/control_flow/one_std_task.yaml', 'mistral/tests/resources/data_flow/two_subsequent_tasks.yaml', 'mistral/tests/resources/retry_task/retry_task.yaml', 'mistral/tests/resources/test_rest.yaml', 'mistral/tests/unit/engine/test_transport.py', 'mistral/tests/resources/data_flow/three_subsequent_tasks.yaml', 'mistral/workbook/workflow.py', 'mistral/tests/resources/control_flow/direct_flow.yaml', 'mistral/tests/resources/data_flow/two_dependent_tasks.yaml', 'mistral/tests/resources/control_flow/require_flow.yaml', 'functionaltests/api/v1/demo.yaml', 'mistral/db/sqlalchemy/models.py', 'mistral/engine/__init__.py', 'mistral/tests/resources/control_flow/no_namespaces.yaml', 'mistral/tests/resources/retry_task/delay_retry_task.yaml', 'mistral/tests/api/v1/controllers/test_workbook_definition.py', 'mistral/tests/resources/retry_task/sync_task.yaml', 'mistral/engine/data_flow.py', 'mistral/tests/resources/retry_task/two_tasks.yaml', 'mistral/engine/workflow.py', 'mistral/tests/unit/db/test_sqlalchemy_db_api.py', 'mistral/tests/unit/workbook/test_workbook.py', 'mistral/tests/resources/control_flow/one_sync_task.yaml']",26,4cc56f8b120abd3928346360ad8a728097bff7bf,bp/mistral-workflow-start-task, start: create-vm-nova,,44,33
openstack%2Fmistral~master~If25d8b9a4e0844a261655d3adc81d2d67d2905ab,openstack/mistral,master,If25d8b9a4e0844a261655d3adc81d2d67d2905ab,Remove 'task' from start_workflow_execution,ABANDONED,2014-06-17 00:24:33.000000000,2014-06-23 11:45:22.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-06-17 00:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9a3f19dbcc5f5089f5d26d7ea846b92522d96606', 'message': ""Remove 'task' from start_workflow_execution\n\nRemoved task from start_workflow_execution signatures \nand unit test calls. \n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: If25d8b9a4e0844a261655d3adc81d2d67d2905ab\n""}, {'number': 2, 'created': '2014-06-18 00:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/21c412fb83d158da1b96ef13911251a2a9d76db5', 'message': ""Remove 'task' from start_workflow_execution\n\nRemoved task from start_workflow_execution signatures\nand unit test calls.\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: If25d8b9a4e0844a261655d3adc81d2d67d2905ab\n""}, {'number': 3, 'created': '2014-06-20 04:52:40.000000000', 'files': ['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/unit/engine/test_transport.py', 'mistral/tests/unit/engine/test_task_retry.py', 'mistral/api/controllers/v1/execution.py', 'mistral/services/periodic.py', 'mistral/tests/base.py', 'mistral/engine/__init__.py', 'mistral/tests/unit/engine/default/test_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e118acf28de18fb3087eaa2b160315b1c2f0575c', 'message': ""Remove 'task' from start_workflow_execution\n\nRemoved task from start_workflow_execution signatures\nand unit test calls.\n\nPartially implements: blueprint mistral-workflow-start-task\n\nChange-Id: If25d8b9a4e0844a261655d3adc81d2d67d2905ab\n""}]",2,100391,e118acf28de18fb3087eaa2b160315b1c2f0575c,17,7,3,9432,,,0,"Remove 'task' from start_workflow_execution

Removed task from start_workflow_execution signatures
and unit test calls.

Partially implements: blueprint mistral-workflow-start-task

Change-Id: If25d8b9a4e0844a261655d3adc81d2d67d2905ab
",git fetch https://review.opendev.org/openstack/mistral refs/changes/91/100391/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/test_data_flow.py', 'mistral/tests/unit/engine/test_transport.py', 'mistral/tests/unit/engine/test_task_retry.py', 'mistral/api/controllers/v1/execution.py', 'mistral/services/periodic.py', 'mistral/tests/base.py', 'mistral/engine/__init__.py', 'mistral/tests/unit/engine/default/test_engine.py']",8,9a3f19dbcc5f5089f5d26d7ea846b92522d96606,bp/mistral-workflow-start-task," execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, CONTEXT)"," execution = self.engine.start_workflow_execution(WB_NAME, ""create-vms"", CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, ""backup-vms"", CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, ""create-vm-nova"", CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, ""start-task"", CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, ""start-task"", CONTEXT) execution = self.engine.start_workflow_execution(WB_NAME, ""task1"", {}) execution = self.engine.start_workflow_execution(WB_NAME, ""std_http_task"", {})",23,56
openstack%2Fgnocchi~master~I28bcf73c598c8fe66a949fb68dde73e19b9b31be,openstack/gnocchi,master,I28bcf73c598c8fe66a949fb68dde73e19b9b31be,Fix up examples in README.rst,MERGED,2014-06-20 20:11:14.000000000,2014-06-23 11:41:48.000000000,2014-06-23 11:41:48.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 9562}, {'_account_id': 10683}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-20 20:11:14.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/de32314ac7143b22df6c15154ce1ba7c9c7c70ad', 'message': 'Fix up examples in README.rst\n\nResolve a few typos in the examples and reflect expected\nentity body format to avoid Bad Request on schema mismatch.\n\nChange-Id: I28bcf73c598c8fe66a949fb68dde73e19b9b31be\n'}]",0,101641,de32314ac7143b22df6c15154ce1ba7c9c7c70ad,11,6,1,2284,,,0,"Fix up examples in README.rst

Resolve a few typos in the examples and reflect expected
entity body format to avoid Bad Request on schema mismatch.

Change-Id: I28bcf73c598c8fe66a949fb68dde73e19b9b31be
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/41/101641/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,de32314ac7143b22df6c15154ce1ba7c9c7c70ad,," curl -i http://0.0.0.0:8041/v1/entity -X POST \ -H ""Content-Type: application/json"" -H ""Accept: application/json"" \ -d '{""archives"": [[1, 3600]]}' r = requests.post('http://0.0.0.0:8041/v1/entity', data=json.dumps({""archives"": [[1, 3600]]}))"," curl -i 'http://0.0.0.0:8041/v1/entity -X POST -H ""Content:Type: application/json"" -H ""Accept: application/json"" -d '{""archives"": [1, 3600]}' r = requests.post('http://0.0.0.0:8041/v1/entity', data=json.dumps({""archives"": [1, 3600]})) ",4,6
openstack%2Fneutron~stable%2Ficehouse~I2aa7ffd6bb297837a39cdd00794af100bf9ab407,openstack/neutron,stable/icehouse,I2aa7ffd6bb297837a39cdd00794af100bf9ab407,ofa_neutron_agent: Fix _phys_br_block_untranslated_traffic,MERGED,2014-06-12 07:00:48.000000000,2014-06-23 11:40:22.000000000,2014-06-23 08:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8344}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 10117}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-06-12 07:00:48.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/db7f8a78608c0c3f4a5db14f5bdbb36792b74df0', 'message': 'ofa_neutron_agent: Fix _phys_br_block_untranslated_traffic\n\nInstall the flow to the correct bridge.\n\nCloses-Bug: 1301142\nChange-Id: I2aa7ffd6bb297837a39cdd00794af100bf9ab407\n(cherry picked from commit 7f5e7c945821b75bd7321bfd0b0c63f2888ac72e)\n'}]",0,99584,db7f8a78608c0c3f4a5db14f5bdbb36792b74df0,26,10,1,8344,,,0,"ofa_neutron_agent: Fix _phys_br_block_untranslated_traffic

Install the flow to the correct bridge.

Closes-Bug: 1301142
Change-Id: I2aa7ffd6bb297837a39cdd00794af100bf9ab407
(cherry picked from commit 7f5e7c945821b75bd7321bfd0b0c63f2888ac72e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/99584/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ofagent/agent/ofa_neutron_agent.py'],1,db7f8a78608c0c3f4a5db14f5bdbb36792b74df0,bug/1301142," match = self.int_br.ofparser.OFPMatch(in_port=int( msg = self.int_br.ofparser.OFPFlowMod(self.int_br.datapath, priority=2, match=match)"," match = br.ofparser.OFPMatch(in_port=int( msg = br.ofparser.OFPFlowMod(self.int_br.datapath, priority=2, match=match)",3,3
openstack%2Fmurano~master~I5aa978f7095efc57f2d6fad81b5553e1880ad931,openstack/murano,master,I5aa978f7095efc57f2d6fad81b5553e1880ad931,Added DB migrations on Alembic,MERGED,2014-05-29 14:09:01.000000000,2014-06-23 11:39:25.000000000,2014-06-23 11:39:25.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-05-29 14:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d3d5ce43c8b15a4d7a72e3b716f70bdfc55ab30c', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 2, 'created': '2014-05-30 11:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d3e55bdf99636dbe64252ed2b6d8f64039ec9229', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 3, 'created': '2014-06-02 09:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/71350ad97fa923f4f06d143442b1ec1339f11d2c', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 4, 'created': '2014-06-04 10:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/879c9c8b49a18320e43a2656472b71fa20fdd1b3', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 5, 'created': '2014-06-05 10:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/008bb3daccfca1d26d2805a5ecda6391b6dcdcbd', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 6, 'created': '2014-06-05 11:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f8bbfc04cc8235381240524ffb71245ba57b98d7', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 7, 'created': '2014-06-05 12:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8c3054d19c54bec4abacfd49d23487cbfc81c82a', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 8, 'created': '2014-06-05 12:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/cfe2e477c9e0be36c47f625391aabea5877818ac', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 9, 'created': '2014-06-06 12:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2c6d16d1827c4dc830c71693947d44b7d8027d3a', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 10, 'created': '2014-06-06 13:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2f57a78ed113733d78d66b545da53fd2ceee04a7', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 11, 'created': '2014-06-06 14:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/70b790b3ad711f32210b84eff1d3820af7e09b27', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 12, 'created': '2014-06-06 16:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/79d44b10659ecb4e5aace62bf791f5ad0ec2723a', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 13, 'created': '2014-06-08 19:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a8440ce332e7d24c8cc848a3836afd92b679650c', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 14, 'created': '2014-06-08 19:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/60942784489b51b1bbba9afcf5b85b8956f8cf41', 'message': ""Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn't preserve all the migration scripts, it merges them into a\nsingle migration script. That's what we would do even without Alembic. It's a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n""}, {'number': 15, 'created': '2014-06-09 15:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b236be923868ec60ae352cdfcba2105368c2a939', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 16, 'created': '2014-06-10 09:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/e8ab9610b973c08133f33e73fa928ddbe97b1975', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 17, 'created': '2014-06-10 14:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/9880ea6c1cfccb864c2a442e67e594ee631006ee', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 18, 'created': '2014-06-10 14:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ba30afc27bc26f33dc48d0d409f362fac5db9141', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 19, 'created': '2014-06-18 12:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c7b21130944b409b8ee417155d85f5671b5ac803', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 20, 'created': '2014-06-19 14:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a6999db5ae8b8b3a3fe25dfba55cbe3d7400c80e', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 21, 'created': '2014-06-20 10:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/5a4fe360dafdb09e2186572fa94e9540871b86f2', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 22, 'created': '2014-06-20 13:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0fc406bdf3b59f3d5d797e0c57979aa1d5886c2d', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}, {'number': 23, 'created': '2014-06-20 14:01:55.000000000', 'files': ['doc/source/install/manual.rst', 'test-requirements.txt', 'murano/db/migration/__init__.py', 'murano/db/session.py', 'murano/db/sqla/types.py', 'murano/db/migrate_repo/versions/007_instance_table_extended.py', 'murano/db/migration/alembic.ini', 'murano/tests/db/__init__.py', 'murano/tests/db/migration/__init__.py', 'murano/db/migrate_repo/versions/010_add_unique_environment_constraint.py', 'requirements.txt', 'murano/db/migrate_repo/versions/006_add_default_categories.py', 'murano/db/models.py', 'murano/tests/db/migration/test_migrations_base.py', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py', 'murano/db/migrate_repo/versions/003_add_stats_table.py', 'murano/db/migrate_repo/versions/004_add_repository_tables.py', 'murano/db/migrate_repo/versions/008_cpu_stats.py', 'murano/db/migration/migration.py', 'contrib/devstack/lib/murano', 'murano/cmd/manage.py', 'murano/db/migrate_repo/README', 'murano/db/migrate_repo/versions/009_increase_package_name_length.py', 'MANIFEST.in', 'murano/db/migrate_repo/versions/001_add_initial_tables.py', 'murano/cmd/db_manage.py', 'murano/db/migrate_repo/versions/__init__.py', 'murano/openstack/common/processutils.py', 'murano/db/migration/alembic_migrations/script.py.mako', 'murano/db/migrate_repo/versions/002_add_networking_field.py', 'murano/tests/db/migration/test_migrations.conf', 'murano/db/migrate_repo/versions/005_add_instance_table.py', 'murano/db/migrate_repo/migrate.cfg', 'murano/db/migration/alembic_migrations/env.py', 'setup.cfg', 'murano/db/migration/alembic_migrations/README', 'murano/tests/db/migration/test_migrations.py', 'murano/db/sqla/__init__.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/9030bc728511237d22c1dde476282addc7396504', 'message': 'Added DB migrations on Alembic\n\nThis commit migrates Murano database migration framework from\nsqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All\nother OpenStack projects are in  process of migration to Alembic or have\nalready finished migration.\n\nThis change doesn\'t preserve all the migration scripts, it merges them into a\nsingle migration script. That\'s what we would do even without Alembic. It\'s a\ncommon practice to squash migration scripts into a single one right after the\nrelease.\n\nNOTICE:\nCLI command to run migrations changed. Now it looks like this:\n$ murano-db-manage upgrade\n\nMigration path:\n1. Simple solution is just to re-create your database from scratch\n2. You can stamp your database with revision to make Alembic think that it\n   already applied the first migration:\n   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head\n\nFor usage instructions see:\nmurano/db/migraiton/alembic_migrations/README\n\nThis patch also adds opportunistic tests for migrations. These tests will run in\nOpenStack Infrastructure jenkins slaves. It\'ll use real MySQL and Postgres databases.\nTests will run in a ""snake walk"" manner, which means that upgrade and downgrade path\nwill be tested.\nBase for migration tests is copied from Nova. Please note, that at this moment we\ncannot use code from oslo, because it is not documented and is not tested. Once\ntest_migrations_base appears in project \'oslo.db\', we\'ll be able to remove our own\ntest_migrations_base and use the one from \'oslo.db\'.\n\nimplements: blueprint alembic-migrations\nChange-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931\n'}]",35,96471,9030bc728511237d22c1dde476282addc7396504,188,9,23,7600,,,0,"Added DB migrations on Alembic

This commit migrates Murano database migration framework from
sqlalchemy-migrate to Alembic. sqlalchemy-migrate is considered abandoned. All
other OpenStack projects are in  process of migration to Alembic or have
already finished migration.

This change doesn't preserve all the migration scripts, it merges them into a
single migration script. That's what we would do even without Alembic. It's a
common practice to squash migration scripts into a single one right after the
release.

NOTICE:
CLI command to run migrations changed. Now it looks like this:
$ murano-db-manage upgrade

Migration path:
1. Simple solution is just to re-create your database from scratch
2. You can stamp your database with revision to make Alembic think that it
   already applied the first migration:
   $ tox -e venv -- murano-db-manage --config-file etc/murano/murano.conf stamp --revision head

For usage instructions see:
murano/db/migraiton/alembic_migrations/README

This patch also adds opportunistic tests for migrations. These tests will run in
OpenStack Infrastructure jenkins slaves. It'll use real MySQL and Postgres databases.
Tests will run in a ""snake walk"" manner, which means that upgrade and downgrade path
will be tested.
Base for migration tests is copied from Nova. Please note, that at this moment we
cannot use code from oslo, because it is not documented and is not tested. Once
test_migrations_base appears in project 'oslo.db', we'll be able to remove our own
test_migrations_base and use the one from 'oslo.db'.

implements: blueprint alembic-migrations
Change-Id: I5aa978f7095efc57f2d6fad81b5553e1880ad931
",git fetch https://review.opendev.org/openstack/murano refs/changes/71/96471/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/manual.rst', 'murano/db/migration/__init__.py', 'murano/db/session.py', 'murano/db/migrate_repo/versions/007_instance_table_extended.py', 'murano/db/migration/alembic.ini', 'requirements.txt', 'murano/db/migrate_repo/versions/006_add_default_categories.py', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py', 'murano/db/migrate_repo/versions/003_add_stats_table.py', 'murano/db/migrate_repo/versions/004_add_repository_tables.py', 'murano/db/migrate_repo/versions/008_cpu_stats.py', 'murano/db/migration/migration.py', 'contrib/devstack/lib/murano', 'murano/cmd/manage.py', 'murano/db/migrate_repo/manage.py', 'murano/db/migrate_repo/README', 'murano/db/migrate_repo/versions/009_increase_package_name_length.py', 'murano/db/migrate_repo/versions/001_add_initial_tables.py', 'murano/cmd/db_manage.py', 'murano/db/migrate_repo/versions/__init__.py', 'murano/db/migration/alembic_migrations/script.py.mako', 'murano/db/migrate_repo/versions/002_add_networking_field.py', 'murano/db/migrate_repo/versions/005_add_instance_table.py', 'murano/db/migrate_repo/migrate.cfg', 'murano/db/migration/alembic_migrations/env.py', 'setup.cfg', 'murano/db/migration/alembic_migrations/README']",27,d3d5ce43c8b15a4d7a72e3b716f70bdfc55ab30c,bp/alembic-migrations,"Please see https://alembic.readthedocs.org/en/latest/index.html for general documentation To create alembic migrations use: $ murano-db-manage revision --message --autogenerate Stamp db with most recent migration version, without actually running migrations $ murano-db-manage stamp --revision head Upgrade can be performed by: $ murano-db-manage upgrade $ murano-db-manage upgrade --revision head Downgrading db: $ murano-db-manage downgrade $ murano-db-manage downgrade --revision base ",,550,617
openstack%2Ffuel-web~master~Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e,openstack/fuel-web,master,Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e,Refactoring for error dialogs,MERGED,2014-03-27 13:22:53.000000000,2014-06-23 11:36:53.000000000,2014-06-23 11:36:53.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-03-27 13:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5784ac4de783c7fc7757a07d50bb5803c279190a', 'message': 'Update for error dialogs.\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 2, 'created': '2014-03-27 14:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a5e2140cac70daf79fe9057e1ee9bb0478fa915f', 'message': 'Update for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 3, 'created': '2014-04-01 10:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1d5fd2af896f3145ac055c0042ecf3fb4d277c74', 'message': 'Update for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 4, 'created': '2014-04-01 14:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3896dd19d3bc94e860c8f0274a29233902696ba7', 'message': 'Update for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 5, 'created': '2014-04-03 12:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a7db233abe33c83de14091616633dae9131ad10b', 'message': 'Update for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 6, 'created': '2014-04-03 12:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7036bf8de55c74ecfe5dd13456577c8cdc7f3907', 'message': 'Update for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 7, 'created': '2014-04-03 13:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8a2dac95cdbc1830da1de5581a071caeb1ac10ee', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 8, 'created': '2014-04-07 08:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/62f0491395980239f4bbb6c455e95efe8d57fac0', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 9, 'created': '2014-04-09 11:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/005906e4227d71d71a3d084de0452bace0afa731', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 10, 'created': '2014-04-09 11:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/92c13d38acd41671a53a4fce0e54d4eedcdb98c4', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 11, 'created': '2014-04-15 08:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6b90bcaea09616acbb8a1ef241b614929025ef30', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 12, 'created': '2014-06-03 08:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fae509836d2c7732a27a00c94562d37f7e1ea41b', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 13, 'created': '2014-06-04 14:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/50f042e8c6025e9d06d8726f7908e6d789e858e1', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 14, 'created': '2014-06-16 09:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/071d2cb16b0e47614271950833fe97de180c883b', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 15, 'created': '2014-06-19 07:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d14f452799ed25bc14a8b9770299a93dcce20f90', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}, {'number': 16, 'created': '2014-06-20 12:17:46.000000000', 'files': ['nailgun/static/i18n/translation.json', 'nailgun/static/templates/dialogs/base_dialog.html', 'nailgun/static/templates/dialogs/error_message.html', 'nailgun/static/templates/dialogs/simple_message.html', 'nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.js', 'nailgun/static/js/views/wizard.js', 'nailgun/static/js/views/cluster_page_tabs/actions_tab.js', 'nailgun/static/js/views/dialogs.js', 'nailgun/static/js/utils.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js', 'nailgun/static/js/views/cluster_page_tabs/network_tab.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d5a0878a53a021b5505e7b5c389a0b720f44dd09', 'message': 'Refactoring for error dialogs\n\nCloses-Bug:#1297158\n\nChange-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e\n'}]",64,83373,d5a0878a53a021b5505e7b5c389a0b720f44dd09,143,6,16,9730,,,0,"Refactoring for error dialogs

Closes-Bug:#1297158

Change-Id: Ib3c457e06357d8b2d1b165fdc12eb85c27785a0e
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/73/83373/9 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/nodes_tab.js', 'nailgun/static/i18n/translation.json', 'nailgun/static/templates/dialogs/base_dialog.html', 'nailgun/static/templates/dialogs/error_message.html', 'nailgun/static/templates/dialogs/simple_message.html', 'nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/js/views/dialogs.js', 'nailgun/static/js/utils.js', 'nailgun/static/js/views/cluster_page_tabs/network_tab.js']",9,5784ac4de783c7fc7757a07d50bb5803c279190a,error_dialogs, utils.showErrorDialog({title: $.t('cluster_page.network_tab.verify_networks.verification_error_title')}); utils.showErrorDialog({title: $.t('cluster_page.network_tab.verify_networks.save_error_title')});, utils.showErrorDialog({title: 'Network verification'}); utils.showErrorDialog({title: 'Networks'});,54,54
openstack%2Fcloudkitty~master~I2499080f7d8ff91ae3bafb0e5bfb8b06fb450d08,openstack/cloudkitty,master,I2499080f7d8ff91ae3bafb0e5bfb8b06fb450d08,Moved to importutils from oslo-incubator,MERGED,2014-06-23 09:46:01.000000000,2014-06-23 11:34:55.000000000,2014-06-23 11:34:54.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-06-23 09:46:01.000000000', 'files': ['cloudkitty/openstack/common/__init__.py', 'cloudkitty/utils.py', 'cloudkitty/openstack/common/importutils.py', 'openstack-common.conf', 'cloudkitty/orchestrator.py', 'tox.ini', 'cloudkitty/openstack/__init__.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/aa23fd49f433d1132a527d4eef7aed3335ea5dc8', 'message': 'Moved to importutils from oslo-incubator\n\nRemoved generic code found in oslo-incubator\n\nChange-Id: I2499080f7d8ff91ae3bafb0e5bfb8b06fb450d08\n'}]",0,101838,aa23fd49f433d1132a527d4eef7aed3335ea5dc8,13,2,1,7042,,,0,"Moved to importutils from oslo-incubator

Removed generic code found in oslo-incubator

Change-Id: I2499080f7d8ff91ae3bafb0e5bfb8b06fb450d08
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/38/101838/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/openstack/common/__init__.py', 'cloudkitty/utils.py', 'cloudkitty/openstack/common/importutils.py', 'openstack-common.conf', 'cloudkitty/orchestrator.py', 'tox.ini', 'cloudkitty/openstack/__init__.py']",7,aa23fd49f433d1132a527d4eef7aed3335ea5dc8,class-loader-oslo,,,103,20
openstack%2Fgnocchi~master~I81cac6e5d008346a78625e895271f3a61a3fb8ec,openstack/gnocchi,master,I81cac6e5d008346a78625e895271f3a61a3fb8ec,Allow more than 2 measurements per entity to be stored,MERGED,2014-06-22 21:31:50.000000000,2014-06-23 11:25:34.000000000,2014-06-23 11:25:34.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 9562}, {'_account_id': 10683}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-22 21:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1089faf5b2be324c6a0eebc3c743bbde2e466731', 'message': ""Allow more than 2 measurements per entity to be stored\n\nTL;DR: gnocchi timeseries deserialization logic does not\n       account for multi-valued aggregation methods\n\nOn POSTing the third measurement to an entity, the creation of\nthe pandas Timestamp from the deseralized blob retrieved from\nswift fails with:\n\n    ValueError: Unable to parse high\n\nwhen attempting to parse what it expects to be a timestamp.\n\nThis occurs as a result of the open-high-low-close aggregate\nnot acting as expected in terms of producing a *single*\naggregated value per period. Instead there are 4 separate\naggregated valued involved: 'high', 'close', 'open' & 'low'.\n\nSo after the third datapoint is stored, the stored data for\nohlc is no longer just a simple dict mapping timestamps to\ntheir corresponding values, as expected by the deserialization\nlogic.\n\nInstead there are are also 'high', 'close', 'open' & 'low'\nkeys in the dict, e.g.:\n\n  [{u'aggregation_method': u'ohlc',\n    u'values': {u'high': 32.0,\n                u'close': 32.0,\n                u'open': 32.0,\n                u'low': 32.0,\n                u'2013-01-01 23:23:31+00:00': 31.0},\n    u'max_size': 3600,\n    u'sampling': u'60S'}]\n\nFor now, we remove 'ohlc' from the set of supported aggregation\nmethods, until we can figure out how to accomodate multi-valued\naggregation methods.\n\nChange-Id: I81cac6e5d008346a78625e895271f3a61a3fb8ec\n""}, {'number': 2, 'created': '2014-06-22 21:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8e73a866607dc8ab415759d66b86ef2d61cf5abe', 'message': ""Allow more than 2 measurements per entity to be stored\n\nTL;DR: gnocchi timeseries deserialization logic does not\n       account for multi-valued aggregation methods\n\nOn POSTing the third measurement to an entity, the creation of\nthe pandas Timestamp from the deseralized blob retrieved from\nswift fails with:\n\n    ValueError: Unable to parse high\n\nwhen attempting to parse what it expects to be a timestamp.\n\nThis occurs as a result of the open-high-low-close aggregate\nnot acting as expected in terms of producing a *single*\naggregated value per period. Instead there are 4 separate\naggregated valued involved: 'high', 'close', 'open' & 'low'.\n\nSo after the third datapoint is stored, the stored data for\nohlc is no longer just a simple dict mapping timestamps to\ntheir corresponding values, as expected by the deserialization\nlogic.\n\nInstead there are are also 'high', 'close', 'open' & 'low'\nkeys in the dict, e.g.:\n\n  [{u'aggregation_method': u'ohlc',\n    u'values': {u'high': 32.0,\n                u'close': 32.0,\n                u'open': 32.0,\n                u'low': 32.0,\n                u'2013-01-01 23:23:31+00:00': 31.0},\n    u'max_size': 3600,\n    u'sampling': u'60S'}]\n\nFor now, we remove 'ohlc' from the set of supported aggregation\nmethods, until we can figure out how to accomodate multi-valued\naggregation methods.\n\nChange-Id: I81cac6e5d008346a78625e895271f3a61a3fb8ec\n""}, {'number': 3, 'created': '2014-06-23 10:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e5fc32e4e677e1e66780782816351832c0bacefb', 'message': ""Allow more than 2 measurements per entity to be stored\n\nTL;DR: gnocchi timeseries deserialization logic does not\n       account for multi-valued aggregation methods\n\nOn POSTing the third measurement to an entity, the creation of\nthe pandas Timestamp from the deseralized blob retrieved from\nswift fails with:\n\n    ValueError: Unable to parse high\n\nwhen attempting to parse what it expects to be a timestamp.\n\nThis occurs as a result of the open-high-low-close aggregate\nnot acting as expected in terms of producing a *single*\naggregated value per period. Instead there are 4 separate\naggregated valued involved: 'high', 'close', 'open' & 'low'.\n\nSo after the third datapoint is stored, the stored data for\nohlc is no longer just a simple dict mapping timestamps to\ntheir corresponding values, as expected by the deserialization\nlogic.\n\nInstead there are are also 'high', 'close', 'open' & 'low'\nkeys in the dict, e.g.:\n\n  [{u'aggregation_method': u'ohlc',\n    u'values': {u'high': 32.0,\n                u'close': 32.0,\n                u'open': 32.0,\n                u'low': 32.0,\n                u'2013-01-01 23:23:31+00:00': 31.0},\n    u'max_size': 3600,\n    u'sampling': u'60S'}]\n\nFor now, we remove 'ohlc' from the set of supported aggregation\nmethods, until we can figure out how to accomodate multi-valued\naggregation methods.\n\nChange-Id: I81cac6e5d008346a78625e895271f3a61a3fb8ec\n""}, {'number': 4, 'created': '2014-06-23 10:34:05.000000000', 'files': ['gnocchi/storage/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/40f47796bcdaa8d52c99987479a725c8758882f7', 'message': ""Allow more than 2 measurements per entity to be stored\n\nTL;DR: gnocchi timeseries deserialization logic does not\n       account for multi-valued aggregation methods\n\nOn POSTing the third measurement to an entity, the creation of\nthe pandas Timestamp from the deseralized blob retrieved from\nswift fails with:\n\n    ValueError: Unable to parse high\n\nwhen attempting to parse what it expects to be a timestamp.\n\nThis occurs as a result of the open-high-low-close aggregate\nnot acting as expected in terms of producing a *single*\naggregated value per period. Instead there are 4 separate\naggregated valued involved: 'high', 'close', 'open' & 'low'.\n\nSo after the third datapoint is stored, the stored data for\nohlc is no longer just a simple dict mapping timestamps to\ntheir corresponding values, as expected by the deserialization\nlogic.\n\nInstead there are are also 'high', 'close', 'open' & 'low'\nkeys in the dict, e.g.:\n\n  [{u'aggregation_method': u'ohlc',\n    u'values': {u'high': 32.0,\n                u'close': 32.0,\n                u'open': 32.0,\n                u'low': 32.0,\n                u'2013-01-01 23:23:31+00:00': 31.0},\n    u'max_size': 3600,\n    u'sampling': u'60S'}]\n\nFor now, we remove 'ohlc' from the set of supported aggregation\nmethods, until we can figure out how to accomodate multi-valued\naggregation methods.\n\nChange-Id: I81cac6e5d008346a78625e895271f3a61a3fb8ec\n""}]",1,101780,40f47796bcdaa8d52c99987479a725c8758882f7,18,6,4,2284,,,0,"Allow more than 2 measurements per entity to be stored

TL;DR: gnocchi timeseries deserialization logic does not
       account for multi-valued aggregation methods

On POSTing the third measurement to an entity, the creation of
the pandas Timestamp from the deseralized blob retrieved from
swift fails with:

    ValueError: Unable to parse high

when attempting to parse what it expects to be a timestamp.

This occurs as a result of the open-high-low-close aggregate
not acting as expected in terms of producing a *single*
aggregated value per period. Instead there are 4 separate
aggregated valued involved: 'high', 'close', 'open' & 'low'.

So after the third datapoint is stored, the stored data for
ohlc is no longer just a simple dict mapping timestamps to
their corresponding values, as expected by the deserialization
logic.

Instead there are are also 'high', 'close', 'open' & 'low'
keys in the dict, e.g.:

  [{u'aggregation_method': u'ohlc',
    u'values': {u'high': 32.0,
                u'close': 32.0,
                u'open': 32.0,
                u'low': 32.0,
                u'2013-01-01 23:23:31+00:00': 31.0},
    u'max_size': 3600,
    u'sampling': u'60S'}]

For now, we remove 'ohlc' from the set of supported aggregation
methods, until we can figure out how to accomodate multi-valued
aggregation methods.

Change-Id: I81cac6e5d008346a78625e895271f3a61a3fb8ec
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/80/101780/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/__init__.py', 'gnocchi/tests/test_rest.py']",2,1089faf5b2be324c6a0eebc3c743bbde2e466731,," def test_add_multiple_measures_per_entity(self): result = self.app.post_json(""/v1/entity"", params={""archives"": [(5, 60), (60, 60)]}) entity = jsonutils.loads(result.body) for x in xrange(5): result = self.app.post_json( ""/v1/entity/%s/measures"" % entity['id'], params=[{""timestamp"": '2013-01-01 23:23:2%d' % x, ""value"": 1234.2 + x}]) self.assertEqual(result.status_code, 204) ",,16,1
openstack%2Fheat~master~Idb5f19ca3c79c787107209ff3a5e4bd723533582,openstack/heat,master,Idb5f19ca3c79c787107209ff3a5e4bd723533582,Add 'query' property to Ceilometer Alarm resource,ABANDONED,2014-06-06 08:32:06.000000000,2014-06-23 11:18:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8246}, {'_account_id': 8435}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-06 08:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f184d37f67db15c80d8ee02e0f8c498e4a8cfb97', 'message': ""Add 'query' property to Ceilometer Alarm resource\n\nThis patch adds support to 'query' parameter required by newer\nCeilometer API, while deprecates the 'matching_metadata' property.\n\nChange-Id: Idb5f19ca3c79c787107209ff3a5e4bd723533582\nCLoses-Bug: #1326721\n""}, {'number': 2, 'created': '2014-06-06 08:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1e223d8de33ce5f1ecb3b3c8ed2316c1ae6b3df7', 'message': ""Add 'query' property to Ceilometer Alarm resource\n\nThis patch adds support to 'query' parameter required by newer\nCeilometer API, while deprecates the 'matching_metadata' property.\n\nChange-Id: Idb5f19ca3c79c787107209ff3a5e4bd723533582\nCloses-Bug: #1326721\n""}, {'number': 3, 'created': '2014-06-06 10:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97efdfaefa3b85a8213d7a46d287eedeb5c78c67', 'message': ""Add 'query' property to Ceilometer Alarm resource\n\nThis patch adds support to 'query' parameter required by newer\nCeilometer API, while deprecates the 'matching_metadata' property.\n\nChange-Id: Idb5f19ca3c79c787107209ff3a5e4bd723533582\nCloses-Bug: #1326721\n""}, {'number': 4, 'created': '2014-06-06 11:47:02.000000000', 'files': ['heat/engine/resources/ceilometer/alarm.py', 'heat/tests/test_ceilometer_alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e4a9315d665bf8e87fa573b972962675a32c0e9d', 'message': ""Add 'query' property to Ceilometer Alarm resource\n\nThis patch adds support to 'query' parameter required by newer\nCeilometer API, while deprecates the 'matching_metadata' property.\n\nChange-Id: Idb5f19ca3c79c787107209ff3a5e4bd723533582\nCloses-Bug: #1326721\n""}]",0,98327,e4a9315d665bf8e87fa573b972962675a32c0e9d,21,5,4,8246,,,0,"Add 'query' property to Ceilometer Alarm resource

This patch adds support to 'query' parameter required by newer
Ceilometer API, while deprecates the 'matching_metadata' property.

Change-Id: Idb5f19ca3c79c787107209ff3a5e4bd723533582
Closes-Bug: #1326721
",git fetch https://review.opendev.org/openstack/heat refs/changes/27/98327/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/ceilometer/alarm.py'],1,f184d37f67db15c80d8ee02e0f8c498e4a8cfb97,bug/1326721,"from heat.engine import support STATISTIC, THRESHOLD, MATCHING_METADATA, QUERY, 'statistic', 'threshold', 'matching_metadata', 'query', 'additionally to the meter_name. '), support_status=support.SupportStatus( support.DEPRECATED, _('Use property %s.') % QUERY) ), QUERY: properties.Schema( properties.Schema.STRING, _('A query string containing a semicolon delimited list, ' 'where each list item is of format ""key[op]data_type::value"".'),"," STATISTIC, THRESHOLD, MATCHING_METADATA, 'statistic', 'threshold', 'matching_metadata', 'additionally to the meter_name.')",12,3
openstack%2Fsolum~master~I7164dcc5a7f018e7ede64777e6a1a6287b6b7546,openstack/solum,master,I7164dcc5a7f018e7ede64777e6a1a6287b6b7546,Add a catalog of local files,MERGED,2014-06-16 13:29:41.000000000,2014-06-23 11:17:36.000000000,2014-06-23 11:17:36.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 8334}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-06-16 13:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/676fb50a3db79bc21500dbe31253318e696ab20c', 'message': 'Add a catalog of local files\n\nChange-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546\n'}, {'number': 2, 'created': '2014-06-17 02:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/57b8a1de0bc0d0c44db02d4beaddb1e2c7f597ef', 'message': 'Add a catalog of local files\n\nChange-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546\n'}, {'number': 3, 'created': '2014-06-18 11:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1e7ec0ad4329586ee7fe2785d4f23bffe5aff28a', 'message': 'Add a catalog of local files\n\nChange-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546\n'}, {'number': 4, 'created': '2014-06-19 11:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0e65044a08f7c61f8eccd509bf39ecbfb9aec692', 'message': 'Add a catalog of local files\n\nChange-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546\n'}, {'number': 5, 'created': '2014-06-23 01:36:51.000000000', 'files': ['solum/tests/common/test_catalog.py', 'solum/tests/deployer/handlers/test_heat.py', 'solum/deployer/handlers/heat.py', 'solum/common/catalog.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/6bfee666b129ad0ecbec6e5a0aa05212177003f7', 'message': 'Add a catalog of local files\n\nChange-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546\n'}]",5,100249,6bfee666b129ad0ecbec6e5a0aa05212177003f7,31,6,5,4715,,,0,"Add a catalog of local files

Change-Id: I7164dcc5a7f018e7ede64777e6a1a6287b6b7546
",git fetch https://review.opendev.org/openstack/solum refs/changes/49/100249/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/deployer/handlers/heat.py', 'solum/common/catalog.py']",2,676fb50a3db79bc21500dbe31253318e696ab20c,new-api,"# Copyright 2014 - Rackspace Hosting. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import os.path def get(name, type_name, content_type='yaml'): """"""This reads a file's contents from local storage. /etc/solum/<type_name>/name.<content_type> """""" proj_dir = os.path.join(os.path.dirname(__file__), '..', '..') file_path = os.path.join(proj_dir, 'etc', 'solum', type_name, '%s.%s' % (name, content_type)) with open(file_path) as fd: return fd.read() ",,29,9
openstack%2Fceilometer~master~Iaedf083a97d0b9b442c7c52d9950833ead7f64bc,openstack/ceilometer,master,Iaedf083a97d0b9b442c7c52d9950833ead7f64bc,Fixed connection pooling in tests,ABANDONED,2014-04-28 20:01:23.000000000,2014-06-23 11:10:59.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 7478}, {'_account_id': 7763}, {'_account_id': 9708}, {'_account_id': 10987}]","[{'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d32f1a9dda3d4a6c596290107498e650d1a5580a', 'message': 'Fixed connection pooling in tests\n\nWe need to disable connection pool for tests to fix connections leaks\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/51cecd477fb86021d2255936c3747ce393527c20', 'message': 'Fixed connection pooling in tests\n\nWe need to disable connection pool for tests to fix connections leaks\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/397bec488966a45fcd49a9e14d55d1520f66cdbb', 'message': 'Fixed connection pooling in tests\n\nWe need to disable connection pool for tests to fix connections leaks\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ef5b33d4cf04b185995887acd18faf9ddba8b297', 'message': 'Fixed connection pooling in tests\n\nWe need to disable connection pool for tests to fix connections leaks\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': ['ceilometer/tests/db.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bf05c520dfb9f5a19d67762874257f5af584d6ff', 'message': 'Fixed connection pooling in tests\n\nWe need to disable connection pool for tests to fix connections leaks\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc\n'}]",4,73062,bf05c520dfb9f5a19d67762874257f5af584d6ff,39,7,5,7763,,,0,"Fixed connection pooling in tests

We need to disable connection pool for tests to fix connections leaks

Related to blueprint sql-unit-tests-on-real-backend

Change-Id: Iaedf083a97d0b9b442c7c52d9950833ead7f64bc
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/62/73062/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/db.py'],1,d32f1a9dda3d4a6c596290107498e650d1a5580a,bp/sql-unit-tests-on-real-backend,"import sqlalchemy.poolimport ceilometer.openstack.common.db.sqlalchemy.session as oslo_sessionimport ceilometer.storage.impl_sqlalchemy as sqlclass SQLTestConnection(sql.Connection): def __init__(self, conf): """"""Use engine with pooling disabled to prevent connections leak """""" print(""OPEN a new DB connection!!!"") self._engine = sqlalchemy.create_engine( conf.database.connection, poolclass=sqlalchemy.pool.NullPool) self._maker = oslo_session.get_maker(self._engine) self.is_sqla_database = None for sql_base in ['mysql', 'postgresql']: if sql_base in self.CONF.database.connection: self.is_sqla_database = sql_base break if self.is_sqla_database: self.conn = SQLTestConnection(self.CONF) else: self.conn = storage.get_connection(self.CONF)", self.conn = storage.get_connection(self.CONF),25,1
openstack%2Fos-loganalyze~master~Ia482f90e1461133ba02f8274577ab1e15932ad3c,openstack/os-loganalyze,master,Ia482f90e1461133ba02f8274577ab1e15932ad3c,add support for linking in grenade logs,MERGED,2014-06-19 13:56:16.000000000,2014-06-23 11:07:00.000000000,2014-06-23 11:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-19 13:56:16.000000000', 'files': ['os_loganalyze/wsgi.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/09d84e412c9e81649280090dc3a1233389a3d6fe', 'message': 'add support for linking in grenade logs\n\nChange-Id: Ia482f90e1461133ba02f8274577ab1e15932ad3c\n'}]",0,101209,09d84e412c9e81649280090dc3a1233389a3d6fe,9,2,1,2750,,,0,"add support for linking in grenade logs

Change-Id: Ia482f90e1461133ba02f8274577ab1e15932ad3c
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/09/101209/1 && git format-patch -1 --stdout FETCH_HEAD,['os_loganalyze/wsgi.py'],1,09d84e412c9e81649280090dc3a1233389a3d6fe,97863,SUPPORTS_SEV = ( '(screen-(n-|c-|q-|g-|h-|ir-|ceil|key|sah)' # openstack screen logs '|grenade.sh|tempest\.txt|syslog)') # other things we understand,SUPPORTS_SEV = '(screen-(n-|c-|q-|g-|h-|ir-|ceil|key|sah)|tempest\.txt|syslog)',3,1
openstack%2Fos-loganalyze~master~Id163660ec3b947f2d0cdd22e458de1e24db266ae,openstack/os-loganalyze,master,Id163660ec3b947f2d0cdd22e458de1e24db266ae,support date linking in syslog,MERGED,2014-06-09 19:29:11.000000000,2014-06-23 11:06:54.000000000,2014-06-23 11:06:54.000000000,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-06-09 19:29:11.000000000', 'files': ['os_loganalyze/wsgi.py', 'os_loganalyze/tests/test_filters.py', 'os_loganalyze/tests/samples/screen-key.txt.gz', 'os_loganalyze/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/a337c26778fd05f486c851f83f1d5167a7f709fb', 'message': 'support date linking in syslog\n\n... and remove all the antiquated keystone log format gorp as\nthis makes the syslog date matching a bit simpler.\n\nChange-Id: Id163660ec3b947f2d0cdd22e458de1e24db266ae\n'}]",0,98867,a337c26778fd05f486c851f83f1d5167a7f709fb,9,2,1,2750,,,0,"support date linking in syslog

... and remove all the antiquated keystone log format gorp as
this makes the syslog date matching a bit simpler.

Change-Id: Id163660ec3b947f2d0cdd22e458de1e24db266ae
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/67/98867/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_loganalyze/wsgi.py', 'os_loganalyze/tests/test_filters.py', 'os_loganalyze/tests/samples/screen-key.txt.gz', 'os_loganalyze/tests/test_wsgi.py']",4,a337c26778fd05f486c851f83f1d5167a7f709fb,97863," }, gen = self.get_generator('screen-c-api.txt.gz', html=False) gen = self.get_generator('screen-c-api.txt.gz', html=False)"," 'screen-key.txt.gz': { 'TOTAL': 144983, 'DEBUG': 129842, # there is curiousness in the fact that keystone logs have a lot # of blank lines, so INFO is higher than you think it should be 'INFO': 15131, 'AUDIT': 0, 'WARNING': 6, 'TRACE': 0, 'ERROR': 0 }, } gen = self.get_generator('screen-key.txt.gz', html=False) gen = self.get_generator('screen-key.txt.gz', html=False)",13,42
openstack%2Ffuel-ostf~master~I4b8c6d956f6447f34257b7e7d24652d087efbefd,openstack/fuel-ostf,master,I4b8c6d956f6447f34257b7e7d24652d087efbefd,Increased timeout for Heat OSTF test,ABANDONED,2014-06-19 09:20:51.000000000,2014-06-23 11:03:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 8782}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-06-19 09:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/8c8f10a6407ee652e37988c7ff3807273c233f5c', 'message': 'Increased timeout for Heat OSTF test\n\nWe had small timeout for Heat stack creation operation\nand this commit will fix it to 10 minutes. Heat stack\nwith small image should be created for this time on any\nenvironments, even with small amount of RAM.\n\nChange-Id: I4b8c6d956f6447f34257b7e7d24652d087efbefd\nCloses-Bug: #1331472\n'}, {'number': 2, 'created': '2014-06-19 12:39:13.000000000', 'files': ['fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/tests/platform_tests/test_heat.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/f78f2c88a6295aef780a341ed93423b7333d28b1', 'message': 'Increased timeout for Heat OSTF test\n\nWe had small timeout for Heat stack creation operation\nand this commit will fix it to 10 minutes. Heat stack\nwith small image should be created for this time on any\nenvironments, even with small amount of RAM.\n\nChange-Id: I4b8c6d956f6447f34257b7e7d24652d087efbefd\nCloses-Bug: #1331472\n'}]",1,101142,f78f2c88a6295aef780a341ed93423b7333d28b1,17,7,2,7227,,,0,"Increased timeout for Heat OSTF test

We had small timeout for Heat stack creation operation
and this commit will fix it to 10 minutes. Heat stack
with small image should be created for this time on any
environments, even with small amount of RAM.

Change-Id: I4b8c6d956f6447f34257b7e7d24652d087efbefd
Closes-Bug: #1331472
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/42/101142/2 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/platform_tests/test_heat.py'],1,8c8f10a6407ee652e37988c7ff3807273c233f5c,(detached," Duration: 640 s. self.verify(600, self._wait_for_stack_status, 2,","# vim: tabstop=4 shiftwidth=4 softtabstop=4 Duration: 440 s. self.verify(100, self._wait_for_stack_status, 2,",2,4
openstack%2Fnova~master~Ifac013077e7948a3d5d012569cb1c13c273d5d35,openstack/nova,master,Ifac013077e7948a3d5d012569cb1c13c273d5d35,Use six.moves to import cPickle,ABANDONED,2014-06-06 10:49:56.000000000,2014-06-23 10:55:47.000000000,,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 167}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-06 10:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4367761f49a401e4d9438dcc9e37663c05289182', 'message': 'except ImportError when importing cPickle on Python3\n\ncPickle is not available with Python3. With Python3 the standard\nversion should be imported.\n\nChange-Id: Ifac013077e7948a3d5d012569cb1c13c273d5d35\n'}, {'number': 2, 'created': '2014-06-06 12:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/617f75d6b15314cd8fcbc04d20dfacaeb4ef4a85', 'message': 'except ImportError when importing cPickle on Python3\n\ncPickle is not available with Python3. With Python3 the standard\nversion should be imported.\n\nChange-Id: Ifac013077e7948a3d5d012569cb1c13c273d5d35\n'}, {'number': 3, 'created': '2014-06-10 14:23:18.000000000', 'files': ['nova/virt/xenapi/client/session.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/337e558f490eab9d5b803af9f2bd57319b3830d9', 'message': 'Use six.moves to import cPickle\n\ncPickle is not available with Python3. With Python3 the standard\nversion should be imported.\n\nChange-Id: Ifac013077e7948a3d5d012569cb1c13c273d5d35\n'}]",1,98366,337e558f490eab9d5b803af9f2bd57319b3830d9,33,10,3,167,,,0,"Use six.moves to import cPickle

cPickle is not available with Python3. With Python3 the standard
version should be imported.

Change-Id: Ifac013077e7948a3d5d012569cb1c13c273d5d35
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/98366/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/client/session.py', 'plugins/xenserver/xenapi/etc/xapi.d/plugins/utils.py']",2,4367761f49a401e4d9438dcc9e37663c05289182,fix_pickle_import,try: import cPickle as pickle except ImportError import pickle,import cPickle as pickle,8,2
openstack%2Fnova~master~I228a7597732d8f775cdc879b2bf018a0d57229bf,openstack/nova,master,I228a7597732d8f775cdc879b2bf018a0d57229bf,Use import from six.moves to import the queue module,ABANDONED,2014-06-07 16:29:56.000000000,2014-06-23 10:54:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 167}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9380}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-07 16:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6d197bc44091f7d67a8ff8bcf1416d4d4f9243a', 'message': 'Use import from six.moves to import the queue module\n\nThe name of the synchronized queue class is queue instead of\nQueue in Python3.\n\nChange-Id: I228a7597732d8f775cdc879b2bf018a0d57229bf\n'}, {'number': 2, 'created': '2014-06-07 19:12:39.000000000', 'files': ['nova/cmd/baremetal_deploy_helper.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/665de7a2b016108c75e422a9353424e4eb151cec', 'message': 'Use import from six.moves to import the queue module\n\nThe name of the synchronized queue class is queue instead of\nQueue in Python3.\n\nChange-Id: I228a7597732d8f775cdc879b2bf018a0d57229bf\n'}]",0,98592,665de7a2b016108c75e422a9353424e4eb151cec,29,11,2,167,,,0,"Use import from six.moves to import the queue module

The name of the synchronized queue class is queue instead of
Queue in Python3.

Change-Id: I228a7597732d8f775cdc879b2bf018a0d57229bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/98592/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/cmd/baremetal_deploy_helper.py'],1,a6d197bc44091f7d67a8ff8bcf1416d4d4f9243a,rename_six_queue,from six.moves import queueQUEUE = queue.Queue() except queue.Empty:,import QueueQUEUE = Queue.Queue() except Queue.Empty:,3,3
openstack%2Fnova~master~If52bc92b6ad16cde7d3a2513e0bd76a2e29a10b1,openstack/nova,master,If52bc92b6ad16cde7d3a2513e0bd76a2e29a10b1,Use import from six.moves to import the built-in objects,ABANDONED,2014-06-07 18:45:52.000000000,2014-06-23 10:54:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 167}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-07 18:45:52.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_versions.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1155c0ca4fca7a1802a36d9b474fd6a34c2cd18b', 'message': 'Use import from six.moves to import the built-in objects\n\nThe name of the built-in objects class is buildins instead of\n__builtins__ in Python3.\n\nChange-Id: If52bc92b6ad16cde7d3a2513e0bd76a2e29a10b1\n'}]",0,98594,1155c0ca4fca7a1802a36d9b474fd6a34c2cd18b,15,8,1,167,,,0,"Use import from six.moves to import the built-in objects

The name of the built-in objects class is buildins instead of
__builtins__ in Python3.

Change-Id: If52bc92b6ad16cde7d3a2513e0bd76a2e29a10b1
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/98594/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/tests/virt/xenapi/test_vm_utils.py', 'nova/tests/test_versions.py', 'nova/tests/test_utils.py']",4,1155c0ca4fca7a1802a36d9b474fd6a34c2cd18b,six_rename_builtin,import six.moves.builtins as __builtin__,import __builtin__,4,4
openstack%2Fnova~master~I3ecf92ae276b368ef2d7a74047f61d7e1f58fa29,openstack/nova,master,I3ecf92ae276b368ef2d7a74047f61d7e1f58fa29,Use import from six.moves to import the httplib module,ABANDONED,2014-06-10 14:45:02.000000000,2014-06-23 10:54:22.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-10 14:45:02.000000000', 'files': ['nova/virt/vmwareapi/read_write_util.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/tests/api/ec2/test_api.py', 'nova/tests/virt/vmwareapi/test_read_write_util.py', 'nova/api/openstack/compute/limits.py', 'nova/tests/api/openstack/compute/test_limits.py', 'nova/tests/integrated/api/client.py', 'nova/scheduler/filters/trusted_filter.py', 'nova/virt/vmwareapi/vim.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2f297e41fac9e6b44ba9a973c0236bc79396b125', 'message': 'Use import from six.moves to import the httplib module\n\nThe name of the httplib module is http.client instead of\nhttplib in Python3.\n\nChange-Id: I3ecf92ae276b368ef2d7a74047f61d7e1f58fa29\n'}]",0,99105,2f297e41fac9e6b44ba9a973c0236bc79396b125,10,7,1,167,,,0,"Use import from six.moves to import the httplib module

The name of the httplib module is http.client instead of
httplib in Python3.

Change-Id: I3ecf92ae276b368ef2d7a74047f61d7e1f58fa29
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/99105/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/read_write_util.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/tests/api/ec2/test_api.py', 'nova/tests/virt/vmwareapi/test_read_write_util.py', 'nova/api/openstack/compute/limits.py', 'nova/tests/api/openstack/compute/test_limits.py', 'nova/tests/integrated/api/client.py', 'nova/scheduler/filters/trusted_filter.py', 'nova/virt/vmwareapi/vim.py']",9,2f297e41fac9e6b44ba9a973c0236bc79396b125,six_http_client,from six.moves import http_client as httplib,import httplib,9,11
openstack%2Ftrove~master~I4b32078b7538c3af8bd453c79dc2ca4c7264cbf0,openstack/trove,master,I4b32078b7538c3af8bd453c79dc2ca4c7264cbf0,Pick a performant innodb_flush_log_at_trx_commit default,ABANDONED,2014-05-12 13:49:32.000000000,2014-06-23 10:47:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-12 13:49:32.000000000', 'files': ['trove/templates/mysql/config.template', 'trove/templates/percona/config.template'], 'web_link': 'https://opendev.org/openstack/trove/commit/67f066b571064c0b0d8a5ccbe8f270c139a5e8f7', 'message': 'Pick a performant innodb_flush_log_at_trx_commit default\n\nUsers that want commit-level safety can opt-in, but\nwe should give people a good experience out-of-the-box.\n\nTo opt-in for slow-but-safe mode: override innodb_flush_log_at_trx_commit=1\n\nChange-Id: I4b32078b7538c3af8bd453c79dc2ca4c7264cbf0\n'}]",2,93305,67f066b571064c0b0d8a5ccbe8f270c139a5e8f7,16,5,1,144,,,0,"Pick a performant innodb_flush_log_at_trx_commit default

Users that want commit-level safety can opt-in, but
we should give people a good experience out-of-the-box.

To opt-in for slow-but-safe mode: override innodb_flush_log_at_trx_commit=1

Change-Id: I4b32078b7538c3af8bd453c79dc2ca4c7264cbf0
",git fetch https://review.opendev.org/openstack/trove refs/changes/05/93305/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/templates/mysql/config.template', 'trove/templates/percona/config.template']",2,67f066b571064c0b0d8a5ccbe8f270c139a5e8f7,mysql_perf_by_default,innodb_flush_log_at_trx_commit=2,,2,0
openstack%2Ftrove~master~I1534237b5ac76fa4a57bd79cd2af80477badca86,openstack/trove,master,I1534237b5ac76fa4a57bd79cd2af80477badca86,replace string format arguments with function parameters,ABANDONED,2014-05-19 15:56:33.000000000,2014-06-23 10:45:37.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-05-19 15:56:33.000000000', 'files': ['trove/tests/fakes/swift.py', 'trove/guestagent/backup/backupagent.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/ed674d54cd8d896ee11f1addd389e6ac283beca8', 'message': 'replace string format arguments with function parameters\n\nThere are files containing string format arguments inside\nlogging messages. Using logging function parameters should\nbe preferred.\n\nChange-Id: I1534237b5ac76fa4a57bd79cd2af80477badca86\nCloses-Bug: #1320925\n'}]",0,94214,ed674d54cd8d896ee11f1addd389e6ac283beca8,17,7,1,167,,,0,"replace string format arguments with function parameters

There are files containing string format arguments inside
logging messages. Using logging function parameters should
be preferred.

Change-Id: I1534237b5ac76fa4a57bd79cd2af80477badca86
Closes-Bug: #1320925
",git fetch https://review.opendev.org/openstack/trove refs/changes/14/94214/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/fakes/swift.py', 'trove/guestagent/backup/backupagent.py']",2,ed674d54cd8d896ee11f1addd389e6ac283beca8,logging_should_be_lazy," LOG.info(_(""Running backup %(id)s""), backup_info) LOG.info(_(""Using incremental runner: %s""), runner.__name__) ""%(success)s""), backup) ""%(checksum)s""), backup) ""%(location)s""), backup) LOG.exception(_(""Error saving %(backup_id)s Backup""), LOG.exception(_(""Error running backup: %(backup_id)s""), backup) LOG.info(_(""Saving %(backup_id)s Backup Info to model""), backup)"," LOG.info(_(""Running backup %(id)s"") % backup_info) LOG.info(_(""Using incremental runner: %s"") % runner.__name__) ""%(success)s"") % backup) ""%(checksum)s"") % backup) ""%(location)s"") % backup) LOG.exception(_(""Error saving %(backup_id)s Backup"") % LOG.exception(_(""Error running backup: %(backup_id)s"") % backup) LOG.info(_(""Saving %(backup_id)s Backup Info to model"") % backup)",16,16
openstack%2Ftrove~master~I3ee387538e6d10bf67ba175215ac0bc142db3b68,openstack/trove,master,I3ee387538e6d10bf67ba175215ac0bc142db3b68,Instance should not come ACTIVE for prepare method fail,ABANDONED,2014-01-24 10:52:11.000000000,2014-06-23 10:44:59.000000000,,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 7092}, {'_account_id': 8309}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 10139}]","[{'number': 1, 'created': '2014-01-24 10:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/aa3297ffba8c6a952eb6dd49aa09672589f8099a', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 2, 'created': '2014-01-24 10:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/93a117b7abcebe01c2a4bf3eae94f475a303ee88', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 3, 'created': '2014-01-24 11:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/72e79f1db1df5bbbf6c86f17e89274412cc83a86', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 4, 'created': '2014-01-24 19:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6331a9242a68171a4742ca36956e4ff2a4028679', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 5, 'created': '2014-01-24 19:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/afa9322dff4ad83fe16ca8c62a91aa6700a3946a', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 6, 'created': '2014-03-07 11:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9576bab5324f42262ff6ab021d58c8e3504574d9', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 7, 'created': '2014-03-07 11:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/794dae08584194f2f05ddc29b1255eca434038b0', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 8, 'created': '2014-03-07 11:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3c0b1e05b950f686ed168f7b8044ba6351395dc7', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 9, 'created': '2014-04-04 12:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ee56bc9208788c20e6eef49340c086e0cc029789', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}, {'number': 10, 'created': '2014-06-02 11:12:33.000000000', 'files': ['trove/guestagent/datastore/mysql/manager.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/c6cbfe874d30b41da160eb27970b428e377a4541', 'message': 'Instance should not come ACTIVE for prepare method fail\n\nReasons:\n- If in any case prepare method fails like while calling\n  stop_db, start_mysql etc methods and related error/exception\n  is not handled then in that case also instance comes ACTIVE.\n\nChanges:\n- put try-except block to handle and set machine status as FAILED.\n\nChange-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68\nCloses-Bug: #1272262\n'}]",9,68885,c6cbfe874d30b41da160eb27970b428e377a4541,100,9,10,8309,,,0,"Instance should not come ACTIVE for prepare method fail

Reasons:
- If in any case prepare method fails like while calling
  stop_db, start_mysql etc methods and related error/exception
  is not handled then in that case also instance comes ACTIVE.

Changes:
- put try-except block to handle and set machine status as FAILED.

Change-Id: I3ee387538e6d10bf67ba175215ac0bc142db3b68
Closes-Bug: #1272262
",git fetch https://review.opendev.org/openstack/trove refs/changes/85/68885/10 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/datastore/mysql/manager.py'],1,aa3297ffba8c6a952eb6dd49aa09672589f8099a,,"import sys try: MySqlAppStatus.get().begin_install() # status end_mysql_install set with secure() app = MySqlApp(MySqlAppStatus.get()) app.install_if_needed(packages) if device_path: #stop and do not update database app.stop_db() device = volume.VolumeDevice(device_path) device.format() if os.path.exists(CONF.mount_point): #rsync exiting data device.migrate_data(CONF.mount_point) #mount the volume device.mount(mount_point) LOG.debug(_(""Mounted the volume."")) app.start_mysql() if backup_info: self._perform_restore(backup_info, context, CONF.mount_point, app) LOG.info(_(""Securing mysql now."")) app.secure(config_contents) enable_root_on_restore = (backup_info and MySqlAdmin().is_root_enabled()) if root_password and not backup_info: app.secure_root(secure_remote_root=True) MySqlAdmin().enable_root(root_password) MySqlAdmin().report_root_enabled(context) elif enable_root_on_restore: app.secure_root(secure_remote_root=False) MySqlAdmin().report_root_enabled(context) else: app.secure_root(secure_remote_root=True) app.complete_install_or_restart() if databases: self.create_database(context, databases) if users: self.create_user(context, users) LOG.info('""prepare"" call has finished.') except Exception: e = sys.exc_info() LOG.error(""Prepare call failed to execute: %s"" % ("" "".join([str(each)for each in e]))) VerticaAppStatus.get().set_status(rd_instance. ServiceStatuses.FAILED) raise RuntimeError(""Prepare call failed to execute"") "," MySqlAppStatus.get().begin_install() # status end_mysql_install set with secure() app = MySqlApp(MySqlAppStatus.get()) app.install_if_needed(packages) if device_path: #stop and do not update database app.stop_db() device = volume.VolumeDevice(device_path) device.format() if os.path.exists(CONF.mount_point): #rsync exiting data device.migrate_data(CONF.mount_point) #mount the volume device.mount(mount_point) LOG.debug(_(""Mounted the volume."")) app.start_mysql() if backup_info: self._perform_restore(backup_info, context, CONF.mount_point, app) LOG.info(_(""Securing mysql now."")) app.secure(config_contents) enable_root_on_restore = (backup_info and MySqlAdmin().is_root_enabled()) if root_password and not backup_info: app.secure_root(secure_remote_root=True) MySqlAdmin().enable_root(root_password) MySqlAdmin().report_root_enabled(context) elif enable_root_on_restore: app.secure_root(secure_remote_root=False) MySqlAdmin().report_root_enabled(context) else: app.secure_root(secure_remote_root=True) app.complete_install_or_restart() if databases: self.create_database(context, databases) if users: self.create_user(context, users) LOG.info('""prepare"" call has finished.')",48,40
openstack%2Ftrove-integration~master~I492e2713ae761629f389866728891ccdac307841,openstack/trove-integration,master,I492e2713ae761629f389866728891ccdac307841,updating sources list as part of percona elements,ABANDONED,2014-04-28 16:33:13.000000000,2014-06-23 10:39:44.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6160}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 9782}]","[{'number': 1, 'created': '2014-04-28 16:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/5232de99aec6be153be454ecbd2f7fb538be5657', 'message': 'updating sources list as part of percona elements\n\nUpdate of sources list for percona apt repos, should be handled in percona elements\n\nChange-Id: I492e2713ae761629f389866728891ccdac307841\n'}, {'number': 2, 'created': '2014-04-30 23:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/416b25f704cc852f6fcc57bdbd99a462b580e8a3', 'message': 'updating sources list as part of percona elements\n\nUpdate of sources list for percona apt repos, should be handled in percona elements\n\nChange-Id: I492e2713ae761629f389866728891ccdac307841\n'}, {'number': 3, 'created': '2014-05-19 19:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/1f928ea966c9a6387a3239f47772a1b496a258ec', 'message': 'updating sources list as part of percona elements\n\nUpdate of sources list for percona apt repos, should be handled in percona elements\n\nChange-Id: I492e2713ae761629f389866728891ccdac307841\n'}, {'number': 4, 'created': '2014-05-19 19:04:03.000000000', 'files': ['scripts/files/elements/ubuntu-mysql/pre-install.d/50-percona-apt-source', 'scripts/files/elements/ubuntu-percona/pre-install.d/50-percona-apt-source'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/8d4877f203f9d9c25be692e2b362bded4f9f1cf3', 'message': 'updating sources list as part of percona elements\n\nUpdate of sources list for percona apt repos, should be handled in percona elements\n\nChange-Id: I492e2713ae761629f389866728891ccdac307841\n'}]",0,90791,8d4877f203f9d9c25be692e2b362bded4f9f1cf3,31,6,4,6160,,,0,"updating sources list as part of percona elements

Update of sources list for percona apt repos, should be handled in percona elements

Change-Id: I492e2713ae761629f389866728891ccdac307841
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/91/90791/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/files/elements/ubuntu-percona/pre-install.d/50-percona-server'],1,5232de99aec6be153be454ecbd2f7fb538be5657,ubuntu-percona-element,,,0,0
openstack%2Ffuel-library~master~Iac845c51cf538a70ca381041fca548149a0e66e9,openstack/fuel-library,master,Iac845c51cf538a70ca381041fca548149a0e66e9,"memcached, mysql, horizon and rabbit monitoring with zabbix",ABANDONED,2014-03-21 10:30:00.000000000,2014-06-23 10:12:51.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10392}]","[{'number': 1, 'created': '2014-03-21 10:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/52f73d8e291f8d06b53e0409520ee86d33c00f01', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-21 10:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ca94663dfe8bd969803f5f78eb7f8ed1d3dfb4ab', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}, {'number': 5, 'created': '2014-03-24 04:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c95ad274faa88c6bf33ce978552839ea1af802c7', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-03-24 04:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/929041b1c05a82fa5fdc8f0f4a76e529e6b141ed', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-24 04:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b6ac5ee40325b1c84b6f69fab1f603372794f449', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}, {'number': 6, 'created': '2014-05-26 07:28:46.000000000', 'files': ['deployment/puppet/zabbix/files/import/Template_App_MySQL.xml', 'deployment/puppet/zabbix/manifests/monitoring/horizon_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring/memcached_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_Memcache.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_RabbitMQ_ha.xml', 'deployment/puppet/zabbix/manifests/monitoring/rabbitmq_mon.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Horizon.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/manifests/monitoring/mysql_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_RabbitMQ.xml', 'deployment/puppet/zabbix/templates/.my.cnf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2e5bf834e686bd6548723591aef68a079eacf393', 'message': 'memcached, mysql, horizon and rabbit monitoring with zabbix\n\nChange-Id: Iac845c51cf538a70ca381041fca548149a0e66e9\nImplements: blueprint monitoring-system\n'}]",0,82049,2e5bf834e686bd6548723591aef68a079eacf393,39,4,6,10392,,,0,"memcached, mysql, horizon and rabbit monitoring with zabbix

Change-Id: Iac845c51cf538a70ca381041fca548149a0e66e9
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/49/82049/6 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/files/import/Template_App_MySQL.xml', 'deployment/puppet/zabbix/manifests/monitoring/horizon_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring/memcached_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_Memcache.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_RabbitMQ_ha.xml', 'deployment/puppet/zabbix/manifests/monitoring/rabbitmq_mon.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Horizon.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/manifests/monitoring/mysql_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_RabbitMQ.xml', 'deployment/puppet/zabbix/templates/.my.cnf.erb']",12,52f73d8e291f8d06b53e0409520ee86d33c00f01,bp/monitoring-system,"[client] user=<%= scope.lookupvar(""zabbix::params::db_user"") %> host=<%= scope.lookupvar(""zabbix::params::db_host"") %> password=<%= scope.lookupvar(""zabbix::params::db_password"") %> ",,3375,0
openstack%2Ffuel-library~master~I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b,openstack/fuel-library,master,I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b,Keystone monitoring with zabbix Glance monitoring with zabbix,ABANDONED,2014-03-20 10:39:26.000000000,2014-06-23 10:12:47.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-20 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cc25fedcd8f9e1a9b3faae593436d3be0e1ac060', 'message': 'Keystone monitoring with zabbix\nGlance monitoring with zabbix\n\nChange-Id: I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-20 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4aa4d6da465cf733f67f73183f1e07586d851b1b', 'message': 'Keystone monitoring with zabbix\nGlance monitoring with zabbix\n\nChange-Id: I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-20 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4272a5be33cf6041dd4c66e80497f0a2f18cf135', 'message': 'Keystone monitoring with zabbix\nGlance monitoring with zabbix\n\nChange-Id: I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-05-26 07:28:03.000000000', 'files': ['deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_Registry.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Keystone.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/manifests/monitoring/keystone_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_API.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Keystone_API_check.xml', 'deployment/puppet/zabbix/manifests/monitoring/glance_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_API_check.xml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8f676b6b971838c091f38e4828f9f8a56adcedd5', 'message': 'Keystone monitoring with zabbix\nGlance monitoring with zabbix\n\nChange-Id: I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b\nImplements: blueprint monitoring-system\n'}]",0,81765,8f676b6b971838c091f38e4828f9f8a56adcedd5,37,3,4,10392,,,0,"Keystone monitoring with zabbix
Glance monitoring with zabbix

Change-Id: I1fe9b044dccecb02430bb3dfd1ca3772b81dc57b
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/65/81765/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_Registry.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Keystone.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_API.xml', 'deployment/puppet/zabbix/manifests/monitoring/keystone_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Keystone_API_check.xml', 'deployment/puppet/zabbix/manifests/monitoring/glance_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Glance_API_check.xml']",9,cc25fedcd8f9e1a9b3faae593436d3be0e1ac060,bp/monitoring-system,"<?xml version=""1.0"" encoding=""UTF-8""?> <zabbix_export> <version>2.0</version> <date>2013-07-10T21:16:53Z</date> <groups> <group> <name>Templates</name> </group> </groups> <templates> <template> <template>Template App OpenStack Glance API check</template> <name>Template App OpenStack Glance API check</name> <groups> <group> <name>Templates</name> </group> </groups> <applications> <application> <name>Glance API check</name> </application> </applications> <items> <item> <name>Glance API test succeeded</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>glance.api.status</key> <delay>30</delay> <history>90</history> <trends>365</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>Glance API check</name> </application> </applications> <valuemap/> </item> </items> <discovery_rules/> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression>{Template App OpenStack Glance API check:glance.api.status.last(0)}=0</expression> <name>Glance API test failed on {HOST.NAME}</name> <url/> <status>0</status> <priority>4</priority> <description/> <type>0</type> <dependencies/> </trigger> </triggers> </zabbix_export> ",,745,0
openstack%2Ffuel-library~master~I07c15fd93274ddb3430a05926c3c222b1157adc4,openstack/fuel-library,master,I07c15fd93274ddb3430a05926c3c222b1157adc4,cinder and swift monitoring with zabbix,ABANDONED,2014-03-21 09:16:09.000000000,2014-06-23 10:12:43.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-21 09:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0716286e6cc0364b9622ca686f85ca826bdd6847', 'message': 'cinder and swift monitoring with zabbix\n\nChange-Id: I07c15fd93274ddb3430a05926c3c222b1157adc4\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-21 09:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2e0d29354ab8245c216ab6a39757ac6fcebe687f', 'message': 'cinder and swift monitoring with zabbix\n\nChange-Id: I07c15fd93274ddb3430a05926c3c222b1157adc4\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-21 09:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/103a42a50f68434a3969bfb1402428316a9701c6', 'message': 'cinder and swift monitoring with zabbix\n\nChange-Id: I07c15fd93274ddb3430a05926c3c222b1157adc4\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-05-26 07:28:25.000000000', 'files': ['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_API.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Proxy.xml', 'deployment/puppet/zabbix/manifests/monitoring/cinder_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring/swift_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Account.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Container.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_API_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_Scheduler.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_Volume.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Object.xml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89c59f4e684ec155b7b8edee98f78f403f00c7ab', 'message': 'cinder and swift monitoring with zabbix\n\nChange-Id: I07c15fd93274ddb3430a05926c3c222b1157adc4\nImplements: blueprint monitoring-system\n'}]",0,82036,89c59f4e684ec155b7b8edee98f78f403f00c7ab,49,3,4,10392,,,0,"cinder and swift monitoring with zabbix

Change-Id: I07c15fd93274ddb3430a05926c3c222b1157adc4
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/36/82036/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_API.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Proxy.xml', 'deployment/puppet/zabbix/manifests/monitoring/cinder_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring/swift_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Account.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Container.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_API_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_Scheduler.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Cinder_Volume.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Swift_Object.xml']",12,0716286e6cc0364b9622ca686f85ca826bdd6847,bp/monitoring-system,"<?xml version=""1.0"" encoding=""UTF-8""?> <zabbix_export> <version>2.0</version> <date>2013-07-10T21:22:38Z</date> <groups> <group> <name>Templates</name> </group> </groups> <templates> <template> <template>Template App OpenStack Swift Object</template> <name>Template App OpenStack Swift Object</name> <groups> <group> <name>Templates</name> </group> </groups> <applications> <application> <name>Swift Object</name> </application> </applications> <items> <item> <name>Swift Object Replicator process is running</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>proc.num[python,swift,,swift-object-replicator]</key> <delay>30</delay> <history>90</history> <trends>365</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>Swift Object</name> </application> </applications> <valuemap/> </item> <item> <name>Swift Object Server is listening on port</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>net.tcp.service[http,{$IP_STORAGE},6000]</key> <delay>30</delay> <history>90</history> <trends>365</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>Swift Object</name> </application> </applications> <valuemap/> </item> <item> <name>Swift Object Server process is running</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>proc.num[python,swift,,swift-object-server]</key> <delay>30</delay> <history>90</history> <trends>365</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>Swift Object</name> </application> </applications> <valuemap/> </item> </items> <discovery_rules/> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression>{Template App OpenStack Swift Object:proc.num[python,swift,,swift-object-replicator].last(0)}=0</expression> <name>Swift Object Replicator process is not running on {HOST.NAME}</name> <url/> <status>0</status> <priority>4</priority> <description/> <type>0</type> <dependencies/> </trigger> <trigger> <expression>{Template App OpenStack Swift Object:proc.num[python,swift,,swift-object-server].last(0)}=0</expression> <name>Swift Object Server process is not running on {HOST.NAME}</name> <url/> <status>0</status> <priority>4</priority> <description/> <type>0</type> <dependencies/> </trigger> <trigger> <expression>{Template App OpenStack Swift Object:net.tcp.service[http,{$IP_STORAGE},6000].last(0)}=0</expression> <name>Swift Object Server service is down on {HOST.NAME}</name> <url/> <status>0</status> <priority>4</priority> <description/> <type>0</type> <dependencies/> </trigger> </triggers> </zabbix_export> ",,1171,0
openstack%2Ffuel-library~master~I75ae6376e3f6a639c39e991ddf46d5ef68197f1b,openstack/fuel-library,master,I75ae6376e3f6a639c39e991ddf46d5ef68197f1b,misc services monitoring with zabbix,ABANDONED,2014-03-21 10:57:01.000000000,2014-06-23 10:12:39.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 3, 'created': '2014-03-21 10:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/27d43b13cae36a3fe816beba014c6d90aa7f91d0', 'message': 'misc services monitoring with zabbix\n\nhaproxy, zabbix server, firewall, virtual openstack cluster\n\nChange-Id: I75ae6376e3f6a639c39e991ddf46d5ef68197f1b\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-21 10:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/910fdf58c763500502f626c8d5d67ba927694efa', 'message': 'misc services monitoring with zabbix\n\nhaproxy, zabbix server, firewall, virtual openstack cluster\n\nChange-Id: I75ae6376e3f6a639c39e991ddf46d5ef68197f1b\nImplements: blueprint monitoring-system\n'}, {'number': 1, 'created': '2014-03-21 10:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d64f0edddca7d29fca71e9448bce914ab4e00d60', 'message': 'misc services monitoring with zabbix\n\nhaproxy, zabbix server, firewall, virtual openstack cluster\n\nChange-Id: I75ae6376e3f6a639c39e991ddf46d5ef68197f1b\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-05-26 07:29:07.000000000', 'files': ['deployment/puppet/zabbix/manifests/monitoring/firewall_mon.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/manifests/monitoring/haproxy_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/manifests/monitoring/openstack_virtual_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_Iptables_Stats.xml', 'deployment/puppet/zabbix/files/import/Template_OpenStack_Cluster.xml', 'deployment/puppet/zabbix/files/import/Template_App_Zabbix_Server.xml', 'deployment/puppet/zabbix/manifests/monitoring/zabbixserver_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_HAProxy.xml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/53f9f86ef354ec2db790b3ed06a98713f31fbfc9', 'message': 'misc services monitoring with zabbix\n\nhaproxy, zabbix server, firewall, virtual openstack cluster\n\nChange-Id: I75ae6376e3f6a639c39e991ddf46d5ef68197f1b\nImplements: blueprint monitoring-system\n'}]",0,82067,53f9f86ef354ec2db790b3ed06a98713f31fbfc9,35,2,4,10392,,,0,"misc services monitoring with zabbix

haproxy, zabbix server, firewall, virtual openstack cluster

Change-Id: I75ae6376e3f6a639c39e991ddf46d5ef68197f1b
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/67/82067/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/manifests/monitoring/firewall_mon.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/manifests/monitoring/haproxy_mon.pp', 'deployment/puppet/zabbix/manifests/monitoring/openstack_virtual_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_Iptables_Stats.xml', 'deployment/puppet/zabbix/files/import/Template_OpenStack_Cluster.xml', 'deployment/puppet/zabbix/files/import/Template_App_Zabbix_Server.xml', 'deployment/puppet/zabbix/manifests/monitoring/zabbixserver_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_HAProxy.xml']",10,27d43b13cae36a3fe816beba014c6d90aa7f91d0,bp/monitoring-system,"<?xml version=""1.0"" encoding=""UTF-8""?> <zabbix_export> <version>2.0</version> <date>2013-07-31T09:48:06Z</date> <groups> <group> <name>Load Balancers</name> </group> <group> <name>Templates</name> </group> </groups> <templates> <template> <template>Template App HAProxy</template> <name>Template App HAProxy</name> <groups> <group> <name>Load Balancers</name> </group> <group> <name>Templates</name> </group> </groups> <applications> <application> <name>HAProxy Backend</name> </application> <application> <name>HAProxy Backend Server</name> </application> <application> <name>HAProxy Frontend</name> </application> </applications> <items/> <discovery_rules> <discovery_rule> <name>HAProxy Backend</name> <type>0</type> <snmp_community/> <snmp_oid/> <key>haproxy.be.discovery</key> <delay>60</delay> <status>0</status> <allowed_hosts/> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter>{#HASV}:BACKEND</filter> <lifetime>30</lifetime> <description/> <item_prototypes> <item_prototype> <name>HAProxy - {#HASTAT} Active (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.act]</key> <delay>30</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Backup (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.bck]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes in</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.bin]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes out</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.bout]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check code</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.check_code]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Duration</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.check_duration]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>milliseconds</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.check_status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Client Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.cli_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Connection Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.econ]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Connections</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Current Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.scur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.dreq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.dresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Check count</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.chkfail]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Failures</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Health Check details</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hanafail]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>4</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 1XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_1xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 2XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_2xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 3XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_3xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 4XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_4xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 5XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_5xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP other responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.hrsp_other]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Last Change</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.lastchg]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Queued requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.qmax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.smax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Process ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.pid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queued Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.qcur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queue Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.qlimit]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Redispatches</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.wredis]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Redispatches</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.ereq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.req_rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.req_rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Response Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.eresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Retries</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.wretr]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Retries</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Server Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.srv_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Service ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.sid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>sessions per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.rate_lim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Sessions Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.slim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Throttle</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.throttle]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Times Chosen</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.lbtot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Downtime</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.downtime]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.req_tot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.stot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Tracked</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.tracked]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Transitions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.chkdown]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Type</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.type]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Unique Proxy ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.iid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Weight</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.be[{#HAPX}.{#HASV}.weight]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend</name> </application> </applications> <valuemap/> </item_prototype> </item_prototypes> <trigger_prototypes/> <graph_prototypes/> </discovery_rule> <discovery_rule> <name>HAProxy Backend Server</name> <type>0</type> <snmp_community/> <snmp_oid/> <key>haproxy.sv.discovery</key> <delay>60</delay> <status>0</status> <allowed_hosts/> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter>:</filter> <lifetime>30</lifetime> <description/> <item_prototypes> <item_prototype> <name>HAProxy - {#HASTAT} Active (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.act]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Backup (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.bck]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes in</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.bin]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes out</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.bout]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check code</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.check_code]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Duration</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.check_duration]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>milliseconds</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.check_status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Client Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.cli_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Connection Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.econ]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Connections</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Current Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.scur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.dreq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.dresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Check count</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.chkfail]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Failures</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Health Check details</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hanafail]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>4</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 1XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_1xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 2XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_2xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 3XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_3xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 4XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_4xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 5XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_5xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP other responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.hrsp_other]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Last Change</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.lastchg]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Queued requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.qmax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.smax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Process ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.pid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queued Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.qcur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queue Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.qlimit]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Redispatches</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.wredis]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Redispatches</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.ereq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.req_rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.req_rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Response Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.eresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Retries</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.wretr]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Retries</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Server Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.srv_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Service ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.sid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>sessions per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.rate_lim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Sessions Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.slim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Throttle</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.throttle]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Times Chosen</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.lbtot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Downtime</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.downtime]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.req_tot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.stot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Tracked</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.tracked]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Transitions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.chkdown]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Type</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.type]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Unique Proxy ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.iid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Weight</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.sv[{#HAPX}.{#HASV}.weight]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Backend Server</name> </application> </applications> <valuemap/> </item_prototype> </item_prototypes> <trigger_prototypes> <trigger_prototype> <expression>{Template App HAProxy:haproxy.sv[{#HAPX}.{#HASV}.status].str(UP)}=0</expression> <name>{#HASV} backend of {#HAPX} proxy down</name> <url/> <status>0</status> <priority>3</priority> <description/> <type>0</type> </trigger_prototype> </trigger_prototypes> <graph_prototypes/> </discovery_rule> <discovery_rule> <name>HAProxy Frontend</name> <type>0</type> <snmp_community/> <snmp_oid/> <key>haproxy.fe.discovery</key> <delay>60</delay> <status>0</status> <allowed_hosts/> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter>{#HASV}:FRONTEND</filter> <lifetime>30</lifetime> <description/> <item_prototypes> <item_prototype> <name>HAProxy - {#HASTAT} Active (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.act]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Backup (Y/N)</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.bck]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes in</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.bin]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Bytes out</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.bout]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Bytes</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check code</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.check_code]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Duration</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.check_duration]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>milliseconds</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Check Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.check_status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Client Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.cli_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Connection Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.econ]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Connections</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Current Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.scur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.dreq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Req</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Denied Responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.dresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Check count</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.chkfail]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Failures</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Failed Health Check details</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hanafail]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>4</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 1XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_1xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 2XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_2xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 3XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_3xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 4XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_4xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP 5XX responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_5xx]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} HTTP other responses</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_other]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Last Change</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.lastchg]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Queued requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.qmax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Max Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.smax]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Process ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.pid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queued Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.qcur]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Queue Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.qlimit]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Redispatches</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.wredis]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Redispatches</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.ereq]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Req</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.req_rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Request Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.req_rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Requests per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Response Errors</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.eresp]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Responses</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Retries</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.wretr]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Retries</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Server Aborts</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.srv_abrt]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Service ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.sid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.rate]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>sessions per second</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.rate_lim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Session Rate Max</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.rate_max]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Sessions Limit</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.slim]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Sessions</units> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Status</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.status]</key> <delay>60</delay> <history>365</history> <trends>365</trends> <status>0</status> <value_type>1</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Throttle</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.throttle]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Times Chosen</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.lbtot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Downtime</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.downtime]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units>Seconds</units> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Requests</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.req_tot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units/> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Total Sessions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.stot]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>0</value_type> <allowed_hosts/> <units>Sess</units> <delta>1</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Tracked</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.tracked]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Transitions</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.chkdown]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>2</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Type</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.type]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Unique Proxy ID</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.iid]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> <item_prototype> <name>HAProxy - {#HASTAT} Weight</name> <type>0</type> <snmp_community/> <multiplier>0</multiplier> <snmp_oid/> <key>haproxy.fe[{#HAPX}.{#HASV}.weight]</key> <delay>60</delay> <history>365</history> <trends>9999</trends> <status>0</status> <value_type>3</value_type> <allowed_hosts/> <units/> <delta>0</delta> <snmpv3_securityname/> <snmpv3_securitylevel>0</snmpv3_securitylevel> <snmpv3_authpassphrase/> <snmpv3_privpassphrase/> <formula>1</formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type>0</data_type> <authtype>0</authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link>0</inventory_link> <applications> <application> <name>HAProxy Frontend</name> </application> </applications> <valuemap/> </item_prototype> </item_prototypes> <trigger_prototypes/> <graph_prototypes> <graph_prototype> <name>HAProxy - {#HAPX} Requests</name> <width>900</width> <height>200</height> <yaxismin>0.0000</yaxismin> <yaxismax>100.0000</yaxismax> <show_work_period>1</show_work_period> <show_triggers>1</show_triggers> <type>0</type> <show_legend>1</show_legend> <show_3d>0</show_3d> <percent_left>0.0000</percent_left> <percent_right>0.0000</percent_right> <ymin_type_1>1</ymin_type_1> <ymax_type_1>0</ymax_type_1> <ymin_item_1>0</ymin_item_1> <ymax_item_1>0</ymax_item_1> <graph_items> <graph_item> <sortorder>0</sortorder> <drawtype>0</drawtype> <color>C80000</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.dreq]</key> </item> </graph_item> <graph_item> <sortorder>1</sortorder> <drawtype>0</drawtype> <color>00C800</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.qcur]</key> </item> </graph_item> <graph_item> <sortorder>2</sortorder> <drawtype>0</drawtype> <color>0000C8</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.ereq]</key> </item> </graph_item> <graph_item> <sortorder>3</sortorder> <drawtype>0</drawtype> <color>AA00AA</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.req_tot]</key> </item> </graph_item> </graph_items> </graph_prototype> <graph_prototype> <name>HAProxy - {#HAPX} Responses</name> <width>900</width> <height>200</height> <yaxismin>0.0000</yaxismin> <yaxismax>100.0000</yaxismax> <show_work_period>1</show_work_period> <show_triggers>1</show_triggers> <type>0</type> <show_legend>1</show_legend> <show_3d>0</show_3d> <percent_left>0.0000</percent_left> <percent_right>0.0000</percent_right> <ymin_type_1>1</ymin_type_1> <ymax_type_1>0</ymax_type_1> <ymin_item_1>0</ymin_item_1> <ymax_item_1>0</ymax_item_1> <graph_items> <graph_item> <sortorder>0</sortorder> <drawtype>0</drawtype> <color>C80000</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_1xx]</key> </item> </graph_item> <graph_item> <sortorder>1</sortorder> <drawtype>0</drawtype> <color>00C800</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_2xx]</key> </item> </graph_item> <graph_item> <sortorder>2</sortorder> <drawtype>0</drawtype> <color>0000C8</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_3xx]</key> </item> </graph_item> <graph_item> <sortorder>3</sortorder> <drawtype>0</drawtype> <color>C800C8</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_4xx]</key> </item> </graph_item> <graph_item> <sortorder>4</sortorder> <drawtype>0</drawtype> <color>00C8C8</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_5xx]</key> </item> </graph_item> <graph_item> <sortorder>5</sortorder> <drawtype>0</drawtype> <color>C8C800</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.hrsp_other]</key> </item> </graph_item> </graph_items> </graph_prototype> <graph_prototype> <name>HAProxy - {#HAPX} Sessions</name> <width>900</width> <height>200</height> <yaxismin>0.0000</yaxismin> <yaxismax>100.0000</yaxismax> <show_work_period>1</show_work_period> <show_triggers>1</show_triggers> <type>0</type> <show_legend>1</show_legend> <show_3d>0</show_3d> <percent_left>0.0000</percent_left> <percent_right>0.0000</percent_right> <ymin_type_1>1</ymin_type_1> <ymax_type_1>0</ymax_type_1> <ymin_item_1>0</ymin_item_1> <ymax_item_1>0</ymax_item_1> <graph_items> <graph_item> <sortorder>0</sortorder> <drawtype>0</drawtype> <color>C80000</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.econ]</key> </item> </graph_item> <graph_item> <sortorder>1</sortorder> <drawtype>0</drawtype> <color>00C800</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.stot]</key> </item> </graph_item> </graph_items> </graph_prototype> <graph_prototype> <name>HAProxy - {#HAPX} Traffic</name> <width>900</width> <height>200</height> <yaxismin>0.0000</yaxismin> <yaxismax>100.0000</yaxismax> <show_work_period>1</show_work_period> <show_triggers>1</show_triggers> <type>0</type> <show_legend>1</show_legend> <show_3d>0</show_3d> <percent_left>0.0000</percent_left> <percent_right>0.0000</percent_right> <ymin_type_1>1</ymin_type_1> <ymax_type_1>0</ymax_type_1> <ymin_item_1>0</ymin_item_1> <ymax_item_1>0</ymax_item_1> <graph_items> <graph_item> <sortorder>0</sortorder> <drawtype>0</drawtype> <color>C80000</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.bin]</key> </item> </graph_item> <graph_item> <sortorder>1</sortorder> <drawtype>0</drawtype> <color>00C800</color> <yaxisside>0</yaxisside> <calc_fnc>2</calc_fnc> <type>0</type> <item> <host>Template App HAProxy</host> <key>haproxy.fe[{#HAPX}.{#HASV}.bout]</key> </item> </graph_item> </graph_items> </graph_prototype> </graph_prototypes> </discovery_rule> </discovery_rules> <macros/> <templates/> <screens/> </template> </templates> </zabbix_export> ",,8950,0
openstack%2Ffuel-library~master~Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97,openstack/fuel-library,master,Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97,Neutron monitoring with zabbix,ABANDONED,2014-03-24 06:25:55.000000000,2014-06-23 10:12:36.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-24 06:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/63e694bd10ed8489d7be5b0a86d03539107c1cc4', 'message': 'Neutron monitoring with zabbix\n\nChange-Id: Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-24 06:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fc7ac1d959145055ff7287e5e3d5c1920e2cf45f', 'message': 'Neutron monitoring with zabbix\n\nChange-Id: Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-24 06:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d4ba42cfa8c309dec45cbcfcec97539bceb1b2c3', 'message': 'Neutron monitoring with zabbix\n\nChange-Id: Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-05-26 07:29:27.000000000', 'files': ['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_DHCP_Agent.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_API_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_API.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_OVS_Agent.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_L3_Agent.xml', 'deployment/puppet/zabbix/manifests/monitoring/neutron_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_Metadata_Agent.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_Server.xml', 'deployment/puppet/zabbix/templates/check_api.conf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/72a3ae960e1ca7ed7207952e5f81dfa82ff25c97', 'message': 'Neutron monitoring with zabbix\n\nChange-Id: Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97\nImplements: blueprint monitoring-system\n'}]",0,82433,72a3ae960e1ca7ed7207952e5f81dfa82ff25c97,39,2,4,10392,,,0,"Neutron monitoring with zabbix

Change-Id: Id2e3cc26c4823b761a8810c0dc4c4c90f293ff97
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/33/82433/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_API_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_DHCP_Agent.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_API.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_OVS_Agent.xml', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_L3_Agent.xml', 'deployment/puppet/zabbix/manifests/monitoring/neutron_mon.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_Metadata_Agent.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Neutron_Server.xml', 'deployment/puppet/zabbix/templates/check_api.conf.erb']",11,63e694bd10ed8489d7be5b0a86d03539107c1cc4,bp/monitoring-system,neutron_map=neutron_timeout=5,,688,0
openstack%2Ffuel-library~master~Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93,openstack/fuel-library,master,Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93,Add zabbix class declaration to osnailyfacter,ABANDONED,2014-04-07 07:36:49.000000000,2014-06-23 10:12:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10392}]","[{'number': 1, 'created': '2014-04-07 07:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/653b9315657237a4be48d082935f8dfb51b9a929', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-04-14 13:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6e7772a8328ecf3eed17e6692d9e7f6ec1c080dc', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-04-14 13:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/117cd930503622fff887397a343d473b3df8d1f2', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-04-14 13:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1aad80c5939de0354bbeadef80e2a81ff46f2b08', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 5, 'created': '2014-04-27 17:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6abce769ed3c3db4b889788522d3c336cc319440', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\nUnset mysql root password\nFix for rabbitmq-manage exec call\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 6, 'created': '2014-04-27 17:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d196379866082b2d4597d214099cecdacd38c2b', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\nUnset mysql root password\nFix for rabbitmq-manage exec call\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 7, 'created': '2014-05-26 07:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ed3f2db2376723739c999b8db5aa96ce7eb659de', 'message': 'Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\nUnset mysql root password\nFix for rabbitmq-manage exec call\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n'}, {'number': 8, 'created': '2014-06-11 07:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cc617ab144731578621ed3b639a55fbbdf4da70f', 'message': ""Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\nUnset mysql root password\nFix for rabbitmq-manage exec call\nRetry API call to zabbix, if it's unavailable\nConfigure zabbix server to log to rsyslog\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n""}, {'number': 9, 'created': '2014-06-11 08:12:13.000000000', 'files': ['deployment/puppet/zabbix/manifests/agent/userparameter.pp', 'deployment/puppet/zabbix/manifests/monitoring/rabbitmq_mon.pp', 'deployment/puppet/zabbix/manifests/agent/scripts.pp', 'deployment/puppet/zabbix/manifests/frontend.pp', 'deployment/puppet/zabbix/manifests/db/mysql.pp', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix.rb', 'deployment/puppet/zabbix/manifests/monitoring/mysql_mon.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1cb600ac49f3f75071c3604585583921f0910aa1', 'message': ""Add zabbix class declaration to osnailyfacter\n\nAdd minor fix to zabbix agent scripts\nUserparameters now use the correct zabbix_agent.d path\nFixed mysql userparameters\nUnset mysql root password\nFix for rabbitmq-manage exec call\nRetry API call to zabbix, if it's unavailable\n\nChange-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93\nImplements: blueprint monitoring-system\n""}]",0,85657,1cb600ac49f3f75071c3604585583921f0910aa1,60,3,9,10392,,,0,"Add zabbix class declaration to osnailyfacter

Add minor fix to zabbix agent scripts
Userparameters now use the correct zabbix_agent.d path
Fixed mysql userparameters
Unset mysql root password
Fix for rabbitmq-manage exec call
Retry API call to zabbix, if it's unavailable

Change-Id: Ieb0b5f2ceb0869c6201aac45dc66d4f0185fae93
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/57/85657/9 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/zabbix/manifests/agent/scripts.pp'],1,653b9315657237a4be48d082935f8dfb51b9a929,bp/monitoring-system, file { '/etc/sudoers.d': ensure => directory } ,,4,0
openstack%2Ffuel-library~master~I1b02b1729788da95efa49631983ad43bfe47632d,openstack/fuel-library,master,I1b02b1729788da95efa49631983ad43bfe47632d,Zabbix server installation,ABANDONED,2014-03-11 09:14:26.000000000,2014-06-23 10:12:13.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10392}]","[{'number': 1, 'created': '2014-03-11 09:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5131cdc206f1bcdfea4c2b3cd495f1453b4f1d31', 'message': 'Zabbix server installation\n\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 2, 'created': '2014-03-13 08:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0913fe6eed4fd033763f68615365e1a5a061aaa4', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 4, 'created': '2014-03-13 09:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/eb04a4997dd44e4e4f445948fe5823b421d52972', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 5, 'created': '2014-03-13 09:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9cb6a1b4b2b58b241c32ea3a26bb6625af1148e8', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 3, 'created': '2014-03-13 09:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/640dc933c7324d3dc94afe99a819a5c9c7e97f2b', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 6, 'created': '2014-03-25 07:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fe158702b13765f2d76279ccf5f791524befdd43', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 7, 'created': '2014-04-01 09:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5520c526dc4cc8b6563c6785e540f20a55e95bc2', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 10, 'created': '2014-04-01 11:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b5c1c14c2eb1147e88db4cdeb4a3310161bfc713', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 11, 'created': '2014-04-01 11:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/49f08e15f81a0a317aff6024382d90603feb5194', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 8, 'created': '2014-04-01 11:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a4ba4fa167ee46e0d7692f41e0d41d925cefb650', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 9, 'created': '2014-04-01 11:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d850c69d09cecb447214b7af582aa08ae33170ca', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 12, 'created': '2014-05-26 07:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/db1d13a0f1f38b1526ce253d86d2aa250c7e28ab', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}, {'number': 13, 'created': '2014-06-23 05:52:22.000000000', 'files': ['deployment/puppet/zabbix/manifests/db.pp', 'deployment/puppet/zabbix/templates/data_clean.erb', 'deployment/puppet/zabbix/LICENSE', 'deployment/puppet/zabbix/README.md', 'deployment/puppet/zabbix/lib/puppet/parser/functions/get_server_by_role.rb', 'deployment/puppet/zabbix/manifests/params.pp', 'deployment/puppet/zabbix/templates/zabbix.conf.php.erb', 'deployment/puppet/zabbix/AUTHORS.txt', 'deployment/puppet/zabbix/manifests/server.pp', 'deployment/puppet/zabbix/Modulefile', 'deployment/puppet/zabbix/templates/zabbix_server.conf.erb', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/templates/php_ini.erb', 'deployment/puppet/zabbix/files/sql/block_dev.sql', 'deployment/puppet/zabbix/manifests/frontend.pp', 'deployment/puppet/zabbix/manifests/db/mysql.pp', 'deployment/puppet/zabbix/manifests/params/openstack.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ae08faed67528e80bb81e22e8a760f1edd6233bf', 'message': 'Zabbix server installation\n\nImplements: blueprint monitoring-system\nChange-Id: I1b02b1729788da95efa49631983ad43bfe47632d\n'}]",2,79566,ae08faed67528e80bb81e22e8a760f1edd6233bf,108,4,13,10392,,,0,"Zabbix server installation

Implements: blueprint monitoring-system
Change-Id: I1b02b1729788da95efa49631983ad43bfe47632d
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/66/79566/12 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/manifests/db.pp', 'deployment/puppet/zabbix/AUTHORS.txt', 'deployment/puppet/zabbix/manifests/server.pp', 'deployment/puppet/zabbix/templates/check_db.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agent_userparam.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_server.conf.erb', 'deployment/puppet/zabbix/templates/check_api.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agentd.conf.erb', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/manifests/frontend.pp', 'deployment/puppet/zabbix/templates/zabbix.api.yaml.erb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_usermacro.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_configuration_import/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_configuration_import.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_host.rb', 'deployment/puppet/zabbix/lib/puppet/parser/functions/get_server_by_role.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_template_link/ruby.rb', 'deployment/puppet/zabbix/templates/check_rabbit.conf.erb', 'deployment/puppet/zabbix/manifests/params.pp', 'deployment/puppet/zabbix/templates/zabbix.conf.php.erb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_usermacro/ruby.rb', 'deployment/puppet/zabbix/files/sql/data_clean.sql', 'deployment/puppet/zabbix/templates/php_ini.erb', 'deployment/puppet/zabbix/templates/zabbix_agent_server_include.conf.erb', 'deployment/puppet/zabbix/files/sql/block_dev.sql', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_hostgroup/ruby.rb', 'deployment/puppet/zabbix/manifests/db/mysql.pp', 'deployment/puppet/zabbix/manifests/params/openstack.pp', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_hostgroup.rb', 'deployment/puppet/zabbix/templates/zabbix.yaml.erb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_host/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_template_link.rb']",34,5131cdc206f1bcdfea4c2b3cd495f1453b4f1d31,bp/monitoring-system," Puppet::Type.newtype(:zabbix_template_link) do desc <<-EOT Manage a template link in Zabbix EOT ensurable do defaultvalues defaultto :present end newparam(:name, :namevar => true) do desc 'Template link name.' end newparam(:host) do desc 'Technical name of the host.' end newparam(:template) do desc 'Template name to link the host to.' end newparam(:api) do desc 'Zabbix api info: endpoint, username, password.' isrequired end end ",,1679,0
openstack%2Ffuel-library~master~I11ecd953985bc1d096c656d16c3e1690dc560917,openstack/fuel-library,master,I11ecd953985bc1d096c656d16c3e1690dc560917,Add custom types for zabbix configuration Add basic server config,ABANDONED,2014-03-18 10:18:07.000000000,2014-06-23 10:12:09.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10392}]","[{'number': 1, 'created': '2014-03-18 10:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bdb835ab8c95dd20e991e2c8637e0a1f010749b7', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-19 07:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/986213870264966fa7100ea0595ddffee8974c7e', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-19 07:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/915aad43639d9b04db60d03f1443c1a2df57cfed', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 5, 'created': '2014-03-20 09:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aa90bb33ee0f183949706def899cdb959b95ef60', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-03-20 09:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fb8f6bce947ad99b31487c234ddc18d73849be8b', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 6, 'created': '2014-04-01 10:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b6e901e9714098306f4c5ab7acc9df836bd41700', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 9, 'created': '2014-04-01 11:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/903a21397ec6e3a28126eeebd6f002a2c5e11a68', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 8, 'created': '2014-04-01 11:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8a19eeb1e42b494f59b788ddf86819bc9ea982f4', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 7, 'created': '2014-04-01 11:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/13fd3bd60263f38901a461892ca391cc00b13750', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 10, 'created': '2014-05-26 07:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/98ab386c8aec78762ed6316d062ab1b8061b2897', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}, {'number': 11, 'created': '2014-06-23 06:44:08.000000000', 'files': ['deployment/puppet/zabbix/spec/unit/type/zabbix_hostgroup_spec.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_template_link_spec.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_usermacro/ruby_spec.rb', 'deployment/puppet/zabbix/files/import/Template_App_Zabbix_Agent.xml', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/spec/unit/type/zabbix_configuration_import_spec.rb', 'deployment/puppet/zabbix/files/import/Template_Fuel_OS_Linux.xml', 'deployment/puppet/zabbix/spec/spec_helper.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_usermacro.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_configuration_import/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_configuration_import.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_host.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_host_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_template_link/ruby.rb', 'deployment/puppet/zabbix/manifests/params.pp', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_usermacro/ruby.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_spec.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_usermacro_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_hostgroup/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_hostgroup.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_template_link/ruby_spec.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_host/ruby_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_host/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_template_link.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2140c193e7f9775dbbd9a0457862ec8c2be5d987', 'message': 'Add custom types for zabbix configuration\nAdd basic server config\n\nChange-Id: I11ecd953985bc1d096c656d16c3e1690dc560917\nImplements: blueprint monitoring-system\n'}]",2,81217,2140c193e7f9775dbbd9a0457862ec8c2be5d987,99,4,11,10392,,,0,"Add custom types for zabbix configuration
Add basic server config

Change-Id: I11ecd953985bc1d096c656d16c3e1690dc560917
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/17/81217/11 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/spec/unit/type/zabbix_hostgroup_spec.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_template_link_spec.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_usermacro/ruby_spec.rb', 'deployment/puppet/zabbix/files/import/Template_App_Zabbix_Agent.xml', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/spec/unit/type/zabbix_configuration_import_spec.rb', 'deployment/puppet/zabbix/files/import/Template_Fuel_OS_Linux.xml', 'deployment/puppet/zabbix/spec/spec_helper.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_usermacro.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_configuration_import/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_configuration_import.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_host.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_host_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_template_link/ruby.rb', 'deployment/puppet/zabbix/manifests/params.pp', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_usermacro/ruby.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_spec.rb', 'deployment/puppet/zabbix/spec/unit/type/zabbix_usermacro_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_hostgroup/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_hostgroup.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_template_link/ruby_spec.rb', 'deployment/puppet/zabbix/spec/unit/provider/zabbix_host/ruby_spec.rb', 'deployment/puppet/zabbix/lib/puppet/provider/zabbix_host/ruby.rb', 'deployment/puppet/zabbix/lib/puppet/type/zabbix_template_link.rb']",26,bdb835ab8c95dd20e991e2c8637e0a1f010749b7,bp/monitoring-system," Puppet::Type.newtype(:zabbix_template_link) do desc <<-EOT Manage a template link in Zabbix EOT ensurable do defaultvalues defaultto :present end newparam(:name, :namevar => true) do desc 'Template link name.' newvalues(/.+/) end newparam(:host) do desc 'Technical name of the host.' newvalues(/.+/) isrequired end newparam(:template) do desc 'Template name to link the host to.' newvalues(/.+/) isrequired end newparam(:api) do desc 'Zabbix api info: endpoint, username, password.' isrequired validate do |value| fail(""api is not a hash"") unless value.kind_of?(Hash) fail(""api hash does not contain username"") unless value.has_key?(""username"") fail(""username is not valid"") unless value['username'] =~ /.+/ fail(""api hash does not contain password"") unless value.has_key?(""password"") fail(""password is not valid"") unless value['password'] =~ /.+/ fail(""api hash does not contain endpoint"") unless value.has_key?(""endpoint"") fail(""endpoint is not valid"") unless value['endpoint'] =~ /http(s)?:\/\/.+/ end end end ",,4494,6
openstack%2Ffuel-library~master~I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7,openstack/fuel-library,master,I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7,Zabbix agent installation Basic OS monitoring,ABANDONED,2014-03-20 07:32:56.000000000,2014-06-23 10:12:05.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10392}]","[{'number': 1, 'created': '2014-03-20 07:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/924fca2678c61672d229f96dbc8b178889019a3e', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-20 07:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aa0049fe9a0a06935201c78d30d85dd9ac608393', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-03-28 10:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5d6c6475c85b0e26aac4049927b7dc92fef5a853', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-28 10:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fcd9880377f61d64354c909af61e512707c949e6', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 5, 'created': '2014-04-02 07:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d52f4196b74674c19ccddd253950a0ccc81e3c06', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 6, 'created': '2014-04-02 07:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/27ea44eefe3d834989a83537e09a3ebb3d7b698b', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 7, 'created': '2014-05-26 07:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2f309caf0b00a7dd2efc98b82f0fb6b129d47a59', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}, {'number': 8, 'created': '2014-06-23 08:26:38.000000000', 'files': ['deployment/puppet/zabbix/files/scripts/check_api.py', 'deployment/puppet/zabbix/manifests/agent/userparameter.pp', 'deployment/puppet/zabbix/files/zabbix-sudo', 'deployment/puppet/zabbix/manifests/agent/scripts.pp', 'deployment/puppet/zabbix/manifests/agent.pp', 'deployment/puppet/zabbix/templates/check_rabbit.conf.erb', 'deployment/puppet/zabbix/templates/check_db.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agent_userparam.conf.erb', 'deployment/puppet/zabbix/files/scripts/vfs.mdadm.discovery.sh', 'deployment/puppet/zabbix/templates/check_api.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agentd.conf.erb', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/scripts/query_db.py', 'deployment/puppet/zabbix/files/scripts/vfs.dev.discovery.sh', 'deployment/puppet/zabbix/files/scripts/monitoring.conf', 'deployment/puppet/zabbix/files/scripts/haproxy.sh', 'deployment/puppet/zabbix/files/scripts/check_rabbit.py'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c9f31f450a0f200f6df51b3dc4e6b48752b65f22', 'message': 'Zabbix agent installation\nBasic OS monitoring\n\nChange-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7\nImplements: blueprint monitoring-system\n'}]",0,81723,c9f31f450a0f200f6df51b3dc4e6b48752b65f22,63,4,8,10392,,,0,"Zabbix agent installation
Basic OS monitoring

Change-Id: I540dd7a5c4491b737cd5208d4fabe5d2fec74bc7
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/23/81723/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/files/scripts/check_api.py', 'deployment/puppet/zabbix/manifests/agent/userparameter.pp', 'deployment/puppet/zabbix/files/zabbix-sudo', 'deployment/puppet/zabbix/manifests/agent/scripts.pp', 'deployment/puppet/zabbix/manifests/agent.pp', 'deployment/puppet/zabbix/templates/check_rabbit.conf.erb', 'deployment/puppet/zabbix/templates/check_db.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agent_userparam.conf.erb', 'deployment/puppet/zabbix/files/scripts/vfs.mdadm.discovery.sh', 'deployment/puppet/zabbix/templates/check_api.conf.erb', 'deployment/puppet/zabbix/templates/zabbix_agentd.conf.erb', 'deployment/puppet/zabbix/manifests/init.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/scripts/query_db.py', 'deployment/puppet/zabbix/files/scripts/vfs.dev.discovery.sh', 'deployment/puppet/zabbix/files/scripts/monitoring.conf', 'deployment/puppet/zabbix/files/scripts/haproxy.sh', 'deployment/puppet/zabbix/files/scripts/check_rabbit.py']",18,924fca2678c61672d229f96dbc8b178889019a3e,bp/monitoring-system,"#!/usr/bin/python import urllib2 import simplejson as json import sys import base64 import ConfigParser import logging CONF_FILE = '/etc/zabbix/check_rabbit.conf' LOGGING_LEVELS = { 'CRITICAL': logging.CRITICAL, 'WARNING': logging.WARNING, 'INFO': logging.INFO, 'DEBUG': logging.DEBUG } def get_logger(level): logger = logging.getLogger() ch = logging.StreamHandler(sys.stdout) logger.setLevel(LOGGING_LEVELS[level]) logger.addHandler(ch) return logger class RabbitmqAPI(object): def __init__(self, logger, config): self.logger = logger self.login = config.get('rabbitmq', 'user') self.password = config.get('rabbitmq', 'password') self.host = config.get('rabbitmq', 'host') self.auth_string = base64.encodestring('%s:%s' % (self.login, self.password)).replace('\n', '') self.max_queues = int(config.get('rabbitmq', 'max_queues')) def get_http(self, url): try: request = urllib2.Request('%s/api/%s' % (self.host, url)) request.add_header(""Authorization"", ""Basic %s"" % self.auth_string) return json.loads(urllib2.urlopen(request, timeout=2).read()) except urllib2.URLError as e: self.logger.error(""URL error: '%s'"" % e) sys.exit(1) except ValueError as e: self.logger.error(""Value error: '%s'"" % e) sys.exit(1) def get_queues_items(self): response = self.get_http('overview') if 'queue_totals' in response: self.logger.critical(response['queue_totals']['messages']) else: self.logger.error('No queue_totals in response') def get_missing_queues(self): queues = 0 response = self.get_http('queues') for queue in response: queues += 1 self.logger.critical(self.max_queues-queues) def get_queues_without_consumers(self): queues_without_consumers = 0 response = self.get_http('queues') for queue in response: queues_without_consumers += 1 if queue['consumers'] > 0: queues_without_consumers -= 1 self.logger.critical(queues_without_consumers) def get_missing_nodes(self): missing_nodes = 0 response = self.get_http('nodes') for node in response: if not node['running']: missing_nodes += 1 self.logger.critical(missing_nodes) def get_unmirror_queues(self): response = self.get_http('queues') unmirror_queues = 0 for queue in response: if 'x-ha-policy' in queue['arguments']: unmirror_queues += 1 if 'synchronised_slave_nodes' in queue and len(queue['synchronised_slave_nodes']) > 0: unmirror_queues -= 1 self.logger.critical(unmirror_queues) def usage(): print(""check_rabbit.py usage:\n \ queues-items - item count in queues\n \ queues-without-consumers - count queues without consumers\n \ missing-nodes - count missing nodes from rabbitmq cluster\n \ unmirror-queues - count unmirrored queues\n \ missing-queues max_queues - compare queues count to max_queues\n"") def main(): config = ConfigParser.RawConfigParser() config.read(CONF_FILE) logger = get_logger(config.get('rabbitmq', 'log_level')) API = RabbitmqAPI(logger, config) if len(sys.argv) < 2: logger.critical('No argvs, dunno what to do') sys.exit(1) if sys.argv[1] == 'missing-queues': API.get_missing_queues() elif sys.argv[1] == 'queues-items': API.get_queues_items() elif sys.argv[1] == 'queues-without-consumers': API.get_queues_without_consumers() elif sys.argv[1] == 'missing-nodes': API.get_missing_nodes() elif sys.argv[1] == 'unmirror-queues': API.get_unmirror_queues() else: usage() if __name__ == ""__main__"": main() ",,730,1
openstack%2Ffuel-library~master~I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5,openstack/fuel-library,master,I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5,Add nova monitoring with zabbix,ABANDONED,2014-03-20 10:02:34.000000000,2014-06-23 10:11:59.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-20 10:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d852d33d6e65d6a4e2e732c3111e78ad1a65d847', 'message': 'Add nova monitoring with zabbix\n\nChange-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5\nImplements: blueprint monitoring-system\n'}, {'number': 2, 'created': '2014-03-20 10:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/abb1f0fc0e6df87c0fa52ec75c28314f781ab774', 'message': 'Add nova monitoring with zabbix\n\nChange-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5\nImplements: blueprint monitoring-system\n'}, {'number': 3, 'created': '2014-03-20 10:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fcc24181d3456d543beaf7bf743623fac2385328', 'message': 'Add nova monitoring with zabbix\n\nChange-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5\nImplements: blueprint monitoring-system\n'}, {'number': 4, 'created': '2014-05-26 07:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/17537c334f53f44c6fa5599ebd810ebf7495089f', 'message': 'Add nova monitoring with zabbix\n\nChange-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5\nImplements: blueprint monitoring-system\n'}, {'number': 5, 'created': '2014-06-23 09:15:04.000000000', 'files': ['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_OSAPI_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_EC2.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Network.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Libvirt.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_OSAPI.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Cert.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Scheduler.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_ConsoleAuth.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Compute.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_Metadata.xml', 'deployment/puppet/zabbix/manifests/monitoring/nova_mon.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/30a60ef004f09b17e92646117fcf5ae76be9d810', 'message': 'Add nova monitoring with zabbix\n\nChange-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5\nImplements: blueprint monitoring-system\n'}]",0,81754,30a60ef004f09b17e92646117fcf5ae76be9d810,57,3,5,10392,,,0,"Add nova monitoring with zabbix

Change-Id: I6788a2cb690ffa60bbe1bd9fca6d29043d2025e5
Implements: blueprint monitoring-system
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/54/81754/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_OSAPI_check.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_EC2.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Network.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Libvirt.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_OSAPI.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Cert.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Scheduler.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_ConsoleAuth.xml', 'deployment/puppet/zabbix/manifests/server/config.pp', 'deployment/puppet/zabbix/manifests/monitoring.pp', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_Compute.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API.xml', 'deployment/puppet/zabbix/files/import/Template_App_OpenStack_Nova_API_Metadata.xml', 'deployment/puppet/zabbix/manifests/monitoring/nova_mon.pp']",14,d852d33d6e65d6a4e2e732c3111e78ad1a65d847,bp/monitoring-system,"class zabbix::monitoring::nova_mon { include zabbix::params # Nova (controller) if defined(Class['openstack::controller']) { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova API"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova API', api => $zabbix::params::api_hash, } zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova API OSAPI"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova API OSAPI', api => $zabbix::params::api_hash, } zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova API OSAPI check"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova API OSAPI check', api => $zabbix::params::api_hash, } zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova API EC2"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova API EC2', api => $zabbix::params::api_hash, } zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova Cert"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova Cert', api => $zabbix::params::api_hash, } zabbix::agent::userparameter { 'nova.api.status': command => ""/etc/zabbix/scripts/check_api.py nova_os http ${::internal_address} 8774""; } if ! $::fuel_settings['quantum'] { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova Network"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova Network', api => $zabbix::params::api_hash, } } } #Nova (compute) if defined(Class['openstack::compute']) { if ! $::fuel_settings['quantum'] { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova API Metadata"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova API Metadata', api => $zabbix::params::api_hash, } } } if defined(Class['nova::consoleauth']) { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova ConsoleAuth"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova ConsoleAuth', api => $zabbix::params::api_hash, } } if defined(Class['nova::scheduler']) { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova Scheduler"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova Scheduler', api => $zabbix::params::api_hash, } } #Nova compute if defined(Class['nova::compute']) { zabbix_template_link { ""$zabbix::params::host_name Template App OpenStack Nova Compute"": host => $zabbix::params::host_name, template => 'Template App OpenStack Nova Compute', api => $zabbix::params::api_hash, } } #Libvirt if defined(Class['nova::compute::libvirt']) { zabbix_template_link { ""$::fqdn Template App OpenStack Libvirt"": host => $::fqdn, template => 'Template App OpenStack Libvirt', api => $zabbix::params::api_hash, } } } ",,1069,0
openstack%2Fnova~master~I925497df70c688ee49964a97c609f0513cd55536,openstack/nova,master,I925497df70c688ee49964a97c609f0513cd55536,Support accessing pci specs key with dot,ABANDONED,2014-06-23 08:28:41.000000000,2014-06-23 10:03:30.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-23 08:28:41.000000000', 'files': ['nova/pci/pci_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/20a9d7ae6d923e2b23b0df9f3bdbf2179bf65a25', 'message': 'Support accessing pci specs key with dot\n\nChange-Id: I925497df70c688ee49964a97c609f0513cd55536\n'}]",0,101824,20a9d7ae6d923e2b23b0df9f3bdbf2179bf65a25,10,7,1,12074,,,0,"Support accessing pci specs key with dot

Change-Id: I925497df70c688ee49964a97c609f0513cd55536
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/101824/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/pci/pci_utils.py'],1,20a9d7ae6d923e2b23b0df9f3bdbf2179bf65a25,Bug1333074," def _get_pci_value(name_path): """""" This function will support accessing pci specs key with dot. Example: pci_passthrough_whitelist=[{ ""vendor_id"":""8086"",""product_id"":""1515"", ""phys_function.0.3"": ""0x0""}] """""" pci_value = pci_dev for key in name_path.split('.'): if key.isdigit(): key = int(key) pci_value = pci_value[key] return pci_value def _matching_devices(spec): try: return all(_get_pci_value(k) == v for k, v in spec.iteritems()) except (KeyError, IndexError), e: return False"," def _matching_devices(spec): return all(pci_dev.get(k) == v for k, v in spec.iteritems())",16,1
openstack%2Fneutron~master~I7e7658d03639afae7bf6d3ad71445cb5b6459c09,openstack/neutron,master,I7e7658d03639afae7bf6d3ad71445cb5b6459c09,Pass serializer to oslo.messaging Notifier,MERGED,2014-06-20 11:36:27.000000000,2014-06-23 09:50:57.000000000,2014-06-23 09:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-20 11:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff1eabb6ffbea2cc258df2d45467bdedb8397f0e', 'message': 'Pass serializer to oslo.messaging Notifier\n\noslo.messaging has a workaround [1] that requires context to be\ntransformed to pure dict before passing into amqpdriver.\n\n[1]: oslo/messaging/_drivers/amqpdriver.py#L337\n\nblueprint oslo-messaging\n\nChange-Id: I7e7658d03639afae7bf6d3ad71445cb5b6459c09\n'}, {'number': 2, 'created': '2014-06-20 12:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/677d42940a3d2186b1b1fd0bbec5b2996f563d53', 'message': 'Pass serializer to oslo.messaging Notifier\n\noslo.messaging has a workaround [1] that requires context to be\ntransformed to pure dict before passing into amqpdriver.\n\nRenamed serializer class to reflect its broader usage.\n\nUpdated FakeNotifier to expect serializer and other keyword arguments\nsupported by oslo.messaging Notifier class.\n\n[1]: oslo/messaging/_drivers/amqpdriver.py#L337\n\nblueprint oslo-messaging\n\nChange-Id: I7e7658d03639afae7bf6d3ad71445cb5b6459c09\n'}, {'number': 3, 'created': '2014-06-20 13:07:20.000000000', 'files': ['neutron/common/rpc.py', 'neutron/tests/fake_notifier.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/48e9c8b79bea9c9a65ceb1c24528a89db6d313d2', 'message': 'Pass serializer to oslo.messaging Notifier\n\noslo.messaging has a workaround [1] that requires context to be\ntransformed to pure dict before passing into amqpdriver.\n\nRenamed serializer class to reflect its broader usage.\n\nUpdated FakeNotifier to expect serializer and other keyword arguments\nsupported by oslo.messaging Notifier class.\n\n[1]: oslo/messaging/_drivers/amqpdriver.py#L337\n\nblueprint oslo-messaging\n\nCloses-Bug: #1332412\nChange-Id: I7e7658d03639afae7bf6d3ad71445cb5b6459c09\n'}]",2,101485,48e9c8b79bea9c9a65ceb1c24528a89db6d313d2,53,18,3,9656,,,0,"Pass serializer to oslo.messaging Notifier

oslo.messaging has a workaround [1] that requires context to be
transformed to pure dict before passing into amqpdriver.

Renamed serializer class to reflect its broader usage.

Updated FakeNotifier to expect serializer and other keyword arguments
supported by oslo.messaging Notifier class.

[1]: oslo/messaging/_drivers/amqpdriver.py#L337

blueprint oslo-messaging

Closes-Bug: #1332412
Change-Id: I7e7658d03639afae7bf6d3ad71445cb5b6459c09
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/101485/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/common/rpc.py'],1,ff1eabb6ffbea2cc258df2d45467bdedb8397f0e,bp/oslo-messaging," serializer = PluginRpcSerializer() NOTIFIER = messaging.Notifier(TRANSPORT, serializer=serializer)", NOTIFIER = messaging.Notifier(TRANSPORT),2,1
openstack%2Fdiskimage-builder~master~I40b5bf39348a69add1f955c49f310e3bda21be0e,openstack/diskimage-builder,master,I40b5bf39348a69add1f955c49f310e3bda21be0e,Factor out error behavior in dib-lint,MERGED,2014-05-27 18:19:54.000000000,2014-06-23 09:38:05.000000000,2014-06-23 09:38:04.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 7732}, {'_account_id': 8399}, {'_account_id': 9268}]","[{'number': 1, 'created': '2014-05-27 18:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/500fcb5c6be5eba3c8f285cbafefc6d04776fa80', 'message': 'Factor out error behavior in dib-lint\n\nCurrently when dib-lint finds a problem it does something like:\n\n echo ""ERROR: Problem found""\n rc=1\n\nThis is repetitive and error-prone since it\'s easy to forget to set\nrc to actually fail the check.  This change makes those two steps\na single function call.\n\nChange-Id: I40b5bf39348a69add1f955c49f310e3bda21be0e\n'}, {'number': 2, 'created': '2014-05-28 16:05:30.000000000', 'files': ['bin/dib-lint'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e824b43cbda26b3d484b12610a0a14480a714c66', 'message': 'Factor out error behavior in dib-lint\n\nCurrently when dib-lint finds a problem it does something like:\n\n echo ""ERROR: Problem found""\n rc=1\n\nThis is repetitive and error-prone since it\'s easy to forget to set\nrc to actually fail the check.  This change makes those two steps\na single function call.\n\nChange-Id: I40b5bf39348a69add1f955c49f310e3bda21be0e\n'}]",6,95850,e824b43cbda26b3d484b12610a0a14480a714c66,33,8,2,6928,,,0,"Factor out error behavior in dib-lint

Currently when dib-lint finds a problem it does something like:

 echo ""ERROR: Problem found""
 rc=1

This is repetitive and error-prone since it's easy to forget to set
rc to actually fail the check.  This change makes those two steps
a single function call.

Change-Id: I40b5bf39348a69add1f955c49f310e3bda21be0e
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/50/95850/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/dib-lint'],1,500fcb5c6be5eba3c8f285cbafefc6d04776fa80,lint-fail,"error() { echo ""ERROR: $1"" rc=1 } error ""$i is not executable"" error ""$i should use 4 spaces indent"" error ""$i is not sorted alphabetically"" error ""$i is not set -e"" error ""$i is not set -u"" error ""$i contains tab characters"""," echo ""ERROR: $i is not executable"" rc=1 echo ""ERROR: $i should use 4 spaces indent"" rc=1 echo ""ERROR: $i is not sorted alphabetically"" rc=1 echo ""ERROR: $i is not set -e"" rc=1 echo ""ERROR: $i is not set -u"" rc=1 echo ""ERROR: $i contains tab characters"" rc=1",11,12
openstack%2Foslo.messaging~master~If1dc2f85eab6f542bc21961b9d5c0bd0ab64add2,openstack/oslo.messaging,master,If1dc2f85eab6f542bc21961b9d5c0bd0ab64add2,Handle unused allowed_remote_exmods in _multi_send,MERGED,2014-06-16 12:23:16.000000000,2014-06-23 09:33:30.000000000,2014-06-23 09:33:30.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2813}, {'_account_id': 7293}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-06-16 12:23:16.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/210ec5003df3fc0505f658ff233d062688d93255', 'message': 'Handle unused allowed_remote_exmods in _multi_send\n\nallowed_remote_exmods which is passed to _multi_send method in\nimpl_zmq.py is not passed further to _call, _cast, etc.\n\nDue to that, all remote exceptions, that are supposed to be\nexpected, are wrapped into messaging.RemoteError exception with\nall details of the remote exception.\n\nTo fix this allowed_remote_exmods needs to be passed as a\nparameter in a called method().\n\nChange-Id: If1dc2f85eab6f542bc21961b9d5c0bd0ab64add2\nCloses-Bug: 1330460\n'}]",1,100236,210ec5003df3fc0505f658ff233d062688d93255,16,5,1,7293,,,0,"Handle unused allowed_remote_exmods in _multi_send

allowed_remote_exmods which is passed to _multi_send method in
impl_zmq.py is not passed further to _call, _cast, etc.

Due to that, all remote exceptions, that are supposed to be
expected, are wrapped into messaging.RemoteError exception with
all details of the remote exception.

To fix this allowed_remote_exmods needs to be passed as a
parameter in a called method().

Change-Id: If1dc2f85eab6f542bc21961b9d5c0bd0ab64add2
Closes-Bug: 1330460
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/36/100236/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_zmq.py'],1,210ec5003df3fc0505f658ff233d062688d93255,bug/1330460," return_val = method(_addr, context, _topic, msg, timeout, envelope, allowed_remote_exmods)"," return_val = method(_addr, context, _topic, msg, timeout, envelope)",2,1
openstack%2Fneutron-specs~master~I803026cc74935c4afcf1c1ccf04949f34a7461ca,openstack/neutron-specs,master,I803026cc74935c4afcf1c1ccf04949f34a7461ca,lbaas-api-and-objmodel-improvement,MERGED,2014-04-28 20:01:23.000000000,2014-06-23 09:30:01.000000000,2014-06-18 14:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 85}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 6274}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 7317}, {'_account_id': 7398}, {'_account_id': 7823}, {'_account_id': 9200}, {'_account_id': 9375}, {'_account_id': 10273}, {'_account_id': 10558}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11644}, {'_account_id': 11675}, {'_account_id': 11685}]","[{'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/adcbbf9477c27990c1d9b62bdd7dc45b30a30a39', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a7a03e5c0e15c437bc99b89c9e480ab5239d9e75', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 3, 'created': '2014-04-29 13:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/24cbf7c28b26b00d55d34c5e32742d0c205bf871', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 4, 'created': '2014-05-21 22:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2b9236f39879450597ad1c62c885aa05e857f657', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 5, 'created': '2014-05-21 23:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/207b6b1154a7c61ddb5a5e50883260228fb7fd57', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 6, 'created': '2014-05-28 21:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7c7ef37e91c660973c6a3742d2cf9bbd37fc860d', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 7, 'created': '2014-05-28 21:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2ad594924e89eeeb0d70712f279a3ca46c2eda63', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 8, 'created': '2014-05-28 22:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/768abf9e0a86f89ce2a6f4abeafa1194ab427d30', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 9, 'created': '2014-05-29 03:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6ad15fc9e0adb786b0430084c7bebaffe4f63e01', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 10, 'created': '2014-05-29 13:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5210e7e2944b55462c7bf3af4c2a5c180cd9c509', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 11, 'created': '2014-06-10 11:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/23542009275215520d89c5cd7a2f2a939bef614c', 'message': 'lbaas-api-and-objmodel-improvement\n\nModifying original spec from Eugene to account for\nagreed on object model.\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 12, 'created': '2014-06-10 14:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0a28085314e84687a77dbaf6e521178ddee305b9', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 13, 'created': '2014-06-17 16:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4a3abfc452ea8244815a85d10c293d09eb69c755', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 14, 'created': '2014-06-17 19:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/67fefaf29f7da0fcfd4c273e9c0cd494786c2808', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 15, 'created': '2014-06-17 19:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e40b49c8c51327d0385d4bf919b93b2118c890b5', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 16, 'created': '2014-06-17 21:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/97584c8ed45becee51d54fc819b0245e8f1aefd3', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 17, 'created': '2014-06-17 21:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c355c65c01c71302d146c3c6f08d3eae7325551f', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 18, 'created': '2014-06-17 21:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e33af8733084ff6565075960cb131adc25f17b1c', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 19, 'created': '2014-06-17 21:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cadb1d6a08e9ccefbf54a37f085ae1b498ec422c', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 20, 'created': '2014-06-17 21:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f278e80315905e52965a799ed4a2da724bc30af6', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}, {'number': 21, 'created': '2014-06-17 22:40:36.000000000', 'files': ['specs/juno/lbaas-api-and-objmodel-improvement.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0ff5c2be3b35fbddde72ddd17fff013e4a183028', 'message': 'lbaas-api-and-objmodel-improvement\n\nChange-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca\n'}]",197,89903,0ff5c2be3b35fbddde72ddd17fff013e4a183028,159,21,21,6072,,,0,"lbaas-api-and-objmodel-improvement

Change-Id: I803026cc74935c4afcf1c1ccf04949f34a7461ca
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/03/89903/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/lbaas-api-and-objmodel-improvement.rst'],1,adcbbf9477c27990c1d9b62bdd7dc45b30a30a39,lbaas-api-and-objmodel-improvement,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== LBaaS API and Object Model improvement ========================================== https://blueprints.launchpad.net/neutron/+spec/lbaas-api-and-objmodel-improvement LBaaS needs improved/extended API to be able to configure advanced use cases that go beyond single VIP+single pool configuration. Problem description =================== A detailed description of the problem: * The ""advanced"" LB configuration which is supported by all LB vendors, both hw and sw, may consist of multiple service endpoints on 1 ip address, and multiple pools. Here, 'service endpoint' means IP address + port The problem with existing API/object model is that it only accounts for single VIP and single pool per loadbalancer Proposed change =============== None Proposed change =============== https://wiki.openstack.org/wiki/Neutron/LBaaS/LoadbalancerInstance/Discussion There are a few things that needs to be done in order to make LBaaS API more consistent, convenient and robust: 1. Currently Pool object is the root object(*), which is logically incorrect and confusing. Need to make Pool a pure-db object. From API perspective that means that creating Pool object will not be a starting point of the workflow. - ""Provider"" attribute of Pool will be marked as deprecated. - vip_id attribute will be removed (to allow multiple Listeners to point to single pool) 2. VIP object becomes the root object(*) of the LBaaS object model. It becomes a placeholder for neutron port (Ip address(es) particularly) - VIP object continues to have existing attributes - Creating a VIP also means creating the first Listener, if Listener attributes are provided - VIP loses pool_id attribute (in fact, it's marked as deprecated) providing pool_id at VIP creation will associate created default Listener to a Pool with that pool_id 3. Additional object 'Listener' (or ServicePort) is introduced, which is a placeholder for former VIP parameters such as tcp_port, protocol, protocol-specific paratemers such as SSL stuff. Listener and VIP relate as N:1 (*) Root object is an object that represents 'service instance'. It could be deployed/undeployed, turned on/off, or capability requirements may be applied to it. It also is a starting point of configuration workflow. Alternatives ------------ None Data model impact ----------------- New DB model introduced: - Listener. Listener object receives some protocol-specific properties of the former VIP Some existing DB models are changed: - VIP. VIP model loses some attributes to Listener. - Pool. Provider attribute should move to DB model. That is needed to maintain API compatibility. It will be removed during the next cycle. Migration moving to new Object Model is required. In particular, migration will add Listener to each of existing Vips and attach VIP's pool to that Listener REST API impact --------------- Top level resources, each supports CRUD operations: * VIP * Listener * Pool * Member * HealthMonitor 1. VIP Actions: Create, Update, Delete, List, Show Verbs: POST, PUT, DELETE, GET Attributes: * id - autogenerated ID * tenant_id - owning tenant * name - name of the VIP * subnet_id - id of the subnet to which VIP is plugged * address - ip address in that subnet (may be omitted) * protocol_port - tcp port for the first listener (may be omitted, compatibility) * protocol - protocol of the first listener (may be omitted, compatibility) * connection_limit - connection limit for the first listener * admin_state_up - administrative state 2. Listener Actions: Create, Update, Delete, List, Show Verbs: POST, PUT, DELETE, GET Attributes: * id - autogenerated ID * vip_id - owning VIP * name - name of the listener * protocol_port - tcp port for the first listener (may be omitted, compatibility) * protocol - protocol of the first listener (may be omitted, compatibility) * connection_limit - connection limit for the first listener * admin_state_up - administrative state * pool_id - id of the default pool for the listener Note that one doesn't need to specify address/subnet parameters for the Listener as they are inherited from the VIP. 3. Pool Mostly same as existing API. Pool API resource loses 'vip_id' attribute Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Neutron client is affected by this change. New commands will be introduced: lb-create-listener lb-show-listener lb-update-listener lb-delete-listener lb-list-listeners Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- API change is fully bw-compatible. Some attributes and workflow aspects will be marked as deprecated. Implementation ============== Assignee(s) ----------- Primary assignee: enikanorov Work Items ---------- * API/object model change - single patch * depending change to lbaas agent scheduling * Change to neutron client * New tempest API tests Dependencies ============ None Testing ======= The change expected to be fully backward-compatible. Existing tests should be able to pass. Additional API tests are needed for the new VIP-centric workflow. Documentation Impact ==================== This API change has DocImpact References ========== * VIP-centric proposal: https://wiki.openstack.org/wiki/Neutron/LBaaS/LoadbalancerInstance/Discussion * VIP-centric proposal (API examples): https://etherpad.openstack.org/p/neutron-lbaas-api-proposals ",,234,0
openstack%2Fcookbook-openstack-identity~master~I1017894e1c824df45a281e003466ac94dc0e183e,openstack/cookbook-openstack-identity,master,I1017894e1c824df45a281e003466ac94dc0e183e,Allow other services to register via resource,MERGED,2014-06-18 19:38:03.000000000,2014-06-23 09:26:49.000000000,2014-06-23 09:26:49.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 5371}, {'_account_id': 7858}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-18 19:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/5ea42ad2c432acd8ca9c95cfe1aece64b0258d10', 'message': 'use attribute for valid values of service_types\n\nChange-Id: I1017894e1c824df45a281e003466ac94dc0e183e\n'}, {'number': 2, 'created': '2014-06-20 16:53:29.000000000', 'files': ['resources/register.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/933c109f5e98d29ee5cbb281557bb08466165bf3', 'message': 'Allow other services to register via resource\n\nSince there are a lot of incubator projects that also\nuse the keystone service catalog and need to register during\ndeployments, we should open this functionality for those\nother services to use.\n\nChange-Id: I1017894e1c824df45a281e003466ac94dc0e183e\n'}]",2,101003,933c109f5e98d29ee5cbb281557bb08466165bf3,18,6,2,7858,,,0,"Allow other services to register via resource

Since there are a lot of incubator projects that also
use the keystone service catalog and need to register during
deployments, we should open this functionality for those
other services to use.

Change-Id: I1017894e1c824df45a281e003466ac94dc0e183e
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/03/101003/1 && git format-patch -1 --stdout FETCH_HEAD,"['resources/register.rb', 'attributes/default.rb']",2,5ea42ad2c432acd8ca9c95cfe1aece64b0258d10,misc-service-register,# LWRP options default['openstack']['identity']['service_types'] = %w{image identity compute storage ec2 volume object-store metering network orchestration cloudformation database data-processing} ,,5,1
openstack%2Ffuel-web~master~Id2ffb1369ff9b2bd480d097b73fad084a3330013,openstack/fuel-web,master,Id2ffb1369ff9b2bd480d097b73fad084a3330013,"Upgrades, ostf checker checks that service returns 200",MERGED,2014-06-20 13:08:24.000000000,2014-06-23 09:25:14.000000000,2014-06-23 09:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-20 13:08:24.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_checker.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/checker.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c0b1b1690e30fb6b76b9e9af3e95cf0b8268aa52', 'message': 'Upgrades, ostf checker checks that service returns 200\n\nOSTF checker was checking that\nservice returns 404 now it checks\nthat service returns 200 response\ncode.\n\nblueprint upgrade-to-5-1\n\nChange-Id: Id2ffb1369ff9b2bd480d097b73fad084a3330013\n'}]",0,101521,c0b1b1690e30fb6b76b9e9af3e95cf0b8268aa52,14,5,1,8749,,,0,"Upgrades, ostf checker checks that service returns 200

OSTF checker was checking that
service returns 404 now it checks
that service returns 200 response
code.

blueprint upgrade-to-5-1

Change-Id: Id2ffb1369ff9b2bd480d097b73fad084a3330013
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/21/101521/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_checker.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/checker.py']",2,c0b1b1690e30fb6b76b9e9af3e95cf0b8268aa52,bp/upgrade-to-5-1," _, code = self.safe_get('http://{host}:{port}/'.format( return code == 200"," _, code = self.safe_get('http://{host}:{port}/ostf/not_found'.format( return code == 404",3,3
openstack%2Ffuel-web~master~I27c2347a6be6550c18d00786118573a811b0a944,openstack/fuel-web,master,I27c2347a6be6550c18d00786118573a811b0a944,Use version yaml which is generated by make system,MERGED,2014-06-20 12:39:25.000000000,2014-06-23 09:24:57.000000000,2014-06-23 09:24:57.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-06-20 12:39:25.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/fake_upgrade/config/version.yaml', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/base.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.yaml', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/cli.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1256b9b53a2fde7cd01fff1a6a0e0a997b9640c0', 'message': 'Use version yaml which is generated by make system\n\n* user version yaml which is generated by\n  make system instead of hardcoded version.yaml\n* added version yaml rollback\n* removed unused method `clean_iptables_rules`\n\nblueprint upgrade-to-5-1\nChange-Id: I27c2347a6be6550c18d00786118573a811b0a944\n'}]",0,101515,1256b9b53a2fde7cd01fff1a6a0e0a997b9640c0,14,5,1,8749,,,0,"Use version yaml which is generated by make system

* user version yaml which is generated by
  make system instead of hardcoded version.yaml
* added version yaml rollback
* removed unused method `clean_iptables_rules`

blueprint upgrade-to-5-1
Change-Id: I27c2347a6be6550c18d00786118573a811b0a944
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/15/101515/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/fake_upgrade/config/version.yaml', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/base.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.yaml', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/cli.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/config.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py']",7,1256b9b53a2fde7cd01fff1a6a0e0a997b9640c0,bp/upgrade-to-5-1," self.upgrader.switch_version_file_to_previous_version = \ mock.MagicMock() self.called_once(self.upgrader.switch_version_file_to_previous_version) @mock.patch('fuel_upgrade.engines.docker_engine.utils.symlink') def test_switch_version_file_to_previous_version(self, symlink_mock, _): self.upgrader.switch_version_file_to_previous_version() symlink_mock.assert_called_once_with( '/etc/fuel/0/version.yaml', '/etc/fuel/version.yaml')",,44,23
openstack%2Fgnocchi~master~I65da4d2b5093ff8ffece9b972cbeacc322e9dd33,openstack/gnocchi,master,I65da4d2b5093ff8ffece9b972cbeacc322e9dd33,Explicitly expose POST measurements as accepting JSON,ABANDONED,2014-06-20 20:26:19.000000000,2014-06-23 09:23:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 9562}, {'_account_id': 10683}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-20 20:26:19.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/17b76dccd6fb71576016e9bddfe4f824b588fc4f', 'message': ""Explicitly expose POST measurements as accepting JSON\n\nOtherwise submitting JSON-encoded measurements is seen to fail\non Fedora20 with:\n\n  406 Not Acceptable\n\nand the following gnocchi-api logging indicating an unexpected\ncontent-type:\n\n  ERROR pecan.core [-] Controller 'post_measures' defined does not support content_type 'None'. Supported type(s): ['text/html']\n\nChange-Id: I65da4d2b5093ff8ffece9b972cbeacc322e9dd33\n""}]",2,101647,17b76dccd6fb71576016e9bddfe4f824b588fc4f,12,7,1,2284,,,0,"Explicitly expose POST measurements as accepting JSON

Otherwise submitting JSON-encoded measurements is seen to fail
on Fedora20 with:

  406 Not Acceptable

and the following gnocchi-api logging indicating an unexpected
content-type:

  ERROR pecan.core [-] Controller 'post_measures' defined does not support content_type 'None'. Supported type(s): ['text/html']

Change-Id: I65da4d2b5093ff8ffece9b972cbeacc322e9dd33
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/47/101647/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,17b76dccd6fb71576016e9bddfe4f824b588fc4f,," @vexpose(Measures, 'json')", @vexpose(Measures),1,1
openstack%2Fneutron~master~I91f6eaf207d85d33d0fd809b4254e9bd1e7599c6,openstack/neutron,master,I91f6eaf207d85d33d0fd809b4254e9bd1e7599c6,FWaaS: Don't contact l3 agent if tenant has no routers,ABANDONED,2014-06-13 15:20:46.000000000,2014-06-23 08:54:02.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6995}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10041}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-13 15:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1372e1b0a1aa1963a8d1c41b535ba2416b6eb515', 'message': ""FWaaS: Don't contact l3 agent if tenant has no routers\n\nFWaaS needs to have router in order to perform iptables rules in its\nnamespace. The router_info on the agent side is filled only in case\nrouter has any interface. This patch forbids contacting FWaaS agent in\ncase tenant has no router or if there is no router with at least one\ninterface.\n\nChange-Id: I91f6eaf207d85d33d0fd809b4254e9bd1e7599c6\nCloses-bug: #1324363\n""}, {'number': 2, 'created': '2014-06-16 11:34:02.000000000', 'files': ['neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/services/firewall/fwaas_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/824e69d54bc066960d65091b01d7fb7b64104520', 'message': ""FWaaS: Don't contact l3 agent if tenant has no routers\n\nFWaaS needs to have router in order to perform iptables rules in its\nnamespace. The router_info on the agent side is filled only in case\nrouter has any interface. This patch forbids contacting FWaaS agent in\ncase tenant has no router or if there is no router with at least one\ninterface.\n\nChange-Id: I91f6eaf207d85d33d0fd809b4254e9bd1e7599c6\nCloses-bug: #1324363\n""}]",8,99956,824e69d54bc066960d65091b01d7fb7b64104520,38,20,2,8655,,,0,"FWaaS: Don't contact l3 agent if tenant has no routers

FWaaS needs to have router in order to perform iptables rules in its
namespace. The router_info on the agent side is filled only in case
router has any interface. This patch forbids contacting FWaaS agent in
case tenant has no router or if there is no router with at least one
interface.

Change-Id: I91f6eaf207d85d33d0fd809b4254e9bd1e7599c6
Closes-bug: #1324363
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/99956/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/firewall/fwaas_plugin.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py']",2,1372e1b0a1aa1963a8d1c41b535ba2416b6eb515,bug/1324363,"from neutron.common import constants def test_create_firewall_check_for_tenant_failed(self): with mock.patch.object( fwaas_plugin, 'tenant_has_router_with_interface', return_value=False): result = self._create_firewall(None, 'fw', '', None) self.assertEqual(exc.HTTPConflict.code, result.status_code) class TestTenantHasRouterWithInterface(base.BaseTestCase): def setUp(self): super(TestTenantHasRouterWithInterface, self).setUp() l3_plugin = mock.Mock() nm_mock = mock.patch('neutron.manager.NeutronManager').start() self.service_plugins_mock = nm_mock.get_service_plugins self.service_plugins_mock.return_value = { const.L3_ROUTER_NAT: l3_plugin} self.get_ports_mock = nm_mock.get_plugin.return_value.get_ports self.get_routers_mock = l3_plugin.get_routers self.context = object() self.tenant_id = 'tenant-id' def _test_helper(self, ports=None, routers=None, exp_exc=None): self.get_ports_mock.return_value = ports or list() self.get_routers_mock.return_value = routers or list() if exp_exc is None: retval = fwaas_plugin.tenant_has_router_with_interface( self.context, self.tenant_id) else: self.assertRaises( exp_exc, fwaas_plugin.tenant_has_router_with_interface, self.context, self.tenant_id) return retval def test_success(self): self.assertTrue(self._test_helper(['port'], [{'id': 'id'}])) self.get_routers_mock.assert_called_once_with( self.context, filters={'tenant_id': [self.tenant_id]}) self.get_ports_mock.assert_called_once_with( self.context, filters={'device_owner': [constants.DEVICE_OWNER_ROUTER_INTF], 'device_id': ['id']}) def test_no_router(self): self.assertFalse(self._test_helper(['port'])) self.get_routers_mock.assert_called_once_with( self.context, filters={'tenant_id': [self.tenant_id]}) self.assertFalse(self.get_ports_mock.called) def test_no_interface(self): self.assertFalse(self._test_helper(routers=[{'id': 'id'}])) self.get_routers_mock.assert_called_once_with( self.context, filters={'tenant_id': [self.tenant_id]}) self.get_ports_mock.assert_called_once_with( self.context, filters={'device_owner': [constants.DEVICE_OWNER_ROUTER_INTF], 'device_id': ['id']}) def test_no_l3_plugin(self): self.service_plugins_mock.return_value = dict() self.assertTrue(self._test_helper()) self.assertFalse(self.get_routers_mock.called or self.get_ports_mock.called)",,97,0
openstack%2Fneutron~master~I45cb2b5b82b421c016dcc9603b04edb638ff84cf,openstack/neutron,master,I45cb2b5b82b421c016dcc9603b04edb638ff84cf,"Revert ""Check NVP router's status before deploying a service""",MERGED,2014-06-23 02:16:34.000000000,2014-06-23 08:30:36.000000000,2014-06-23 08:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7317}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-23 02:16:34.000000000', 'files': ['neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/plugins/vmware/common/exceptions.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1608ffbd17ddce0d380bd7af433eeaf7d9787cb2', 'message': 'Revert ""Check NVP router\'s status before deploying a service""\n\nThis reverts commit 25103df197c1f366eac8dd3069fabc01d3bd18e9.\nSince it always leads to an gate failure filed on https://bugs.launchpad.net/neutron/+bug/1332502 although can\'t find the reason until now.\n\nChange-Id: I45cb2b5b82b421c016dcc9603b04edb638ff84cf\n'}]",2,101789,1608ffbd17ddce0d380bd7af433eeaf7d9787cb2,20,17,1,7317,,,0,"Revert ""Check NVP router's status before deploying a service""

This reverts commit 25103df197c1f366eac8dd3069fabc01d3bd18e9.
Since it always leads to an gate failure filed on https://bugs.launchpad.net/neutron/+bug/1332502 although can't find the reason until now.

Change-Id: I45cb2b5b82b421c016dcc9603b04edb638ff84cf
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/101789/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/plugins/vmware/common/exceptions.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py']",6,1608ffbd17ddce0d380bd7af433eeaf7d9787cb2,router_check," def _create_and_get_router(self): req = self._create_router(self.fmt, self._tenant_id) res = self.deserialize(self.fmt, req) return res['router']['id'] def test_create_firewall_without_policy(self): attrs['router_id'] = self._create_and_get_router() expected_res_status=201) as fw:"," def test_create_firewall_without_policy(self, **kwargs): if 'router_id' in kwargs: attrs['router_id'] = kwargs.pop('router_id') else: attrs['router_id'] = self._create_and_get_router() **kwargs) as fw: def test_create_firewall_with_invalid_router(self): name = ""new_fw"" attrs = self._get_test_firewall_attrs(name) attrs['router_id'] = self._create_and_get_router() self.assertRaises(webob.exc.HTTPClientError, self.test_create_firewall_without_policy, router_id=None) self.assertRaises(webob.exc.HTTPClientError, self.test_create_firewall_without_policy, router_id='invalid_id') router_id = self._create_and_get_router( arg_list=('service_router',), service_router=False) self.assertRaises(webob.exc.HTTPClientError, self.test_create_firewall_without_policy, router_id=router_id) router_id = self._create_and_get_router(active_set=False) self.assertRaises(webob.exc.HTTPClientError, self.test_create_firewall_without_policy, router_id=router_id) ",55,128
openstack%2Ffuel-library~master~Ieae42c5ff0948483d98960cfd6d7fa60bd085de2,openstack/fuel-library,master,Ieae42c5ff0948483d98960cfd6d7fa60bd085de2,Remove unused puppet module lvm,ABANDONED,2014-06-20 14:16:59.000000000,2014-06-23 08:03:30.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-06-20 14:16:59.000000000', 'files': ['deployment/puppet/lvm/lib/puppet/type/physical_volume.rb', 'deployment/puppet/lvm/Modulefile', 'deployment/puppet/lvm/spec/unit/puppet/provider/logical_volume/lvm.rb', 'deployment/puppet/lvm/.gitignore', 'deployment/puppet/lvm/README.markdown', 'deployment/puppet/lvm/lib/puppet/type/volume_group.rb', 'deployment/puppet/lvm/lib/puppet/type/filesystem.rb', 'deployment/puppet/lvm/lib/puppet/type/logical_volume.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/volume_group.rb', 'deployment/puppet/lvm/spec/unit/puppet/provider/physical_volume/lvm.rb', 'deployment/puppet/lvm/.project', 'deployment/puppet/lvm/lib/puppet/provider/volume_group/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/provider/filesystem/lvm.rb', 'deployment/puppet/lvm/LICENSE', 'deployment/puppet/lvm/spec/lib/helpers.rb', 'deployment/puppet/lvm/lib/puppet/provider/logical_volume/lvm.rb', 'deployment/puppet/lvm/spec/lib/matchers.rb', 'deployment/puppet/lvm/lib/puppet/provider/filesystem/lvm.rb', 'deployment/puppet/lvm/spec/spec_helper.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/logical_volume.rb', 'deployment/puppet/lvm/lib/puppet/provider/physical_volume/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/filesystem.rb', 'deployment/puppet/lvm/manifests/init.pp', 'deployment/puppet/lvm/spec/unit/puppet/provider/volume_group/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/physical_volume.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/93ec8b9828e3d40411555416bdde92956ccd8659', 'message': 'Remove unused puppet module lvm\n\nChange-Id: Ieae42c5ff0948483d98960cfd6d7fa60bd085de2\nImplements: blueprint merge-openstack-puppet-modules\n'}]",0,101560,93ec8b9828e3d40411555416bdde92956ccd8659,9,3,1,11827,,,0,"Remove unused puppet module lvm

Change-Id: Ieae42c5ff0948483d98960cfd6d7fa60bd085de2
Implements: blueprint merge-openstack-puppet-modules
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/60/101560/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/lvm/lib/puppet/type/physical_volume.rb', 'deployment/puppet/lvm/Modulefile', 'deployment/puppet/lvm/spec/unit/puppet/provider/logical_volume/lvm.rb', 'deployment/puppet/lvm/.gitignore', 'deployment/puppet/lvm/README.markdown', 'deployment/puppet/lvm/lib/puppet/type/volume_group.rb', 'deployment/puppet/lvm/lib/puppet/type/filesystem.rb', 'deployment/puppet/lvm/lib/puppet/type/logical_volume.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/volume_group.rb', 'deployment/puppet/lvm/spec/unit/puppet/provider/physical_volume/lvm.rb', 'deployment/puppet/lvm/.project', 'deployment/puppet/lvm/lib/puppet/provider/volume_group/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/provider/filesystem/lvm.rb', 'deployment/puppet/lvm/LICENSE', 'deployment/puppet/lvm/spec/lib/helpers.rb', 'deployment/puppet/lvm/lib/puppet/provider/logical_volume/lvm.rb', 'deployment/puppet/lvm/spec/lib/matchers.rb', 'deployment/puppet/lvm/lib/puppet/provider/filesystem/lvm.rb', 'deployment/puppet/lvm/spec/spec_helper.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/logical_volume.rb', 'deployment/puppet/lvm/lib/puppet/provider/physical_volume/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/filesystem.rb', 'deployment/puppet/lvm/manifests/init.pp', 'deployment/puppet/lvm/spec/unit/puppet/provider/volume_group/lvm.rb', 'deployment/puppet/lvm/spec/unit/puppet/type/physical_volume.rb']",25,93ec8b9828e3d40411555416bdde92956ccd8659,bp/merge-openstack-puppet-modules,,"Dir.chdir(File.dirname(__FILE__)) { (s = lambda { |f| File.exist?(f) ? require(f) : Dir.chdir("".."") { s.call(f) } }).call(""spec/spec_helper.rb"") } describe Puppet::Type.type(:physical_volume) do before do @type = Puppet::Type.type(:physical_volume) stub_default_provider! end it ""should exist"" do Puppet::Type.type(:physical_volume).should_not be_nil end describe ""the name parameter"" do it ""should exist"" do @type.attrclass(:name).should_not be_nil end it ""should only allow fully qualified files"" do lambda { @type.new :name => ""mypv"" }.should raise_error(Puppet::Error) end it ""should support fully qualified names"" do @type.new(:name => ""/my/pv"")[:name].should == ""/my/pv"" end end describe ""the 'ensure' parameter"" do it ""should exist"" do @type.attrclass(:ensure).should_not be_nil end it ""should support 'present' as a value"" do with(:name => ""/my/pv"", :ensure => :present) do |resource| resource[:ensure].should == :present end end it ""should support 'absent' as a value"" do with(:name => ""/my/pv"", :ensure => :absent) do |resource| resource[:ensure].should == :absent end end it ""should not support other values"" do specifying(:name => ""/my/pv"", :ensure => :foobar).should raise_error(Puppet::Error) end end end ",0,1350
openstack%2Fcinder~master~Ibd5c1865d42638a735fd588e9c10e8f714c9c030,openstack/cinder,master,Ibd5c1865d42638a735fd588e9c10e8f714c9c030,vmware:Ignore inaccessible/inMaintenance datastore,MERGED,2014-03-14 13:09:05.000000000,2014-06-23 07:59:21.000000000,2014-06-23 07:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1653}, {'_account_id': 2243}, {'_account_id': 7948}, {'_account_id': 7992}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-03-14 13:09:05.000000000', 'files': ['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/36b5782dea6d0e627c65c73dbfee39d55dbee318', 'message': 'vmware:Ignore inaccessible/inMaintenance datastore\n\nThe vmdk driver uses the number of hosts connected to a datastore as one\nof the criteria for selecting a datastore for volume creation. It might\nincorrectly consider a host to which the datastore is inaccessible while\ncomputing the number of connected hosts. This is because, the driver\nsometimes uses the aggregated accessible status of a datastore while\ndetermining its accessibility to a host. Also, the driver is ignoring\nthe maintenance status of the datastore and might create a volume in a\ndatastore which is entering maintenance or already in maintenance. This\nchange fixes these issues in datastore filtering.\n\nChange-Id: Ibd5c1865d42638a735fd588e9c10e8f714c9c030\nCloses-Bug: #1291346\nCloses-Bug: #1291291\n'}]",0,80559,36b5782dea6d0e627c65c73dbfee39d55dbee318,23,7,1,9171,,,0,"vmware:Ignore inaccessible/inMaintenance datastore

The vmdk driver uses the number of hosts connected to a datastore as one
of the criteria for selecting a datastore for volume creation. It might
incorrectly consider a host to which the datastore is inaccessible while
computing the number of connected hosts. This is because, the driver
sometimes uses the aggregated accessible status of a datastore while
determining its accessibility to a host. Also, the driver is ignoring
the maintenance status of the datastore and might create a volume in a
datastore which is entering maintenance or already in maintenance. This
change fixes these issues in datastore filtering.

Change-Id: Ibd5c1865d42638a735fd588e9c10e8f714c9c030
Closes-Bug: #1291346
Closes-Bug: #1291291
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/80559/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py']",2,36b5782dea6d0e627c65c73dbfee39d55dbee318,bug/1291291," def _is_usable(self, mount_info): """"""Check if a datastore is usable as per the given mount info. :param mount_info: Host mount information writable = mount_info.accessMode == 'readWrite' mounted = getattr(mount_info, 'mounted', True) # If accessible attribute is not set, then default is False accessible = getattr(mount_info, 'accessible', False) summary = self.get_summary(datastore) if not summary.accessible: return [] if not hasattr(host_mounts, 'DatastoreHostMount'): return [] if self._is_usable(host_mount.mountInfo): def _in_maintenance(self, summary): """"""Check if a datastore is entering maintenance or in maintenance. :param summary: Summary information about the datastore :return: True if the datastore is entering maintenance or in maintenance """""" if hasattr(summary, 'maintenanceMode'): return summary.maintenanceMode in ['enteringMaintenance', 'inMaintenance'] return False def _is_valid(self, datastore, host): """"""Check if the datastore is valid for the given host. A datastore is considered valid for a host only if the datastore is writable, mounted and accessible. Also, the datastore should not be in maintenance mode. summary = self.get_summary(datastore) in_maintenance = self._in_maintenance(summary) if not summary.accessible or in_maintenance: return False return self._is_usable(host_mount.mountInfo)"," def _is_usable(self, datastore, mount_info): """"""Check if the given datastore is usable as per the given mount info. :param datastore: Reference to the datastore entity :param mount_info: host mount information writable = mount_info.accessMode == ""readWrite"" mounted = True if hasattr(mount_info, ""mounted""): mounted = mount_info.mounted if hasattr(mount_info, ""accessible""): accessible = mount_info.accessible else: # If accessible attribute is not set, we look at summary summary = self.get_summary(datastore) accessible = summary.accessible if self._is_usable(datastore, host_mount.mountInfo): def _is_valid(self, datastore, host): """"""Check if host's datastore is accessible, mounted and writable. return self._is_usable(datastore, host_mount.mountInfo)",143,111
openstack%2Fopenstack-manuals~master~I7803ee5f6811184f847733fca138172a983f2e1f,openstack/openstack-manuals,master,I7803ee5f6811184f847733fca138172a983f2e1f,Imported Translations from Transifex,MERGED,2014-06-23 06:07:46.000000000,2014-06-23 07:35:09.000000000,2014-06-23 07:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2014-06-23 06:07:46.000000000', 'files': ['doc/common/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/38ae296fd0d53143ecd6c080a2046b1de9c916ff', 'message': 'Imported Translations from Transifex\n\nChange-Id: I7803ee5f6811184f847733fca138172a983f2e1f\n'}]",0,101807,38ae296fd0d53143ecd6c080a2046b1de9c916ff,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I7803ee5f6811184f847733fca138172a983f2e1f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/101807/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/locale/ja.po'],1,38ae296fd0d53143ecd6c080a2046b1de9c916ff,transifex/translations,"""POT-Creation-Date: 2014-06-23 02:03+0000\n"" ""PO-Revision-Date: 2014-06-23 00:51+0000\n""msgstr ""HOST""","""POT-Creation-Date: 2014-06-19 04:32+0000\n"" ""PO-Revision-Date: 2014-06-18 18:51+0000\n""msgstr """"",3,3
openstack%2Fcinder~master~I2e69fc4103559d49d2cee16ea04787a252dbf879,openstack/cinder,master,I2e69fc4103559d49d2cee16ea04787a252dbf879,vmware: Force chunked transfer for upload-to-image,MERGED,2014-04-03 13:24:28.000000000,2014-06-23 07:21:49.000000000,2014-06-23 07:21:49.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1653}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9751}, {'_account_id': 10730}]","[{'number': 1, 'created': '2014-04-03 13:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e14790678153d2d7dc150eb0418faf43e17426df', 'message': 'vmware: Force chunked transfer for upload-to-image\n\nThe upload-to-image operation downloads (using stream-optimized HTTP NFC\ntransfer) the virtual disk corresponding to the volume to a pipe from\nwhere the glance image client reads the data for upload. Due to a recent\nchange in the glance image client, success in seeking the input file\nobject results in forgoing the chunked transfer in favor of regular\ntransfer. The glance image client expects an IOError if the input file\nobject is a pipe. Currently the pipe seek() is a NOP and this results in\nupload-to-image failure. This changes fixes such failures by throwing\nan IOError indicating an illegal seek.\n\nChange-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879\nCloses-Bug: #1295239\n'}, {'number': 2, 'created': '2014-04-07 13:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba94bfb7d59db4c7b60171103b7e1329b9663747', 'message': 'vmware: Force chunked transfer for upload-to-image\n\nThe upload-to-image operation downloads (using stream-optimized HTTP NFC\ntransfer) the virtual disk corresponding to the volume to a pipe from\nwhere the glance image client reads the data for upload. Due to a recent\nchange in the glance image client, success in seeking the input file\nobject results in forgoing the chunked transfer in favor of regular\ntransfer. The glance image client expects an IOError if the input file\nobject is a pipe. Currently the pipe seek() is a NOP and this results in\nupload-to-image failure. This changes fixes such failures by throwing\nan IOError indicating an illegal seek.\n\nChange-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879\nCloses-Bug: #1295239\n'}, {'number': 3, 'created': '2014-06-20 12:51:47.000000000', 'files': ['cinder/tests/test_vmware_io_util.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/read_write_util.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf18199571b7965a8fe77db3d910b0e798f12946', 'message': 'vmware: Force chunked transfer for upload-to-image\n\nThe upload-to-image operation downloads (using stream-optimized HTTP NFC\ntransfer) the virtual disk corresponding to the volume to a pipe from\nwhere the glance image client reads the data for upload. Due to a recent\nchange in the glance image client, success in seeking the input file\nobject results in forgoing the chunked transfer in favor of regular\ntransfer. The glance image client expects an IOError if the input file\nobject is a pipe. Currently the pipe seek() is a NOP and this results in\nupload-to-image failure. This changes fixes such failures by throwing\nan IOError indicating an illegal seek.\n\nChange-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879\nCloses-Bug: #1295239\n'}]",0,85031,cf18199571b7965a8fe77db3d910b0e798f12946,39,10,3,9171,,,0,"vmware: Force chunked transfer for upload-to-image

The upload-to-image operation downloads (using stream-optimized HTTP NFC
transfer) the virtual disk corresponding to the volume to a pipe from
where the glance image client reads the data for upload. Due to a recent
change in the glance image client, success in seeking the input file
object results in forgoing the chunked transfer in favor of regular
transfer. The glance image client expects an IOError if the input file
object is a pipe. Currently the pipe seek() is a NOP and this results in
upload-to-image failure. This changes fixes such failures by throwing
an IOError indicating an illegal seek.

Change-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879
Closes-Bug: #1295239
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/85031/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/read_write_util.py']",2,e14790678153d2d7dc150eb0418faf43e17426df,bug/1295239, data = self.file_handle.read(READ_CHUNKSIZE) self._progress += len(data) return data, self._progress += READ_CHUNKSIZE return self.file_handle.read(READ_CHUNKSIZE),7,3
openstack%2Ftripleo-incubator~master~If494f3d5165c89200ac5c965c601f6f67645bae2,openstack/tripleo-incubator,master,If494f3d5165c89200ac5c965c601f6f67645bae2,"Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where useful.",MERGED,2014-05-15 15:42:25.000000000,2014-06-23 07:17:37.000000000,2014-06-23 07:17:37.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 5639}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 8041}, {'_account_id': 8532}, {'_account_id': 8688}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-05-15 15:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/ec5261f8602167c2a935a4cf818fe7b3e709c00a', 'message': 'Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where needed.\n\nThis is an attempt to remove duplicated code intended to check\nfor the running OS, I replaced that with the TRIPLEO_OS_* variables\nwhich are set by devtests_variables in the early stages.\n\nChange-Id: If494f3d5165c89200ac5c965c601f6f67645bae2\n'}, {'number': 2, 'created': '2014-05-20 13:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/b105ff26a5b9aa7108d10239dd03cdb42eb498dd', 'message': 'Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where needed.\n\nThis is an attempt to remove duplicated code intended to check\nfor the running OS; I replaced that with simple checks against\nthe TRIPLEO_OS_* variables (set by devtests_variables in the\nearly stages). Documentation is updated a bit to avoid confusion\nbetween TRIPLEO_OS_* and NODE_DIST.\n\nChange-Id: If494f3d5165c89200ac5c965c601f6f67645bae2\n'}, {'number': 3, 'created': '2014-06-05 08:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/67dac032a5716a9c3e16b42f4a51b8093707d10a', 'message': 'Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where useful.\n\nThis is an attempt to remove duplicated code intended to check\nfor the running OS; I replaced that with simple checks against\nthe TRIPLEO_OS_* variables (set by devtests_variables in the\nearly stages). Documentation is updated a bit to avoid confusion\nbetween TRIPLEO_OS_* and NODE_DIST.\n\nChange-Id: If494f3d5165c89200ac5c965c601f6f67645bae2\n'}, {'number': 4, 'created': '2014-06-06 16:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/105b711a145b86a1bd2a6c44f87855b630644452', 'message': 'Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where useful.\n\nThis is an attempt to remove duplicated code intended to check\nfor the running OS; I replaced that with simple checks against\nthe TRIPLEO_OS_* variables (set by devtests_variables in the\nearly stages). Documentation is updated a bit to avoid confusion\nbetween TRIPLEO_OS_* and NODE_DIST.\n\nChange-Id: If494f3d5165c89200ac5c965c601f6f67645bae2\n'}, {'number': 5, 'created': '2014-06-16 03:01:32.000000000', 'files': ['scripts/create-nodes', 'scripts/devtest_variables.sh', 'scripts/install-dependencies', 'README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/3e4738b16e3eb0de30bde39ff1d2e439ceae2243', 'message': 'Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where useful.\n\nThis is an attempt to remove duplicated code intended to check\nfor the running OS; I replaced that with simple checks against\nthe TRIPLEO_OS_* variables (set by devtests_variables in the\nearly stages). Documentation is updated a bit to avoid confusion\nbetween TRIPLEO_OS_* and NODE_DIST.\n\nChange-Id: If494f3d5165c89200ac5c965c601f6f67645bae2\n'}]",5,93745,3e4738b16e3eb0de30bde39ff1d2e439ceae2243,92,14,5,6796,,,0,"Make good use of TRIPLEO_OS_{FAMILY,DISTRO} where useful.

This is an attempt to remove duplicated code intended to check
for the running OS; I replaced that with simple checks against
the TRIPLEO_OS_* variables (set by devtests_variables in the
early stages). Documentation is updated a bit to avoid confusion
between TRIPLEO_OS_* and NODE_DIST.

Change-Id: If494f3d5165c89200ac5c965c601f6f67645bae2
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/45/93745/4 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/create-nodes', 'scripts/install-dependencies']",2,ec5261f8602167c2a935a4cf818fe7b3e709c00a,usergroup_script,"if [ ""$TRIPLEO_OS_DISTRO"" = ""unsupported"" ]; then echo Make sure you have installed all the needed dependencies or subsequent steps will fail.if [ ""$TRIPLEO_OS_FAMILY"" = ""debian"" ]; thenif [ ""$TRIPLEO_OS_FAMILY"" = ""redhat"" ]; then if [ ""$TRIPLEO_OS_DISTRO"" = ""redhat"" -o ""$TRIPLEO_OS_DISTRO"" = ""centos"" ] && [ ! -f /etc/yum.repos.d/epel.repo ]; then echo EPEL repository is required to install python-pip for RHEL/CentOS. echo See http://fedoraproject.org/wiki/EPEL exit 1 fiif [ ""$TRIPLEO_OS_FAMILY"" = ""suse"" ]; then # Need these in path for sudo service & usermod to work PATH=/sbin:/usr/sbin:$PATHcase ""$TRIPLEO_OS_FAMILY"" in 'debian' | 'suse')if [ ""$TRIPLEO_OS_FAMILY"" = ""suse"" ]; thenif [ ""$TRIPLEO_OS_FAMILY"" = ""redhat"" ]; then","os=unsupported if [ -f /etc/redhat-release ]; then if $(grep -Eqs 'Red Hat Enterprise Linux Server release 6|CentOS release 6' /etc/redhat-release); then if [ -f /etc/yum.repos.d/epel.repo ]; then echo EPEL repository is required to install python-pip for RHEL/CentOS. echo See http://fedoraproject.org/wiki/EPEL exit 1 fi fi os=redhat fi if [ -f /etc/debian_version ]; then os=debian fi if [ -f /etc/SuSE-release ]; then os=suse # Need these in path for sudo service & usermod to work PATH=/sbin:/usr/sbin:$PATH fi if [ ""$os"" = ""unsupported"" ]; then echo Aborting.if [ ""$os"" = ""debian"" ]; thenif [ ""$os"" = ""redhat"" ]; thenif [ ""$os"" = ""suse"" ]; thencase ""$os"" in 'Debian' | 'suse')if [ ""$os"" = ""suse"" ]; thenif [ ""$os"" = ""redhat"" ]; then",17,32
openstack%2Fapi-site~master~I12441588edeaf21e2835eb17ff757c60242c5f26,openstack/api-site,master,I12441588edeaf21e2835eb17ff757c60242c5f26,Imported Translations from Transifex,MERGED,2014-06-23 06:01:05.000000000,2014-06-23 07:09:57.000000000,2014-06-23 07:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2014-06-23 06:01:05.000000000', 'files': ['api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/c1ead6f14786e75bc9f744a25c3725c40d24cf1f', 'message': 'Imported Translations from Transifex\n\nChange-Id: I12441588edeaf21e2835eb17ff757c60242c5f26\n'}]",0,101806,c1ead6f14786e75bc9f744a25c3725c40d24cf1f,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I12441588edeaf21e2835eb17ff757c60242c5f26
",git fetch https://review.opendev.org/openstack/api-site refs/changes/06/101806/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po']",2,c1ead6f14786e75bc9f744a25c3725c40d24cf1f,transifex/translations,"""POT-Creation-Date: 2014-06-16 07:44+0000\n"" ""PO-Revision-Date: 2014-06-22 18:21+0000\n"" ""Last-Translator: Andreas Jaeger <jaegerandi@gmail.com>\n""msgstr ""Der Mandantenname. Beide, der <placeholder-1/> und <placeholder-2/> sind optional, sollten aber nicht zusammen angegeben werden. Wenn beide Attribute angegeben sind, antwortet der Server mit <placeholder-3/><placeholder-4/>.""","""POT-Creation-Date: 2014-06-03 09:59+0000\n"" ""PO-Revision-Date: 2014-06-02 14:31+0000\n"" ""Last-Translator: Carsten Duch <cad@teuto.net>\n""msgstr ""Der Mandantenname. Beide, der <placeholder-1/> und <placeholder-2/> sind optional, sollten aber nicht zusammen angegeben werden. Wenn beide Attribute angegeben sind antwortet der Server mit <placeholder-3/><placeholder-4/>.""",13,13
openstack%2Fneutron~master~I71c62f270ac7a1ff1426a3f49a32133b65580e35,openstack/neutron,master,I71c62f270ac7a1ff1426a3f49a32133b65580e35,Configure agents using neutron.common.config.init (formerly .parse),MERGED,2014-06-03 14:01:38.000000000,2014-06-23 06:47:38.000000000,2014-06-18 16:04:32.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9897}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-06-03 14:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57c29c45c69cc27850aae30ec3aa708439a29a08', 'message': ""Configure agents using neutron.common.config.parse (WIP)\nConfigure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 2, 'created': '2014-06-03 14:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9ef98d1c2ee50c05a0ce527406a6c3e10a635ad', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 3, 'created': '2014-06-03 20:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de3168d245a846f7625993d9c266733a34f473fa', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 4, 'created': '2014-06-04 19:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f94f5323aaedb43f19f559e764ce9adc07c055f', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 5, 'created': '2014-06-07 08:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13272216fa2b6d84f70f23245b91de1a106a80b5', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 6, 'created': '2014-06-09 10:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa6736db95c5bfe728bb29748e80514a8cf4b8c0', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 7, 'created': '2014-06-09 14:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f2dfd149e7f467a94d38371a6e764ce56a24e81', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 8, 'created': '2014-06-12 15:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8fd004c79312034b387beca0502dcbed381b6e7', 'message': ""Configure agents using neutron.common.config.parse\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into parse() function, so\nthe first step for migration is to make agents use it.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 9, 'created': '2014-06-12 16:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2c2740e95140a03fdd94dce8813966f9c6741c9', 'message': ""Configure agents using neutron.common.config.init (formerly .parse)\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into init() function, so\nthe first step for migration is to make agents use it.\n\nThe function is renamed to be explicit about the fact that we don't just\nparse configuration by calling it, but also do other common\ninitializations, like setting RPC layer.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 10, 'created': '2014-06-12 21:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee58b87db9fb031f2ab15dc92f44776619a69b4c', 'message': ""Configure agents using neutron.common.config.init (formerly .parse)\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into init() function, so\nthe first step for migration is to make agents use it.\n\nThe function is renamed to be explicit about the fact that we don't just\nparse configuration by calling it, but also do other common\ninitializations, like setting RPC layer.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 11, 'created': '2014-06-14 18:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1b7b5598e6032e4c657a99d26099ebd5225d6ed', 'message': ""Configure agents using neutron.common.config.init (formerly .parse)\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into init() function, so\nthe first step for migration is to make agents use it.\n\nThe function is renamed to be explicit about the fact that we don't just\nparse configuration by calling it, but also do other common\ninitializations, like setting RPC layer.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 12, 'created': '2014-06-16 11:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ca7a35c1eeea2d59133ba71a06870d4bed438ca', 'message': ""Configure agents using neutron.common.config.init (formerly .parse)\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into init() function, so\nthe first step for migration is to make agents use it.\n\nThe function is renamed to be explicit about the fact that we don't just\nparse configuration by calling it, but also do other common\ninitializations, like setting RPC layer.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}, {'number': 13, 'created': '2014-06-17 20:04:45.000000000', 'files': ['neutron/tests/unit/bigswitch/test_restproxy_agent.py', 'neutron/tests/unit/ryu/test_ryu_agent.py', 'neutron/agent/l3_agent.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/cmd/usage_audit.py', 'neutron/server/__init__.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/cmd/sanity_check.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/agent/dhcp_agent.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/ml2/drivers/cisco/apic/test_cisco_apic_common.py', 'neutron/tests/unit/test_debug_commands.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/plugins/oneconvergence/agent/nvsd_neutron_agent.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/plugins/vmware/check_nsx_config.py', 'neutron/tests/base.py', 'neutron/plugins/nec/agent/nec_neutron_agent.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/agent/metadata/agent.py', 'neutron/common/config.py', 'neutron/tests/unit/nec/test_nec_agent.py', 'neutron/plugins/bigswitch/agent/restproxy_agent.py', 'neutron/tests/unit/hyperv/test_hyperv_neutron_agent.py', 'neutron/tests/unit/oneconvergence/test_nvsd_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0db9c23e307a000af5e8fed6960ccd55c0e3a38', 'message': ""Configure agents using neutron.common.config.init (formerly .parse)\n\nAfter oslo.messaging port is done, we'll need to initialize RPC layer\nfrom all RPC agents. We'll put initialization into init() function, so\nthe first step for migration is to make agents use it.\n\nThe function is renamed to be explicit about the fact that we don't just\nparse configuration by calling it, but also do other common\ninitializations, like setting RPC layer.\n\nblueprint oslo-messaging\n\nChange-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35\n""}]",8,97505,c0db9c23e307a000af5e8fed6960ccd55c0e3a38,205,28,13,9656,,,0,"Configure agents using neutron.common.config.init (formerly .parse)

After oslo.messaging port is done, we'll need to initialize RPC layer
from all RPC agents. We'll put initialization into init() function, so
the first step for migration is to make agents use it.

The function is renamed to be explicit about the fact that we don't just
parse configuration by calling it, but also do other common
initializations, like setting RPC layer.

blueprint oslo-messaging

Change-Id: I71c62f270ac7a1ff1426a3f49a32133b65580e35
",git fetch https://review.opendev.org/openstack/neutron refs/changes/05/97505/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/oneconvergence/agent/nvsd_neutron_agent.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/agent/l3_agent.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/cmd/usage_audit.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/plugins/nec/agent/nec_neutron_agent.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/agent/dhcp_agent.py', 'neutron/agent/metadata/agent.py', 'neutron/plugins/bigswitch/agent/restproxy_agent.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/test_debug_commands.py', 'neutron/tests/unit/test_dhcp_agent.py']",18,57c29c45c69cc27850aae30ec3aa708439a29a08,bp/oslo-messaging,from neutron.common import config as common_config common_config.parse(sys.argv[1:]), cfg.CONF(project='neutron'),56,34
openstack%2Fcookbook-openstack-compute~master~I287ee2ce9daa80ca2f17e68b50cf44eefea81c98,openstack/cookbook-openstack-compute,master,I287ee2ce9daa80ca2f17e68b50cf44eefea81c98,Fixes a typo in nova-cert,MERGED,2014-06-20 07:01:38.000000000,2014-06-23 06:25:37.000000000,2014-06-23 06:25:37.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7116}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-06-20 07:01:38.000000000', 'files': ['recipes/nova-cert.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/62bb3793973d68002696d253593d9fcd470dba92', 'message': ""Fixes a typo in nova-cert\n\nIt should be status instead of statusi passed to the supports attribute.\nFor now it doesn't cause any errors but that really depends on how chef\nbehaves.\n\nChange-Id: I287ee2ce9daa80ca2f17e68b50cf44eefea81c98\n""}]",0,101431,62bb3793973d68002696d253593d9fcd470dba92,16,5,1,7116,,,0,"Fixes a typo in nova-cert

It should be status instead of statusi passed to the supports attribute.
For now it doesn't cause any errors but that really depends on how chef
behaves.

Change-Id: I287ee2ce9daa80ca2f17e68b50cf44eefea81c98
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/31/101431/1 && git format-patch -1 --stdout FETCH_HEAD,['recipes/nova-cert.rb'],1,62bb3793973d68002696d253593d9fcd470dba92,fix-typo," supports status: true, restart: true"," supports statusi: true, restart: true",1,1
openstack%2Fnova~master~I7593560b84bda3719de811fbc214b1f52e1a121f,openstack/nova,master,I7593560b84bda3719de811fbc214b1f52e1a121f,Properly skip coreutils readlink tests,MERGED,2014-05-24 03:53:47.000000000,2014-06-23 06:17:46.000000000,2014-06-23 06:17:44.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6509}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-24 03:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5db7f4563d9bfb782621f718548444a740d93937', 'message': ""Mark tests Linux only instead of non-OSX\n\nSome tests in VirtDiskVFSLocalFSTestPaths class are skipped\nif we're running on OSX by doing a check using is_osx() function\nfrom tests.utils. However, these tests are rather Linux only than\nnon OSX, so modify a check to verify we're running on  Linux\nand skip the tests otherwise.\n\nThis change allows to run a complete test suite on OSes rather than\nLinux and OSX, such as FreeBSD.\n\nThese tests were the only consumer of tests.utils.is_osx, but\nit's kept because it could be still potentially useful.\n\nChange-Id: I7593560b84bda3719de811fbc214b1f52e1a121f\n""}, {'number': 2, 'created': '2014-05-26 16:29:59.000000000', 'files': ['nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0380b5d9e46030b92c97ddb80bbd9773a1bb3bf6', 'message': ""Properly skip coreutils readlink tests\n\nSome tests in VirtDiskVFSLocalFSTestPaths class are skipped\nif we're running on OSX by doing a check using is_osx() function\nfrom tests.utils. However, these tests actually require readlink\nfrom coreutils, so replace OS X check by more general check\nfor coreutils readlink presence.\n\nThis change allows to run a complete test suite on OSes rather than\nLinux and OSX, such as FreeBSD.\n\nThese tests were the only consumer of tests.utils.is_osx, but\nit's kept because it could be still potentially useful.\n\nChange-Id: I7593560b84bda3719de811fbc214b1f52e1a121f\n""}]",0,95322,0380b5d9e46030b92c97ddb80bbd9773a1bb3bf6,36,10,2,6509,,,0,"Properly skip coreutils readlink tests

Some tests in VirtDiskVFSLocalFSTestPaths class are skipped
if we're running on OSX by doing a check using is_osx() function
from tests.utils. However, these tests actually require readlink
from coreutils, so replace OS X check by more general check
for coreutils readlink presence.

This change allows to run a complete test suite on OSes rather than
Linux and OSX, such as FreeBSD.

These tests were the only consumer of tests.utils.is_osx, but
it's kept because it could be still potentially useful.

Change-Id: I7593560b84bda3719de811fbc214b1f52e1a121f
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/95322/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_virt_disk_vfs_localfs.py', 'nova/tests/utils.py']",2,5db7f4563d9bfb782621f718548444a740d93937,,def is_linux(): return platform.system() == 'Linux' ,,8,4
openstack%2Foslo.messaging~master~I67cc0774a65886ef9fce0b72e52157b622248a85,openstack/oslo.messaging,master,I67cc0774a65886ef9fce0b72e52157b622248a85,Removes the use of mutables as default args,MERGED,2014-06-07 05:31:14.000000000,2014-06-23 06:10:24.000000000,2014-06-23 06:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 9004}, {'_account_id': 9796}, {'_account_id': 10515}]","[{'number': 1, 'created': '2014-06-07 05:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a8dabce6df7e35cc3b24e4e56e3a197392ee8686', 'message': ""Removes the use of mutables as default args\n\nPassing mutable objects as default args is a known Python pitfall.\nWe'd better avoid this.\n\nChange-Id: I67cc0774a65886ef9fce0b72e52157b622248a85\nCloses-Bug: #1327473\n""}, {'number': 2, 'created': '2014-06-21 03:42:25.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/base.py', 'oslo/messaging/transport.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/_drivers/impl_fake.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/821ee096a6b1dd897892af90b47738051d0fa8f4', 'message': ""Removes the use of mutables as default args\n\nPassing mutable objects as default args is a known Python pitfall.\nWe'd better avoid this.\n\nChange-Id: I67cc0774a65886ef9fce0b72e52157b622248a85\nCloses-Bug: #1327473\n""}]",0,98569,821ee096a6b1dd897892af90b47738051d0fa8f4,24,7,2,9796,,,0,"Removes the use of mutables as default args

Passing mutable objects as default args is a known Python pitfall.
We'd better avoid this.

Change-Id: I67cc0774a65886ef9fce0b72e52157b622248a85
Closes-Bug: #1327473
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/69/98569/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/base.py', 'oslo/messaging/transport.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/impl_fake.py', 'oslo/messaging/_drivers/impl_zmq.py']",7,a8dabce6df7e35cc3b24e4e56e3a197392ee8686,mutable_parameter," _msg_id=None, allowed_remote_exmods=None): allowed_remote_exmods = allowed_remote_exmods or [] envelope=False, allowed_remote_exmods=None): allowed_remote_exmods = allowed_remote_exmods or [] envelope=False, _msg_id=None, allowed_remote_exmods=None): allowed_remote_exmods = allowed_remote_exmods or [] allowed_remote_exmods=None):"," _msg_id=None, allowed_remote_exmods=[]): envelope=False, allowed_remote_exmods=[]): envelope=False, _msg_id=None, allowed_remote_exmods=[]): allowed_remote_exmods=[]):",16,12
openstack%2Fneutron~master~I41286e0b8f74c90b7078c3d3fb041b6586d95ab0,openstack/neutron,master,I41286e0b8f74c90b7078c3d3fb041b6586d95ab0,Remove the useless vim modelines,MERGED,2014-06-19 06:32:05.000000000,2014-06-23 06:10:22.000000000,2014-06-23 06:10:20.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 4726}, {'_account_id': 4727}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 8290}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10018}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}]","[{'number': 1, 'created': '2014-06-19 06:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6daa9f545a6311544f3eea344bcdceb344d23ee', 'message': 'Remove the useless vim modelines\n\nChange-Id: I41286e0b8f74c90b7078c3d3fb041b6586d95ab0\nCloses-Bug: #1229324\n'}, {'number': 2, 'created': '2014-06-21 07:08:18.000000000', 'files': ['neutron/plugins/mlnx/agent/__init__.py', 'neutron/plugins/midonet/__init__.py', 'neutron/plugins/cisco/db/n1kv_models_v2.py', 'neutron/plugins/mlnx/common/__init__.py', 'neutron/services/provider_configuration.py', 'neutron/plugins/embrane/l2base/fake/__init__.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/plugins/cisco/extensions/credential.py', 'neutron/tests/unit/ryu/test_defaults.py', 'neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/plugins/plumgrid/plumgrid_plugin/plugin_ver.py', 'neutron/plugins/brocade/vlanbm.py', 'neutron/tests/unit/test_neutron_manager.py', 'neutron/db/migration/alembic_migrations/versions/38fc1f6789f8_cisco_n1kv_overlay.py', 'neutron/plugins/embrane/common/contexts.py', 'neutron/db/migration/alembic_migrations/versions/263772d65691_cisco_db_cleanup_2.py', 'neutron/db/migration/alembic_migrations/versions/33dd0a9fa487_embrane_lbaas_driver.py', 'neutron/db/migration/alembic_migrations/versions/1d76643bcec4_nvp_netbinding.py', 'neutron/db/migration/alembic_migrations/versions/53bbd27ec841_extra_dhcp_opts_supp.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/plugins/mlnx/db/__init__.py', 'neutron/plugins/cisco/nexus/__init__.py', 'neutron/agent/linux/__init__.py', 'neutron/hooks.py', 'tools/install_venv_common.py', 'neutron/agent/linux/utils.py', 'neutron/plugins/cisco/extensions/policy_profile.py', 'neutron/db/migration/alembic_migrations/versions/3cb5d900c5de_security_groups.py', 'neutron/plugins/vmware/common/nsx_utils.py', 'neutron/services/firewall/drivers/linux/iptables_fwaas.py', 'neutron/services/loadbalancer/constants.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/db/migration/alembic_migrations/versions/1149d7de0cfa_port_security.py', 'neutron/plugins/bigswitch/config.py', 'neutron/tests/unit/services/__init__.py', 'neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py', 'neutron/db/migration/alembic_migrations/versions/477a4488d3f4_ml2_vxlan_type_driver.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsv2.py', 'neutron/plugins/bigswitch/extensions/__init__.py', 'neutron/plugins/vmware/extensions/networkgw.py', 'neutron/agent/linux/ovsdb_monitor.py', 'neutron/plugins/embrane/l2base/support_base.py', 'neutron/tests/unit/test_extension_firewall.py', 'neutron/services/loadbalancer/drivers/__init__.py', 'neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron/plugins/bigswitch/db/__init__.py', 'neutron/tests/unit/brocade/__init__.py', 'neutron/plugins/nec/agent/__init__.py', 'neutron/common/test_lib.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron/plugins/hyperv/__init__.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/db/migration/alembic_migrations/versions/b7a8863760e_rm_cisco_vlan_bindin.py', 'neutron/db/migration/alembic_migrations/versions/1b693c095aa3_quota_ext_db_grizzly.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/plugins/nec/extensions/router_provider.py', 'neutron/db/migration/alembic_migrations/versions/38335592a0dc_nvp_portmap.py', 'neutron/db/migration/alembic_migrations/versions/49332180ca96_ryu_plugin_update.py', 'neutron/plugins/bigswitch/vcsversion.py', 'neutron/plugins/brocade/nos/nosdriver.py', 'neutron/plugins/mlnx/common/exceptions.py', 'neutron/plugins/brocade/nos/nctemplates.py', 'neutron/plugins/linuxbridge/common/constants.py', 'neutron/plugins/vmware/extensions/servicerouter.py', 'neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py', 'neutron/plugins/nec/packet_filter.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/services/loadbalancer/agent/agent_device_driver.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'tools/check_i18n.py', 'neutron/db/migration/alembic_migrations/versions/f44ab9871cd6_bsn_security_groups.py', 'neutron/plugins/embrane/__init__.py', 'neutron/db/migration/alembic_migrations/versions/e6b16a30d97_cisco_provider_nets.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/plugins/hyperv/hyperv_neutron_plugin.py', 'neutron/tests/unit/ryu/test_ryu_db.py', 'neutron/tests/unit/midonet/__init__.py', 'neutron/tests/unit/nec/test_portbindings.py', 'neutron/tests/unit/test_metadata_namespace_proxy.py', 'neutron/services/firewall/__init__.py', 'neutron/tests/unit/test_extension_pnet.py', 'neutron/db/migration/alembic_migrations/versions/3cabb850f4a5_table_to_track_port_.py', 'neutron/quota.py', 'neutron/plugins/vmware/vshield/edge_appliance_driver.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/plugins/embrane/agent/__init__.py', 'neutron/db/migration/alembic_migrations/versions/13de305df56e_add_nec_pf_name.py', 'neutron/db/migration/alembic_migrations/versions/1c33fa3cd1a1_extra_route_config.py', 'neutron/services/firewall/drivers/fwaas_base.py', 'neutron/db/migration/alembic_migrations/versions/grizzly_release.py', 'neutron/plugins/embrane/base_plugin.py', 'neutron/db/migration/alembic_migrations/versions/2a3bae1ceb8_nec_port_binding.py', 'neutron/plugins/plumgrid/drivers/plumlib.py', 'neutron/tests/unit/embrane/test_embrane_defaults.py', 'neutron/agent/linux/daemon.py', 'neutron/db/migration/alembic_migrations/versions/3a520dd165d0_cisco_nexus_multi_switch.py', 'neutron/services/service_base.py', 'neutron/context.py', 'neutron/plugins/embrane/l2base/support_exceptions.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/db/migration/alembic_migrations/versions/86cf4d88bd3_remove_bigswitch_por.py', 'neutron/plugins/embrane/agent/dispatcher.py', 'neutron/db/migration/alembic_migrations/versions/176a85fc7d79_add_portbindings_db.py', 'neutron/db/migration/alembic_migrations/versions/35c7c198ddea_lbaas_healthmon_del_status.py', 'neutron/tests/unit/test_db_migration.py', 'neutron/db/firewall/firewall_db.py', 'neutron/tests/unit/openvswitch/__init__.py', 'neutron/scheduler/__init__.py', 'neutron/plugins/mlnx/common/constants.py', 'neutron/services/loadbalancer/__init__.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/plugins/embrane/agent/operations/router_operations.py', 'neutron/agent/dhcp_agent.py', 'neutron/plugins/bigswitch/db/porttracker_db.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/plugins/plumgrid/drivers/__init__.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/cisco/common/__init__.py', 'neutron/plugins/ryu/db/api_v2.py', 'neutron/tests/unit/ml2/drivers/test_bigswitch_mech.py', 'neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron/tests/unit/test_extension_ext_net.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsfactory.py', 'neutron/tests/unit/test_linux_ip_lib.py', 'neutron/tests/unit/ryu/__init__.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py', 'neutron/plugins/midonet/agent/__init__.py', 'neutron/tests/unit/bigswitch/__init__.py', 'neutron/tests/unit/metaplugin/test_metaplugin.py', 'neutron/tests/unit/ml2/drivers/brocade/test_brocade_mechanism_driver.py', 'neutron/plugins/mlnx/common/config.py', 'neutron/plugins/plumgrid/__init__.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/agent/metadata/namespace_proxy.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/plugins/midonet/agent/midonet_driver.py', 'neutron/tests/unit/nec/test_agent_scheduler.py', 'neutron/tests/unit/hyperv/test_hyperv_neutron_plugin.py', 'neutron/plugins/common/constants.py', 'neutron/plugins/midonet/common/__init__.py', 'neutron/db/migration/alembic_migrations/versions/40dffbf4b549_nvp_dist_router.py', 'neutron/plugins/embrane/plugins/embrane_fake_plugin.py', 'neutron/plugins/nec/drivers/__init__.py', 'neutron/db/migration/alembic_migrations/versions/5918cbddab04_add_tables_for_route.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/db/vpn/__init__.py', 'neutron/agent/linux/ip_lib.py', 'neutron/db/migration/alembic_migrations/versions/ed93525fd003_bigswitch_quota.py', 'neutron/plugins/plumgrid/plumgrid_plugin/__init__.py', 'neutron/services/firewall/drivers/__init__.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/db/migration/alembic_migrations/versions/50d5ba354c23_ml2_binding_vif_details.py', 'neutron/db/migration/alembic_migrations/versions/63afba73813_ovs_tunnelendpoints_id_unique.py', 'neutron/plugins/nec/nec_router.py', 'neutron/api/v2/attributes.py', 'neutron/db/migration/alembic_migrations/versions/54c2c487e913_lbaas.py', 'neutron/tests/unit/agent/linux/__init__.py', 'neutron/plugins/hyperv/db.py', 'neutron/tests/unit/test_iptables_firewall.py', 'neutron/services/firewall/drivers/linux/__init__.py', 'neutron/tests/unit/test_quota_ext.py', 'neutron/plugins/hyperv/common/constants.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/db/migration/alembic_migrations/versions/569e98a8132b_metering.py', 'neutron/plugins/vmware/dhcp_meta/rpc.py', 'neutron/version.py', 'neutron/debug/debug_agent.py', 'neutron/policy.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron/__init__.py', 'neutron/tests/functional/sanity/test_ovs_sanity.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/plugins/metaplugin/meta_models_v2.py', 'neutron/tests/unit/test_debug_commands.py', 'neutron/plugins/nec/drivers/trema.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/plugins/brocade/db/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/tests/unit/extensions/extensionattribute.py', 'neutron/tests/unit/cisco/n1kv/__init__.py', 'neutron/db/firewall/__init__.py', 'neutron/plugins/plumgrid/common/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/__init__.py', 'neutron/plugins/cisco/extensions/_credential_view.py', 'neutron/plugins/bigswitch/__init__.py', 'neutron/plugins/mlnx/db/mlnx_models_v2.py', 'neutron/tests/unit/test_agent_config.py', 'neutron/tests/unit/metaplugin/fake_plugin.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/plugins/cisco/common/cisco_faults.py', 'neutron/plugins/mlnx/rpc_callbacks.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/plugins/nec/common/constants.py', 'neutron/db/migration/alembic_migrations/versions/52ff27f7567a_support_for_vpnaas.py', 'neutron/tests/unit/test_api_v2_resource.py', 'neutron/db/migration/alembic_migrations/versions/8f682276ee4_ryu_plugin_quota.py', 'neutron/plugins/vmware/common/config.py', 'neutron/db/migration/alembic_migrations/versions/11c6e18605c8_pool_monitor_status_.py', 'neutron/tests/unit/test_agent_netns_cleanup.py', 'neutron/db/migration/alembic_migrations/versions/c88b6b5fea3_cisco_n1kv_tables.py', 'neutron/agent/netns_cleanup_util.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/db/migration/alembic_migrations/versions/157a5d299379_ml2_binding_profile.py', 'neutron/tests/unit/database_stubs.py', 'neutron/plugins/linuxbridge/common/__init__.py', 'neutron/services/l3_router/__init__.py', 'neutron/common/rpc.py', 'neutron/plugins/mlnx/common/comm_utils.py', 'neutron/plugins/hyperv/agent/utilsfactory.py', 'neutron/services/__init__.py', 'neutron/tests/unit/nec/test_security_group.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/api/v2/base.py', 'neutron/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/plugins/cisco/__init__.py', 'neutron/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron/tests/unit/test_servicetype.py', 'neutron/debug/commands.py', 'neutron/plugins/nec/common/__init__.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/db/migration/alembic_migrations/versions/32a65f71af51_ml2_portbinding.py', 'neutron/tests/unit/openvswitch/test_ovs_db.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/tests/unit/test_attributes.py', 'neutron/tests/unit/services/firewall/drivers/__init__.py', 'neutron/tests/unit/bigswitch/test_capabilities.py', 'neutron/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron/tests/unit/test_provider_configuration.py', 'tools/install_venv.py', 'neutron/plugins/linuxbridge/db/__init__.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/tests/unit/agent/linux/test_ovsdb_monitor.py', 'neutron/plugins/metaplugin/common/__init__.py', 'neutron/tests/unit/mlnx/__init__.py', 'neutron/db/migration/alembic_migrations/versions/2c4af419145b_l3_support.py', 'neutron/services/vpn/agent.py', 'neutron/plugins/embrane/agent/operations/__init__.py', 'neutron/plugins/embrane/common/config.py', 'neutron/db/migration/alembic_migrations/versions/66a59a7f516_nec_openflow_router.py', 'neutron/plugins/nec/common/exceptions.py', 'neutron/db/migration/alembic_migrations/versions/45680af419f9_nvp_qos.py', 'neutron/plugins/common/utils.py', 'neutron/plugins/cisco/db/__init__.py', 'neutron/plugins/cisco/l2device_plugin_base.py', 'neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py', 'neutron/tests/unit/services/firewall/__init__.py', 'neutron/tests/unit/mlnx/test_mlnx_neutron_agent.py', 'neutron/tests/unit/db/__init__.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/plugins/hyperv/agent/__init__.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/tests/unit/services/firewall/agents/__init__.py', 'neutron/tests/base.py', 'neutron/plugins/cisco/network_plugin.py', 'neutron/plugins/cisco/common/config.py', 'neutron/plugins/nec/extensions/packetfilter.py', 'neutron/plugins/cisco/nexus/cisco_nexus_snippets.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'neutron/plugins/hyperv/agent/utils.py', 'neutron/tests/unit/db/firewall/__init__.py', 'neutron/plugins/bigswitch/version.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/db/migration/alembic_migrations/versions/3d6fae8b70b0_nvp_lbaas_plugin.py', 'neutron/plugins/mlnx/db/mlnx_db_v2.py', 'neutron/tests/unit/extensions/foxinsocks.py', 'neutron/tests/unit/nec/test_config.py', 'neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py', 'neutron/tests/functional/agent/linux/__init__.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/cmd/usage_audit.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/db/migration/alembic_migrations/versions/557edfc53098_new_service_types.py', 'neutron/plugins/cisco/test/nexus/__init__.py', 'neutron/tests/unit/bigswitch/test_agent_scheduler.py', 'neutron/plugins/vmware/extensions/qos.py', 'neutron/agent/firewall.py', 'neutron/tests/unit/embrane/test_embrane_neutron_plugin.py', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/agent/common/__init__.py', 'neutron/plugins/embrane/plugins/__init__.py', 'neutron/db/migration/alembic_migrations/versions/5ac71e65402c_ml2_initial.py', 'neutron/db/migration/alembic_migrations/versions/abc88c33f74f_lb_stats_needs_bigint.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/plugins/embrane/plugins/embrane_ovs_plugin.py', 'neutron/db/migration/alembic_migrations/versions/1341ed32cc1e_nvp_netbinding_update.py', 'neutron/db/migration/alembic_migrations/versions/338d7508968c_vpnaas_peer_address_.py', 'neutron/db/migration/alembic_migrations/versions/50e86cb2637a_nsx_mappings.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/plugins/cisco/db/network_models_v2.py', 'neutron/plugins/cisco/models/virt_phy_sw_v2.py', 'neutron/plugins/common/__init__.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/services/firewall/agents/__init__.py', 'neutron/plugins/ryu/ryu_neutron_plugin.py', 'neutron/tests/unit/hyperv/test_hyperv_neutron_agent.py', 'neutron/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron/db/migration/alembic_migrations/versions/2528ceb28230_nec_pf_netid_fix.py', 'neutron/tests/functional/agent/linux/test_ovsdb_monitor.py', 'neutron/plugins/vmware/vshield/vcns.py', 'neutron/tests/unit/cisco/n1kv/fake_client.py', 'neutron/services/firewall/agents/varmour/varmour_utils.py', 'neutron/tests/unit/extensions/extendedattribute.py', 'neutron/plugins/linuxbridge/common/config.py', 'neutron/db/migration/alembic_migrations/versions/f9263d6df56_remove_dhcp_lease.py', 'neutron/plugins/nec/extensions/__init__.py', 'neutron/plugins/embrane/common/utils.py', 'neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/agent/linux/external_process.py', 'neutron/tests/post_mortem_debug.py', 'neutron/plugins/vmware/dhcp_meta/__init__.py', 'neutron/services/loadbalancer/drivers/radware/__init__.py', 'neutron/plugins/mlnx/__init__.py', 'neutron/db/migration/alembic_migrations/versions/46a0efbd8f0_cisco_n1kv_multisegm.py', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron/plugins/cisco/extensions/qos.py', 'neutron/debug/shell.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/plugins/bigswitch/routerrule_db.py', 'neutron/plugins/cisco/common/cisco_exceptions.py', 'neutron/plugins/nec/db/models.py', 'neutron/tests/unit/linuxbridge/test_lb_security_group.py', 'neutron/tests/unit/test_linux_interface.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/plugins/metaplugin/__init__.py', 'neutron/db/migration/alembic_migrations/versions/49f5e553f61f_ml2_security_groups.py', 'neutron/tests/unit/db/vpn/__init__.py', 'neutron/plugins/bigswitch/tests/__init__.py', 'neutron/tests/unit/test_routerserviceinsertion.py', 'neutron/db/migration/alembic_migrations/versions/e197124d4b9_add_unique_constrain.py', 'neutron/plugins/nec/router_drivers.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/agent/linux/async_process.py', 'neutron/agent/linux/dhcp.py', 'neutron/plugins/nec/db/router.py', 'neutron/tests/unit/linuxbridge/__init__.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/plugins/hyperv/agent/utilsv2.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/db/migration/alembic_migrations/versions/3c6e57a23db4_add_multiprovider.py', 'neutron/plugins/nec/db/packetfilter.py', 'neutron/plugins/midonet/common/config.py', 'neutron/plugins/mlnx/mlnx_plugin.py', 'neutron/db/migration/alembic_migrations/versions/4692d074d587_agent_scheduler.py', 'neutron/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron/plugins/cisco/models/__init__.py', 'neutron/plugins/vmware/check_nsx_config.py', 'neutron/agent/rpc.py', 'neutron/debug/__init__.py', 'neutron/plugins/nec/db/api.py', 'neutron/plugins/metaplugin/meta_db_v2.py', 'neutron/plugins/nec/__init__.py', 'neutron/agent/linux/polling.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/plugins/hyperv/rpc_callbacks.py', 'neutron/plugins/metaplugin/meta_neutron_plugin.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/tests/unit/services/loadbalancer/__init__.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/tests/unit/cisco/__init__.py', 'neutron/plugins/embrane/common/constants.py', 'neutron/plugins/nec/common/ofc_client.py', 'neutron/tests/unit/agent/__init__.py', 'neutron/agent/__init__.py', 'neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py', 'neutron/tests/unit/test_agent_ovs_cleanup.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'neutron/plugins/brocade/nos/fake_nosdriver.py', 'neutron/plugins/embrane/common/exceptions.py', 'neutron/plugins/embrane/common/operation.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/plugins/ryu/common/config.py', 'neutron/services/firewall/agents/l3reference/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/plugins/brocade/db/models.py', 'neutron/tests/unit/db/loadbalancer/__init__.py', 'neutron/services/loadbalancer/drivers/radware/exceptions.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/plugins/cisco/common/cisco_constants.py', 'neutron/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron/services/vpn/common/topics.py', 'neutron/plugins/hyperv/agent_notifier_api.py', 'neutron/plugins/plumgrid/common/exceptions.py', 'neutron/tests/functional/agent/__init__.py', 'bin/neutron-rootwrap', 'neutron/services/vpn/plugin.py', 'neutron/plugins/cisco/common/cisco_credentials_v2.py', 'neutron/db/migration/alembic_migrations/versions/1fcfc149aca4_agents_unique_by_type_and_host.py', 'neutron/services/firewall/agents/varmour/__init__.py', 'neutron/db/loadbalancer/__init__.py', 'neutron/plugins/cisco/db/nexus_models_v2.py', 'neutron/plugins/embrane/common/__init__.py', 'neutron/plugins/cisco/extensions/__init__.py', 'neutron/plugins/vmware/nsxlib/lsn.py', 'neutron/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron/plugins/ml2/drivers/mech_bigswitch/driver.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/tests/unit/extension_stubs.py', 'neutron/cmd/sanity/checks.py', 'neutron/db/migration/alembic_migrations/versions/39cf3f799352_fwaas_havana_2_model.py', 'neutron/wsgi.py', 'neutron/db/migration/alembic_migrations/versions/20ae61555e95_ml2_gre_type_driver.py', 'neutron/tests/unit/plumgrid/test_plumgrid_plugin.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/scheduler/dhcp_agent_scheduler.py', 'neutron/plugins/nec/db/__init__.py', 'tools/with_venv.sh', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/db/migration/alembic_migrations/versions/folsom_initial.py', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/plugins/cisco/extensions/network_profile.py', 'neutron/db/migration/alembic_migrations/versions/f489cf14a79c_lbaas_havana.py', 'neutron/plugins/midonet/plugin.py', 'neutron/tests/unit/agent/linux/test_polling.py', 'neutron/db/migration/alembic_migrations/versions/5a875d0e5c_ryu.py', 'neutron/plugins/embrane/l2base/fake/fake_l2_plugin.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/db/test_agent_db.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py', 'neutron/db/migration/alembic_migrations/versions/14f24494ca31_arista_ml2.py', 'neutron/services/vpn/common/__init__.py', 'neutron/tests/unit/test_api_api_common.py', 'neutron/db/migration/alembic_migrations/versions/3b54bf9e29f7_nec_plugin_sharednet.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/plugins/midonet/common/net_util.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/db/migration/alembic_migrations/versions/2a6d0b51f4bb_cisco_plugin_cleanup.py', 'neutron/agent/common/config.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/tests/functional/__init__.py', 'neutron/tests/unit/_test_rootwrap_exec.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron/plugins/ryu/common/__init__.py', 'neutron/tests/unit/test_metadata_agent.py', 'neutron/tests/unit/nec/test_trema_driver.py', 'neutron/plugins/mlnx/agent/utils.py', 'neutron/tests/unit/dummy_plugin.py', 'neutron/tests/unit/hyperv/__init__.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/tests/unit/nec/__init__.py', 'neutron/plugins/metaplugin/common/config.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/db/migration/alembic_migrations/versions/27ef74513d33_quota_in_plumgrid_pl.py', 'neutron/plugins/hyperv/common/__init__.py', 'neutron/plugins/vmware/vshield/__init__.py', 'neutron/auth.py', 'neutron/db/migration/alembic_migrations/versions/1efb85914233_allowedaddresspairs.py', 'neutron/db/vpn/vpn_db.py', 'neutron/plugins/cisco/extensions/n1kv.py', 'neutron/db/migration/alembic_migrations/versions/havana_release.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/tests/test_server.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/cmd/sanity_check.py', 'neutron/plugins/mlnx/agent_notify_api.py', 'neutron/plugins/openvswitch/common/__init__.py', 'neutron/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron/plugins/hyperv/model.py', 'neutron/plugins/cisco/n1kv/__init__.py', 'neutron/plugins/brocade/nos/__init__.py', 'neutron/services/vpn/__init__.py', 'neutron/db/migration/alembic_migrations/versions/32b517556ec9_remove_tunnelip_mode.py', 'neutron/plugins/cisco/db/nexus_db_v2.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/plugins/embrane/l2base/fake/fakeplugin_support.py', 'neutron/tests/unit/embrane/test_embrane_l3_plugin.py', 'neutron/db/migration/alembic_migrations/versions/icehouse_release.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/test/nexus/fake_nexus_driver.py', 'neutron/tests/unit/nec/test_db.py', 'neutron/plugins/cisco/extensions/_qos_view.py', 'neutron/plugins/vmware/vshield/vcns_driver.py', 'neutron/plugins/brocade/__init__.py', 'neutron/services/firewall/agents/firewall_agent_api.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/tests/unit/__init__.py', 'neutron/plugins/bigswitch/extensions/routerrule.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron/db/migration/alembic_migrations/versions/3ed8f075e38a_nvp_fwaas_plugin.py', 'neutron/tests/unit/midonet/test_midonet_plugin.py', 'neutron/plugins/vmware/common/utils.py', 'neutron/db/migration/alembic_migrations/versions/52c5e4a18807_lbaas_pool_scheduler.py', 'neutron/tests/unit/test_extensions.py', 'neutron/db/migration/alembic_migrations/versions/1064e98b7917_nec_pf_port_del.py', 'neutron/db/migration/alembic_migrations/versions/363468ac592c_nvp_network_gw.py', 'neutron/db/migration/alembic_migrations/versions/3cbf70257c28_nvp_mac_learning.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/plumgrid/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/tests/unit/test_post_mortem_debug.py', 'neutron/plugins/metaplugin/proxy_neutron_plugin.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/plugins/plumgrid/drivers/fake_plumlib.py', 'neutron/tests/__init__.py', 'neutron/tests/unit/extensions/__init__.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/plugins/vmware/vshield/edge_firewall_driver.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/48b6f43f7471_service_type.py', 'neutron/tests/unit/test_extension_extended_attribute.py', 'neutron/plugins/nec/ofc_driver_base.py', 'neutron/plugins/embrane/l2base/__init__.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/plugins/nec/common/config.py', 'neutron/agent/linux/interface.py', 'neutron/tests/unit/embrane/__init__.py', 'neutron/tests/unit/test_linux_external_process.py', 'neutron/plugins/ryu/db/models_v2.py', 'neutron/tests/unit/brocade/test_brocade_db.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/tests/unit/nec/test_nec_agent.py', 'neutron/tests/unit/metaplugin/__init__.py', 'neutron/api/views/versions.py', 'neutron/cmd/__init__.py', 'neutron/agent/metadata/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/tests/unit/nec/stub_ofc_driver.py', 'neutron/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b30c47233d9794149244e1be691cab4cc6f24567', 'message': 'Remove the useless vim modelines\n\nChange-Id: I41286e0b8f74c90b7078c3d3fb041b6586d95ab0\nCloses-Bug: #1229324\n'}]",0,101112,b30c47233d9794149244e1be691cab4cc6f24567,56,26,2,8290,,,0,"Remove the useless vim modelines

Change-Id: I41286e0b8f74c90b7078c3d3fb041b6586d95ab0
Closes-Bug: #1229324
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/101112/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/mlnx/agent/__init__.py', 'neutron/plugins/midonet/__init__.py', 'neutron/plugins/cisco/db/n1kv_models_v2.py', 'neutron/plugins/mlnx/common/__init__.py', 'neutron/services/provider_configuration.py', 'neutron/plugins/embrane/l2base/fake/__init__.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/plugins/cisco/extensions/credential.py', 'neutron/tests/unit/ryu/test_defaults.py', 'neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/plugins/plumgrid/plumgrid_plugin/plugin_ver.py', 'neutron/plugins/brocade/vlanbm.py', 'neutron/tests/unit/test_neutron_manager.py', 'neutron/db/migration/alembic_migrations/versions/38fc1f6789f8_cisco_n1kv_overlay.py', 'neutron/plugins/embrane/common/contexts.py', 'neutron/db/migration/alembic_migrations/versions/263772d65691_cisco_db_cleanup_2.py', 'neutron/db/migration/alembic_migrations/versions/33dd0a9fa487_embrane_lbaas_driver.py', 'neutron/db/migration/alembic_migrations/versions/1d76643bcec4_nvp_netbinding.py', 'neutron/db/migration/alembic_migrations/versions/53bbd27ec841_extra_dhcp_opts_supp.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/plugins/mlnx/db/__init__.py', 'neutron/plugins/cisco/nexus/__init__.py', 'neutron/agent/linux/__init__.py', 'neutron/hooks.py', 'tools/install_venv_common.py', 'neutron/agent/linux/utils.py', 'neutron/plugins/cisco/extensions/policy_profile.py', 'neutron/db/migration/alembic_migrations/versions/3cb5d900c5de_security_groups.py', 'neutron/plugins/vmware/common/nsx_utils.py', 'neutron/services/firewall/drivers/linux/iptables_fwaas.py', 'neutron/services/loadbalancer/constants.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/db/migration/alembic_migrations/versions/1149d7de0cfa_port_security.py', 'neutron/plugins/bigswitch/config.py', 'neutron/tests/unit/services/__init__.py', 'neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py', 'neutron/db/migration/alembic_migrations/versions/477a4488d3f4_ml2_vxlan_type_driver.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsv2.py', 'neutron/plugins/bigswitch/extensions/__init__.py', 'neutron/plugins/vmware/extensions/networkgw.py', 'neutron/agent/linux/ovsdb_monitor.py', 'neutron/plugins/embrane/l2base/support_base.py', 'neutron/tests/unit/test_extension_firewall.py', 'neutron/services/loadbalancer/drivers/__init__.py', 'neutron/tests/unit/ml2/drivers/test_arista_mechanism_driver.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron/plugins/bigswitch/db/__init__.py', 'neutron/tests/unit/brocade/__init__.py', 'neutron/plugins/nec/agent/__init__.py', 'neutron/common/test_lib.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron/plugins/hyperv/__init__.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/db/migration/alembic_migrations/versions/b7a8863760e_rm_cisco_vlan_bindin.py', 'neutron/db/migration/alembic_migrations/versions/1b693c095aa3_quota_ext_db_grizzly.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/plugins/nec/extensions/router_provider.py', 'neutron/db/migration/alembic_migrations/versions/38335592a0dc_nvp_portmap.py', 'neutron/db/migration/alembic_migrations/versions/49332180ca96_ryu_plugin_update.py', 'neutron/plugins/bigswitch/vcsversion.py', 'neutron/plugins/brocade/nos/nosdriver.py', 'neutron/plugins/mlnx/common/exceptions.py', 'neutron/plugins/brocade/nos/nctemplates.py', 'neutron/plugins/linuxbridge/common/constants.py', 'neutron/plugins/vmware/extensions/servicerouter.py', 'neutron/db/migration/alembic_migrations/versions/2032abe8edac_lbaas_add_status_des.py', 'neutron/plugins/nec/packet_filter.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/services/loadbalancer/agent/agent_device_driver.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'tools/check_i18n.py', 'neutron/db/migration/alembic_migrations/versions/f44ab9871cd6_bsn_security_groups.py', 'neutron/plugins/embrane/__init__.py', 'neutron/db/migration/alembic_migrations/versions/e6b16a30d97_cisco_provider_nets.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/plugins/hyperv/hyperv_neutron_plugin.py', 'neutron/tests/unit/ryu/test_ryu_db.py', 'neutron/tests/unit/midonet/__init__.py', 'neutron/tests/unit/nec/test_portbindings.py', 'neutron/tests/unit/test_metadata_namespace_proxy.py', 'neutron/services/firewall/__init__.py', 'neutron/tests/unit/test_extension_pnet.py', 'neutron/db/migration/alembic_migrations/versions/3cabb850f4a5_table_to_track_port_.py', 'neutron/quota.py', 'neutron/plugins/vmware/vshield/edge_appliance_driver.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/plugins/embrane/agent/__init__.py', 'neutron/db/migration/alembic_migrations/versions/13de305df56e_add_nec_pf_name.py', 'neutron/db/migration/alembic_migrations/versions/1c33fa3cd1a1_extra_route_config.py', 'neutron/services/firewall/drivers/fwaas_base.py', 'neutron/db/migration/alembic_migrations/versions/grizzly_release.py', 'neutron/plugins/embrane/base_plugin.py', 'neutron/db/migration/alembic_migrations/versions/2a3bae1ceb8_nec_port_binding.py', 'neutron/plugins/plumgrid/drivers/plumlib.py', 'neutron/tests/unit/embrane/test_embrane_defaults.py', 'neutron/agent/linux/daemon.py', 'neutron/db/migration/alembic_migrations/versions/3a520dd165d0_cisco_nexus_multi_switch.py', 'neutron/services/service_base.py', 'neutron/context.py', 'neutron/plugins/embrane/l2base/support_exceptions.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/db/migration/alembic_migrations/versions/86cf4d88bd3_remove_bigswitch_por.py', 'neutron/plugins/embrane/agent/dispatcher.py', 'neutron/db/migration/alembic_migrations/versions/176a85fc7d79_add_portbindings_db.py', 'neutron/db/migration/alembic_migrations/versions/35c7c198ddea_lbaas_healthmon_del_status.py', 'neutron/tests/unit/test_db_migration.py', 'neutron/db/firewall/firewall_db.py', 'neutron/tests/unit/openvswitch/__init__.py', 'neutron/scheduler/__init__.py', 'neutron/plugins/mlnx/common/constants.py', 'neutron/services/loadbalancer/__init__.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/plugins/embrane/agent/operations/router_operations.py', 'neutron/agent/dhcp_agent.py', 'neutron/plugins/bigswitch/db/porttracker_db.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/plugins/plumgrid/drivers/__init__.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/cisco/common/__init__.py', 'neutron/plugins/ryu/db/api_v2.py', 'neutron/tests/unit/ml2/drivers/test_bigswitch_mech.py', 'neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron/tests/unit/test_extension_ext_net.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/hyperv/test_hyperv_utilsfactory.py', 'neutron/tests/unit/test_linux_ip_lib.py', 'neutron/tests/unit/ryu/__init__.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py', 'neutron/plugins/midonet/agent/__init__.py', 'neutron/tests/unit/bigswitch/__init__.py', 'neutron/tests/unit/metaplugin/test_metaplugin.py', 'neutron/tests/unit/ml2/drivers/brocade/test_brocade_mechanism_driver.py', 'neutron/plugins/mlnx/common/config.py', 'neutron/plugins/plumgrid/__init__.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/agent/metadata/namespace_proxy.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/plugins/midonet/agent/midonet_driver.py', 'neutron/tests/unit/nec/test_agent_scheduler.py', 'neutron/tests/unit/hyperv/test_hyperv_neutron_plugin.py', 'neutron/plugins/common/constants.py', 'neutron/plugins/midonet/common/__init__.py', 'neutron/db/migration/alembic_migrations/versions/40dffbf4b549_nvp_dist_router.py', 'neutron/plugins/embrane/plugins/embrane_fake_plugin.py', 'neutron/plugins/nec/drivers/__init__.py', 'neutron/db/migration/alembic_migrations/versions/5918cbddab04_add_tables_for_route.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/db/vpn/__init__.py', 'neutron/agent/linux/ip_lib.py', 'neutron/db/migration/alembic_migrations/versions/ed93525fd003_bigswitch_quota.py', 'neutron/plugins/plumgrid/plumgrid_plugin/__init__.py', 'neutron/services/firewall/drivers/__init__.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/db/migration/alembic_migrations/versions/50d5ba354c23_ml2_binding_vif_details.py', 'neutron/db/migration/alembic_migrations/versions/63afba73813_ovs_tunnelendpoints_id_unique.py', 'neutron/plugins/nec/nec_router.py', 'neutron/api/v2/attributes.py', 'neutron/db/migration/alembic_migrations/versions/54c2c487e913_lbaas.py', 'neutron/tests/unit/agent/linux/__init__.py', 'neutron/plugins/hyperv/db.py', 'neutron/tests/unit/test_iptables_firewall.py', 'neutron/services/firewall/drivers/linux/__init__.py', 'neutron/tests/unit/test_quota_ext.py', 'neutron/plugins/hyperv/common/constants.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/db/migration/alembic_migrations/versions/569e98a8132b_metering.py', 'neutron/plugins/vmware/dhcp_meta/rpc.py', 'neutron/version.py', 'neutron/debug/debug_agent.py', 'neutron/policy.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron/__init__.py', 'neutron/tests/functional/sanity/test_ovs_sanity.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/plugins/metaplugin/meta_models_v2.py', 'neutron/tests/unit/test_debug_commands.py', 'neutron/plugins/nec/drivers/trema.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/plugins/brocade/db/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/tests/unit/extensions/extensionattribute.py', 'neutron/tests/unit/cisco/n1kv/__init__.py', 'neutron/db/firewall/__init__.py', 'neutron/plugins/plumgrid/common/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/__init__.py', 'neutron/plugins/cisco/extensions/_credential_view.py', 'neutron/plugins/bigswitch/__init__.py', 'neutron/plugins/mlnx/db/mlnx_models_v2.py', 'neutron/tests/unit/test_agent_config.py', 'neutron/tests/unit/metaplugin/fake_plugin.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/plugins/cisco/common/cisco_faults.py', 'neutron/plugins/mlnx/rpc_callbacks.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/plugins/nec/common/constants.py', 'neutron/db/migration/alembic_migrations/versions/52ff27f7567a_support_for_vpnaas.py', 'neutron/tests/unit/test_api_v2_resource.py', 'bin/quantum-rootwrap', 'neutron/db/migration/alembic_migrations/versions/8f682276ee4_ryu_plugin_quota.py', 'neutron/plugins/vmware/common/config.py', 'neutron/db/migration/alembic_migrations/versions/11c6e18605c8_pool_monitor_status_.py', 'neutron/tests/unit/test_agent_netns_cleanup.py', 'neutron/db/migration/alembic_migrations/versions/c88b6b5fea3_cisco_n1kv_tables.py', 'neutron/agent/netns_cleanup_util.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/db/migration/alembic_migrations/versions/157a5d299379_ml2_binding_profile.py', 'neutron/tests/unit/database_stubs.py', 'neutron/plugins/linuxbridge/common/__init__.py', 'neutron/services/l3_router/__init__.py', 'neutron/common/rpc.py', 'neutron/plugins/mlnx/common/comm_utils.py', 'neutron/plugins/hyperv/agent/utilsfactory.py', 'neutron/services/__init__.py', 'neutron/tests/unit/nec/test_security_group.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/api/v2/base.py', 'neutron/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/plugins/cisco/__init__.py', 'neutron/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron/tests/unit/test_servicetype.py', 'neutron/debug/commands.py', 'neutron/plugins/nec/common/__init__.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/db/migration/alembic_migrations/versions/32a65f71af51_ml2_portbinding.py', 'neutron/tests/unit/openvswitch/test_ovs_db.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/tests/unit/test_attributes.py', 'neutron/tests/unit/services/firewall/drivers/__init__.py', 'neutron/tests/unit/bigswitch/test_capabilities.py', 'neutron/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron/tests/unit/test_provider_configuration.py', 'tools/install_venv.py', 'neutron/plugins/linuxbridge/db/__init__.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/tests/unit/agent/linux/test_ovsdb_monitor.py', 'neutron/plugins/metaplugin/common/__init__.py', 'neutron/tests/unit/mlnx/__init__.py', 'neutron/db/migration/alembic_migrations/versions/2c4af419145b_l3_support.py', 'neutron/services/vpn/agent.py', 'neutron/plugins/embrane/agent/operations/__init__.py', 'neutron/plugins/embrane/common/config.py', 'neutron/db/migration/alembic_migrations/versions/66a59a7f516_nec_openflow_router.py', 'neutron/plugins/nec/common/exceptions.py', 'neutron/db/migration/alembic_migrations/versions/45680af419f9_nvp_qos.py', 'neutron/plugins/common/utils.py', 'neutron/plugins/cisco/db/__init__.py', 'neutron/plugins/cisco/l2device_plugin_base.py', 'bin/quantum-rpc-zmq-receiver', 'neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py', 'neutron/tests/unit/services/firewall/__init__.py', 'neutron/tests/unit/mlnx/test_mlnx_neutron_agent.py', 'neutron/tests/unit/db/__init__.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/plugins/hyperv/agent/__init__.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/tests/unit/services/firewall/agents/__init__.py', 'neutron/tests/base.py', 'neutron/plugins/cisco/network_plugin.py', 'neutron/plugins/cisco/common/config.py', 'neutron/plugins/nec/extensions/packetfilter.py', 'neutron/plugins/cisco/nexus/cisco_nexus_snippets.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'neutron/plugins/hyperv/agent/utils.py', 'neutron/tests/unit/db/firewall/__init__.py', 'neutron/plugins/bigswitch/version.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/db/migration/alembic_migrations/versions/3d6fae8b70b0_nvp_lbaas_plugin.py', 'neutron/plugins/mlnx/db/mlnx_db_v2.py', 'neutron/tests/unit/extensions/foxinsocks.py', 'neutron/tests/unit/nec/test_config.py', 'neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py', 'neutron/tests/functional/agent/linux/__init__.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/cmd/usage_audit.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/db/migration/alembic_migrations/versions/557edfc53098_new_service_types.py', 'neutron/plugins/cisco/test/nexus/__init__.py', 'neutron/tests/unit/bigswitch/test_agent_scheduler.py', 'neutron/plugins/vmware/extensions/qos.py', 'neutron/agent/firewall.py', 'neutron/tests/unit/embrane/test_embrane_neutron_plugin.py', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/agent/common/__init__.py', 'neutron/plugins/embrane/plugins/__init__.py', 'neutron/db/migration/alembic_migrations/versions/5ac71e65402c_ml2_initial.py', 'neutron/db/migration/alembic_migrations/versions/abc88c33f74f_lb_stats_needs_bigint.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/plugins/embrane/plugins/embrane_ovs_plugin.py', 'neutron/db/migration/alembic_migrations/versions/1341ed32cc1e_nvp_netbinding_update.py', 'neutron/db/migration/alembic_migrations/versions/338d7508968c_vpnaas_peer_address_.py', 'neutron/db/migration/alembic_migrations/versions/50e86cb2637a_nsx_mappings.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/plugins/cisco/db/network_models_v2.py', 'neutron/plugins/cisco/models/virt_phy_sw_v2.py', 'neutron/plugins/common/__init__.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/services/firewall/agents/__init__.py', 'neutron/plugins/ryu/ryu_neutron_plugin.py', 'neutron/tests/unit/hyperv/test_hyperv_neutron_agent.py', 'neutron/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron/db/migration/alembic_migrations/versions/2528ceb28230_nec_pf_netid_fix.py', 'neutron/tests/functional/agent/linux/test_ovsdb_monitor.py', 'neutron/plugins/vmware/vshield/vcns.py', 'neutron/tests/unit/cisco/n1kv/fake_client.py', 'neutron/services/firewall/agents/varmour/varmour_utils.py', 'neutron/tests/unit/extensions/extendedattribute.py', 'neutron/plugins/linuxbridge/common/config.py', 'neutron/db/migration/alembic_migrations/versions/f9263d6df56_remove_dhcp_lease.py', 'neutron/plugins/nec/extensions/__init__.py', 'neutron/plugins/embrane/common/utils.py', 'neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/agent/linux/external_process.py', 'neutron/tests/post_mortem_debug.py', 'neutron/plugins/vmware/dhcp_meta/__init__.py', 'neutron/services/loadbalancer/drivers/radware/__init__.py', 'neutron/plugins/mlnx/__init__.py', 'neutron/db/migration/alembic_migrations/versions/46a0efbd8f0_cisco_n1kv_multisegm.py', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron/plugins/cisco/extensions/qos.py', 'neutron/debug/shell.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/plugins/bigswitch/routerrule_db.py', 'neutron/plugins/cisco/common/cisco_exceptions.py', 'neutron/plugins/nec/db/models.py', 'neutron/tests/unit/linuxbridge/test_lb_security_group.py', 'neutron/tests/unit/test_linux_interface.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/plugins/metaplugin/__init__.py', 'neutron/db/migration/alembic_migrations/versions/49f5e553f61f_ml2_security_groups.py', 'neutron/tests/unit/db/vpn/__init__.py', 'neutron/plugins/bigswitch/tests/__init__.py', 'neutron/tests/unit/test_routerserviceinsertion.py', 'neutron/db/migration/alembic_migrations/versions/e197124d4b9_add_unique_constrain.py', 'neutron/plugins/nec/router_drivers.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/agent/linux/async_process.py', 'neutron/agent/linux/dhcp.py', 'neutron/plugins/nec/db/router.py', 'neutron/tests/unit/linuxbridge/__init__.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/plugins/hyperv/agent/utilsv2.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/db/migration/alembic_migrations/versions/3c6e57a23db4_add_multiprovider.py', 'neutron/plugins/nec/db/packetfilter.py', 'neutron/plugins/midonet/common/config.py', 'neutron/plugins/mlnx/mlnx_plugin.py', 'neutron/db/migration/alembic_migrations/versions/4692d074d587_agent_scheduler.py', 'neutron/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron/plugins/cisco/models/__init__.py', 'neutron/plugins/vmware/check_nsx_config.py', 'neutron/agent/rpc.py', 'neutron/debug/__init__.py', 'neutron/plugins/nec/db/api.py', 'neutron/plugins/metaplugin/meta_db_v2.py', 'neutron/plugins/nec/__init__.py', 'neutron/agent/linux/polling.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/plugins/hyperv/rpc_callbacks.py', 'neutron/plugins/metaplugin/meta_neutron_plugin.py', 'neutron/tests/unit/nec/test_ofc_client.py', 'neutron/tests/unit/services/loadbalancer/__init__.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py', 'neutron/tests/unit/cisco/__init__.py', 'neutron/plugins/embrane/common/constants.py', 'neutron/plugins/nec/common/ofc_client.py', 'neutron/tests/unit/agent/__init__.py', 'neutron/agent/__init__.py', 'neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py', 'neutron/tests/unit/test_agent_ovs_cleanup.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'neutron/plugins/brocade/nos/fake_nosdriver.py', 'neutron/plugins/embrane/common/exceptions.py', 'neutron/plugins/embrane/common/operation.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/plugins/ryu/common/config.py', 'neutron/services/firewall/agents/l3reference/__init__.py', 'neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/plugins/brocade/db/models.py', 'neutron/tests/unit/db/loadbalancer/__init__.py', 'neutron/services/loadbalancer/drivers/radware/exceptions.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/plugins/cisco/common/cisco_constants.py', 'neutron/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron/services/vpn/common/topics.py', 'neutron/plugins/hyperv/agent_notifier_api.py', 'neutron/plugins/plumgrid/common/exceptions.py', 'neutron/tests/functional/agent/__init__.py', 'bin/neutron-rootwrap', 'neutron/services/vpn/plugin.py', 'neutron/plugins/cisco/common/cisco_credentials_v2.py', 'neutron/db/migration/alembic_migrations/versions/1fcfc149aca4_agents_unique_by_type_and_host.py', 'neutron/services/firewall/agents/varmour/__init__.py', 'neutron/db/loadbalancer/__init__.py', 'neutron/plugins/cisco/db/nexus_models_v2.py', 'neutron/plugins/embrane/common/__init__.py', 'neutron/plugins/cisco/extensions/__init__.py', 'neutron/plugins/vmware/nsxlib/lsn.py', 'neutron/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron/plugins/ml2/drivers/mech_bigswitch/driver.py', 'neutron/plugins/cisco/n1kv/n1kv_client.py', 'neutron/tests/unit/extension_stubs.py', 'neutron/cmd/sanity/checks.py', 'neutron/db/migration/alembic_migrations/versions/39cf3f799352_fwaas_havana_2_model.py', 'neutron/wsgi.py', 'neutron/db/migration/alembic_migrations/versions/20ae61555e95_ml2_gre_type_driver.py', 'neutron/tests/unit/plumgrid/test_plumgrid_plugin.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/scheduler/dhcp_agent_scheduler.py', 'neutron/plugins/nec/db/__init__.py', 'tools/with_venv.sh', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/db/migration/alembic_migrations/versions/folsom_initial.py', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/plugins/cisco/extensions/network_profile.py', 'neutron/db/migration/alembic_migrations/versions/f489cf14a79c_lbaas_havana.py', 'neutron/plugins/midonet/plugin.py', 'neutron/tests/unit/agent/linux/test_polling.py', 'neutron/db/migration/alembic_migrations/versions/5a875d0e5c_ryu.py', 'neutron/plugins/embrane/l2base/fake/fake_l2_plugin.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/db/test_agent_db.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py', 'neutron/db/migration/alembic_migrations/versions/14f24494ca31_arista_ml2.py', 'neutron/services/vpn/common/__init__.py', 'neutron/tests/unit/test_api_api_common.py', 'neutron/db/migration/alembic_migrations/versions/3b54bf9e29f7_nec_plugin_sharednet.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/plugins/midonet/common/net_util.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/db/migration/alembic_migrations/versions/2a6d0b51f4bb_cisco_plugin_cleanup.py', 'neutron/agent/common/config.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/tests/functional/__init__.py', 'neutron/tests/unit/_test_rootwrap_exec.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron/plugins/ryu/common/__init__.py', 'neutron/tests/unit/test_metadata_agent.py', 'neutron/tests/unit/nec/test_trema_driver.py', 'neutron/plugins/mlnx/agent/utils.py', 'neutron/tests/unit/dummy_plugin.py', 'neutron/tests/unit/hyperv/__init__.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/tests/unit/nec/__init__.py', 'neutron/plugins/metaplugin/common/config.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/db/migration/alembic_migrations/versions/27ef74513d33_quota_in_plumgrid_pl.py', 'neutron/plugins/hyperv/common/__init__.py', 'neutron/plugins/vmware/vshield/__init__.py', 'neutron/auth.py', 'neutron/db/migration/alembic_migrations/versions/1efb85914233_allowedaddresspairs.py', 'neutron/db/vpn/vpn_db.py', 'neutron/plugins/cisco/extensions/n1kv.py', 'neutron/db/migration/alembic_migrations/versions/havana_release.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/tests/test_server.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/cmd/sanity_check.py', 'neutron/plugins/mlnx/agent_notify_api.py', 'neutron/plugins/openvswitch/common/__init__.py', 'neutron/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron/plugins/hyperv/model.py', 'neutron/plugins/cisco/n1kv/__init__.py', 'neutron/plugins/brocade/nos/__init__.py', 'neutron/services/vpn/__init__.py', 'neutron/db/migration/alembic_migrations/versions/32b517556ec9_remove_tunnelip_mode.py', 'neutron/plugins/cisco/db/nexus_db_v2.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/plugins/embrane/l2base/fake/fakeplugin_support.py', 'neutron/tests/unit/embrane/test_embrane_l3_plugin.py', 'neutron/db/migration/alembic_migrations/versions/icehouse_release.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/plugins/cisco/test/nexus/fake_nexus_driver.py', 'neutron/tests/unit/nec/test_db.py', 'neutron/plugins/cisco/extensions/_qos_view.py', 'neutron/plugins/vmware/vshield/vcns_driver.py', 'neutron/plugins/brocade/__init__.py', 'neutron/services/firewall/agents/firewall_agent_api.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/tests/unit/__init__.py', 'neutron/plugins/bigswitch/extensions/routerrule.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron/db/migration/alembic_migrations/versions/3ed8f075e38a_nvp_fwaas_plugin.py', 'neutron/tests/unit/midonet/test_midonet_plugin.py', 'neutron/plugins/vmware/common/utils.py', 'neutron/db/migration/alembic_migrations/versions/52c5e4a18807_lbaas_pool_scheduler.py', 'neutron/tests/unit/test_extensions.py', 'neutron/db/migration/alembic_migrations/versions/1064e98b7917_nec_pf_port_del.py', 'neutron/db/migration/alembic_migrations/versions/363468ac592c_nvp_network_gw.py', 'neutron/db/migration/alembic_migrations/versions/3cbf70257c28_nvp_mac_learning.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/plumgrid/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/tests/unit/test_post_mortem_debug.py', 'neutron/plugins/metaplugin/proxy_neutron_plugin.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/plugins/plumgrid/drivers/fake_plumlib.py', 'neutron/tests/__init__.py', 'neutron/tests/unit/extensions/__init__.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/plugins/vmware/vshield/edge_firewall_driver.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/48b6f43f7471_service_type.py', 'neutron/tests/unit/test_extension_extended_attribute.py', 'neutron/plugins/nec/ofc_driver_base.py', 'neutron/plugins/embrane/l2base/__init__.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/plugins/nec/common/config.py', 'neutron/agent/linux/interface.py', 'neutron/tests/unit/embrane/__init__.py', 'neutron/tests/unit/test_linux_external_process.py', 'neutron/plugins/ryu/db/models_v2.py', 'neutron/tests/unit/brocade/test_brocade_db.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/tests/unit/nec/test_nec_agent.py', 'neutron/tests/unit/metaplugin/__init__.py', 'neutron/api/views/versions.py', 'neutron/cmd/__init__.py', 'neutron/agent/metadata/__init__.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/tests/unit/nec/stub_ofc_driver.py', 'neutron/tests/unit/test_auth.py']",544,c6daa9f545a6311544f3eea344bcdceb344d23ee,bug/1229324,,# vim: tabstop=4 shiftwidth=4 softtabstop=4 ,0,1066
openstack%2Fcinder~master~I62564644cfb1fb39b36370e1150da84f54c1e59a,openstack/cinder,master,I62564644cfb1fb39b36370e1150da84f54c1e59a,Add volume service capabilities info to debug log message,ABANDONED,2014-06-23 04:44:43.000000000,2014-06-23 06:09:57.000000000,,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-23 04:44:43.000000000', 'files': ['cinder/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/651de6518e2f5c0ee5801c2cd1cba2340210e59e', 'message': 'Add volume service capabilities info to debug log message\n\nAdd volume service capabilities info to scheduler debug log\nto make it easy to debug.\n\nChange-Id: I62564644cfb1fb39b36370e1150da84f54c1e59a\n'}]",1,101796,651de6518e2f5c0ee5801c2cd1cba2340210e59e,6,3,1,1313,,,0,"Add volume service capabilities info to debug log message

Add volume service capabilities info to scheduler debug log
to make it easy to debug.

Change-Id: I62564644cfb1fb39b36370e1150da84f54c1e59a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/96/101796/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/scheduler/host_manager.py'],1,651de6518e2f5c0ee5801c2cd1cba2340210e59e,detailed_log," ""%(host)s: %(capabilities)s."" % {'service_name': service_name, 'host': host, 'capabilities': capabilities})"," ""%(host)s."" % {'service_name': service_name, 'host': host})",3,2
openstack%2Fnova~master~I5286babcc9afecca5e713bf0a9301e91319548c2,openstack/nova,master,I5286babcc9afecca5e713bf0a9301e91319548c2,Log cleanups for nova.virt.libvirt.vif,ABANDONED,2014-05-22 08:35:47.000000000,2014-06-23 05:51:29.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-22 08:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25e0e077072004b25e403ffb31d10194a01dbc43', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for error and warning levels\n - remove translation of debug logs\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 2, 'created': '2014-05-23 15:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b92196d5b34cba2f962901a7b288172fc85b3720', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for error and warning levels\n - remove translation of debug logs\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 3, 'created': '2014-05-27 12:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c4b72f08262910088a0ec596ea9bbf6ab428c16', 'message': 'Log cleanups.\n\nMore log cleanups:\n - add log hints for error and warning levels\n - remove translation of debug logs\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 4, 'created': '2014-06-03 20:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/520d96739372de3eb13d4dc604461d380b8c5579', 'message': 'Log cleanups for nova.virt.libvirt.vif\n\nMore log cleanups:\n - add log hints for error and warning levels\n - remove translation of debug logs\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 5, 'created': '2014-06-16 21:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/514952faa223af20a3af03436006dd5414f047f9', 'message': 'Log cleanups for nova.virt.libvirt.vif\n\nMore log cleanups:\n - add log hints for error and warning levels\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 6, 'created': '2014-06-17 21:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/958190672c953cb2c7bbf6dd98a5fc5e62a3d275', 'message': 'Log cleanups for nova.virt.libvirt.vif\n\nMore log cleanups:\n - add log hints for error and warning levels\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}, {'number': 7, 'created': '2014-06-19 03:25:50.000000000', 'files': ['nova/virt/libvirt/vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ba8b37c87b33e27cad8d0e1982413afc69f4be5', 'message': 'Log cleanups for nova.virt.libvirt.vif\n\nMore log cleanups:\n - add log hints for error and warning levels\n\nChange-Id: I5286babcc9afecca5e713bf0a9301e91319548c2\n'}]",4,94796,1ba8b37c87b33e27cad8d0e1982413afc69f4be5,96,15,7,2271,,,0,"Log cleanups for nova.virt.libvirt.vif

More log cleanups:
 - add log hints for error and warning levels

Change-Id: I5286babcc9afecca5e713bf0a9301e91319548c2
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/94796/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/vif.py'],1,25e0e077072004b25e403ffb31d10194a01dbc43,log-hints,"from nova.openstack.common.gettextutils import _LE from nova.openstack.common.gettextutils import _LW LOG.debug('vif_type=%(vif_type)s instance=%(instance)s ' 'vif=%(vif)s', LOG.debug('Ensuring vlan %(vlan)s and bridge %(bridge)s', LOG.debug(""Ensuring bridge %s"", LOG.exception(_LE(""Failed while plugging vif""), instance=instance) LOG.exception(_LE(""Failed while plugging vif""), instance=instance) LOG.exception(_LE(""Failed while plugging vif""), instance=instance) LOG.debug('vif_type=%(vif_type)s instance=%(instance)s vif=%(vif)s', LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.exception(_LE(""Failed while unplugging vif""), instance=instance) LOG.debug('vif_type=%(vif_type)s instance=%(instance)s vif=%(vif)s', LOG.warn(_LW('VIF driver \""%s\"" is marked as deprecated and will be ' 'removed in the Juno release.'),"," LOG.debug(_('vif_type=%(vif_type)s instance=%(instance)s ' 'vif=%(vif)s'), LOG.debug(_('Ensuring vlan %(vlan)s and bridge %(bridge)s'), LOG.debug(_(""Ensuring bridge %s""), LOG.exception(_(""Failed while plugging vif""), instance=instance) LOG.exception(_(""Failed while plugging vif""), instance=instance) LOG.exception(_(""Failed while plugging vif""), instance=instance) LOG.debug(_('vif_type=%(vif_type)s instance=%(instance)s ' 'vif=%(vif)s'), LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.exception(_(""Failed while unplugging vif""), instance=instance) LOG.debug(_('vif_type=%(vif_type)s instance=%(instance)s ' 'vif=%(vif)s'), LOG.warn('VIF driver \""%s\"" is marked as deprecated and will be ' 'removed in the Juno release.',",27,20
openstack%2Fcinder~master~I4ba7fe625a88967607adaa18d329bec56825201c,openstack/cinder,master,I4ba7fe625a88967607adaa18d329bec56825201c,Attach log listeners to other engines,MERGED,2014-06-21 02:10:17.000000000,2014-06-23 05:28:35.000000000,2014-06-23 05:28:34.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-21 02:10:17.000000000', 'files': ['cinder/volume/manager.py', 'cinder/scheduler/manager.py', 'cinder/flow_utils.py', 'cinder/volume/flows/common.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/09a369ae1b094c201d4536ebd75b5d18bc3d6ebd', 'message': 'Attach log listeners to other engines\n\nAttach the created task/flow/engine listener to\nthe other usages of taskflow that exist in cinder\nso that those locations can also benefit from\nthe same logging of state and activity.\n\nPart of blueprint task-logging\n\nChange-Id: I4ba7fe625a88967607adaa18d329bec56825201c\n'}]",0,101680,09a369ae1b094c201d4536ebd75b5d18bc3d6ebd,15,5,1,1297,,,0,"Attach log listeners to other engines

Attach the created task/flow/engine listener to
the other usages of taskflow that exist in cinder
so that those locations can also benefit from
the same logging of state and activity.

Part of blueprint task-logging

Change-Id: I4ba7fe625a88967607adaa18d329bec56825201c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/80/101680/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/flow_utils.py', 'cinder/scheduler/manager.py', 'cinder/volume/flows/common.py', 'cinder/volume/api.py']",5,09a369ae1b094c201d4536ebd75b5d18bc3d6ebd,bp/task-logging,"from cinder import flow_utils with flow_utils.DynamicLogListener(flow_engine, logger=LOG):","from cinder.volume.flows import common as flow_common with flow_common.DynamicLogListener(flow_engine, logger=LOG):",106,95
openstack%2Ftempest~master~I60b9f1cf38475faa4cddd9e69fcad575f0d4f1f3,openstack/tempest,master,I60b9f1cf38475faa4cddd9e69fcad575f0d4f1f3,Remove assertTrue from ssh unit tests,MERGED,2014-06-20 12:22:47.000000000,2014-06-23 05:28:27.000000000,2014-06-23 05:28:26.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-20 12:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/130fb1f75b23988f167f17822ba59217bd1722c5', 'message': 'Remove assertTrue from ssh unit tests\n\nThese unit tests failed on gerrit review 98819 with the extremely\nobvious: AssertionError: False is not true.\n\nInstead actually use the Less/Greater assertions so we even know\nwhat the values are on either side of the equation. Also add an\nextra second of buffer to the timeouts, because we have no real\ntime guaruntees here, and a busy system might totally not get around\nto this for an extra second (especially as we are doing int level\ncompares).\n\nChange-Id: I60b9f1cf38475faa4cddd9e69fcad575f0d4f1f3\n'}, {'number': 2, 'created': '2014-06-20 12:25:29.000000000', 'files': ['tempest/tests/test_ssh.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a51495806caa9e409a31b1d9be3d5df819e1c972', 'message': 'Remove assertTrue from ssh unit tests\n\nThese unit tests failed on gerrit review 98819 with the extremely\nobvious: AssertionError: False is not true.\n\nInstead actually use the Less/Greater assertions so we even know\nwhat the values are on either side of the equation. Also add an\nextra second of buffer to the timeouts, because we have no real\ntime guaruntees here, and a busy system might totally not get around\nto this for an extra second (especially as we are doing int level\ncompares).\n\nCloses-Bug: #1332512\n\nChange-Id: I60b9f1cf38475faa4cddd9e69fcad575f0d4f1f3\n'}]",0,101511,a51495806caa9e409a31b1d9be3d5df819e1c972,32,7,2,2750,,,0,"Remove assertTrue from ssh unit tests

These unit tests failed on gerrit review 98819 with the extremely
obvious: AssertionError: False is not true.

Instead actually use the Less/Greater assertions so we even know
what the values are on either side of the equation. Also add an
extra second of buffer to the timeouts, because we have no real
time guaruntees here, and a busy system might totally not get around
to this for an extra second (especially as we are doing int level
compares).

Closes-Bug: #1332512

Change-Id: I60b9f1cf38475faa4cddd9e69fcad575f0d4f1f3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/101511/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/test_ssh.py'],1,130fb1f75b23988f167f17822ba59217bd1722c5,die_assert_true," self.assertLess((end_time - start_time), 4) self.assertGreater((end_time - start_time), 1) self.assertLess((end_time - start_time), 5) self.assertGreaterEqual((end_time - start_time), 2)", self.assertTrue((end_time - start_time) < 3) self.assertTrue((end_time - start_time) > 1) self.assertTrue((end_time - start_time) < 4) self.assertTrue((end_time - start_time) >= 2),4,4
openstack%2Fneutron~master~Ic9b3756ac2bc36ddc689a66c078e205e0674f513,openstack/neutron,master,Ic9b3756ac2bc36ddc689a66c078e205e0674f513,"ValueError should use '%' instead of ','",MERGED,2014-06-17 06:27:41.000000000,2014-06-23 05:28:18.000000000,2014-06-23 05:28:18.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5892}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7505}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9407}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 11114}]","[{'number': 1, 'created': '2014-06-17 06:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1dcedf0af31381cb692819b35044707c936f760', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 2, 'created': '2014-06-17 06:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efb6a0705964bcb16f85083e343ec7379bae584d', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 3, 'created': '2014-06-19 02:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/573b64ee77c8db2426f1b0ca32fbddfe325850a1', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 4, 'created': '2014-06-19 02:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/834e74fe06b9bd1127032f9115592bafab59aba3', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 5, 'created': '2014-06-19 07:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42747d97d71e4bdf9db956eedbf5a3fbe3bd1666', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 6, 'created': '2014-06-19 08:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24124204605f87fd9c83e3c91a64233c48291e43', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 7, 'created': '2014-06-19 09:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa911713a5fb306bccab74afb3ca4ae35ca06759', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 8, 'created': '2014-06-20 01:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb752267fecd71014a0b85ab749267b98cd1600a', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}, {'number': 9, 'created': '2014-06-20 02:44:04.000000000', 'files': ['neutron/manager.py', 'neutron/tests/unit/test_neutron_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/61ac9c379f0acb43cd4bbcd9bd04cd9f53d315ca', 'message': ""ValueError should use '%' instead of ','\n\nThe method _load_service_plugins() in /neutron/neutron/managers.py\n throw a ValueError using ',' to connect log and variables.\nValueError do not support using ',' to connect log and variables,\nwe should use '%' instead of ','\n\nChange-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513\nCloses-Bug:#1264210\n""}]",24,100431,61ac9c379f0acb43cd4bbcd9bd04cd9f53d315ca,159,29,9,11114,,,0,"ValueError should use '%' instead of ','

The method _load_service_plugins() in /neutron/neutron/managers.py
 throw a ValueError using ',' to connect log and variables.
ValueError do not support using ',' to connect log and variables,
we should use '%' instead of ','

Change-Id: Ic9b3756ac2bc36ddc689a66c078e205e0674f513
Closes-Bug:#1264210
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/100431/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/manager.py', 'neutron/tests/unit/test_neutron_manager.py']",2,c1dcedf0af31381cb692819b35044707c936f760,,"import testtools from testtools.matchers._basic import MatchesRegex from testtools.matchers import AfterPreprocessing matcher = AfterPreprocessing(unicode, MatchesRegex('.*%s.*' % constants.DUMMY)) with testtools.ExpectedException(ValueError, matcher): manager.NeutronManager.get_instance() matcher = AfterPreprocessing(unicode, MatchesRegex('.*%s.*' % constants.DUMMY)) with testtools.ExpectedException(ValueError, matcher): manager.NeutronManager.get_instance()"," self.assertRaises(ValueError, manager.NeutronManager.get_instance) self.assertRaises(ValueError, manager.NeutronManager.get_instance)",13,3
openstack%2Ftempest~master~I42d7f22f6194f624f8488493de29e60ff19d211a,openstack/tempest,master,I42d7f22f6194f624f8488493de29e60ff19d211a,Fix T104 for scenario test subdirs,MERGED,2014-06-19 14:22:23.000000000,2014-06-23 05:28:10.000000000,2014-06-23 05:28:09.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 6167}, {'_account_id': 7428}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 14:22:23.000000000', 'files': ['tempest/tests/test_hacking.py', 'tempest/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b12ad764336cdbafcc3289b0b6f16db89d01135f', 'message': ""Fix T104 for scenario test subdirs\n\nThis commit fixes the T104 hacking check to handle subdirs in the\nscenario tests. Previously the check assumed that all the scenario\ntests were in the scenario dir. However, this isn't necessarily the\ncase. For example, the heat scenario tests are all in the path:\ntempest/scenario/orchestration which means they were excluded from\nthe T104 check. This commit fixes the oversight and adds unit tests\nto cover this condition.\n\nChange-Id: I42d7f22f6194f624f8488493de29e60ff19d211a\n""}]",0,101217,b12ad764336cdbafcc3289b0b6f16db89d01135f,14,7,1,5196,,,0,"Fix T104 for scenario test subdirs

This commit fixes the T104 hacking check to handle subdirs in the
scenario tests. Previously the check assumed that all the scenario
tests were in the scenario dir. However, this isn't necessarily the
case. For example, the heat scenario tests are all in the path:
tempest/scenario/orchestration which means they were excluded from
the T104 check. This commit fixes the oversight and adds unit tests
to cover this condition.

Change-Id: I42d7f22f6194f624f8488493de29e60ff19d211a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/17/101217/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/test_hacking.py', 'tempest/hacking/checks.py']",2,b12ad764336cdbafcc3289b0b6f16db89d01135f,fix-t104, if 'tempest/scenario/' in filename and '/test_' in filename:, if 'tempest/scenario/test_' in filename:,7,1
openstack%2Ftempest~master~I4dabe663a177aac853ea0e6f4b58b28da890be71,openstack/tempest,master,I4dabe663a177aac853ea0e6f4b58b28da890be71,Add new rescue compute feature flag,MERGED,2014-06-19 00:37:13.000000000,2014-06-23 05:28:06.000000000,2014-06-23 05:28:05.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 00:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e0eba19c0373acea2356c609adcd8f9da38a636', 'message': 'Add new rescue compute feature flag\n\nThis adds a new feature flag to toggle whether resuce mode is supported by\nthe hypervisor and skips rescue tests accordingly.  The feature is enabled by\ndefault.\n\nChange-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71\nCloses-bug: #1331870.\n'}, {'number': 2, 'created': '2014-06-19 00:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cd2f3064df20da727896d69fb9c8b54b4c01c6ea', 'message': 'Add new rescue compute feature flag\n\nThis adds a new feature flag to toggle whether resuce mode is supported by\nthe hypervisor and skips rescue tests accordingly.  The feature is enabled by\ndefault.\n\nChange-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71\nCloses-bug: #1331870.\n'}, {'number': 3, 'created': '2014-06-19 03:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cecad3b4f273ab03e70c72263900529172743f72', 'message': 'Add new rescue compute feature flag\n\nThis adds a new feature flag to toggle whether resuce mode is supported by\nthe hypervisor and skips rescue tests accordingly.  The feature is enabled by\ndefault.\n\nChange-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71\nCloses-bug: #1331870.\n'}, {'number': 4, 'created': '2014-06-19 06:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/76fc60202c2ffb3396484ba2adfad0c023ef5583', 'message': 'Add new rescue compute feature flag\n\nThis adds a new feature flag to toggle whether resuce mode is supported by\nthe hypervisor and skips rescue tests accordingly.  The feature is enabled by\ndefault.\n\nChange-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71\nCloses-bug: #1331870.\n'}, {'number': 5, 'created': '2014-06-19 23:53:10.000000000', 'files': ['tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/v3/servers/test_server_rescue.py', 'etc/tempest.conf.sample', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/config.py', 'tempest/api/compute/servers/test_server_rescue_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e37b4f18f652cf50880375b260c48cb7b6830e4', 'message': 'Add new rescue compute feature flag\n\nThis adds a new feature flag to toggle whether rescue mode is supported by\nthe hypervisor and skips rescue tests accordingly.  The feature is enabled by\ndefault.\n\nChange-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71\nCloses-bug: #1331870.\n'}]",0,101063,2e37b4f18f652cf50880375b260c48cb7b6830e4,31,7,5,1420,,,0,"Add new rescue compute feature flag

This adds a new feature flag to toggle whether rescue mode is supported by
the hypervisor and skips rescue tests accordingly.  The feature is enabled by
default.

Change-Id: I4dabe663a177aac853ea0e6f4b58b28da890be71
Closes-bug: #1331870.
",git fetch https://review.opendev.org/openstack/tempest refs/changes/63/101063/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/v3/servers/test_server_rescue.py', 'etc/tempest.conf.sample', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/config.py', 'tempest/api/compute/servers/test_server_rescue_negative.py']",6,4e0eba19c0373acea2356c609adcd8f9da38a636,rescue_feature_flag," if not CONF.compute_feature_enabled.rescue: msg = ""Server rescue not available."" raise cls.skipException(msg) ",,27,2
openstack%2Frequirements~master~I17a9fd335e2a3b746ddb069f13bf6cf710b38118,openstack/requirements,master,I17a9fd335e2a3b746ddb069f13bf6cf710b38118,Bump up minimum cliff version to 1.6.0,MERGED,2014-06-20 15:48:19.000000000,2014-06-23 05:28:03.000000000,2014-06-23 05:28:03.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 7680}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-20 15:48:19.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3eaf108264f32bab51adff6c3a6ac0427ac3c119', 'message': 'Bump up minimum cliff version to 1.6.0\n\nOpenStackClient uses --max-width and the value formatter, both introduced\nin 1.6.0.\n\nChange-Id: I17a9fd335e2a3b746ddb069f13bf6cf710b38118\n'}]",0,101588,3eaf108264f32bab51adff6c3a6ac0427ac3c119,16,5,1,970,,,0,"Bump up minimum cliff version to 1.6.0

OpenStackClient uses --max-width and the value formatter, both introduced
in 1.6.0.

Change-Id: I17a9fd335e2a3b746ddb069f13bf6cf710b38118
",git fetch https://review.opendev.org/openstack/requirements refs/changes/88/101588/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,3eaf108264f32bab51adff6c3a6ac0427ac3c119,,cliff>=1.6.0,cliff>=1.4.3,1,1
openstack%2Fmistral-dashboard~master~I7befbaf7f297873361f4e4de9416f84043b83196,openstack/mistral-dashboard,master,I7befbaf7f297873361f4e4de9416f84043b83196,Color statuses for both executions and tasks,MERGED,2014-06-18 08:26:33.000000000,2014-06-23 05:08:58.000000000,2014-06-23 05:08:58.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-06-18 08:26:33.000000000', 'files': ['mistraldashboard/dashboards/mistral/executions/tables.py', 'mistraldashboard/dashboards/mistral/executions/templates/executions/_label.html'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/143e486bcc827fa6cc6adcaade6b21a5a65bb7fb', 'message': 'Color statuses for both executions and tasks\n\nChange-Id: I7befbaf7f297873361f4e4de9416f84043b83196\nImplements: blueprint mistral-ui\n'}]",0,100817,143e486bcc827fa6cc6adcaade6b21a5a65bb7fb,11,4,1,10127,,,0,"Color statuses for both executions and tasks

Change-Id: I7befbaf7f297873361f4e4de9416f84043b83196
Implements: blueprint mistral-ui
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/17/100817/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistraldashboard/dashboards/mistral/executions/tables.py', 'mistraldashboard/dashboards/mistral/executions/templates/executions/_label.html']",2,143e486bcc827fa6cc6adcaade6b21a5a65bb7fb,bp/mistral-ui,"<span class=""label {{ type }}"">{{ label }}</span>",,16,2
openstack%2Fneutron~master~I6460744e2cffec0b9f009da071597374d8c027f6,openstack/neutron,master,I6460744e2cffec0b9f009da071597374d8c027f6,Fix auto_schedule_networks to resist DBDuplicateEntry,MERGED,2014-06-18 13:32:46.000000000,2014-06-23 05:05:22.000000000,2014-06-23 05:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-06-18 13:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbbc12ae90900615f563a9137e799d395a0711fa', 'message': 'Fix auto_schedule_networks to resist DBDuplicateEntry\n\nThis exception may happen if API and RPC workers are in different\nprocesses.\nAlso make minor refactoring of auto_schedule_networks method\nto avoid unnecessary db queries.\n\nChange-Id: I6460744e2cffec0b9f009da071597374d8c027f6\nCloses-Bug: #1331456\n'}, {'number': 2, 'created': '2014-06-20 12:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4daf1b4d2538beff68f19d9858699917663e2766', 'message': 'Fix auto_schedule_networks to resist DBDuplicateEntry\n\nThis exception may happen if API and RPC workers are in different\nprocesses.\nAlso make minor refactoring of auto_schedule_networks method\nto avoid unnecessary db queries.\nAdd missing unit tests and adjust unit test naming style\n\nChange-Id: I6460744e2cffec0b9f009da071597374d8c027f6\nCloses-Bug: #1331456\n'}, {'number': 3, 'created': '2014-06-20 14:08:49.000000000', 'files': ['neutron/tests/unit/test_dhcp_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3867174bc82b7fd85dd79bc0cc5625a15df2d8fb', 'message': 'Fix auto_schedule_networks to resist DBDuplicateEntry\n\nThis exception may happen if API and RPC workers are in different\nprocesses.\nAlso make minor refactoring of auto_schedule_networks method\nto avoid unnecessary db queries.\nAdd missing unit tests and adjust unit test naming style\n\nChange-Id: I6460744e2cffec0b9f009da071597374d8c027f6\nCloses-Bug: #1331456\n'}]",5,100903,3867174bc82b7fd85dd79bc0cc5625a15df2d8fb,58,19,3,6072,,,0,"Fix auto_schedule_networks to resist DBDuplicateEntry

This exception may happen if API and RPC workers are in different
processes.
Also make minor refactoring of auto_schedule_networks method
to avoid unnecessary db queries.
Add missing unit tests and adjust unit test naming style

Change-Id: I6460744e2cffec0b9f009da071597374d8c027f6
Closes-Bug: #1331456
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/100903/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/scheduler/dhcp_agent_scheduler.py'],1,fbbc12ae90900615f563a9137e799d395a0711fa,bug/1331456," # a list of (agent, net_ids) tuples bindings_to_add = [] with context.session.begin(subtransactions=True): fields = ['network_id', 'enable_dhcp'] subnets = plugin.get_subnets(context, fields=fields) net_ids = set(s['network_id'] for s in subnets if s['enable_dhcp']) if not net_ids: LOG.debug(_('No non-hosted networks')) return False bindings_to_add.append((dhcp_agent, net_id)) # do it outside transaction so particular scheduling results don't # make other to fail for agent, net_id in bindings_to_add: self._schedule_bind_network(context, [agent], net_id)"," with context.session.begin(subtransactions=True): fields = ['network_id', 'enable_dhcp'] subnets = plugin.get_subnets(context, fields=fields) net_ids = set(s['network_id'] for s in subnets if s['enable_dhcp']) if not net_ids: LOG.debug(_('No non-hosted networks')) return False binding = agentschedulers_db.NetworkDhcpAgentBinding() binding.dhcp_agent = dhcp_agent binding.network_id = net_id context.session.add(binding)",14,11
openstack%2Fneutron~stable%2Ficehouse~I66221eec0cb4083d178d7d5651360ee1874e3d1b,openstack/neutron,stable/icehouse,I66221eec0cb4083d178d7d5651360ee1874e3d1b,ofagent: Add a missing push_vlan action,MERGED,2014-06-13 03:19:59.000000000,2014-06-23 05:01:45.000000000,2014-06-23 04:03:27.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 8344}, {'_account_id': 9732}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-06-13 03:19:59.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/fake_oflib.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24f2460e14afc4359d6ed23374e549ebbe03e8e5', 'message': 'ofagent: Add a missing push_vlan action\n\nFix the flow for _provision_local_vlan_inbound_for_tunnel\nto push-vlan explicitly.  While the old code happened to\nwork with older versions of OVS, it was spec-wise incorrect because\nit failed to meet the prerequisite of the following set-field.\nThe latest version of OVS correctly rejects such a flow.\n\nCloses-Bug: #1308927\nChange-Id: I66221eec0cb4083d178d7d5651360ee1874e3d1b\n(cherry picked from commit 9f673c2482528bdde15776c52928dbaceecdf811)\n'}]",0,99830,24f2460e14afc4359d6ed23374e549ebbe03e8e5,23,11,1,8344,,,0,"ofagent: Add a missing push_vlan action

Fix the flow for _provision_local_vlan_inbound_for_tunnel
to push-vlan explicitly.  While the old code happened to
work with older versions of OVS, it was spec-wise incorrect because
it failed to meet the prerequisite of the following set-field.
The latest version of OVS correctly rejects such a flow.

Closes-Bug: #1308927
Change-Id: I66221eec0cb4083d178d7d5651360ee1874e3d1b
(cherry picked from commit 9f673c2482528bdde15776c52928dbaceecdf811)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/99830/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/fake_oflib.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py']",3,24f2460e14afc4359d6ed23374e549ebbe03e8e5,bug/stable/icehouse/1308927,"## @author: YAMAMOTO Takashi, VA Linux Systems Japan K.K. self.agent.tun_br.ofparser = importutils.import_module( 'ryu.ofproto.ofproto_v1_3_parser') self.agent.tun_br.datapath = 'tun_br' def test__provision_local_vlan_inbound_for_tunnel(self): with mock.patch.object(self.agent, 'ryu_send_msg') as sendmsg: self.agent._provision_local_vlan_inbound_for_tunnel(1, 'gre', 3) ofp = importutils.import_module('ryu.ofproto.ofproto_v1_3') ofpp = importutils.import_module('ryu.ofproto.ofproto_v1_3_parser') expected_msg = ofpp.OFPFlowMod( 'tun_br', instructions=[ ofpp.OFPInstructionActions( ofp.OFPIT_APPLY_ACTIONS, [ ofpp.OFPActionPushVlan(), ofpp.OFPActionSetField(vlan_vid=1 | ofp.OFPVID_PRESENT), ]), ofpp.OFPInstructionGotoTable(table_id=10), ], match=ofpp.OFPMatch(tunnel_id=3), priority=1, table_id=2) sendmsg.assert_has_calls([mock.call(expected_msg)]) ",,116,18
openstack%2Ftempest~master~I740a95151057ae31d050d51485ec228a5ec9e57f,openstack/tempest,master,I740a95151057ae31d050d51485ec228a5ec9e57f,Don't try to trace non-printable characters in debug output,MERGED,2014-06-19 01:59:43.000000000,2014-06-23 04:58:26.000000000,2014-06-23 04:58:25.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 01:59:43.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c32c09ab443ad1d9e07a1b8625cde9dd807158f', 'message': ""Don't try to trace non-printable characters in debug output\n\nChange-Id: I740a95151057ae31d050d51485ec228a5ec9e57f\n""}]",0,101074,2c32c09ab443ad1d9e07a1b8625cde9dd807158f,13,5,1,1192,,,0,"Don't try to trace non-printable characters in debug output

Change-Id: I740a95151057ae31d050d51485ec228a5ec9e57f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/74/101074/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,2c32c09ab443ad1d9e07a1b8625cde9dd807158f,fix-ascii-issue,"import string filter(lambda x: x in string.printable, str(req_body)[:2048]), filter(lambda x: x in string.printable, str(resp_body)[:2048])),"," str(req_body)[:2048], str(resp_body)[:2048]),",5,2
openstack%2Fnova~master~Iaf8a7414841bed9de7f9d507b17dcb02832ffe78,openstack/nova,master,Iaf8a7414841bed9de7f9d507b17dcb02832ffe78,Allow allocating port which used by instance self,ABANDONED,2014-04-16 10:27:35.000000000,2014-06-23 04:54:40.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1004}, {'_account_id': 1030}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7088}, {'_account_id': 7653}, {'_account_id': 8021}, {'_account_id': 8163}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 8976}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11061}]","[{'number': 1, 'created': '2014-04-16 10:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c094e7bfd5210693b0d521c48ff8bef61636ee0', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfaild for libvit error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allow allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 2, 'created': '2014-04-17 09:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09cf7162f392e72333b73da46e8b77a9cbdbc74d', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 3, 'created': '2014-04-22 03:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e8eeaa3716c3be6a4853c1d2a7446231b461a4b', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 4, 'created': '2014-04-25 06:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc77ea4dc5c9138630691016cf430f8b1ba1e0c1', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 5, 'created': '2014-04-30 05:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ac89f7712556d2abef6691e1f111fb98704c0ed', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance() method.\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 6, 'created': '2014-05-05 08:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adbde31e34ac43a01a94065da782b76ce9c941d5', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 7, 'created': '2014-05-08 03:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ea522cc0daa36dc8e27deccafb54cc20c535dc0', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 8, 'created': '2014-06-03 06:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ad3286844b960d5fe3902a695c6cf71cedc6b78', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}, {'number': 9, 'created': '2014-06-23 01:49:37.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7916f98131f7219cc194c24b8045f98dd24456fa', 'message': 'Allow allocating port which used by instance self\n\nWhen booting an instance with a port specified, if the instance spawn\nfailed for libvirt error, the instance will be rescheduled, and will raise\na ""PortInUse"" exception.\nThis patch allows allocating port which used by the instance self in\nallocate_for_instance().\n\nChange-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78\nCloses-bug: #1308405\n'}]",17,87915,7916f98131f7219cc194c24b8045f98dd24456fa,178,22,9,8290,,,0,"Allow allocating port which used by instance self

When booting an instance with a port specified, if the instance spawn
failed for libvirt error, the instance will be rescheduled, and will raise
a ""PortInUse"" exception.
This patch allows allocating port which used by the instance self in
allocate_for_instance().

Change-Id: Iaf8a7414841bed9de7f9d507b17dcb02832ffe78
Closes-bug: #1308405
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/87915/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,9c094e7bfd5210693b0d521c48ff8bef61636ee0,bug/1308405, if port.get('device_id') and port.get('device_id') \ != instance['uuid']:, if port.get('device_id'):,15,1
openstack%2Fmistral-extra~master~If90698e1235984ba92ff605586ea58b94b96ae1f,openstack/mistral-extra,master,If90698e1235984ba92ff605586ea58b94b96ae1f,Fix run_vm_job example,MERGED,2014-06-20 10:47:19.000000000,2014-06-23 04:29:38.000000000,2014-06-23 04:29:37.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-06-20 10:47:19.000000000', 'files': ['examples/vm_job/run_vm_job.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/5c3cfee53b7503d40cce300ee6e01e2867a5886a', 'message': 'Fix run_vm_job example\n\n * Fixed run_vm_example according to https://review.openstack.org/#/c/100904/,\n   and it is also optimized by defining base-parameters in Nova namespace\n * Fixed task.publish property: we use YAQL in values of dictionaries\n   instead of string key\n\nChange-Id: If90698e1235984ba92ff605586ea58b94b96ae1f\n'}]",0,101474,5c3cfee53b7503d40cce300ee6e01e2867a5886a,11,3,1,7700,,,0,"Fix run_vm_job example

 * Fixed run_vm_example according to https://review.openstack.org/#/c/100904/,
   and it is also optimized by defining base-parameters in Nova namespace
 * Fixed task.publish property: we use YAQL in values of dictionaries
   instead of string key

Change-Id: If90698e1235984ba92ff605586ea58b94b96ae1f
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/74/101474/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/vm_job/run_vm_job.yaml'],1,5c3cfee53b7503d40cce300ee6e01e2867a5886a,fix_run_vm_job, base-parameters: headers: X-Auth-Token: $.openstack.auth_token url: '{$.nova_url}/{$.openstack.project_id}/servers' url: '{$.nova_url}/{$.openstack.project_id}/servers/{$.vm_id}' url: '{$.nova_url}/{$.openstack.project_id}/servers/{$.vm_id}' publish: vm_id: $.vm_id vm_ip: $.vm_ip result: $.summ_result, url: '{$.nova_url}/{$.project_id}/servers' X-Auth-Token: $.auth_token url: '{$.nova_url}/{$.project_id}/servers/{$.vm_id}' headers: X-Auth-Token: $.auth_token url: '{$.nova_url}/{$.project_id}/servers/{$.vm_id}' headers: X-Auth-Token: $.auth_token project_id: $.project_id auth_token: $.auth_token publish: vm_id: vm_id vm_ip: vm_ip project_id: $.project_id auth_token: $.auth_token result: summ_result project_id: $.project_id auth_token: $.auth_token,9,17
openstack%2Fcinder~master~I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d,openstack/cinder,master,I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d,Fix nfs_shares config file parsing of spaces,MERGED,2014-06-17 20:30:20.000000000,2014-06-23 04:26:08.000000000,2014-06-20 19:26:11.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4523}, {'_account_id': 8247}, {'_account_id': 9067}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-17 20:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e5faba0e9dfade80a07f2990398f252ebb6e1b7', 'message': ""Fix nfs_shares config file parsing of spaces\n\nDriver fails in case if 'nfs_shares' file lines contain more than one\nspace between it's patrs. This patch fixes this.\n\nChange-Id: I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d\n""}, {'number': 2, 'created': '2014-06-20 15:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a02f200855bc680d92949d9620a2c87effb1dc90', 'message': ""Fix nfs_shares config file parsing of spaces\n\nDriver fails in case if 'nfs_shares' file lines contain more than one\nspace between it's patrs. This patch fixes this.\n\nChange-Id: I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d\n""}, {'number': 3, 'created': '2014-06-20 17:02:14.000000000', 'files': ['cinder/volume/drivers/nexenta/nfs.py', 'cinder/tests/test_nexenta.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f453bb92b93e3c49136a3788d25b74a3ab95c204', 'message': ""Fix nfs_shares config file parsing of spaces\n\nDriver fails in case if 'nfs_shares' file lines contain more than one\nspace between it's patrs. This patch fixes this.\n\nChange-Id: I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d\n""}]",5,100673,f453bb92b93e3c49136a3788d25b74a3ab95c204,22,6,3,8296,,,0,"Fix nfs_shares config file parsing of spaces

Driver fails in case if 'nfs_shares' file lines contain more than one
space between it's patrs. This patch fixes this.

Change-Id: I446ab23f0ae06ec9e8ad18ebc1d79c705de47e4d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/100673/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/nexenta/nfs.py'],1,5e5faba0e9dfade80a07f2990398f252ebb6e1b7,nexenta_shares_config_fix, share_address = share[:share.find(' ')].strip() share_address = share_address.decode('unicode_escape') nms_url = share[share.find(' '):].strip() if nms_url.find(' '): share_opts = nms_url[nms_url.find(' '):].strip() nms_url = nms_url[:nms_url.find(' ')].strip() else: share_opts = None," share_info = share.split(' ', 2) share_address = share_info[0].strip().decode('unicode_escape') nms_url = share_info[1].strip() share_opts = share_info[2].strip() if len(share_info) > 2 else None",8,4
openstack%2Fcinder~master~I2c5616a1bdf38d7618e7840288c7094df6afecd4,openstack/cinder,master,I2c5616a1bdf38d7618e7840288c7094df6afecd4,Sync the latest common db code from oslo,MERGED,2014-02-28 10:26:36.000000000,2014-06-23 04:23:41.000000000,2014-06-20 16:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 6849}, {'_account_id': 7198}, {'_account_id': 7350}, {'_account_id': 7491}, {'_account_id': 8871}, {'_account_id': 9450}, {'_account_id': 9751}, {'_account_id': 10327}]","[{'number': 1, 'created': '2014-02-28 10:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/868b906209f5550b5c5b89ceb709eaa967846904', 'message': 'WIP: Sync oslo.db code\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}, {'number': 2, 'created': '2014-04-28 08:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8632a9eb278509149c18e75334ede903f446290f', 'message': ""Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator until commit\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it's up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nCo-Authored-By: Roman Podoliaka <rpodolyaka@mirantis.com>\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n""}, {'number': 3, 'created': '2014-04-28 08:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7e89c15fca7a547b50ecc97eb650885863537a6a', 'message': ""Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it's up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nCo-Authored-By: Roman Podoliaka <rpodolyaka@mirantis.com>\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n""}, {'number': 4, 'created': '2014-04-28 11:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2dca8d9c71fc6795393365dd44002fb79eb519e6', 'message': ""Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it's up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nCo-Authored-By: Roman Podoliaka <rpodolyaka@mirantis.com>\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n""}, {'number': 5, 'created': '2014-04-29 13:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed55524e9cc9b426231ad807c784de72990d6852', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}, {'number': 6, 'created': '2014-04-29 14:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d42083418e2b1e3416a9f06c5af5a7a612930398', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}, {'number': 7, 'created': '2014-05-22 12:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbabd44caa49dd72fd512cbc4c826357621cabf7', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}, {'number': 8, 'created': '2014-05-22 12:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/63cc1d6be2d666065c692b8684ce665bf5b69491', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\noslo-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}, {'number': 9, 'created': '2014-06-19 22:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe5f7ee9ab27e28fe93b643e5131bc88efe0769a', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\noslo-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\nCloses-bug: 1231657\n'}, {'number': 10, 'created': '2014-06-20 10:09:47.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/db/api.py', 'cinder/openstack/common/db/sqlalchemy/models.py', 'cinder/openstack/common/context.py', 'cinder/openstack/common/db/options.py', 'cinder/db/sqlalchemy/api.py', 'cinder/openstack/common/db/exception.py', 'cinder/openstack/common/db/sqlalchemy/utils.py', 'cinder/openstack/common/test.py', 'cinder/tests/test_storwize_svc.py', 'cinder/openstack/common/db/sqlalchemy/migration.py', 'cinder/openstack/common/db/sqlalchemy/session.py', 'cinder/openstack/common/db/__init__.py', 'cinder/test.py', 'cinder/openstack/common/db/sqlalchemy/__init__.py', 'cinder/openstack/common/db/sqlalchemy/provision.py', 'cinder/tests/conf_fixture.py', 'cinder/openstack/common/db/api.py', 'cinder/openstack/common/db/sqlalchemy/test_migrations.py', 'cinder/openstack/common/db/sqlalchemy/test_base.py', 'cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f3aafeb2f948936d2f5bad8008d829412289d309', 'message': 'Sync the latest common db code from oslo\n\nThis sync brings the latest openstack/common/db code from\nolso-incubator.\n\nChanges in application code caused by API changes in openstack.common.db -\noslo.db no longer stores SQLAlchemy Engine and sessionmaker instances\nglobally and it\'s up to applications to create them. So we should add\nmethods for work with engine and session to Cinder.\n\nList of changes:\n\n54f7e7f Prevent races in opportunistic db test cases\n8a0f581 Use oslotest instead of common test module\n4a591ea Start ping listener also for postgresql\nf0e50ed Add a warning to not use get_table for working with ForeignKeys\n2fd457b Ignore migrate versioning tables in utf8 sanity check\n9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9\nf7705f3 Make table utf-8 charset checking be optional for DB migration\n5b7e61c Dispose db connections pool on disconnect\n295fcd9 Do not use the \'extend\' method on a dict_items object\nd1988b9 Set sql_mode callback on connect instead of checkout\na1a8280 Fix excessive logging from db.sqlalchemy.session\ndc2d829 Add lockutils fixture to OpportunisticTestCase\nd10f871 Adapt DB provisioning code for CI requirements\n5920bed Make db utils importable without migrate\n9933bdd Get mysql_sql_mode parameter from config\n96a2217 Prevent incorrect usage of _wrap_db_error()\n6cab37c Python3: define a __next__() method for ModelBase\n20a7510 Add from_config() method to EngineFacade\n7959826 db: move all options into database group\nfea119e Drop special case for MySQL traditional mode, update unit tests\na584166 Make TRADITIONAL the default SQL mode\ndda24eb Introduce mysql_sql_mode option, remove old warning\n0b5af67 Introduce a method to set any MySQL session SQL mode\n8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors\n5b9e9f4 Fix doc build errors in db.sqlalchemy\n0f24d82 Fix migration.db_version when no tables\nac84a40 Update log translation domains\nc0d357b Add model_query() to db.sqlalchemy.utils module\n84254fc Fix a small typo in api.py\nb8a676c Remove CONF.database.connection default value\n86707cd Remove None for dict.get()\n0545121 Fix duplicating of SQL queries in logs\nfcf517d Update oslo log messages with translation domains\nfa05b7c Restore the ability to load the DB backend lazily\n630d395 Don\'t use cfg.CONF in oslo.db\nce69e7f Don\'t store engine instances in oslo.db\n35dc1d7 py3kcompat: remove\nb4f72b2 Don\'t raise MySQL 2013 \'Lost connection\' errors\n271adfb Format sql in db.sqlalchemy.session docstring\n0334cb3 Handle exception messages with six.text_type\neff69ce Drop dependency on log from oslo db code\n7a11a04 Automatic retry db.api query if db connection lost\n11f2add Clean up docstring in db.sqlalchemy.session\n1b5147f Only enable MySQL TRADITIONAL mode if we\'re running against MySQL\n39e1c5c Move db tests base.py to common code\n986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+\n9a203e6 Use dialect rather than a particular DB API driver\n1779029 Move helper DB functions to db.sqlalchemy.utils\nbcf6d5e Small edits on help strings\nae01e9a Transition from migrate to alembic\n70ebb19 Fix mocking of utcnow() for model datetime cols\n7aa94df Add a db check for CHARSET=utf8\naff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers\nfa0f36f Fix database connection string is secret\n8575d87 Removed copyright from empty files\nd08d27f Fix the obsolete exception message\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n9bc593e Add docstring for exception handlers of session\n855644a Removal of _REPOSITORY global variable.\nea6caf9 Remove string.lowercase usage\na33989e Remove eventlet tpool from common db.api\ne40903b Database hook enabling traditional mode at MySQL\nf2115a0 Replace xrange in for loop with range\nc802fa6 SQLAlchemy error patterns improved\n1c1f199 Remove unused import\n6d0a6c3 Correct invalid docstrings\n135dd00 Remove start index 0 in range()\n28f8fd5 Make _extra_keys a property of ModelBase\n45658e2 Fix violations of H302:import only modules\nbb4d7a2 Enables db2 server disconnects to be handled pessimistically\n915f8ab db.sqlalchemy.session add [sql].idle_timeout\ne6494c2 Use six.iteritems to make dict work on Python2/3\n48cfb7b Drop dependency on processutils from oslo db code\n4c47d3e Fix locking in migration tests\nc2ee282 Incorporating MIT licensed code\nc5a1088 Typos fix in db and periodic_task module\nfb0e86a Use six.moves.configparser instead of ConfigParser\n1dd4971 fix typo in db session docstring\n8a01dd8 The ability to run tests at various backend\n0fe4e28 Use log.warning() instead of log.warn() in oslo.db\n12bcdb7 Remove vim header\n4c22556 Use py3kcompat urlutils functions instead of urlparse\nca7a2ab Don\'t use deprecated module commands\n6603e8f Remove sqlalchemy-migrate 0.7.3 patching\n274c7e2 Drop dependency on lockutils from oslo db code\n97d8cf4 Remove lazy loading of database backend\n2251cb5 Do not name variables as builtins\n3acd57c Add db2 communication error code when check the db connection\nc2dcf6e Add [sql].connection as deprecated opt for db\n001729d Modify SQLA session due to dispose of eventlet\n4de827a Clean up db.sqla.Models.extra_keys interface\n347f29e Use functools.wrap() instead of custom implementation\n771d843 Move base migration test classes to common code\n9721129 exception: remove\n56ff3b3 Use single meta when change column type\n3f2f70e Helper function to sanitize db url credentials\ndf3f2ba BaseException.message is deprecated since Python 2.6\nc76be5b Add function drop_unique_constraint()\nd4d8126 Change sqlalchemy/utils.py mode back to 644\ncf41936 Move sqlalchemy migration from Nova\n5758360 Raise ValueError if sort_dir is unknown\n31c1995 python3: Add python3 compatibility support\n3972c3f Migrate sqlalchemy utils from Nova\n1a2df89 Enable H302 hacking check\n3f503fa Add a monkey-patching util for sqlalchemy-migrate\n7ba5f4b Don\'t use mixture of cfg.Opt() deprecated args\n489e2b7 Ensure that DB configuration is backward compatible\n7119e29 Enable hacking H404 test.\nebaa578 Enable user to configure pool_timeout\n30cb47e Changed processing unique constraint name.\n6d27681 Enable H306 hacking check.\n444bdbc Add a slave db handle for the SQLAlchemy backend.\n484a1df Enable hacking H403 test\n4ff33b0 Specify database group instead of DEFAULT\n\nChange-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4\n'}]",10,77125,f3aafeb2f948936d2f5bad8008d829412289d309,92,11,10,7491,,,0,"Sync the latest common db code from oslo

This sync brings the latest openstack/common/db code from
olso-incubator.

Changes in application code caused by API changes in openstack.common.db -
oslo.db no longer stores SQLAlchemy Engine and sessionmaker instances
globally and it's up to applications to create them. So we should add
methods for work with engine and session to Cinder.

List of changes:

54f7e7f Prevent races in opportunistic db test cases
8a0f581 Use oslotest instead of common test module
4a591ea Start ping listener also for postgresql
f0e50ed Add a warning to not use get_table for working with ForeignKeys
2fd457b Ignore migrate versioning tables in utf8 sanity check
9fed4ed Fix Keystone doc build errors with SQLAlchemy 0.9
f7705f3 Make table utf-8 charset checking be optional for DB migration
5b7e61c Dispose db connections pool on disconnect
295fcd9 Do not use the 'extend' method on a dict_items object
d1988b9 Set sql_mode callback on connect instead of checkout
a1a8280 Fix excessive logging from db.sqlalchemy.session
dc2d829 Add lockutils fixture to OpportunisticTestCase
d10f871 Adapt DB provisioning code for CI requirements
5920bed Make db utils importable without migrate
9933bdd Get mysql_sql_mode parameter from config
96a2217 Prevent incorrect usage of _wrap_db_error()
6cab37c Python3: define a __next__() method for ModelBase
20a7510 Add from_config() method to EngineFacade
7959826 db: move all options into database group
fea119e Drop special case for MySQL traditional mode, update unit tests
a584166 Make TRADITIONAL the default SQL mode
dda24eb Introduce mysql_sql_mode option, remove old warning
0b5af67 Introduce a method to set any MySQL session SQL mode
8dccc7b Handle ibm_db_sa DBDuplicateEntry integrity errors
5b9e9f4 Fix doc build errors in db.sqlalchemy
0f24d82 Fix migration.db_version when no tables
ac84a40 Update log translation domains
c0d357b Add model_query() to db.sqlalchemy.utils module
84254fc Fix a small typo in api.py
b8a676c Remove CONF.database.connection default value
86707cd Remove None for dict.get()
0545121 Fix duplicating of SQL queries in logs
fcf517d Update oslo log messages with translation domains
fa05b7c Restore the ability to load the DB backend lazily
630d395 Don't use cfg.CONF in oslo.db
ce69e7f Don't store engine instances in oslo.db
35dc1d7 py3kcompat: remove
b4f72b2 Don't raise MySQL 2013 'Lost connection' errors
271adfb Format sql in db.sqlalchemy.session docstring
0334cb3 Handle exception messages with six.text_type
eff69ce Drop dependency on log from oslo db code
7a11a04 Automatic retry db.api query if db connection lost
11f2add Clean up docstring in db.sqlalchemy.session
1b5147f Only enable MySQL TRADITIONAL mode if we're running against MySQL
39e1c5c Move db tests base.py to common code
986dafd Fix parsing of UC errors in sqlite 3.7.16+/3.8.2+
9a203e6 Use dialect rather than a particular DB API driver
1779029 Move helper DB functions to db.sqlalchemy.utils
bcf6d5e Small edits on help strings
ae01e9a Transition from migrate to alembic
70ebb19 Fix mocking of utcnow() for model datetime cols
7aa94df Add a db check for CHARSET=utf8
aff0171 Remove ""vim: tabstop=4 shiftwidth=4 softtabstop=4"" from headers
fa0f36f Fix database connection string is secret
8575d87 Removed copyright from empty files
d08d27f Fix the obsolete exception message
8b2b0b7 Use hacking import_exceptions for gettextutils._
9bc593e Add docstring for exception handlers of session
855644a Removal of _REPOSITORY global variable.
ea6caf9 Remove string.lowercase usage
a33989e Remove eventlet tpool from common db.api
e40903b Database hook enabling traditional mode at MySQL
f2115a0 Replace xrange in for loop with range
c802fa6 SQLAlchemy error patterns improved
1c1f199 Remove unused import
6d0a6c3 Correct invalid docstrings
135dd00 Remove start index 0 in range()
28f8fd5 Make _extra_keys a property of ModelBase
45658e2 Fix violations of H302:import only modules
bb4d7a2 Enables db2 server disconnects to be handled pessimistically
915f8ab db.sqlalchemy.session add [sql].idle_timeout
e6494c2 Use six.iteritems to make dict work on Python2/3
48cfb7b Drop dependency on processutils from oslo db code
4c47d3e Fix locking in migration tests
c2ee282 Incorporating MIT licensed code
c5a1088 Typos fix in db and periodic_task module
fb0e86a Use six.moves.configparser instead of ConfigParser
1dd4971 fix typo in db session docstring
8a01dd8 The ability to run tests at various backend
0fe4e28 Use log.warning() instead of log.warn() in oslo.db
12bcdb7 Remove vim header
4c22556 Use py3kcompat urlutils functions instead of urlparse
ca7a2ab Don't use deprecated module commands
6603e8f Remove sqlalchemy-migrate 0.7.3 patching
274c7e2 Drop dependency on lockutils from oslo db code
97d8cf4 Remove lazy loading of database backend
2251cb5 Do not name variables as builtins
3acd57c Add db2 communication error code when check the db connection
c2dcf6e Add [sql].connection as deprecated opt for db
001729d Modify SQLA session due to dispose of eventlet
4de827a Clean up db.sqla.Models.extra_keys interface
347f29e Use functools.wrap() instead of custom implementation
771d843 Move base migration test classes to common code
9721129 exception: remove
56ff3b3 Use single meta when change column type
3f2f70e Helper function to sanitize db url credentials
df3f2ba BaseException.message is deprecated since Python 2.6
c76be5b Add function drop_unique_constraint()
d4d8126 Change sqlalchemy/utils.py mode back to 644
cf41936 Move sqlalchemy migration from Nova
5758360 Raise ValueError if sort_dir is unknown
31c1995 python3: Add python3 compatibility support
3972c3f Migrate sqlalchemy utils from Nova
1a2df89 Enable H302 hacking check
3f503fa Add a monkey-patching util for sqlalchemy-migrate
7ba5f4b Don't use mixture of cfg.Opt() deprecated args
489e2b7 Ensure that DB configuration is backward compatible
7119e29 Enable hacking H404 test.
ebaa578 Enable user to configure pool_timeout
30cb47e Changed processing unique constraint name.
6d27681 Enable H306 hacking check.
444bdbc Add a slave db handle for the SQLAlchemy backend.
484a1df Enable hacking H403 test
4ff33b0 Specify database group instead of DEFAULT

Change-Id: I2c5616a1bdf38d7618e7840288c7094df6afecd4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/25/77125/10 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/openstack/common/gettextutils.py', 'cinder/db/api.py', 'cinder/openstack/common/db/sqlalchemy/models.py', 'cinder/openstack/common/context.py', 'cinder/openstack/common/db/options.py', 'cinder/db/sqlalchemy/api.py', 'cinder/openstack/common/db/exception.py', 'cinder/openstack/common/db/sqlalchemy/utils.py', 'cinder/openstack/common/test.py', 'cinder/openstack/common/db/sqlalchemy/migration.py', 'cinder/openstack/common/db/sqlalchemy/session.py', 'cinder/openstack/common/db/__init__.py', 'cinder/test.py', 'cinder/openstack/common/db/sqlalchemy/__init__.py', 'cinder/openstack/common/db/sqlalchemy/provision.py', 'cinder/tests/conf_fixture.py', 'cinder/openstack/common/db/api.py', 'cinder/openstack/common/db/sqlalchemy/test_migrations.py', 'cinder/openstack/common/db/sqlalchemy/test_base.py', 'cinder/db/sqlalchemy/models.py']",21,868b906209f5550b5c5b89ceb709eaa967846904,sync-oslo-db," def save(self, session=None): from cinder.db.sqlalchemy import api as db_api if session is None: session = db_api.get_session() super(CinderBase, self).save(session) ",,2463,461
openstack%2Fcinder~master~I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e,openstack/cinder,master,I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e,Use oslo-incubator module units,MERGED,2013-12-30 11:42:04.000000000,2014-06-23 03:47:12.000000000,2014-06-23 03:47:12.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9366}, {'_account_id': 9624}, {'_account_id': 9751}, {'_account_id': 9796}]","[{'number': 1, 'created': '2013-12-30 11:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7a629cc15f618614ea4c32bce95e59e06ffa793e', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 2, 'created': '2014-01-01 23:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/512a064845f4c18cef2cba506ca2251a5982623a', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 3, 'created': '2014-01-17 16:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/291544a3f1277fe5464cb569ecb39cbdb2a341ed', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 4, 'created': '2014-02-06 13:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/421f4007b06b388603cfcab715c6870230252e79', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 5, 'created': '2014-02-06 14:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad64781f0fcb3d330789e4348886cc9db6af8d16', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 6, 'created': '2014-02-15 00:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7140dbce7700ec339a281ba6d23cccffd29cf0ea', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 7, 'created': '2014-02-15 06:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6fa19b2d83eec754ef4c0ccb679810ea62eb6ff8', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 8, 'created': '2014-02-20 15:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9cb13147fc196a921fe5ab9672321cd50306993f', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 9, 'created': '2014-02-20 15:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b0a67fba14b1c9399c38e420bb45e1673dd6760', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 10, 'created': '2014-02-25 01:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/06fd8d32999afc4bfcaad676bca8647a653ff9d9', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 11, 'created': '2014-03-03 08:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/18ca2450f101c29b0dad7b258af4fe635cd9f4c2', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 12, 'created': '2014-03-03 10:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74ba30382fb827cadc21bf9b2940c095af96778e', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 13, 'created': '2014-03-05 12:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/06a5704e0f5a8e269b97c57626557b9adfebec78', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 14, 'created': '2014-03-05 16:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7a48c650fa86396447b78335a0c0afec46d5ee3e', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 15, 'created': '2014-03-14 02:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50aa1789e98389dd649171011c8cb0368b96255f', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 16, 'created': '2014-03-14 04:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f688db96f1e67637b0c397828fc09f9e16fdc672', 'message': 'Use common module units in Oslo\n\nModule units in oslo include more brief definitions for units const,\nand also was synced into other projects like glance. Let us do this\nfor Cinder.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n'}, {'number': 17, 'created': '2014-04-30 03:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9230a83a239309c6d09e8c82717f98a011367721', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 18, 'created': '2014-05-10 14:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd6a1b6716509eb0c1f5a28f5d1793508db30ed7', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 19, 'created': '2014-05-21 16:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9f1d77518f309d28bc9ce8a598a72b04d118a33f', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 20, 'created': '2014-05-21 20:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f18e6ef1b1e41550c9fce2c9d8cb41727bc5c572', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 21, 'created': '2014-05-30 08:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ca092a08a9e67a57f12be61f2252adf99dcb627', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 22, 'created': '2014-06-18 13:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/34a547f5e1fea6aa4ae323f82ead7aed3807cc33', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 23, 'created': '2014-06-18 14:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5a1596f222314532d4f469c20165af78fbf17cec', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 24, 'created': '2014-06-19 02:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f9cd18cb5b412c516d57a280d72ce752823b1a99', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}, {'number': 25, 'created': '2014-06-21 16:12:23.000000000', 'files': ['cinder/volume/flows/api/create_volume.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'openstack-common.conf', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/solidfire.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/tests/test_nfs.py', 'cinder/tests/test_gpfs.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/tests/test_nexenta.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/tests/test_coraid.py', 'cinder/volume/utils.py', 'cinder/tests/test_hplefthand.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/nexenta/utils.py', 'cinder/tests/test_solidfire.py', 'cinder/tests/test_vmware_vmdk.py', 'cinder/volume/drivers/scality.py', 'cinder/tests/test_glusterfs.py', 'cinder/tests/test_vmware_volumeops.py', 'cinder/tests/test_volume.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/tests/test_scality.py', 'cinder/volume/drivers/hds/hnas_backend.py', 'cinder/backup/drivers/ceph.py', 'cinder/volume/drivers/lvm.py', 'cinder/volume/drivers/xenapi/lib.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/test_sheepdog.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/openstack/common/units.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f13e7e0fd4e84372cffa891c5470f2bb094b760', 'message': ""Use oslo-incubator module units\n\nThere is Cinder's version units module, that looks good. Considering\nconsistency with other projects like Nova, Glance, Cinder would be\nbetter to use oslo-incubator's version.\n\nChange-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e\n""}]",3,64429,7f13e7e0fd4e84372cffa891c5470f2bb094b760,160,10,25,9796,,,0,"Use oslo-incubator module units

There is Cinder's version units module, that looks good. Considering
consistency with other projects like Nova, Glance, Cinder would be
better to use oslo-incubator's version.

Change-Id: I07e93e9d8a985df0f96c3e80de9c3f23bf6a0c1e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/64429/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/huawei/rest_common.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/test_volume.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_scality.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/backup/drivers/ceph.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/xenapi/lib.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/tests/test_nfs.py', 'cinder/volume/drivers/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_gpfs.py', 'cinder/volume/flows/create_volume/__init__.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/test_nexenta.py', 'cinder/tests/test_sheepdog.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/storwize_svc.py', 'cinder/tests/test_coraid.py', 'cinder/volume/utils.py', 'cinder/tests/test_backup_ceph.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/nexenta/utils.py', 'cinder/tests/test_solidfire.py', 'cinder/tests/test_vmware_vmdk.py', 'cinder/openstack/common/units.py', 'cinder/volume/drivers/scality.py', 'cinder/tests/test_glusterfs.py']",36,7a629cc15f618614ea4c32bce95e59e06ffa793e,new_units,"from cinder.openstack.common import units AndReturn((2 * units.Gi, 5 * units.Gi)) AndReturn((3 * units.Gi, 10 * units.Gi)) AndReturn((0, 5 * units.Gi)) AndReturn((0, 10 * units.Gi)) str(volume['size'] * units.Gi),","from cinder import units AndReturn((2 * units.GiB, 5 * units.GiB)) AndReturn((3 * units.GiB, 10 * units.GiB)) AndReturn((0, 5 * units.GiB)) AndReturn((0, 10 * units.GiB)) str(volume['size'] * units.GiB),",173,158
openstack%2Ftempest~master~I26449a2a881be396daf75838451cfe01a915f513,openstack/tempest,master,I26449a2a881be396daf75838451cfe01a915f513,Don't store duplicate policies for server_group,MERGED,2014-05-30 01:30:31.000000000,2014-06-23 03:27:40.000000000,2014-06-23 03:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 7428}, {'_account_id': 8021}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-30 01:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/068c57d8cf17a9dd4fd21ab586bc00b31623aefb', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nThis patch relates to the bug I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nin Nova. So I need to modify the issue here firstly.\n\nAfter this patch merged, I'll fix the issue in Nova. And more correlate\ntest-cases will definitly be supplied in tempest.\n\nChange-Id: I26449a2a881be396daf75838451cfe01a915f513\nCloses-Bug: #1324348\n""}, {'number': 2, 'created': '2014-05-30 02:57:02.000000000', 'files': ['tempest/api/compute/servers/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/af630da010ae7083e0a4da87b5014f45d90ac7ef', 'message': ""Don't store duplicate policies for server_group\n\nIt doesn't make sense to store same policies in a server_group.\nWe only need to store one and ignore the duplicate policies.\n\nThis patch relates to the bug I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b\nin Nova. So I need to skip one test-case here firstly in order to modify the\nissue in Nova.\n\nAfter the Nova's patch merged, this test-case will be restored,\nand more correlate cases will definitly be supplied in tempest.\n\nChange-Id: I26449a2a881be396daf75838451cfe01a915f513\nCloses-Bug: #1324348\n""}]",0,96645,af630da010ae7083e0a4da87b5014f45d90ac7ef,44,8,2,8021,,,0,"Don't store duplicate policies for server_group

It doesn't make sense to store same policies in a server_group.
We only need to store one and ignore the duplicate policies.

This patch relates to the bug I4f3ad544aef78cbbc076c7a47cca04832a2f5b4b
in Nova. So I need to skip one test-case here firstly in order to modify the
issue in Nova.

After the Nova's patch merged, this test-case will be restored,
and more correlate cases will definitly be supplied in tempest.

Change-Id: I26449a2a881be396daf75838451cfe01a915f513
Closes-Bug: #1324348
",git fetch https://review.opendev.org/openstack/tempest refs/changes/45/96645/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_group.py'],1,068c57d8cf17a9dd4fd21ab586bc00b31623aefb,bug/1324348," policies = ['affinity', 'anti-affinity']"," policies = ['affinity', 'affinity']",1,1
openstack%2Fcinder-specs~master~Id7b026121e7f36fcd15a19e73f4fc9faab428b52,openstack/cinder-specs,master,Id7b026121e7f36fcd15a19e73f4fc9faab428b52,Add BP for Huawei-SDSHypervisor-Driver,ABANDONED,2014-06-21 04:44:15.000000000,2014-06-23 02:34:06.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-21 04:44:15.000000000', 'files': ['specs/juno/huawei-sdshypervisor-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b3d95d225595ac018db31c0f1ccf972e88bd2cf3', 'message': 'Add BP for Huawei-SDSHypervisor-Driver\n\nChange-Id: Id7b026121e7f36fcd15a19e73f4fc9faab428b52\n'}]",0,101687,b3d95d225595ac018db31c0f1ccf972e88bd2cf3,4,1,1,11538,,,0,"Add BP for Huawei-SDSHypervisor-Driver

Change-Id: Id7b026121e7f36fcd15a19e73f4fc9faab428b52
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/87/101687/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/huawei-sdshypervisor-driver.rst'],1,b3d95d225595ac018db31c0f1ccf972e88bd2cf3,bp/for,"============================================== Cinder volume driver for Huawei SDSHypervisor ==============================================This proposal is to add Huawei SDSHypervisor driver to cinder. Huawei SDSHypervisor is a software defined storage product, is a software runing in host, virtualizes heterogeneous SAN device to provide virtual block device based user's QoS, while providing advanced features such as snapshot, clone, cache and so on. We will add a new Cinder driver that using socket API interact with Huawei SDShypervisor storage. SDShypervisor data panel using private Key value protocal, so we also add a new connector to realize attach/detach volume. ```` ```` Add new driver in /cinder/volume/drivers path, and realize cinder driverAdd new connector in cinder/brick/initiator path, and realize abstract connector methods:","============================================= Cinder volume driver for Huawei SDSHypervisor =============================================This proposal is to add Huawei SDSHypervisor driver to cinder. Huawei SDSHypervisor is a software defined storage product, is a software runing in host, virtualizes heterogeneous SAN device to provide virtual block device based user's QoS, while providing advanced features such as snapshot, clone, cache and so on. We will add a new Cinder driver that using socket API interact with Huawei SDShypervisor storage. SDShypervisor data panel using private Key value protocal, so we also add a new connector to realize attach/detach volume.```` Add new driver in /cinder/volume/drivers path, and realize cinder driver Add new connector in cinder/brick/initiator path, and realize abstract connector methods:",20,10
openstack%2Fcinder-specs~master~I803841bb783dd7ccb3a01ca5c88bcbaad3ce0b72,openstack/cinder-specs,master,I803841bb783dd7ccb3a01ca5c88bcbaad3ce0b72,This BP would add Huawei SDShypervisor driver.,ABANDONED,2014-06-21 03:35:26.000000000,2014-06-23 02:33:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-21 03:35:26.000000000', 'files': ['specs/juno/huawei-sdshypervisor-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/32c24051500f741392aff74a5151dd9a37028168', 'message': 'This BP would add Huawei SDShypervisor driver.\n\nChange-Id: I803841bb783dd7ccb3a01ca5c88bcbaad3ce0b72\n'}]",0,101685,32c24051500f741392aff74a5151dd9a37028168,5,1,1,11538,,,0,"This BP would add Huawei SDShypervisor driver.

Change-Id: I803841bb783dd7ccb3a01ca5c88bcbaad3ce0b72
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/85/101685/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/huawei-sdshypervisor-driver.rst'],1,32c24051500f741392aff74a5151dd9a37028168,bp/cinder driver,"============================================= Cinder volume driver for Huawei SDSHypervisor =============================================This proposal is to add Huawei SDSHypervisor driver to cinder. Huawei SDSHypervisor is a software defined storage product, is a software runing in host, virtualizes heterogeneous SAN device to provide virtual block device based user's QoS, while providing advanced features such as snapshot, clone, cache and so on. Currently, Huawei SDShypervisor cann't be accessed by Openstack Cinder.We will add a new Cinder driver that using socket API interact with Huawei SDShypervisor storage. SDShypervisor data panel using private Key value protocal, so we also add a new connector to realize attach/detach volume. The following diagram shows the command and data paths. `` +------------------+ | | | Cinder + | | Cinder Volume | | | | | +------------------+ | | | | | | | | +---------------+-------+ +----+------------------+ | | | | + | | | | SDShypervisor | | SDShypervisor Driver | | connector | | | | | | | +-----------------------+ +-----------------------+ | | | | | | CLI Socket API | | | | | | +--+-----------+---+ | | | | | SDShypervisor | | storeage | | | +------------------+ `` Add new driver in /cinder/volume/drivers path, and realize cinder driver minimum features: * Volume Create/Delete * Volume Attach/Detach * Snapshot Create/Delete * Create Volume from Snapshot * Get Volume Stats * Copy Image to Volume * Copy Volume to Image * Clone Volume * Extend Volume Add new connector in cinder/brick/initiator path, and realize abstract connector methods: * connect_volume * disconnect_volumeRealize Cinder driver minimum features using socket API. Realize new connector using CLI.","============================================== Cinder volume driver for Huawei SDSHypervisor ==============================================This proposal is to add Huawei SDSHypervisor driver to cinder. Huawei SDSHypervisor is a software defined storage product, which virtualizes heterogeneous SAN device to provide virtual block device based user QoS, while providing advanced features such as snapshot, clone and so on.Currently, Huawei SDSHypervisor cann't be accessed by cinder and used by nova compute.Add new driver in /cinder/volume/drivers path, and realize cinder driver minimum features: *Volume Create/Delete *Volume Attach/Detach *Snapshot Create/Delete *Create Volume from Snapshot *Get Volume Stats *Copy Image to Volume *Copy Volume to Image *Clone Volume *Extend Volume Realize cinder driver minimum features using socket interact with SDShypervisor.",61,21
openstack%2Fcinder-specs~master~I0c6bf29bac73c1e948cbb107acdec37ed2d8968e,openstack/cinder-specs,master,I0c6bf29bac73c1e948cbb107acdec37ed2d8968e,Add BP for Huawei-SDSHypervisor-Driver,ABANDONED,2014-06-21 03:35:26.000000000,2014-06-23 02:33:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-21 03:35:26.000000000', 'files': ['specs/juno/huawei-sdshypervisor-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/dc24fc6d3b236bc1aefd6b784e56f9a38b7a7d6a', 'message': 'Add BP for Huawei-SDSHypervisor-Driver\n\nChange-Id: I0c6bf29bac73c1e948cbb107acdec37ed2d8968e\n'}]",0,101684,dc24fc6d3b236bc1aefd6b784e56f9a38b7a7d6a,4,1,1,11538,,,0,"Add BP for Huawei-SDSHypervisor-Driver

Change-Id: I0c6bf29bac73c1e948cbb107acdec37ed2d8968e
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/84/101684/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/huawei-sdshypervisor-driver.rst'],1,dc24fc6d3b236bc1aefd6b784e56f9a38b7a7d6a,bp/would,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Cinder volume driver for Huawei SDSHypervisor ============================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/huawei-sdshypervisor-driver This proposal is to add Huawei SDSHypervisor driver to cinder. Huawei SDSHypervisor is a software defined storage product, which virtualizes heterogeneous SAN device to provide virtual block device based user QoS, while providing advanced features such as snapshot, clone and so on. Problem description =================== Currently, Huawei SDSHypervisor cann't be accessed by cinder and used by nova compute. Proposed change =============== Add new driver in /cinder/volume/drivers path, and realize cinder driver minimum features: *Volume Create/Delete *Volume Attach/Detach *Snapshot Create/Delete *Create Volume from Snapshot *Get Volume Stats *Copy Image to Volume *Copy Volume to Image *Clone Volume *Extend Volume Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: zhangni <zhangni@huawei.com> Other contributors: None Work Items ---------- Realize cinder driver minimum features using socket interact with SDShypervisor. Dependencies ============ None Testing ======= None Documentation Impact ==================== The CinderSupportMatrix table should be updated to add Huawei SDShypervisor. https://wiki.openstack.org/wiki/CinderSupportMatrix References ========== None ",,130,0
openstack%2Fneutron~master~I5dc954a849a8598b5a2926d3a155efca14851b3a,openstack/neutron,master,I5dc954a849a8598b5a2926d3a155efca14851b3a,NSX: Ensure that DynamicLoop for sync doesn't raise,ABANDONED,2014-04-01 18:57:27.000000000,2014-06-23 02:28:08.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7317}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-04-01 18:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd1e6e00181e9dc86c08446f8cebb0029168aa76', 'message': ""NSX: Ensure that DynamicLoop for sync doesn't raise\n\nIf the method called within DynamicLoop raises an exception the\nDynamicLoop stops running. This patch fixes this by adding a method\nthat catches any exception raises by _synchronize_state(). There is\nno mechanism in loopingcalls that provides the ability to keep running\nif an exception is raised.\n\nChange-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a\nCloses-bug: #1300952\n""}, {'number': 2, 'created': '2014-04-01 19:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f4f4b245f53519e5b5d21664fe6ea0a43b3e23a', 'message': ""NSX: Ensure that DynamicLoop for sync doesn't raise\n\nIf the method called within DynamicLoop raises an exception the\nDynamicLoop stops running. This patch fixes this by adding a method\nthat catches any exception raises by _synchronize_state(). There is\nno mechanism in loopingcalls that provides the ability to keep running\nif an exception is raised.\n\nChange-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a\nCloses-bug: #1300952\n""}, {'number': 3, 'created': '2014-04-01 21:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4fb2519ef0a30375476b2795a6b2ad4b79358a70', 'message': ""NSX: Ensure that DynamicLoop for sync doesn't raise\n\nIf the method called within DynamicLoop raises an exception the\nDynamicLoop stops running. This patch fixes this by adding a method\nthat catches any exception raises by _synchronize_state(). There is\nno mechanism in loopingcalls that provides the ability to keep running\nif an exception is raised.\n\nChange-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a\nCloses-bug: #1300952\n""}, {'number': 4, 'created': '2014-04-01 21:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7867d37c2408b1452638017247c6a9a552d3105', 'message': ""NSX: Ensure that DynamicLoop for sync doesn't raise\n\nIf the method called within DynamicLoop raises an exception the\nDynamicLoop stops running. This patch fixes this by adding a method\nthat catches any exception raises by _synchronize_state(). There is\nno mechanism in loopingcalls that provides the ability to keep running\nif an exception is raised.\n\nChange-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a\nCloses-bug: #1300952\n""}, {'number': 5, 'created': '2014-04-02 17:34:16.000000000', 'files': ['neutron/plugins/vmware/common/sync.py', 'neutron/tests/unit/vmware/test_nsx_sync.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7870109997f21775465bba67729682d4f317d775', 'message': ""NSX: Ensure that DynamicLoop for sync doesn't raise\n\nIf the method called within DynamicLoop raises an exception the\nDynamicLoop stops running. This patch fixes this by adding a method\nthat catches any exception raises by _synchronize_state(). There is\nno mechanism in loopingcalls that provides the ability to keep running\nif an exception is raised.\n\nChange-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a\nCloses-bug: #1300952\n""}]",10,84523,7870109997f21775465bba67729682d4f317d775,75,18,5,4395,,,0,"NSX: Ensure that DynamicLoop for sync doesn't raise

If the method called within DynamicLoop raises an exception the
DynamicLoop stops running. This patch fixes this by adding a method
that catches any exception raises by _synchronize_state(). There is
no mechanism in loopingcalls that provides the ability to keep running
if an exception is raised.

Change-Id: I5dc954a849a8598b5a2926d3a155efca14851b3a
Closes-bug: #1300952
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/84523/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/vmware/common/sync.py', 'neutron/tests/unit/vmware/test_nsx_sync.py']",2,cd1e6e00181e9dc86c08446f8cebb0029168aa76,master," def test_looping_call_never_die(self): with mock.patch.object(sync.NsxSynchronizer, '_synchronize_state', return_value=0.01) as nsx_sync: with mock.patch.object(sync.NsxSynchronizer, '_synchronize_state_never_raise'): nsx_sync.side_effect = Exception synchronizer = sync.NsxSynchronizer(mock.ANY, mock.ANY, 100, 0, 0) time.sleep(.03) # stop looping call before asserting synchronizer._sync_looping_call.stop() self.assertTrue( synchronizer._synchronize_state_never_raise.call_count) ",,27,1
openstack%2Fneutron~master~Idde71c37f5d5c113ac04376ed607e0c156b07477,openstack/neutron,master,Idde71c37f5d5c113ac04376ed607e0c156b07477,Check NVP router's status before deploying a service,MERGED,2014-03-31 07:15:36.000000000,2014-06-23 02:16:34.000000000,2014-06-14 04:53:09.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 7317}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-31 07:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d366d08c8309b411ccccfb7121f464c1f6565a0', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 2, 'created': '2014-04-01 02:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8781ba2b4072ae1ee1c7f9dc6de7dfd5266e7884', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 3, 'created': '2014-04-08 02:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ee6994f5bb398ec77f905083a4e739f7612d329', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 4, 'created': '2014-04-14 08:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99304e588a096aeeb23ada0b4740cb75ae5e5662', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 5, 'created': '2014-04-25 06:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ffec9966cb184feb792faa4ba9a779f2cd256eee', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 6, 'created': '2014-04-26 04:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e0911c2daded8a5f68b795d261e67a69440c009', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 7, 'created': '2014-05-26 08:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ca68bbe37699466e6ed95ba439300c178e3fd35', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}, {'number': 8, 'created': '2014-06-09 03:21:55.000000000', 'files': ['neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/plugins/vmware/common/exceptions.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/25103df197c1f366eac8dd3069fabc01d3bd18e9', 'message': 'Check NVP router\'s status before deploying a service\n\nWith NVP advanced service plugin, router creation is asynchronous while\nall service call is synchronous, so it is possible that advanced service\nrequest is called before edge deployment completed.\nThe solution is to check the router status before deploying an advanced service.\nIf the router is not in ACTIVE status, the service deployment request would return\n""Router not in \'ACTIVE\' status"" error.\n\nChange-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477\nCloses-Bug: #1298865\n'}]",19,84072,25103df197c1f366eac8dd3069fabc01d3bd18e9,167,23,8,7317,,,0,"Check NVP router's status before deploying a service

With NVP advanced service plugin, router creation is asynchronous while
all service call is synchronous, so it is possible that advanced service
request is called before edge deployment completed.
The solution is to check the router status before deploying an advanced service.
If the router is not in ACTIVE status, the service deployment request would return
""Router not in 'ACTIVE' status"" error.

Change-Id: Idde71c37f5d5c113ac04376ed607e0c156b07477
Closes-Bug: #1298865
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/84072/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py']",5,0d366d08c8309b411ccccfb7121f464c1f6565a0,router_check,"import testtools def test_create_firewall_without_policy(self, **extras): if 'router_id' in extras: attrs['router_id'] = extras.pop('router_id') else: attrs['router_id'] = self._create_and_get_router() test_db_firewall.ADMIN_STATE_UP) as fw: def test_create_firewall_with_invalid_router(self): name = ""new_fw"" attrs = self._get_test_firewall_attrs(name) attrs['router_id'] = self._create_and_get_router() with testtools.ExpectedException(webob.exc.HTTPClientError): self.test_create_firewall_without_policy(router_id=None) with testtools.ExpectedException(webob.exc.HTTPClientError): self.test_create_firewall_without_policy(router_id='invalid_id') with testtools.ExpectedException(webob.exc.HTTPClientError): router_id = self._create_and_get_router( arg_list=('service_router',), service_router=False) self.test_create_firewall_without_policy(router_id=router_id) with testtools.ExpectedException(webob.exc.HTTPClientError): router_id = self._create_and_get_router(active_set=False) self.test_create_firewall_without_policy(router_id=router_id) "," def _create_and_get_router(self): req = self._create_router(self.fmt, self._tenant_id) res = self.deserialize(self.fmt, req) return res['router']['id'] def test_create_firewall_without_policy(self): attrs['router_id'] = self._create_and_get_router() test_db_firewall.ADMIN_STATE_UP, expected_res_status=201) as fw:",117,54
openstack%2Fnova~master~Id43ea931c995865ddc3455abfb625d86dd93e78f,openstack/nova,master,Id43ea931c995865ddc3455abfb625d86dd93e78f,Migrate nvp-qos to generic name qos-queue,MERGED,2014-06-11 21:27:24.000000000,2014-06-23 02:11:45.000000000,2014-06-23 02:11:43.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-11 21:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24ff374c74ba5cc718de048e925d4f5181683e43', 'message': 'Make nvp-qos a constant like other extensions\n\nThis patch moves nvp-qos to the constants file as the other extensions are\ndone and improves a doc string.\n\nChange-Id: Id43ea931c995865ddc3455abfb625d86dd93e78f\nCloses-bug: 1329075\n'}, {'number': 2, 'created': '2014-06-16 23:07:58.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/network/neutronv2/constants.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/41bb7dc7b9886a8000c3c1759b2c305ec91824fd', 'message': ""Migrate nvp-qos to generic name qos-queue\n\nIn Juno, the nvp-qos extension was renamed to qos-queue in favor of having\na generic name. In order to maintain backwards compatibility neutron\nadvertises both nvp-qos and qos-queue (since icehouse). This patch phases out\nnvp-qos from nova so that it uses qos-queue so that in Kxxx we'll be able to\ndrop nvp-qos from neutron completely.\n\nIn addition this patch moves qos-queue to a constant like the other extensions\nand improves a doc string.\n\nChange-Id: Id43ea931c995865ddc3455abfb625d86dd93e78f\nCloses-bug: 1329075\n""}]",0,99485,41bb7dc7b9886a8000c3c1759b2c305ec91824fd,34,12,2,4395,,,0,"Migrate nvp-qos to generic name qos-queue

In Juno, the nvp-qos extension was renamed to qos-queue in favor of having
a generic name. In order to maintain backwards compatibility neutron
advertises both nvp-qos and qos-queue (since icehouse). This patch phases out
nvp-qos from nova so that it uses qos-queue so that in Kxxx we'll be able to
drop nvp-qos from neutron completely.

In addition this patch moves qos-queue to a constant like the other extensions
and improves a doc string.

Change-Id: Id43ea931c995865ddc3455abfb625d86dd93e78f
Closes-bug: 1329075
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/99485/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/network/neutronv2/constants.py']",3,24ff374c74ba5cc718de048e925d4f5181683e43,bug/1329075,NVP_QOS_EXT = 'nvp-qos',,8,5
openstack%2Fopenstack-manuals~master~If45df5045988528426e9109cd5f8e54a5e88077e,openstack/openstack-manuals,master,If45df5045988528426e9109cd5f8e54a5e88077e,Add Japanese documents to www/ja,MERGED,2014-06-22 01:13:15.000000000,2014-06-23 02:03:23.000000000,2014-06-23 02:03:22.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-06-22 01:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/11e75c302a712698c69141580cabae455a308bbc', 'message': 'Add Japanese documents to www/ja\n\nAdd Japanese documents to www/ja as current draft.\n\nChange-Id: If45df5045988528426e9109cd5f8e54a5e88077e\n'}, {'number': 2, 'created': '2014-06-23 00:10:16.000000000', 'files': ['www/draft-i18n-manuals.html', 'www/ja/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f8d0ce4350da524f3f624e4a831e94dc117e40be', 'message': 'Add Japanese documents to www/ja\n\nAdd Japanese documents to www/ja as current draft.\n\nChange-Id: If45df5045988528426e9109cd5f8e54a5e88077e\n'}]",0,101722,f8d0ce4350da524f3f624e4a831e94dc117e40be,13,4,2,10497,,,0,"Add Japanese documents to www/ja

Add Japanese documents to www/ja as current draft.

Change-Id: If45df5045988528426e9109cd5f8e54a5e88077e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/101722/1 && git format-patch -1 --stdout FETCH_HEAD,['www/ja/index.html'],1,11e75c302a712698c69141580cabae455a308bbc,www/ja," <div>  OpenStack  </a> </li> </ul> <dl> <dd> <a href=""http://docs.openstack.org/ja/trunk/install-guide/install/apt-debian/content/"">  Debian 7.0 (Wheezy)  () </dd> <dd> <a href=""http://docs.openstack.org/ja/trunk/install-guide/install/zypper/content/"">  openSUSESUSE Linux Enterprise Server  () </a> </dd> <dd> <a href=""http://docs.openstack.org/ja/trunk/install-guide/install/yum/content/"">  Red Hat Enterprise LinuxCentOSFedora  () </a> </dd> <dd> <a href=""http://docs.openstack.org/ja/trunk/install-guide/install/apt/content/"">  Ubuntu 12.04/14.04 (LTS)  () </a> </dd> </dl> <ul class=""subsectionNav""> <li class=""link""> <a> OpenStack  </a> <a href=""http://openstack-ja.github.io/openstack-manuals/openstack-ops/content/"">  </a> </dd> <dd> <a href=""http://docs.openstack.org/ja/security-guide/content/"">  () </dd> <dd> <a href=""http://docs.openstack.org/ja/high-availability-guide/content/"">  () </a> </dd> </dl> <ul class=""subsectionNav""> <li class=""link""> <a> OpenStack  </a> </li> </ul> <dl> <dd> <a href=""http://docs.openstack.org/ja/user-guide/content/"">  () </a> </dd> <dd> <a href=""http://docs.openstack.org/ja/user-guide-admin/content/"">  () </a> </dd> <dd> <a href=""http://docs.openstack.org/ja/api/quick-start/content/""> API  () </a> <div class=""span-12 last-right"" id=""subnav-right""> <ul class=""subsectionNav last-right-more""> <li class=""link last-right-more"">  "," <div class=""span-12"">   <dt> <a href=""http://openstack-ja.github.io/openstack-manuals/openstack-ops/content/""> OpenStack  </a> </dt> <a href=""http://docs.openstack.org/ops/""> Operations Guide  <div class=""span-12 last"" id=""subnav""> <ul class=""subsectionNav last-right""> <li class=""link"">  ",73,16
openstack%2Fsolum~master~Ia21216ba3e6a0370e8b721ff2186e0f27d50f5df,openstack/solum,master,Ia21216ba3e6a0370e8b721ff2186e0f27d50f5df,Don't re-authenticate if we have a trust token,ABANDONED,2014-06-19 11:43:48.000000000,2014-06-23 01:36:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-06-19 11:43:48.000000000', 'files': ['solum/tests/common/test_clients.py', 'solum/tests/common/test_solum_keystoneclient.py', 'solum/common/solum_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/a7cae9e0c96cab268e690c49025e460e46508764', 'message': ""Don't re-authenticate if we have a trust token\n\nChange-Id: Ia21216ba3e6a0370e8b721ff2186e0f27d50f5df\n""}]",0,101181,a7cae9e0c96cab268e690c49025e460e46508764,4,1,1,4715,,,0,"Don't re-authenticate if we have a trust token

Change-Id: Ia21216ba3e6a0370e8b721ff2186e0f27d50f5df
",git fetch https://review.opendev.org/openstack/solum refs/changes/81/101181/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/common/test_clients.py', 'solum/tests/common/test_solum_keystoneclient.py', 'solum/common/solum_keystoneclient.py']",3,a7cae9e0c96cab268e690c49025e460e46508764,new-api, if self.context.auth_token_info is None: client.authenticate(), client.authenticate(),6,3
