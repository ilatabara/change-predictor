id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fcharm-neutron-api~master~I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61,openstack/charm-neutron-api,master,I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61,Added vsd-cms-id as part of config option.,MERGED,2016-04-17 00:48:49.000000000,2016-05-06 14:37:36.000000000,2016-05-06 14:37:36.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 10068}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 21154}]","[{'number': 1, 'created': '2016-04-17 00:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/a23d229db0452c7cdbf942dfa0733e38170fbcec', 'message': 'Added vsd-cms-id as part of config option to cover the case when Nuage VSD&VSC are deployed outside for juju framework and removed nuage-tarball from and remove respective code form neutron_api_hook.py\n\nChange-Id: I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61\nSigned-off-by: sunny-verma <sunnyverma1992@gmail.com>\n'}, {'number': 2, 'created': '2016-05-05 17:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/f58813c5edc324d0061758bfdb24daa7ad5d982e', 'message': 'Added vsd-cms-id as part of config option.\n\nTo cover the case when Nuage VSD & VSC are deployed outside of juju framework.\nRemoved nuage-tarball from config file\nRemoved respective code form neutron_api_hook.py\n\nChange-Id: I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61\nSigned-off-by: sunny-verma <sunnyverma1992@gmail.com>\n'}, {'number': 3, 'created': '2016-05-05 22:03:51.000000000', 'files': ['templates/kilo/nuage_plugin.ini', 'hooks/neutron_api_context.py', 'hooks/neutron_api_hooks.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/a0dddcdf034ed3412bf525e752d584a759ed4513', 'message': 'Added vsd-cms-id as part of config option.\n\nTo cover the case when Nuage VSD & VSC are deployed outside of juju\nframework.\nRemoved nuage-tarball from config file\nRemoved respective code form neutron_api_hook.py\n\nChange-Id: I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61\nSigned-off-by: sunny-verma <sunnyverma1992@gmail.com>\n'}]",6,306789,a0dddcdf034ed3412bf525e752d584a759ed4513,21,6,3,21451,,,0,"Added vsd-cms-id as part of config option.

To cover the case when Nuage VSD & VSC are deployed outside of juju
framework.
Removed nuage-tarball from config file
Removed respective code form neutron_api_hook.py

Change-Id: I4518435ded9e1a4eb3d98cbb2e77f04b4f2dda61
Signed-off-by: sunny-verma <sunnyverma1992@gmail.com>
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/89/306789/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/kilo/nuage_plugin.ini', 'hooks/neutron_api_context.py', 'hooks/neutron_api_hooks.py', 'config.yaml']",4,a23d229db0452c7cdbf942dfa0733e38170fbcec,nuage, vsd-cms-id: type: string default: description: | CMS ID is used as an authentication token from VSD to CMS. This value is being generated via nuage scripts and can be set pre/post deployment., nuage-tarball-url: type: string default: description: Optional URL to tarball containing Nuage python packages.,11,34
openstack%2Fneutron-specs~master~I3b85a56bc9be054c8113ca484ae8042c88c6dcd4,openstack/neutron-specs,master,I3b85a56bc9be054c8113ca484ae8042c88c6dcd4,Fix typo in rbac-networks,MERGED,2016-05-06 03:53:30.000000000,2016-05-06 14:37:19.000000000,2016-05-06 14:37:19.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 10980}, {'_account_id': 14605}, {'_account_id': 14611}, {'_account_id': 16237}, {'_account_id': 20079}, {'_account_id': 20128}]","[{'number': 1, 'created': '2016-05-06 03:53:30.000000000', 'files': ['specs/liberty/rbac-networks.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3518b0903511e7a2df907b23e177c1245a518d11', 'message': 'Fix typo in rbac-networks\n\nchange wilcard to wildcard.\n\nChange-Id: I3b85a56bc9be054c8113ca484ae8042c88c6dcd4\n'}]",0,313216,3518b0903511e7a2df907b23e177c1245a518d11,13,13,1,17523,,,0,"Fix typo in rbac-networks

change wilcard to wildcard.

Change-Id: I3b85a56bc9be054c8113ca484ae8042c88c6dcd4
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/16/313216/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/rbac-networks.rst'],1,3518b0903511e7a2df907b23e177c1245a518d11,,the network will be mapped into a wildcard entry in the new table to preserve,the network will be mapped into a wilcard entry in the new table to preserve,1,1
openstack%2Ftripleo-docs~master~I4fc8448eb675073c3eed1d0cae77193306d37c4d,openstack/tripleo-docs,master,I4fc8448eb675073c3eed1d0cae77193306d37c4d,Document ready-state configuration,MERGED,2016-03-30 15:39:35.000000000,2016-05-06 14:37:12.000000000,2016-05-06 14:37:11.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7419}, {'_account_id': 7471}, {'_account_id': 9317}, {'_account_id': 10239}, {'_account_id': 11105}, {'_account_id': 12715}, {'_account_id': 20156}, {'_account_id': 20996}]","[{'number': 1, 'created': '2016-03-30 15:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/258dd8474be2b714997013d97ff3bfe49335beb0', 'message': 'Document ready-state configuration\n\nDepends-On: I0913a70c8f50ab6a80f527086ad7c78a5ddde3e1\nChange-Id: I4fc8448eb675073c3eed1d0cae77193306d37c4d\n'}, {'number': 2, 'created': '2016-04-12 10:29:48.000000000', 'files': ['doc/source/advanced_deployment/advanced_deployment.rst', 'doc/source/advanced_deployment/ready_state.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/8d7d3b16a7689807291686d5743827aa6e9f7b0a', 'message': 'Document ready-state configuration\n\nChange-Id: I4fc8448eb675073c3eed1d0cae77193306d37c4d\n'}]",0,299481,8d7d3b16a7689807291686d5743827aa6e9f7b0a,22,10,2,7419,,,0,"Document ready-state configuration

Change-Id: I4fc8448eb675073c3eed1d0cae77193306d37c4d
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/81/299481/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/advanced_deployment/advanced_deployment.rst', 'doc/source/advanced_deployment/ready_state.rst']",2,258dd8474be2b714997013d97ff3bfe49335beb0,ready-state,"Ready-state configuration ========================= .. note:: Ready-state configuration currently works only with Dell DRAC machines. Ready-state configuration can be used to prepare bare-metal resources for deployment. It includes BIOS configuration based on a predefined profile. Define the target BIOS configuration ------------------------------------ To define a BIOS setting, list the name of the setting and its target value for each profile:: { ""compute"" :{ ""bios_settings"": {""ProcVirtualization"": ""Enabled""} } } Trigger the ready-state configuration ------------------------------------- Make sure the nodes have profiles assigned as described in :doc:`profile_matching`. Create a JSON file with the target ready-state configuration for each profile. Then trigger the configuration:: openstack baremetal configure ready state ready-state.json ",,32,0
openstack%2Fnova~master~Ia0243d91cb00c610df1b29df983d5c6abe0a89c4,openstack/nova,master,Ia0243d91cb00c610df1b29df983d5c6abe0a89c4,neutron: skip test_deallocate_for_instance_2* in py34 job,MERGED,2015-12-08 22:13:18.000000000,2016-05-06 14:32:48.000000000,2015-12-09 21:41:11.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5538}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-08 22:13:18.000000000', 'files': ['tests-py3.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/ba01b11b8632d466ecf6c14bdc7490bfed93ec21', 'message': ""neutron: skip test_deallocate_for_instance_2* in py34 job\n\nFor whatever reason the two tests race fail in the py34 job at a rate of\nabout 12 hits per week. These aren't problems in the py27 job.\n\nSince no one seems to be looking at these, and the unit tests should\nalways be passing, let's just skip the tests for now.\n\nChange-Id: Ia0243d91cb00c610df1b29df983d5c6abe0a89c4\nRelated-Bug: #1521599\n""}]",0,254979,ba01b11b8632d466ecf6c14bdc7490bfed93ec21,17,12,1,6873,,,0,"neutron: skip test_deallocate_for_instance_2* in py34 job

For whatever reason the two tests race fail in the py34 job at a rate of
about 12 hits per week. These aren't problems in the py27 job.

Since no one seems to be looking at these, and the unit tests should
always be passing, let's just skip the tests for now.

Change-Id: Ia0243d91cb00c610df1b29df983d5c6abe0a89c4
Related-Bug: #1521599
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/254979/1 && git format-patch -1 --stdout FETCH_HEAD,['tests-py3.txt'],1,ba01b11b8632d466ecf6c14bdc7490bfed93ec21,bug/1521599,nova.tests.unit.network.test_neutronv2.TestNeutronv2.test_deallocate_for_instance_2 nova.tests.unit.network.test_neutronv2.TestNeutronv2.test_deallocate_for_instance_2_with_requested,,2,0
openstack%2Fnova~master~I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab,openstack/nova,master,I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab,Catch UnsupportedAlgorithm exceptions,ABANDONED,2016-01-13 16:42:00.000000000,2016-05-06 14:27:51.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6802}, {'_account_id': 7012}, {'_account_id': 7634}, {'_account_id': 8119}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11428}, {'_account_id': 12712}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15524}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-01-13 16:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08e9e6e82e0c59f8ab59ce1073419834bfad54c3', 'message': 'Catch UnsupportedAlgorithm exceptions\n\nFor signature verification, only SHA-2 family hash algorithms are\nused.  Some older platforms, with an older version of openssl (older\nthan 1.0.1) do not support SHA-2 hashes.\n\nThis patch skips the signature verification unit tests that require\nSHA-2 support on systems that do not have SHA-2 support.  It also\ncatches the UnsupportedAlgorithm exception that is generated when a\nsystem that does not have SHA-2 support tries to verify the signature,\nproviding better feedback to the user.\n\nChange-Id: I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab\nCloses-Bug: 1522525\n'}, {'number': 2, 'created': '2016-01-13 22:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf3844be1f1dd3244cab984f5eb873ddafd41169', 'message': 'Catch UnsupportedAlgorithm exceptions\n\nFor signature verification, only SHA-2 family hash algorithms are\nused.  Some older platforms, with an older version of openssl (older\nthan 1.0.1) do not support SHA-2 hashes.\n\nThis patch skips the signature verification unit tests that require\nSHA-2 support on systems that do not have SHA-2 support.  It also\ncatches the UnsupportedAlgorithm exception that is generated when a\nsystem that does not have SHA-2 support tries to verify the signature,\nproviding better feedback to the user.\n\nChange-Id: I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab\nCloses-Bug: 1522525\n'}, {'number': 3, 'created': '2016-01-25 21:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/436a2a7051da6aa28c37e87838336ffdb71cd91a', 'message': 'Catch UnsupportedAlgorithm exceptions\n\nFor signature verification, only SHA-2 family hash algorithms are\nused.  Some older platforms, with an older version of openssl (older\nthan 1.0.1) do not support SHA-2 hashes.\n\nThis patch skips the signature verification unit tests that require\nSHA-2 support on systems that do not have SHA-2 support.  It also\ncatches the UnsupportedAlgorithm exception that is generated when a\nsystem that does not have SHA-2 support tries to verify the signature,\nproviding better feedback to the user.\n\nChange-Id: I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab\nCloses-Bug: 1522525\n'}, {'number': 4, 'created': '2016-01-26 14:38:51.000000000', 'files': ['nova/signature_utils.py', 'nova/tests/unit/test_signature_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9c5f4a7e8df2a38a5ef98929808ac634d926b063', 'message': 'Catch UnsupportedAlgorithm exceptions\n\nFor signature verification, only SHA-2 family hash algorithms are\nused.  Some older platforms, with an older version of openssl (older\nthan 1.0.1) do not support SHA-2 hashes.\n\nThis patch skips the signature verification unit tests that require\nSHA-2 support on systems that do not have SHA-2 support.  It also\ncatches the UnsupportedAlgorithm exception that is generated when a\nsystem that does not have SHA-2 support tries to verify the signature,\nproviding better feedback to the user.\n\nChange-Id: I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab\nCloses-Bug: 1522525\n'}]",12,267021,9c5f4a7e8df2a38a5ef98929808ac634d926b063,68,22,4,7012,,,0,"Catch UnsupportedAlgorithm exceptions

For signature verification, only SHA-2 family hash algorithms are
used.  Some older platforms, with an older version of openssl (older
than 1.0.1) do not support SHA-2 hashes.

This patch skips the signature verification unit tests that require
SHA-2 support on systems that do not have SHA-2 support.  It also
catches the UnsupportedAlgorithm exception that is generated when a
system that does not have SHA-2 support tries to verify the signature,
providing better feedback to the user.

Change-Id: I5128c02ab5b91a67c8bb54d58e2ae33df29a85ab
Closes-Bug: 1522525
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/267021/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/signature_utils.py', 'nova/tests/unit/test_signature_utils.py']",2,08e9e6e82e0c59f8ab59ce1073419834bfad54c3,bug/1522525,"import unittestfrom cryptography.hazmat.primitives import hashes @unittest.skipIf(not default_backend().hash_supported(hashes.SHA256()), ""SHA-2 hash algorithms not supported by backend"") @unittest.skipIf(not default_backend().hash_supported(hashes.SHA256()), ""SHA-2 hash algorithms not supported by backend"") @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_unsupported_algorithm(self, mock_get_pub_key): public_key = TEST_RSA_PRIVATE_KEY.public_key() public_key.verifier = mock.MagicMock( side_effect=crypto_exceptions.UnsupportedAlgorithm( ""When OpenSSL is older than 1.0.1 then only SHA1 is "" ""supported with MGF1."", crypto_exceptions._Reasons.UNSUPPORTED_HASH)) mock_get_pub_key.return_value = public_key img_sig_cert_uuid = 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693' self.assertRaisesRegex(exception.SignatureVerificationError, 'Unable to verify signature since the ' 'algorithm is unsupported on this system', signature_utils.get_verifier, None, img_sig_cert_uuid, 'SHA-256', 'BLAH', signature_utils.RSA_PSS) ",,37,3
openstack%2Ftripleo-ci~master~Ie8e163dfc15b55d64040b436dc6e63fdac58ba1b,openstack/tripleo-ci,master,Ie8e163dfc15b55d64040b436dc6e63fdac58ba1b,Use megabytes for overcloud image size,MERGED,2016-05-04 15:22:36.000000000,2016-05-06 14:27:42.000000000,2016-05-06 14:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6796}]","[{'number': 1, 'created': '2016-05-04 15:22:36.000000000', 'files': ['scripts/deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1f548f59f0d4e8cc1eaf0223f7a5209903f1c23d', 'message': 'Use megabytes for overcloud image size\n\nThe overcloud image is large enough that du -h displays the size\nin gigabytes, but megabytes is probably more useful since it will\nbe more granular.  This also appears to be what was intended based\non the variable name.\n\nChange-Id: Ie8e163dfc15b55d64040b436dc6e63fdac58ba1b\n'}]",0,312594,1f548f59f0d4e8cc1eaf0223f7a5209903f1c23d,12,3,1,6928,,,0,"Use megabytes for overcloud image size

The overcloud image is large enough that du -h displays the size
in gigabytes, but megabytes is probably more useful since it will
be more granular.  This also appears to be what was intended based
on the variable name.

Change-Id: Ie8e163dfc15b55d64040b436dc6e63fdac58ba1b
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/94/312594/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/deploy.sh'],1,1f548f59f0d4e8cc1eaf0223f7a5209903f1c23d,image-mb,OVERCLOUD_IMAGE_MB=$(du -ms overcloud-full.qcow2 | cut -f 1 | sed 's|.$||'),OVERCLOUD_IMAGE_MB=$(du -hs overcloud-full.qcow2 | cut -f 1 | sed 's|.$||'),1,1
openstack%2Ftripleo-ci~master~I157d789648a53a027d8921d5aae001279e2083f6,openstack/tripleo-ci,master,I157d789648a53a027d8921d5aae001279e2083f6,Increase timeout and logging for crm_resource,MERGED,2016-05-05 14:57:01.000000000,2016-05-06 14:27:22.000000000,2016-05-06 14:27:22.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6928}]","[{'number': 1, 'created': '2016-05-05 14:57:01.000000000', 'files': ['scripts/deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cd314c3f0606f9a838b32e811bf0fbb30dc7aa76', 'message': ""Increase timeout and logging for crm_resource\n\nFor now the crm resource failing silently with message\n'Killed by signal 15' which makes difficult its identification.\nAdded nice log messages in case of failure.\nIncreased timeout to 240 seconds because of big number of failed\njobs\n\nChange-Id: I157d789648a53a027d8921d5aae001279e2083f6\n""}]",1,313011,cd314c3f0606f9a838b32e811bf0fbb30dc7aa76,12,3,1,10969,,,0,"Increase timeout and logging for crm_resource

For now the crm resource failing silently with message
'Killed by signal 15' which makes difficult its identification.
Added nice log messages in case of failure.
Increased timeout to 240 seconds because of big number of failed
jobs

Change-Id: I157d789648a53a027d8921d5aae001279e2083f6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/11/313011/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/deploy.sh'],1,cd314c3f0606f9a838b32e811bf0fbb30dc7aa76,crm_resource," timeout -k 10 240 ssh $SSH_OPTIONS heat-admin@$(nova list | grep controller-0 | awk '{print $12}' | cut -d'=' -f2) sudo crm_resource -r openstack-heat-api --wait || { exitcode=$? echo ""crm_resource for openstack-heat-api has failed!"" exit $exitcode } timeout -k 10 240 ssh $SSH_OPTIONS heat-admin@$(nova list | grep controller-0 | awk '{print $12}' | cut -d'=' -f2) sudo crm_resource -r openstack-heat-engine --wait|| { exitcode=$? echo ""crm_resource for openstack-heat-engine has failed!"" exit $exitcode } stop_metric ""tripleo.overcloud.${TOCI_JOBTYPE}.settle.seconds"""," timeout -k 10 180 ssh $SSH_OPTIONS heat-admin@$(nova list | grep controller-0 | awk '{print $12}' | cut -d'=' -f2) sudo crm_resource -r openstack-heat-api --wait timeout -k 10 180 ssh $SSH_OPTIONS heat-admin@$(nova list | grep controller-0 | awk '{print $12}' | cut -d'=' -f2) sudo crm_resource -r openstack-heat-engine --wait stop_metric ""tripleo.overcloud.${TOCI_JOBTYPE}.settle.seconds""",11,3
openstack%2Frequirements~master~I7b5c1e699b2d650df48152ecd06aaf69c94be16c,openstack/requirements,master,I7b5c1e699b2d650df48152ecd06aaf69c94be16c,Add python-daemon to global-requirements,ABANDONED,2016-05-05 14:34:37.000000000,2016-05-06 14:22:08.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-05-05 14:34:37.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2830d520a3f430260c7f2ebc1bb15fc7b32b5f2d', 'message': 'Add python-daemon to global-requirements\n\nThis patch is introducing the python-daemon library to\nglobal-requiremnts, this library is used by the VirtualBMC project where\neach virtual BMC created runs own it\'s own process (as a daemon).\n\nThis library implements the well-behaved daemon specification of PEP\n3143, ""Standard daemon process library"" and uses the Apache-2.0 license.\n\nChange-Id: I7b5c1e699b2d650df48152ecd06aaf69c94be16c\n'}]",0,313004,2830d520a3f430260c7f2ebc1bb15fc7b32b5f2d,5,3,1,6773,,,0,"Add python-daemon to global-requirements

This patch is introducing the python-daemon library to
global-requiremnts, this library is used by the VirtualBMC project where
each virtual BMC created runs own it's own process (as a daemon).

This library implements the well-behaved daemon specification of PEP
3143, ""Standard daemon process library"" and uses the Apache-2.0 license.

Change-Id: I7b5c1e699b2d650df48152ecd06aaf69c94be16c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/04/313004/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,2830d520a3f430260c7f2ebc1bb15fc7b32b5f2d,python-daemon,python-daemon===2.1.1,,2,0
openstack%2Ftripleo-heat-templates~stable%2Fmitaka~I2ac929e241707db72a0beabf9d5cd7fc14b90f76,openstack/tripleo-heat-templates,stable/mitaka,I2ac929e241707db72a0beabf9d5cd7fc14b90f76,Fix controller-no-external.yaml in bonded configs.,MERGED,2016-04-23 06:57:28.000000000,2016-05-06 14:11:03.000000000,2016-05-06 14:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10873}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-04-23 06:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4a11ef719d4a51b6cea83d59b63b31b2ec394d94', 'message': ""Fix controller-no-external.yaml in bonded configs.\n\nFor some reason the controller-no-external.yaml template is configured\nfor DHCP on the control plane interface. We switched to static control\nplane IPs before the controller-no-external.yaml was created (IIRC), so\nI'm not sure how that happened. This change brings the\ncontroller-no-external.yaml in line with the rest of the bonded NIC\ntemplates.\n\nChange-Id: I2ac929e241707db72a0beabf9d5cd7fc14b90f76\n(cherry picked from commit 6d27813db3ce06b4352ac42c3e45887030094c39)\n""}, {'number': 2, 'created': '2016-04-23 09:28:12.000000000', 'files': ['network/config/bond-with-vlans/controller-no-external.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/29cc933a8ae0ed433c2461d8bd07cf5352565a40', 'message': ""Fix controller-no-external.yaml in bonded configs.\n\nFor some reason the controller-no-external.yaml template is configured\nfor DHCP on the control plane interface. We switched to static control\nplane IPs before the controller-no-external.yaml was created (IIRC), so\nI'm not sure how that happened. This change brings the\ncontroller-no-external.yaml in line with the rest of the bonded NIC\ntemplates.\n\nCloses-Bug: #1573943\nChange-Id: I2ac929e241707db72a0beabf9d5cd7fc14b90f76\n(cherry picked from commit 6d27813db3ce06b4352ac42c3e45887030094c39)\n""}]",0,309662,29cc933a8ae0ed433c2461d8bd07cf5352565a40,13,4,2,19740,,,0,"Fix controller-no-external.yaml in bonded configs.

For some reason the controller-no-external.yaml template is configured
for DHCP on the control plane interface. We switched to static control
plane IPs before the controller-no-external.yaml was created (IIRC), so
I'm not sure how that happened. This change brings the
controller-no-external.yaml in line with the rest of the bonded NIC
templates.

Closes-Bug: #1573943
Change-Id: I2ac929e241707db72a0beabf9d5cd7fc14b90f76
(cherry picked from commit 6d27813db3ce06b4352ac42c3e45887030094c39)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/309662/2 && git format-patch -1 --stdout FETCH_HEAD,['network/config/bond-with-vlans/controller-no-external.yaml'],1,4a11ef719d4a51b6cea83d59b63b31b2ec394d94,fix_controller_no_external, ControlPlaneIp: default: '' description: IP address/subnet on the ctlplane network type: string ControlPlaneSubnetCidr: # Override this via parameter_defaults default: '24' description: The subnet CIDR of the control plane network. type: string DnsServers: # Override this via parameter_defaults default: [] description: A list of DNS servers (2 max for some implementations) that will be added to resolv.conf. type: comma_delimited_list EC2MetadataIp: # Override this via parameter_defaults description: The IP address of the EC2 metadata server. type: string type: interface name: nic1 use_dhcp: false addresses: - ip_netmask: list_join: - '/' - - {get_param: ControlPlaneIp} - {get_param: ControlPlaneSubnetCidr} routes: - ip_netmask: 169.254.169.254/32 next_hop: {get_param: EC2MetadataIp} -,,31,0
openstack%2Ftripleo-heat-templates~master~I1734a9755c4254221033cf2245ce9da8b2eeb924,openstack/tripleo-heat-templates,master,I1734a9755c4254221033cf2245ce9da8b2eeb924,Document IPv6 syntax for GlanceFilePcmkDevice,MERGED,2016-04-11 19:21:19.000000000,2016-05-06 14:10:51.000000000,2016-05-06 14:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}]","[{'number': 1, 'created': '2016-04-11 19:21:19.000000000', 'files': ['environments/storage-environment.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80be9ef0806328ee597ab39847f038b973bb006c', 'message': 'Document IPv6 syntax for GlanceFilePcmkDevice\n\nChange-Id: I1734a9755c4254221033cf2245ce9da8b2eeb924\nCloses-Bug: 1568995\n'}]",0,304298,80be9ef0806328ee597ab39847f038b973bb006c,7,3,1,20414,,,0,"Document IPv6 syntax for GlanceFilePcmkDevice

Change-Id: I1734a9755c4254221033cf2245ce9da8b2eeb924
Closes-Bug: 1568995
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/304298/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/storage-environment.yaml'],1,80be9ef0806328ee597ab39847f038b973bb006c,bug/1568995," ## (If using IPv6, use both double- and single-quotes, ## e.g. ""'[fdd0::1]:/export/glance'"")",,2,0
openstack%2Ftripleo-docs~master~I4e96f94c929477dad13917442d966a6a1a3781e1,openstack/tripleo-docs,master,I4e96f94c929477dad13917442d966a6a1a3781e1,Document accessing stored introspection ramdisk logs,MERGED,2016-05-05 14:12:13.000000000,2016-05-06 14:10:42.000000000,2016-05-06 14:10:42.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10239}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-05-05 14:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/654e516da545ab04c0cb060ee21175c30c8a76a4', 'message': 'Document accessing stored introspection ramdisk logs\n\nChange-Id: I4e96f94c929477dad13917442d966a6a1a3781e1\n'}, {'number': 2, 'created': '2016-05-05 14:19:00.000000000', 'files': ['doc/source/troubleshooting/troubleshooting-nodes.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/8b7f44e21b151d5adb9417787fdf28ac8e0ab9cd', 'message': 'Document accessing stored introspection ramdisk logs\n\nChange-Id: I4e96f94c929477dad13917442d966a6a1a3781e1\n'}]",3,312979,8b7f44e21b151d5adb9417787fdf28ac8e0ab9cd,11,4,2,10239,,,0,"Document accessing stored introspection ramdisk logs

Change-Id: I4e96f94c929477dad13917442d966a6a1a3781e1
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/79/312979/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/troubleshooting/troubleshooting-nodes.rst'],1,654e516da545ab04c0cb060ee21175c30c8a76a4,troubleshooting,"Accessing logs from the ramdisk ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Introspection logs are saved on ramdisk failures. Starting with the Newton release, they are actually stored on all introspection failures. The standard location is ``/var/log/ironic-inspector/ramdisk``, and the files there are actually ``tar.gz`` without an extension. To collect introspection logs in other case, set ``always_store_ramdisk_logs = true`` in ``/etc/ironic-inspector/inspector.conf``, restart the ``openstack-ironic-inspector`` service and retry the introspection. ",,12,0
openstack%2Fkarbor~master~I70b3b30e123eb8d4ca8a7d601394821ded93a207,openstack/karbor,master,I70b3b30e123eb8d4ca8a7d601394821ded93a207,Create BankCheckpointCollection implementation,MERGED,2016-02-15 17:00:12.000000000,2016-05-06 14:10:11.000000000,2016-05-06 14:10:11.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 13070}, {'_account_id': 19346}, {'_account_id': 20883}]","[{'number': 1, 'created': '2016-02-15 17:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/a3426cb428e283842aea4d28e4cb1ae1655a082f', 'message': ""[WIP] Create BankCheckpointCollection implementation\n\nThis will add a checkpoint collection implementation that uses the bank\nand lease plugin interfaces to manage it's content.\n\n!!! This is still a WIP !!!\nTODO:\n * Implement Checkpoint class\n * Implement All the testing requirements\n * Implement the actual collection\n * Unit tests\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\n""}, {'number': 2, 'created': '2016-02-16 12:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/95b88cbe92c4fd686a54e8114143e84ac615cec8', 'message': ""[WIP] Create BankCheckpointCollection implementation\n\nThis will add a checkpoint collection implementation that uses the bank\nand lease plugin interfaces to manage it's content.\n\n!!! This is still a WIP !!!\nTODO:\n * Implement Checkpoint class\n * Implement All the testing requirements\n * Implement the actual collection\n * Unit tests\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\n""}, {'number': 3, 'created': '2016-02-16 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/9d3ee96b33cadd55abe69449d5f53a659a0d2588', 'message': ""[WIP] Create BankCheckpointCollection implementation\n\nThis will add a checkpoint collection implementation that uses the bank\nand lease plugin interfaces to manage it's content.\n\n!!! This is still a WIP !!!\nTODO:\n * Implement Checkpoint class\n * Implement All the testing requirements\n * Implement the actual collection\n * Unit tests\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\n""}, {'number': 4, 'created': '2016-02-29 16:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/b3874d361b7bb05fcabc006b98f77f956bde454a', 'message': ""[WIP] Create BankCheckpointCollection implementation\n\nThis will add a checkpoint collection implementation that uses the bank\nand lease plugin interfaces to manage it's content.\n\n!!! This is still a WIP !!!\nTODO:\n * Implement Checkpoint class\n * Implement All the testing requirements\n * Implement the actual collection\n * Unit tests\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\n""}, {'number': 5, 'created': '2016-03-01 14:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/3c68319fa1497db4f3adea40887860c448090ec1', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\n""}, {'number': 6, 'created': '2016-03-20 22:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/6abb3075687e396cc0575f309b5d16fae3b99fa5', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}, {'number': 7, 'created': '2016-03-22 21:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/fae4435c7d389b8dc1fdddaa7e790354f642de2a', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}, {'number': 8, 'created': '2016-03-30 09:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/f41df08eaf4181f43ae667e9fcecf76cd8aa968c', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}, {'number': 9, 'created': '2016-04-17 13:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/88651726df462d8fecfd841a964b4930429dc4e4', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}, {'number': 10, 'created': '2016-04-17 13:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/2ea61e57c28366a04beb37c1b00fe4c87aa4ca2c', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}, {'number': 11, 'created': '2016-05-01 07:41:34.000000000', 'files': ['smaug/tests/unit/protection/test_checkpoint_collection.py', 'smaug/services/protection/checkpoint.py', 'smaug/services/protection/bank_plugin.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/177e78f0a09d31b89128f08a0bc774e0deb44558', 'message': ""Create BankCheckpointCollection implementation\n\nThis adds a checkpoint collection implementation that uses the bank.\nIt still ignores leases and doesn't serialize the plan since those are\nnot yet implemented in Smaug.\n\nChange-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207\nSigned-off-by: Saggi Mizrahi <ficoos@gmail.com>\n""}]",16,280325,177e78f0a09d31b89128f08a0bc774e0deb44558,39,5,11,2023,,,0,"Create BankCheckpointCollection implementation

This adds a checkpoint collection implementation that uses the bank.
It still ignores leases and doesn't serialize the plan since those are
not yet implemented in Smaug.

Change-Id: I70b3b30e123eb8d4ca8a7d601394821ded93a207
Signed-off-by: Saggi Mizrahi <ficoos@gmail.com>
",git fetch https://review.opendev.org/openstack/karbor refs/changes/25/280325/7 && git format-patch -1 --stdout FETCH_HEAD,['smaug/services/protection/checkpoint.py'],1,a3426cb428e283842aea4d28e4cb1ae1655a082f,bug1561406,class Checkpoint(object): pass ,,4,0
openstack%2Frally~master~I348c5971f2375f8de08b9fd8f021ea09906ff844,openstack/rally,master,I348c5971f2375f8de08b9fd8f021ea09906ff844,fix bug on booting server from volume,MERGED,2016-05-05 07:16:36.000000000,2016-05-06 14:09:59.000000000,2016-05-06 14:09:59.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 10475}]","[{'number': 1, 'created': '2016-05-05 07:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ebe931ce45cd14aa85745955a38d5f979dfb2f44', 'message': 'fix bug on booting server from volume.\nthe arg of image must be None,when booting server from volume. Otherwise still boot server from image\n\nChange-Id: I348c5971f2375f8de08b9fd8f021ea09906ff844\n'}, {'number': 2, 'created': '2016-05-05 09:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b525cc76618fbcc7433a2bde29733bb9753b91af', 'message': 'fix bug on booting server from volume.\n\nThe arg of image must be None,when booting server from volume.\nOtherwise still boot server from image\n\nChange-Id: I348c5971f2375f8de08b9fd8f021ea09906ff844\nCloses-Bug: #1578556\n'}, {'number': 3, 'created': '2016-05-06 02:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b711f340cdba3e6f7e3a07ca42d029a005fca89b', 'message': 'fix bug on booting server from volume.\n\nThe arg of image must be None,when booting server from volume.\nOtherwise still boot server from image\n\nChange-Id: I348c5971f2375f8de08b9fd8f021ea09906ff844\nCloses-Bug: #1578556\n'}, {'number': 4, 'created': '2016-05-06 06:26:07.000000000', 'files': ['rally/plugins/openstack/scenarios/nova/servers.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/037f3ae69ebddb434d4bb79aeda682bea78e70c1', 'message': 'fix bug on booting server from volume\n\nThe arg of image must be None,when booting server from volume.\nOtherwise still boot server from image\n\nChange-Id: I348c5971f2375f8de08b9fd8f021ea09906ff844\nCloses-Bug: #1578556\n'}]",1,312845,037f3ae69ebddb434d4bb79aeda682bea78e70c1,14,3,4,21528,,,0,"fix bug on booting server from volume

The arg of image must be None,when booting server from volume.
Otherwise still boot server from image

Change-Id: I348c5971f2375f8de08b9fd8f021ea09906ff844
Closes-Bug: #1578556
",git fetch https://review.opendev.org/openstack/rally refs/changes/45/312845/4 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/scenarios/nova/servers.py'],1,ebe931ce45cd14aa85745955a38d5f979dfb2f44,bug/1578556," self._boot_server(None, flavor, auto_assign_nic=auto_assign_nic,"," self._boot_server(image, flavor, auto_assign_nic=auto_assign_nic,",1,1
openstack%2Frally~master~I720c48b4761805606572693f88e5227617738640,openstack/rally,master,I720c48b4761805606572693f88e5227617738640,Remove redundant constrain from constant runner schema,MERGED,2016-05-06 03:43:31.000000000,2016-05-06 14:08:10.000000000,2016-05-06 14:08:10.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 10475}]","[{'number': 1, 'created': '2016-05-06 03:43:31.000000000', 'files': ['rally/plugins/common/runners/constant.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/00fd251a88abd93c6736079f1ef4479530dbb857', 'message': 'Remove redundant constrain from constant runner schema\n\nChange-Id: I720c48b4761805606572693f88e5227617738640\n'}]",0,313214,00fd251a88abd93c6736079f1ef4479530dbb857,7,3,1,12395,,,0,"Remove redundant constrain from constant runner schema

Change-Id: I720c48b4761805606572693f88e5227617738640
",git fetch https://review.opendev.org/openstack/rally refs/changes/14/313214/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/common/runners/constant.py'],1,00fd251a88abd93c6736079f1ef4479530dbb857,fix_schema,," ""minimum"": 1",0,1
openstack%2Fpython-openstackclient~master~I4a4ed7b0a2f522ee04d1c3270afcda7064285c39,openstack/python-openstackclient,master,I4a4ed7b0a2f522ee04d1c3270afcda7064285c39,"Make ""flavor show"" command to show a private flavor properly",MERGED,2016-05-02 09:01:25.000000000,2016-05-06 14:07:54.000000000,2016-05-06 14:07:54.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-05-02 09:01:25.000000000', 'files': ['releasenotes/notes/bug-1575478-5a0a923c3a32f96a.yaml', 'openstackclient/compute/v2/flavor.py', 'openstackclient/tests/compute/v2/test_flavor.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/681d6dc2de83ef13b4fb2fb4abe70f3c1ccb0e10', 'message': 'Make ""flavor show"" command to show a private flavor properly\n\nThe ""flavor show"" command could not show a\nprivate flavor by flavor name becauce it could\nnot find a private flavor by flavor name.\nIn ""until.find_resource(parsed_args.flavor)"",\nIf parsed_args.falvor is a name of a flavor,\n""flavors.find(name=parsed_args.flavor)""will be\ncalled to find a flavor.But the default value of\n""is_public"" is ""Ture"" in ""flavors.find()"" so that\nwe can only find public flavors.If we want to find\nall flaovrs by flavor name,we should add\n""is_public=None"" in ""flavors.find()"".\n\nSo I tried to change\n""until.find_resource(parsed_args.flavor)"" to\n""until.find_resource(parsed_args.flavor, is_public=None)"",\nbut then I could not find any flavor by flavor id\nbecause ""is_public"" is an unexpected argument of\n""flavors.get()"" in ""until.find_resource()"".\n\nIn this case,I think ""until.find_resource()""\ncan not find a private flavor properly,and\nwe should combine ""manager.get(flavor.id)"" and\n""manager.find(name=flavor.name, is_public=None)""\nby ourselve to find a flavor.\n\nAlso,this bug affects other flavor commands like\n""flavor set/unset/delete"",so I fix them in this patch too.\n\nChange-Id: I4a4ed7b0a2f522ee04d1c3270afcda7064285c39\nCloses-Bug: #1575478\n'}]",0,311700,681d6dc2de83ef13b4fb2fb4abe70f3c1ccb0e10,7,3,1,21514,,,0,"Make ""flavor show"" command to show a private flavor properly

The ""flavor show"" command could not show a
private flavor by flavor name becauce it could
not find a private flavor by flavor name.
In ""until.find_resource(parsed_args.flavor)"",
If parsed_args.falvor is a name of a flavor,
""flavors.find(name=parsed_args.flavor)""will be
called to find a flavor.But the default value of
""is_public"" is ""Ture"" in ""flavors.find()"" so that
we can only find public flavors.If we want to find
all flaovrs by flavor name,we should add
""is_public=None"" in ""flavors.find()"".

So I tried to change
""until.find_resource(parsed_args.flavor)"" to
""until.find_resource(parsed_args.flavor, is_public=None)"",
but then I could not find any flavor by flavor id
because ""is_public"" is an unexpected argument of
""flavors.get()"" in ""until.find_resource()"".

In this case,I think ""until.find_resource()""
can not find a private flavor properly,and
we should combine ""manager.get(flavor.id)"" and
""manager.find(name=flavor.name, is_public=None)""
by ourselve to find a flavor.

Also,this bug affects other flavor commands like
""flavor set/unset/delete"",so I fix them in this patch too.

Change-Id: I4a4ed7b0a2f522ee04d1c3270afcda7064285c39
Closes-Bug: #1575478
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/00/311700/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1575478-5a0a923c3a32f96a.yaml', 'openstackclient/compute/v2/flavor.py', 'openstackclient/tests/compute/v2/test_flavor.py']",3,681d6dc2de83ef13b4fb2fb4abe70f3c1ccb0e10,bug/1575478," self.flavors_mock.get.side_effect = exceptions.NotFound(None) self.flavors_mock.find.assert_called_with(name=parsed_args.flavor, is_public=None) # Return value of _find_resource() self.flavors_mock.find.return_value = self.flavor self.flavors_mock.get.side_effect = exceptions.NotFound(None) self.flavors_mock.get.side_effect = exceptions.NotFound(None) self.flavors_mock.find.assert_called_with(name=parsed_args.flavor, is_public=None)", try: self.flavors_mock.find.assert_called_with(name=parsed_args.flavor) except Exception: self.flavors_mock.get.assert_called_with(parsed_args.flavor) # Return value of utils.find_resource() self.flavors_mock.get.return_value = self.flavor try: self.flavors_mock.find.assert_called_with(name=parsed_args.flavor) except Exception: self.flavors_mock.get.assert_called_with(parsed_args.flavor),37,21
openstack%2Fheat~master~I14238618b5ec27c0e380383c2928ac56e605495f,openstack/heat,master,I14238618b5ec27c0e380383c2928ac56e605495f,"Revert ""Replace SD RPC polling by long RPC call""",MERGED,2016-05-05 19:19:49.000000000,2016-05-06 14:05:36.000000000,2016-05-06 14:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 8399}]","[{'number': 1, 'created': '2016-05-05 19:19:49.000000000', 'files': ['heat/engine/resources/openstack/heat/software_deployment.py', 'heat/tests/openstack/heat/test_software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/94480d4d31e0978c2e2e906a0f36b3da5ae321a2', 'message': 'Revert ""Replace SD RPC polling by long RPC call""\n\nThis partially reverts commit a709637a17166cb12e5d94944837bac6451b2o851.\n\nUsing long-polling causes a regression for non-convergence stacks, since\nno other resources will be polled, started, or otherwise progressed\nwhile we\'re waiting for the response. It can effectively serialise part\nof the stack.\n\nThis patch leaves the new RPC call in place, since reverting that would\nbe a backward-incompatible change to the RPC API, and since we may find\na use for it once everyone is switched to convergence.\n\nChange-Id: I14238618b5ec27c0e380383c2928ac56e605495f\n'}]",0,313122,94480d4d31e0978c2e2e906a0f36b3da5ae321a2,8,6,1,4257,,,0,"Revert ""Replace SD RPC polling by long RPC call""

This partially reverts commit a709637a17166cb12e5d94944837bac6451b2o851.

Using long-polling causes a regression for non-convergence stacks, since
no other resources will be polled, started, or otherwise progressed
while we're waiting for the response. It can effectively serialise part
of the stack.

This patch leaves the new RPC call in place, since reverting that would
be a backward-incompatible change to the RPC API, and since we may find
a use for it once everyone is switched to convergence.

Change-Id: I14238618b5ec27c0e380383c2928ac56e605495f
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/313122/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/heat/software_deployment.py', 'heat/tests/openstack/heat/test_software_deployment.py']",2,94480d4d31e0978c2e2e906a0f36b3da5ae321a2,, self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd,from oslo_utils import timeutils self.stack.created_time = timeutils.utcnow() self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd,9,12
openstack%2Fnova~master~I7fd86265ffa4d5bf3d4350a98b48685258947e43,openstack/nova,master,I7fd86265ffa4d5bf3d4350a98b48685258947e43,Remove legacy v2 unit tests[q-v],MERGED,2016-05-02 03:01:42.000000000,2016-05-06 14:04:27.000000000,2016-05-06 14:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-02 03:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d71b8f3098304904955a32f5a76b5870124d645b', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 2, 'created': '2016-05-02 04:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1da05f0001b711908f70be9fc7d4bd0838370f3b', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 3, 'created': '2016-05-02 22:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f28bbdaeb9d1980d13623c0ec100612d1f43922', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 4, 'created': '2016-05-03 23:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/864f6462fa356b78999814e328313559f5596c7d', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 6, 'created': '2016-05-04 00:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ce6f25b441f0699bcd916c918639aa06f2270dc', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 7, 'created': '2016-05-04 03:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a9be5bf2d1b2544e3c48e82cbb44c462c3eb918', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 8, 'created': '2016-05-04 17:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f283d1186315f27b69525ebc4eecfe9a0df54c0', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 9, 'created': '2016-05-05 11:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db26ed219fa72a922ee52ae45171fede2ae0a0c2', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 10, 'created': '2016-05-05 19:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c73d3b6935e008f8967fa24c692aa03d464a471c', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}, {'number': 11, 'created': '2016-05-06 05:02:32.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_server_metadata.py', 'nova/tests/unit/api/openstack/compute/test_server_start_stop.py', 'nova/tests/unit/api/openstack/compute/test_volumes.py', 'nova/tests/unit/api/openstack/compute/test_security_group_default_rules.py', 'nova/tests/unit/api/openstack/compute/test_neutron_security_groups.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/tests/unit/api/openstack/compute/test_snapshots.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_security_groups.py', 'nova/tests/unit/api/openstack/compute/test_tenant_networks.py', 'nova/tests/unit/api/openstack/compute/test_services.py', 'nova/tests/unit/api/openstack/compute/test_pause_server.py', 'nova/tests/unit/api/openstack/compute/test_remote_consoles.py', 'nova/tests/unit/api/openstack/compute/test_server_groups.py', 'nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py', 'nova/tests/unit/api/openstack/compute/test_rescue.py', 'nova/tests/unit/api/openstack/compute/test_quota_classes.py', 'nova/tests/unit/api/openstack/compute/test_quotas.py', 'nova/tests/unit/api/openstack/compute/test_server_group_quotas.py', 'nova/tests/unit/api/openstack/compute/test_suspend_server.py', 'nova/tests/unit/api/openstack/compute/test_server_password.py', 'nova/tests/unit/api/openstack/compute/test_scheduler_hints.py', 'nova/tests/unit/api/openstack/compute/test_server_reset_state.py', 'nova/tests/unit/api/openstack/compute/test_used_limits.py', 'nova/tests/unit/api/openstack/compute/test_server_external_events.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/de67ca52c5f71705b5d8978384da51212880f25b', 'message': 'Remove legacy v2 unit tests[q-v]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[q-v].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43\n'}]",0,311656,de67ca52c5f71705b5d8978384da51212880f25b,79,10,10,6167,,,0,"Remove legacy v2 unit tests[q-v]

There are two implementation code for similar API in Nova repository.
One is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been
used as the default API since Liberty and legacy v2 API has been marked
as deprecated. We have used and tested v2.1 API so well and now is nice
time to remove legacy API code based on the consensus of the design
summit of Austin. This patch removes unit tests of legacy v2 API[q-v].

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: I7fd86265ffa4d5bf3d4350a98b48685258947e43
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/311656/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_server_metadata.py', 'nova/tests/unit/api/openstack/compute/test_server_start_stop.py', 'nova/tests/unit/api/openstack/compute/test_volumes.py', 'nova/tests/unit/api/openstack/compute/test_security_group_default_rules.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/tests/unit/api/openstack/compute/test_snapshots.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_security_groups.py', 'nova/tests/unit/api/openstack/compute/test_tenant_networks.py', 'nova/tests/unit/api/openstack/compute/test_services.py', 'nova/tests/unit/api/openstack/compute/test_pause_server.py', 'nova/tests/unit/api/openstack/compute/test_remote_consoles.py', 'nova/tests/unit/api/openstack/compute/test_server_groups.py', 'nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py', 'nova/tests/unit/api/openstack/compute/test_rescue.py', 'nova/tests/unit/api/openstack/compute/test_quota_classes.py', 'nova/tests/unit/api/openstack/compute/test_quotas.py', 'nova/tests/unit/api/openstack/compute/test_server_group_quotas.py', 'nova/tests/unit/api/openstack/compute/test_suspend_server.py', 'nova/tests/unit/api/openstack/compute/test_server_password.py', 'nova/tests/unit/api/openstack/compute/test_scheduler_hints.py', 'nova/tests/unit/api/openstack/compute/test_server_reset_state.py', 'nova/tests/unit/api/openstack/compute/test_used_limits.py', 'nova/tests/unit/api/openstack/compute/test_server_external_events.py']",25,d71b8f3098304904955a32f5a76b5870124d645b,bp/remove-legacy-v2-api-code,,"from nova.api.openstack.compute.legacy_v2.contrib import server_external_events \ as server_external_events_v2 @mock.patch('nova.objects.instance.Instance.get_by_uuid', fake_get_by_uuid) class ServerExternalEventsTestV2(ServerExternalEventsTestV21): server_external_events = server_external_events_v2 invalid_error = webob.exc.HTTPBadRequest",0,797
openstack%2Fpuppet-openstack-integration~master~Ic8e99628b3fa67c884146ba8033fa6712aacd515,openstack/puppet-openstack-integration,master,Ic8e99628b3fa67c884146ba8033fa6712aacd515,CI test - never merge,ABANDONED,2016-05-05 20:50:44.000000000,2016-05-06 14:04:16.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2016-05-05 20:50:44.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/ac56cf2d471d12d49eb173cff850eec31480d1be', 'message': 'CI test - never merge\n\nChange-Id: Ic8e99628b3fa67c884146ba8033fa6712aacd515\n'}]",0,313153,ac56cf2d471d12d49eb173cff850eec31480d1be,7,2,1,3153,,,0,"CI test - never merge

Change-Id: Ic8e99628b3fa67c884146ba8033fa6712aacd515
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/53/313153/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,ac56cf2d471d12d49eb173cff850eec31480d1be,ci-test,test ,,1,0
openstack%2Fironic-python-agent~master~Ia14835e6867b945cccb8b1987aa4881d8524561c,openstack/ironic-python-agent,master,Ia14835e6867b945cccb8b1987aa4881d8524561c,Stop using git:// and be nice to people behind proxy servers,MERGED,2016-05-05 18:59:45.000000000,2016-05-06 14:01:45.000000000,2016-05-06 02:05:19.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 11655}, {'_account_id': 21242}]","[{'number': 1, 'created': '2016-05-05 18:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1ef6b128b2fa23494c92246e8b258df574e7c316', 'message': ""Stop using git:// and be nice to people behind proxy servers\n\nDoing a git clone git://... behind a proxy server is painful. Use the\n'official' QEMU github mirror and clone with https.\n\nChange-Id: Ia14835e6867b945cccb8b1987aa4881d8524561c\nCloses-Bug: #1578778\n""}, {'number': 2, 'created': '2016-05-05 19:00:46.000000000', 'files': ['imagebuild/tinyipa/build-tinyipa.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4be5e084080cde8e53dd83e21a4ac9da3a12b6b2', 'message': ""Stop using git:// and be nice to people behind proxy servers\n\nThe build of tinyipa is doing a: git clone git://...\n\nDoing a git clone git://... behind a proxy server is painful. Use the\n'official' QEMU github mirror and clone with https.\n\nChange-Id: Ia14835e6867b945cccb8b1987aa4881d8524561c\nCloses-Bug: #1578778\n""}]",0,313115,4be5e084080cde8e53dd83e21a4ac9da3a12b6b2,10,5,2,14760,,,0,"Stop using git:// and be nice to people behind proxy servers

The build of tinyipa is doing a: git clone git://...

Doing a git clone git://... behind a proxy server is painful. Use the
'official' QEMU github mirror and clone with https.

Change-Id: Ia14835e6867b945cccb8b1987aa4881d8524561c
Closes-Bug: #1578778
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/15/313115/2 && git format-patch -1 --stdout FETCH_HEAD,['imagebuild/tinyipa/build-tinyipa.sh'],1,1ef6b128b2fa23494c92246e8b258df574e7c316,,git clone https://github.com/qemu/qemu.git $BUILDDIR/tmp/qemu --depth=1 --branch v2.5.0,git clone git://git.qemu-project.org/qemu.git $BUILDDIR/tmp/qemu --depth=1 --branch v2.5.0,1,1
openstack%2Fnova~master~I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee,openstack/nova,master,I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee,Remove legacy v2 unit tests[f-n],MERGED,2016-05-02 03:31:44.000000000,2016-05-06 13:57:34.000000000,2016-05-06 13:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-02 03:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd4fb18d20eeacaff5b2899806f6bb9b747e86b8', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 2, 'created': '2016-05-02 04:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e94cb12d70e9a01e32c69ee077bdef1d0901a776', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 3, 'created': '2016-05-02 22:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8230423b4957307b1c836895257d1d2a37bffd3e', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 4, 'created': '2016-05-03 23:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3aa9ca850b230bbb6e2c9e7569253e4610aa0c8c', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 6, 'created': '2016-05-04 00:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dce8507660eef69e0811d84d172671b27d47e96e', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 7, 'created': '2016-05-04 03:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15e96eafdf66655b1897dec94226123778680b30', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 8, 'created': '2016-05-04 17:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/983547f555eeb841064b1090a46ddb821fb94bc4', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 9, 'created': '2016-05-04 18:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e966e92c63f6ae80bc192fe103766b75827fcac', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 10, 'created': '2016-05-04 21:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fbc3150d0cc7df2af4d3ee6c6e063dfad495656', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 11, 'created': '2016-05-04 22:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2169f68642367d222a3d8e63cb734924d0f0bfa0', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 12, 'created': '2016-05-04 23:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d0151431310e9f1a29fc1edf311dd7cb2ce60be', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 13, 'created': '2016-05-05 11:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bbdc7bdada0b3ccb87144b91b2a9331746ee070', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 14, 'created': '2016-05-05 19:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fab1d90113bf46a530f30e1e565c95f233e212d', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}, {'number': 15, 'created': '2016-05-06 05:02:32.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_hosts.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips_bulk.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/tests/unit/api/openstack/compute/test_neutron_security_groups.py', 'nova/tests/unit/api/openstack/compute/test_hypervisor_status.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_pools.py', 'nova/tests/unit/api/openstack/compute/test_instance_actions.py', 'nova/tests/unit/api/openstack/compute/test_keypairs.py', 'nova/tests/unit/api/openstack/compute/test_networks.py', 'nova/tests/unit/api/openstack/compute/test_images.py', 'nova/tests/unit/api/openstack/compute/test_multiple_create.py', 'nova/tests/unit/api/openstack/compute/test_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_lock_server.py', 'nova/tests/unit/api/openstack/compute/test_fixed_ips.py', 'nova/tests/unit/api/openstack/compute/test_flavors.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py', 'nova/tests/unit/api/openstack/compute/test_fping.py', 'nova/tests/unit/api/openstack/compute/test_multinic.py', 'nova/tests/unit/api/openstack/compute/test_flavor_access.py', 'nova/tests/unit/api/openstack/compute/test_image_metadata.py', 'nova/tests/unit/api/openstack/compute/test_migrations.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/test_flavors_extra_specs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7eb7a3dbb20fbce92ecb0cd1e319fd3277ec828c', 'message': 'Remove legacy v2 unit tests[f-n]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\nused as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin. This patch removes unit tests of legacy v2 API[f-n].\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee\n'}]",0,311658,7eb7a3dbb20fbce92ecb0cd1e319fd3277ec828c,102,10,14,6167,,,0,"Remove legacy v2 unit tests[f-n]

There are two implementation code for similar API in Nova repository.
One is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been
used as the default API since Liberty and legacy v2 API has been marked
as deprecated. We have used and tested v2.1 API so well and now is nice
time to remove legacy API code based on the consensus of the design
summit of Austin. This patch removes unit tests of legacy v2 API[f-n].

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: I543bc2a9c068aae2c755f8159c7d2a9fff2c67ee
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/311658/15 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_hosts.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips_bulk.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/tests/unit/api/openstack/compute/test_limits.py', 'nova/tests/unit/api/openstack/compute/test_neutron_security_groups.py', 'nova/tests/unit/api/openstack/compute/test_hypervisor_status.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_pools.py', 'nova/tests/unit/api/openstack/compute/test_instance_actions.py', 'nova/tests/unit/api/openstack/compute/test_keypairs.py', 'nova/tests/unit/api/openstack/compute/test_networks.py', 'nova/tests/unit/api/openstack/compute/test_images.py', 'nova/tests/unit/api/openstack/compute/test_multiple_create.py', 'nova/tests/unit/api/openstack/compute/test_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_lock_server.py', 'nova/tests/unit/api/openstack/compute/test_fixed_ips.py', 'nova/tests/unit/api/openstack/compute/test_flavors.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_flavor_manage.py', 'nova/tests/unit/api/openstack/compute/test_fping.py', 'nova/tests/unit/api/openstack/compute/test_multinic.py', 'nova/tests/unit/api/openstack/compute/test_flavor_access.py', 'nova/tests/unit/api/openstack/compute/test_image_metadata.py', 'nova/tests/unit/api/openstack/compute/test_migrations.py', 'nova/tests/unit/api/openstack/compute/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/test_flavors_extra_specs.py']",25,dd4fb18d20eeacaff5b2899806f6bb9b747e86b8,bp/remove-legacy-v2-api-code,,from nova.api.openstack.compute.legacy_v2.contrib import flavorextraspecs \ as flavorextraspecs_v2 class FlavorsExtraSpecsTestV2(FlavorsExtraSpecsTestV21): bad_request = webob.exc.HTTPBadRequest flavorextraspecs = flavorextraspecs_v2,0,913
openstack%2Fhorizon~master~Iaec6eb5487416f68afacbff272b22e86b41b1582,openstack/horizon,master,Iaec6eb5487416f68afacbff272b22e86b41b1582,Add download button for volume transfer creds,MERGED,2015-11-20 13:41:54.000000000,2016-05-06 13:57:08.000000000,2016-05-06 13:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 13325}, {'_account_id': 14151}, {'_account_id': 17172}, {'_account_id': 17642}, {'_account_id': 20992}]","[{'number': 1, 'created': '2015-11-20 13:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9bdcceda986c3e6d23b9698ea44bc62f111076b0', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 2, 'created': '2015-12-10 13:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/29c19be68324266428f001176c40f309e649e8ea', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 3, 'created': '2015-12-10 14:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/143db7fe21b7f82639f0a7c62540dfe13cff055f', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 4, 'created': '2015-12-11 08:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/336770af075682b76d2e0ff949520a23cd4b9972', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 5, 'created': '2016-01-15 11:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32a12979d6acf5c5f796f7d80c5c1754d425d00d', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 6, 'created': '2016-01-22 17:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d83bf59f41ffff16d6c556ea205d9854fb2acf72', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 7, 'created': '2016-02-08 07:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/59c2bff558445d1a6a9e6bb8c1747c1b77ddd60d', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 8, 'created': '2016-02-08 08:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2db307e956bc668175ad225fabbdb1356a738ab6', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 9, 'created': '2016-02-12 09:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f6c66d46b678942bd94c7e7b21b2fd2237dac8f8', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 10, 'created': '2016-02-24 11:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a3f22568d23b4c7236338ab114428358c45948dd', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 11, 'created': '2016-03-15 10:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/79fbdc5db926ff9354ed3184356ea65ef7c64d36', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 12, 'created': '2016-03-31 14:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0953796273303669f3fa7afca4bfeaa325f65a94', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 13, 'created': '2016-04-06 13:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/691753fe7f34de0b45b86913b9a649d13bf3f32c', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 14, 'created': '2016-04-14 10:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cdf35b7fef5e2a5112026e055a2a7abacc5c2aaf', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}, {'number': 15, 'created': '2016-04-15 09:10:02.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_show_transfer.html', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/urls.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/views.py', 'openstack_dashboard/dashboards/project/volumes/volumes/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0039ac040099df691b8338a1418fc76bf615bc88', 'message': 'Add download button for volume transfer creds\n\nAdds a download credentials button for the volume\ntransfer action, available in the transfer details\nthat appear after creating a new transfer\n\nChange-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582\nCloses-Bug: 1515648\n'}]",10,248082,0039ac040099df691b8338a1418fc76bf615bc88,77,11,15,12281,,,0,"Add download button for volume transfer creds

Adds a download credentials button for the volume
transfer action, available in the transfer details
that appear after creating a new transfer

Change-Id: Iaec6eb5487416f68afacbff272b22e86b41b1582
Closes-Bug: 1515648
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/248082/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/templates/volumes/volumes/_show_transfer.html', 'openstack_dashboard/dashboards/project/volumes/volumes/urls.py', 'openstack_dashboard/dashboards/project/volumes/volumes/views.py']",3,9bdcceda986c3e6d23b9698ea44bc62f111076b0,bug/1515648,"from django import http from django.template.defaultfilters import slugify # noqa from django.utils.decorators import method_decoratorfrom django.views.decorators.cache import cache_control from django.views.decorators.cache import never_cache download_label = _(""Download transfer credentials"") context['download_label'] = self.download_label context['download_url'] = reverse( 'horizon:project:volumes:volumes:download_transfer_creds', args=[context['transfer_id'], context['auth_key']] ) class DownloadTransferCreds(generic.View): @method_decorator(cache_control(max_age=0, no_cache=True, no_store=True, must_revalidate=True)) @method_decorator(never_cache) def get(self, request, transfer_id, auth_key): try: transfer = cinder.transfer_get(self.request, transfer_id) except Exception: transfer = None response = http.HttpResponse(content_type='application/text') response['Content-Disposition'] = \ 'attachment; filename=%s.txt' % slugify( getattr(transfer, 'name', transfer_id)) response.write('%s: %s\n%s: %s' % ( _(""Transfer ID""), transfer_id, _(""Authorization Key""), auth_key)) response['Content-Length'] = str(len(response.content)) return response",,42,1
openstack%2Ftempest~master~I0ec375d24f6aac69a79578180efe5018b25a1bdd,openstack/tempest,master,I0ec375d24f6aac69a79578180efe5018b25a1bdd,ssh before shelve to avoid ssh failures,MERGED,2016-05-05 16:12:35.000000000,2016-05-06 13:56:57.000000000,2016-05-06 13:56:57.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 10016}, {'_account_id': 10385}, {'_account_id': 12024}]","[{'number': 1, 'created': '2016-05-05 16:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8df9d1716b6a72e908619624931cd8e1a34696df', 'message': 'ssh before shelve to avoid ssh failures\n\nThe current test to attach / detach volumes on a shelved\nserver, performe the shelves before having verified that the\nserver was ssh-able. This makes failures in the VM setup\nbefore and after shelve non distinguishable.\n\nAdding an ssh check before shelve.\n\nChange-Id: I0ec375d24f6aac69a79578180efe5018b25a1bdd\n'}, {'number': 2, 'created': '2016-05-05 18:48:23.000000000', 'files': ['tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f344eec211553dcd7e6fa61d461a09c716693baf', 'message': 'ssh before shelve to avoid ssh failures\n\nThe current test to attach / detach volumes on a shelved\nserver, performe the shelves before having verified that the\nserver was ssh-able. This makes failures in the VM setup\nbefore and after shelve non distinguishable.\n\nAdding an ssh check before shelve.\n\nChange-Id: I0ec375d24f6aac69a79578180efe5018b25a1bdd\n'}]",0,313041,f344eec211553dcd7e6fa61d461a09c716693baf,20,7,2,1921,,,0,"ssh before shelve to avoid ssh failures

The current test to attach / detach volumes on a shelved
server, performe the shelves before having verified that the
server was ssh-able. This makes failures in the VM setup
before and after shelve non distinguishable.

Adding an ssh check before shelve.

Change-Id: I0ec375d24f6aac69a79578180efe5018b25a1bdd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/41/313041/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/common/utils/data_utils.py', 'tempest/services/object_storage/object_client.py', 'tempest/scenario/manager.py', 'doc/source/configuration.rst', 'tempest/cmd/verify_tempest_config.py', 'tempest/scenario/test_network_basic_ops.py', 'doc/source/library.rst', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/volume/admin/test_volume_types.py', 'tempest/services/network/resources.py', 'tempest/tests/cmd/test_verify_tempest_config.py', 'doc/source/plugin.rst', 'tempest/config.py', 'tempest/exceptions.py', 'tempest/api/database/flavors/test_flavors.py', 'tempest/common/credentials_factory.py', 'tox.ini', 'tempest/hacking/checks.py', 'HACKING.rst', 'tempest/tests/lib/common/utils/test_data_utils.py']",20,8df9d1716b6a72e908619624931cd8e1a34696df,debug_remote_client_failure,," def test_rand_infiniband_guid_address(self): actual = data_utils.rand_infiniband_guid_address() self.assertIsInstance(actual, str) self.assertRegex(actual, ""^([0-9a-f][0-9a-f]:){7}"" ""[0-9a-f][0-9a-f]$"") actual2 = data_utils.rand_infiniband_guid_address() self.assertNotEqual(actual, actual2) ",115,154
openstack%2Ftempest~master~If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e,openstack/tempest,master,If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e,Pass server to RemoteClient in API tests,MERGED,2016-04-29 21:40:14.000000000,2016-05-06 13:56:36.000000000,2016-05-06 13:56:36.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 9732}, {'_account_id': 10016}, {'_account_id': 10385}, {'_account_id': 12017}]","[{'number': 1, 'created': '2016-04-29 21:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4eb2ce9d4acba8a86c02ffcd8f16f22fb64e3394', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}, {'number': 2, 'created': '2016-05-02 22:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5cd7df53956b5fa615857f04fb41c857b72e20cf', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}, {'number': 3, 'created': '2016-05-03 03:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c46108857a68711ad15b76821237ad2cce7c47de', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}, {'number': 4, 'created': '2016-05-04 14:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/30ebba30e26eaa8528f04b2b772db832af501856', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}, {'number': 5, 'created': '2016-05-05 15:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ddc95fe2f04de0a93985251a9d9fa812f7a1c154', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}, {'number': 6, 'created': '2016-05-05 18:42:28.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/api/compute/servers/test_server_personality.py', 'tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2a70a610767efe6335c3e3e258fa140a43cccd12', 'message': 'Pass server to RemoteClient in API tests\n\nRemote client can do better debugging if it knows the server, so\npassing the server to it in all API tests.\n\nChange-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e\n'}]",0,311283,2a70a610767efe6335c3e3e258fa140a43cccd12,45,8,6,1921,,,0,"Pass server to RemoteClient in API tests

Remote client can do better debugging if it knows the server, so
passing the server to it in all API tests.

Change-Id: If4eedc30e80b9af95a7db62fbf0ab71ee0b0300e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/83/311283/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/api/compute/servers/test_server_personality.py', 'tempest/api/compute/volumes/test_attach_volume.py']",4,4eb2ce9d4acba8a86c02ffcd8f16f22fb64e3394,debug_remote_client_failure," self.validation_resources['keypair']['private_key'], server=self.server, servers_client=self.servers_client) self.validation_resources['keypair']['private_key'], server=self.server, servers_client=self.servers_client) self.validation_resources['keypair']['private_key'], server=self.server, servers_client=self.servers_client)", self.validation_resources['keypair']['private_key']) self.validation_resources['keypair']['private_key']) self.validation_resources['keypair']['private_key']),39,13
openstack%2Ftempest~master~I3127e58a9d333df0f55adb2960dc7f26d66c4609,openstack/tempest,master,I3127e58a9d333df0f55adb2960dc7f26d66c4609,Extend remote client to allow for better debugging,MERGED,2016-04-29 21:01:33.000000000,2016-05-06 13:54:21.000000000,2016-05-06 13:54:21.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 7812}, {'_account_id': 9152}, {'_account_id': 9732}, {'_account_id': 10016}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 17716}]","[{'number': 1, 'created': '2016-04-29 21:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1f14d62d866559d2ad99cffae2fba9e227ccb62', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 2, 'created': '2016-04-29 21:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb6a479dc339e1eb8cfd29f0066b8b6f2747b20d', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 3, 'created': '2016-05-02 22:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/98110d33642dd865b436f7428820c6e2aee08886', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 4, 'created': '2016-05-03 03:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4218a0141174702ca8d4ec014fa1d6af9577224f', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 5, 'created': '2016-05-03 22:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5930d06a5304d406da850614c717ec892ae5155e', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 6, 'created': '2016-05-03 23:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6fe24670aec88d2556348f116e06b413962440a2', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 7, 'created': '2016-05-04 11:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b57c94ce4a4ba9b16ec7e43eb6d0787402e2e631', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 8, 'created': '2016-05-05 15:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9e32d5422c148069e0ff9c122cda49dfe2361668', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 9, 'created': '2016-05-05 16:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6df0faaac46e5f95f20065d57d7b5e9171afefa7', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}, {'number': 10, 'created': '2016-05-05 18:39:42.000000000', 'files': ['tempest/common/utils/linux/remote_client.py', 'tempest/tests/common/utils/linux/test_remote_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f5e4fcce1487a484374258cf46732cd22623b2a', 'message': 'Extend remote client to allow for better debugging\n\nExtend the ssh remote client so that server details can be passed\nin, to enrich debug messages with server details and console log\nwhen available. Add unit test coverage for the exception handling\nand logging as well.\n\nChange-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609\n'}]",18,311270,5f5e4fcce1487a484374258cf46732cd22623b2a,54,11,10,1921,,,0,"Extend remote client to allow for better debugging

Extend the ssh remote client so that server details can be passed
in, to enrich debug messages with server details and console log
when available. Add unit test coverage for the exception handling
and logging as well.

Change-Id: I3127e58a9d333df0f55adb2960dc7f26d66c4609
",git fetch https://review.opendev.org/openstack/tempest refs/changes/70/311270/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/utils/linux/remote_client.py'],1,d1f14d62d866559d2ad99cffae2fba9e227ccb62,debug_remote_client_failure,"import sys def __init__(self, ip_address, username, password=None, pkey=None, server=None, servers_client=None): """""" :param ip_address: IP address to ssh to :param username: ssh username :param password: ssh password (optional) :param pkey: ssh public key (optional) :param server: server dict, used for debugging purposes :param servers_client: servers client, used for debugging purposes """""" self.log_console = CONF.compute_feature_enabled.console_output try: return self.ssh_client.exec_command(cmd) except tempest.lib.exceptions.SSHTimeout: original_exception = sys.exc_info() if self.server and self.severs_client: msg = 'Timeout trying to ssh to sever %s' LOG.debug(msg % self.server) try: msg = 'Console log for server %s: %s' console_log = self.severs_client.get_console_output( self.server['id']) LOG.debug(msg % (self.server['id'], console_log)) except Exception: msg = 'Could not get console_log for server %s' LOG.debug(msg % self.server['id']) # re-raise the original ssh timeout exception raise original_exception"," def __init__(self, ip_address, username, password=None, pkey=None): return self.ssh_client.exec_command(cmd)",30,2
openstack%2Fopenstack-ansible-security~liberty~I28a9f45b8c5a923fd470524fbae890a3db7f2b44,openstack/openstack-ansible-security,liberty,I28a9f45b8c5a923fd470524fbae890a3db7f2b44,Switch from dict to individual variables,ABANDONED,2016-05-05 14:12:20.000000000,2016-05-06 13:46:49.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 15993}]","[{'number': 1, 'created': '2016-05-05 14:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/8667ec1384e4f8ebd2035f6d8faf510f8e1ac286', 'message': ""Switch from dict to individual variables\n\nThe dictionary-based variables didn't work properly and this patch\nchanges them to individual variables. If users followed the existing\ndocumentation, their environments will be unaffected by this change\n(they are still broken).\n\nThe new variables follow the pattern `security_VARIABLENAME` which\nwill soon become the standard for the role to avoid variable name\ncollisions with other playbooks and roles.\n\nThis is a manual backport of:\n  I455f66a0b4f423e2cf0e753b129367427f29479f\n\nCloses-bug: 1577944\n\nChange-Id: I28a9f45b8c5a923fd470524fbae890a3db7f2b44\n""}, {'number': 2, 'created': '2016-05-05 21:27:21.000000000', 'files': ['doc/source/developer-notes/V-38514.rst', 'doc/source/developer-notes/V-38587.rst', 'doc/source/developer-notes/V-38603.rst', 'doc/source/developer-notes/V-38676.rst', 'doc/source/developer-notes/V-38582.rst', 'doc/source/developer-notes/V-38566.rst', 'doc/source/developer-notes/V-38591.rst', 'doc/source/developer-notes/V-38671.rst', 'doc/source/developer-notes/V-38543.rst', 'defaults/main.yml', 'doc/source/developer-notes/V-38575.rst', 'doc/source/developer-notes/V-38437.rst', 'doc/source/developer-notes/V-38539.rst', 'doc/source/developer-notes/V-38606.rst', 'tasks/auth.yml', 'doc/source/developer-notes/V-38490.rst', 'doc/source/developer-notes/V-38648.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-38584.rst', 'templates/osas-auditd.j2', 'doc/source/developer-notes/V-38517.rst', 'doc/source/developer-notes/V-38627.rst', 'doc/source/developer-notes/V-38515.rst', 'doc/source/developer-notes/V-38516.rst', 'tasks/kernel.yml', 'tasks/services.yml', 'doc/source/developer-notes/V-38691.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/2ae68bb26f1baa580110df5f4348f9a1e086af36', 'message': ""Switch from dict to individual variables\n\nThe dictionary-based variables didn't work properly and this patch\nchanges them to individual variables. If users followed the existing\ndocumentation, their environments will be unaffected by this change\n(they are still broken).\n\nThe new variables follow the pattern `security_VARIABLENAME` which\nwill soon become the standard for the role to avoid variable name\ncollisions with other playbooks and roles.\n\nThis is a manual backport of:\n  I455f66a0b4f423e2cf0e753b129367427f29479f\n\nCloses-bug: 1577944\n\nChange-Id: I28a9f45b8c5a923fd470524fbae890a3db7f2b44\n""}]",0,312980,2ae68bb26f1baa580110df5f4348f9a1e086af36,10,4,2,538,,,0,"Switch from dict to individual variables

The dictionary-based variables didn't work properly and this patch
changes them to individual variables. If users followed the existing
documentation, their environments will be unaffected by this change
(they are still broken).

The new variables follow the pattern `security_VARIABLENAME` which
will soon become the standard for the role to avoid variable name
collisions with other playbooks and roles.

This is a manual backport of:
  I455f66a0b4f423e2cf0e753b129367427f29479f

Closes-bug: 1577944

Change-Id: I28a9f45b8c5a923fd470524fbae890a3db7f2b44
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/80/312980/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer-notes/V-38514.rst', 'doc/source/developer-notes/V-38587.rst', 'doc/source/developer-notes/V-38603.rst', 'doc/source/developer-notes/V-38676.rst', 'doc/source/developer-notes/V-38582.rst', 'doc/source/developer-notes/V-38566.rst', 'doc/source/developer-notes/V-38591.rst', 'doc/source/developer-notes/V-38671.rst', 'doc/source/developer-notes/V-38543.rst', 'defaults/main.yml', 'doc/source/developer-notes/V-38575.rst', 'doc/source/developer-notes/V-38437.rst', 'doc/source/developer-notes/V-38539.rst', 'doc/source/developer-notes/V-38606.rst', 'tasks/auth.yml', 'doc/source/developer-notes/V-38490.rst', 'doc/source/developer-notes/V-38648.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-38584.rst', 'templates/osas-auditd.j2', 'doc/source/developer-notes/V-38517.rst', 'doc/source/developer-notes/V-38627.rst', 'doc/source/developer-notes/V-38515.rst', 'doc/source/developer-notes/V-38516.rst', 'tasks/kernel.yml', 'tasks/services.yml', 'doc/source/developer-notes/V-38691.rst']",27,8667ec1384e4f8ebd2035f6d8faf510f8e1ac286,bug/1577944, security_disable_bluetooth: no, disable_services['bluetooth']: no,164,143
openstack%2Fopenstack-ansible-security~stable%2Fmitaka~Icfedf76500e5192ff76669b083500aabbecae24e,openstack/openstack-ansible-security,stable/mitaka,Icfedf76500e5192ff76669b083500aabbecae24e,Switch from dict to individual variables,ABANDONED,2016-05-05 14:09:10.000000000,2016-05-06 13:46:42.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 14:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/fe71d9b6a3bc0c4744826569729cca1fe946e034', 'message': ""Switch from dict to individual variables\n\nThe dictionary-based variables didn't work properly and this patch\nchanges them to individual variables. If users followed the existing\ndocumentation, their environments will be unaffected by this change\n(they are still broken).\n\nThe new variables follow the pattern `security_VARIABLENAME` which\nwill soon become the standard for the role to avoid variable name\ncollisions with other playbooks and roles.\n\nThis is a manual backport of:\n  https://review.openstack.org/#/c/312506/\n\nCloses-bug: 1577944\n\nChange-Id: Icfedf76500e5192ff76669b083500aabbecae24e\n""}, {'number': 2, 'created': '2016-05-05 14:11:52.000000000', 'files': ['doc/source/developer-notes/V-38514.rst', 'doc/source/developer-notes/V-38587.rst', 'doc/source/developer-notes/V-38603.rst', 'doc/source/developer-notes/V-38676.rst', 'doc/source/developer-notes/V-38582.rst', 'doc/source/developer-notes/V-38566.rst', 'doc/source/developer-notes/V-38591.rst', 'doc/source/developer-notes/V-38671.rst', 'doc/source/developer-notes/V-38543.rst', 'defaults/main.yml', 'doc/source/developer-notes/V-38575.rst', 'doc/source/developer-notes/V-38437.rst', 'releasenotes/notes/disable-failed-access-audit-logging-789dc01c8bcbef17.yaml', 'doc/source/developer-notes/V-38539.rst', 'doc/source/developer-notes/V-38606.rst', 'tasks/auth.yml', 'doc/source/developer-notes/V-38490.rst', 'releasenotes/notes/dictionary-variables-removed-957c7b7b2108ba1f.yaml', 'doc/source/developer-notes/V-38648.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-38584.rst', 'templates/osas-auditd.j2', 'doc/source/developer-notes/V-38517.rst', 'doc/source/developer-notes/V-38627.rst', 'doc/source/developer-notes/V-38515.rst', 'doc/source/developer-notes/V-38516.rst', 'tasks/kernel.yml', 'tasks/services.yml', 'doc/source/developer-notes/V-38691.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/10d75a6d478e994993123a3fa2d956f3080aa672', 'message': ""Switch from dict to individual variables\n\nThe dictionary-based variables didn't work properly and this patch\nchanges them to individual variables. If users followed the existing\ndocumentation, their environments will be unaffected by this change\n(they are still broken).\n\nThe new variables follow the pattern `security_VARIABLENAME` which\nwill soon become the standard for the role to avoid variable name\ncollisions with other playbooks and roles.\n\nThis is a manual backport of:\n  I455f66a0b4f423e2cf0e753b129367427f29479f\n\nCloses-bug: 1577944\n\nChange-Id: Icfedf76500e5192ff76669b083500aabbecae24e\n""}]",0,312977,10d75a6d478e994993123a3fa2d956f3080aa672,7,3,2,538,,,0,"Switch from dict to individual variables

The dictionary-based variables didn't work properly and this patch
changes them to individual variables. If users followed the existing
documentation, their environments will be unaffected by this change
(they are still broken).

The new variables follow the pattern `security_VARIABLENAME` which
will soon become the standard for the role to avoid variable name
collisions with other playbooks and roles.

This is a manual backport of:
  I455f66a0b4f423e2cf0e753b129367427f29479f

Closes-bug: 1577944

Change-Id: Icfedf76500e5192ff76669b083500aabbecae24e
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/77/312977/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer-notes/V-38514.rst', 'doc/source/developer-notes/V-38587.rst', 'doc/source/developer-notes/V-38603.rst', 'doc/source/developer-notes/V-38676.rst', 'doc/source/developer-notes/V-38582.rst', 'doc/source/developer-notes/V-38566.rst', 'doc/source/developer-notes/V-38591.rst', 'doc/source/developer-notes/V-38671.rst', 'doc/source/developer-notes/V-38543.rst', 'defaults/main.yml', 'doc/source/developer-notes/V-38575.rst', 'doc/source/developer-notes/V-38437.rst', 'releasenotes/notes/disable-failed-access-audit-logging-789dc01c8bcbef17.yaml', 'doc/source/developer-notes/V-38539.rst', 'doc/source/developer-notes/V-38606.rst', 'tasks/auth.yml', 'doc/source/developer-notes/V-38490.rst', 'releasenotes/notes/dictionary-variables-removed-957c7b7b2108ba1f.yaml', 'doc/source/developer-notes/V-38648.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-38584.rst', 'templates/osas-auditd.j2', 'doc/source/developer-notes/V-38517.rst', 'doc/source/developer-notes/V-38627.rst', 'doc/source/developer-notes/V-38515.rst', 'doc/source/developer-notes/V-38516.rst', 'tasks/kernel.yml', 'tasks/services.yml', 'doc/source/developer-notes/V-38691.rst']",29,fe71d9b6a3bc0c4744826569729cca1fe946e034,bug/1577944, security_disable_bluetooth: no, disable_services['bluetooth']: no,174,144
openstack%2Fsahara-image-elements~master~Ia6b122f0e1cf719bc7e66a6ebb2a441ff3823c1f,openstack/sahara-image-elements,master,Ia6b122f0e1cf719bc7e66a6ebb2a441ff3823c1f,testcommit,ABANDONED,2016-04-15 14:11:43.000000000,2016-05-06 13:43:04.000000000,,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 13919}]","[{'number': 1, 'created': '2016-04-15 14:11:43.000000000', 'files': ['diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/fb5ee3e190cd0b091d2d36706a7fe9ce958b7f94', 'message': 'testcommit\n\nChange-Id: Ia6b122f0e1cf719bc7e66a6ebb2a441ff3823c1f\n'}]",0,306451,fb5ee3e190cd0b091d2d36706a7fe9ce958b7f94,5,3,1,13919,,,0,"testcommit

Change-Id: Ia6b122f0e1cf719bc7e66a6ebb2a441ff3823c1f
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/51/306451/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,fb5ee3e190cd0b091d2d36706a7fe9ce958b7f94,,,,1,0
openstack%2Fsahara~stable%2Fmitaka~Ie9ade1d8704532b8b6ef3351a20da6fca3c1cf67,openstack/sahara,stable/mitaka,Ie9ade1d8704532b8b6ef3351a20da6fca3c1cf67,testcommit,ABANDONED,2016-04-21 07:35:14.000000000,2016-05-06 13:42:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}]","[{'number': 1, 'created': '2016-04-21 07:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a2ced3c5a64a815c45d3bd3854d28d4cb66c987e', 'message': 'testcommit for ci\n\nChange-Id: Ie9ade1d8704532b8b6ef3351a20da6fca3c1cf67\n'}, {'number': 2, 'created': '2016-04-29 07:36:29.000000000', 'files': ['sahara/api/acl.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/bb11c59ec94fa598cd9fec03d772d10c7cc8abc8', 'message': 'testcommit\n\nChange-Id: Ie9ade1d8704532b8b6ef3351a20da6fca3c1cf67\n'}]",0,308811,bb11c59ec94fa598cd9fec03d772d10c7cc8abc8,9,2,2,13919,,,0,"testcommit

Change-Id: Ie9ade1d8704532b8b6ef3351a20da6fca3c1cf67
",git fetch https://review.opendev.org/openstack/sahara refs/changes/11/308811/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/api/acl.py'],1,a2ced3c5a64a815c45d3bd3854d28d4cb66c987e,,,,1,0
openstack%2Fopenstack-ansible-security~master~Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720,openstack/openstack-ansible-security,master,Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720,Doc updates,MERGED,2016-04-07 13:58:24.000000000,2016-05-06 13:39:49.000000000,2016-04-15 10:52:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 20777}]","[{'number': 1, 'created': '2016-04-07 13:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/d84ea310bb8e87f409bff70fd0d349cb3e339446', 'message': '[WIP] Doc updates\n\nChange-Id: Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720\n'}, {'number': 2, 'created': '2016-04-08 11:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/20d41f73c6e1e0ec7ac2728b4675b514db7e2206', 'message': 'Doc updates\n\nThis commit fixes some RST-related errors, spelling/typos, and updates\nsome variable values which are incorrect.\n\nChange-Id: Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720\n'}, {'number': 3, 'created': '2016-04-15 10:39:21.000000000', 'files': ['doc/source/developer-notes/V-38575.rst', 'doc/source/developer-notes/V-38497.rst', 'doc/source/stig-notes/V-38690.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-38464.rst', 'doc/source/developer-notes/V-38470.rst', 'doc/source/developer-notes/V-38619.rst', 'doc/source/developer-notes/V-51369.rst', 'doc/source/developer-notes/V-38468.rst', 'doc/source/developer-notes/V-38481.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/e44efd0fe7ee89c3400e4634f133872da3b5989f', 'message': 'Doc updates\n\nThis commit fixes some RST-related errors, spelling/typos, and updates\nsome variable values which are incorrect.\n\nChange-Id: Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720\n'}]",5,302776,e44efd0fe7ee89c3400e4634f133872da3b5989f,18,6,3,7307,,,0,"Doc updates

This commit fixes some RST-related errors, spelling/typos, and updates
some variable values which are incorrect.

Change-Id: Ibc78dffc6246f8df2c0d5d42ca2d831c4c335720
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/76/302776/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer-notes/V-38575.rst', 'doc/source/stig-notes/V-38690.rst', 'doc/source/configuration.rst', 'doc/source/developer-notes/V-51369.rst']",4,d84ea310bb8e87f409bff70fd0d349cb3e339446,doc_updates,"as well as they are on Red Hat-based systems. The openstack-ansible project has chosen to use the more Ubuntu-compatible Linux security module, AppArmor.","as well as they are on Red Hat-based systems. The openstack-ansible has chosen to use the more Ubuntu-compatible Linux security module, AppArmor.",5,6
openstack%2Fglance~stable%2Fkilo~Id7f645fc599e57f6c0842bba2b7a2f3db52784ae,openstack/glance,stable/kilo,Id7f645fc599e57f6c0842bba2b7a2f3db52784ae,Cause forbidden when deactivating image(non-admin),ABANDONED,2015-11-23 18:01:47.000000000,2016-05-06 13:18:15.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 12000}, {'_account_id': 17116}]","[{'number': 1, 'created': '2015-11-23 18:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5a8ed4f3215787b3eba843de084f2c456762e875', 'message': 'Cause forbidden when deactivating image(non-admin)\n\nIf a user tries to deactivate an image that is hosted by the admin that\nhas public visiblity, it will currently return a 500 error. This changes\nthat behaviour to return a Forbidden.\n\nCloses-Bug: 1485940\nChange-Id: Id7f645fc599e57f6c0842bba2b7a2f3db52784ae\n(cherry picked from commit 15c08d822af0e4f2c488433210fe240a282b6d86)\n'}, {'number': 2, 'created': '2015-12-19 13:53:14.000000000', 'files': ['glance/api/authorization.py', 'glance/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/33e5363375823d676cd0c34abba93a4722205537', 'message': 'Cause forbidden when deactivating image(non-admin)\n\nIf a user tries to deactivate an image that is hosted by the admin that\nhas public visiblity, it will currently return a 500 error. This changes\nthat behaviour to return a Forbidden.\n\nCloses-Bug: 1485940\nChange-Id: Id7f645fc599e57f6c0842bba2b7a2f3db52784ae\n(cherry picked from commit 15c08d822af0e4f2c488433210fe240a282b6d86)\n'}]",0,248856,33e5363375823d676cd0c34abba93a4722205537,8,4,2,6159,,,0,"Cause forbidden when deactivating image(non-admin)

If a user tries to deactivate an image that is hosted by the admin that
has public visiblity, it will currently return a 500 error. This changes
that behaviour to return a Forbidden.

Closes-Bug: 1485940
Change-Id: Id7f645fc599e57f6c0842bba2b7a2f3db52784ae
(cherry picked from commit 15c08d822af0e4f2c488433210fe240a282b6d86)
",git fetch https://review.opendev.org/openstack/glance refs/changes/56/248856/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/authorization.py', 'glance/tests/unit/test_auth.py']",2,5a8ed4f3215787b3eba843de084f2c456762e875,," def test_deactivate_image(self): self.assertRaises(exception.Forbidden, self.image.deactivate) def test_activate_image(self): self.assertRaises(exception.Forbidden, self.image.activate) ",,14,0
openstack%2Fpuppet-magnum~master~I15746919a7246f6137b802f5aa6f022c63a62046,openstack/puppet-magnum,master,I15746919a7246f6137b802f5aa6f022c63a62046,Add rpc_backend parameter in messaging,ABANDONED,2016-05-02 06:45:14.000000000,2016-05-06 13:17:37.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9414}]","[{'number': 1, 'created': '2016-05-02 06:45:14.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/fa346ff54f9de8c184f8bb6c7288317205379286', 'message': 'Add rpc_backend parameter in messaging\n\nChange-Id: I15746919a7246f6137b802f5aa6f022c63a62046\n'}]",0,311674,fa346ff54f9de8c184f8bb6c7288317205379286,6,3,1,9414,,,0,"Add rpc_backend parameter in messaging

Change-Id: I15746919a7246f6137b802f5aa6f022c63a62046
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/74/311674/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,fa346ff54f9de8c184f8bb6c7288317205379286,add_rpc_backend,"# [*rpc_backend*] # (optional) The rpc backend implementation to use, can be: # rabbit (for rabbitmq) # Defaults to 'rabbit' # $rpc_backend = 'rabbit', 'DEFAULT/rpc_backend' : value => $rpc_backend;", 'DEFAULT/rpc_backend' : value => 'rabbit';,7,1
openstack%2Fpython-swiftclient~stable%2Fkilo~Ib60ce97cef03e0423082c497604525eba2300fa9,openstack/python-swiftclient,stable/kilo,Ib60ce97cef03e0423082c497604525eba2300fa9,Correct the help message of swift tempurl,ABANDONED,2015-07-13 08:19:34.000000000,2016-05-06 13:15:47.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 6983}]","[{'number': 1, 'created': '2015-07-13 08:19:34.000000000', 'files': ['swiftclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/f90d7e1b44efffdc3e5a0a617f574299d67f8871', 'message': 'Correct the help message of swift tempurl\n\ncorrect the help message of swift tempurl\nuse <> instead of [] in Positional arguments.\n\nChange-Id: Ib60ce97cef03e0423082c497604525eba2300fa9\n(cherry picked from commit 91855bd912c75d4b6b86a3245a44099d8d03c676)\n'}]",0,201036,f90d7e1b44efffdc3e5a0a617f574299d67f8871,7,3,1,6983,,,0,"Correct the help message of swift tempurl

correct the help message of swift tempurl
use <> instead of [] in Positional arguments.

Change-Id: Ib60ce97cef03e0423082c497604525eba2300fa9
(cherry picked from commit 91855bd912c75d4b6b86a3245a44099d8d03c676)
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/36/201036/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/shell.py'],1,f90d7e1b44efffdc3e5a0a617f574299d67f8871,bug/1469973,Positional arguments: <method> An HTTP method to allow for this temporary URL. <seconds> The amount of time in seconds the temporary URL will <path> The full path to the Swift object. Example: <key> The secret temporary URL key set on the Swift cluster.,Positions arguments: [method] An HTTP method to allow for this temporary URL. [seconds] The amount of time in seconds the temporary URL will [path] The full path to the Swift object. Example: [key] The secret temporary URL key set on the Swift cluster.,5,5
openstack%2Fheat~stable%2Fkilo~I4d61022db505581f0c1b2feed009c56df18a9ee5,openstack/heat,stable/kilo,I4d61022db505581f0c1b2feed009c56df18a9ee5,Create watch tasks in its own thread,ABANDONED,2016-02-16 00:46:12.000000000,2016-05-06 13:15:05.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 8833}]","[{'number': 1, 'created': '2016-02-16 00:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a5b59513331211130b8451034247d871005f3cc4', 'message': 'Create watch tasks in its own thread\n\nThis change moves the creation of stack watch tasks into its own thread\nwhich retries until it has been done without error.\n\nThe intent is to prevent create_periodic_tasks from raising an error\nwhen the database is not available, and retry stack watch creation until\nthe database becomes available.\n\nOnce execution gets past create_periodic_tasks() then systemd is\nnotified that the service is up, and heat will recover when the database\ncomes back.\n\nChange-Id: I4d61022db505581f0c1b2feed009c56df18a9ee5\nCloses-Bug: #1545885\n(cherry picked from commit 97a42d483ccf504676b191394d498374bf631c0f)\n'}, {'number': 2, 'created': '2016-04-07 20:44:38.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2e25b9a872661a59aaaa0a82fb694586365a3a8d', 'message': 'Create watch tasks in its own thread\n\nThis change moves the creation of stack watch tasks into its own thread\nwhich retries until it has been done without error.\n\nThe intent is to prevent create_periodic_tasks from raising an error\nwhen the database is not available, and retry stack watch creation until\nthe database becomes available.\n\nOnce execution gets past create_periodic_tasks() then systemd is\nnotified that the service is up, and heat will recover when the database\ncomes back.\n\nChange-Id: I4d61022db505581f0c1b2feed009c56df18a9ee5\nCloses-Bug: #1545885\n(cherry picked from commit d4e270cd9faffead520eea8bf03bdb74b4b1a160)\n'}]",0,280455,2e25b9a872661a59aaaa0a82fb694586365a3a8d,9,5,2,4571,,,0,"Create watch tasks in its own thread

This change moves the creation of stack watch tasks into its own thread
which retries until it has been done without error.

The intent is to prevent create_periodic_tasks from raising an error
when the database is not available, and retry stack watch creation until
the database becomes available.

Once execution gets past create_periodic_tasks() then systemd is
notified that the service is up, and heat will recover when the database
comes back.

Change-Id: I4d61022db505581f0c1b2feed009c56df18a9ee5
Closes-Bug: #1545885
(cherry picked from commit d4e270cd9faffead520eea8bf03bdb74b4b1a160)
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/280455/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,a5b59513331211130b8451034247d871005f3cc4,bug/1545885," def create_watch_tasks(): while True: try: # Create a periodic_watcher_task per-stack admin_context = context.get_admin_context() stacks = stack_object.Stack.get_all( admin_context, tenant_safe=False) for s in stacks: self.stack_watch.start_watch_task(s.id, admin_context) LOG.info(_LI(""Watch tasks created"")) return except Exception as e: LOG.error(_LE(""Watch task creation attempt failed, %s""), e) if self.manage_thread_grp is None: self.manage_thread_grp = threadgroup.ThreadGroup() self.manage_thread_grp.add_thread(create_watch_tasks) if self.thread_group_mgr is None: self.thread_group_mgr = ThreadGroupManager() if self.manage_thread_grp is None: self.manage_thread_grp = threadgroup.ThreadGroup()"," # Create a periodic_watcher_task per-stack admin_context = context.get_admin_context() stacks = stack_object.Stack.get_all( admin_context, tenant_safe=False) for s in stacks: self.stack_watch.start_watch_task(s.id, admin_context) self.thread_group_mgr = ThreadGroupManager() self.manage_thread_grp = threadgroup.ThreadGroup()",29,9
openstack%2Fhorizon~stable%2Fkilo~Iab283181428ede84cbc020ebf52a171714f56fa1,openstack/horizon,stable/kilo,Iab283181428ede84cbc020ebf52a171714f56fa1,Fix FWaaS Rules table displaying,ABANDONED,2015-12-16 07:21:02.000000000,2016-05-06 13:14:44.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 12281}, {'_account_id': 17172}]","[{'number': 1, 'created': '2015-12-16 07:21:02.000000000', 'files': ['openstack_dashboard/dashboards/project/firewalls/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/aca33dfd2a3761c68593be09f2e4cbbdea5d85e1', 'message': 'Fix FWaaS Rules table displaying\n\nWhen we try to add a new firewall rule, it has no policy connection\nby default: we should use ""Insert Rule"" from Policies table. However,\nhorizon can\'t display FWaaS tables anymore, breaking with error:\n""\'NoneType\' object has no attribute \'id\'"". This patch adds a policy\ncheck to ""get_policy_link"" method to show firewall rules without\npolicy connections.\n\nCloses-Bug: #1494216\n\nChange-Id: Iab283181428ede84cbc020ebf52a171714f56fa1\n(cherry picked from commit 9022617d9a3faa311842d34e708d42abca8e6a1b)\n'}]",0,258290,aca33dfd2a3761c68593be09f2e4cbbdea5d85e1,16,8,1,4264,,,0,"Fix FWaaS Rules table displaying

When we try to add a new firewall rule, it has no policy connection
by default: we should use ""Insert Rule"" from Policies table. However,
horizon can't display FWaaS tables anymore, breaking with error:
""'NoneType' object has no attribute 'id'"". This patch adds a policy
check to ""get_policy_link"" method to show firewall rules without
policy connections.

Closes-Bug: #1494216

Change-Id: Iab283181428ede84cbc020ebf52a171714f56fa1
(cherry picked from commit 9022617d9a3faa311842d34e708d42abca8e6a1b)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/90/258290/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/firewalls/tables.py'],1,aca33dfd2a3761c68593be09f2e4cbbdea5d85e1,bug/1494216," if datum.policy: return reverse('horizon:project:firewalls:policydetails', kwargs={'policy_id': datum.policy.id})"," return reverse('horizon:project:firewalls:policydetails', kwargs={'policy_id': datum.policy.id})",3,2
openstack%2Fheat~stable%2Fkilo~I7a795efba7d1e75c188b16aef4e7e0726f7d74bf,openstack/heat,stable/kilo,I7a795efba7d1e75c188b16aef4e7e0726f7d74bf,Fix instance resize conflict,ABANDONED,2016-03-16 08:16:25.000000000,2016-05-06 13:14:10.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 7253}, {'_account_id': 8358}, {'_account_id': 12363}, {'_account_id': 16297}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-03-16 08:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/872cf4fd4bae418f7a0fbacf9919ba228078d926', 'message': ""Fix instance resize conflict\n\nHeat's instance resize conflicts Nova's auto resize confirm.\nSometimes in spite of instance resize success,\nstatus go to UPDATE_FAILED.\nThis fixes the conflict.\n\nChange-Id: I7a795efba7d1e75c188b16aef4e7e0726f7d74bf\nCloses-Bug: #1557933\n""}, {'number': 2, 'created': '2016-03-18 00:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e72552e6fa0a8b0c0b9757feba53064e8bc634c', 'message': ""Fix instance resize conflict\n\nHeat's instance resize conflicts Nova's auto resize confirm.\nSometimes in spite of instance resize success,\nstatus go to UPDATE_FAILED.\nThis fixes the conflict.\n\nChange-Id: I7a795efba7d1e75c188b16aef4e7e0726f7d74bf\nCloses-Bug: #1557933\n""}, {'number': 3, 'created': '2016-03-22 00:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/661f680cbb1dd478eddf7d0e982e0e3354a0d40d', 'message': ""Fix instance resize conflict\n\nHeat's instance resize conflicts Nova's auto resize confirm.\nSometimes in spite of instance resize success,\nstatus go to UPDATE_FAILED.\nThis fixes the conflict.\n\nChange-Id: I7a795efba7d1e75c188b16aef4e7e0726f7d74bf\nCloses-Bug: #1557933\n""}, {'number': 4, 'created': '2016-03-22 02:14:07.000000000', 'files': ['heat/engine/clients/os/nova.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/330e1970ef9d6103fee1010d06518839666be039', 'message': ""Fix instance resize conflict\n\nHeat's instance resize conflicts Nova's auto resize confirm.\nSometimes in spite of instance resize success,\nstatus go to UPDATE_FAILED.\nThis fixes the conflict.\n\nChange-Id: I7a795efba7d1e75c188b16aef4e7e0726f7d74bf\nCloses-Bug: #1557933\n""}]",5,293300,330e1970ef9d6103fee1010d06518839666be039,28,7,4,16297,,,0,"Fix instance resize conflict

Heat's instance resize conflicts Nova's auto resize confirm.
Sometimes in spite of instance resize success,
status go to UPDATE_FAILED.
This fixes the conflict.

Change-Id: I7a795efba7d1e75c188b16aef4e7e0726f7d74bf
Closes-Bug: #1557933
",git fetch https://review.opendev.org/openstack/heat refs/changes/00/293300/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/clients/os/nova.py'],1,872cf4fd4bae418f7a0fbacf9919ba228078d926,bug/1557933," try: server.confirm_resize() except Exception as exc: self.refresh_server(server) LOG.warn(_(""Confirm resize failed: '%s'"") % exc) while server.status == 'VERIFY_RESIZE': yield self.refresh_server(server) if server.status != 'ACTIVE': raise exc", server.confirm_resize(),10,1
openstack%2Fpuppet-tripleo~master~Iada2ba5ff37760537cd15630333d2e80550fc031,openstack/puppet-tripleo,master,Iada2ba5ff37760537cd15630333d2e80550fc031,add metadata.json file,MERGED,2016-05-05 17:14:43.000000000,2016-05-06 13:13:16.000000000,2016-05-06 13:13:16.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-05-05 17:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b31074add6d87c4af0dfe2ce5df2d71204ae0c09', 'message': ""add metadata.json file\n\nThis file will be useful to contain the release tag so we can\nautomatically generate tarballs in OpenStack Infra.\nNo requirements have been set, on purpose, because we won't use\npuppetlabs forge to install the module.\n\nChange-Id: Iada2ba5ff37760537cd15630333d2e80550fc031\n""}, {'number': 2, 'created': '2016-05-05 19:04:00.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d287418d48242b7bbb57ded7784fa37e5fd40e2b', 'message': ""add metadata.json file\n\nThis file will be useful to contain the release tag so we can\nautomatically generate tarballs in OpenStack Infra.\nNo requirements have been set, on purpose, because we won't use\npuppetlabs forge to install the module.\n\nChange-Id: Iada2ba5ff37760537cd15630333d2e80550fc031\n""}]",2,313068,d287418d48242b7bbb57ded7784fa37e5fd40e2b,12,5,2,3153,,,0,"add metadata.json file

This file will be useful to contain the release tag so we can
automatically generate tarballs in OpenStack Infra.
No requirements have been set, on purpose, because we won't use
puppetlabs forge to install the module.

Change-Id: Iada2ba5ff37760537cd15630333d2e80550fc031
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/68/313068/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,b31074add6d87c4af0dfe2ce5df2d71204ae0c09,metadata,"{ ""name"": ""openstack-tripleo"", ""version"": ""1.0.0"", ""author"": ""OpenStack Contributors"", ""summary"": ""Puppet module for TripleO"", ""license"": ""Apache-2.0"", ""source"": ""git://github.com/openstack/puppet-tripleo.git"", ""project_page"": ""https://launchpad.net/puppet-tripleo"", ""issues_url"": ""https://bugs.launchpad.net/puppet-gnocchi"", ""description"": ""Installs and configures OpenStack Gnocchi (Metric & index storage API)."", ""requirements"": [ { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ], ""operatingsystem_support"": [ { ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""20""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""7""] } ] } ",,25,0
openstack%2Fopenstack-ansible-plugins~stable%2Fmitaka~Ia40e2e08be4d384eb3e5992502daaebe3d338d32,openstack/openstack-ansible-plugins,stable/mitaka,Ia40e2e08be4d384eb3e5992502daaebe3d338d32,Adjust release note for config template,MERGED,2016-05-05 13:54:09.000000000,2016-05-06 13:13:08.000000000,2016-05-06 13:13:08.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 13:54:09.000000000', 'files': ['releasenotes/notes/config_template-MultiStrOps-support-c28e33fd5044e14d.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/d1f38d5ff4cf25401a9386e4e9bf62379e4c2a25', 'message': ""Adjust release note for config template\n\nThe config template release note has a stand alone 'fixes' note which,\nwhen rendered, makes no sense as it stands alone. As the bug is\nclearly attached to the milestone it is unnecessary to mention the\nbug fixed so that line has been removed.\n\nChange-Id: Ia40e2e08be4d384eb3e5992502daaebe3d338d32\n(cherry picked from commit 79f3735ee0e2e5a924904f6f8b6d479a42bd96c3)\n""}]",0,312964,d1f38d5ff4cf25401a9386e4e9bf62379e4c2a25,6,2,1,6816,,,0,"Adjust release note for config template

The config template release note has a stand alone 'fixes' note which,
when rendered, makes no sense as it stands alone. As the bug is
clearly attached to the milestone it is unnecessary to mention the
bug fixed so that line has been removed.

Change-Id: Ia40e2e08be4d384eb3e5992502daaebe3d338d32
(cherry picked from commit 79f3735ee0e2e5a924904f6f8b6d479a42bd96c3)
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/64/312964/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/config_template-MultiStrOps-support-c28e33fd5044e14d.yaml'],1,d1f38d5ff4cf25401a9386e4e9bf62379e4c2a25,," The ability to support MultiStrOps has been added to the config_template action plugin. This change updates the parser to use the ``set()`` type to determine if values within a given key are to be rendered as ``MultiStrOps``. If an override is used in an INI config file the set type is defined using the standard yaml construct of ""?"" as the item marker."," The ability to support MultiStrOps has been added to the config_template action plugin. This change updates the parser to use the ``set()`` type to determine if values within a given key are to be rendered as ``MultiStrOps``. If an override is used in an INI config file the set type is defined using the standard yaml construct of ""?"" as the item marker.fixes: - Resolves issue https://bugs.launchpad.net/openstack-ansible/+bug/1542513",6,9
openstack%2Fneutron~stable%2Fkilo~I8607cdecdc16c5f94635c94e2f02700c732806eb,openstack/neutron,stable/kilo,I8607cdecdc16c5f94635c94e2f02700c732806eb,port security: gracefully handle resources with no bindings,ABANDONED,2016-03-30 09:00:05.000000000,2016-05-06 13:13:07.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14571}]","[{'number': 1, 'created': '2016-03-30 09:00:05.000000000', 'files': ['neutron/db/portsecurity_db.py', 'neutron/db/portsecurity_db_common.py', 'neutron/tests/unit/plugins/ml2/test_ext_portsecurity.py', 'neutron/extensions/portsecurity.py', 'neutron/tests/unit/db/test_portsecurity_db.py', 'neutron/plugins/ml2/extensions/port_security.py', 'neutron/tests/unit/db/test_portsecurity_db_common.py', 'neutron/tests/unit/plugins/ml2/extensions/test_port_security.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f4ff6678cedc7e93e0cc5ad9e4eabc2ff86c753', 'message': 'port security: gracefully handle resources with no bindings\n\nResources could be created before the extension was enabled in the\nsetup. In that case, no bindings are created for them. In that case, we\nshould gracefully return default (True) value when extracting the value\nusing the mixin; and we should also create binding model on update\nrequest, if there is no existing binding model for the resource.\n\nWhile at it, introduced a constant to store the default value for port\nsecurity (True) and changed several tests to use the constant instead of\nextracting it from extension resource map.\n\nConflicts:\n\tneutron/tests/unit/plugins/ml2/test_ext_portsecurity.py\n\nChange-Id: I8607cdecdc16c5f94635c94e2f02700c732806eb\nCloses-Bug: #1509312\n(cherry picked from commit b0519cf0ada3b3d9b76f84948f9ad3c142fc50be)\n'}]",0,299217,5f4ff6678cedc7e93e0cc5ad9e4eabc2ff86c753,13,8,1,9656,,,0,"port security: gracefully handle resources with no bindings

Resources could be created before the extension was enabled in the
setup. In that case, no bindings are created for them. In that case, we
should gracefully return default (True) value when extracting the value
using the mixin; and we should also create binding model on update
request, if there is no existing binding model for the resource.

While at it, introduced a constant to store the default value for port
security (True) and changed several tests to use the constant instead of
extracting it from extension resource map.

Conflicts:
	neutron/tests/unit/plugins/ml2/test_ext_portsecurity.py

Change-Id: I8607cdecdc16c5f94635c94e2f02700c732806eb
Closes-Bug: #1509312
(cherry picked from commit b0519cf0ada3b3d9b76f84948f9ad3c142fc50be)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/299217/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/portsecurity_db.py', 'neutron/db/portsecurity_db_common.py', 'neutron/tests/unit/plugins/ml2/test_ext_portsecurity.py', 'neutron/extensions/portsecurity.py', 'neutron/tests/unit/db/test_portsecurity_db.py', 'neutron/plugins/ml2/extensions/port_security.py', 'neutron/tests/unit/db/test_portsecurity_db_common.py', 'neutron/tests/unit/plugins/ml2/extensions/test_port_security.py']",8,5f4ff6678cedc7e93e0cc5ad9e4eabc2ff86c753,bug/1509312,"import mock def _test_extend_dict_no_port_security(self, func): """"""Test extend_*_dict won't crash if port_security item is None."""""" session = mock.Mock() getattr(driver, func)(session, db_data, response_data) def test_extend_port_dict_no_port_security(self): self._test_extend_dict_no_port_security('extend_port_dict') def test_extend_network_dict_no_port_security(self): self._test_extend_dict_no_port_security('extend_network_dict')"," def test_extend_port_dict_no_port_security(self): """"""Test _extend_port_security_dict won't crash if port_security item is None """""" driver._extend_port_security_dict(response_data, db_data)",170,39
openstack%2Fopenstack-ansible-os_barbican~master~Iaf1810591a35600386d78db2d62858bfc87c7265,openstack/openstack-ansible-os_barbican,master,Iaf1810591a35600386d78db2d62858bfc87c7265,Add .swp files to .gitignore,MERGED,2016-05-04 14:18:37.000000000,2016-05-06 13:13:03.000000000,2016-05-06 13:13:03.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-04 14:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/ded0c234fd8617ebf5cc47cb27d43dfc7e88b3fd', 'message': 'Add .swp files to .gitignore\n\nChange-Id: Iaf1810591a35600386d78db2d62858bfc87c7265\n'}, {'number': 2, 'created': '2016-05-05 18:46:17.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/d1abd312a51adfacd371cdacef1df96ad140883f', 'message': 'Add .swp files to .gitignore\n\nChange-Id: Iaf1810591a35600386d78db2d62858bfc87c7265\n'}]",0,312542,d1abd312a51adfacd371cdacef1df96ad140883f,11,4,2,6816,,,0,"Add .swp files to .gitignore

Change-Id: Iaf1810591a35600386d78db2d62858bfc87c7265
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/42/312542/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,ded0c234fd8617ebf5cc47cb27d43dfc7e88b3fd,ignore-swap-files,*.swp,,1,0
openstack%2Fopenstack-ansible-os_barbican~master~Ibae87f45736bfab1538cee6a8acdfea913cf2b79,openstack/openstack-ansible-os_barbican,master,Ibae87f45736bfab1538cee6a8acdfea913cf2b79,Change pip install task state to 'latest',MERGED,2016-05-04 08:46:55.000000000,2016-05-06 13:12:57.000000000,2016-05-06 13:12:57.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-05-04 08:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/542d990dd700947da63aed60c8892739025a1e89', 'message': ""Change pip install task state to 'latest'\n\nCurrently all pip install tasks only require the package to be\npresent. This means that when an environment undergoes a minor\nupgrade the package is not upgraded to the same version that\nwas tested with. This ultimately results in a deployed\nenvironment that does not match the tested environment.\n\nWhile for the services installed into venvs this is not an\nissue, it does affect those which do not use venvs and any\npackages which are installed outside of a venv or on top\nof a venv.\n\nThis patch changes the behaviour to ensure that the install\ntask will always use the latest available package. In\ndeveloper_mode this will mean using the version specified\nin upper-constraints, and in an integrated build this will\nmean the version which is available in the wheel repo's\nfolder for the tag.\n\nChange-Id: Ibae87f45736bfab1538cee6a8acdfea913cf2b79\n""}, {'number': 2, 'created': '2016-05-05 18:43:32.000000000', 'files': ['tasks/install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/72c80fe792f49e6948d03b83702a0104f9d52210', 'message': ""Change pip install task state to 'latest'\n\nCurrently all pip install tasks only require the package to be\npresent. This means that when an environment undergoes a minor\nupgrade the package is not upgraded to the same version that\nwas tested with. This ultimately results in a deployed\nenvironment that does not match the tested environment.\n\nWhile for the services installed into venvs this is not an\nissue, it does affect those which do not use venvs and any\npackages which are installed outside of a venv or on top\nof a venv.\n\nThis patch changes the behaviour to ensure that the install\ntask will always use the latest available package. In\ndeveloper_mode this will mean using the version specified\nin upper-constraints, and in an integrated build this will\nmean the version which is available in the wheel repo's\nfolder for the tag.\n\nChange-Id: Ibae87f45736bfab1538cee6a8acdfea913cf2b79\n""}]",0,312381,72c80fe792f49e6948d03b83702a0104f9d52210,14,5,2,6816,,,0,"Change pip install task state to 'latest'

Currently all pip install tasks only require the package to be
present. This means that when an environment undergoes a minor
upgrade the package is not upgraded to the same version that
was tested with. This ultimately results in a deployed
environment that does not match the tested environment.

While for the services installed into venvs this is not an
issue, it does affect those which do not use venvs and any
packages which are installed outside of a venv or on top
of a venv.

This patch changes the behaviour to ensure that the install
task will always use the latest available package. In
developer_mode this will mean using the version specified
in upper-constraints, and in an integrated build this will
mean the version which is available in the wheel repo's
folder for the tag.

Change-Id: Ibae87f45736bfab1538cee6a8acdfea913cf2b79
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/81/312381/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/install.yml'],1,542d990dd700947da63aed60c8892739025a1e89,pip-install-latest," state: ""latest"""," state: ""present""",1,1
openstack%2Fopenstack-ansible-os_barbican~master~Id12f601334a4c696970f77daf50fb46931d71776,openstack/openstack-ansible-os_barbican,master,Id12f601334a4c696970f77daf50fb46931d71776,Use master git branches when testing,MERGED,2016-05-05 17:00:58.000000000,2016-05-06 13:12:54.000000000,2016-05-06 13:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 17:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/1f2f35f53760acb8157f2d045ff72257a8e58a58', 'message': 'Use master git branches when testing\n\nIn the test vars, change the barbican, keystone, and requirements git\ninstall branches to master for consistency with other roles.\n\nChange-Id: Id12f601334a4c696970f77daf50fb46931d71776\n'}, {'number': 2, 'created': '2016-05-05 17:32:24.000000000', 'files': ['other-requirements.txt', 'tests/test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/b39a432e0402d2e35501f1999a9d2334f94e1df6', 'message': 'Use master git branches when testing\n\nIn the test vars, change the barbican, keystone, and requirements git\ninstall branches to master for consistency with other roles.\n\nChange-Id: Id12f601334a4c696970f77daf50fb46931d71776\n'}]",0,313059,b39a432e0402d2e35501f1999a9d2334f94e1df6,9,2,2,14805,,,0,"Use master git branches when testing

In the test vars, change the barbican, keystone, and requirements git
install branches to master for consistency with other roles.

Change-Id: Id12f601334a4c696970f77daf50fb46931d71776
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/59/313059/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/test-vars.yml'],1,1f2f35f53760acb8157f2d045ff72257a8e58a58,test_against_master,keystone_git_install_branch: masterkeystone_requirements_git_install_branch: masterbarbican_git_install_branch: masterbarbican_requirements_git_install_branch: master,keystone_git_install_branch: stable/mitakakeystone_requirements_git_install_branch: stable/mitakabarbican_git_install_branch: stable/mitakabarbican_requirements_git_install_branch: stable/mitaka,4,4
openstack%2Ffuel-qa~stable%2Fmitaka~Id2e604a085239d0f7a8c5ad45454f3659a18f025,openstack/fuel-qa,stable/mitaka,Id2e604a085239d0f7a8c5ad45454f3659a18f025,Don't process pre-checks methods like test cases,MERGED,2016-05-06 10:20:00.000000000,2016-05-06 13:12:46.000000000,2016-05-06 13:12:46.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 9588}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 12867}, {'_account_id': 14057}]","[{'number': 1, 'created': '2016-05-06 10:20:00.000000000', 'files': ['fuelweb_test/testrail/upload_cases_description.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/96fb6a8b65dbaa480a4e6afac1f2f9f176d4b801', 'message': ""Don't process pre-checks methods like test cases\n\nChange-Id: Id2e604a085239d0f7a8c5ad45454f3659a18f025\n""}]",0,313311,96fb6a8b65dbaa480a4e6afac1f2f9f176d4b801,12,8,1,6719,,,0,"Don't process pre-checks methods like test cases

Change-Id: Id2e604a085239d0f7a8c5ad45454f3659a18f025
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/11/313311/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/testrail/upload_cases_description.py'],1,96fb6a8b65dbaa480a4e6afac1f2f9f176d4b801,testrail_fix_before_class," # Skip @before_class methods without doc strings: # they are just pre-checks, not separate tests cases if case.entry.info.before_class: if case.entry.home.func_doc is None: logger.debug('Skipping method ""{0}"", because it is not a ' 'test case'.format(case.entry.home.func_name)) return False ",,8,0
openstack%2Ffuel-qa~master~I6c7f560e70bc555d22ab342d48723642c9df8e25,openstack/fuel-qa,master,I6c7f560e70bc555d22ab342d48723642c9df8e25,Pylint: add fuel_tests,MERGED,2016-05-05 13:41:34.000000000,2016-05-06 13:12:30.000000000,2016-05-06 13:12:30.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9588}, {'_account_id': 9977}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 13505}, {'_account_id': 14057}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-05-05 13:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/76bba5b3fa7e365212689926af7144d6b2d0ad35', 'message': ""Pylint: add fuel_tests\n\n1. Add fuel_tests target\n2. Fix failures of Pylint(it's voting for now)\n\nChange-Id: I6c7f560e70bc555d22ab342d48723642c9df8e25\n""}, {'number': 2, 'created': '2016-05-06 10:20:46.000000000', 'files': ['fuel_tests/tests/test_neutron.py', 'fuel_tests/tests/conftest.py', 'fuel_tests/tests/test_ceph.py', 'fuel_tests/models/manager.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f34477a74845519e77284b6e4494a217cbd162dc', 'message': ""Pylint: add fuel_tests\n\n1. Add fuel_tests target\n2. Fix failures of Pylint(it's voting for now)\n\nChange-Id: I6c7f560e70bc555d22ab342d48723642c9df8e25\n""}]",0,312957,f34477a74845519e77284b6e4494a217cbd162dc,17,15,2,19119,,,0,"Pylint: add fuel_tests

1. Add fuel_tests target
2. Fix failures of Pylint(it's voting for now)

Change-Id: I6c7f560e70bc555d22ab342d48723642c9df8e25
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/57/312957/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_tests/tests/test_neutron.py', 'fuel_tests/tests/conftest.py', 'fuel_tests/tests/test_ceph.py', 'fuel_tests/models/manager.py', 'tox.ini']",5,76bba5b3fa7e365212689926af7144d6b2d0ad35,bug/1578998,"envlist = pep8, py27, pylint, docs, pep8-py{34,35}, pylint-py{27}-{fuelweb,system,gates,fuel} pylint --rcfile=.pylintrc_gerrit fuelweb_test system_test gates_tests fuel_tests[testenv:pylint-py27-fuel] deps= -r{toxinidir}/fuelweb_test/requirements.txt pylint commands=pylint fuel_tests ","envlist = pep8, py27, pylint, docs, pep8-py{34,35}, pylint-py{27}-{fuelweb,system,gates} pylint --rcfile=.pylintrc_gerrit fuelweb_test system_test gates_tests",30,8
openstack%2Fanchor~master~I0c673392c7f6badd7d66c307ace594b1d711674d,openstack/anchor,master,I0c673392c7f6badd7d66c307ace594b1d711674d,Force a recent hash in examples,MERGED,2016-05-06 06:31:35.000000000,2016-05-06 13:12:23.000000000,2016-05-06 13:12:23.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-05-06 06:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/065e1c7b40ac114d9ff3f4d3a9ae585648d02306', 'message': 'Force a recent hash in examples\n\nOn some systems openssl still defaults to sha1 in new certificate requests,\nwhich is rejected by Anchor. Force sha256 in all examples instead.\n\nChange-Id: I0c673392c7f6badd7d66c307ace594b1d711674d\n'}, {'number': 2, 'created': '2016-05-06 06:40:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/anchor/commit/6fdb9be69e9d53234f0d101c76636e06c5d4d6cc', 'message': 'Force a recent hash in examples\n\nOn some systems openssl still defaults to sha1 in new certificate requests,\nwhich is rejected by Anchor. Force sha256 in all examples instead.\n\nChange-Id: I0c673392c7f6badd7d66c307ace594b1d711674d\n'}]",0,313240,6fdb9be69e9d53234f0d101c76636e06c5d4d6cc,9,4,2,1528,,,0,"Force a recent hash in examples

On some systems openssl still defaults to sha1 in new certificate requests,
which is rejected by Anchor. Force sha256 in all examples instead.

Change-Id: I0c673392c7f6badd7d66c307ace594b1d711674d
",git fetch https://review.opendev.org/openstack/anchor refs/changes/40/313240/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,065e1c7b40ac114d9ff3f4d3a9ae585648d02306,," -newkey rsa:4096 -subj ""/CN=Anchor Test CA"" -nodes -x509 -days 365 \ -sha256 -subj ""/CN=anchor-test.example.com"" -sha256"," -newkey rsa:4096 -subj ""/CN=Anchor Test CA"" -nodes -x509 -days 365 -subj ""/CN=anchor-test.example.com""",3,2
openstack%2Fnova~stable%2Fkilo~I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1,openstack/nova,stable/kilo,I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1,XenAPI: Cope with more Cinder backends,ABANDONED,2016-02-09 17:31:05.000000000,2016-05-06 13:12:23.000000000,,"[{'_account_id': 3}, {'_account_id': 161}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 6735}, {'_account_id': 6873}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-09 17:31:05.000000000', 'files': ['nova/tests/unit/virt/xenapi/test_volume_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/virt/xenapi/volume_utils.py', 'nova/tests/unit/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/14857ee1e9a5e9c7ae5762bd9bc968cda3b3ea72', 'message': ""XenAPI: Cope with more Cinder backends\n\nSome Cinder backends (e.g. storwize 7000) expose multiple LUNs for a single\nSR connection from the XenServer host.  Since the SR UUID was based on the\n'volume' ID, which is unique per volume, multiple SRs would be connecting\nto the same array when multiple volumes are exposed.\n\nThis fixes the issue by making sure that we only connect to the array once\nfor each (host,port,IQN) tuple, and we can re-use the SR for as many LUNs\nare presented.\n\nChange-Id: I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1\nCloses-Bug: 1515672\n(cherry picked from commit 5bd222e8d854ca7f03ee6936454ee57e0d6e1a78)\n""}]",0,277982,14857ee1e9a5e9c7ae5762bd9bc968cda3b3ea72,13,7,1,161,,,0,"XenAPI: Cope with more Cinder backends

Some Cinder backends (e.g. storwize 7000) expose multiple LUNs for a single
SR connection from the XenServer host.  Since the SR UUID was based on the
'volume' ID, which is unique per volume, multiple SRs would be connecting
to the same array when multiple volumes are exposed.

This fixes the issue by making sure that we only connect to the array once
for each (host,port,IQN) tuple, and we can re-use the SR for as many LUNs
are presented.

Change-Id: I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1
Closes-Bug: 1515672
(cherry picked from commit 5bd222e8d854ca7f03ee6936454ee57e0d6e1a78)
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/277982/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/xenapi/test_volume_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/virt/xenapi/volume_utils.py', 'nova/tests/unit/virt/xenapi/test_vmops.py']",4,14857ee1e9a5e9c7ae5762bd9bc968cda3b3ea72,bug/1515672,"import uuid def test_no_vm_orphaned_volume_old_sr(self, forget_sr, find_sr_by_uuid, @mock.patch.object(vm_utils, 'lookup', side_effect=[None, None]) @mock.patch.object(vm_utils, 'hard_shutdown_vm') @mock.patch.object(volume_utils, 'find_sr_by_uuid', side_effect=[None, 'sr_ref']) @mock.patch.object(volume_utils, 'forget_sr') @mock.patch.object(uuid, 'uuid5', return_value='fake-uuid') def test_no_vm_orphaned_volume(self, uuid5, forget_sr, find_sr_by_uuid, hard_shutdown_vm, lookup): fake_data = {'volume_id': 'fake-uuid', 'target_portal': 'host:port', 'target_iqn': 'iqn'} self.vmops.destroy(self.instance, 'network_info', {'block_device_mapping': [{'connection_info': {'data': fake_data}}]}) call1 = mock.call(self.vmops._session, 'FA15E-D15C-fake-uuid') call2 = mock.call(self.vmops._session, 'fake-uuid') uuid5.assert_called_once_with(volume_utils.SR_NAMESPACE, 'host/port/iqn') find_sr_by_uuid.assert_has_calls([call1, call2]) forget_sr.assert_called_once_with(self.vmops._session, 'sr_ref') self.assertEqual(0, hard_shutdown_vm.call_count) "," def test_no_vm_orphaned_volume(self, forget_sr, find_sr_by_uuid,",104,9
openstack%2Fanchor~master~I004cbfe486657a80f482e506e4e1fc9396564391,openstack/anchor,master,I004cbfe486657a80f482e506e4e1fc9396564391,Better messages for deprecated algos,MERGED,2016-05-06 06:31:35.000000000,2016-05-06 13:12:17.000000000,2016-05-06 13:12:17.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-05-06 06:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/4a0fdafd32aec2d043d38b210e662c1756eb400b', 'message': 'Better messages for deprecated algos\n\nFor known, but deprecated algorithms (md{2,4,5}, sha1), log a better message\nrather than just the OID of the rejected algorithm.\n\nChange-Id: I004cbfe486657a80f482e506e4e1fc9396564391\n'}, {'number': 2, 'created': '2016-05-06 06:40:47.000000000', 'files': ['tests/validators/test_standards_validator.py', 'anchor/validators/standards.py', 'anchor/X509/signature.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/e5852553334c257679a921e03bb37caac3242a69', 'message': 'Better messages for deprecated algos\n\nFor known, but deprecated algorithms (md{2,4,5}, sha1), log a better message\nrather than just the OID of the rejected algorithm.\n\nChange-Id: I004cbfe486657a80f482e506e4e1fc9396564391\n'}]",0,313239,e5852553334c257679a921e03bb37caac3242a69,9,4,2,1528,,,0,"Better messages for deprecated algos

For known, but deprecated algorithms (md{2,4,5}, sha1), log a better message
rather than just the OID of the rejected algorithm.

Change-Id: I004cbfe486657a80f482e506e4e1fc9396564391
",git fetch https://review.opendev.org/openstack/anchor refs/changes/39/313239/2 && git format-patch -1 --stdout FETCH_HEAD,"['anchor/validators/standards.py', 'anchor/X509/signature.py']",2,4a0fdafd32aec2d043d38b210e662c1756eb400b,,"DEPRECATED_ALGORITHM_NAMES = { asn1_univ.ObjectIdentifier('1.2.840.113549.1.1.2'): 'MD2 with RSA', asn1_univ.ObjectIdentifier('1.2.840.113549.1.1.3'): 'MD4 with RSA', asn1_univ.ObjectIdentifier('1.2.840.113549.1.1.4'): 'MD5 with RSA', asn1_univ.ObjectIdentifier('1.2.840.113549.1.1.5'): 'SHA1 with RSA', asn1_univ.ObjectIdentifier('1.2.840.10040.4.3'): 'SHA1 with DSA', } # valid algorithms def uses_deprecated_algorithm(self): """"""Check for deprecated algorithm in signatures. Returns the name of the algorithm found, or None if everything's ok. """""" name = DEPRECATED_ALGORITHM_NAMES.get(self._get_signing_algorithm()) return name ",,22,0
openstack%2Fanchor~master~Ib5fa6ffcdba879c4eabff513ee2b09a41271bebf,openstack/anchor,master,Ib5fa6ffcdba879c4eabff513ee2b09a41271bebf,"Revert ""Modified config to bypass standards validation""",MERGED,2016-05-06 06:06:54.000000000,2016-05-06 13:12:08.000000000,2016-05-06 13:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-05-06 06:06:54.000000000', 'files': ['config.json'], 'web_link': 'https://opendev.org/openstack/anchor/commit/fef692f901735a198f1e84ae7baf526256faeb4c', 'message': 'Revert ""Modified config to bypass standards validation""\n\nStandards validation was correct, but could use a better error message. That\nwill follow in later commits.\n\nThis reverts commit 87d9da87b49c62a2ea4dfb76c4432b4d5c43eefd.\n\nChange-Id: Ib5fa6ffcdba879c4eabff513ee2b09a41271bebf\n'}]",0,313236,fef692f901735a198f1e84ae7baf526256faeb4c,7,4,1,1528,,,0,"Revert ""Modified config to bypass standards validation""

Standards validation was correct, but could use a better error message. That
will follow in later commits.

This reverts commit 87d9da87b49c62a2ea4dfb76c4432b4d5c43eefd.

Change-Id: Ib5fa6ffcdba879c4eabff513ee2b09a41271bebf
",git fetch https://review.opendev.org/openstack/anchor refs/changes/36/313236/1 && git format-patch -1 --stdout FETCH_HEAD,['config.json'],1,fef692f901735a198f1e84ae7baf526256faeb4c,," ""standards_compliance"": {},",,1,0
openstack%2Fnova~stable%2Fkilo~I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10,openstack/nova,stable/kilo,I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10,libvirt: ignore error messages from multipath command output before parsing,ABANDONED,2015-12-15 23:38:22.000000000,2016-05-06 13:11:46.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 5538}, {'_account_id': 9732}, {'_account_id': 12898}, {'_account_id': 14552}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-12-15 23:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2a5d4528b7ac03cd42487321a5b5a6bdf93e2b4', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via https://review.openstack.org/#/c/165560/\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 2, 'created': '2015-12-16 22:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d82a0355a6c855f7821f3805406aaa6794d427c8', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via https://review.openstack.org/#/c/229152/ (os-brick)\nand https://review.openstack.org/#/c/165560/ for the unit test.\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 3, 'created': '2015-12-16 22:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca3014d574549bb6c2fd272cd1884bdb7cf2d916', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 4, 'created': '2016-01-04 14:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1eec191a633a1b2f834754f6ad0088e138f7c054', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 5, 'created': '2016-01-04 22:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ae6a550dbf316534913302ab52d10d3b9337d22', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 6, 'created': '2016-01-04 22:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41fb4bc14fdce8e604cec6f176f17ac7d09689fd', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 7, 'created': '2016-01-05 14:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b06f90d5e7ba9dfe7afea65174d95e3084f82dc0', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 8, 'created': '2016-02-02 23:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/834525498637317fbb044bd417fc67f1cff7db38', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}, {'number': 9, 'created': '2016-03-07 14:50:28.000000000', 'files': ['nova/virt/libvirt/volume.py', 'nova/tests/unit/virt/libvirt/test_volume.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39c37abf8be503c6f199ccd58903705d143be22c', 'message': ""libvirt: ignore error messages from multipath command output before parsing\n\nThis fixes an issue in _get_multipath_device_name() that fails to\nparse the output from 'multipath' command when the stdout contains\nerror messages in addition to the expected output. As a result\nlibvirt will be instructed to attach wrong, not existing devices names,\nto the instance. This behavior will result in instances not being able\nto boot anymore unless manually fixed.\n\nThis fix back-ports the necessary code changes from the upstream\nos-brick module while adding a unit test, originally\nintroduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc\nrelated to https://review.openstack.org/#/c/165560 and\nhttps://review.openstack.org/#/c/172660\n\nThe unit test has been introduced via\nhttps://review.openstack.org/#/c/165560\n\nChange-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10\nCo-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com\nCloses-Bug: #1433204\n""}]",0,258191,39c37abf8be503c6f199ccd58903705d143be22c,71,8,9,14552,,,0,"libvirt: ignore error messages from multipath command output before parsing

This fixes an issue in _get_multipath_device_name() that fails to
parse the output from 'multipath' command when the stdout contains
error messages in addition to the expected output. As a result
libvirt will be instructed to attach wrong, not existing devices names,
to the instance. This behavior will result in instances not being able
to boot anymore unless manually fixed.

This fix back-ports the necessary code changes from the upstream
os-brick module while adding a unit test, originally
introduced via os-brick commit 99d67bd77cbc83c0a465c64fce2827ee5d5d0afc
related to https://review.openstack.org/#/c/165560 and
https://review.openstack.org/#/c/172660

The unit test has been introduced via
https://review.openstack.org/#/c/165560

Change-Id: I6bdcbeecb1330ed6b5c8bbe928ecfc7b3062aa10
Co-Authored-By: Tomoki Sekiyama tomoki.sekiyama.qu@hitachi.com
Closes-Bug: #1433204
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/258191/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/volume.py', 'nova/tests/unit/virt/libvirt/test_volume.py']",2,e2a5d4528b7ac03cd42487321a5b5a6bdf93e2b4,bug/1433204," @mock.patch.object(os.path, 'realpath', return_value='/dev/sda') @mock.patch.object(os, 'stat', return_value=True) def test_get_multipath_device_name(self, mock_stat, mock_realpath): libvirt_driver = volume.LibvirtISCSIVolumeDriver(self.fake_conn) multipath_output = ( ""Mar 17 14:32:37 | sda: No fc_host device for 'host-1'\n"" ""mpathb (36e00000000010001) dm-4 IET ,VIRTUAL-DISK\n"" ""size=1.0G features='0' hwhandler='0' wp=rw\n"" ""|-+- policy='service-time 0' prio=0 status=active\n"" ""| `- 2:0:0:1 sda 8:0 active undef running\n"" ""`-+- policy='service-time 0' prio=0 status=enabled\n"" "" `- 3:0:0:1 sdb 8:16 active undef running\n"", """") expected = '/dev/mapper/mpathb' with mock.patch.object(utils, 'execute', return_value=multipath_output): self.assertEqual(expected, libvirt_driver._get_multipath_device_name('/dev/sda')) ",,21,1
openstack%2Fnova~stable%2Fkilo~I62c0800f68d8fd89fed98eea9e3f95d1adbe9d7f,openstack/nova,stable/kilo,I62c0800f68d8fd89fed98eea9e3f95d1adbe9d7f,Detach and terminate conn if Cinder attach fails,ABANDONED,2015-10-22 13:10:15.000000000,2016-05-06 13:11:20.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 8802}, {'_account_id': 8871}, {'_account_id': 9171}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10618}, {'_account_id': 12898}, {'_account_id': 14358}, {'_account_id': 16376}]","[{'number': 1, 'created': '2015-10-22 13:10:15.000000000', 'files': ['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4268bb1f566cfb42f5de1b24f4c1837911620bcc', 'message': ""Detach and terminate conn if Cinder attach fails\n\nDriver's detach volume is not called while handling\nfailure during Cinder attach. This can result in data\nloss in the case of VMware driver since the instance\nVM is not re-configured to remove volume's vmdk. Also,\nthe connection won't be terminated if attach fails.\nThis patch fixes the above issues with cleanup during\nCinder attach failure.\n\nCloses-bug: #1460044\nChange-Id: I62c0800f68d8fd89fed98eea9e3f95d1adbe9d7f\n(cherry picked from commit aa899506366cd84d5170cb913f33c0c0ca7a8b27)\n""}]",0,238493,4268bb1f566cfb42f5de1b24f4c1837911620bcc,18,12,1,8802,,,0,"Detach and terminate conn if Cinder attach fails

Driver's detach volume is not called while handling
failure during Cinder attach. This can result in data
loss in the case of VMware driver since the instance
VM is not re-configured to remove volume's vmdk. Also,
the connection won't be terminated if attach fails.
This patch fixes the above issues with cleanup during
Cinder attach failure.

Closes-bug: #1460044
Change-Id: I62c0800f68d8fd89fed98eea9e3f95d1adbe9d7f
(cherry picked from commit aa899506366cd84d5170cb913f33c0c0ca7a8b27)
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/238493/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py']",2,4268bb1f566cfb42f5de1b24f4c1837911620bcc,bug/1460044," try: volume_api.attach(context, volume_id, instance.uuid, self['mount_device'], mode=mode) except Exception: with excutils.save_and_reraise_exception(): if do_driver_attach: try: virt_driver.detach_volume(connection_info, instance, self['mount_device'], encryption=encryption) except Exception: LOG.warn(_LW(""Driver failed to detach volume "" ""%(volume_id)s at %(mount_point)s.""), {'volume_id': volume_id, 'mount_point': self['mount_device']}, exc_info=True, context=context, instance=instance) volume_api.terminate_connection(context, volume_id, connector) # Cinder-volume might have completed volume attach. So # we should detach the volume. If the attach did not # happen, the detach request will be ignored. volume_api.detach(context, volume_id)"," volume_api.attach(context, volume_id, instance.uuid, self['mount_device'], mode=mode)",50,2
openstack%2Fcinder~stable%2Fkilo~Ib10909a098fb2cd070129c239b6d3b95edc8fea0,openstack/cinder,stable/kilo,Ib10909a098fb2cd070129c239b6d3b95edc8fea0,Check context before returning cached value,ABANDONED,2016-01-13 05:08:34.000000000,2016-05-06 13:06:06.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4523}, {'_account_id': 7063}, {'_account_id': 9535}, {'_account_id': 10621}, {'_account_id': 11561}, {'_account_id': 11600}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 15296}, {'_account_id': 16862}, {'_account_id': 17852}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-01-13 05:08:34.000000000', 'files': ['cinder/tests/keymgr/test_barbican.py', 'cinder/keymgr/barbican.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4dee2e70931e5f7821b07428eb2e6c366b92cbc8', 'message': 'Check context before returning cached value\n\nThe key manager caches the value of barbican client to be reused,\nsaving an extra call to keystone.  The cached value is only\napplicable to the current context, so the context must be checked\nbefore returning the cached value.\n\nChange-Id: Ib10909a098fb2cd070129c239b6d3b95edc8fea0\nCloses-Bug: #1523646\n(cherry picked from commit 0832a0355381229ece235440a9c5de1301e51d07)\n'}]",0,266680,4dee2e70931e5f7821b07428eb2e6c366b92cbc8,23,18,1,11561,,,0,"Check context before returning cached value

The key manager caches the value of barbican client to be reused,
saving an extra call to keystone.  The cached value is only
applicable to the current context, so the context must be checked
before returning the cached value.

Change-Id: Ib10909a098fb2cd070129c239b6d3b95edc8fea0
Closes-Bug: #1523646
(cherry picked from commit 0832a0355381229ece235440a9c5de1301e51d07)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/80/266680/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/keymgr/test_barbican.py', 'cinder/keymgr/barbican.py']",2,4dee2e70931e5f7821b07428eb2e6c366b92cbc8,bug/1523646," self._current_context = None # Confirm context is provided, if not raise not authorized if not ctxt: msg = _(""User is not authorized to use key manager."") LOG.error(msg) raise exception.NotAuthorized(msg) if not hasattr(ctxt, 'project_id') or ctxt.project_id is None: msg = _(""Unable to create Barbican Client without project_id."") LOG.error(msg) raise exception.KeyManagerError(msg) # If same context, return cached barbican client if self._barbican_client and self._current_context == ctxt: return self._barbican_client try: auth = identity.v3.Token( auth_url=CONF.keymgr.encryption_auth_url, token=ctxt.auth_token, project_id=ctxt.project_id) sess = session.Session(auth=auth) self._barbican_client = barbican_client.Client( session=sess, endpoint=self._barbican_endpoint) self._current_context = ctxt except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_LE(""Error creating Barbican client.""))"," if not self._barbican_client: # Confirm context is provided, if not raise not authorized if not ctxt: msg = _(""User is not authorized to use key manager."") LOG.error(msg) raise exception.NotAuthorized(msg) if not hasattr(ctxt, 'project_id') or ctxt.project_id is None: msg = _(""Unable to create Barbican Client without project_id."") LOG.error(msg) raise exception.KeyManagerError(msg) try: auth = identity.v3.Token( auth_url=CONF.keymgr.encryption_auth_url, token=ctxt.auth_token, project_id=ctxt.project_id) sess = session.Session(auth=auth) self._barbican_client = barbican_client.Client( session=sess, endpoint=self._barbican_endpoint) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_LE(""Error creating Barbican client.""))",28,22
openstack%2Fglance~stable%2Fkilo~I8f3640276368292ced508d5f4c918c147b9d1f19,openstack/glance,stable/kilo,I8f3640276368292ced508d5f4c918c147b9d1f19,Validate empty location value for v1 api,ABANDONED,2016-01-22 17:05:19.000000000,2016-05-06 13:01:37.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 14676}]","[{'number': 1, 'created': '2016-01-22 17:05:19.000000000', 'files': ['glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/common/store_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8b26f23616d1467791e998ebf151e0866687ce77', 'message': 'Validate empty location value for v1 api\n\nWhen empty string is passed as location value the glance\nraises internal server error.\nThe patch checks that location value is present in image meta\nand generates BadRequest if it is empty.\n\nConflicts:\n\tglance/tests/unit/v1/test_api.py\n\nChange-Id: I8f3640276368292ced508d5f4c918c147b9d1f19\nCloses-Bug: #1498460\n(cherry picked from commit c2cbdd84e721271244dbf1c946e79fc2a0398420)\n'}]",0,271429,8b26f23616d1467791e998ebf151e0866687ce77,6,3,1,5202,,,0,"Validate empty location value for v1 api

When empty string is passed as location value the glance
raises internal server error.
The patch checks that location value is present in image meta
and generates BadRequest if it is empty.

Conflicts:
	glance/tests/unit/v1/test_api.py

Change-Id: I8f3640276368292ced508d5f4c918c147b9d1f19
Closes-Bug: #1498460
(cherry picked from commit c2cbdd84e721271244dbf1c946e79fc2a0398420)
",git fetch https://review.opendev.org/openstack/glance refs/changes/29/271429/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py', 'glance/common/store_utils.py']",3,8b26f23616d1467791e998ebf151e0866687ce77,bug/1498460, if not uri: return False,,46,11
openstack%2Fglance_store~stable%2Fkilo~I2179a1e6e27a636bfca448fa18481eb11e64e6da,openstack/glance_store,stable/kilo,I2179a1e6e27a636bfca448fa18481eb11e64e6da,Swift store: do not send a 0 byte chunk,ABANDONED,2016-01-13 11:35:43.000000000,2016-05-06 12:58:58.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 8122}, {'_account_id': 14676}]","[{'number': 1, 'created': '2016-01-13 11:35:43.000000000', 'files': ['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'glance_store/exceptions.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/83e61b2dc6e8586b76b441b9751513ea54f25788', 'message': 'Swift store: do not send a 0 byte chunk\n\nWhen a chunk of size 0 is added, it is immediately deleted. Swift might try to\ndelete it before its creation is complete, though, leading to a race condition.\nNot sending this 0 byte chunk solves this issue.\n\nCo-Authored-By: Stuart McLaren <stuart.mclaren@hp.com>\nChange-Id: I2179a1e6e27a636bfca448fa18481eb11e64e6da\nCloses-Bug: #1518431\n(cherry picked from commit 399aec1f81853d66c8319405c9170ac69e346e78)\n'}]",0,266851,83e61b2dc6e8586b76b441b9751513ea54f25788,8,4,1,11391,,,0,"Swift store: do not send a 0 byte chunk

When a chunk of size 0 is added, it is immediately deleted. Swift might try to
delete it before its creation is complete, though, leading to a race condition.
Not sending this 0 byte chunk solves this issue.

Co-Authored-By: Stuart McLaren <stuart.mclaren@hp.com>
Change-Id: I2179a1e6e27a636bfca448fa18481eb11e64e6da
Closes-Bug: #1518431
(cherry picked from commit 399aec1f81853d66c8319405c9170ac69e346e78)
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/51/266851/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'glance_store/exceptions.py']",3,83e61b2dc6e8586b76b441b9751513ea54f25788,,"class ZeroSizeChunk(GlanceStoreException): message = _(""Zero size chunk"") ",,14,11
openstack%2Fnova~stable%2Fkilo~I9148849574b05e4168876478af5173028b42074c,openstack/nova,stable/kilo,I9148849574b05e4168876478af5173028b42074c,"Fixes ""Hyper-V destroy vm fails on Windows Server 2008R2""",ABANDONED,2015-09-14 20:43:33.000000000,2016-05-06 12:58:28.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 10118}, {'_account_id': 10635}, {'_account_id': 12604}, {'_account_id': 16839}]","[{'number': 1, 'created': '2015-09-14 20:43:33.000000000', 'files': ['nova/virt/hyperv/pathutils.py', 'nova/tests/unit/virt/hyperv/test_pathutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f74d34e55bfcd71dab5bebbfe7948cf5c09bfa3', 'message': 'Fixes ""Hyper-V destroy vm fails on Windows Server 2008R2""\n\nDelete vm fails on Windows Server 2008R2 with the following error:\n[Error 145] The directory is not empty: \'C:\\\\OpenStack\\\\Instances\\\\instance-00000003\'\n\nThis is happening because on Windows 2008R2 it takes a while (1-2 sec. )\nfor Hyper-V to delete the instance specific files that it stores in the\ninstance folder.\n\nThis patch fixes this bug by adding a retry in the delete method if\nit gets that specific error: WindowsError 145\n\nCloses Bug: 1467409\nChange-Id: I8c194320dfa0c9a00ede3cd5bf38446f896156e3\n(cherry picked from commit d2735ddb0666381bfbc5fa5f8d4b2157cceeabbb)\n\n---------------------------------------------------------------------\nsquashed with another change that did not mock time.sleep\n---------------------------------------------------------------------\n\nhyper-v: mock time.sleep in test_rmtree\n\nAdded in change I8c194320dfa0c9a00ede3cd5bf38446f896156e3, test_rmtree\nalways takes at least one second because time.sleep(1) is not mocked\nout. It\'s a bit of a nit but we should always mock out sleep calls so\nthe tests run as fast as possible - which matters when you have over 13K\nof them.\n\n(cherry picked from commit ec5879d3aa85f305f2ed91d26f0529e283586c89)\nCloses-Bug: #1486203\n\nChange-Id: I9148849574b05e4168876478af5173028b42074c\n'}]",3,223290,1f74d34e55bfcd71dab5bebbfe7948cf5c09bfa3,18,9,1,8213,,,0,"Fixes ""Hyper-V destroy vm fails on Windows Server 2008R2""

Delete vm fails on Windows Server 2008R2 with the following error:
[Error 145] The directory is not empty: 'C:\\OpenStack\\Instances\\instance-00000003'

This is happening because on Windows 2008R2 it takes a while (1-2 sec. )
for Hyper-V to delete the instance specific files that it stores in the
instance folder.

This patch fixes this bug by adding a retry in the delete method if
it gets that specific error: WindowsError 145

Closes Bug: 1467409
Change-Id: I8c194320dfa0c9a00ede3cd5bf38446f896156e3
(cherry picked from commit d2735ddb0666381bfbc5fa5f8d4b2157cceeabbb)

---------------------------------------------------------------------
squashed with another change that did not mock time.sleep
---------------------------------------------------------------------

hyper-v: mock time.sleep in test_rmtree

Added in change I8c194320dfa0c9a00ede3cd5bf38446f896156e3, test_rmtree
always takes at least one second because time.sleep(1) is not mocked
out. It's a bit of a nit but we should always mock out sleep calls so
the tests run as fast as possible - which matters when you have over 13K
of them.

(cherry picked from commit ec5879d3aa85f305f2ed91d26f0529e283586c89)
Closes-Bug: #1486203

Change-Id: I9148849574b05e4168876478af5173028b42074c
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/223290/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/tests/unit/virt/hyperv/test_pathutils.py']",2,1f74d34e55bfcd71dab5bebbfe7948cf5c09bfa3,bug/1467409," @mock.patch('time.sleep') @mock.patch('shutil.rmtree') def test_rmtree(self, mock_rmtree, mock_sleep): class WindowsError(Exception): def __init__(self, winerror=None): self.winerror = winerror mock_rmtree.side_effect = [WindowsError( pathutils.ERROR_DIR_IS_NOT_EMPTY), True] fake_windows_error = WindowsError with mock.patch('__builtin__.WindowsError', fake_windows_error, create=True): self._pathutils.rmtree(mock.sentinel.FAKE_PATH) mock_rmtree.assert_has_calls([mock.call(mock.sentinel.FAKE_PATH), mock.call(mock.sentinel.FAKE_PATH)]) mock_sleep.assert_called_once_with(1) ",,31,1
openstack%2Fhorizon~stable%2Fkilo~I0ab6bd8c90de4c4646e2f01abbd036c0281246e9,openstack/horizon,stable/kilo,I0ab6bd8c90de4c4646e2f01abbd036c0281246e9,Update project list in the header bar.,ABANDONED,2016-03-02 17:50:57.000000000,2016-05-06 12:57:18.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5623}, {'_account_id': 12355}, {'_account_id': 13176}, {'_account_id': 14151}, {'_account_id': 16047}]","[{'number': 1, 'created': '2016-03-02 17:50:57.000000000', 'files': ['openstack_dashboard/dashboards/identity/projects/tables.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1a79bf8d11b4785641f0014eefbeee10671ccb96', 'message': 'Update project list in the header bar.\n\nAfter create new projects, in the header bar,\nshow only active projects.\n\nChange-Id: I0ab6bd8c90de4c4646e2f01abbd036c0281246e9\nCloses-Bug: #1456266\n(cherry picked from commit 9264c72caa9bd48f9413b5b1dcc042324a9a96b2)\n'}]",0,287348,1a79bf8d11b4785641f0014eefbeee10671ccb96,8,7,1,6589,,,0,"Update project list in the header bar.

After create new projects, in the header bar,
show only active projects.

Change-Id: I0ab6bd8c90de4c4646e2f01abbd036c0281246e9
Closes-Bug: #1456266
(cherry picked from commit 9264c72caa9bd48f9413b5b1dcc042324a9a96b2)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/48/287348/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/projects/tables.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py']",2,1a79bf8d11b4785641f0014eefbeee10671ccb96,bug/1456266, auth_utils.remove_project_cache(request.user.token.unscoped_token) auth_utils.remove_project_cache(request.user.token.unscoped_token), auth_utils.remove_project_cache(request.user.token.id) auth_utils.remove_project_cache(request.user.token.id),3,3
openstack%2Fhorizon~stable%2Fkilo~I000887b34c6d28a998f3c1f22fc441cba840e780,openstack/horizon,stable/kilo,I000887b34c6d28a998f3c1f22fc441cba840e780,Modified the code for kilo version.,ABANDONED,2015-11-10 19:56:38.000000000,2016-05-06 12:56:44.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5623}, {'_account_id': 6637}, {'_account_id': 6763}, {'_account_id': 12281}, {'_account_id': 16707}, {'_account_id': 16769}, {'_account_id': 18465}]","[{'number': 1, 'created': '2015-11-10 19:56:38.000000000', 'files': ['horizon/static/horizon/js/horizon.modals.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/104adcb39991125f44bc4df2a75c1e59a7ab04a7', 'message': 'Modified the code for kilo version.\n\nStyle was inconsistence between last step and other steps of workflow\nThe following were the inconsistencies:\n1) For required field, An error message was displayed beyond field\n2) error message was not marked in red\n\nCloses-bug: #1511231\n\n(cherry picked from commit 6977239374e9c3f18cfc241e54589dc142dfe4d3)\n\nChange-Id: I000887b34c6d28a998f3c1f22fc441cba840e780\n'}]",0,243803,104adcb39991125f44bc4df2a75c1e59a7ab04a7,13,9,1,18857,,,0,"Modified the code for kilo version.

Style was inconsistence between last step and other steps of workflow
The following were the inconsistencies:
1) For required field, An error message was displayed beyond field
2) error message was not marked in red

Closes-bug: #1511231

(cherry picked from commit 6977239374e9c3f18cfc241e54589dc142dfe4d3)

Change-Id: I000887b34c6d28a998f3c1f22fc441cba840e780
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/243803/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.modals.js'],1,104adcb39991125f44bc4df2a75c1e59a7ab04a7,," $form.find('div.row div.alert-danger').remove(); $form.find('.form-group.has-error').each(function () { $group.removeClass('has-error'); $group.find('span.help-block.alert').remove(); $fieldset.find('div.row').prepend( $field.closest('.form-group').addClass('has-error'); $.each(errors, function (index, error) { $field.after( '<span class=""help-block alert alert-danger"">' +"," $form.find('td.actions div.alert-danger').remove(); $form.find('.form-group.error').each(function () { $group.removeClass('error'); $group.find('span.help-block.error').remove(); $fieldset.find('td.actions').prepend( $field.closest('.form-group').addClass('error'); $.each(errors, function (index, error) { $field.before( '<span class=""help-block error"">' +",8,8
openstack%2Fhorizon~stable%2Fkilo~I6b2c554350399f97f639e4c1e8d1ac8a34c9d046,openstack/horizon,stable/kilo,I6b2c554350399f97f639e4c1e8d1ac8a34c9d046,Fix UTF-8 handling in tables,ABANDONED,2015-09-24 06:44:00.000000000,2016-05-06 12:54:40.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 14131}, {'_account_id': 17172}]","[{'number': 1, 'created': '2015-09-24 06:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f6835dbc9d18439570478b962f6eae28c27c25ec', 'message': 'Fix UTF-8 handling in tables\n\nPrevious fix was not complete.\n\nAltered the transform for sequence comparison to use str\ninstead of repr for greater py2/py3 compatibility in the\nface of unicode.\n\nCloses-Bug: #1488443\nRelated-Bug: #1464461\nCo-Authored-By: Richard Jones <r1chardj0n3s@gmail.com>\nChange-Id: I6b2c554350399f97f639e4c1e8d1ac8a34c9d046\n(cherry picked from commit 6a8361de947dfb4a941336a14a5275640835780a)\n'}, {'number': 2, 'created': '2015-09-24 07:38:05.000000000', 'files': ['horizon/tables/actions.py', 'horizon/test/tests/tables.py', 'horizon/test/tests/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0b873d69ef4b55c065898df25d0521c77a432fe4', 'message': 'Fix UTF-8 handling in tables\n\nPrevious fix was not complete.\n\nAltered the transform for sequence comparison to use str\ninstead of repr for greater py2/py3 compatibility in the\nface of unicode.\n\nCloses-Bug: #1488443\nRelated-Bug: #1464461\nCo-Authored-By: Richard Jones <r1chardj0n3s@gmail.com>\nChange-Id: I6b2c554350399f97f639e4c1e8d1ac8a34c9d046\n(cherry picked from commit 6a8361de947dfb4a941336a14a5275640835780a)\n'}]",3,227143,0b873d69ef4b55c065898df25d0521c77a432fe4,14,6,2,4264,,,0,"Fix UTF-8 handling in tables

Previous fix was not complete.

Altered the transform for sequence comparison to use str
instead of repr for greater py2/py3 compatibility in the
face of unicode.

Closes-Bug: #1488443
Related-Bug: #1464461
Co-Authored-By: Richard Jones <r1chardj0n3s@gmail.com>
Change-Id: I6b2c554350399f97f639e4c1e8d1ac8a34c9d046
(cherry picked from commit 6a8361de947dfb4a941336a14a5275640835780a)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/227143/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/tables/actions.py', 'horizon/test/tests/tables.py', 'horizon/test/tests/tabs.py']",3,f6835dbc9d18439570478b962f6eae28c27c25ec,bug/1488443,"# encoding=utf-8 #import six self.assertQuerysetEqual(table.data, ['FakeObject: object_1', 'FakeObject: object_2', 'FakeObject: object_3', u'FakeObject: bject_4'], transform=six.text_type) self.assertContains(res, ""Displaying 4 items"", 1)"," self.assertQuerysetEqual(table.data, ['<FakeObject: object_1>', '<FakeObject: object_2>', '<FakeObject: object_3>']) self.assertContains(res, ""Displaying 3 items"", 1)",82,24
openstack%2Ffuel-library~stable%2Fmitaka~I86fb5433d100d2ea675b259a963a0e84268fa095,openstack/fuel-library,stable/mitaka,I86fb5433d100d2ea675b259a963a0e84268fa095,"For OCF status, match mysqld by process id",ABANDONED,2016-05-05 06:16:25.000000000,2016-05-06 12:49:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 06:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01eada49e7bd2bfd264cdacf86772afb6ddbadfc', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well. Add a dummy_test to status check, which does\nselect 1.\n\nCo-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2016-05-05 07:08:22.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/08146707c0e333ae6dbb21985c77671bad31373a', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well. Add a dummy_test to status check, which does\nselect 1.\n\nFix mysqld process matching:\nMake ps -C mysqld to match the datadir and exclude\nwsrep_recover/wsrep-recover as well\n\nCo-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,312835,08146707c0e333ae6dbb21985c77671bad31373a,24,4,2,6926,,,0,"For OCF status, match mysqld by process id

When started and doing SST, pidfile is not created immediately.
Fix race conditions by making action status to search by
the pid as well. Add a dummy_test to status check, which does
select 1.

Fix mysqld process matching:
Make ps -C mysqld to match the datadir and exclude
wsrep_recover/wsrep-recover as well

Co-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
Closes-bug: #1574999

Change-Id: I86fb5433d100d2ea675b259a963a0e84268fa095
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/35/312835/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,01eada49e7bd2bfd264cdacf86772afb6ddbadfc,bug/1574999,"dummy_test(){ $MYSQL $MYSQL_OPTIONS_TEST -s -N -e ""select 1;"" > /dev/null } dummy_test if [ $? -eq 0 ]; then ocf_log info ""${LH} MySQL PID found and looks healthy"" break fi fi # Match a mysqld pid by the datadir, exclude position recovery pid=$(ps -C mysqld -o pid= -o args= | awk -v v=""${OCF_RESKEY_datadir}"" \ '/datadir='$v'/ { if ($1 ~ !/wsrep-recover/) print $1}') if [ ""${pid}"" ] ; then dummy_test if [ $? -eq 0 ]; then ocf_log info ""${LH} MySQL process ${pid} found and looks healthy"" return $OCF_SUCCESS fi"," ocf_log info ""${LH} MySQL PID found"" break",20,2
openstack%2Ffuel-library~stable%2Fmitaka~I55f487b1021e5971b60f34fa338b5fc87967495f,openstack/fuel-library,stable/mitaka,I55f487b1021e5971b60f34fa338b5fc87967495f,Ensure same node lists for possible masters search,ABANDONED,2016-05-05 08:21:24.000000000,2016-05-06 12:48:33.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 17730}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 08:21:24.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/caa0b83018a2b502f44bcf9839c7591246d76a98', 'message': ""Ensure same node lists for possible masters search\n\nThe 'crm_node --partition' returns nodes in different order\nfor different nodes. Ensure the same node lists to\nreach a consensus for the choosen master across all of the nodes\nin a partition.\n\nCloses-bug: #1578278\n\nChange-Id: I55f487b1021e5971b60f34fa338b5fc87967495f\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,312856,caa0b83018a2b502f44bcf9839c7591246d76a98,15,4,1,6926,,,0,"Ensure same node lists for possible masters search

The 'crm_node --partition' returns nodes in different order
for different nodes. Ensure the same node lists to
reach a consensus for the choosen master across all of the nodes
in a partition.

Closes-bug: #1578278

Change-Id: I55f487b1021e5971b60f34fa338b5fc87967495f
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/56/312856/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,caa0b83018a2b502f44bcf9839c7591246d76a98,bug/1578278," # Ensure the same nodes list to reach a consensus for the choosen master across all of the nodes NODES=$(printf -- '%s\n' ""${NODES}"" | sort -u)",,2,0
openstack%2Ffuel-main~stable%2Fmitaka~If614549621374cf4714f08152c914b85a448b534,openstack/fuel-main,stable/mitaka,If614549621374cf4714f08152c914b85a448b534,Always create /etc/fuel_build_id flag,MERGED,2016-05-05 14:30:05.000000000,2016-05-06 12:42:30.000000000,2016-05-06 12:38:55.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 10288}, {'_account_id': 12817}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 14:30:05.000000000', 'files': ['iso/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d66dab3291d492e90c2955575df6ba5f43075c5d', 'message': ""Always create /etc/fuel_build_id flag\n\nWe need always create /etc/fuel_build_id flag-file since\nit's used for preprovisioned master node detection. The absence\nof this file means that we are on clean CentOS and should use\nonline repos.\n\nChange-Id: If614549621374cf4714f08152c914b85a448b534\nCloses-bug: #1578548\n(cherry picked from commit 656137de077d3b4c68d34d795ca30d66dd3a5709)\n""}]",0,313000,d66dab3291d492e90c2955575df6ba5f43075c5d,13,6,1,12817,,,0,"Always create /etc/fuel_build_id flag

We need always create /etc/fuel_build_id flag-file since
it's used for preprovisioned master node detection. The absence
of this file means that we are on clean CentOS and should use
online repos.

Change-Id: If614549621374cf4714f08152c914b85a448b534
Closes-bug: #1578548
(cherry picked from commit 656137de077d3b4c68d34d795ca30d66dd3a5709)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/00/313000/1 && git format-patch -1 --stdout FETCH_HEAD,['iso/module.mk'],1,d66dab3291d492e90c2955575df6ba5f43075c5d,,,ifdef BUILD_IDendif,0,2
openstack%2Fcinder~master~I489193c18ae6603f0bc750c7b63e1dd0b4a71e28,openstack/cinder,master,I489193c18ae6603f0bc750c7b63e1dd0b4a71e28,Pass default executor to os-brick,MERGED,2016-05-04 18:31:59.000000000,2016-05-06 12:13:37.000000000,2016-05-05 01:53:41.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 12924}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 18827}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-05-04 18:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5d8d944b858308fc512b70fd07f936d9da161801', 'message': ""Pass default executor to os-brick\n\nos-brick uses processutils.execute in the current version by default. It\nwill priv_rootwrap.execute in the new version if nothing will be passed.\nSo we don't need to pass anything to os-brick explicitly.\n\nChange-Id: I489193c18ae6603f0bc750c7b63e1dd0b4a71e28\n""}, {'number': 2, 'created': '2016-05-04 18:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f914142d6b5a5a85dba859e68a5592b5a2f2e95', 'message': ""Pass default executor to os-brick\n\nos-brick uses processutils.execute in the current version by default. It\nwill priv_rootwrap.execute in the new version if nothing will be passed.\nSo we don't need to pass anything to os-brick explicitly.\n\nChange-Id: I489193c18ae6603f0bc750c7b63e1dd0b4a71e28\n""}, {'number': 3, 'created': '2016-05-04 18:49:37.000000000', 'files': ['cinder/tests/unit/test_utils.py', 'cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6425d9a323c452befd97039bd59a74e24f6d7653', 'message': ""Pass default executor to os-brick\n\nos-brick uses processutils.execute in the current version by default. It\nwill priv_rootwrap.execute in the new version if nothing will be passed.\nSo we don't need to pass anything to os-brick explicitly.\n\nChange-Id: I489193c18ae6603f0bc750c7b63e1dd0b4a71e28\n""}]",1,312681,6425d9a323c452befd97039bd59a74e24f6d7653,68,26,3,1736,,,0,"Pass default executor to os-brick

os-brick uses processutils.execute in the current version by default. It
will priv_rootwrap.execute in the new version if nothing will be passed.
So we don't need to pass anything to os-brick explicitly.

Change-Id: I489193c18ae6603f0bc750c7b63e1dd0b4a71e28
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/312681/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/utils.py'],1,5d8d944b858308fc512b70fd07f936d9da161801,default-os-brick-execute," execute=None,"," execute=processutils.execute,",1,1
openstack%2Fopenstack-ansible-galera_server~master~Iea8b002b57fa72230056656f42eaa75e84e9b5a6,openstack/openstack-ansible-galera_server,master,Iea8b002b57fa72230056656f42eaa75e84e9b5a6,Use the apt_package_pinning role,MERGED,2016-04-29 05:09:08.000000000,2016-05-06 12:11:59.000000000,2016-05-06 12:11:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-04-29 05:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/fc9a401d2371373653ad375e756415d90a755237', 'message': 'Use the apt_package_pinning role\n\nAdd the galera_apt_pinned_packages default variable which is passed to\nthe apt_package_pinning role, instead of a template within this role, to\npin the MariaDB repo.\n\nChange-Id: Iea8b002b57fa72230056656f42eaa75e84e9b5a6\n'}, {'number': 2, 'created': '2016-05-06 02:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/f7f228b317a790b066cb4dbcdfb6aca5ccb29748', 'message': 'Use the apt_package_pinning role\n\nAdd the galera_apt_pinned_packages default variable which is passed to\nthe apt_package_pinning role, instead of a template within this role, to\npin the MariaDB repo.\n\nA new task has been added so that the pin created by this role will be\nremoved during upgrades from the previous release.\n\nChange-Id: Iea8b002b57fa72230056656f42eaa75e84e9b5a6\n'}, {'number': 3, 'created': '2016-05-06 02:08:30.000000000', 'files': ['tasks/galera_pre_install.yml', 'templates/galera_pin.pref.j2', 'defaults/main.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/090240e9e7b4872255686b9cfa86ab26b494cb84', 'message': 'Use the apt_package_pinning role\n\nAdd the galera_apt_pinned_packages default variable which is passed to\nthe apt_package_pinning role, instead of a template within this role, to\npin the MariaDB repo.\n\nChange-Id: Iea8b002b57fa72230056656f42eaa75e84e9b5a6\n'}]",4,311021,090240e9e7b4872255686b9cfa86ab26b494cb84,17,5,3,14805,,,0,"Use the apt_package_pinning role

Add the galera_apt_pinned_packages default variable which is passed to
the apt_package_pinning role, instead of a template within this role, to
pin the MariaDB repo.

Change-Id: Iea8b002b57fa72230056656f42eaa75e84e9b5a6
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/21/311021/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_pre_install.yml', 'templates/galera_pin.pref.j2', 'defaults/main.yml', 'meta/main.yml']",4,fc9a401d2371373653ad375e756415d90a755237,use_apt_package_pinning," apt_pinned_packages: ""{{ galera_apt_pinned_packages }}""",,3,15
openstack%2Fnova~master~Ief0a45142989f6ca60bb6b6c643cdbd631f038ef,openstack/nova,master,Ief0a45142989f6ca60bb6b6c643cdbd631f038ef,Make DEFAULT of list_opts() use v2.1 API code,ABANDONED,2016-05-06 00:03:49.000000000,2016-05-06 11:47:11.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-06 00:03:49.000000000', 'files': ['nova/api/opts.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/af1938e034819660a014d82ec490c286c0b6297a', 'message': 'Make DEFAULT of list_opts() use v2.1 API code\n\nThe list_opts() used legacy v2 API code, and that blocked to remove\nthe legacy code.\nThis patch makes DEFAULT of list_opts() use v2.1 API code instead.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Ief0a45142989f6ca60bb6b6c643cdbd631f038ef\n'}]",2,313191,af1938e034819660a014d82ec490c286c0b6297a,12,10,1,6167,,,0,"Make DEFAULT of list_opts() use v2.1 API code

The list_opts() used legacy v2 API code, and that blocked to remove
the legacy code.
This patch makes DEFAULT of list_opts() use v2.1 API code instead.

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: Ief0a45142989f6ca60bb6b6c643cdbd631f038ef
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/313191/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/opts.py'],1,af1938e034819660a014d82ec490c286c0b6297a,bp/remove-legacy-v2-api-code," ('DEFAULT', nova.api.openstack.api_opts),","import itertools import nova.api.auth import nova.api.metadata.base import nova.api.metadata.handler import nova.api.metadata.vendordata_jsonimport nova.api.openstack.common import nova.api.openstack.compute import nova.api.openstack.compute.hide_server_addresses import nova.api.openstack.compute.legacy_v2.contrib import nova.api.openstack.compute.legacy_v2.contrib.fping import nova.api.openstack.compute.legacy_v2.contrib.os_tenant_networks import nova.api.openstack.compute.legacy_v2.extensions import nova.api.openstack.compute.legacy_v2.servers ('DEFAULT', itertools.chain( [nova.api.metadata.vendordata_json.file_opt], [nova.api.openstack.compute.allow_instance_snapshots_opt], nova.api.auth.auth_opts, nova.api.metadata.base.metadata_opts, nova.api.metadata.handler.metadata_opts, nova.api.openstack.common.osapi_opts, nova.api.openstack.compute.legacy_v2.contrib.ext_opts, nova.api.openstack.compute.legacy_v2.contrib.fping.fping_opts, nova.api.openstack.compute.legacy_v2.contrib.os_tenant_networks. os_network_opts, nova.api.openstack.compute.legacy_v2.extensions.ext_opts, nova.api.openstack.compute.hide_server_addresses.opts, nova.api.openstack.compute.legacy_v2.servers.server_opts, )),",1,30
openstack%2Ffuel-mirror~master~Ib48a9f7134727ffe1219bd4f5c62b3f5fcd67115,openstack/fuel-mirror,master,Ib48a9f7134727ffe1219bd4f5c62b3f5fcd67115,[builder] Add separate build target for CentOS 7.1,MERGED,2016-04-20 12:38:56.000000000,2016-05-06 11:20:30.000000000,2016-04-22 12:51:23.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 18455}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-20 12:38:56.000000000', 'files': ['perestroika/docker-builder/mockbuild/centos71.conf'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/b347aca0d4e3a7cdf5d24fb2fc5f71fb41c20785', 'message': '[builder] Add separate build target for CentOS 7.1\n\n   Need to split out CentOS 7.1 and CentOS 7 rolling releases\n\nChange-Id: Ib48a9f7134727ffe1219bd4f5c62b3f5fcd67115\nPartial-Bug: #1572538\n'}]",0,308304,b347aca0d4e3a7cdf5d24fb2fc5f71fb41c20785,20,6,1,9582,,,0,"[builder] Add separate build target for CentOS 7.1

   Need to split out CentOS 7.1 and CentOS 7 rolling releases

Change-Id: Ib48a9f7134727ffe1219bd4f5c62b3f5fcd67115
Partial-Bug: #1572538
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/04/308304/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/docker-builder/mockbuild/centos71.conf'],1,b347aca0d4e3a7cdf5d24fb2fc5f71fb41c20785,bug/1572538,"CONFIG_CONTENT="" config_opts['plugin_conf']['tmpfs_enable'] = True config_opts['plugin_conf']['tmpfs_opts'] = {} config_opts['plugin_conf']['tmpfs_opts']['required_ram_mb'] = 2048 config_opts['plugin_conf']['tmpfs_opts']['max_fs_size'] = '25g' config_opts['plugin_conf']['tmpfs_opts']['mode'] = '0755' config_opts['plugin_conf']['tmpfs_opts']['keep_mounted'] = False config_opts['root'] = 'epel-71-x86_64' config_opts['target_arch'] = 'x86_64' config_opts['legal_host_arches'] = ('x86_64',) config_opts['chroot_setup_cmd'] = 'install @buildsys-build' config_opts['dist'] = 'el7' # only useful for --resultdir variable subst config_opts['macros']['%dist'] = '.el7' config_opts['releasever'] = '7' config_opts['yum.conf'] = \""\""\"" [main] keepcache=1 debuglevel=2 reposdir=/dev/null logfile=/var/log/yum.log retries=20 obsoletes=1 gpgcheck=0 assumeyes=1 syslog_ident=mock syslog_device= # repos [base] name=BaseOS baseurl=http://vault.centos.org/7.1.1503/os/x86_64/ failovermethod=priority gpgkey=file:///etc/pki/mock/RPM-GPG-KEY-CentOS-7 gpgcheck=1 [updates] name=updates enabled=1 baseurl=http://vault.centos.org/7.1.1503/updates/x86_64/ failovermethod=priority gpgkey=file:///etc/pki/mock/RPM-GPG-KEY-CentOS-7 gpgcheck=1 [extras] name=extras baseurl=http://vault.centos.org/7.1.1503/extras/x86_64/ failovermethod=priority gpgkey=file:///etc/pki/mock/RPM-GPG-KEY-EPEL-7 gpgcheck=1 [epel] name=epel baseurl=http://mirror.yandex.ru/epel/7/x86_64/ failovermethod=priority gpgkey=file:///etc/pki/mock/RPM-GPG-KEY-EPEL-7 gpgcheck=1 \""\""\"" "" ",,60,0
openstack%2Ffuel-mirror~master~I1df54e3e6b475617ad069dd5af8454e7bd4db0a1,openstack/fuel-mirror,master,I1df54e3e6b475617ad069dd5af8454e7bd4db0a1,convert-version.py modified for import as module,MERGED,2015-12-22 12:37:38.000000000,2016-05-06 11:14:00.000000000,2016-01-14 11:39:14.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6631}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 10391}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 18205}]","[{'number': 1, 'created': '2015-12-22 12:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/a5649e7e6bbd4b83fed87a640ffa335e00bbf049', 'message': 'convert_version.py modified for import as module\n\nChange-Id: I1df54e3e6b475617ad069dd5af8454e7bd4db0a1\n'}, {'number': 2, 'created': '2015-12-22 13:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/cd9c6022632e70361d4180e05e0ca039bb2efd3a', 'message': 'convert_version.py modified for import as module\n\nRefactoring. Logic extracted as independent function that give\na possibility to use this module independently of perestroika.\n\nChange-Id: I1df54e3e6b475617ad069dd5af8454e7bd4db0a1\n'}, {'number': 3, 'created': '2016-01-13 09:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/7936965d8a640b2a99f2a879756888b648bd43fa', 'message': 'convert_version.py modified for import as module\n\nRefactoring. Logic extracted as independent function that give\na possibility to use this module independently of perestroika.\n\nChange-Id: I1df54e3e6b475617ad069dd5af8454e7bd4db0a1\n'}, {'number': 4, 'created': '2016-01-14 09:26:57.000000000', 'files': ['perestroika/convert-version.py'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/e334e04cd5d124d9713e445841749aa6c66bcaf5', 'message': 'convert-version.py modified for import as module\n\nRefactoring. Logic extracted as independent function that give\na possibility to use this module independently of perestroika.\n\nChange-Id: I1df54e3e6b475617ad069dd5af8454e7bd4db0a1\n'}]",8,260473,e334e04cd5d124d9713e445841749aa6c66bcaf5,25,9,4,6631,,,0,"convert-version.py modified for import as module

Refactoring. Logic extracted as independent function that give
a possibility to use this module independently of perestroika.

Change-Id: I1df54e3e6b475617ad069dd5af8454e7bd4db0a1
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/73/260473/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/convert-version.py'],1,a5649e7e6bbd4b83fed87a640ffa335e00bbf049,, print convert_version(pip_ver) def convert_version(pip_ver): return ('.'.join(pkg_ver_part) + pkg_alpha + '.'.join(pkg_rev_part)) , print('.'.join(pkg_ver_part) + pkg_alpha + '.'.join(pkg_rev_part)),7,1
openstack%2Ftripleo-quickstart~master~I64acaceb0b9d1df79890d27225541ab9b6cf0c0b,openstack/tripleo-quickstart,master,I64acaceb0b9d1df79890d27225541ab9b6cf0c0b,fix white space in quickstart.sh,ABANDONED,2016-05-05 20:58:12.000000000,2016-05-06 11:12:43.000000000,,"[{'_account_id': 3}, {'_account_id': 18846}, {'_account_id': 21522}]","[{'number': 1, 'created': '2016-05-05 20:58:12.000000000', 'files': ['quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c2c18974a7e6fef27ab49ce0456a723a9da3c530', 'message': 'fix white space in quickstart.sh\n\nChange-Id: I64acaceb0b9d1df79890d27225541ab9b6cf0c0b\n'}]",0,313156,c2c18974a7e6fef27ab49ce0456a723a9da3c530,6,3,1,9592,,,0,"fix white space in quickstart.sh

Change-Id: I64acaceb0b9d1df79890d27225541ab9b6cf0c0b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/56/313156/1 && git format-patch -1 --stdout FETCH_HEAD,['quickstart.sh'],1,c2c18974a7e6fef27ab49ce0456a723a9da3c530,whitespace,, ,1,1
openstack%2Fnova~master~Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b,openstack/nova,master,Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b,Config options: centralize imagecache libvirt options (3),MERGED,2016-04-22 03:54:18.000000000,2016-05-06 11:12:07.000000000,2016-05-06 08:11:29.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19741}]","[{'number': 1, 'created': '2016-04-22 03:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24485d63b00e2f0975390dc2346b37f469e70f5c', 'message': 'Config options: centralize imagecache libvirt options (3)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the third patch in a long-chain patchs.\n\nChange-Id: Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 2, 'created': '2016-05-05 03:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a71df29f0fbd603d27bdcfc0b73c6793d5c62d88', 'message': 'Config options: centralize imagecache libvirt options (3)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the third patch in a long-chain patchs.\n\nChange-Id: Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 3, 'created': '2016-05-05 09:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d170e3d07b97db4acf0448e037c951edacfc8157', 'message': 'Config options: centralize imagecache libvirt options (3)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the third patch in a long-chain patchs.\n\nChange-Id: Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 4, 'created': '2016-05-05 11:21:48.000000000', 'files': ['nova/virt/libvirt/imagecache.py', 'nova/conf/libvirt.py', 'nova/virt/opts.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ad0ab6b968e9a6b98c21df141a0987f3d5b4774', 'message': 'Config options: centralize imagecache libvirt options (3)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the third patch in a long-chain patchs.\n\nChange-Id: Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}]",0,309255,1ad0ab6b968e9a6b98c21df141a0987f3d5b4774,62,16,4,19741,,,0,"Config options: centralize imagecache libvirt options (3)

The config options of the ""nova.conf"" section ""libvirt"" got
moved to the new central location ""nova/conf/libvirt.py"".
Subsequent patches will then move another options in libvirt section.
This is the third patch in a long-chain patchs.

Change-Id: Ie1e9b16ba3bb702ff5a8712a94fca0afdcbbd80b
Co-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>
Implements: blueprint centralize-config-options-newton
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/309255/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/imagecache.py', 'nova/conf/libvirt.py', 'nova/virt/opts.py']",3,24485d63b00e2f0975390dc2346b37f469e70f5c,bp/centralize-config-options-newton,,"import nova.virt.libvirt.imagecache nova.virt.libvirt.imagecache.imagecache_opts,",27,30
openstack%2Fkeystone~master~I0fc72cbd11d079b3d10db2f3154cafb86b43ed1d,openstack/keystone,master,I0fc72cbd11d079b3d10db2f3154cafb86b43ed1d,Enhance federation group mapping validation,ABANDONED,2016-05-06 11:06:19.000000000,2016-05-06 11:07:40.000000000,,[],"[{'number': 1, 'created': '2016-05-06 11:06:19.000000000', 'files': ['keystone/federation/utils.py', 'keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/contrib/federation/test_utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7c76cc873fcc683430b572c0cc081e1c92a15880', 'message': 'Enhance federation group mapping validation\n\nA group must be reffered either with an ID, or the name _and_ the\ndomain. Change the JSON validation schema to check this.\n\nChange-Id: I0fc72cbd11d079b3d10db2f3154cafb86b43ed1d\n'}]",0,313502,7c76cc873fcc683430b572c0cc081e1c92a15880,2,0,1,18940,,,0,"Enhance federation group mapping validation

A group must be reffered either with an ID, or the name _and_ the
domain. Change the JSON validation schema to check this.

Change-Id: I0fc72cbd11d079b3d10db2f3154cafb86b43ed1d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/02/313502/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/federation/utils.py', 'keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/contrib/federation/test_utils.py']",3,7c76cc873fcc683430b572c0cc081e1c92a15880,(detached," def test_mapping_validation_bad_domain(self): mapping = mapping_fixtures.MAPPING_BAD_DOMAIN self.assertRaises(exception.ValidationError, mapping_utils.validate_mapping_structure, mapping) def test_mapping_validation_bad_group(self): mapping = mapping_fixtures.MAPPING_BAD_GROUP self.assertRaises(exception.ValidationError, mapping_utils.validate_mapping_structure, mapping) def test_mapping_validation_with_group_id_and_domain(self): mapping = mapping_fixtures.MAPPING_GROUP_ID_WITH_DOMAIN self.assertRaises(exception.ValidationError, mapping_utils.validate_mapping_structure, mapping) ",from keystone.tests.unit import utils as test_utils @test_utils.wip('waiting for fix the validator ' 'to choke on group name without domain'),124,30
openstack%2Ffuel-mirror~master~Ib15f9bf33d04c2f22bdc3dcda010029a0ea99185,openstack/fuel-mirror,master,Ib15f9bf33d04c2f22bdc3dcda010029a0ea99185,[deb][publish] Fix source replacement,MERGED,2016-04-01 08:48:47.000000000,2016-05-06 11:04:27.000000000,2016-04-08 11:27:10.000000000,"[{'_account_id': 3}, {'_account_id': 7613}, {'_account_id': 8777}, {'_account_id': 8971}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 14348}, {'_account_id': 19921}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-01 08:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/2626ccb070c77730003e86c6f9ba059d83b914c2', 'message': '[deb][publish] Fix source replacement\n\n   Remove existing source from all suites instead of specified one\n\nChange-Id: Ib15f9bf33d04c2f22bdc3dcda010029a0ea99185\n'}, {'number': 2, 'created': '2016-04-08 11:09:42.000000000', 'files': ['perestroika/publisher.v5/publish-deb-binaries.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/d8ba2492e2427abd82dca6e7e7c5bcdde9b09a89', 'message': '[deb][publish] Fix source replacement\n\n   Remove existing source from all suites instead of specified one\n\nCloses-Bug: #1567454\n\nChange-Id: Ib15f9bf33d04c2f22bdc3dcda010029a0ea99185\n'}]",4,300364,d8ba2492e2427abd82dca6e7e7c5bcdde9b09a89,26,9,2,9582,,,0,"[deb][publish] Fix source replacement

   Remove existing source from all suites instead of specified one

Closes-Bug: #1567454

Change-Id: Ib15f9bf33d04c2f22bdc3dcda010029a0ea99185
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/64/300364/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/publisher.v5/publish-deb-binaries.sh'],1,2626ccb070c77730003e86c6f9ba059d83b914c2,300364, for dist_name in ${DEB_BASE_DIST_NAME} ${DEB_PROPOSED_DIST_NAME} \ ${DEB_UPDATES_DIST_NAME} ${DEB_SECURITY_DIST_NAME} \ ${DEB_HOLDBACK_DIST_NAME} ; do reprepro ${REPREPRO_COMP_OPTS} --architecture source \ remove ${dist_name} ${SRC_NAME} || : done, reprepro ${REPREPRO_COMP_OPTS} --architecture source \ remove ${DEB_DIST_NAME} ${SRC_NAME} || :,6,2
openstack%2Fopenstack-ansible~master~I2b1582812e638e2b3b455b7c34b93d13e08a168a,openstack/openstack-ansible,master,I2b1582812e638e2b3b455b7c34b93d13e08a168a,DOCS: Configuration section - cleanup,MERGED,2016-05-05 03:35:41.000000000,2016-05-06 10:48:57.000000000,2016-05-06 10:48:57.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 8246}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 14805}, {'_account_id': 18784}]","[{'number': 1, 'created': '2016-05-05 03:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/84db06bf38bf82a54a2d2c076f093b99588a9c55', 'message': '[WIP] DOCS: Configuration section - cleanup\n\nAs per discussion in the OSA docs summit session, clean up\nof installation guide. This fixes typos, minor RST mark up\nchanges, and passive voice.\n\nThis patch also merges a some of sections into the larger\nchapter. This is in an effort to remove multiple smaller\nfiles.\n\nChange-Id: I2b1582812e638e2b3b455b7c34b93d13e08a168a\n'}, {'number': 2, 'created': '2016-05-06 01:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5191746a126bcc7bc58b08fa6cd73bc5865b3395', 'message': 'DOCS: Configuration section - cleanup\n\nAs per discussion in the OSA docs summit session, clean up\nof installation guide. This fixes typos, minor RST mark up\nchanges, and passive voice.\n\nThis patch also merges a some of the sections into the larger\nchapter. This is in an effort to remove multiple smaller\nfiles.\n\nThis patch is the first of many to avoid major conflicts.\n\nChange-Id: I2b1582812e638e2b3b455b7c34b93d13e08a168a\n'}, {'number': 3, 'created': '2016-05-06 01:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ce459b981b0272701ba9009c8ba7c7674ebc0fd2', 'message': 'DOCS: Configuration section - cleanup\n\nAs per discussion in the OSA docs summit session, clean up\nof installation guide. This fixes typos, minor RST mark up\nchanges, and passive voice.\n\nThis patch also merges a some of the sections into the larger\nchapter. This is in an effort to remove multiple smaller\nfiles.\n\nThis patch is the first of many to avoid major conflicts.\n\nChange-Id: I2b1582812e638e2b3b455b7c34b93d13e08a168a\n'}, {'number': 4, 'created': '2016-05-06 05:20:10.000000000', 'files': ['doc/source/install-guide/configure-hostlist.rst', 'doc/source/install-guide/configure-hypervisor.rst', 'doc/source/install-guide/configure-ironic-nodes.rst', 'doc/source/install-guide/configure-ironic-images.rst', 'doc/source/install-guide/configure-cinder-az.rst', 'doc/source/install-guide/configure-ironic-deployment.rst', 'doc/source/install-guide/configure-ironic-neutron.rst', 'doc/source/install-guide/configure-cinder.rst', 'doc/source/install-guide/configure-ironic.rst', 'doc/source/install-guide/configure-creds.rst', 'doc/source/install-guide/configure-cinder-horizon.rst', 'doc/source/install-guide/configure-ironic-baremetal-node.rst', 'doc/source/install-guide/configure-ironic-flavor.rst', 'doc/source/install-guide/configure-cinder-nfs.rst', 'doc/source/install-guide/configure-initial.rst', 'doc/source/install-guide/configure-networking.rst', 'doc/source/install-guide/configure-nova.rst', 'doc/source/install-guide/configure-cinder-backup.rst', 'doc/source/install-guide/configure-glance.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/55155f301e13e5c0867ba4a42fc714dfdc6f72f2', 'message': 'DOCS: Configuration section - cleanup\n\nAs per discussion in the OSA docs summit session, clean up\nof installation guide. This fixes typos, minor RST mark up\nchanges, and passive voice.\n\nThis patch also merges a some of the sections into the larger\nchapter. This is in an effort to remove multiple smaller\nfiles.\n\nThis patch is the first of many to avoid major conflicts.\n\nChange-Id: I2b1582812e638e2b3b455b7c34b93d13e08a168a\n'}]",88,312815,55155f301e13e5c0867ba4a42fc714dfdc6f72f2,22,8,4,10607,,,0,"DOCS: Configuration section - cleanup

As per discussion in the OSA docs summit session, clean up
of installation guide. This fixes typos, minor RST mark up
changes, and passive voice.

This patch also merges a some of the sections into the larger
chapter. This is in an effort to remove multiple smaller
files.

This patch is the first of many to avoid major conflicts.

Change-Id: I2b1582812e638e2b3b455b7c34b93d13e08a168a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/15/312815/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install-guide/configure-hostlist.rst', 'doc/source/install-guide/configure-hypervisor.rst', 'doc/source/install-guide/configure-ironic-nodes.rst', 'doc/source/install-guide/configure-ironic-images.rst', 'doc/source/install-guide/configure-cinder-az.rst', 'doc/source/install-guide/configure-ironic-deployment.rst', 'doc/source/install-guide/configure-ironic-neutron.rst', 'doc/source/install-guide/configure-cinder.rst', 'doc/source/install-guide/configure-ironic.rst', 'doc/source/install-guide/configure-creds.rst', 'doc/source/install-guide/configure-cinder-horizon.rst', 'doc/source/install-guide/configure-ironic-baremetal-node.rst', 'doc/source/install-guide/configure-ironic-flavor.rst', 'doc/source/install-guide/configure-cinder-nfs.rst', 'doc/source/install-guide/configure-initial.rst', 'doc/source/install-guide/configure-networking.rst', 'doc/source/install-guide/configure-nova.rst', 'doc/source/install-guide/configure-cinder-backup.rst', 'doc/source/install-guide/configure-glance.rst']",19,84db06bf38bf82a54a2d2c076f093b99588a9c55,asettle/OSAdocs,"Configuring the Image (glance) Service ======================================(glance) Service uses the local file system on the target host to store images. When deploying production clouds, we recommend backing glance with aOpenStack-Ansible provides two configurations for controlling where glance stores files: the default store and additional stores. glance stores images in file-based storage by default. Two additional stores, ``http`` and ``cinder`` (Block Storage), are also enabled by default. You can choose alternative default stores and alternative additional stores.The configuration above configures glance to use ``rbd`` (Ceph) by default, but the swift enables ``http`` and ``cinder`` stores in the glance configuration files.This example uses cephx authentication and requires an existing ``glance``In ``user_variables.yml``:#. Set the swift account credentials: used for storing images. If the container does not exist, it is By default, glance uses caching and authenticates with the Identity (keystone) service. The default maximum size of the image cache is 10GB. The default glance container size is 12GB. In some configurations, glance attempts to cache an image``super$ecure`` would need to be entered as ``super$$ecure``. This is necessary","Configuring the Image Service -----------------------------Service uses the local file system on the target host to store images. When deploying production clouds we recommend backing Glance with aOpenStack-Ansible provides two configurations for controlling where the Image Service stores files: the default store and additional stores. As mentioned in the previous section, the Image Service stores images in file-based storage by default. Two additional stores, http and cinder, are also enabled by default. Deployers can choose alternative default stores, as shown in the swift example in the next section, and deployers can choose alternative additional stores.The configuration above will configure the Image Service to use rbd (Ceph) by default, but the swift, http and cinder stores will also be enabled in the Image Service configuration files. The example uses cephx authentication and requires an existing ``glance``in ``user_variables.yml``#. Set the swift account credentials (see *Special Considerations* at the bottom of this page): used for storing images. If the container doesn't exist, it will be By default, the Image Service uses caching and authenticates with the Identity service. The default maximum size of the image cache is 10 GB. The default Image Service container size is 12 GB. In some configurations, the Image Service might attempt to cache an image``super$ecure`` would need to be entered as ``super$$ecure``. This is needed",532,569
openstack%2Ffuel-mirror~stable%2F8.0~I02c308f8f79c12c6918a289eeb7d7d546b2366c2,openstack/fuel-mirror,stable/8.0,I02c308f8f79c12c6918a289eeb7d7d546b2366c2,[build] Remove gitSHA suffix from CR packages,MERGED,2016-05-06 10:05:57.000000000,2016-05-06 10:40:40.000000000,2016-05-06 10:37:33.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-06 10:05:57.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/60d1a212d09e42a6b06aefb4a519cb3af6e4db71', 'message': '[build] Remove gitSHA suffix from CR packages\n\n  - Remove gitSHA suffixes from revision part of verison strings of\n    openstack packages\n\n  - Do not increment revision for CR at specs projects\n\nChange-Id: I02c308f8f79c12c6918a289eeb7d7d546b2366c2\nCloses-Bug: #1533259\n(cherry picked from commit 02c439bc64c5ddbd80f7291691c6f2863aaca9f6)\n'}]",0,313305,60d1a212d09e42a6b06aefb4a519cb3af6e4db71,14,6,1,12817,,,0,"[build] Remove gitSHA suffix from CR packages

  - Remove gitSHA suffixes from revision part of verison strings of
    openstack packages

  - Do not increment revision for CR at specs projects

Change-Id: I02c308f8f79c12c6918a289eeb7d7d546b2366c2
Closes-Bug: #1533259
(cherry picked from commit 02c439bc64c5ddbd80f7291691c6f2863aaca9f6)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/05/313305/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,60d1a212d09e42a6b06aefb4a519cb3af6e4db71,bug/1575171," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] \ && [ ${GERRIT_PROJECT} == ""${SRC_PROJECT}"" ] \ && _rev=$(( $_rev + 1 ))"," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && _rev=$(( $_rev + 1 )) [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && release=""${release}.git.${gitshasrc}.${gitshaspec}""",6,4
openstack%2Ffuel-mirror~stable%2F8.0~I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22,openstack/fuel-mirror,stable/8.0,I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22,Expand the ignore cases,MERGED,2016-05-06 10:06:05.000000000,2016-05-06 10:37:14.000000000,2016-05-06 10:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-06 10:06:05.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/c70cd40a089305d1fa1e1c780767f738ec41472e', 'message': 'Expand the ignore cases\n\n * perestroika/build-deb.sh & perestroika/build-rpm.sh\n   - Add variable ""ignore_list"" and use it for\n     expand the ignore cases\n * Add horizon-vendor-theme to ignores\n\nChange-Id: I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22\n(cherry picked from commit 786564b9f628f4c70cbef08953a54427dc7598a1)\n'}]",0,313306,c70cd40a089305d1fa1e1c780767f738ec41472e,14,6,1,12817,,,0,"Expand the ignore cases

 * perestroika/build-deb.sh & perestroika/build-rpm.sh
   - Add variable ""ignore_list"" and use it for
     expand the ignore cases
 * Add horizon-vendor-theme to ignores

Change-Id: I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22
(cherry picked from commit 786564b9f628f4c70cbef08953a54427dc7598a1)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/06/313306/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,c70cd40a089305d1fa1e1c780767f738ec41472e,bug/1575171," local ignore_list=""openstack-macros horizon-vendor-theme"" if [ $(echo $ignore_list | grep -Eo ""(^| )$PACKAGENAME( |$)"") ]; then"," if [ ""$PACKAGENAME"" == ""openstack-macros"" ]; then",4,2
openstack%2Fopenstack-ansible~master~I6e187ab5d88f1387876012d4f40f96205cc7a6ee,openstack/openstack-ansible,master,I6e187ab5d88f1387876012d4f40f96205cc7a6ee,Doc: Configuring the network refactor,MERGED,2016-05-04 10:03:49.000000000,2016-05-06 10:34:01.000000000,2016-05-06 10:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 10607}, {'_account_id': 12402}, {'_account_id': 15993}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-05-04 10:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/deed5aeb05726ebfa693d2bfb1336ded93c23839', 'message': 'Doc: Configuring the network refactor\n\nFor better understanding and avoiding inconsistencies, this commit\nremoves focuses on a consistent network configuration explanation,\nwith 2 paths for the deployer:\n\n- The reference ""path""\n- The single host ""path""\n\nEach path is explained the same way, this way the deployers know how to\nfollow the path.\n\nCloses-bug: #1547598\n\nChange-Id: I6e187ab5d88f1387876012d4f40f96205cc7a6ee\nSigned-off-by: Jean-Philippe Evrard <jean-philippe@evrard.me>\n'}, {'number': 2, 'created': '2016-05-05 20:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d2e4eb15e6073fc6ac825670d79b8e59b023695c', 'message': 'Doc: Configuring the network refactor\n\nFor better understanding and avoiding inconsistencies, this commit\nremoves focuses on a consistent network configuration explanation,\nwith 2 paths for the deployer:\n\n- The reference ""path""\n- The single host ""path""\n\nEach path is explained the same way, this way the deployers know how to\nfollow the path.\n\nCloses-bug: #1547598\n\nChange-Id: I6e187ab5d88f1387876012d4f40f96205cc7a6ee\nSigned-off-by: Jean-Philippe Evrard <jean-philippe@evrard.me>\n'}, {'number': 3, 'created': '2016-05-06 01:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/04bce88439d5724d5bfcd595e322efd8e711797b', 'message': 'Doc: Configuring the network refactor\n\nFor better understanding and avoiding inconsistencies, this commit\nremoves focuses on a consistent network configuration explanation,\nwith 2 paths for the deployer:\n\n- The reference ""path""\n- The single host ""path""\n\nEach path is explained the same way, this way the deployers know how to\nfollow the path.\n\nCloses-bug: #1547598\n\nChange-Id: I6e187ab5d88f1387876012d4f40f96205cc7a6ee\nSigned-off-by: Jean-Philippe Evrard <jean-philippe@evrard.me>\n'}, {'number': 4, 'created': '2016-05-06 08:02:12.000000000', 'files': ['doc/source/install-guide/targethosts-networkconfig.rst', 'doc/source/install-guide/targethosts-networkrefarch.rst', 'doc/source/install-guide/targethosts.rst', 'doc/source/install-guide/targethosts-network.rst', 'doc/source/install-guide/targethosts-networkexample.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7e8d629108605930d6fdacebba07c03024012ce3', 'message': 'Doc: Configuring the network refactor\n\nFor better understanding and avoiding inconsistencies, this commit\nremoves focuses on a consistent network configuration explanation,\nwith 2 paths for the deployer:\n\n- The reference ""path""\n- The single host ""path""\n\nEach path is explained the same way, this way the deployers know how to\nfollow the path.\n\nCloses-bug: #1547598\n\nChange-Id: I6e187ab5d88f1387876012d4f40f96205cc7a6ee\nSigned-off-by: Jean-Philippe Evrard <jean-philippe@evrard.me>\n'}]",15,312421,7e8d629108605930d6fdacebba07c03024012ce3,21,6,4,17068,,,0,"Doc: Configuring the network refactor

For better understanding and avoiding inconsistencies, this commit
removes focuses on a consistent network configuration explanation,
with 2 paths for the deployer:

- The reference ""path""
- The single host ""path""

Each path is explained the same way, this way the deployers know how to
follow the path.

Closes-bug: #1547598

Change-Id: I6e187ab5d88f1387876012d4f40f96205cc7a6ee
Signed-off-by: Jean-Philippe Evrard <jean-philippe@evrard.me>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/21/312421/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install-guide/targethosts-networkconfig.rst', 'doc/source/install-guide/targethosts-networkrefarch.rst', 'doc/source/install-guide/targethosts.rst', 'doc/source/install-guide/targethosts-network.rst', 'doc/source/install-guide/targethosts-networkexample.rst']",5,deed5aeb05726ebfa693d2bfb1336ded93c23839,bug/1547598,========================================= Simple architecture: A single target host =========================================,=================================================================================== Configuring the network on a target host: Simple architecture: A single target host ===================================================================================,92,10
openstack%2Ffuel-library~stable%2F7.0~I3dd00453607509d53f3e5fe9ae9d1898d6f0b69d,openstack/fuel-library,stable/7.0,I3dd00453607509d53f3e5fe9ae9d1898d6f0b69d,Stop process when rabbit is running but is not connected to master.,ABANDONED,2016-05-04 10:19:10.000000000,2016-05-06 10:30:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 10489}, {'_account_id': 17730}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 10:19:10.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7ae5238bf65a599db520f4c298d096da45fca41b', 'message': ""Stop process when rabbit is running but is not connected to master.\n\nIt's should goes down due to avoid split brain.\n\nChange-Id: I3dd00453607509d53f3e5fe9ae9d1898d6f0b69d\nCloses-Bug: #1541471\nUpstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758\n""}]",0,312428,7ae5238bf65a599db520f4c298d096da45fca41b,15,6,1,17730,,,0,"Stop process when rabbit is running but is not connected to master.

It's should goes down due to avoid split brain.

Change-Id: I3dd00453607509d53f3e5fe9ae9d1898d6f0b69d
Closes-Bug: #1541471
Upstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/312428/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,7ae5238bf65a599db520f4c298d096da45fca41b,,"#!/bin/sh # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License.# Note that the script uses an external file to setup RabbitMQ policies # so make sure to create it from an example shipped with the package. #OCF_RESKEY_pid_file_default=""/var/run/rabbitmq/pid"" OCF_RESKEY_log_dir_default=""/var/log/rabbitmq"" OCF_RESKEY_mnesia_base_default=""/var/lib/rabbitmq/mnesia"" OCF_RESKEY_host_ip_default=""127.0.0.1""OCF_RESKEY_use_fqdn_default=false OCF_RESKEY_fqdn_prefix_default="""" OCF_RESKEY_max_rabbitmqctl_timeouts_default=3 OCF_RESKEY_policy_file_default=""/usr/local/sbin/set_rabbitmq_policy"": ${OCF_RESKEY_use_fqdn=${OCF_RESKEY_use_fqdn_default}} : ${OCF_RESKEY_fqdn_prefix=${OCF_RESKEY_fqdn_prefix_default}}: ${OCF_RESKEY_policy_file=${OCF_RESKEY_policy_file_default}}OCF_RESKEY_stop_time_default=${OCF_RESKEY_start_time_default} : ${OCF_RESKEY_stop_time=${OCF_RESKEY_start_time_default}} # The EXTENDED_OCF_PARAMS parameter below does not exist by default # and hence converted to an empty string unless overridden. It # could be used by an extention script to add new parameters. For # example see https://review.openstack.org/#/c/249180/10 <parameter name=""stop_time"" unique=""0"" required=""0""> <longdesc lang=""en""> Timeout for stopping rabbitmq server </longdesc> <shortdesc lang=""en"">Timeout for stopping rabbitmq server</shortdesc> <content type=""string"" default=""${OCF_RESKEY_stop_time_default}"" /> </parameter> <parameter name=""host_ip"" unique=""0"" required=""0""> <longdesc lang=""en""> ${OCF_RESKEY_binary} should listen on this IP address </longdesc> <shortdesc lang=""en"">${OCF_RESKEY_binary} should listen on this IP address</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_host_ip_default}"" /> </parameter> <parameter name=""use_fqdn"" unique=""0"" required=""0""> <longdesc lang=""en""> Either to use FQDN or a shortname for the rabbitmq node </longdesc> <shortdesc lang=""en"">Use FQDN</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_use_fqdn_default}"" /> </parameter> <parameter name=""fqdn_prefix"" unique=""0"" required=""0""> <longdesc lang=""en""> Optional FQDN prefix for RabbitMQ nodes in cluster. FQDN prefix can be specified to host multiple RabbitMQ instances on a node or in case of RabbitMQ running in dedicated network/interface. </longdesc> <shortdesc lang=""en"">FQDN prefix</shortdesc> <content type=""string"" default=""${OCF_RESKEY_fqdn_prefix_default}"" /> </parameter> <parameter name=""policy_file"" unique=""0"" required=""0""> <longdesc lang=""en""> A path to the shell script to setup RabbitMQ policies </longdesc> <shortdesc lang=""en"">A policy file path</shortdesc> <content type=""string"" default=""${OCF_RESKEY_policy_file_default}"" /> </parameter> $EXTENDED_OCF_PARAMS #TODO(bogdando) move proc_kill, proc_stop to shared OCF functions # to be shipped with HA cluster packages ########################################################### # Attempts to kill a process with retries and checks procfs # to make sure the process is stopped. # # Globals: # LL # Arguments: # $1 - pid of the process to try and kill # $2 - service name used for logging and match-based kill, if the pid is ""none"" # $3 - signal to use, defaults to SIGTERM # $4 - number of retries, defaults to 5 # $5 - time to sleep between retries, defaults to 2 # Returns: # 0 - if successful # 1 - if process is still running according to procfs # 2 - if invalid parameters passed in ########################################################### proc_kill() { local pid=""${1}"" local service_name=""${2}"" local signal=""${3:-SIGTERM}"" local count=""${4:-5}"" local process_sleep=""${5:-2}"" local LH=""${LL} proc_kill():"" local pgrp=""$(ps -o pgid= ${pid} 2>/dev/null | tr -d '[[:space:]]')"" if [ ""${pid}"" -a ""${pgrp}"" = ""1"" ] ; then ocf_log err ""${LH} shall not kill by the bad pid 1 (init)!"" return 2 fi if [ ""${pid}"" = ""none"" ]; then local matched matched=""$(pgrep -fla ${service_name})"" if [ -z ""${matched}"" ] ; then ocf_log err ""${LH} cannot find any processes matching the ${service_name}!"" return 2 fi ocf_log debug ""${LH} no pid provided, will try the ${service_name}, matched list: ${matched}"" while [ $count -gt 0 ]; do if [ -z ""${matched}"" ]; then break else matched=""$(pgrep -fla ${service_name})"" ocf_log debug ""${LH} Stopping ${service_name} with ${signal}..."" ocf_run pkill -f -""${signal}"" ""${service_name}"" fi sleep $process_sleep count=$(( count-1 )) done pgrep -f ""${service_name}"" > /dev/null if [ $? -ne 0 ] ; then ocf_log debug ""${LH} Stopped ${service_name} with ${signal}"" return 0 else ocf_log warn ""${LH} Failed to stop ${service_name} with ${signal}"" return 1 fi else # pid is not none while [ $count -gt 0 ]; do if [ ! -d ""/proc/${pid}"" ]; then break else ocf_log debug ""${LH} Stopping ${service_name} with ${signal}..."" ocf_run pkill -""${signal}"" -g ""${pgrp}"" fi sleep $process_sleep count=$(( count-1 )) done # Check if the process ended after the last sleep if [ ! -d ""/proc/${pid}"" ] ; then ocf_log debug ""${LH} Stopped ${service_name} with ${signal}"" return 0 fi ocf_log warn ""${LH} Failed to stop ${service_name} with ${signal}"" return 1 fi } ########################################################### # Attempts to kill a process with the given pid or pid file # using proc_kill and will retry with sigkill if sigterm is # unsuccessful. # # Globals: # OCF_ERR_GENERIC # OCF_SUCCESS # LL # Arguments: # $1 - pidfile or pid or 'none', if stopping by the name matching # $2 - service name used for logging or for the failback stopping method # $3 - stop process timeout (in sec), used to determine how many times we try # SIGTERM and an upper limit on how long this function should try and # stop the process. Defaults to 15. # Returns: # OCF_SUCCESS - if successful # OCF_ERR_GENERIC - if process is still running according to procfs ########################################################### proc_stop() { local pid_param=""${1}"" local service_name=""${2}"" local timeout=""${3:-15}"" local LH=""${LL} proc_stop():"" local i local pid local pidfile if [ ""${pid_param}"" = ""none"" ] ; then pid=""none"" else # check if provide just a number echo ""${pid_param}"" | egrep -q '^[0-9]+$' if [ $? -eq 0 ]; then pid=""${pid_param}"" elif [ -e ""${pid_param}"" ]; then # check if passed in a pid file pidfile=""${pid_param}"" pid=$(cat ""${pidfile}"" 2>/dev/null | tr -s "" "" ""\n"" | sort -u) else ocf_log warn ""${LH} pid param ${pid_param} is not a file or a number, try match by ${service_name}"" pid=""none"" fi fi # number of times to try a SIGTEM is (timeout - 5 seconds) / 2 seconds local stop_count=$(( ($timeout-5)/2 )) # make sure we stop at least once if [ $stop_count -le 0 ]; then stop_count=1 fi if [ -z ""${pid}"" ] ; then ocf_log warn ""${LH} unable to get PID from ${pidfile}, try match by ${service_name}"" pid=""none"" fi if [ -n ""${pid}"" ]; then for i in ${pid} ; do [ ""${i}"" ] || break ocf_log info ""${LH} Stopping ${service_name} by PID ${i}"" proc_kill ""${i}"" ""${service_name}"" SIGTERM $stop_count if [ $? -ne 0 ]; then # SIGTERM failed, send a single SIGKILL proc_kill ""${i}"" ""${service_name}"" SIGKILL 1 2 if [ $? -ne 0 ]; then ocf_log err ""${LH} ERROR: could not stop ${service_name}"" return ""${OCF_ERR_GENERIC}"" fi fi done fi # Remove the pid file here which will remove empty pid files as well if [ -n ""${pidfile}"" ]; then rm -f ""${pidfile}"" fi ocf_log info ""${LH} Stopped ${service_name}"" return ""${OCF_SUCCESS}"" } local timeout if [ ""$1"" = ""-t"" ]; then timeout=""/usr/bin/timeout ${OCF_RESKEY_command_timeout} $2"" shift 2 else timeout=$COMMAND_TIMEOUT fi local cmd=""${1:-status}"" ${timeout} ${cmd}"" local LH=""${LL} master_score():"" if [ -z $score ] ; then ocf_log info ""${LH} Updating master score attribute with ${score}""# Return either FQDN or shortname, depends on the OCF_RESKEY_use_fqdn. get_hostname() { if [ ""${OCF_RESKEY_use_fqdn}"" = 'false' ] ; then echo ""$(hostname -s)"" else echo ""$(hostname -f)"" fi } # Strip the FQDN to the shortname, if OCF_RESKEY_use_fqdn was set; # Prepend prefix to the hostname process_fqdn() { if [ ""${OCF_RESKEY_use_fqdn}"" = 'false' ] ; then echo ""${OCF_RESKEY_fqdn_prefix}$1"" | awk -F. '{print $1}' else echo ""${OCF_RESKEY_fqdn_prefix}$1"" fi } local hostname hostname=$(process_fqdn $(get_hostname)) hn=$(process_fqdn ""${host}"") if [ ""${hostname}"" = ""${hn}"" ] ; then if [ -z ""${stime}"" -o ""${stime}"" = ""(null)"" ] ; then# Return either rabbit node name as FQDN or shortname, depends on the OCF_RESKEY_use_fqdn. rabbit_node_name() { echo ""rabbit@$(process_fqdn $1)"" } H=""$(get_hostname)"" export RABBITMQ_NODENAME=$(rabbit_node_name $H) MNESIA_FILES=""${OCF_RESKEY_mnesia_base}/$(rabbit_node_name $H)"" local files files=$(su -s /bin/sh - $OCF_RESKEY_username -c ""find ${dir} ! -writable"") if [ ""${files}"" ]; then export LL=""${OCF_RESOURCE_INSTANCE}[$$]:"" if [ $rc -eq 0 ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then ocf_run rm -rf ""${MNESIA_FILES}"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed from ${MNESIA_FILES}."" until $(iptables -nvL | grep -q 'temporary RMQ block') || [ $tries -eq 0 ]; do tries=$((tries-1)) local c_status if [ ""$1"" = 'nodes' ] elif [ ""$1"" = 'running' ] c_status=`${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null` if [ $rc -ne 0 ] ; then echo $(echo ""${c_status}"" | awk -F, '{ for (i=1;i<=NF;i++) { if ($i ~ /@/) { gsub(/[\[\]}{]/,"""",$i); print $i; } }}' | tr -d ""\'"") if [ -z ""$1"" ]; then} # Get current master. If a parameter is provided, # do not check node with that name get_master_name_but() { local node for node in $(get_alive_pacemaker_nodes_but ""$@"") do ocf_log info ""${LH} looking if $node is master"" if is_master $node; then ocf_log info ""${LH} master is $node"" echo $node break fi done } # Returns 0 if we are clustered with provideded node is_clustered_with() { get_running_nodes | grep -q $(rabbit_node_name $1); check_need_join_to() { local join_to local running_nodes join_to=$(rabbit_node_name $1) running_nodes=$(get_running_nodes) if [ ""${join_to}"" = ""${node}"" ] ; then# Stop rmq beam process by pid and by rabbit node name match. Returns SUCCESS/ERROR kill_rmq_and_remove_pid() { # Stop the rabbitmq-server by its pidfile, use the name matching as a fallback, # and ignore the exit code proc_stop ""${OCF_RESKEY_pid_file}"" ""beam.*${RABBITMQ_NODENAME}"" ""${OCF_RESKEY_stop_time}"" # Ensure the beam.smp stopped by the rabbit node name matching as well proc_stop none ""beam.*${RABBITMQ_NODENAME}"" ""${OCF_RESKEY_stop_time}"" if [ $? -eq 0 ] ; then return $OCF_SUCCESS else return $OCF_ERR_GENERIC local rmq_node local nowtime rmq_node=$(rabbit_node_name $node) ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then nowtime=""$(now)"" ocf_log info ""${LH} Rabbit app started successfully. Updating start time attribute with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ $rc -ne 0 ] ; then if [ ""${nodename}"" = ""${RABBITMQ_NODENAME}"" ] ; then if [ ""${nodename}"" = ""${rnode}"" ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then tries=$((tries+1)) if is_clustered_with $nodename; then else break if [ $rc -eq 0 ] ; then# Stop RMQ beam server process. Returns SUCCESS/ERROR if [ $rc -ne 0 ] ; then # Try to stop without known PID ocf_log err ""${LH} RMQ-server process PIDFILE was not found!"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" if [ $? -eq 0 ] ; then ocf_log info ""${LH} RMQ-server process stopped succesfully, although there was no PIDFILE found."" ocf_log info ""${LH} grant a graceful termintation window ${OCF_RESKEY_stop_time} to end its beam"" sleep ""${OCF_RESKEY_stop_time}"" else kill_rmq_and_remove_pid fi elif [ ""${pid}"" ] ; then # Try to stop gracefully by known PID ocf_log info ""${LH} Execute stop with timeout: ${TIMEOUT_ARG}"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop ${OCF_RESKEY_pid_file} 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" [ $? -eq 0 ] && ocf_log info ""${LH} RMQ-server process (PID=${pid}) stopped succesfully."" # Ensure there is no beam process and pidfile left pgrep -f ""beam.*${RABBITMQ_NODENAME}"" > /dev/null rc=$? if [ -f ${OCF_RESKEY_pid_file} -o $rc -eq 0 ] ; then ocf_log warn ""${LH} The pidfile or beam's still exist, forcing the RMQ-server cleanup"" fi # Return the actual status get_status if [ $? -ne 0 ] ; then return $OCF_SUCCESS else if [ $rc -ne 0 ] ; then if [ $rc -ne 0 ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then local command if [ -f ""${OCF_RESKEY_pid_file}"" ] ; then if [ ""${pid}"" -a -d ""/proc/${pid}"" ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then ocf_run kill -TERM $pid ocf_run rm -f $OCF_RESKEY_pid_file command=""${OCF_RESKEY_binary} >> \""${OCF_RESKEY_log_dir}/startup_log\"" 2>/dev/null"" if [ -f ""${OCF_RESKEY_pid_file}"" ] ; then if [ ""${pid}"" != ""0"" -a -d ""/proc/${pid}"" ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ ""${pid}"" = ""0"" ] ; then local rc=$? if [ $rc -eq 0 ] ; then local list list=`${OCF_RESKEY_ctl} eval 'rabbit_plugins:active().'` echo ""${list}"" if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ -z ""${startup_log}"" ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then if [ $mrc -eq 0 ] ; then local mlist mlist=`list_active_plugins` ocf_log info ""${LH} Starting plugins: ${mlist}"" if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -ne $OCF_SUCCESS ]; then if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc -ne 0 ] ; then for a in $(seq 1 10) ; do if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -eq $OCF_SUCCESS ]; then if [ $rc -eq $OCF_ERR_GENERIC ] ; then local rc=$OCF_NOT_RUNNING local LH=""${LL} get_status():"" local beam_running pgrep -f ""beam.*${RABBITMQ_NODENAME}"" > /dev/null beam_running=$? # report not running only if the which_applications() reported an error AND the beam is not running if [ $rc -ne 0 -a $beam_running -ne 0 ] ; then ocf_log info ""${LH} failed with code ${rc}. Command output: ${body}"" # return a generic error, if there were errors and beam is found running elif [ $rc -ne 0 ] ; then ocf_log info ""${LH} found the beam process running but failed with code ${rc}. Command output: ${body}"" return $OCF_ERR_GENERIC # try to parse the which_applications() output only if it exited w/o errors if [ ""${what}"" -a $rc -eq 0 ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then ocf_log info ""${LH} app ${what} was not found in command output: ${body}"" [ $rc -ne $OCF_SUCCESS ] && rc=$OCF_NOT_RUNNING if [ ""${result}"" != 'true' ] ; then count=`crm_attribute -N $THIS_PCMK_NODE -l reboot --name $crm_attr_name --query 2>/dev/null` count=`echo ""${count}"" | awk '{print $3}' | awk -F ""="" '{print $2}' | sed -e '/(null)/d'`wait_sync() { wait_time=$1 queues=""${COMMAND_TIMEOUT} ${OCF_RESKEY_ctl} list_queues name state"" su_rabbit_cmd -t ""${wait_time}"" ""sh -c \""while ${queues} | grep -q 'syncing,'; \ do sleep 2; done\"""" return $? } local status_master=1 if [ $rc -eq $OCF_NOT_RUNNING ] ; then elif [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} We are the running master"" elif [ $status_master -eq 0 -a $rabbit_running -ne $OCF_SUCCESS ] ; then ocf_log err ""${LH} We are the master and RMQ-runtime (beam) is not running. this is a failure"" exit $OCF_FAILED_MASTER if [ $rabbit_running -eq $OCF_SUCCESS ] ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" else local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -z ""$master_name"" ]; then ocf_log info ""${LH} no master is elected currently. Skipping cluster health check."" elif is_clustered_with $master_name; then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" else # Rabbit is running but is not connected to master # Failing to avoid split brain ocf_log err ""${LH} rabbit node is running out of the cluster"" stop_server_process rc=$OCF_ERR_GENERIC fi fi if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then # Do not refetch the master status as we know it already if [ $rc -eq $OCF_RUNNING_MASTER ]; then local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -n ""$master_name"" ]; then ocf_log info ""${LH} master exists and rabbit app is not running. Exiting to be restarted by pacemaker"" stop_server_process rc=$OCF_ERR_GENERIC fi fi if [ $rc -eq $OCF_ERR_GENERIC ]; then elif [ $rc -ne $OCF_RUNNING_MASTER ] ; then if [ -z ""${node_start_time}"" -o ""${node_start_time}"" = ""(null)"" ] ; then [ $rc_alive -eq 137 -o $rc_alive -eq 124 ] && ocf_log err ""${LH} 'rabbitmqctl list_channels' timed out, per-node explanation: $(enhanced_list_channels)"" master_score 0 master_score 0 if [ ""${name}"" = ""${RABBITMQ_NODENAME}"" ] ; then master_score 0 local q_c q_c=`printf ""%b\n"" ""${queues}"" | wc -l` local mem mem=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 '{sum+=$1} END {print (sum/1048576)}'` local mes mes=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 '{sum+=$2} END {print sum}'` local c_u c_u=`printf ""%b\n"" ""${queues}"" | awk -v sum=0 -v cnt=${q_c} '{sum+=$3} END {print (sum+1)/(cnt+1)}'` local status status=`echo $(su_rabbit_cmd ""${OCF_RESKEY_ctl} -q status"")` if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} RMQ going to start."" start_rmq_server_app rc=$? if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} RMQ prepared for start succesfully."" fi if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) # Fail early without additional rabbitmqctl invocations if [ $? -ne $OCF_SUCCESS ] ; then ocf_log err ""RMQ-runtime (beam) couldn't be stopped and will likely became unmanaged. Take care of it manually!"" ocf_log info ""${LH} action end."" exit $OCF_ERR_GENERIC # Ensure the actual status to be returned get_status if [ $? -eq $OCF_NOT_RUNNING ] ; then ocf_log info ""${LH} RMQ-runtime (beam) not running."" ocf_log info ""${LH} action end."" return $OCF_SUCCESS else ocf_log err ""RMQ-runtime (beam) couldn't be stopped and will likely became unmanaged. Take care of it manually!"" ocf_log info ""${LH} action end."" exit $OCF_ERR_GENERIC fi } ####################################################################### # Enhanced list_channels: # - nodes are processed in parallel # - report contains information about which nodes timed out # # 'list_channels' is used as a healh-check for current node, but it # actually checks overall health of all node in cluster. And there were # some bugs where only one (non-local) channel became stuck, but OCF # script was wrongfully killing local node. # # Hopefully all such bugs are fixed, but if not - it will allow to # detect such conditions. # # Somewhat strange implementation is due to the following reasons: # - ability to support older versions of RabbitMQ which have reached # end-of-life with single version of the script # - zero dependencies - for older versions this functionality could be # implemented as a plugin, but it'll require this plugin installation enhanced_list_channels() { # One second less than timeout of su_rabbit_cmd local timeout=$((${TIMEOUT_ARG:-5} - 1)) su_rabbit_cmd ""xargs -0 ${OCF_RESKEY_ctl} eval"" <<EOF SecondsToCompletion = $timeout, %% Milliseconds since unix epoch Now = fun() -> {Mega, Secs, Micro} = os:timestamp(), Mili = Micro div 1000, Mili + 1000 * (Secs + 1000000 * Mega) end, %% We shouldn't continue execution past this time ShouldEndAt = Now() + SecondsToCompletion * 1000, %% How many milliseconds we still have Timeout = fun() -> case ShouldEndAt - Now() of Past when Past =< 0 -> 0; Timeout -> Timeout end end, %% Lambda combinator - for defining anonymous recursive functions Y = fun(F) -> (fun (X) -> F(fun(Y) -> (X(X))(Y) end) end)( fun (X) -> F(fun(Y) -> (X(X))(Y) end) end) end, Parent = self(), ListChannels = Y(fun(Rec) -> fun (({Node, [], OkChannelsCount})) -> Parent ! {Node, ok, OkChannelsCount}; ({Node, [Chan|Rest], OkChannelsCount}) -> case catch rpc:call(Node, rabbit_channel, info, [Chan], Timeout()) of Infos when is_list(Infos) -> Rec({Node, Rest, OkChannelsCount + 1}); {badrpc, {'EXIT', {noproc, _}}} -> %% Channel became dead before we could request it's status, don't care Rec({Node, Rest, OkChannelsCount}); Err -> Parent ! {Node, Err, OkChannelsCount} end end end), SingleNodeListing = fun(Node) -> case catch rpc:call(Node, pg_local, get_members, [rabbit_channels], Timeout()) of LocalChannels when is_list(LocalChannels) -> ListChannels({Node, LocalChannels, 0}); Err -> Parent ! {Node, Err, 0} end end, AllNodes = rabbit_mnesia:cluster_nodes(running), [ spawn(fun() -> SingleNodeListing(Node) end) || Node <- AllNodes ], WaitForNodes = Y(fun(Rec) -> fun ({[], Acc}) -> Acc; ({RemainingNodes, Acc}) -> receive {Node, _Status, _ChannelCount} = Smth -> RemainingNodes1 = lists:delete(Node, RemainingNodes), Rec({RemainingNodes1, [Smth|Acc]}) after Timeout() + 100 -> Acc end end end), Result = WaitForNodes({AllNodes, []}), ExpandedResult = [ case lists:keysearch(Node, 1, Result) of {value, NodeResult} -> NodeResult; false -> {Node, no_data_collected, 0} end || Node <- AllNodes ], ExpandedResult. EOF if [ $rc -ne 0 -a ""${join_to}"" ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then local nowtime if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ ""${OCF_RESKEY_CRM_meta_notify_type}"" = 'pre' ] ; then # PRE- anything notify section case ""$OCF_RESKEY_CRM_meta_notify_operation"" in promote) if [ $rc -eq $OCF_SUCCESS ] ; then ocf_log info ""${LH} Deleting master attribute for node ${i}"" ocf_run crm_attribute -N $i -l reboot --name 'rabbit-master' --delete esac if [ ""${OCF_RESKEY_CRM_meta_notify_type}"" = 'post' ] ; then rc=$OCF_SUCCESS ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" elif my_host ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} ignoring post-promote of self"" elif is_clustered_with ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} we are already clustered with master - ${OCF_RESKEY_CRM_meta_notify_promote_uname}. Nothing to do."" else # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" fi return $rc if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc_join -eq $OCF_SUCCESS ]; then jjj_join ""${OCF_RESKEY_CRM_meta_notify_master_uname}"" nowtime=""$(now)"" ocf_log info ""${LH} Updating start time attribute with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ -s ""${OCF_RESKEY_definitions_dump_file}"" ] ; then ocf_run curl --silent --show-error --request POST --user $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password $OCF_RESKEY_host_ip:15672/api/definitions --header ""Content-Type:application/json"" --data @$OCF_RESKEY_definitions_dump_file if [ $rc -eq $OCF_SUCCESS ] ; then if [ $rc2 -eq $OCF_ERR_GENERIC ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) # On other nodes processing the post-stop, make sure the stopped node will be forgotten if [ $rc -ne $OCF_SUCCESS ] ; then # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) ocf_log info ""${LH} Deleting start time attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete if [ $rc2 -ne $OCF_SUCCESS ] ; then local nowtime if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then if [ $rc -ne $OCF_SUCCESS ] ; then if [ $rc -eq 0 ] ; then if [ $rc -ne 0 ] ; then [ -f ""${OCF_RESKEY_policy_file}"" ] && . ""${OCF_RESKEY_policy_file}"" nowtime=""$(now)"" ocf_log info ""${LH} Updating start timestamp with ${nowtime}"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update ""${nowtime}"" if [ $rc = $OCF_RUNNING_MASTER ] if [ ""${OCF_RESKEY_debug}"" = 'true' ] ; then ocf_log info ""${LH} Deleting master attribute"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete ocf_log info ""${LH} Deleting start timestamp"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # Wait for synced state first ocf_log info ""${LH} waiting $((OCF_RESKEY_stop_time/2)) to sync"" wait_sync $((OCF_RESKEY_stop_time/2)) ","#!/bin/bashOCF_RESKEY_pid_file_default=/var/run/rabbitmq/p_pid OCF_RESKEY_log_dir_default=/var/log/rabbitmq OCF_RESKEY_mnesia_base_default=/var/lib/rabbitmq/mnesiaOCF_RESKEY_max_rabbitmqctl_timeouts_default=1 local cmd=${1:-status} ${COMMAND_TIMEOUT} ${cmd}"" if [[ -z $score ]] ; then local hostname=$(hostname -s) hn=$(echo ""$host"" | awk -F. '{print $1}') if [[ ""X${hostname}"" == ""X${hn}"" ]] ; then if [ -z ""${stime}"" -o x""${stime}"" == x""(null)"" ] ; then H=`hostname -s` export RABBITMQ_NODENAME=""rabbit@${H}"" MNESIA_FILES=""${OCF_RESKEY_mnesia_base}/rabbit@${H}"" local files=$(su -s /bin/sh - $OCF_RESKEY_username -c ""find ${dir} ! -writable"") if [ ! -z ""${files}"" ]; then export LL=""${OCF_RESOURCE_INSTANCE}:""rabbit_node_name() { echo ""rabbit@""$(echo ""$1"" | awk -F. '{print $1}') } if [[ $rc == 0 ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_run rm -rf ${MNESIA_FILES}* ocf_log warn ""${LH} Beam have been killed. Mnesia files appear corrupted and have been removed."" until $(iptables -nvL | grep -q 'temporary RMQ block') || [[ $tries -eq 0 ]]; do ((tries--)) if [ ""$1"" == 'nodes' ] elif [ ""$1"" == 'running' ] local c_status c_status=$(${OCF_RESKEY_ctl} eval ""mnesia:system_info(${infotype})."" 2>/dev/null) if [[ $rc != 0 ]] ; then echo $(echo ""${c_status}"" | grep ""${cl}"" | awk -F, '{ for (i=1;i<=NF;i++) { if ($i ~ /@/) { gsub(/[\[\]}{]/,"""",$i); print $i; } }}' | tr -d ""\'"") return $? if [ -z $1 ]; thencheck_need_join_to() { local join_to=$(rabbit_node_name $1) local running_nodes=$(get_running_nodes) if [[ ${join_to} == ${node} ]] ; thenkill_rmq_and_remove_pid() { local pid if [[ -f $OCF_RESKEY_pid_file ]] ; then pid=$(cat $OCF_RESKEY_pid_file) if [[ -z ${pid} ]] ; then ocf_log err ""${LH} pidfile is empty, cannot kill by unknown PID! Try to stop it manually!"" fi # todo: check content for digital if [[ -d /proc/${pid}/ ]] ; then ocf_run kill -9 $pid ocf_log warn ""${LH} RMQ-runtime (beam) PID=${pid} stopped by 'kill -9', sorry..."" fi ocf_run rm -f $OCF_RESKEY_pid_file local rmq_node=$(rabbit_node_name $node) ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_log info ""${LH} Rabbit app started successfully. Updating start time attribute with $(now)"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update $(now) if [[ $rc != 0 ]] ; then if [[ ""$nodename"" == ""$RABBITMQ_NODENAME"" ]] ; then if [[ ""$nodename"" == ""$rnode"" ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ((tries++)) if get_running_nodes | grep -q $(rabbit_node_name $nodename) then if [[ $rc == 0 ]] ; then# Stop RMQ server process. Returns OCS_SUCCESS if [[ $rc != 0 ]] ; then ocf_log err ""${LH} RMQ-server process PIDFILE was not found!"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" rc=$? if [[ $rc == 0 ]] ; then ocf_log info ""${LH} RMQ-server process stopped succesfully, although there was no PIDFILE found."" return $OCF_SUCCESS else ocf_log err ""${LH} Cannot stop RMQ-server process, and cannot kill it by unknown PID! Try to stop it manually!"" return $OCF_ERR_GENERIC fi if [[ -z ${pid} ]] ; then ocf_log info ""${LH} Execute stop with timeout: ${TIMEOUT_ARG}"" su_rabbit_cmd ""${OCF_RESKEY_ctl} stop ${OCF_RESKEY_pid_file} 2>&1 >> \""${OCF_RESKEY_log_dir}/shutdown_log\"""" rc=$? if [[ $rc == 0 ]] ; then ocf_log info ""${LH} RMQ-server process (PID=${pid}) stopped succesfully."" fi kill_rmq_and_remove_pid return $OCF_SUCCESS if [[ $rc != 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ -f $OCF_RESKEY_pid_file ]] ; then if [[ -d /proc/${pid} && ! -z ${pid} ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ocf_run kill -9 $pid ocf_run rm -rf $OCF_RESKEY_pid_file local command=""${OCF_RESKEY_binary} >> \""${OCF_RESKEY_log_dir}/startup_log\"" 2>/dev/null"" if [[ -f $OCF_RESKEY_pid_file ]] ; then if [[ $pid != 0 && -d /proc/${pid} ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ ""${pid}"" == ""0"" ]] ; then if [[ $? == 0 ]] ; then local LIST=`${OCF_RESKEY_ctl} eval 'rabbit_plugins:active().'` echo ""${LIST}"" if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ -z $startup_log ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then if [[ $mrc == 0 ]] ; then local MLIST=`list_active_plugins` ocf_log info ""${LH} Starting plugins: $MLIST"" if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc != $OCF_SUCCESS ]]; then if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc != 0 ]] ; then for ((a=10; a > 0 ; a--)) ; do if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc == $OCF_SUCCESS ]]; then if [[ $rc == $OCF_ERR_GENERIC ]] ; then local rc=$OCF_ERR_GENERIC if [[ $rc != 0 ]] ; then ocf_log info ""get_status() failed with code ${rc}. Command output: ${body}"" if [[ ! -z $what ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then ocf_log info ""get_status(): app ${what} was not found in command output: ${body}"" if [[ ""${result}"" != ""true"" ]] ; then count=`crm_attribute -N $THIS_PCMK_NODE -l reboot --name $crm_attr_name --query 2>/dev/null | awk '{print $3}' | awk -F ""="" '{print $2}' | sed -e '/(null)/d'` local scope local status_master local prev_rc if [[ $rc == $OCF_NOT_RUNNING ]] ; then elif [[ $rc == $OCF_SUCCESS ]] ; then if [ $rabbit_running == $OCF_SUCCESS ] ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" prev_rc=$rc nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do ocf_log info ""${LH} rabbit app is running. looking for master on $node"" is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is running. master is $node"" if get_running_nodes | grep -q $(rabbit_node_name $node) then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" rc=$prev_rc break fi fi done [ $rc -eq $OCF_ERR_GENERIC ] && ocf_log err ""${LH} rabbit node is running out of the cluster"" if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then prev_rc=$rc is_master $THIS_PCMK_NODE i_am_master=$? if [ $i_am_master -eq 0 ]; then nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is not running. master is $node. exiting to be restarted by pacemaker"" fi done fi if [[ $rc == $OCF_ERR_GENERIC ]]; then else if [ -z ""${node_start_time}"" -o x""${node_start_time}"" == x""(null)"" ] ; then if [[ ""${name}"" == ""${RABBITMQ_NODENAME}"" ]] ; then local q_c=`echo -e ""${queues}"" | wc -l` local mem=`echo -e ""${queues}"" | awk -v sum=0 '{sum+=$1} END {print (sum/1048576)}'` local mes=`echo -e ""${queues}"" | awk -v sum=0 '{sum+=$2} END {print sum}'` local c_u=`echo -e ""${queues}"" | awk -v sum=0 -v cnt=${q_c} '{sum+=$3} END {print (sum+1)/(cnt+1)}'` local status=`echo $(su_rabbit_cmd ""${OCF_RESKEY_ctl} -q status"")` if [[ ""${OCF_RESKEY_debug}"" == ""true"" ]] ; then local msg local master_node if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ $rc == $OCF_SUCCESS ]] ; then ocf_log info ""${LH} RMQ going to start."" start_rmq_server_app rc=$? if [[ $rc == $OCF_SUCCESS ]] ; then ocf_log info ""${LH} RMQ prepared for start succesfully."" fi if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then # remove master flag # remove master score crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete # remove file with rmq-server start timestamp #todo: make this timeout corresponded to the stop timeout for resource sleep 10 ocf_log info ""${LH} action end."" get_status rc=$? if [[ $rc == $OCF_NOT_RUNNING ]] ; then ocf_log info ""${LH} RMQ-runtime (beam) not running."" return $OCF_SUCCESS else return $OCF_ERR_GENERIC if [[ $rc != 0 && $join_to != '' ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'pre' ]] ; then # PRE- anything notify section case ""$OCF_RESKEY_CRM_meta_notify_operation"" in promote) if [[ $rc == $OCF_SUCCESS ]] ; then crm_attribute -N $i -l reboot --name 'rabbit-master' --delete esac if [[ ${OCF_RESKEY_CRM_meta_notify_type} == 'post' ]] ; then ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" ocf_log info ""${LH} post-promote end."" return $OCF_SUCCESS # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ${OCF_RESKEY_CRM_meta_notify_promote_uname} rc=$? if [[ $rc == $OCF_ERR_GENERIC ]] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" return $OCF_ERR_GENERIC fi if [[ $rc == $OCF_SUCCESS ]] ; then if [[ ${rc_join} == $OCF_SUCCESS ]]; then jjj_join ${OCF_RESKEY_CRM_meta_notify_master_uname} if [[ -s ${OCF_RESKEY_definitions_dump_file} ]] ; then ocf_run curl -X POST -u $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password 127.0.0.1:15672/api/definitions --header ""Content-Type:application/json"" -d @$OCF_RESKEY_definitions_dump_file if [[ $rc == $OCF_SUCCESS ]] ; then if [[ $rc2 == $OCF_ERR_GENERIC ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then # On ohter nodes processing the post-stop, make sure the stopped node will be forgotten if [[ $rc != $OCF_SUCCESS ]] ; then crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete if [[ $rc2 != $OCF_SUCCESS ]] ; then if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then if [[ $rc != $OCF_SUCCESS ]] ; then if [[ $rc == 0 ]] ; then if [[ $rc != 0 ]] ; then ocf_log info ""${LH} Setting HA policy for all queues"" rabbitmqctl set_policy ha-all ""."" '{""ha-mode"":""all"", ""ha-sync-mode"":""automatic""}' --apply-to all --priority 0 rabbitmqctl set_policy heat_rpc_expire ""^heat-engine-listener\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 rabbitmqctl set_policy results_expire ""^results\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 rabbitmqctl set_policy tasks_expire ""^tasks\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 ocf_log info ""${LH} Updating start timestamp"" ocf_run crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --update $(now) if [ $rc == $OCF_RUNNING_MASTER ] if [[ ${OCF_RESKEY_debug} == ""true"" ]] ; then crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-master' --delete crm_attribute -N $THIS_PCMK_NODE -l reboot --name 'rabbit-start-time' --delete",751,269
openstack%2Fopenstack-ansible-galera_client~master~I26111d7191db793b9cddca29c681399040ab6011,openstack/openstack-ansible-galera_client,master,I26111d7191db793b9cddca29c681399040ab6011,Use the apt_package_pinning role,MERGED,2016-04-29 00:55:52.000000000,2016-05-06 10:30:24.000000000,2016-05-06 10:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-04-29 00:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/6f61928d047f862473488c32d55627d57f41b5ce', 'message': 'Use the apt_package_pinning role\n\nAdd a dependency on the apt_package_pinning role and use it, instead of a\ntemplate within this role, to pin the MariaDB repo.\n\nChange-Id: I26111d7191db793b9cddca29c681399040ab6011\n'}, {'number': 2, 'created': '2016-04-29 05:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/9b7f14e4d992647e17dd7b84a33ae0238bb2a712', 'message': 'Use the apt_package_pinning role\n\nAdd a dependency on the apt_package_pinning role and use it, instead of a\ntemplate within this role, to pin the MariaDB repo.\n\nChange-Id: I26111d7191db793b9cddca29c681399040ab6011\n'}, {'number': 3, 'created': '2016-05-06 01:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/be8ac2ab6bb2320c43392d49e48d17bc89e655d9', 'message': 'Use the apt_package_pinning role\n\nAdd a dependency on the apt_package_pinning role and use it, instead of a\ntemplate within this role, to pin the MariaDB repo.\n\nA new task has been added so that the pin created by this role will be\nremoved during upgrades from the previous release.\n\nChange-Id: I26111d7191db793b9cddca29c681399040ab6011\n'}, {'number': 4, 'created': '2016-05-06 02:11:23.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tasks/galera_client_pre_install.yml', 'releasenotes/notes/apt-package-pinning-dependency-6e2e94d829508859.yaml', 'templates/galera_client_pin.pref.j2', 'defaults/main.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/03936b3f11e7872544a5205839f67958305d0562', 'message': 'Use the apt_package_pinning role\n\nAdd a dependency on the apt_package_pinning role and use it, instead of a\ntemplate within this role, to pin the MariaDB repo.\n\nChange-Id: I26111d7191db793b9cddca29c681399040ab6011\n'}]",5,310969,03936b3f11e7872544a5205839f67958305d0562,19,5,4,14805,,,0,"Use the apt_package_pinning role

Add a dependency on the apt_package_pinning role and use it, instead of a
template within this role, to pin the MariaDB repo.

Change-Id: I26111d7191db793b9cddca29c681399040ab6011
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/69/310969/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tasks/galera_client_pre_install.yml', 'releasenotes/notes/apt-package-pinning-dependency-6e2e94d829508859.yaml', 'defaults/main.yml', 'meta/main.yml']",5,6f61928d047f862473488c32d55627d57f41b5ce,use_apt_package_pinning," - role: apt_package_pinning apt_pinned_packages: ""{{ galera_apt_pinned_packages }}"" when: - ansible_pkg_mgr == 'apt'",,14,10
openstack%2Ffuel-library~stable%2F8.0~I3c308b033b4514c2067601e8111758e0b5c44d3d,openstack/fuel-library,stable/8.0,I3c308b033b4514c2067601e8111758e0b5c44d3d,Stop process when rabbit is running but is not connected to master.,ABANDONED,2016-05-04 10:38:59.000000000,2016-05-06 10:26:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 10489}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 10:38:59.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/729499c4344f5f0b2a0618a5c6a4822bf53bbf56', 'message': ""Stop process when rabbit is running but is not connected to master.\n\nIt's should goes down due to avoid split brain.\n\nChange-Id: I3c308b033b4514c2067601e8111758e0b5c44d3d\nCloses-Bug: #1541471\nUpstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758\n""}]",0,312439,729499c4344f5f0b2a0618a5c6a4822bf53bbf56,12,5,1,17730,,,0,"Stop process when rabbit is running but is not connected to master.

It's should goes down due to avoid split brain.

Change-Id: I3c308b033b4514c2067601e8111758e0b5c44d3d
Closes-Bug: #1541471
Upstream PR: https://github.com/rabbitmq/rabbitmq-server/pull/758
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/39/312439/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,729499c4344f5f0b2a0618a5c6a4822bf53bbf56,,"# Note that the script uses an external file to setup RabbitMQ policies # so make sure to create it from an example shipped with the package.OCF_RESKEY_max_rabbitmqctl_timeouts_default=3 OCF_RESKEY_policy_file_default=""/usr/local/sbin/set_rabbitmq_policy"": ${OCF_RESKEY_policy_file=${OCF_RESKEY_policy_file_default}}<parameter name=""policy_file"" unique=""0"" required=""0""> <longdesc lang=""en""> A path to the shell script to setup RabbitMQ policies </longdesc> <shortdesc lang=""en"">A policy file path</shortdesc> <content type=""string"" default=""${OCF_RESKEY_policy_file_default}"" /> </parameter> # Strip the FQDN to the shortname, if OCF_RESKEY_use_fqdn was set; # Prepend prefix to the hostname export LL=""${OCF_RESOURCE_INSTANCE}[$$]:"" ocf_run rm -rf ""${MNESIA_FILES}"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed from ${MNESIA_FILES}.""# Get current master. If a parameter is provided, # do not check node with that name get_master_name_but() { local node for node in $(get_alive_pacemaker_nodes_but ""$@"") do ocf_log info ""${LH} looking if $node is master"" if is_master $node; then ocf_log info ""${LH} master is $node"" echo $node break fi done } # Returns 0 if we are clustered with provideded node is_clustered_with() { get_running_nodes | grep -q $(rabbit_node_name $1); return $? } ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if is_clustered_with $nodename; then else break local LH=""${LL} get_status():"" ocf_log info ""${LH} failed with code ${rc}. Command output: ${body}"" ocf_log info ""${LH} found the beam process running but failed with code ${rc}. Command output: ${body}"" ocf_log info ""${LH} app ${what} was not found in command output: ${body}"" ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" else local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -z ""$master_name"" ]; then ocf_log info ""${LH} no master is elected currently. Skipping cluster health check."" elif is_clustered_with $master_name; then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" # Rabbit is running but is not connected to master # Failing to avoid split brain ocf_log err ""${LH} rabbit node is running out of the cluster"" stop_server_process rc=$OCF_ERR_GENERIC fi if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -n ""$master_name"" ]; then ocf_log info ""${LH} master exists and rabbit app is not running. Exiting to be restarted by pacemaker"" stop_server_process rc=$OCF_ERR_GENERIC fi fi if [ $rc -eq $OCF_ERR_GENERIC ]; then rc=$OCF_SUCCESS ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" elif my_host ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} ignoring post-promote of self"" elif is_clustered_with ""${OCF_RESKEY_CRM_meta_notify_promote_uname}""; then ocf_log info ""${LH} we are already clustered with master - ${OCF_RESKEY_CRM_meta_notify_promote_uname}. Nothing to do."" else # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" fi return $rc ocf_run curl --silent --show-error --request POST --user $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password $OCF_RESKEY_host_ip:15672/api/definitions --header ""Content-Type:application/json"" --data @$OCF_RESKEY_definitions_dump_file [ -f ""${OCF_RESKEY_policy_file}"" ] && . ""${OCF_RESKEY_policy_file}""","# Note that the script uses set_rabbitmq_policy.sh script located in the # same directory to setup RabbitMQ policies.OCF_RESKEY_max_rabbitmqctl_timeouts_default=1# Strip the FQDN to the shortname, if OCF_RESKEY_use_fqdn was set export LL=""${OCF_RESOURCE_INSTANCE}:"" ocf_run rm -rf ""${MNESIA_FILES}/*"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed."" ocf_log info ""${LH} Joining to cluster by node '${rmq_node}'."" if get_running_nodes | grep -q $(rabbit_node_name $nodename) then ocf_log info ""get_status() failed with code ${rc}. Command output: ${body}"" ocf_log info ""get_status() found the beam process running but failed with code ${rc}. Command output: ${body}"" ocf_log info ""get_status(): app ${what} was not found in command output: ${body}"" local rc_check=$OCF_SUCCESS ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" rc_check=$OCF_SUCCESS rc_check=$OCF_ERR_GENERIC nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do ocf_log info ""${LH} rabbit app is running. looking for master on $node"" is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then ocf_log info ""${LH} rabbit app is running. master is $node"" if get_running_nodes | grep -q $(rabbit_node_name $node) then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" rc_check=$OCF_SUCCESS break fi fi done [ $rc_check -eq $OCF_ERR_GENERIC ] && ocf_log err ""${LH} rabbit node is running out of the cluster"" if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then nodelist=$(get_alive_pacemaker_nodes_but $THIS_PCMK_NODE) rc_check=$OCF_SUCCESS for node in $nodelist do is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc_check=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is not running. master is $node. exiting to be restarted by pacemaker"" break fi done fi if [ $rc -eq $OCF_ERR_GENERIC -o $rc_check -eq $OCF_ERR_GENERIC ]; then ocf_log warn ""${LH} there are no nodes to join to reported on post-promote. Nothing to do."" ocf_log info ""${LH} post-promote end."" return $OCF_SUCCESS # Note, this should fail when the mnesia is inconsistent. # For example, when the ""old"" master processing the promition of the new one. # Later this ex-master node will rejoin the cluster at post-start. jjj_join ""${OCF_RESKEY_CRM_meta_notify_promote_uname}"" rc=$? if [ $rc -eq $OCF_ERR_GENERIC ] ; then ocf_log err ""${LH} Failed to join the cluster on post-promote. The resource will be restarted."" return $OCF_ERR_GENERIC fi ocf_run curl -X POST -u $OCF_RESKEY_admin_user:$OCF_RESKEY_admin_password $OCF_RESKEY_host_ip:15672/api/definitions --header ""Content-Type:application/json"" -d @$OCF_RESKEY_definitions_dump_file local set_policy_path=""$(dirname $0)/set_rabbitmq_policy.sh"" [ -f $set_policy_path ] && . $set_policy_path",106,69
openstack%2Fnova~master~I3e452172e366b87b373eff33c454472c6be8f1f2,openstack/nova,master,I3e452172e366b87b373eff33c454472c6be8f1f2,Config options: centralize imagebackend libvirt options (2),MERGED,2016-04-22 02:58:52.000000000,2016-05-06 10:26:02.000000000,2016-05-06 06:12:19.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-22 02:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ccf12f70d868a9111711c88e23c093836bbc1d0', 'message': 'Config options: centralize imagebackend libvirt options (2)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the second patch in a long-chain patchs.\n\nChange-Id: I3e452172e366b87b373eff33c454472c6be8f1f2\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 2, 'created': '2016-04-22 03:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a30799d5c84a9c20291bc468556690b7ea7e216', 'message': 'Config options: centralize imagebackend libvirt options (2)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the second patch in a long-chain patchs.\n\nChange-Id: I3e452172e366b87b373eff33c454472c6be8f1f2\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 3, 'created': '2016-05-05 03:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/780b84d6fddfe33a55d15a5fa9bab8955bc6fdb2', 'message': 'Config options: centralize imagebackend libvirt options (2)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the second patch in a long-chain patchs.\n\nChange-Id: I3e452172e366b87b373eff33c454472c6be8f1f2\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 4, 'created': '2016-05-05 09:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fee29a763dec4813cfefbbe0a3d2268bf56ae43c', 'message': 'Config options: centralize imagebackend libvirt options (2)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the second patch in a long-chain patchs.\n\nChange-Id: I3e452172e366b87b373eff33c454472c6be8f1f2\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}, {'number': 5, 'created': '2016-05-05 11:21:24.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/opts.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d39778d5cebbbbc0780b6bce069bc9d1b268fda6', 'message': 'Config options: centralize imagebackend libvirt options (2)\n\nThe config options of the ""nova.conf"" section ""libvirt"" got\nmoved to the new central location ""nova/conf/libvirt.py"".\nSubsequent patches will then move another options in libvirt section.\nThis is the second patch in a long-chain patchs.\n\nChange-Id: I3e452172e366b87b373eff33c454472c6be8f1f2\nCo-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>\nImplements: blueprint centralize-config-options-newton\n'}]",1,309246,d39778d5cebbbbc0780b6bce069bc9d1b268fda6,85,16,5,19741,,,0,"Config options: centralize imagebackend libvirt options (2)

The config options of the ""nova.conf"" section ""libvirt"" got
moved to the new central location ""nova/conf/libvirt.py"".
Subsequent patches will then move another options in libvirt section.
This is the second patch in a long-chain patchs.

Change-Id: I3e452172e366b87b373eff33c454472c6be8f1f2
Co-Authored-by: Markus Zoeller <mzoeller@de.ibm.com>
Implements: blueprint centralize-config-options-newton
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/309246/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/opts.py', 'nova/virt/images.py']",5,1ccf12f70d868a9111711c88e23c093836bbc1d0,bp/centralize-config-options-newton,," # NOTE(sirp): The config option import must go here to avoid an import # cycle CONF.import_opt('images_type', 'nova.virt.libvirt.imagebackend', group='libvirt')",27,36
openstack%2Ffuel-qa~master~Id2e604a085239d0f7a8c5ad45454f3659a18f025,openstack/fuel-qa,master,Id2e604a085239d0f7a8c5ad45454f3659a18f025,Don't process pre-checks methods like test cases,MERGED,2016-05-06 08:56:13.000000000,2016-05-06 10:25:48.000000000,2016-05-06 10:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-05-06 08:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/cb1e6c58924e17ea47a6519b64f6654b85949908', 'message': '[WIP] tmp\n\nChange-Id: Id2e604a085239d0f7a8c5ad45454f3659a18f025\n'}, {'number': 2, 'created': '2016-05-06 10:03:18.000000000', 'files': ['fuelweb_test/testrail/upload_cases_description.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/15a7cc7f2903f896012d88e82b90c2f0a3fe60ca', 'message': ""Don't process pre-checks methods like test cases\n\nChange-Id: Id2e604a085239d0f7a8c5ad45454f3659a18f025\n""}]",0,313283,15a7cc7f2903f896012d88e82b90c2f0a3fe60ca,15,8,2,6719,,,0,"Don't process pre-checks methods like test cases

Change-Id: Id2e604a085239d0f7a8c5ad45454f3659a18f025
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/83/313283/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/testrail/upload_cases_description.py'],1,cb1e6c58924e17ea47a6519b64f6654b85949908,testrail_fix_before_class," title = None if isinstance(s, basestring): title = ' '.join(map(string.strip, s.split('\n'))) elif isinstance(s, list): title = ''.join([' '.join(map( string.strip, el.split('\n'))) for el in s])"," title = ' '.join(map(string.strip, s.split('\n')))",6,1
openstack%2Fopenstack-ansible~master~I097aa2495276dc3073d4d1fd947091c37abab7db,openstack/openstack-ansible,master,I097aa2495276dc3073d4d1fd947091c37abab7db,Doc: Configuring the network on target refactor,MERGED,2016-03-10 17:31:16.000000000,2016-05-06 10:24:11.000000000,2016-05-06 10:24:11.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 10607}, {'_account_id': 10881}, {'_account_id': 12402}, {'_account_id': 13354}, {'_account_id': 15993}, {'_account_id': 16310}, {'_account_id': 17068}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-10 17:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8589f656df2a35838c8f0e36a1641c5b782fa565', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and consistency between\ngithub .example file and the install-guide.\nSeparating the /etc/network/interface for compute\nand Infra services target hosts\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 2, 'created': '2016-03-10 18:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dfd6005289e6a3ec712f9f6bb251855109f55df7', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and consistency between\ngithub .example file and the install-guide.\nSeparating the /etc/network/interface for compute\nand Infra services target hosts\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 3, 'created': '2016-04-04 20:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fbe85d21bd546a8f0d722a42d81a4007a413b540', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and consistency between\ngithub .example file and the install-guide.\nSeparating the /etc/network/interface for compute\nand Infra services target hosts\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 4, 'created': '2016-04-27 16:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/53be4ae519fc9aa6680efb1f4b3f1536ad7d9001', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes an old file and focuses on a simpler\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 5, 'created': '2016-04-29 15:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/02f6958399be4ad44a3b2dc970249d16976c57bd', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes an old file and focuses on a simpler\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 6, 'created': '2016-04-30 17:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d0b78c7ad66341c789a86ad129e89ae180a668ea', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes an old file and focuses on a simpler\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 7, 'created': '2016-05-04 08:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a3b803b7120d3dd93b52b8489d02476bc76c40d5', 'message': 'Doc: Configuring the network on target Refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes an old file and focuses on a simpler\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 8, 'created': '2016-05-04 08:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b3c3833756eb6dd414aa521466d56dd0cc500c67', 'message': 'Doc: Configuring the network on target refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes focuses on a simpler ""single host""\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}, {'number': 9, 'created': '2016-05-05 21:58:20.000000000', 'files': ['doc/source/install-guide/targethosts-networkexample.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0086227b3d482a9b3852edfc360a5dd625cae545', 'message': 'Doc: Configuring the network on target refactor\n\nFor better understanding and avoiding inconsistencies,\nthis commit removes focuses on a simpler ""single host""\npage.\n\nChange-Id: I097aa2495276dc3073d4d1fd947091c37abab7db\nCloses-bug: 1547598\n'}]",26,291310,0086227b3d482a9b3852edfc360a5dd625cae545,63,11,9,13354,,,0,"Doc: Configuring the network on target refactor

For better understanding and avoiding inconsistencies,
this commit removes focuses on a simpler ""single host""
page.

Change-Id: I097aa2495276dc3073d4d1fd947091c37abab7db
Closes-bug: 1547598
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/10/291310/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install-guide/targethosts-networkexample.rst'],1,8589f656df2a35838c8f0e36a1641c5b782fa565,bug/1547598," Addresses for infrastructure, networking, and storage: - Tunnel: no IP (IPs exist in the containers and inet should be set to manual) - Storage: no IP (IPs exist in the containers and inet should be set to manual) Addresses for Compute: - Host management: 10.240.0.21 - Host management gateway: 10.240.0.1 - DNS servers: 69.20.0.164 69.20.0.196 - Container management: 172.29.236.21 - Tunnel: 172.29.240.21 - Storage: 172.29.244.21 iface br-vxlan inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 # Bridge port references tagged interface bridge_ports bond1.30 # OpenStack Networking VLAN bridge auto br-vlan iface br-vlan inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 # Bridge port references untagged interface bridge_ports bond1 # Storage bridge (optional) auto br-storage iface br-storage inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 # Bridge port reference tagged interface bridge_ports bond0.20 **Figure 3.3. Target hosts for Compute service** .. image:: figures/networkarch-bare-external-example.png Contents of the ``/etc/network/interfaces`` file: .. code-block:: yaml # Physical interface 1 auto eth0 iface eth0 inet manual bond-master bond0 bond-primary eth0 # Physical interface 2 auto eth1 iface eth1 inet manual bond-master bond1 bond-primary eth1 # Physical interface 3 auto eth2 iface eth2 inet manual bond-master bond0 # Physical interface 4 auto eth3 iface eth3 inet manual bond-master bond1 .. code-block:: yaml # Bond interface 0 (physical interfaces 1 and 3) auto bond0 iface bond0 inet static bond-slaves eth0 eth2 bond-mode active-backup bond-miimon 100 bond-downdelay 200 bond-updelay 200 address 10.240.0.21 netmask 255.255.252.0 gateway 10.240.0.1 dns-nameservers 69.20.0.164 69.20.0.196 # Bond interface 1 (physical interfaces 2 and 4) auto bond1 iface bond1 inet manual bond-slaves eth1 eth3 bond-mode active-backup bond-miimon 100 bond-downdelay 250 bond-updelay 250 # Container management VLAN interface iface bond0.10 inet manual vlan-raw-device bond0 # OpenStack Networking VXLAN (tunnel/overlay) VLAN interface iface bond1.30 inet manual vlan-raw-device bond1 # Storage network VLAN interface (optional) iface bond0.20 inet manual vlan-raw-device bond0 # Container management bridge auto br-mgmt iface br-mgmt inet static bridge_stp off bridge_waitport 0 bridge_fd 0 # Bridge port references tagged interface bridge_ports bond0.10 address 172.29.236.21 netmask 255.255.252.0 dns-nameservers 69.20.0.164 69.20.0.196 # OpenStack Networking VXLAN (tunnel/overlay) bridge auto br-vxlan address 172.29.240.21 address 172.29.244.21", Addresses: - Tunnel: 172.29.240.11 - Storage: 172.29.244.11**Figure 3.3. Target hosts for Compute service** .. image:: figures/networkarch-bare-external-example.png address 172.29.240.11 address 172.29.244.11,125,9
openstack%2Fkolla~master~I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e,openstack/kolla,master,I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e,Add Kibana quick start guide,MERGED,2016-04-14 18:38:20.000000000,2016-05-06 10:20:45.000000000,2016-05-06 10:20:45.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 14027}, {'_account_id': 15447}, {'_account_id': 16233}, {'_account_id': 16993}, {'_account_id': 17731}, {'_account_id': 19384}]","[{'number': 1, 'created': '2016-04-14 18:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b843b8b8a2282ac7badebdd43eb0b83ed69f2760', 'message': 'Add Kibana quick start quide\n\nIncludes basic information about how to search, visualize and analyse logs,\ncreate a Dashboard and export/import created items.\n\nCloses-bug 1570544\n\nChange-Id: I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e\n'}, {'number': 2, 'created': '2016-04-15 16:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4a7883edf1398aa9c9c579b1451d0a5cb4967604', 'message': 'Add Kibana quick start guide\n\nIncludes basic information about how to search, visualize and analyse logs,\ncreate a Dashboard and export/import created items.\n\nCloses-Bug #1570544\n\nChange-Id: I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e\n'}, {'number': 3, 'created': '2016-04-15 16:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b08f23b17949869c1b0a823af9c382209c8ca5c3', 'message': 'Add Kibana quick start guide\n\nIncludes basic information about how to search, visualize and analyse logs,\ncreate a Dashboard and export/import created items.\n\nCloses-Bug: #1570544\n\nChange-Id: I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e\n'}, {'number': 4, 'created': '2016-04-15 20:18:48.000000000', 'files': ['doc/quickstart.rst', 'doc/kibana-guide.rst', 'doc/index.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/732ef0e7154d72434f767d5eed09f14ec5e4b5a2', 'message': 'Add Kibana quick start guide\n\nIncludes basic information about how to search, visualize and analyse logs,\ncreate a Dashboard and export/import created items.\n\nCloses-Bug: #1570544\n\nChange-Id: I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e\n'}]",5,306019,732ef0e7154d72434f767d5eed09f14ec5e4b5a2,27,11,4,16620,,,0,"Add Kibana quick start guide

Includes basic information about how to search, visualize and analyse logs,
create a Dashboard and export/import created items.

Closes-Bug: #1570544

Change-Id: I70ce5d28a6bb719a94570d23e85d5ba4aa0b114e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/19/306019/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/kibana-start-guide.rst'],1,b843b8b8a2282ac7badebdd43eb0b83ed69f2760,bug/1570544,"How to setup and use Kibana - basic configuration ================================================= Default index pattern --------------------- After successful Kibana deployment, it can be accessed on {{ kolla_internal_vip_address }}:{{ kibana_server_port }} in any web browser. By default kibana_server_port is set to 5601. When Kibana is opened for the first time, it requires creating a default index pattern. To view, analyse and search logs, at least one index pattern has to be created. To match indices stored in ElasticSearch, we suggest to use following configuration: - Index contains time-based events - check - Use event times to create index names [DEPRECATED] - not checked - Index name or pattern - log-* - Do not expand index pattern when searching (Not recommended) - not checked - Time-field name - Timestamp After setting parameters, one can create an index with 'Create' button. Note: This step is necessary until the default Kibana dashboard is implemented in Kolla. Search logs - Discover tab -------------------------- Logs search is available under Discover tab. In the menu on the left side, one can choose any field that will be included in a new search. To do this, add button has to be pressed. This button appears after pointing any field from available ones. After adding a specific field, it is marked as selected field in the menu on the left. Search panel is updated automatically. To remove field from a current search, remove button has to be pressed. This button appears after pointing any field from selected ones. Current search can be saved by using 'Save search' option in the menu on the right. Visualize data - Visualize tab ------------------------------ In the visualization tab a wide range of charts is available. If any visualization has not been saved yet, after choosing this tab 'Create a new visualization' panel is opened. If a visualization has already been saved, after choosing this tab, lately modified visualization is opened. In this case, one can create a new visualization by choosing 'add visualization' option in the menu on the right. In order to create new visualization, one of the available options has to be chosen (pie chart, area chart). Each visualization can be created from a saved or a new search. After choosing any kind of search, a design panel is opened. In this panel, a chart can be generated and previewed. In the menu on the left, metrics for a chart can be chosen. The chart can be generated by pressing a green arrow on the top of the left-side menu. NOTE: After creating a visualization, it can be saved by choosing 'save visualization' option in the menu on the right. If it is not saved, it will be lost after leaving a page or creating another visualization. Organize visualizations and searches - Dashboard tab ---------------------------------------------------- In the Dashboard tab all of saved visualizations and searches can be organized in one Dashboard. To add visualization or search, one can choose 'add visualization' option in the menu on the right and then choose an item from all saved ones. The order and size of elements can be changed directly in this place by moving them or resizing. The color of charts can also be changed by checking a colorful dots on the legend near each visualization. NOTE: After creating a dashboard, it can be saved by choosing 'save dashboard' option in the menu on the right. If it is not saved, it will be lost after leaving a page or creating another dashboard. If a Dashboard has already been saved, it can be opened by choosing 'open dashboard' option in the menu on the right. Exporting and importing created items - Settings tab ------------------------------------------------------------ Once visualizations, searches or dashboards are created, they can be exported to a json format by choosing Settings tab and then Objects tab. Each of the item can be exported separately by selecting it in the menu. All of the items can also be exported at once by choosing 'export everything' option. In the same tab (Settings - Objects) one can also import saved items by choosing 'import' option. ",,85,0
openstack%2Ffuel-mirror~master~I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22,openstack/fuel-mirror,master,I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22,Expand the ignore cases,MERGED,2016-04-01 14:45:59.000000000,2016-05-06 10:06:05.000000000,2016-04-05 11:13:15.000000000,"[{'_account_id': 3}, {'_account_id': 7613}, {'_account_id': 8040}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-01 14:45:59.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/786564b9f628f4c70cbef08953a54427dc7598a1', 'message': 'Expand the ignore cases\n\n * perestroika/build-deb.sh & perestroika/build-rpm.sh\n   - Add variable ""ignore_list"" and use it for\n     expand the ignore cases\n * Add horizon-vendor-theme to ignores\n\nChange-Id: I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22\n'}]",0,300535,786564b9f628f4c70cbef08953a54427dc7598a1,16,7,1,14318,,,0,"Expand the ignore cases

 * perestroika/build-deb.sh & perestroika/build-rpm.sh
   - Add variable ""ignore_list"" and use it for
     expand the ignore cases
 * Add horizon-vendor-theme to ignores

Change-Id: I1c4f81e6a6f404ec71fee38ed9fd1d483a38cb22
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/35/300535/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,786564b9f628f4c70cbef08953a54427dc7598a1,," local ignore_list=""openstack-macros horizon-vendor-theme"" if [ $(echo $ignore_list | grep -Eo ""(^| )$PACKAGENAME( |$)"") ]; then"," if [ ""$PACKAGENAME"" == ""openstack-macros"" ]; then",4,2
openstack%2Ffuel-mirror~master~I02c308f8f79c12c6918a289eeb7d7d546b2366c2,openstack/fuel-mirror,master,I02c308f8f79c12c6918a289eeb7d7d546b2366c2,[build] Remove gitSHA suffix from CR packages,MERGED,2016-03-02 15:57:52.000000000,2016-05-06 10:05:57.000000000,2016-03-15 15:56:20.000000000,"[{'_account_id': 3}, {'_account_id': 7613}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 14348}]","[{'number': 1, 'created': '2016-03-02 15:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/db9cf08f570271f907799162b1d15b5f1027de8a', 'message': '[build] Remove gitSHA suffix from CR packages\n\n  - Remove gitSHA suffixes from revision part of verison strings of\n    openstack packages\n\n  - Do not increment revision for CR at specs projects\n\nChange-Id: I02c308f8f79c12c6918a289eeb7d7d546b2366c2\nCloses-Bug: #1533259\n'}, {'number': 2, 'created': '2016-03-15 13:59:33.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/02c439bc64c5ddbd80f7291691c6f2863aaca9f6', 'message': '[build] Remove gitSHA suffix from CR packages\n\n  - Remove gitSHA suffixes from revision part of verison strings of\n    openstack packages\n\n  - Do not increment revision for CR at specs projects\n\nChange-Id: I02c308f8f79c12c6918a289eeb7d7d546b2366c2\nCloses-Bug: #1533259\n'}]",0,287280,02c439bc64c5ddbd80f7291691c6f2863aaca9f6,16,5,2,9582,,,0,"[build] Remove gitSHA suffix from CR packages

  - Remove gitSHA suffixes from revision part of verison strings of
    openstack packages

  - Do not increment revision for CR at specs projects

Change-Id: I02c308f8f79c12c6918a289eeb7d7d546b2366c2
Closes-Bug: #1533259
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/80/287280/2 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,db9cf08f570271f907799162b1d15b5f1027de8a,bug/1533259," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] \ && [ ${GERRIT_PROJECT} == ""${SRC_PROJECT}"" ] \ && _rev=$(( $_rev + 1 ))"," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && _rev=$(( $_rev + 1 )) [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && release=""${release}.git.${gitshasrc}.${gitshaspec}""",6,4
openstack%2Fkolla~master~I053e54c54883318dfc7daa64a58276487805de66,openstack/kolla,master,I053e54c54883318dfc7daa64a58276487805de66,Add images from profile as matched only if no regex is used,MERGED,2016-05-06 08:20:22.000000000,2016-05-06 10:00:11.000000000,2016-05-06 10:00:10.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-05-06 08:20:22.000000000', 'files': ['kolla/cmd/build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6654cb1682d4dfa120a8196dfe93b1a120923909', 'message': 'Add images from profile as matched only if no regex is used\n\nChange-Id: I053e54c54883318dfc7daa64a58276487805de66\nCloses-Bug: 1578955\n'}]",0,313269,6654cb1682d4dfa120a8196dfe93b1a120923909,7,3,1,14027,,,0,"Add images from profile as matched only if no regex is used

Change-Id: I053e54c54883318dfc7daa64a58276487805de66
Closes-Bug: 1578955
",git fetch https://review.opendev.org/openstack/kolla refs/changes/69/313269/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/cmd/build.py'],1,6654cb1682d4dfa120a8196dfe93b1a120923909,bug/1578955, elif self.conf.profile:, if self.conf.profile:,1,2
openstack%2Fheat-specs~master~Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee,openstack/heat-specs,master,Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee,Support tempest plugin,MERGED,2016-03-28 09:19:39.000000000,2016-05-06 09:59:56.000000000,2016-05-06 09:59:56.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 17716}]","[{'number': 1, 'created': '2016-03-28 09:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/369810652f95f9b81190896c37df76d41ca99b3d', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 2, 'created': '2016-03-29 11:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/f0f587937e1a6fdb818c81606409de1a6cd89494', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 3, 'created': '2016-04-11 13:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/96a9ec194b970953bb4980e84fcf986b2bae6223', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 4, 'created': '2016-05-04 03:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/5c83824f18329aa6c6d75c30dadd104a691fafdf', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 5, 'created': '2016-05-04 03:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/b1f31d4c797000d376ebf062298058e7e4262093', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 6, 'created': '2016-05-05 03:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/1bafca3a602df8a4cb80bbd9545718a67cc6b50f', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}, {'number': 7, 'created': '2016-05-05 09:48:48.000000000', 'files': ['specs/newton/tempest-plugin-support.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/24d1c6c885bb23e6c1f884c8c3acaecf3db694c1', 'message': 'Support tempest plugin\n\nThis spec aims to add tempest plugin support in heat, and migrate\nexisting integration tests to run on tempest framework.\n\nChange-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee\nblueprint: tempest-plugin-support\n'}]",33,298160,24d1c6c885bb23e6c1f884c8c3acaecf3db694c1,39,10,7,7404,,,0,"Support tempest plugin

This spec aims to add tempest plugin support in heat, and migrate
existing integration tests to run on tempest framework.

Change-Id: Iba3b973e79479512f5fc7e891ad9c1c7aeffe9ee
blueprint: tempest-plugin-support
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/60/298160/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/newton/tempest-plugin-support.rst', 'specs/templates/newton-template.rst']",3,369810652f95f9b81190896c37df76d41ca99b3d,bp/tempest-plugin-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html =========================== The title of your blueprint =========================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/example Introduction paragraph -- why are we doing anything? Problem description =================== A detailed description of the problem. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Include where in the heat tree hierarchy this will reside. If your specification proposes any changes to the Heat REST API such as changing parameters which can be returned or accepted, or even the semantics of what happens when a client calls into the API, then you should add the APIImpact flag to the commit message. Specifications with the APIImpact flag can be found with the following query: https://review.openstack.org/#/q/status:open+project:openstack/heat-specs+message:apiimpact,n,z Alternatives ------------ This is an optional section, where it does apply we'd just like a demonstration that some thought has been put into why the proposed approach is the best one. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Can optionally can list additional ids if they intend on doing substantial implementation work on this blueprint. Milestones ---------- Target Milestone for completion: newton-1 Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ - Include specific references to specs and/or blueprints in heat, or in other projects, that this one either depends on or is related to. - Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? ",,196,0
openstack%2Fneutron~master~I923e415c1b8e9a431be89221c78c14f39c42c80f,openstack/neutron,master,I923e415c1b8e9a431be89221c78c14f39c42c80f,Add exponential back-off RPC client,MERGED,2016-02-16 10:36:38.000000000,2016-05-06 09:58:58.000000000,2016-05-06 02:37:46.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9200}, {'_account_id': 9551}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 11159}, {'_account_id': 11682}, {'_account_id': 12581}, {'_account_id': 12860}, {'_account_id': 12999}, {'_account_id': 13667}, {'_account_id': 13717}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 16707}, {'_account_id': 18289}]","[{'number': 1, 'created': '2016-02-16 10:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a2aa407646d6ab85737233302c22db362e90612', 'message': ""Add exponential back-off to RPC calls\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 2, 'created': '2016-03-08 05:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/117e3b738bea464a17aec4eae6cc30b8873f8569', 'message': ""Add exponential back-off to agent RPC calls\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a cieling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintoduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 3, 'created': '2016-03-08 06:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d7fdcaf54506b26a1bf26629e621d1f70b18192', 'message': ""Add exponential back-off to agent RPC calls\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 4, 'created': '2016-03-08 06:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c65b8b976d42a8fe8f8efa979a6078079d19f23a', 'message': ""Add exponential back-off to agent RPC calls\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 5, 'created': '2016-03-08 18:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3636b02a90ac8582a5c3dde19b44a67bf013334d', 'message': ""Add exponential back-off to agent RPC calls\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 6, 'created': '2016-03-12 01:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c0c5e2ec3bcbd6b37ed881dd1efb3fb74bb3ac2', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nThis is currently only available to agents that specifically request\nthis type of client via the get_backoff_client function in\nneutron.common.rpc. Once Newton opens it will become the default\nand assuming it doesn't show any major bugs it will be back-ported\nto replace Mitaka and possibly Liberty as well.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nPartial-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 7, 'created': '2016-03-14 07:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33221428bafc18f42c04f7f28bcd91010a0ee86e', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nThis is currently only available to agents that specifically request\nthis type of client via the get_backoff_client function in\nneutron.common.rpc. Once Newton opens it will become the default\nand assuming it doesn't show any major bugs it will be back-ported\nto replace Mitaka and possibly Liberty as well.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof the configured default timeout value * 10.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nPartial-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 8, 'created': '2016-04-12 01:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ddc84e2bdbe7a268e31d88881b0a463e4c07013', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 9, 'created': '2016-04-12 10:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14d1c78bd11a1090e96d94d18f6b2c711458137a', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 10, 'created': '2016-04-13 10:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/160cd3996436045382df1b91dcf3b10ab72c0253', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 11, 'created': '2016-04-15 17:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d4234424de588ef383ada62911675a5d98b0fb0', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 12, 'created': '2016-04-21 11:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dddd222f98de6739a1ddf258d51a94767b5012c3', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 13, 'created': '2016-04-23 09:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2fbd29fc261cca7b0f3a7955f75e786045fe7a9c', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}, {'number': 14, 'created': '2016-05-05 09:50:58.000000000', 'files': ['neutron/common/rpc.py', 'neutron/tests/unit/common/test_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e668b6a3720c1509ffef4ad5b91b4242dfd47b3', 'message': ""Add exponential back-off RPC client\n\nThis adds an exponential backoff mechanism for timeout values\non any RPC calls in Neutron that don't explicitly request a timeout\nvalue. This will prevent the clients from DDoSing the server by\ngiving up on requests and retrying them before they are fulfilled.\n\nEach RPC call method in each namespace gets its own timeout value since\nsome calls are expected to be much more expensive than others and we\ndon't want to modify the timeouts of cheap calls.\n\nThe backoff currently has no reduction mechanism under the assumption\nthat timeouts not legitimately caused by heavy system load\n(i.e. messages completely dropped by AMQP) are rare enough that the\ncost of shrinking the timeout back down and potentially causing\nanother server timeout isn't worth it. The timeout does have a ceiling\nof 10 times the configured default timeout value.\n\nWhenever a timeout exception occurs, the client will also sleep for a\nrandom value between 0 and the configured default timeout value to\nintroduce a splay across all of the agents that may be trying to\ncommunicate with the server.\n\nThis patch is intended to be uninvasive for candidacy to be\nback-ported. A larger refactor of delivering data to the agents\nis being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.\n\nCloses-Bug: #1554332\nChange-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f\n""}]",90,280595,3e668b6a3720c1509ffef4ad5b91b4242dfd47b3,241,39,14,7787,,,0,"Add exponential back-off RPC client

This adds an exponential backoff mechanism for timeout values
on any RPC calls in Neutron that don't explicitly request a timeout
value. This will prevent the clients from DDoSing the server by
giving up on requests and retrying them before they are fulfilled.

Each RPC call method in each namespace gets its own timeout value since
some calls are expected to be much more expensive than others and we
don't want to modify the timeouts of cheap calls.

The backoff currently has no reduction mechanism under the assumption
that timeouts not legitimately caused by heavy system load
(i.e. messages completely dropped by AMQP) are rare enough that the
cost of shrinking the timeout back down and potentially causing
another server timeout isn't worth it. The timeout does have a ceiling
of 10 times the configured default timeout value.

Whenever a timeout exception occurs, the client will also sleep for a
random value between 0 and the configured default timeout value to
introduce a splay across all of the agents that may be trying to
communicate with the server.

This patch is intended to be uninvasive for candidacy to be
back-ported. A larger refactor of delivering data to the agents
is being discussed in I3af200ad84483e6e1fe619d516ff20bc87041f7c.

Closes-Bug: #1554332
Change-Id: I923e415c1b8e9a431be89221c78c14f39c42c80f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/280595/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/rpc.py', 'neutron/tests/unit/common/test_rpc.py']",2,7a2aa407646d6ab85737233302c22db362e90612,bug/1554332,"import testtools @mock.patch.object(rpc, 'BackingOffClient')class TimeoutTestCase(base.DietTestCase): def setUp(self): super(TimeoutTestCase, self).setUp() self.messaging_conf = messaging_conffixture.ConfFixture(CONF) self.messaging_conf.transport_driver = 'fake' self.messaging_conf.response_timeout = 0 self.useFixture(self.messaging_conf) self.addCleanup(rpc.cleanup) rpc.init(CONF) rpc.TRANSPORT = mock.MagicMock() rpc.TRANSPORT._send.side_effect = messaging.MessagingTimeout target = messaging.Target(version='1.0', topic='testing') self.client = rpc.get_client(target) self.call_context = mock.Mock() def test_timeout_store_defaults(self): # any method should default to the configured timeout self.assertEqual(rpc.TRANSPORT.conf.rpc_response_timeout, rpc._METHOD_TIMEOUTS['method_1']) self.assertEqual(rpc.TRANSPORT.conf.rpc_response_timeout, rpc._METHOD_TIMEOUTS['method_2']) # a change to an existing should affect new or existing ones rpc._METHOD_TIMEOUTS['method_2'] = 7000 self.assertEqual(rpc.TRANSPORT.conf.rpc_response_timeout, rpc._METHOD_TIMEOUTS['method_1']) self.assertEqual(rpc.TRANSPORT.conf.rpc_response_timeout, rpc._METHOD_TIMEOUTS['method_3']) def test_method_timeout_increases_on_timeout_exception(self): rpc._METHOD_TIMEOUTS['method_1'] = 1 for i in range(5): with testtools.ExpectedException(messaging.MessagingTimeout): self.client.call(self.call_context, 'method_1') # we only care to check the timeouts sent to the transport timeouts = [call[1]['timeout'] for call in rpc.TRANSPORT._send.call_args_list] self.assertEqual([1, 2, 4, 8, 16], timeouts) def test_timeout_unchanged_on_other_exception(self): rpc._METHOD_TIMEOUTS['method_1'] = 1 rpc.TRANSPORT._send.side_effect = ValueError with testtools.ExpectedException(ValueError): self.client.call(self.call_context, 'method_1') rpc.TRANSPORT._send.side_effect = messaging.MessagingTimeout with testtools.ExpectedException(messaging.MessagingTimeout): self.client.call(self.call_context, 'method_1') timeouts = [call[1]['timeout'] for call in rpc.TRANSPORT._send.call_args_list] self.assertEqual([1, 1], timeouts) def test_timeouts_for_methods_tracked_independently(self): rpc._METHOD_TIMEOUTS['method_1'] = 1 rpc._METHOD_TIMEOUTS['method_2'] = 1 for method in ('method_1', 'method_1', 'method_2', 'method_1', 'method_2'): with testtools.ExpectedException(messaging.MessagingTimeout): self.client.call(self.call_context, method) timeouts = [call[1]['timeout'] for call in rpc.TRANSPORT._send.call_args_list] self.assertEqual([1, 2, 1, 4, 2], timeouts) def test_timeouts_for_namespaces_tracked_independently(self): rpc._METHOD_TIMEOUTS['ns1.method'] = 1 rpc._METHOD_TIMEOUTS['ns2.method'] = 1 for ns in ('ns1', 'ns2'): self.client.target.namespace = ns for i in range(4): with testtools.ExpectedException(messaging.MessagingTimeout): self.client.call(self.call_context, 'method') timeouts = [call[1]['timeout'] for call in rpc.TRANSPORT._send.call_args_list] self.assertEqual([1, 2, 4, 8, 1, 2, 4, 8], timeouts) def test_method_timeout_increases_with_prepare(self): rpc._METHOD_TIMEOUTS['method_1'] = 1 ctx = self.client.prepare(version='1.4') with testtools.ExpectedException(messaging.MessagingTimeout): ctx.call(self.call_context, 'method_1') with testtools.ExpectedException(messaging.MessagingTimeout): ctx.call(self.call_context, 'method_1') # we only care to check the timeouts sent to the transport timeouts = [call[1]['timeout'] for call in rpc.TRANSPORT._send.call_args_list] self.assertEqual([1, 2], timeouts) "," @mock.patch.object(messaging, 'RPCClient')",157,8
openstack%2Ffuel-mirror~stable%2F8.0~I222be69d28a2c1c43a1ef1e063696bf25ad15c10,openstack/fuel-mirror,stable/8.0,I222be69d28a2c1c43a1ef1e063696bf25ad15c10,[publisher] Implement custom repo path,MERGED,2016-04-28 11:28:07.000000000,2016-05-06 09:58:04.000000000,2016-05-06 09:57:56.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:28:07.000000000', 'files': ['perestroika/publisher.v5/publish-rpm-binaries.sh', 'perestroika/publisher.v5/publish-deb-binaries.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/33f71a0e94c420e648d44f79acae504cbe9302eb', 'message': '[publisher] Implement custom repo path\n\n   Use CUSTOM_REPO_ID variable to override default path for CR\n   repositories\n\nPartial-Bug: #1575171\n\nChange-Id: I222be69d28a2c1c43a1ef1e063696bf25ad15c10\nCloses-Bug: #1511757\n(cherry picked from commit 36fd222432445620888068feed7fdee3b9f96926)\n'}]",0,310741,33f71a0e94c420e648d44f79acae504cbe9302eb,14,6,1,12817,,,0,"[publisher] Implement custom repo path

   Use CUSTOM_REPO_ID variable to override default path for CR
   repositories

Partial-Bug: #1575171

Change-Id: I222be69d28a2c1c43a1ef1e063696bf25ad15c10
Closes-Bug: #1511757
(cherry picked from commit 36fd222432445620888068feed7fdee3b9f96926)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/41/310741/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/publisher.v5/publish-rpm-binaries.sh', 'perestroika/publisher.v5/publish-deb-binaries.sh']",2,33f71a0e94c420e648d44f79acae504cbe9302eb,bug/1575171," if [ -n ""${CUSTOM_REPO_ID}"" ] ; then unset LP_BUG REQUEST_NUM=${CUSTOM_REPO_ID} fi",,8,0
openstack%2Ffuel-mirror~stable%2F8.0~I8adcb6dc942c52830ef4a355d015742af9039cc3,openstack/fuel-mirror,stable/8.0,I8adcb6dc942c52830ef4a355d015742af9039cc3,Fix latest tag detection for openstack packages,MERGED,2016-04-28 11:28:20.000000000,2016-05-06 09:57:47.000000000,2016-05-06 09:57:39.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:28:20.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/f293c5e60957294ead39c72e466fe1a0e3056916', 'message': 'Fix latest tag detection for openstack packages\n\n  git-describe returns wrong tag for some openstack projects\n  Closes-Bug: #1541036\n\nPartial-Bug: #1575171\n\nChange-Id: I8adcb6dc942c52830ef4a355d015742af9039cc3\n(cherry picked from commit 12663742b8ab583ee6500bef8cc74209b67bcf6a)\n'}]",0,310742,f293c5e60957294ead39c72e466fe1a0e3056916,14,6,1,12817,,,0,"Fix latest tag detection for openstack packages

  git-describe returns wrong tag for some openstack projects
  Closes-Bug: #1541036

Partial-Bug: #1575171

Change-Id: I8adcb6dc942c52830ef4a355d015742af9039cc3
(cherry picked from commit 12663742b8ab583ee6500bef8cc74209b67bcf6a)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/42/310742/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,f293c5e60957294ead39c72e466fe1a0e3056916,bug/1575171, local release_tag=$(git -C $_srcpath describe --abbrev=0 --candidates=1), local release_tag=`git -C $_srcpath describe --abbrev=0`,2,2
openstack%2Ffuel-mirror~stable%2F8.0~I76b01cf78bd2a01f625f1e83743a700cb9acb6f5,openstack/fuel-mirror,stable/8.0,I76b01cf78bd2a01f625f1e83743a700cb9acb6f5,[build][deb] Fix tarball generation,MERGED,2016-04-28 11:29:08.000000000,2016-05-06 09:57:04.000000000,2016-05-06 09:56:57.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:29:08.000000000', 'files': ['perestroika/build-deb.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/59b0c3b442024ba6fb97c7b3b257105522d70298', 'message': '[build][deb] Fix tarball generation\n\n   Use `git-archive` instead of `tar` to creating source tarball\n   for MOS projects\n\nPartial-Bug: #1575171\n\nChange-Id: I76b01cf78bd2a01f625f1e83743a700cb9acb6f5\nRelated-Bug: #1541822\n(cherry picked from commit 5e7d068894ccf718af0b62af8b7283a3cc67b86f)\n'}]",0,310743,59b0c3b442024ba6fb97c7b3b257105522d70298,14,6,1,12817,,,0,"[build][deb] Fix tarball generation

   Use `git-archive` instead of `tar` to creating source tarball
   for MOS projects

Partial-Bug: #1575171

Change-Id: I76b01cf78bd2a01f625f1e83743a700cb9acb6f5
Related-Bug: #1541822
(cherry picked from commit 5e7d068894ccf718af0b62af8b7283a3cc67b86f)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/43/310743/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/build-deb.sh'],1,59b0c3b442024ba6fb97c7b3b257105522d70298,bug/1575171, cat > ${_srcpath}/.gitattributes <<-EOF /debian export-ignore /tests export-ignore /.gitignore export-ignore /.gitreview export-ignore EOF git -C ${_srcpath} archive --format tar.gz --worktree-attributes -o ${BUILDDIR}/${TAR_NAME} HEAD," mv ${_srcpath}/debian ${_srcpath}/renameforexcludedebian [ -d ""${_srcpath}/tests"" ] && mv ${_srcpath}/tests ${_srcpath}/renameforexcludetests pushd ${_srcpath} &>/dev/null tar -czf ""${BUILDDIR}/${TAR_NAME}"" $EXCLUDES --exclude=renameforexcludedebian --exclude=renameforexcludetests * popd &>/dev/null mv ${_srcpath}/renameforexcludedebian ${_srcpath}/debian [ -d ""${_srcpath}/renameforexcludetests"" ] && mv ${_srcpath}/renameforexcludetests ${_srcpath}/tests",7,7
openstack%2Ffuel-mirror~stable%2F8.0~I99c1e843f4369c6505a69ad1792659152f6872c0,openstack/fuel-mirror,stable/8.0,I99c1e843f4369c6505a69ad1792659152f6872c0,[build][rpm] Switch to latest epel release,MERGED,2016-04-28 11:29:39.000000000,2016-05-06 09:56:50.000000000,2016-05-06 09:56:42.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:29:39.000000000', 'files': ['perestroika/docker-builder/mockbuild/Dockerfile'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/292fb8cbcb76a4440a02139734f81712a26afadf', 'message': '[build][rpm] Switch to latest epel release\n\nCloses-Bug: #1571773\n\nPartial-Bug: #1575171\n\nChange-Id: I99c1e843f4369c6505a69ad1792659152f6872c0\n(cherry picked from commit 1d93085bb87ac948e45b4b09201b773f17cea8a3)\n'}]",0,310745,292fb8cbcb76a4440a02139734f81712a26afadf,14,6,1,12817,,,0,"[build][rpm] Switch to latest epel release

Closes-Bug: #1571773

Partial-Bug: #1575171

Change-Id: I99c1e843f4369c6505a69ad1792659152f6872c0
(cherry picked from commit 1d93085bb87ac948e45b4b09201b773f17cea8a3)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/45/310745/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/docker-builder/mockbuild/Dockerfile'],1,292fb8cbcb76a4440a02139734f81712a26afadf,bug/1575171,RUN yum -y --disableplugin=fastestmirror install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && \,RUN yum -y --disableplugin=fastestmirror install http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm && \,1,1
openstack%2Ffuel-mirror~stable%2F8.0~I4beb448d5b3073033cfa1df6580680cb9153fc66,openstack/fuel-mirror,stable/8.0,I4beb448d5b3073033cfa1df6580680cb9153fc66,[build] Do not include CR repositories at build stage,MERGED,2016-04-28 11:29:22.000000000,2016-05-06 09:56:21.000000000,2016-05-06 09:56:13.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:29:22.000000000', 'files': ['perestroika/build-fuel-deb.sh', 'perestroika/build-deb.sh', 'perestroika/build-rpm.sh', 'perestroika/build-fuel-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/a79627345afe38c5cfe1aec35ba710e24aa23d0e', 'message': '[build] Do not include CR repositories at build stage\n\nPartial-Bug: #1575171\n\nChange-Id: I4beb448d5b3073033cfa1df6580680cb9153fc66\nPartial-Bug: #1511757\n(cherry picked from commit 4af7fc2e9cccbb99ffd3651462bf2c4f1a5ef9c5)\n'}]",0,310744,a79627345afe38c5cfe1aec35ba710e24aa23d0e,14,6,1,12817,,,0,"[build] Do not include CR repositories at build stage

Partial-Bug: #1575171

Change-Id: I4beb448d5b3073033cfa1df6580680cb9153fc66
Partial-Bug: #1511757
(cherry picked from commit 4af7fc2e9cccbb99ffd3651462bf2c4f1a5ef9c5)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/44/310744/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-fuel-deb.sh', 'perestroika/build-deb.sh', 'perestroika/build-fuel-rpm.sh', 'perestroika/build-rpm.sh']",4,a79627345afe38c5cfe1aec35ba710e24aa23d0e,bug/1575171," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && [ ""$IS_UPDATES"" != ""true"" ] && [ -n ""$LP_BUG"" ] && \ [ ""$GERRIT_STATUS"" == ""NEW"" ] && [ ""$IS_UPDATES"" == ""true"" ] && [ -n ""$LP_BUG"" ] && \"," [ ""$GERRIT_CHANGE_STATUS"" == ""NEW"" ] && [ ""$IS_UPDATES"" != ""true"" ] && \ [ ""$GERRIT_STATUS"" == ""NEW"" ] && [ ""$IS_UPDATES"" == ""true"" ] && \",8,8
openstack%2Ftripleo-heat-templates~master~Ia0c201fd3b01cd524e096e6f246d707c6e643944,openstack/tripleo-heat-templates,master,Ia0c201fd3b01cd524e096e6f246d707c6e643944,Additional parameters for Nuage Neutron plugin integration,MERGED,2016-04-19 15:38:04.000000000,2016-05-06 09:43:48.000000000,2016-05-06 09:43:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7065}, {'_account_id': 10873}, {'_account_id': 11479}]","[{'number': 1, 'created': '2016-04-19 15:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/59d27716eee754bbc22261fbd47eed2ae454ae71', 'message': 'Additional parameters for Nuage Neutron plugin integration\n\nAdd additional parameters, specifically:\n\n* set core plugin to Nuage\n* disable service plugins\n* disable OVS, l3, metadata and DHCP agent\n* rename OVS bridge to alubr0\n* include Nuage API extensions\n\nChange-Id: Ia0c201fd3b01cd524e096e6f246d707c6e643944\n'}, {'number': 2, 'created': '2016-04-28 22:58:59.000000000', 'files': ['environments/neutron-nuage-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f29747ca85fa7515c6369e51869ac7f1d53e130', 'message': 'Additional parameters for Nuage Neutron plugin integration\n\nAdd additional parameters, specifically:\n\n* set core plugin to Nuage\n* disable service plugins\n* disable OVS, l3, metadata and DHCP agent\n* rename OVS bridge to alubr0\n* include Nuage API extensions\n\nChange-Id: Ia0c201fd3b01cd524e096e6f246d707c6e643944\n'}]",14,307884,1f29747ca85fa7515c6369e51869ac7f1d53e130,13,7,2,11479,,,0,"Additional parameters for Nuage Neutron plugin integration

Add additional parameters, specifically:

* set core plugin to Nuage
* disable service plugins
* disable OVS, l3, metadata and DHCP agent
* rename OVS bridge to alubr0
* include Nuage API extensions

Change-Id: Ia0c201fd3b01cd524e096e6f246d707c6e643944
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/307884/2 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-nuage-config.yaml', 'environments/nova-nuage-config.yaml']",2,59d27716eee754bbc22261fbd47eed2ae454ae71,, NovaComputeExtraConfig: nova::network::neutron::neutron_ovs_bridge: 'alubr0',,11,0
openstack%2Fswift~feature%2Fcrypto~I0c09cedfabe5093fea367e93652ee89cc44d7d2f,openstack/swift,feature/crypto,I0c09cedfabe5093fea367e93652ee89cc44d7d2f,crypto - only set body crypto meta if body is read and encrypted,MERGED,2016-04-14 12:21:17.000000000,2016-05-06 09:43:05.000000000,2016-05-06 09:43:05.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 12261}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-04-14 12:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ec4c05f6158837ac0094fe2e74c1bf38859bec4d', 'message': 'crypto - only set body crypto meta if body is read and encrypted\n\nCurrently if the object body has not been read then the\nencrypter footers callback will still set crypto_meta\nin sysmeta footers. That causes some of the copy-related\nfunctional test failures.\n\ne.g. a PUT with x-copy-from will read its input data\nfrom the target object (in proxy object controller)\nand read no data from the PUT request body. That\nactually works for an encrypted object while we have\na single key - the encrypted object and all its sysmeta\nis correctly copied. But the encrypter footers callback\nis then called and sets an etag for the empty string\nand also sets crypto meta that overwrites the correct\nsysmeta crypto_meta that was just copied.\n\nThis patch changes the footers callback to only set\ncrypto related footers if the object body actually\ngot read and encrypted. Similarly only replace any\nEtag in a PUT response if the body was encrypted.\n\nThis is not intended to solve the copy issues, it\nis simply defensive coding against unknown downstream\nbehaviour. The Put with x-copy-from example merely\nillustrates why it makes sense to not assume the body\nis always read.\n\nChange-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f\n'}, {'number': 2, 'created': '2016-04-18 12:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6ecdc6897d06ddc6dbeb4015074ad624d2dbc7c6', 'message': 'crypto - only set body crypto meta if body is read and encrypted\n\nCurrently if the object body has not been read then the\nencrypter footers callback will still set crypto_meta\nin sysmeta footers. That causes some of the copy-related\nfunctional test failures.\n\ne.g. a PUT with x-copy-from will read its input data\nfrom the source object (in proxy object controller)\nand read no data from the PUT request body. That copy\nactually works for an encrypted object while we have\na single key - the encrypted object and all its sysmeta\nis correctly copied. But the encrypter footers callback\nis then called and sets an etag for the empty string\nand also sets crypto meta that overwrites the correct\nsysmeta crypto_meta that was just copied.\n\nThis patch changes the footers callback to only set\ncrypto related footers if the object body actually\ngot read and encrypted. Similarly only replace any\nEtag in a PUT response if the body was encrypted.\n\nThis is not intended to solve the copy issues, it\nis simply defensive coding against unknown downstream\nbehaviour. The Put with x-copy-from example merely\nillustrates why it makes sense to not assume the body\nis always read.\n\nChange-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f\n'}, {'number': 3, 'created': '2016-04-18 14:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5ed98eaa5ab5d14fe4088786587036061f26c441', 'message': 'crypto - only set body crypto meta if body is read and encrypted\n\nCurrently if the object body has not been read then the\nencrypter footers callback will still set crypto_meta\nin sysmeta footers. That causes some of the copy-related\nfunctional test failures.\n\ne.g. a PUT with x-copy-from will read its input data\nfrom the source object (in proxy object controller)\nand read no data from the PUT request body. That copy\nactually works for an encrypted object while we have\na single key - the encrypted object and all its sysmeta\nis correctly copied. But the encrypter footers callback\nis then called and sets an etag for the empty string\nand also sets crypto meta that overwrites the correct\nsysmeta crypto_meta that was just copied.\n\nThis patch changes the footers callback to only set\ncrypto related footers if the object body actually\ngot read and encrypted. Similarly only replace any\nEtag in a PUT response if the body was encrypted.\n\nThis is not intended to solve the copy issues, it\nis simply defensive coding against unknown downstream\nbehaviour. The Put with x-copy-from example merely\nillustrates why it makes sense to not assume the body\nis always read.\n\nChange-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f\n'}, {'number': 4, 'created': '2016-04-21 03:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d065a094358c1b7468355838ad024ed4495b3bb', 'message': 'crypto - only set body crypto meta if body is read and encrypted\n\nCurrently if the object body has not been read then the\nencrypter footers callback will still set crypto_meta\nin sysmeta footers. That causes some of the copy-related\nfunctional test failures.\n\ne.g. a PUT with x-copy-from will read its input data\nfrom the source object (in proxy object controller)\nand read no data from the PUT request body. That copy\nactually works for an encrypted object while we have\na single key - the encrypted object and all its sysmeta\nis correctly copied. But the encrypter footers callback\nis then called and sets an etag for the empty string\nand also sets crypto meta that overwrites the correct\nsysmeta crypto_meta that was just copied.\n\nThis patch changes the footers callback to only set\ncrypto related footers if the object body actually\ngot read and encrypted. Similarly only replace any\nEtag in a PUT response if the body was encrypted.\n\nThis is not intended to solve the copy issues, it\nis simply defensive coding against unknown downstream\nbehaviour. The Put with x-copy-from example merely\nillustrates why it makes sense to not assume the body\nis always read.\n\nChange-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f\n'}, {'number': 5, 'created': '2016-05-05 10:22:29.000000000', 'files': ['swift/common/middleware/encrypter.py', 'test/unit/common/middleware/test_encrypter.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c55c8d6046cd86639103669654839d5224bd67ff', 'message': 'crypto - only set body crypto meta if body is read and encrypted\n\nCurrently if the object body has not been read then the\nencrypter footers callback will still set crypto_meta\nin sysmeta footers. That causes some of the copy-related\nfunctional test failures.\n\ne.g. a PUT with x-copy-from will read its input data\nfrom the source object (in proxy object controller)\nand read no data from the PUT request body. That copy\nactually works for an encrypted object while we have\na single key - the encrypted object and all its sysmeta\nis correctly copied. But the encrypter footers callback\nis then called and sets an etag for the empty string\nand also sets crypto meta that overwrites the correct\nsysmeta crypto_meta that was just copied.\n\nThis patch changes the footers callback to only set\ncrypto related footers if the object body actually\ngot read and encrypted. Similarly only replace any\nEtag in a PUT response if the body was encrypted.\n\nThis is not intended to solve the copy issues, it\nis simply defensive coding against unknown downstream\nbehaviour. The Put with x-copy-from example merely\nillustrates why it makes sense to not assume the body\nis always read.\n\nChange-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f\n'}]",10,305794,c55c8d6046cd86639103669654839d5224bd67ff,31,8,5,7847,,,0,"crypto - only set body crypto meta if body is read and encrypted

Currently if the object body has not been read then the
encrypter footers callback will still set crypto_meta
in sysmeta footers. That causes some of the copy-related
functional test failures.

e.g. a PUT with x-copy-from will read its input data
from the source object (in proxy object controller)
and read no data from the PUT request body. That copy
actually works for an encrypted object while we have
a single key - the encrypted object and all its sysmeta
is correctly copied. But the encrypter footers callback
is then called and sets an etag for the empty string
and also sets crypto meta that overwrites the correct
sysmeta crypto_meta that was just copied.

This patch changes the footers callback to only set
crypto related footers if the object body actually
got read and encrypted. Similarly only replace any
Etag in a PUT response if the body was encrypted.

This is not intended to solve the copy issues, it
is simply defensive coding against unknown downstream
behaviour. The Put with x-copy-from example merely
illustrates why it makes sense to not assume the body
is always read.

Change-Id: I0c09cedfabe5093fea367e93652ee89cc44d7d2f
",git fetch https://review.opendev.org/openstack/swift refs/changes/94/305794/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/encrypter.py', 'test/unit/common/middleware/test_encrypter.py']",2,ec4c05f6158837ac0094fe2e74c1bf38859bec4d,p-cr-encrypter-cleanup," def test_PUT_nothing_read(self): # simulate an artificial scenario of a downstream filter/app not # actually reading the input stream from encrypter. class NonReadingApp(object): def __call__(self, env, start_response): # note: no read form wsgi.input req = Request(env) env['swift.callback.update_footers'](req.headers) call_headers.append(req.headers) resp = HTTPCreated(req=req, headers={'Etag': 'response etag'}) return resp(env, start_response) env = {'REQUEST_METHOD': 'PUT', CRYPTO_KEY_CALLBACK: fetch_crypto_keys} hdrs = {'content-type': 'text/plain', 'content-length': 0, 'etag': 'etag from client'} req = Request.blank('/v1/a/c/o', environ=env, body='', headers=hdrs) call_headers = [] resp = req.get_response(encrypter.Encrypter(NonReadingApp(), {})) self.assertEqual('201 Created', resp.status) self.assertEqual('response etag', resp.headers['Etag']) self.assertEqual(1, len(call_headers)) self.assertEqual('etag from client', call_headers[0]['etag']) # verify no encryption footers for k in call_headers[0]: self.assertFalse(k.lower().startswith('x-object-sysmeta-crypto-')) # check that an upstream footer callback gets called other_footers = { 'Etag': 'other etag', 'X-Object-Sysmeta-Other': 'other sysmeta', 'X-Backend-Container-Update-Override-Etag': 'other override'} env.update({'swift.callback.update_footers': lambda footers: footers.update(other_footers)}) req = Request.blank('/v1/a/c/o', environ=env, body='', headers=hdrs) call_headers = [] resp = req.get_response(encrypter.Encrypter(NonReadingApp(), {})) self.assertEqual('201 Created', resp.status) self.assertEqual('response etag', resp.headers['Etag']) self.assertEqual(1, len(call_headers)) # verify that other middleware's footers made it to app for k, v in other_footers.items(): self.assertEqual(v, call_headers[0][k]) # verify no encryption footers for k in call_headers[0]: self.assertFalse(k.lower().startswith('x-object-sysmeta-crypto-')) ",,96,30
openstack%2Fhorizon~master~I1438dbb659001c1c468d8429dbea35d51e64dd7e,openstack/horizon,master,I1438dbb659001c1c468d8429dbea35d51e64dd7e,Further Theming fixes for Launch Instances,MERGED,2016-04-11 12:53:23.000000000,2016-05-06 09:41:12.000000000,2016-05-06 09:41:12.000000000,"[{'_account_id': 3}, {'_account_id': 9622}, {'_account_id': 11778}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-04-11 12:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bebad898cf9cd4dd14e2e8b798ccc13da5bb3d3f', 'message': 'Further Theming fixes for Launch Instances\n\n- Use actions_column, instead of action-col, for consistency\n- Use themable checkboxes instead of regular ones\n- Remove redundant SCSS\n- Remove some more *-sm classes\n- Fix colspans\n\nChange-Id: I1438dbb659001c1c468d8429dbea35d51e64dd7e\nCloses-Bug: 1568839\n'}, {'number': 2, 'created': '2016-04-11 13:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f3f6fe3b3b94c79b845543ac66c07009202e644b', 'message': 'Further Theming fixes for Launch Instances\n\n- Use actions_column, instead of action-col, for consistency\n- Use themable checkboxes instead of regular ones\n- Remove redundant SCSS\n- Remove some more *-sm classes\n- Fix colspans\n- Remove usage of ng-style\n\nChange-Id: I1438dbb659001c1c468d8429dbea35d51e64dd7e\nCloses-Bug: 1568839\n'}, {'number': 3, 'created': '2016-04-14 10:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce46d6d2dc7335d41df6cfddc1efc013c5cf2ea9', 'message': 'Further Theming fixes for Launch Instances\n\n- Use actions_column, instead of action-col, for consistency\n- Use themable checkboxes instead of regular ones\n- Remove redundant SCSS\n- Remove some more *-sm classes\n- Fix colspans\n- Remove usage of ng-style\n\nChange-Id: I1438dbb659001c1c468d8429dbea35d51e64dd7e\nCloses-Bug: 1568839\n'}, {'number': 4, 'created': '2016-05-02 05:51:07.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-groups.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair-details.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source-details.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/configuration/configuration.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-group-details.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.js', 'horizon/static/framework/widgets/table/table.scss', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/networkports/ports.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/flavor/flavor.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fd569dafaa0caea5aa4dad263de1d81dfab0e385', 'message': 'Further Theming fixes for Launch Instances\n\n- Use actions_column, instead of action-col, for consistency\n- Use themable checkboxes instead of regular ones\n- Remove redundant SCSS\n- Remove some more *-sm classes\n- Fix colspans\n- Remove usage of ng-style\n\nChange-Id: I1438dbb659001c1c468d8429dbea35d51e64dd7e\nCloses-Bug: 1568839\n'}]",2,304103,fd569dafaa0caea5aa4dad263de1d81dfab0e385,22,4,4,12826,,,0,"Further Theming fixes for Launch Instances

- Use actions_column, instead of action-col, for consistency
- Use themable checkboxes instead of regular ones
- Remove redundant SCSS
- Remove some more *-sm classes
- Fix colspans
- Remove usage of ng-style

Change-Id: I1438dbb659001c1c468d8429dbea35d51e64dd7e
Closes-Bug: 1568839
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/304103/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-groups.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair-details.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source-details.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/configuration/configuration.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-group-details.html', 'horizon/static/framework/widgets/table/table.scss', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/networkports/ports.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/flavor/select-flavor-table.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html']",11,bebad898cf9cd4dd14e2e8b798ccc13da5bb3d3f,bug/1568839," <td class=""actions_column""> <action action-classes=""'btn btn-default'"" <td class=""actions_column""> <action action-classes=""'btn btn-default'"" <td class=""detail"" colspan=""4"" ng-include=""ctrl.tableDetails"">"," <td class=""action-col""> <action action-classes=""'btn btn-sm btn-default'"" <td class=""action-col""> <action action-classes=""'btn btn-sm btn-default'"" <td></td> <td class=""detail"" colspan=""3"" ng-include=""ctrl.tableDetails"">",71,122
openstack%2Fkolla~master~I628414e4c66dd3eee160e6b5cbb261caa9af2f29,openstack/kolla,master,I628414e4c66dd3eee160e6b5cbb261caa9af2f29,Add missing core library to murano,ABANDONED,2015-09-30 11:29:54.000000000,2016-05-06 09:40:56.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 11105}, {'_account_id': 17478}]","[{'number': 1, 'created': '2015-09-30 11:29:54.000000000', 'files': ['docker/murano/murano-base/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/murano/murano-api/start.sh', 'ansible/roles/murano/tasks/bootstrap.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7e4314bf15bd8fcfae16af1e4de5b638ff21e8ac', 'message': 'Add missing core library to murano\n\nChange-Id: I628414e4c66dd3eee160e6b5cbb261caa9af2f29\n'}]",8,229372,7e4314bf15bd8fcfae16af1e4de5b638ff21e8ac,13,4,1,17478,,,0,"Add missing core library to murano

Change-Id: I628414e4c66dd3eee160e6b5cbb261caa9af2f29
",git fetch https://review.opendev.org/openstack/kolla refs/changes/72/229372/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'docker/murano/murano-base/Dockerfile.j2', 'docker/murano/murano-api/start.sh', 'ansible/roles/murano/tasks/bootstrap.yml']",4,7e4314bf15bd8fcfae16af1e4de5b638ff21e8ac,murano-core-library," OS_AUTH_URL: ""{{ openstack_auth_v2.auth_url }}"" OS_USERNAME: ""{{ openstack_auth_v2.username }}"" OS_PASSWORD: ""{{ openstack_auth_v2.password }}"" OS_TENANT_NAME: ""{{ openstack_auth_v2.project_name }}"" OS_VOLUME_API_VERSION: ""2""",,13,0
openstack%2Fha-guide~master~I26963cec9b3622841eaad2ca055d9392da74f180,openstack/ha-guide,master,I26963cec9b3622841eaad2ca055d9392da74f180,Bind keystone to the native IP of each host rather than VIP.,ABANDONED,2016-03-16 08:13:01.000000000,2016-05-06 09:40:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 8358}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 14151}, {'_account_id': 20003}]","[{'number': 1, 'created': '2016-03-16 08:13:01.000000000', 'files': ['doc/ha-guide/source/controller-ha-keystone.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/c52284c820391c24be10852e50192cd7aeb6de1e', 'message': 'Bind keystone to the native IP of each host rather than VIP.\n\nChange-Id: I26963cec9b3622841eaad2ca055d9392da74f180\nCloses-bug: #1518558\n'}]",0,293299,c52284c820391c24be10852e50192cd7aeb6de1e,8,7,1,8358,,,0,"Bind keystone to the native IP of each host rather than VIP.

Change-Id: I26963cec9b3622841eaad2ca055d9392da74f180
Closes-bug: #1518558
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/99/293299/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-keystone.rst'],1,c52284c820391c24be10852e50192cd7aeb6de1e,bug/1518558, bind_host = 10.0.0.12 public_bind_host = 10.0.0.12 admin_bind_host = 10.0.0.12, bind_host = 10.0.0.11 public_bind_host = 10.0.0.11 admin_bind_host = 10.0.0.11,3,3
openstack%2Fnova~master~I1476b2e364032d7c98f71df0cd61f1d1c19e005d,openstack/nova,master,I1476b2e364032d7c98f71df0cd61f1d1c19e005d,Remove the legacy v2 API entry from api-paste.ini,MERGED,2016-05-04 02:48:37.000000000,2016-05-06 09:40:21.000000000,2016-05-06 01:30:11.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-05-04 02:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/866455d8ac04012f6cd7245e8429532f9e782e18', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests already stopped to run against with legacy v2 API.\nThis patch remove the legacy V2 API entry from api-paste.ini.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}, {'number': 2, 'created': '2016-05-04 10:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee5497c637a441305fca8a3aee00fb61769089df', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests already stopped to run against with legacy v2 API.\nThis patch remove the legacy V2 API entry from api-paste.ini.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}, {'number': 3, 'created': '2016-05-04 12:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1942fe36bcd2a1fb704e4f20539060bd8a310a28', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests already stopped to run against with legacy\nv2 API. This patch removes the legacy V2 API entry from\napi-paste.ini, also removes piple factory method. This patch\nstops user to user legacy v2 API.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}, {'number': 4, 'created': '2016-05-04 14:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bca0f9c796443d4561b067c26a697fcd6cd8bed7', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests already stopped to run against with legacy\nv2 API. This patch removes the legacy V2 API entry from\napi-paste.ini, also removes piple factory method. This patch\nstops user to user legacy v2 API.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}, {'number': 5, 'created': '2016-05-05 01:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9715d793bfc1b47eae4a5ce1ad7bcf55121da14', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests and functional tests already stopped to\nrun against with legacy v2 API. This patch removes the legacy\nV2 API entry from api-paste.ini, it stops user from using\nlegacy V2 API. This patch also adds deprecated report in pipeline\nfactory method to notice the user update their api-paste.ini\nafter upgrade code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}, {'number': 6, 'created': '2016-05-05 10:51:13.000000000', 'files': ['nova/api/auth.py', 'nova/tests/unit/api/test_auth.py', 'etc/nova/api-paste.ini', 'releasenotes/notes/remove-legacy-v2-api-7ac6d74edaedf011.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/5a64f5782452d59d6ac25379a2420585e861af5a', 'message': 'Remove the legacy v2 API entry from api-paste.ini\n\nThe api sample tests and functional tests already stopped to\nrun against with legacy v2 API. This patch removes the legacy\nV2 API entry from api-paste.ini, it stops user from using\nlegacy V2 API. This patch also adds deprecated report in pipeline\nfactory method to notice the user update their api-paste.ini\nafter upgrade code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d\n'}]",12,312314,5a64f5782452d59d6ac25379a2420585e861af5a,93,17,6,5754,,,0,"Remove the legacy v2 API entry from api-paste.ini

The api sample tests and functional tests already stopped to
run against with legacy v2 API. This patch removes the legacy
V2 API entry from api-paste.ini, it stops user from using
legacy V2 API. This patch also adds deprecated report in pipeline
factory method to notice the user update their api-paste.ini
after upgrade code.

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: I1476b2e364032d7c98f71df0cd61f1d1c19e005d
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/312314/5 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/api-paste.ini'],1,866455d8ac04012f6cd7245e8429532f9e782e18,bp/remove-legacy-v2-api-code,,# starting in Liberty the v21 implementation replaces the v2 # implementation and is suggested that you use it as the default. If # this causes issues with your clients you can rollback to the # *frozen* v2 api by commenting out the above stanza and using the # following instead:: # /v2: openstack_compute_api_legacy_v2 # if rolling back to v2 fixes your issue please file a critical bug # at - https://bugs.launchpad.net/nova/+bugs ## NOTE: this is deprecated in favor of openstack_compute_api_v21_legacy_v2_compatible [composite:openstack_compute_api_legacy_v2] use = call:nova.api.auth:pipeline_factory noauth2 = cors compute_req_id faultwrap sizelimit noauth2 legacy_ratelimit osapi_compute_app_legacy_v2 keystone = cors compute_req_id faultwrap sizelimit authtoken keystonecontext legacy_ratelimit osapi_compute_app_legacy_v2 keystone_nolimit = cors compute_req_id faultwrap sizelimit authtoken keystonecontext osapi_compute_app_legacy_v2 ,0,16
openstack%2Fcinder~master~Ie92bae1ee3b874028e6d4c20894426563bedf4c4,openstack/cinder,master,Ie92bae1ee3b874028e6d4c20894426563bedf4c4,Updated from global requirements,MERGED,2016-04-28 16:10:40.000000000,2016-05-06 09:38:05.000000000,2016-05-05 17:21:26.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 9366}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15439}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-04-28 16:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a31dc51c8cc2ffc732ce98542bc2d207e2de7876', 'message': 'Updated from global requirements\n\nChange-Id: Ie92bae1ee3b874028e6d4c20894426563bedf4c4\n'}, {'number': 2, 'created': '2016-04-30 18:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3739a643abc8c4a5bf64af887b2356cf581216f0', 'message': 'Updated from global requirements\n\nChange-Id: Ie92bae1ee3b874028e6d4c20894426563bedf4c4\n'}, {'number': 3, 'created': '2016-05-03 15:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d75548d3c017326dea1089f81fa64c59f156b50f', 'message': 'Updated from global requirements\n\nChange-Id: Ie92bae1ee3b874028e6d4c20894426563bedf4c4\n'}, {'number': 4, 'created': '2016-05-04 22:06:31.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5291406058a6489749f1b3bb4a8d2da6de98a6e1', 'message': 'Updated from global requirements\n\nChange-Id: Ie92bae1ee3b874028e6d4c20894426563bedf4c4\n'}]",0,310827,5291406058a6489749f1b3bb4a8d2da6de98a6e1,146,44,4,11131,,,0,"Updated from global requirements

Change-Id: Ie92bae1ee3b874028e6d4c20894426563bedf4c4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/27/310827/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a31dc51c8cc2ffc732ce98542bc2d207e2de7876,openstack/requirements,bandit>=1.0.1 # Apache-2.0,bandit>=0.17.3 # Apache-2.0,1,1
openstack%2Ffuel-mirror~stable%2F8.0~I0de5ae65926bb7b2169207f57d7d29ecca8ab561,openstack/fuel-mirror,stable/8.0,I0de5ae65926bb7b2169207f57d7d29ecca8ab561,Change exception for non-python projects,MERGED,2016-04-28 11:26:41.000000000,2016-05-06 09:32:03.000000000,2016-05-06 09:31:56.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:26:41.000000000', 'files': ['perestroika/build-deb.sh', 'perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/e24fa3b8f5b364f935495cdcaa400ae4a9485db2', 'message': ""Change exception for non-python projects\n\n * removed murano-apps from exceptions (murano-apps doesn't requires any type of package)\n * add openstack-macros as exception , because of non-python project\n\nPartial-Bug: #1575171\n\nChange-Id: I0de5ae65926bb7b2169207f57d7d29ecca8ab561\n(cherry picked from commit 53e38992a0e88c69f5f423bc656c4419494f4b4c)\n""}]",0,310740,e24fa3b8f5b364f935495cdcaa400ae4a9485db2,14,6,1,12817,,,0,"Change exception for non-python projects

 * removed murano-apps from exceptions (murano-apps doesn't requires any type of package)
 * add openstack-macros as exception , because of non-python project

Partial-Bug: #1575171

Change-Id: I0de5ae65926bb7b2169207f57d7d29ecca8ab561
(cherry picked from commit 53e38992a0e88c69f5f423bc656c4419494f4b4c)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/40/310740/1 && git format-patch -1 --stdout FETCH_HEAD,"['perestroika/build-deb.sh', 'perestroika/build-rpm.sh']",2,e24fa3b8f5b364f935495cdcaa400ae4a9485db2,bug/1575171," if [ ""$PACKAGENAME"" == ""openstack-macros"" ]; then # Do not perform `setup.py sdist` for openstack-macros package"," if [ ""$PACKAGENAME"" == ""murano-apps"" ]; then # Do not perform `setup.py sdist` for murano-apps package",4,4
openstack%2Ffuel-mirror~stable%2F8.0~I8d1d4eb707b749c12f49bb7880bd0ef1a035e3ba,openstack/fuel-mirror,stable/8.0,I8d1d4eb707b749c12f49bb7880bd0ef1a035e3ba,RPM: Use non-converted git tag instead of package-friendly version,MERGED,2016-04-28 11:26:24.000000000,2016-05-06 09:31:56.000000000,2016-05-06 09:31:48.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 12817}, {'_account_id': 14689}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-28 11:26:24.000000000', 'files': ['perestroika/build-rpm.sh'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/095934bf9d6e758083bc2db9900218fe2277f12e', 'message': 'RPM: Use non-converted git tag instead of package-friendly version\n\nGit command should operate with original git tags, not the ones\nconverted by the convert_version.py script.\n\nPartial-Bug: #1575171\n\nChange-Id: I8d1d4eb707b749c12f49bb7880bd0ef1a035e3ba\nCloses-Bug: #1556114\n(cherry picked from commit 65ba5934ecd9679180b5412d8508f346f9c75c00)\n'}]",0,310738,095934bf9d6e758083bc2db9900218fe2277f12e,14,6,1,12817,,,0,"RPM: Use non-converted git tag instead of package-friendly version

Git command should operate with original git tags, not the ones
converted by the convert_version.py script.

Partial-Bug: #1575171

Change-Id: I8d1d4eb707b749c12f49bb7880bd0ef1a035e3ba
Closes-Bug: #1556114
(cherry picked from commit 65ba5934ecd9679180b5412d8508f346f9c75c00)
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/38/310738/1 && git format-patch -1 --stdout FETCH_HEAD,['perestroika/build-rpm.sh'],1,095934bf9d6e758083bc2db9900218fe2277f12e,bug/1575171, local _rev=$(git -C $_srcpath rev-list --no-merges ${release_tag}..origin/${SOURCE_BRANCH} | wc -l), local _rev=$(git -C $_srcpath rev-list --no-merges ${version}..origin/${SOURCE_BRANCH} | wc -l),1,1
openstack%2Ffuxi~master~I38bc022e96d12e61b96bb773539d13c85a04109e,openstack/fuxi,master,I38bc022e96d12e61b96bb773539d13c85a04109e,Delete code,MERGED,2016-05-06 08:17:41.000000000,2016-05-06 09:14:42.000000000,2016-05-06 09:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 11538}]","[{'number': 1, 'created': '2016-05-06 08:17:41.000000000', 'files': ['.testrepository/format', '.gitignore', '.testrepository/next-stream', 'fuxi/tests/__init__.pyc', '.testrepository/0', '.testrepository/failing', 'fuxi/tests/base.pyc', '.testrepository/times.dbm', 'fuxi/__init__.pyc', 'fuxi/tests/test_fuxi.pyc'], 'web_link': 'https://opendev.org/openstack/fuxi/commit/e986576ed26b475be1aaf8a282a8003a938999d0', 'message': 'Delete code\n\nChange-Id: I38bc022e96d12e61b96bb773539d13c85a04109e\n'}]",0,313268,e986576ed26b475be1aaf8a282a8003a938999d0,6,2,1,11538,,,0,"Delete code

Change-Id: I38bc022e96d12e61b96bb773539d13c85a04109e
",git fetch https://review.opendev.org/openstack/fuxi refs/changes/68/313268/1 && git format-patch -1 --stdout FETCH_HEAD,"['.testrepository/format', '.gitignore', '.testrepository/next-stream', 'fuxi/tests/__init__.pyc', '.testrepository/0', '.testrepository/failing', 'fuxi/tests/base.pyc', '.testrepository/times.dbm', 'fuxi/__init__.pyc', 'fuxi/tests/test_fuxi.pyc']",10,e986576ed26b475be1aaf8a282a8003a938999d0,framework,,,1,15
openstack%2Fmurano~master~I74309fc50fb57dad3b05220f797a4d28a22b7606,openstack/murano,master,I74309fc50fb57dad3b05220f797a4d28a22b7606,Fix tempest.conf generation,MERGED,2016-04-27 21:29:20.000000000,2016-05-06 09:00:47.000000000,2016-05-06 09:00:47.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-04-27 21:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/af02b813ee57a198bce678285d97428a7b65bbf1', 'message': 'Fix tempest.conf generation\n\nThe tempest.conf generation was missing the [service_available]\ngroup, therefore, it was impossible to activate murano. This patch\nfixes that.\n\nChange-Id: I74309fc50fb57dad3b05220f797a4d28a22b7606\n'}, {'number': 2, 'created': '2016-04-27 21:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6dfa52fe167c4683c13246121df63534121fe1d7', 'message': 'Fix tempest.conf generation\n\nThe tempest.conf generation was missing the [service_available]\ngroup, therefore, it was impossible to activate murano. This patch\nfixes that.\n\nChange-Id: I74309fc50fb57dad3b05220f797a4d28a22b7606\nCo-Author: Matthew Treinish\n'}, {'number': 3, 'created': '2016-04-28 03:35:29.000000000', 'files': ['murano_tempest_tests/plugin.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/675db9932307a7b8f872d34d4b67bc4302a26206', 'message': 'Fix tempest.conf generation\n\nThe tempest.conf generation was missing the [service_available]\ngroup, therefore, it was impossible to activate murano. This patch\nfixes that.\n\nChange-Id: I74309fc50fb57dad3b05220f797a4d28a22b7606\nCo-Author: Matthew Treinish\n'}]",1,310595,675db9932307a7b8f872d34d4b67bc4302a26206,32,8,3,6476,,,0,"Fix tempest.conf generation

The tempest.conf generation was missing the [service_available]
group, therefore, it was impossible to activate murano. This patch
fixes that.

Change-Id: I74309fc50fb57dad3b05220f797a4d28a22b7606
Co-Author: Matthew Treinish
",git fetch https://review.opendev.org/openstack/murano refs/changes/95/310595/1 && git format-patch -1 --stdout FETCH_HEAD,['murano_tempest_tests/plugin.py'],1,af02b813ee57a198bce678285d97428a7b65bbf1,fix-tempest.conf-generation," config_application_catalog.ServiceBrokerGroup), ('service_available', config_application_catalog.ServiceAvailableGroup)]", config_application_catalog.ServiceBrokerGroup)],2,1
openstack%2Ffuel-library~stable%2Fmitaka~I5fe7084c840c0ca390f5e5c677d1e4a6cd7f437c,openstack/fuel-library,stable/mitaka,I5fe7084c840c0ca390f5e5c677d1e4a6cd7f437c,Revert a chain of not finished mysql OCF RA fixes,ABANDONED,2016-05-05 09:16:53.000000000,2016-05-06 08:55:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7227}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 09:16:53.000000000', 'files': ['tests/noop/spec/hosts/database/database_spec.rb', 'deployment/puppet/osnailyfacter/manifests/database/database.pp', 'files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2f110b3030d4f388e26d427a303d59a06a48d37a', 'message': 'Revert a chain of not finished mysql OCF RA fixes\n\nThese below shall be reverted as have been backported\ntoo early. Resubmit those later, once fixed the chain\nof recently discovered issues in the master and CI\ngot stabilized.\n\nRevert ""Fix typo""\nThis reverts commit 9ab9264b8e6d5382728f752ac11cc49fbb159002.\n\nRevert ""MySQL OCF RA monitor to not race with SST in progress""\nThis reverts commit 472a213ca9bfec1e43456a9f19bdbc84c9307715.\n\nRevert ""Fix a race for the xtrabackup-v2 SST""\nThis reverts commit db6d56e60e18ea717db85c37a80dafcf9fbb6194.\n\nRevert ""Fix mysql ocf sst in progress tracking""\nThis reverts commit 19fe98b584a3e2916ce76ad61f4e6ebc6e5599ed.\n\nRevert ""Fix possible masters eval""\nThis reverts commit 1146a009f399b3d96bdf5aa2939288aa62ebbbf6.\n\nRevert ""Fix SST check for MySQL OCF RA""\nThis reverts commit aaebffd70689cbd9c45ad3b3e81e25e96ba57185.\n\nRevert ""Fix MySQL RA OCF vars\' local scopes""\nThis reverts commit 6667af69439578f4f909b4bde162f0a4cca325ab.\n\nChange-Id: I5fe7084c840c0ca390f5e5c677d1e4a6cd7f437c\n'}]",0,312872,2f110b3030d4f388e26d427a303d59a06a48d37a,16,8,1,6926,,,0,"Revert a chain of not finished mysql OCF RA fixes

These below shall be reverted as have been backported
too early. Resubmit those later, once fixed the chain
of recently discovered issues in the master and CI
got stabilized.

Revert ""Fix typo""
This reverts commit 9ab9264b8e6d5382728f752ac11cc49fbb159002.

Revert ""MySQL OCF RA monitor to not race with SST in progress""
This reverts commit 472a213ca9bfec1e43456a9f19bdbc84c9307715.

Revert ""Fix a race for the xtrabackup-v2 SST""
This reverts commit db6d56e60e18ea717db85c37a80dafcf9fbb6194.

Revert ""Fix mysql ocf sst in progress tracking""
This reverts commit 19fe98b584a3e2916ce76ad61f4e6ebc6e5599ed.

Revert ""Fix possible masters eval""
This reverts commit 1146a009f399b3d96bdf5aa2939288aa62ebbbf6.

Revert ""Fix SST check for MySQL OCF RA""
This reverts commit aaebffd70689cbd9c45ad3b3e81e25e96ba57185.

Revert ""Fix MySQL RA OCF vars' local scopes""
This reverts commit 6667af69439578f4f909b4bde162f0a4cca325ab.

Change-Id: I5fe7084c840c0ca390f5e5c677d1e4a6cd7f437c
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/72/312872/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/noop/spec/hosts/database/database_spec.rb', 'deployment/puppet/osnailyfacter/manifests/database/database.pp', 'files/fuel-ha-utils/ocf/mysql-wss']",3,2f110b3030d4f388e26d427a303d59a06a48d37a,revert_party," echo $1 | grep -q -E '^\w{8}-\w{4}-\w{4}-\w{4}-\w{12}:([[:digit:]]|-1)' if [ -z ${GTID} ]; then local rcchoose_master() { local LH=""${LL} choose_master():"" local NODES=$1 local -A TMP for NODE in $NODES; do NODE_ID=$(echo $NODE | md5sum | awk '{print $1}') TMP[$NODE_ID]=$NODE done MASTER=$(printf -- '%s\n' ""${!TMP[@]}"" | sort | head -1) if [ -z $MASTER ] then ocf_log err ""${LH} No master picked."" fi ocf_log info ""${LH} Choosed master: ${TMP[$MASTER]}"" echo ${TMP[$MASTER]} } get_possible_masters() { local LH=""${LL} get_possible_masters()"" TMP[$NODE]=$(echo $GTID|cut -d"":"" -f 2) MASTER_GTID=$(printf -- '%s\n' ""${TMP[@]}"" | sort -r | head -1) if [ $MASTER_GTID -eq ${TMP[$NODE]} ]; then ocf_log info ""${LH} Possible masters: $POSSIBLE_MASTERS"" echo $POSSIBLE_MASTERS local MASTERS MASTERS=$(get_possible_masters ""$NODES"") MASTER=$(choose_master ""$MASTERS"") if [ -f ""${OCF_RESKEY_datadir}""/sst_in_progress ]; then ocf_log $loglevel ""${LH} SST is in progress"" return $OCF_SUCCESS fi # Spin waiting for the server to come up. update_node_gtid"," echo $1 | grep -q -E '^\w{8}-\w{4}-\w{4}-\w{4}-\w{12}:([[:digit:]]+|-1)$' local CLUSTER_ID local COMMIT_ID if [ -z ""${GTID}"" ]; thenget_master() { local LH=""${LL} get_master()"" local NODE local NODE_SCORE local LATEST_SEQNO=-1 local SEQNO local MASTER # Form a hash of keys as node names, values as GTID:SEQNO # Cut the seqno off the GTID:SEQNO pairs TMP[$NODE]=$GTID # Find possible masters # Cut the seqnums off the stored GTID:SEQNO pairs, then find the most seen GTID for the nodes MASTER_GTID=$(printf -- '%s\n' ""${TMP[@]%:*}"" | sort | uniq -c | awk '{print $2}' | head -1) ocf_log info ""${LH} The most seen GTID is: ${MASTER_GTID}"" ocf_log info ""${LH} Node's ${NODE} score: ${NODE_SCORE}, GTID/SEQNUM: ${TMP[$NODE]}"" # Filter node names with the most seen GTID as possible masters and find the latest SEQNO if [ ""${MASTER_GTID}"" = ""${TMP[$NODE]%:*}"" ]; then SEQNO=${TMP[$NODE]#*:} [ $SEQNO -gt $LATEST_SEQNO ] && LATEST_SEQNO=$SEQNO ocf_log info ""${LH} Possible masters: $POSSIBLE_MASTERS"" # Cut the gtids off the stored GTID:SEQNO pairs, then # filter the master, which is one who has the latest SEQNO from the possible masters for NODE in $POSSIBLE_MASTERS; do [ ""${LATEST_SEQNO}"" = ""${TMP[$NODE]#*:}"" ] && MASTER=$NODE done ocf_log info ""${LH} Choosed master: ${MASTER} with GTID: ${TMP[$MASTER]}"" echo ""$MASTER"" local MASTER MASTER=$(get_master ""$NODES"")check_if_sst() { local LH=""${LL} check_if_sst():"" local loglevel=${1:-'info'} if [ -f ""${OCF_RESKEY_datadir}/sst_in_progress"" -a ! -f ""${OCF_RESKEY_datadir}/ibdata1"" ]; then ocf_log $loglevel ""${LH} SST is in progress"" return $OCF_SUCCESS fi return $OCF_ERR_GENERIC } local pid local rc2 check_if_sst rc2=$? if [ $rc2 -eq $OCF_SUCCESS -a $rc -ne $OCF_SUCCESS ] ; then # The sst_in_progress file isn't removed if mysqld has died and shall be purged ocf_log warn ""${LH} found and purged a stale sst_in_progress file"" rm -f ""${OCF_RESKEY_datadir}/sst_in_progress"" elif [ $rc2 -eq $OCF_SUCCESS ]; then return $OCF_SUCCESS fi local socket_dir local pid_dir local rc local dir local mysql_extra_params # Spin waiting for the server to come up or exit, if SST's in progress check_if_sst rc=$? [ $rc -eq $OCF_SUCCESS ] && break [ $rc -ne $OCF_SUCCESS ] && update_node_gtid",39,86
openstack%2Ffuel-library~master~I3d0d376e6bef3ccc3e738731b71f4dd60a59e653,openstack/fuel-library,master,I3d0d376e6bef3ccc3e738731b71f4dd60a59e653,"Rework SST check, fix possible masters search",MERGED,2016-05-05 12:04:25.000000000,2016-05-06 08:45:01.000000000,2016-05-06 08:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 12:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5173d714287f6c0ce14449be0e313ccf212d1309', 'message': 'Rework SST check, fix possible masters search\n\n* Fix racing of monitoring with SST\n* Fix printf multilines sorting\n  Expected:  printf -- \'%s\\n\' ${a} | sort -u (returns a sorted multiline)\n  Actuacl: printf -- \'%s\\n\' ""$a"" | sort -u (returns a single string)\n(Those two blocks each other in CI and must be fixed at once)\n\nCloses-bug: # 1574999\nCloses-bug: # 1578278\n\nChange-Id: I3d0d376e6bef3ccc3e738731b71f4dd60a59e653\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2016-05-05 12:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/927506c1f70874de641fe7d4d1997a4239084b25', 'message': 'Rework SST check, fix possible masters search\n\n* Fix racing of monitoring with SST\n* Fix printf multilines sorting\n  Expected:  printf -- \'%s\\n\' ${a} | sort -u (returns a sorted multiline)\n  Actuacl: printf -- \'%s\\n\' ""$a"" | sort -u (returns a single string)\n(Those two blocks each other in CI and must be fixed at once)\n\nCloses-bug: #1574999\nCloses-bug: #1578278\n\nChange-Id: I3d0d376e6bef3ccc3e738731b71f4dd60a59e653\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2016-05-05 13:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/da3ccd67d332c0fa175fec18c893776bd248576c', 'message': 'Rework SST check, fix possible masters search\n\n* Fix racing of monitoring with SST\n* Fix printf multilines sorting\n  Expected:  printf -- \'%s\\n\' ${a} | sort -u (returns a sorted multiline)\n  Actuacl: printf -- \'%s\\n\' ""$a"" | sort -u (returns a single string)\n(Those two blocks each other in CI and must be fixed at once)\n\nCloses-bug: #1574999\nCloses-bug: #1578278\n\nChange-Id: I3d0d376e6bef3ccc3e738731b71f4dd60a59e653\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2016-05-05 14:16:06.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/03991059adcc99989431c27f38c5ffa4ae35b486', 'message': 'Rework SST check, fix possible masters search\n\n* Fix racing of monitoring with SST\n* Fix printf multilines sorting\n  Expected:  printf -- \'%s\\n\' ${a} | sort -u (returns a sorted multiline)\n  Actuacl: printf -- \'%s\\n\' ""$a"" | sort -u (returns a single string)\n* Fix possible masters search, by the greatest SEQNO found for a\n  magority UUID\n(Those blocks each other in CI and must be fixed at once)\n\nCloses-bug: #1574999\nCloses-bug: #1578278\nCloses-bug: #1388779\n\nChange-Id: I3d0d376e6bef3ccc3e738731b71f4dd60a59e653\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",2,312911,03991059adcc99989431c27f38c5ffa4ae35b486,82,20,4,6926,,,0,"Rework SST check, fix possible masters search

* Fix racing of monitoring with SST
* Fix printf multilines sorting
  Expected:  printf -- '%s\n' ${a} | sort -u (returns a sorted multiline)
  Actuacl: printf -- '%s\n' ""$a"" | sort -u (returns a single string)
* Fix possible masters search, by the greatest SEQNO found for a
  magority UUID
(Those blocks each other in CI and must be fixed at once)

Closes-bug: #1574999
Closes-bug: #1578278
Closes-bug: #1388779

Change-Id: I3d0d376e6bef3ccc3e738731b71f4dd60a59e653
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/11/312911/4 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,5173d714287f6c0ce14449be0e313ccf212d1309,bug/1578278,"OCF_RESKEY_streamfmt_default=""xbstream"" OCF_RESKEY_transferfmt_default=""socat"": ${OCF_RESKEY_streamfmt=${OCF_RESKEY_streamfmt_default}} : ${OCF_RESKEY_transferfmt=${OCF_RESKEY_transferfmt_default}} <parameter name=""streamfmt"" unique=""0"" required=""0""> <longdesc lang=""en""> The streamfmt setting for xtrabackup-v2 SST config </longdesc> <shortdesc lang=""en"">SST streamfmt</shortdesc> <content type=""string"" default=""${OCF_RESKEY_streamfmt_default}""/> </parameter> <parameter name=""transferfmt"" unique=""0"" required=""0""> <longdesc lang=""en""> The transferfmt setting for xtrabackup-v2 SST config </longdesc> <shortdesc lang=""en"">SST transferfmt</shortdesc> <content type=""string"" default=""${OCF_RESKEY_transferfmt_default}""/> </parameter> NODES=$(printf -- '%s\n' ${NODES} | sort -u) MASTER_GTID=$(printf -- '%s\n' ${TMP[@]%:*} | grep -vE ""^0$"" | sort | uniq -c | awk '{print $2}' | head -1) local pid local pid2 local pid3 local pid4 # Match a mysqld pid by the datadir, exclude position recovery pid=$(ps -C mysqld -o pid= -o args= | grep ""${OCF_RESKEY_datadir}"" | awk '!/wsrep.recover/ {print $1}') if [ ""${pid}"" ] ; then if [ $? -eq 0 ]; then ocf_log info ""${LH} MySQL process ${pid} found"" # Myslqd's running and may be blocked, check for signs of SST pid2=$(ps -C ${OCF_RESKEY_streamfmt} -o pid= -o command= | awk '!/defunct/ {print $1}') pid3=$(ps -C ${OCF_RESKEY_transferfmt} -o pid= -o command= | awk '!/defunct/ {print $1}') pid4=$(ps -C innobackupex -o pid= -o command= | awk '!/defunct/ {print $1}') if [ ""${pid2}"" -o ""${pid3}"" -o ""${pid4}"" ]; then ocf_log $loglevel ""${LH} SST is in progress"" return $OCF_SUCCESS fi fi ocf_log $loglevel ""${LH} No signs of SST found"" ocf_log info ""${LH} MySQL PID found"" break"," NODES=$(printf -- '%s\n' ""${NODES}"" | sort -u) MASTER_GTID=$(printf -- '%s\n' ""${TMP[@]%:*}"" | grep -vE ""^0$"" | sort | uniq -c | awk '{print $2}' | head -1) if [ -f ""${OCF_RESKEY_datadir}/sst_in_progress"" -a ! -f ""${OCF_RESKEY_datadir}/ibdata1"" ]; then ocf_log $loglevel ""${LH} SST is in progress"" return $OCF_SUCCESSdummy_test(){ $MYSQL $MYSQL_OPTIONS_TEST -s -N -e ""select 1;"" > /dev/null } dummy_test if [ $? -eq 0 ]; then ocf_log info ""${LH} MySQL PID found and looks healthy"" break fi fi # Match a mysqld pid by the datadir, exclude position recovery pid=$(ps -C mysqld -o pid= -o args= | awk -v v=""${OCF_RESKEY_datadir}"" \ '/datadir='$v'/ { if ($1 ~ !/wsrep-recover/) print $1}') if [ ""${pid}"" ] ; then dummy_test if [ $? -eq 0 ]; then ocf_log info ""${LH} MySQL process ${pid} found and looks healthy"" return $OCF_SUCCESS fi",41,25
openstack%2Fproject-config~master~I1b1408fe8a5de46e9df2611d11158562d4723713,openstack/project-config,master,I1b1408fe8a5de46e9df2611d11158562d4723713,Setup propose-puppet-openstack-constraints properly,MERGED,2016-05-06 08:27:11.000000000,2016-05-06 08:40:32.000000000,2016-05-06 08:40:31.000000000,"[{'_account_id': 3}, {'_account_id': 6133}]","[{'number': 1, 'created': '2016-05-06 08:27:11.000000000', 'files': ['zuul/openstack_functions.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9ba75427047f407e84e2a5ab297702481ed28314', 'message': 'Setup propose-puppet-openstack-constraints properly\n\nDo not offline the proposal slave after\npropose-puppet-openstack-constraints is run: Enhance proposal regex for\nthis.\n\nChange-Id: I1b1408fe8a5de46e9df2611d11158562d4723713\n'}]",0,313271,9ba75427047f407e84e2a5ab297702481ed28314,6,2,1,6547,,,0,"Setup propose-puppet-openstack-constraints properly

Do not offline the proposal slave after
propose-puppet-openstack-constraints is run: Enhance proposal regex for
this.

Change-Id: I1b1408fe8a5de46e9df2611d11158562d4723713
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/313271/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/openstack_functions.py'],1,9ba75427047f407e84e2a5ab297702481ed28314,offline-proposal, proposal_re = r'^.*(merge-release-tags|(propose|upstream)-(.*?)-(constraints-.*|updates?|update-(liberty|mitaka)|plugins-list|openstack-constraints))$' # noqa, proposal_re = r'^.*(merge-release-tags|(propose|upstream)-(.*?)-(constraints-.*|updates?|update-(liberty|mitaka)|plugins-list))$' # noqa,1,1
openstack%2Fdragonflow~master~I2d3b9093483747f05ea4ee25f4ab0f4a08b90249,openstack/dragonflow,master,I2d3b9093483747f05ea4ee25f4ab0f4a08b90249,Let connection to FIP obey security group rules,MERGED,2016-04-26 09:56:28.000000000,2016-05-06 08:29:37.000000000,2016-05-06 08:29:37.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 18811}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-04-26 09:56:28.000000000', 'files': ['dragonflow/controller/dnat_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/31a7d74c77e778919b8154a81a90de6c4f8e7686', 'message': 'Let connection to FIP obey security group rules\n\nAccording current codes in dnat_app.app, connections to FIP skip\nINGRESS_CONNTRACK_TABLE table and can directly reach at VM port.\nThis patch will fix that bug.\n\nCloses-Bug:  1569903\n\n Changes to be committed:\n\tmodified:   dragonflow/controller/dnat_app.py\n\nChange-Id: I2d3b9093483747f05ea4ee25f4ab0f4a08b90249\n'}]",1,310156,31a7d74c77e778919b8154a81a90de6c4f8e7686,11,6,1,21007,,,0,"Let connection to FIP obey security group rules

According current codes in dnat_app.app, connections to FIP skip
INGRESS_CONNTRACK_TABLE table and can directly reach at VM port.
This patch will fix that bug.

Closes-Bug:  1569903

 Changes to be committed:
	modified:   dragonflow/controller/dnat_app.py

Change-Id: I2d3b9093483747f05ea4ee25f4ab0f4a08b90249
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/56/310156/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/dnat_app.py'],1,31a7d74c77e778919b8154a81a90de6c4f8e7686,bug/1569903," tunnel_key = lport.get_tunnel_key() network_id = lport.get_external_value('local_network_id') return (mac, ip, tunnel_key, network_id, segmentation_id) vm_mac, vm_ip, vm_tunnel_key, network_id, _ = \ self._get_vm_port_info(floatingip) parser.OFPActionSetField(reg7=vm_tunnel_key), parser.OFPActionSetField(metadata=network_id) ] action_inst = parser.OFPInstructionActions( ofproto.OFPIT_APPLY_ACTIONS, actions) goto_inst = parser.OFPInstructionGotoTable( const.INGRESS_CONNTRACK_TABLE) inst = [action_inst, goto_inst] _, vm_ip, _, _, segmentation_id = self._get_vm_port_info(floatingip)"," ofport = lport.get_external_value('ofport') return (mac, ip, ofport, segmentation_id) vm_mac, vm_ip, vm_ofport, _ = self._get_vm_port_info(floatingip) parser.OFPActionOutput(vm_ofport, 0)] inst = [self.get_datapath().ofproto_parser.OFPInstructionActions( ofproto.OFPIT_APPLY_ACTIONS, actions)] _, vm_ip, _, segmentation_id = self._get_vm_port_info(floatingip)",14,7
openstack%2Fswift~master~I3b07ff0222aba6293ad7d60afe1747acafbe6ce4,openstack/swift,master,I3b07ff0222aba6293ad7d60afe1747acafbe6ce4,Use smaller quorum size in proxy for even numbers of replicas,MERGED,2016-04-27 22:31:59.000000000,2016-05-06 08:29:22.000000000,2016-05-06 08:29:21.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 5600}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 12193}]","[{'number': 1, 'created': '2016-04-27 22:31:59.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'swift/container/updater.py', 'test/unit/proxy/controllers/test_account.py', 'swift/common/utils.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/proxy/controllers/test_base.py', 'swift/container/replicator.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/29544a9e175b1ec9e0dbfd5288edc00a1402d5ca', 'message': ""Use smaller quorum size in proxy for even numbers of replicas\n\nRequiring 2/2 backends for PUT requests means that the cluster can't\ntolerate a single failure. Likewise, if you have 4 replicas in 2\nregions, requiring 3/4 on a POST request means you cannot POST with\nyour inter-region link down or congested.\n\nThis changes the (replication) quorum size in the proxy to be at least\nhalf the nodes instead of a majority of the nodes.\n\nDaemons that were looking for a majority remain unchanged. The\ncontainer reconciler, replicator, and updater still require majorities\nso their functioning is unchanged.\n\nOdd numbers of replicas are unaffected by this commit.\n\nChange-Id: I3b07ff0222aba6293ad7d60afe1747acafbe6ce4\n""}]",0,310608,29544a9e175b1ec9e0dbfd5288edc00a1402d5ca,9,6,1,2622,,,0,"Use smaller quorum size in proxy for even numbers of replicas

Requiring 2/2 backends for PUT requests means that the cluster can't
tolerate a single failure. Likewise, if you have 4 replicas in 2
regions, requiring 3/4 on a POST request means you cannot POST with
your inter-region link down or congested.

This changes the (replication) quorum size in the proxy to be at least
half the nodes instead of a majority of the nodes.

Daemons that were looking for a majority remain unchanged. The
container reconciler, replicator, and updater still require majorities
so their functioning is unchanged.

Odd numbers of replicas are unaffected by this commit.

Change-Id: I3b07ff0222aba6293ad7d60afe1747acafbe6ce4
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/310608/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/updater.py', 'test/unit/common/test_storage_policy.py', 'swift/common/utils.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/proxy/controllers/test_base.py', 'swift/container/replicator.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py']",9,29544a9e175b1ec9e0dbfd5288edc00a1402d5ca,smaller-quorum," def test_quorum_size(self): expected_sizes = {1: 1, 2: 1, 3: 2, 4: 2, 5: 3} got_sizes = dict([(n, utils.quorum_size(n)) for n in expected_sizes]) self.assertEqual(expected_sizes, got_sizes) def test_majority_size(self): got_sizes = dict([(n, utils.majority_size(n))"," def test_replication_quorum_size(self): got_sizes = dict([(n, utils.quorum_size(n))",65,48
openstack%2Fceilometer~master~I421c5b3084d7ff4d2bd6ab43a7a8a477d4a2c560,openstack/ceilometer,master,I421c5b3084d7ff4d2bd6ab43a7a8a477d4a2c560,Remove unused pylintrc,MERGED,2016-05-02 22:05:55.000000000,2016-05-06 08:17:28.000000000,2016-05-06 08:17:28.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 8290}, {'_account_id': 10987}]","[{'number': 1, 'created': '2016-05-02 22:05:55.000000000', 'files': ['tools/lintstack.py', 'pylintrc', '.gitignore', 'test-requirements.txt', 'tools/lintstack.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/25cd1d2385336b5fbeb0c6b5c5f4d634f1a9d062', 'message': ""Remove unused pylintrc\n\nWe never used that in the gate and it's unmaintained. Clean that.\n\nChange-Id: I421c5b3084d7ff4d2bd6ab43a7a8a477d4a2c560\n""}]",0,311874,25cd1d2385336b5fbeb0c6b5c5f4d634f1a9d062,25,6,1,1669,,,0,"Remove unused pylintrc

We never used that in the gate and it's unmaintained. Clean that.

Change-Id: I421c5b3084d7ff4d2bd6ab43a7a8a477d4a2c560
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/74/311874/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/lintstack.py', 'pylintrc', '.gitignore', 'test-requirements.txt', 'tools/lintstack.sh', 'tox.ini']",6,25cd1d2385336b5fbeb0c6b5c5f4d634f1a9d062,jd/remove-pylint,,[testenv:pylint] commands = bash tools/lintstack.sh ,0,313
openstack%2Fswift~master~Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9,openstack/swift,master,Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9,Rework the contributor docs,MERGED,2016-04-05 18:57:04.000000000,2016-05-06 08:16:33.000000000,2016-05-06 08:16:32.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 5600}, {'_account_id': 7847}, {'_account_id': 12193}, {'_account_id': 12261}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 16365}, {'_account_id': 18838}]","[{'number': 1, 'created': '2016-04-05 18:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b260bc75a94aacf27de0566d9aca3fd1f794e39', 'message': 'Added new contributor walkthrough doc\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 2, 'created': '2016-04-05 21:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bf90ca9353e755d91c6fecd0e13c4f1bad50b4dd', 'message': 'Added new contributor walkthrough doc\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 3, 'created': '2016-04-06 00:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/74afb748c129006ba7376a66377b3d79d374c9c6', 'message': 'Added new contributor walkthrough doc\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 4, 'created': '2016-04-06 19:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6047fdf5e1c9b5e8634d04a1ee5d64587f1e8bc4', 'message': 'Rework the contributor docs\n\nThis started as a new ""new_contributor"" doc. But we\'ve already got\nat least 3 different docs like that.\n\nCurrently this WIP is consolidating those documents and giving them\na more natural flow.\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 5, 'created': '2016-04-07 00:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c579af7f7fa4009885f1472704be15c4c8b1da34', 'message': 'Rework the contributor docs\n\nThis started as a new ""new_contributor"" doc. But we\'ve already got\nat least 3 different docs like that.\n\nCurrently this WIP is consolidating those documents and giving them\na more natural flow.\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 6, 'created': '2016-05-05 23:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/27eee255d001cea13e838e7f886bb3b4f3516fd5', 'message': 'Rework the contributor docs\n\nThis started as a new ""new_contributor"" doc. But we\'ve already got\nat least 3 different docs like that.\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}, {'number': 7, 'created': '2016-05-06 05:02:54.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/6827affe62771949a041d958db17ba6cd29232ab', 'message': 'Rework the contributor docs\n\nThis started as a new ""new_contributor"" doc. But we\'ve already got\nat least 3 different docs like that.\n\nChange-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9\n'}]",42,301871,6827affe62771949a041d958db17ba6cd29232ab,45,11,7,330,,,0,"Rework the contributor docs

This started as a new ""new_contributor"" doc. But we've already got
at least 3 different docs like that.

Change-Id: Ia2303ab55eeea01cc71acbccaeab55dad0ef5ff9
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/301871/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/new_contributor.rst']",2,7b260bc75a94aacf27de0566d9aca3fd1f794e39,contrib_docs_rework,"=========================== New Contributor Walkthrough =========================== This is a story about a new contributor fixing a bug in Swift. It's used as an example, and the bug that's described has already been fixed. Overall, I think you should block about 2 hours for this, since it's the first time you're setting this up. ---- *fade in from black* Our hero, a web app developer sits at her computer typing furiously. She wants to learn about Swift's CORS support. She's a website developer, and you know this is an important way to enable your web apps to work across different domain names. In fact, if Swift supports CORS, then she can offload a whole bunch of hard work to Swift (where she wants to store data anyway) and focus more on writing an awesome web app. A quick google search later, and she goes to http://docs.openstack.org/developer/swift/cors.html to read about Swift's support for this. Horror of horrors! She sees two terrible errors in the very first paragraph: a spelling error and a grammar error. Unacceptable! With a mounting sense of disgust, she abandons all plans to use Swift. (Meanwhile, her competitors who did use Swift succeed wildly in the market and sell out for 3 billion dollars. Since they use Swift for data storage, they don't have to worry about hard problems of storage and can focus on making awesome apps. Our hero was forced to solve many hard sotrage problems instead of adding features and polish to her app.) *fade to black* Let's help her out! Let's fix these small docs errors and save our hero's future. First, you need to set up a dev environment. Don't worry! It's simple. But we need to do it so you can test your changes locally and easily share them with others. Note: I'm assuming you have a Mac, so that's how I've written these instructions. The easiest way to get a Swift dev environment is to use vagrant-swift-all-in-one. But first you need some tools.: 1. Get VirtualBox. VirtualBox is a way you can run VMs on your Mac. https://www.virtualbox.org/wiki/Downloads Be sure to download the one ""for OS X hosts"". 2. Get Vagrant. Vagrant is a way to easily automate setting up VMs in VirtualBox. https://www.vagrantup.com/downloads.html 3. Get git. git is a source control system that lets you track changes over time. http://git-scm.com One you have those installed, you'll be ready to set up the dev environment. I'm not sure how familiar you are with command line stuff, so I've made this very detailed. If you already know all this, please forgive me. Open up your Terminal.app. (cmd+space, type in terminal and hit return) Type in:: cd Desktop Now, get vagrant-swift-all-in-one:: git clone https://github.com/swiftstack/vagrant-swift-all-in-one.git At this point, you'll have noticed that you have a new folder on your desktop. Next, move to the new directory:: cd vagrant-swift-all-in-one Last, start up the dev environment:: vagrant up --provision This step will take a while (5-10 minutes). When it's done, you won't see anything different, but you'll have a VM running that has Swift on it. Once that finishes, you'll be ready to get started. First, let's set up the docs building so you can see what you're working on. Type in:: vagrant ssh cd swift autodoc When the autodoc command finishes running, it will give you a URL. It probably looks something like http://saio:8080/v1/AUTH_test/doc/index.html. Change the ""saio"" in that URL to 192.168.8.80 and then open that in a browser (http://192.168.8.80:8080/v1/AUTH_test/doc/index.html). This is the current state of the docs, and it will automatically be rebuild when you make a change to a file and save it. Ok, now that you've got that set up and running, we can leave it running in the background. We'll come back to it later. Now it's time to start making changes to the docs. The CORS docs live in Swift's source code repo. Part of the Vagrant-Swift-All-In-One setup downloaded a current version of Swift's source code. This is where we'll make our changes to fix the bug. In your terminal app, push cmd+T to make a new tab. Then, type:: cd Desktop/vagrant-swift-all-in-one/swift Let's set up an area where you can do work that won't interfere with other people's work (and vice-versa). In source control, this is called a ""branch"". You work on a branch, then your changes are merged into ""master"". :: git checkout -b fix_docs That set up a local branch called ""fix_docs"" and set your local environment to use it. Now any edits you do won't be affected by what other people in the community are doing. Now, open up the right file in a text editor. You're looking for ""doc/source/cors.rst"". Doesn't really matter what text editor you use, but if I can make a recommendation, here are a few that would probably work better than the built-in TextEdit app: http://www.sublimetext.com What I use. very powerful, pretty easy to use, will nag you until you pay money, but you can use it for free. http://www.barebones.com/products/textwrangler/ Pretty simple, I used it years ago, it's free. https://www.peterborgapps.com/smultron/ What someone else in the office recommended. I've not used it, but it looks ok. You've got the right file open, so go fix the errors. *typey, typey* Ok! Now you've fixed the errors! Time to test it and submit it upstream for review. It's always important to test your changes locally before you push them upstream. You want to make sure that you've fixed the issue and everything still works before you submit it for other people to review. To test a docs change, you'll need to rebuild the docs and see if they look right. Remember the ""autodoc"" stuff above? It takes care of all of this. Switch back to your browser, hit reload, and look for your changes. They look good, so let's submit it upstream. First, you'll need one more OpenStack-provided tool. :: sudo pip install git-review git review -s You'll be asked for your computer password on the first step and for your gerrit username on the second. Gerrit is the code review system that we use for every OpenStack project. Gerrit uses Launchpad for its user accounts. Go to https://launchpad.net and sign up. The user name you choose is what you'll type in where it's asking for your gerrit username. Next, you need to ""save"" your work locally. You do this with the following command:: git commit -a A text editor will open, and you'll be prompted to write a commit message. There's a good guideline on writing commit messages at http://chris.beams.io/posts/git-commit/. Write a commit message to describe the change you made. Save your changes, and exit the text editor. Now, you're ready to push your changes to gerrit (the code review tool). :: git review If this is your first time submitting code to an OpenStack project, you'll be prompted to sign the CLA. After that, run ``git review`` again. Now you're done (for now). Reviewers will look at it and leave comments if anything is amiss. If it looks good, it will be approved, and our fearless web app developer hero will not lose to the competition and she'll cash out with billions! *voice over as credits roll* Our culture like to praise the web app developers who cash out with billions as the hero. But that's not possible without building on awesome infrastructure and open-source projects. So who's the real hero? It's you. *fade to black* **Fin.** Epilogue -------- The last thing to thing about is how to turn this all off to go back to your normal day job. You probably have a text editor open, the web browser, and the terminal app with a couple of tabs. In the terminal tab where you have autodoc running, type ``control+c``. This will stop the autodoc process. Then type ``control+d`` to get out of the dev environment VM. Then type ``vagrant destroy`` to fully delete the dev environment VM and recover any space on your computer. If you don't want to delete everything, ``vagrant halt``. In both cases, ``vagrant up`` (from the top of these instructions) will bring it back up. If you ""halt"" instead of ""destroy"", then the ""up"" command is faster. When you're done with everything, definitely use ``vagrant destroy`` to recover the hard drive space. Then type ``control+d`` to close the terminal session. In the other terminal tab, type ``control+d`` to close the session. Once you have the terminal tabs, you can quit the Terminal app and go on with your day. ",,219,0
openstack%2Fheat~stable%2Fmitaka~I610a863c3912ebab90901f02467f6e7957338b36,openstack/heat,stable/mitaka,I610a863c3912ebab90901f02467f6e7957338b36,Imported Translations from Zanata,MERGED,2016-05-06 07:12:10.000000000,2016-05-06 08:04:59.000000000,2016-05-06 08:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 6577}]","[{'number': 1, 'created': '2016-05-06 07:12:10.000000000', 'files': ['heat/locale/es/LC_MESSAGES/heat.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/1fd4fd4c5129578775e27adfe0f8d85dbccacc6d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I610a863c3912ebab90901f02467f6e7957338b36\n'}]",0,313255,1fd4fd4c5129578775e27adfe0f8d85dbccacc6d,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I610a863c3912ebab90901f02467f6e7957338b36
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/313255/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/locale/es/LC_MESSAGES/heat.po'],1,1fd4fd4c5129578775e27adfe0f8d85dbccacc6d,zanata/translations,"""Project-Id-Version: heat 6.0.1.dev10\n""""POT-Creation-Date: 2016-05-05 07:24+0000\n""""PO-Revision-Date: 2016-05-05 12:09+0000\n""msgstr ""Una lista de clsteres a los que est conectada esta poltica.""""Una lista de polticas de cadena a aplicar. El valor predeterminado es anti-"" ""afinidad.""""Las claves son nombres de archivo y los valores son los contenidos de "" ""archivo.""""Una cuota por arrendatario sobre el espacio de prefijo que se puede asignar "" ""desde la agrupacin de subred para subredes de arrendatarios.""msgstr ""Una cadena especificada de servidores DNS a utilizar.""""Una cadena que especifica un nombre simblico para el grupo de seguridad, "" ""que no es necesario que sea exclusivo.""msgstr ""Estado administrativo del servicio vpn.""msgstr ""Permitir o denegar una accin para esta regla de cortafuegos.""""Permitir no almacenar los resultados de la accin tras completar la tarea.""""Metadatos de claves/valores arbitrarios a almacenar para este servidor. Las "" ""claves y los valores deben tener 255 caracteres o menos. Los valores que no "" ""sean de tipo cadena se serializarn en JSON (y la cadena serializada debe "" ""tener 255 caracteres o menos).""""Metadatos arbitrarios de pares clave/valor para almacenar informacin del "" ""agregado.""msgstr ""El algoritmo hash de autenticacin de la poltica ike.""msgstr ""El algoritmo hash de autenticacin de la poltica ipsec.""msgstr ""Bloquear las correlaciones de dispositivo de este servidor.""""predeterminado si se omite.""msgstr ""Notacin de bloque CIDR de esta subred.""""Atributo de conveniencia para captar la primera direccin de red asignada a ""msgstr ""Punto de restauracin de la instancia de base de datos.""msgstr ""Direccin IP DNS utilizada dentro de la red del arrendatario.""msgstr ""Tamao del volumen de base datos en GB.""""Define si el motor Mistral debe poner el flujo de trabajo en espera o no ""msgstr ""Suprimiendo la instantnea en curso""msgstr ""Descripcin del servicio vpn.""""Seccin de tipo diccionario que define las polticas de tarea que influyen ""msgstr ""Algoritmo de cifrado de la poltica ike.""msgstr ""Algoritmo de cifrado de la poltica ipsec.""msgstr ""Direccin final de la agrupacin de asignaciones.""msgstr ""Finalizar el redimensionamiento del grupo %(group)s""""Parmetros adicionales a incluir en el objeto \""floatingip\"" en la solicitud "" ""de creacin. Normalmente los parmetros son especficos del hardware o de "" ""las extensiones instalados.""msgstr ""Nombre fcil de usar de la subred.""""La forma en que los datos de usuario se deben formatear para el servidor. ""msgstr ""ID del arrendatario propietario del supervisor de estado.""msgstr ""ID o nombre del equilibrador de carga al que est asociado el escucha.""msgstr ""Indique si el volumen se debe suprimir cuando se finaliza el servidor.""msgstr ""Versin de Ip de la subred.""msgstr """" ""Los elementos a unir deben ser de tipo cadena, correlacin o lista y no %s""""Lista de bases de datos que se deben crear durante la creacin de instancias "" ""de base de datos.""msgstr ""Lista de interfaces de red a crear en la instancia.""""Lista de usuarios que se deben crear durante la creacin de instancias de "" ""base de datos.""""adems de con el meter_name.""msgstr ""Nombre de la poltica ike.""msgstr ""Nombre del servicio vpn.""msgstr ""Nombre de la zona de disponibilidad para la colocacin del servidor.""""Nombre o UUID del puerto de Neutron al que conectar este NIC. Se tiene que """"Nombre o UUID de la red a la que conectar este NIC. Se tiene que especificar """"Nombres de las bases de datos a las que esos usuarios pueden acceder durante "" ""la creacin de instancias.""msgstr ""Modalidad de negociacin de la poltica ike.""msgstr ""Red a partir de la cual se asigna la IP flotante.""msgstr ""Nmero de periodos sobre los que evaluar.""msgstr """" ""Operador utilizado para comparar estadsticas especficas con el umbral.""msgstr ""Contrasea para esos usuarios durante la creacin de instancias.""msgstr ""Secreto de reenvo perfecto de la poltica ipsec.""msgstr ""Secreto de reenvo perfecto en minsculas de la poltica ike.""msgstr ""Periodo (segundos) sobre el que evaluar.""msgstr ""No se ha creado el recurso""""Configuracin del tiempo de vida de evaluacin de seguridad de la poltica """"Configuracin de tiempo de vida de evaluacin de seguridad de la poltica """"Valor del tiempo de vida de evaluacin de seguridad en las unidades "" ""especificadas.""""Esquema que representa las salidas que producir esta configuracin de "" ""software.""msgstr """" ""A los grupos de seguridad no se les puede asignar el nombre \""default\"".""msgstr """" ""Usuario o grupo del servicio de seguridad utilizado por el arrendatario.""msgstr ""Nombre del grupo de servidores.""""Establezca en \""vpc\"" para tener la asignacin de direccin IP asociada a su "" ""VPC.""""Establecer a true si DHCP est habilitado y a false si est deshabilitado.""""Especifica nombres de base de datos para crear bases de datos durante la "" ""creacin de instancias.""msgstr ""Direccin de inicio de la agrupacin de asignaciones.""msgstr ""Iniciar el redimensionamiento del grupo %(group)s""""El ID del arrendatario propietario del equilibrador de carga. Slo los "" ""usuarios administrativos pueden especificar un ID de arrendatario distinto "" ""del suyo propio.""msgstr ""ID del arrendatario propietario del escucha.""""El ID del arrendatario propietario de la red. Slo los usuarios "" ""administrativos pueden especificar un ID de arrendatario distinto del suyo "" ""propio.""""El ID del arrendatario propietario de la agrupacin de subred. Slo los "" ""usuarios administrativos pueden especificar un ID de arrendatario distinto "" ""del suyo propio.""""El ID del volumen desde el que se debe iniciar. Se debe proporcionar solo "" ""uno de estos dos: volume_id o snapshot_id. ""msgstr ""El ID o nombre de la imagen con la que arrancar.""msgstr ""La version IP, que puede ser 4 o 6.""msgstr ""El destino de la ruta esttica.""msgstr ""La red interna a la que conectar en la pasarela de red.""""el protocolo es ICMP, este valor debe ser de tipo ICMP.""""seguridad. Si el protocolo es TCP o UDP, este valor debe ser menor que o "" ""igual al valor del atributo port_range_max. Si el protocolo es ICMP, este ""msgstr ""El nmero de nodos maestros para esta baha.""""El ID de arrendatario propietario del mbito de direccin. Slo los usuarios "" ""administrativos pueden especificar un ID de arrendatario distinto del suyo """"El ID de arrendatario propietario. Solo es necesario si el interlocutor "" ""tiene un rol administrativo y desea crear un RBAC para otro arrendatario.""""El protocolo que ha coincidido con la regla del grupo de seguridad. Los "" ""valores vlidos incluyen tcp, udp y icmp.""""El prefijo del IP remote (CIDR) a asociador a esta regla de grupo de """"La identidad del direccionador de bifurcacin remoto de la conexin del "" ""sitio ipsec.""""de seguridad para el remote_group_id. El parmetro de modalidad remota "" ""deber establecerse en \""remote_group_id\"".""msgstr ""Direccionador en el que se insertar el servicio vpn.""""La configuracin del tiempo de vida de evaluacin de seguridad de la ""msgstr """" ""Las direcciones iniciales y finales de las agrupaciones de asignaciones.""msgstr ""Umbral contra el que evaluar.""""True si el sistema debe recordar una clave privada generada; False en los "" ""dems casos.""""Identificador exclusivo para el direccionador en que se insertar el "" ""servicio vpn.""""\""{get_attr: [<server name>, networks, <network name>, 0]}\""""msgstr ""Datos de usuario a pasar a la instancia.""msgstr """" ""Nombre de usuario para crear un usuario durante la creacin de instancias.""msgstr ""El valor debe ser un JSON vlido: %s""msgstr ""Versin de la poltica ike.""msgstr ""Peso del miembro de agrupacin.""""Si se debe compartir el mbito de direccin con otros arrendatarios. Tenga "" ""en cuenta que el valor de poltica predeterminado restringe el uso de este """"Si se compartir esta agrupacin de subred entre todos los arrendatarios. "" ""Tenga en cuenta que el valor de poltica predeterminado restringe el uso de "" ""este atributo solo a usuarios administrativos.""msgstr ""Si se debe especificar o no un grupo remoto o un prefijo de IP remota.""""no se puede especificar segmentation_id, excepto si el valor es 0 para "" ""utilizarlo plano""","""Project-Id-Version: heat 6.0.1.dev9\n""""POT-Creation-Date: 2016-05-04 01:21+0000\n""""PO-Revision-Date: 2016-05-04 04:52+0000\n""msgstr ""Una lista de clsteres a los que esta conectada esta poltica.""""Una lista de polticas de cadena a aplicar. Valores predeterminados para "" ""anti-afinidad.""""Las claves son nombres de archivo y los valores son el contenido de archivo.""""Una cuota por inquilino sobre el espacio de prefijo que se puede asignar "" ""desde la agrupacin de subred para subredes de inquilinos.""msgstr ""Una cadena especificada de servidores DNS para ser utilizados.""""Una cadena especificando un nombre simblico para el grupo de seguridad, que "" ""no es necesario que sea nico.""msgstr ""Estado administrativo para el servicio vpn.""msgstr ""Permitir o denegar accin para esta regla de cortafuegos.""""Permitiendo no almacenar los resultados de la accin tras completar la tarea.""""Metadatos de clavees/valores arbitrarios a almacenar para este servidor. Las "" ""claves y los valores deben tener 255 caracteres o menos. Los valores no de "" ""cadena se serializarn en JSON (y la cadena serializada debe tener 255 "" ""caracteres o menos).""""Metadatos arbitrarios de pares clave/valor para almacenar informacin para "" ""el agregado.""msgstr ""El algoritmo hash de autenticacin para la poltica ike.""msgstr ""El algoritmo hash de autenticacin para la poltica ipsec.""msgstr ""Correlaciones de dispositivo de bloque para este servidor.""""predeterminado si est omitido.""msgstr ""Notacin de bloque CIDR para esta subred.""""Atributo de conveniencia para captar la primera direccin de red asignada o ""msgstr ""Punto de restauracin de instancia de base de datos.""msgstr ""Direccin IP DNS utilizada dentro de la red del inquilino.""msgstr ""Tamao de volumen de base datos en GB.""""Define si el el motor Mistral debe poner el flujo de trabajo en espera o no ""msgstr ""Suprimiento la instantnea en curso""msgstr ""Descripcin para el servicio vpn.""""Seccin de tipo diccionario que define las piltocas de tarea que influyen ""msgstr ""Algoritmo de cifrado para la poltica ike.""msgstr ""Algoritmo de cifrado para la poltica ipsec.""msgstr ""Direccin final de la agrupacin de asignacin.""msgstr ""Finalizar redimensionamiento del grupo %(group)s""""Parmetros adicionales a incluir el objeto \""floatingip\"" en la solicitud de "" ""creacin. Normalmente los parmetros son especficos del hardware o de las "" ""extensiones instalados.""msgstr ""Nombre familir de la subred.""""La manera en que los datos de usuario se deben formatear para el servidor. ""msgstr ""ID del inquilino propietario del supervisor de estado.""msgstr """" ""ID o nombre del equilibrador de carga con el que est asociado el escucha.""msgstr ""Indique si el volumen se debe suprimir cuando el servidor se termina.""msgstr ""Versin de Ip para la subred.""msgstr ""Los elementos a unir deben de tipo cadena, correlacin o lista y no %s""""Lista de bases de datos que se deben crear en creacin de instancias de base "" ""de datos.""msgstr ""Lista de interfaces de red para crear en instancia.""""Lista de usuarios que se deben crear en creacin de instancias de base de "" ""datos.""""adicionalmente al meter_name.""msgstr ""Nombre para la poltica ike.""msgstr ""Nombre para el servicio vpn.""msgstr ""Nombre de la zona de disponibilidad para la colocacin de servidor.""""Nombre o UUID del puerto de Neutron al que conectar este NIC. Es necesario """"Nombre o UUID de la red a la que conectar este NIC. Es necesario especificar """"Nombres de las bases de datos a las que esos usuarios pueden acceder en la "" ""creacin de instancias.""msgstr ""Modalidad de negociacin para la poltica ike.""msgstr ""Red a partir de la que se asigna la IP flotante.""msgstr ""Nmero de periodos durante los cuales se debe evaluar.""msgstr ""Operador utilizado para comparar estadsticas especficas con umbral.""msgstr ""Contrasea para los usuarios en la creacin de instancias.""msgstr ""Secreto de reenvo perfecto para la poltica ipsec.""msgstr ""Secreto de reenvo perfecto en minsculas para la poltica ike.""msgstr ""Periodo (segundos) durante el cual evaluar.""msgstr ""El recurso no se ha creado""""Configuracin de tiempo de vida de evaluacin de seguridad para la poltica """"Configuracin de tiempo de vida de evaluacin de seguridad para la poltica """"Valor de tiempo de vida de evaluacin de seguridad en unidades especificadas.""""Esquema que representa las salidas que esta configuracin de software "" ""producir.""msgstr ""Grupos de seguridad no pueden ser asignados a el nombre \""default\"".""msgstr ""Usuario o grupo del servicio de seguridad utilizado por el inquilino.""msgstr ""Nombre de grupo de servidores.""""Establezca en \""vpc\"" para tener asignacin de direccin IP asociada a VPC.""""Establecer a true si DHCP est habilitado y falso si DHCP esta deshabilitado.""""Especifica nombres de base de datos para crear bases de datos en la creacin "" ""de instancias.""msgstr ""Direccin de inicio de la agrupacin de asignacin.""msgstr ""Iniciar redimensionamiento del grupo %(group)s""""El ID del inquilino propietario del equilibrador de carga. Slo los usuarios "" ""administrativos pueden especificar un ID de inquilino distinto del suyo "" ""propio.""msgstr ""ID del inquilino propietario del escucha.""""El ID del inquilino propietario de la red. Slo los usuarios administrativos "" ""pueden especificar un ID de inquilino distinto del suyo propio.""""El ID del inquilino propietario de la agrupacin de subred. Slo los "" ""usuarios administrativos pueden especificar un ID de inquilino distinto del "" ""suyo propio.""""El ID del volumen desde el que se debe iniciar. Solo se debe proporcionar "" ""uno de volume_id o snapshot_id. ""msgstr ""El ID o nombre de la imagen con el que arrancar.""msgstr ""La version IP, cuales son 4 o 6.""msgstr ""El destino para la ruta esttica.""msgstr ""La red interna a la que se conecta en la pasarela de red.""""el protocolo es ICMP, este valor debe ser uno de tipo ICMP.""""seguridad. Si el protocolo es TCP o UDP, este valor debe ser menor que o "" ""igual al valor del atributo port_range_max. Si el protocolo es ICMP, este ""msgstr ""El nmero de nodos mestros para esta baha.""""El ID de inquilino propietario del mbito de direccin. Slo los usuarios "" ""administrativos pueden especificar un ID de inquilino distinto del suyo """"El ID de inquilino propietario. Solo es necesario si el interlocutor tiene "" ""un rol administrativo y desea crear un RBAC para otro inquilino.""""El protoclo que est coincidido con la regla de grupo de seguridad. Valores "" ""vlido incluyen tcp, udp, y icmp.""""El prefijo del IP remote (CIDR) para ser asociado con esta regla de grupo de """"La identidad de direccionador de bifurcacin remoto de la conexin del sitio "" ""ipsec.""""de seguridad para el remote_group_id. El parmetro de modalidad remota debe "" ""establecerse en \""remote_group_id\"".""msgstr ""Direccionador en el que se va a insertar el servicio vpn.""""La configuracin de tiempo de vida de evaluacin de seguridad para la ""msgstr ""Las direccines iniciales y finales para los bancos de asignacin.""msgstr ""Umbral en el que evaluar.""""Verdadero si el sistema debe recordar una clave privada generada; Falso en "" ""los dems casos.""""Identificador exclusivo para el direccionador en el que el servicio vpn se "" ""insertar.""""\""{get_attr: [<nombre de servidor>, networks, <nombre de red>, 0]}\""""msgstr ""Datos de usuario a pasar a instancia.""msgstr ""Nombre de usuario para crear un usuario en la creacin de instancias.""msgstr ""El valor debe ser JSON vlido: %s""msgstr ""Versin para la poltica ike.""msgstr ""Peso del miembro de la agrupacin.""""Si se debe compartir el mbito de direccin con otros inquilinos. Tenga en "" ""cuenta que el valor de poltica predeterminado restringe el uso de este """"Si se compartir esta agrupacin de subred entre todos los inquilinos. Tenga "" ""en cuenta que el valor de poltica predeterminado restringe el uso de este "" ""atributo solo a usuarios administrativos.""msgstr ""Si especificar o no un grupo remote o un prefijo de IP remote.""""segmentation_id no se puede especificar excepto 0 para utilizarlo plano""",146,136
openstack%2Fironic-specs~master~I937893f086f31d8bb5a82f4b54b9295109ad5391,openstack/ironic-specs,master,I937893f086f31d8bb5a82f4b54b9295109ad5391,Add node name regexp and wildcard filter to API,MERGED,2016-01-13 05:32:00.000000000,2016-05-06 08:04:53.000000000,2016-04-20 08:42:47.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6287}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7404}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 14810}]","[{'number': 1, 'created': '2016-01-13 05:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f7d5b7e4082186c27bab1ec2be3e8b55d029f38e', 'message': 'Add allowed node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 2, 'created': '2016-01-13 05:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4fb4d45671d35e5f7272b5058c48266a8f184849', 'message': 'Add allowed node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 3, 'created': '2016-01-13 05:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4c25a5b65b79b1bec22c8927d787e290ee5ff46d', 'message': 'Add allowed node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 4, 'created': '2016-01-13 05:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/49666a56c5341fe1d4a97435b7135981072fe11e', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 5, 'created': '2016-01-13 05:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/cbf46f9ec2865ffbf9b30112ccc6693aa0af3aae', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 6, 'created': '2016-01-13 06:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a69fe3466d005ae69746599ad784835ad51fbe44', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 7, 'created': '2016-01-13 07:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0b260cae34ebc567ebd7124ac78614f6b89082cb', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 8, 'created': '2016-01-13 07:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5756fe3a96cd406942c2846b8ff97b534a16cc3e', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 9, 'created': '2016-01-14 02:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f844503fa0eac643211dbcacab448fbedf0a27aa', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 10, 'created': '2016-02-18 05:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2a45adee31080680268d4b0e01de83ef75f1fa81', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 11, 'created': '2016-02-19 02:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2f019c639e609da246281384adcaee82a5698d0a', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding new API.\n\n GET /v1/nodes/?name=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 12, 'created': '2016-02-29 02:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/18ec5e3c01418f51447e02977798aa0e6017d917', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex).\n\n GET /v1/nodes/?name_regex=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 13, 'created': '2016-02-29 02:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d6e6d3bc1487094ab3d903a56415e7c6b98d83af', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex).\n\n GET /v1/nodes/?name_regex=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 14, 'created': '2016-03-08 00:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/dabab301980419a858f0f6a3d3e676f537ac73b7', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex).\n\n GET /v1/nodes/?name_regex=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 15, 'created': '2016-03-08 00:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/21953a6861ba99f8cae91f12b6f183d57d67fabd', 'message': 'Add node name regexp filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex).\n\n GET /v1/nodes/?name_regex=<regex_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 16, 'created': '2016-03-08 00:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/11e27e6e30c2bcc4fb2be25a8b5f67039a82ddb7', 'message': 'Add node name regexp and wildcard filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex and wildcard).\n\n GET /v1/nodes/?name_regex=<regex_str>\n GET /v1/nodes/?name_wildcard=<wildcard_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 17, 'created': '2016-04-11 01:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c382105166a62f9a604effa365585aa0948db162', 'message': 'Add node name regexp and wildcard filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex and wildcard).\n\n GET /v1/nodes/?name_regex=<regex_str>\n GET /v1/nodes/?name_wildcard=<wildcard_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 18, 'created': '2016-04-14 07:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d44327b1cb36e023d50272c37edf8f5994d71c43', 'message': 'Add node name regexp and wildcard filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex and wildcard).\n\n GET /v1/nodes/?name_regex=<regex_str>\n GET /v1/nodes/?name_wildcard=<wildcard_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}, {'number': 19, 'created': '2016-04-14 07:58:03.000000000', 'files': ['specs/approved/node-name-regexp-api.rst', 'specs/not-implemented/node-name-regexp-api.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4e55cbe4c8a054441fc8a21ebbfbe7f4bac5a0b7', 'message': 'Add node name regexp and wildcard filter to API\n\nThis commit proposes adding a way to filter nodes in the API by\ntheir name (regex and wildcard).\n\n GET /v1/nodes/?name_regex=<regex_str>\n GET /v1/nodes/?name_wildcard=<wildcard_str>\n\nChange-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391\nPartial-Bug: 1526319\n'}]",27,266688,4e55cbe4c8a054441fc8a21ebbfbe7f4bac5a0b7,75,14,19,8106,,,0,"Add node name regexp and wildcard filter to API

This commit proposes adding a way to filter nodes in the API by
their name (regex and wildcard).

 GET /v1/nodes/?name_regex=<regex_str>
 GET /v1/nodes/?name_wildcard=<wildcard_str>

Change-Id: I937893f086f31d8bb5a82f4b54b9295109ad5391
Partial-Bug: 1526319
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/88/266688/4 && git format-patch -1 --stdout FETCH_HEAD,"['specs/approved/node-name-regexp-api.rst', 'specs/not-implemented/node-name-regexp-api.rst']",2,f7d5b7e4082186c27bab1ec2be3e8b55d029f38e,bug/1526319,../approved/node-name-regexp-api.rst,,159,0
openstack%2Ffuel-library~master~Icb1404bbac89bd978296e4194a9f334874da05ca,openstack/fuel-library,master,Icb1404bbac89bd978296e4194a9f334874da05ca,Switch values for cinder_report_interval and cinder_service_down_time,MERGED,2016-04-27 13:42:09.000000000,2016-05-06 07:53:11.000000000,2016-05-04 12:11:51.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13505}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 17730}, {'_account_id': 18290}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-27 13:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/90a6b4dcacbc3a840cf59c484946169f38a51377', 'message': 'Switch values for cinder_report_interval and cinder_service_down_time\n\nValues for cinder_report_interval and cinder_service_down_time are confused\nand should be switched. cinder_report_interval should be 10 instead of 60, and\ncinder_service_down_time should be 60 instead of 10.\n\nChange-Id: Icb1404bbac89bd978296e4194a9f334874da05ca\nRelated-Bug: #1572689\n'}, {'number': 2, 'created': '2016-04-29 15:08:53.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/globals/globals.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/09c1f1f2144c32916b085c23dc3afd918783359b', 'message': 'Switch values for cinder_report_interval and cinder_service_down_time\n\nValues for cinder_report_interval and cinder_service_down_time are confused\nand should be switched. cinder_report_interval should be 10 instead of 60, and\ncinder_service_down_time should be 60 instead of 10.\n\nChange-Id: Icb1404bbac89bd978296e4194a9f334874da05ca\nCloses-Bug: #1568803\nRelated-Bug: #1572689\n'}]",0,310469,09c1f1f2144c32916b085c23dc3afd918783359b,63,18,2,13752,,,0,"Switch values for cinder_report_interval and cinder_service_down_time

Values for cinder_report_interval and cinder_service_down_time are confused
and should be switched. cinder_report_interval should be 10 instead of 60, and
cinder_service_down_time should be 60 instead of 10.

Change-Id: Icb1404bbac89bd978296e4194a9f334874da05ca
Closes-Bug: #1568803
Related-Bug: #1572689
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/69/310469/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/globals/globals.pp'],1,90a6b4dcacbc3a840cf59c484946169f38a51377,bug/1572689," $cinder_report_interval = hiera('cinder_report_interval', 10) $cinder_service_down_time = hiera('cinder_service_down_time', 60)"," $cinder_report_interval = hiera('cinder_report_interval', 60) $cinder_service_down_time = hiera('cinder_service_down_time', 10)",2,2
openstack%2Fnetworking-bgpvpn~master~I0b47e20ee2842ca6dbaa174acf092823a59b8243,openstack/networking-bgpvpn,master,I0b47e20ee2842ca6dbaa174acf092823a59b8243,Updated from global requirements,MERGED,2015-10-16 14:19:37.000000000,2016-05-06 07:49:26.000000000,2016-05-06 07:49:26.000000000,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 12021}, {'_account_id': 16272}, {'_account_id': 20683}, {'_account_id': 20993}]","[{'number': 1, 'created': '2015-10-16 14:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/9db0fb774e506d0e60a77b90ceb0a827d7479d27', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 2, 'created': '2015-10-16 22:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/5c7ea0bd75a21edcaf69e9fe446c46a5d6801fe9', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 3, 'created': '2015-10-23 02:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/162fda126cb32a52ad8fc50ce806148312c12955', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 4, 'created': '2015-10-28 10:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/cc5d1c07beb7e438a8849a3ebfc30571d09a762c', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 5, 'created': '2015-11-09 12:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/2b9eee5106e55e2ceb5f68c4ac4e15f73f997ac9', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 6, 'created': '2015-11-09 14:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/6b158c2c190d532c4674452d6e31deb05454f3ed', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 7, 'created': '2015-11-10 04:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/6e53c5f7a66cf9b0b4a61079e2ce5f38353c2f2d', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 8, 'created': '2015-11-11 04:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/889042484d75a21e9fe1d00382c42ced22472aa6', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 9, 'created': '2015-11-12 22:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/8b277b4b46d2252232c56cffc8412186bcfa0fe0', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 10, 'created': '2015-11-13 13:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/c929af70dd9c40b4bcb21172f9cfa3be104efa4a', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 11, 'created': '2015-11-13 17:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/52a78c444e26f6a56f6825ca13a555f7fe5e1f55', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 12, 'created': '2015-11-17 02:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/f646b1d9208d742107d5a733b4a7a2572d42734c', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 13, 'created': '2015-11-18 20:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/8fd29c6065e150055fdbf9558c6a3b1b2290c070', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 14, 'created': '2015-11-19 15:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/a7b39d35ae76e5275581ef6ce43a2b75bc755353', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 15, 'created': '2015-11-21 16:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/7a0fd69613764e9223f0660e90e53609ca826b5b', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 16, 'created': '2015-11-24 14:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/95c1f02ece0aa67048f5d5e198be95bc0a91c181', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}, {'number': 17, 'created': '2016-05-02 09:03:01.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/c1cec624cc6d6a0560b2b0949e06cb60ab2b1482', 'message': 'Updated from global requirements\n\nChange-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243\n'}]",0,235945,c1cec624cc6d6a0560b2b0949e06cb60ab2b1482,47,6,17,11131,,,0,"Updated from global requirements

Change-Id: I0b47e20ee2842ca6dbaa174acf092823a59b8243
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/45/235945/14 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9db0fb774e506d0e60a77b90ceb0a827d7479d27,openstack/requirements,oslo.service>=0.10.0 # Apache-2.0,oslo.service>=0.9.0 # Apache-2.0,1,1
openstack%2Fswift~master~Id195357733f0556ea439a6dedeb535da531f1235,openstack/swift,master,Id195357733f0556ea439a6dedeb535da531f1235,Set quorum_size of 50% for even replicas and majority_size,ABANDONED,2016-05-06 06:46:38.000000000,2016-05-06 07:46:43.000000000,,"[{'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-05-06 06:46:38.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'test/unit/proxy/controllers/test_account.py', 'swift/common/utils.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/proxy/controllers/test_base.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8d75fe06ebede0c7540b4dcbcde5840774068545', 'message': ""Set quorum_size of 50% for even replicas and majority_size\n\nThis change was discussed during the Austin design summit. Currently Swift\ndoesn't always play nice with even number replication. Say you have a 2 region\ncluster with a replica count of 6. Currently the quorum maths is:\n\n  (n // 2) + 1\n\nMeaning in our 6 replica cluster the output of quorum_size would be 4. On\na multi-region cluster, this means quorum means it must place at least 1\nreplica on the other region.\nSeeing as in the most part the quorum_size calculation for data integrity,\n3 copies on a 6 replica cluster should be enough.\n\nThis change changes the quorum_size algorithm to:\n\n  int(math.ceil(n / 2.0))\n\nMeaning even number replica quorum will now we 50%, odd numbers will continue to\nbe equivalent of (n // 2) + 1.\n\nHowever, these are times in Swift where a majority quorum is required. The\nreconciler deciding on what storage policy to use for one, and the future sharder\nwho needs to have a majority quorum on the best point to split/pivot is another.\nBecause of this a new method `majority_size` has been added to utils, which is\nidentical to the old version of quorum_size.\n\nThe following table will make it clearer:\n\n  ==========================================\n  | replicas | quorum_size | majority_size |\n  ==========================================\n  | 1        | 1           | 1             |\n  | 2        | 1           | 2             |\n  | 3        | 2           | 2             |\n  | 4        | 2           | 3             |\n  | 5        | 3           | 3             |\n  | 6        | 3           | 4             |\n  | 7        | 4           | 4             |\n  ------------------------------------------\n\nChange-Id: Id195357733f0556ea439a6dedeb535da531f1235\n""}]",0,313245,8d75fe06ebede0c7540b4dcbcde5840774068545,6,4,1,7233,,,0,"Set quorum_size of 50% for even replicas and majority_size

This change was discussed during the Austin design summit. Currently Swift
doesn't always play nice with even number replication. Say you have a 2 region
cluster with a replica count of 6. Currently the quorum maths is:

  (n // 2) + 1

Meaning in our 6 replica cluster the output of quorum_size would be 4. On
a multi-region cluster, this means quorum means it must place at least 1
replica on the other region.
Seeing as in the most part the quorum_size calculation for data integrity,
3 copies on a 6 replica cluster should be enough.

This change changes the quorum_size algorithm to:

  int(math.ceil(n / 2.0))

Meaning even number replica quorum will now we 50%, odd numbers will continue to
be equivalent of (n // 2) + 1.

However, these are times in Swift where a majority quorum is required. The
reconciler deciding on what storage policy to use for one, and the future sharder
who needs to have a majority quorum on the best point to split/pivot is another.
Because of this a new method `majority_size` has been added to utils, which is
identical to the old version of quorum_size.

The following table will make it clearer:

  ==========================================
  | replicas | quorum_size | majority_size |
  ==========================================
  | 1        | 1           | 1             |
  | 2        | 1           | 2             |
  | 3        | 2           | 2             |
  | 4        | 2           | 3             |
  | 5        | 3           | 3             |
  | 6        | 3           | 4             |
  | 7        | 4           | 4             |
  ------------------------------------------

Change-Id: Id195357733f0556ea439a6dedeb535da531f1235
",git fetch https://review.opendev.org/openstack/swift refs/changes/45/313245/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policy.py', 'swift/common/utils.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/proxy/controllers/test_container.py', 'test/unit/proxy/controllers/test_base.py', 'swift/container/reconciler.py', 'test/unit/common/test_utils.py']",7,8d75fe06ebede0c7540b4dcbcde5840774068545,," 2: 1, 3: 2, 4: 2, 5: 3} got_sizes = dict([(n, utils.quorum_size(n)) for n in expected_sizes]) self.assertEqual(expected_sizes, got_sizes) def test_replication_majority_size(self): expected_sizes = {1: 1, got_sizes = dict([(n, utils.majority_size(n))"," got_sizes = dict([(n, utils.quorum_size(n))",62,38
openstack%2Fmagnum~master~I487f9000b4c229be3e1b576258473e39cda66f9e,openstack/magnum,master,I487f9000b4c229be3e1b576258473e39cda66f9e,Copy logs if test failed and bay nodes existed,MERGED,2016-04-16 18:52:36.000000000,2016-05-06 07:42:09.000000000,2016-05-06 07:42:09.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}]","[{'number': 1, 'created': '2016-04-16 18:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4ee75c2d6496fa82578faf038d7788640528e36c', 'message': '[WIP] Copy the logs on bay creation timeout\n\nChange-Id: I487f9000b4c229be3e1b576258473e39cda66f9e\n'}, {'number': 2, 'created': '2016-04-17 02:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7f9595aa586d00c8c03ef1e118ad882e40996737', 'message': ""Fix an issue that logs are not copied on gate\n\nIf the bay is pending on CREATE_IN_PROCESS, it won't contain the\nIP addresses of the nodes. Therefore, we need to get them from\nthe Heat stack if missing.\n\nCloses-Bug: #1571272\nChange-Id: I487f9000b4c229be3e1b576258473e39cda66f9e\n""}, {'number': 3, 'created': '2016-04-17 14:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/53e6414ae09b25054ce27336375000e4b20b2962', 'message': ""Copy logs if test failed and bay nodes existed\n\nIf the bay is pending on CREATE_IN_PROCESS, it won't contain the\nIP addresses of the nodes. Therefore, we need to get them from\nthe Heat stack if missing.\n\nCloses-Bug: #1571272\nChange-Id: I487f9000b4c229be3e1b576258473e39cda66f9e\n""}, {'number': 4, 'created': '2016-05-05 21:19:41.000000000', 'files': ['magnum/tests/functional/python_client_base.py', 'magnum/tests/functional/common/base.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d1263387a627904601f6cdc98baa95d1b18c12f8', 'message': ""Copy logs if test failed and bay nodes existed\n\nIf the bay is pending on CREATE_IN_PROCESS, it won't contain the\nIP addresses of the nodes. Therefore, we need to get them from\nthe Heat stack if missing.\n\nCloses-Bug: #1571272\nChange-Id: I487f9000b4c229be3e1b576258473e39cda66f9e\n""}]",4,306776,d1263387a627904601f6cdc98baa95d1b18c12f8,26,5,4,11536,,,0,"Copy logs if test failed and bay nodes existed

If the bay is pending on CREATE_IN_PROCESS, it won't contain the
IP addresses of the nodes. Therefore, we need to get them from
the Heat stack if missing.

Closes-Bug: #1571272
Change-Id: I487f9000b4c229be3e1b576258473e39cda66f9e
",git fetch https://review.opendev.org/openstack/magnum refs/changes/76/306776/4 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/functional/python_client_base.py', 'magnum/tests/functional/common/base.py']",2,4ee75c2d6496fa82578faf038d7788640528e36c,bug/1571272," cls.LOG.info(""Copying logs..."") cls.LOG.info(""nodes_addresses: %s"" % ','.join(nodes_addresses)) cls.LOG.info(""Copying logs from node %s ..."" % str(node_address)) cls.LOG.error(msg)"," cls.LOG.debug(""Copying logs..."") cls.LOG.exception(msg)",38,4
openstack%2Fproject-config~master~I16b68a8240a9b304f823f487bdc0e4082b544932,openstack/project-config,master,I16b68a8240a9b304f823f487bdc0e4082b544932,Integrate shade+magnum neutron job,MERGED,2016-05-05 13:15:00.000000000,2016-05-06 07:37:22.000000000,2016-05-06 07:37:22.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 13:15:00.000000000', 'files': ['jenkins/jobs/shade.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/941770f537f7d627465acc5701bededdd2e3a196', 'message': 'Integrate shade+magnum neutron job\n\nThe non-voting job for neutron has been passing consistently.\nIntegrate with the shade neutron magnum job.\n\nChange-Id: I16b68a8240a9b304f823f487bdc0e4082b544932\n'}]",0,312940,941770f537f7d627465acc5701bededdd2e3a196,7,3,1,6133,,,0,"Integrate shade+magnum neutron job

The non-voting job for neutron has been passing consistently.
Integrate with the shade neutron magnum job.

Change-Id: I16b68a8240a9b304f823f487bdc0e4082b544932
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/312940/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/shade.yaml', 'zuul/layout.yaml']",2,941770f537f7d627465acc5701bededdd2e3a196,,, - name: gate-shade-dsvm-functional-neutron-magnum voting: false - gate-shade-dsvm-functional-neutron-magnum,6,43
openstack%2Fcinder~master~Ide700aeb354233140af7992470a0e900c1866970,openstack/cinder,master,Ide700aeb354233140af7992470a0e900c1866970,Minor typo fixes,ABANDONED,2016-05-03 20:23:45.000000000,2016-05-06 07:35:55.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14339}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16237}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-05-03 20:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f93a53f0db780aba12db5cd281a8ebb4703ccc0', 'message': 'Minor typo fixes - resubmitting as per suggestion from sheel.\n\nChange-Id: Ide700aeb354233140af7992470a0e900c1866970\n'}, {'number': 2, 'created': '2016-05-03 20:30:05.000000000', 'files': ['cinder/volume/drivers/drbdmanagedrv.py', 'cinder/volume/drivers/xio.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6e6ad42ec073c06dea9c2912f60990fc9c39c939', 'message': 'Minor typo fixes\n\nChange-Id: Ide700aeb354233140af7992470a0e900c1866970\n'}]",1,312235,6e6ad42ec073c06dea9c2912f60990fc9c39c939,39,34,2,1586,,,0,"Minor typo fixes

Change-Id: Ide700aeb354233140af7992470a0e900c1866970
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/312235/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/drbdmanagedrv.py', 'cinder/volume/drivers/xio.py']",2,6f93a53f0db780aba12db5cd281a8ebb4703ccc0,dev,# above and every external API results in a call to common function in base,# above and every external API resuslts in a call to common function in base,2,2
openstack%2Fproject-config~master~I3498ff5401ee3897e1ae49bffd9aeaacea4f2dba,openstack/project-config,master,I3498ff5401ee3897e1ae49bffd9aeaacea4f2dba,Use m1.large for centos-7 on tripleo-test-cloud-rh1,MERGED,2016-05-05 14:22:24.000000000,2016-05-06 07:32:23.000000000,2016-05-06 07:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 14:22:24.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c3867bf1440be3756ee8eb3ada9df0b0828c2fa5', 'message': 'Use m1.large for centos-7 on tripleo-test-cloud-rh1\n\nThis flavor brings our jenkin slave more inline with other clouds.\n\n+--------+-----------+-------+------+-----------+-------+-----------+\n| ID     | Name      |   RAM | Disk | Ephemeral | VCPUs | Is Public |\n+--------+-----------+-------+------+-----------+-------+-----------+\n| 4      | m1.large  |  8192 |   80 |         0 |     4 | True      |\n+--------+-----------+-------+------+-----------+-------+-----------+\n\nChange-Id: I3498ff5401ee3897e1ae49bffd9aeaacea4f2dba\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,312992,c3867bf1440be3756ee8eb3ada9df0b0828c2fa5,8,4,1,4162,,,0,"Use m1.large for centos-7 on tripleo-test-cloud-rh1

This flavor brings our jenkin slave more inline with other clouds.

+--------+-----------+-------+------+-----------+-------+-----------+
| ID     | Name      |   RAM | Disk | Ephemeral | VCPUs | Is Public |
+--------+-----------+-------+------+-----------+-------+-----------+
| 4      | m1.large  |  8192 |   80 |         0 |     4 | True      |
+--------+-----------+-------+------+-----------+-------+-----------+

Change-Id: I3498ff5401ee3897e1ae49bffd9aeaacea4f2dba
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/312992/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,c3867bf1440be3756ee8eb3ada9df0b0828c2fa5,, name-filter: m1, name-filter: h1,1,1
openstack%2Foperations-guide~master~I5481a4cd0210ec2c568fd5de2df10fb6130b01df,openstack/operations-guide,master,I5481a4cd0210ec2c568fd5de2df10fb6130b01df,Modify the 'Block Storage' Operations Guide,ABANDONED,2016-05-01 08:05:32.000000000,2016-05-06 07:29:57.000000000,,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-01 08:05:32.000000000', 'files': ['doc/openstack-ops/ch_ops_user_facing.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/12ae55a8e7a9195d1ac0856692f500b4697f2387', 'message': ""Modify the 'Block Storage' Operations Guide\n\nThe 'Cinder Create' cli command output is outdated, this\npatch fix it.\n\nChange-Id: I5481a4cd0210ec2c568fd5de2df10fb6130b01df\n""}]",0,311607,12ae55a8e7a9195d1ac0856692f500b4697f2387,4,2,1,14151,,,0,"Modify the 'Block Storage' Operations Guide

The 'Cinder Create' cli command output is outdated, this
patch fix it.

Change-Id: I5481a4cd0210ec2c568fd5de2df10fb6130b01df
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/07/311607/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_user_facing.xml'],1,12ae55a8e7a9195d1ac0856692f500b4697f2387,create_volume," <para>To add new volumes, you need only a volume size in <screen><prompt>$</prompt> <userinput>cinder create 10</userinput></screen> <para>This creates a 10 GB volume. To list existing volumes and the instances they are attached to, if<computeroutput>+------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+ | ID | Status | Migration Status | Name | Size | Volume Type | Bootable | Multiattach | Attached to | +------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+ | d95a...1aa | available | - | - | 10 | - | false | False | | +------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+</computeroutput></screen>"," <para>To add new volumes, you need only a name and a volume size in <screen><prompt>$</prompt> <userinput>cinder create --display-name test-volume 10</userinput></screen> <para>This creates a 10 GB volume named <literal>test-volume</literal>. To list existing volumes and the instances they are connected to, if<computeroutput>+------------+---------+--------------------+------+-------------+-------------+ | ID | Status | Display Name | Size | Volume Type | Attached to | +------------+---------+--------------------+------+-------------+-------------+ | 0821...19f | active | test-volume | 10 | None | | +------------+---------+--------------------+------+-------------+-------------+</computeroutput></screen>",9,9
openstack%2Foperations-guide~master~Ie3dca44ab3b00a4a12c8b92b7a3779168cae423d,openstack/operations-guide,master,Ie3dca44ab3b00a4a12c8b92b7a3779168cae423d,Update Networking OVS diagram in the Operations Guide,ABANDONED,2015-09-11 01:52:12.000000000,2016-05-06 07:29:50.000000000,,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4625}, {'_account_id': 6804}, {'_account_id': 7244}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 13995}]","[{'number': 1, 'created': '2015-09-11 01:52:12.000000000', 'files': ['doc/openstack-ops/figures/osog_1202.svg', 'doc/openstack-ops/figures/osog_1202.png', 'doc/openstack-ops/figures/osog_1202.graffle'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/1f67316f2fadaaa7d6bd5f8ba5d2aa5b69766ca3', 'message': ""Update Networking OVS diagram in the Operations Guide\n\nAdded linux bridge to the diagram and removed numbering which doesn't correlate\nto the section content\n\nChange-Id: Ie3dca44ab3b00a4a12c8b92b7a3779168cae423d\nCloses-Bug: #1379391\n""}]",0,222434,1f67316f2fadaaa7d6bd5f8ba5d2aa5b69766ca3,14,8,1,10705,,,0,"Update Networking OVS diagram in the Operations Guide

Added linux bridge to the diagram and removed numbering which doesn't correlate
to the section content

Change-Id: Ie3dca44ab3b00a4a12c8b92b7a3779168cae423d
Closes-Bug: #1379391
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/34/222434/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/figures/osog_1202.svg', 'doc/openstack-ops/figures/osog_1202.png', 'doc/openstack-ops/figures/osog_1202.graffle']",3,1f67316f2fadaaa7d6bd5f8ba5d2aa5b69766ca3,bug/1379391,,,3,0
openstack%2Foperations-guide~master~Ibb9aeb177d307a66968c109f166fd3f9eb3d893a,openstack/operations-guide,master,Ibb9aeb177d307a66968c109f166fd3f9eb3d893a,cleanup of ops user facing operations,ABANDONED,2016-05-05 16:22:20.000000000,2016-05-06 07:29:43.000000000,,"[{'_account_id': 3}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 13995}, {'_account_id': 17711}]","[{'number': 1, 'created': '2016-05-05 16:22:20.000000000', 'files': ['doc/ops-guide/source/ops_user_facing_operations.rst'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/7655abd0cf3186fb770a6d47a90e349ebadbd3f9', 'message': 'cleanup of ops user facing operations\n\nadded spaces where necessary\ncorrected spelling where necessary\ncorrected typos\n\nChange-Id: Ibb9aeb177d307a66968c109f166fd3f9eb3d893a\n'}]",3,313045,7655abd0cf3186fb770a6d47a90e349ebadbd3f9,7,5,1,9382,,,0,"cleanup of ops user facing operations

added spaces where necessary
corrected spelling where necessary
corrected typos

Change-Id: Ibb9aeb177d307a66968c109f166fd3f9eb3d893a
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/45/313045/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_user_facing_operations.rst'],1,7655abd0cf3186fb770a6d47a90e349ebadbd3f9,ops_user_facing,personal images or snapshots with other projects. This can be done on the commandID of the owner. This example goes one step further and displays the readable name of the owner: bandwidth cap from that defined in the networkchoose back-ends before you create a share. Functions and behavior of- Max amount of space available for all sharesYou can also specify block device mapping at instance boot,personal images or snapshots with other projects.projects sharing images betweenimages sharing between projects This can be done on the commandID of the owner. Image service database queriesThis example goes one step further and displays the readable name of the owner: bandwidthbandwidth capping cap from that defined in the networkchoose back-ends before you create a share. Functions and behaviour of- Max amount of space awailable for all sharesYou can also specify block deviceblock device mapping at instance boot,7,8
openstack%2Foperations-guide~master~I9dea5179ae5fdcfe8e21bf74d978e0fe0a2a3ae7,openstack/operations-guide,master,I9dea5179ae5fdcfe8e21bf74d978e0fe0a2a3ae7,[WIP] Ops guide networking upgrade content,ABANDONED,2016-03-11 16:01:14.000000000,2016-05-06 07:29:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-11 16:01:14.000000000', 'files': ['doc/ops-guide/source/part_operations.rst', 'doc/ops-guide/source/networking_service_upgrade.rst'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/845e7cd5e5a1048f142280495d0f870bce9a2821', 'message': '[WIP] Ops guide networking upgrade content\n\nChange-Id: I9dea5179ae5fdcfe8e21bf74d978e0fe0a2a3ae7\n'}]",0,291785,845e7cd5e5a1048f142280495d0f870bce9a2821,6,3,1,4656,,,0,"[WIP] Ops guide networking upgrade content

Change-Id: I9dea5179ae5fdcfe8e21bf74d978e0fe0a2a3ae7
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/85/291785/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ops-guide/source/part_operations.rst', 'doc/ops-guide/source/networking_service_upgrade.rst']",2,845e7cd5e5a1048f142280495d0f870bce9a2821,ops_networking_upgrade,================================ Upgrading the Networking Service ================================ ,,4,0
openstack%2Fproject-config~master~I452112a44532ffcfa803f96741387fc1554d640c,openstack/project-config,master,I452112a44532ffcfa803f96741387fc1554d640c,Make gate-murano-python34-db voting; add gate job,MERGED,2016-05-04 13:13:14.000000000,2016-05-06 07:27:42.000000000,2016-05-06 07:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 13:13:14.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b8ac4c73a40517147d4a732b8712d0fc311f3546', 'message': 'Make gate-murano-python34-db voting; add gate job\n\nWith the change I7f684c41846701d42b35d767fcb2335b10156e76, Murano\nunit tests now pass on Python 3 (only a whitelist of tests, not all\ntests pass yet). Make the gate-murano-python34-db check job voting to\navoid Python 3 regressions.\n\nUse also the python3-db-jobs template to add a gate-murano-python34-db\ngate job.\n\nDepends-On: I7f684c41846701d42b35d767fcb2335b10156e76\nBlueprint: murano-python-3-support\nChange-Id: I452112a44532ffcfa803f96741387fc1554d640c\n'}]",0,312493,b8ac4c73a40517147d4a732b8712d0fc311f3546,10,3,1,9107,,,0,"Make gate-murano-python34-db voting; add gate job

With the change I7f684c41846701d42b35d767fcb2335b10156e76, Murano
unit tests now pass on Python 3 (only a whitelist of tests, not all
tests pass yet). Make the gate-murano-python34-db check job voting to
avoid Python 3 regressions.

Use also the python3-db-jobs template to add a gate-murano-python34-db
gate job.

Depends-On: I7f684c41846701d42b35d767fcb2335b10156e76
Blueprint: murano-python-3-support
Change-Id: I452112a44532ffcfa803f96741387fc1554d640c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/93/312493/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b8ac4c73a40517147d4a732b8712d0fc311f3546,bp/murano-python-3-support, - name: python3-db-jobs, voting: false - gate-murano-python34-db,1,2
openstack%2Fproject-config~master~Ib2ccf22ee11135702d4d60f1c7e639cbd2038e87,openstack/project-config,master,Ib2ccf22ee11135702d4d60f1c7e639cbd2038e87,Set TEMPEST_CONCURRENCY to 1 for grenade-ironic,MERGED,2016-04-29 18:57:45.000000000,2016-05-06 07:22:47.000000000,2016-05-06 07:22:46.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10239}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-04-29 18:57:45.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5fe7b298d3651393e0da9411311889d3e267761a', 'message': 'Set TEMPEST_CONCURRENCY to 1 for grenade-ironic\n\ngrenade-dsvm-ironic is configured with 1 Ironic node.\nFix tempest concurrency accordinly.\n\nChange-Id: Ib2ccf22ee11135702d4d60f1c7e639cbd2038e87\n'}]",1,311225,5fe7b298d3651393e0da9411311889d3e267761a,9,5,1,14525,,,0,"Set TEMPEST_CONCURRENCY to 1 for grenade-ironic

grenade-dsvm-ironic is configured with 1 Ironic node.
Fix tempest concurrency accordinly.

Change-Id: Ib2ccf22ee11135702d4d60f1c7e639cbd2038e87
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/311225/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,5fe7b298d3651393e0da9411311889d3e267761a,concurrency, export TEMPEST_CONCURRENCY=1, export TEMPEST_CONCURRENCY=2,1,1
openstack%2Fproject-config~master~I9f4e21b44c717d11511fea48db54a52103e294b1,openstack/project-config,master,I9f4e21b44c717d11511fea48db54a52103e294b1,Retire operations-guide and ha-guide (1/2),MERGED,2016-05-05 18:31:12.000000000,2016-05-06 07:16:16.000000000,2016-05-06 07:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-05 18:31:12.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2abb1170bbef3f959593506ab76fdd829b4029f0', 'message': 'Retire operations-guide and ha-guide (1/2)\n\nThe Docs team has decided to merge the contents of these guides to\nopenstack-manuals and retire the repository.\n\nThis is the first step: Removing all jobs for them, so that we can\nremove the content.\n\nChange-Id: I9f4e21b44c717d11511fea48db54a52103e294b1\n'}]",0,313104,2abb1170bbef3f959593506ab76fdd829b4029f0,12,6,1,6547,,,0,"Retire operations-guide and ha-guide (1/2)

The Docs team has decided to merge the contents of these guides to
openstack-manuals and retire the repository.

This is the first step: Removing all jobs for them, so that we can
remove the content.

Change-Id: I9f4e21b44c717d11511fea48db54a52103e294b1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/04/313104/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,2abb1170bbef3f959593506ab76fdd829b4029f0,retire-manuals, - name: noop-jobs - name: noop-jobs, - name: openstack-doc-rst-gate - name: openstack-doc-translation post: - ha-guide-tox-doc-publishdocs - name: openstack-doc-gate post: - operations-guide-tox-doc-publishdocs,2,20
openstack%2Fproject-config~master~Ie1e0b34d4aefae1aba06e548547e4b8915462053,openstack/project-config,master,Ie1e0b34d4aefae1aba06e548547e4b8915462053,use 24hours everywhere in grafana/neutron.yaml,MERGED,2016-05-05 13:33:28.000000000,2016-05-06 07:16:08.000000000,2016-05-06 07:16:08.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}]","[{'number': 1, 'created': '2016-05-05 13:33:28.000000000', 'files': ['grafana/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cded4a44b7f4d58f60b14551566508df3c81ea55', 'message': 'use 24hours everywhere in grafana/neutron.yaml\n\nAll entries in this file use 24hours with one exception, use 24hours\nthere as well.\n\nChange-Id: Ie1e0b34d4aefae1aba06e548547e4b8915462053\n'}]",0,312950,cded4a44b7f4d58f60b14551566508df3c81ea55,7,3,1,6547,,,0,"use 24hours everywhere in grafana/neutron.yaml

All entries in this file use 24hours with one exception, use 24hours
there as well.

Change-Id: Ie1e0b34d4aefae1aba06e548547e4b8915462053
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/312950/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/neutron.yaml'],1,cded4a44b7f4d58f60b14551566508df3c81ea55,grafana-consistent," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.{SUCCESS,FAILURE})),'24hours'), 'gate-tempest-dsvm-full')"," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.{SUCCESS,FAILURE})),'12hours'), 'gate-tempest-dsvm-full')",1,1
openstack%2Fproject-config~master~Ia353cda03396680a56d459a7a7b034a343468ed1,openstack/project-config,master,Ia353cda03396680a56d459a7a7b034a343468ed1,Set image build in magnum to periodic,MERGED,2016-05-05 07:06:24.000000000,2016-05-06 07:15:26.000000000,2016-05-06 07:15:25.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}]","[{'number': 1, 'created': '2016-05-05 07:06:24.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7ebb331696b39b881acc053775222de58caaf0b1', 'message': 'Set image build in magnum to periodic\n\nInstead of relying on experimental jobs, build the\nimage daily with a periodical job.\n\nChange-Id: Ia353cda03396680a56d459a7a7b034a343468ed1\n'}]",0,312842,7ebb331696b39b881acc053775222de58caaf0b1,7,3,1,6133,,,0,"Set image build in magnum to periodic

Instead of relying on experimental jobs, build the
image daily with a periodical job.

Change-Id: Ia353cda03396680a56d459a7a7b034a343468ed1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/312842/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,7ebb331696b39b881acc053775222de58caaf0b1,, periodic:, experimental:,1,1
openstack%2Fsenlin-dashboard~stable%2Fmitaka~I7a4a8048073feafc261faa6797b296a486cd4671,openstack/senlin-dashboard,stable/mitaka,I7a4a8048073feafc261faa6797b296a486cd4671,Fix empty `Timestamp` column in cluster/node event tables,MERGED,2016-05-04 13:29:44.000000000,2016-05-06 07:04:22.000000000,2016-05-06 07:04:21.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-05-04 13:29:44.000000000', 'files': ['senlin_dashboard/cluster/nodes/event_tables.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/97655ffd57c5b9279b305254a475da99e645d418', 'message': 'Fix empty `Timestamp` column in cluster/node event tables\n\nwe use the filter parse_isotime\n(https://github.com/openstack/horizon/blob/master/horizon/utils/filters.py#L32),\nthe function except string rather than datetime object.\n\nBut the python-openstacksdk\n(https://github.com/openstack/python-openstacksdk/blob/master/openstack/cluster/v1/event.py#L31)\nreturn datetime object parsed from ISO 8601 formatted string,\nso we could remove the filter.\n\nChange-Id: I7a4a8048073feafc261faa6797b296a486cd4671\nCloses-Bug: #1566349\n(cherry picked from commit af47677b68ba6789aa5323605a3f7ee2911b0051)\n'}]",0,312501,97655ffd57c5b9279b305254a475da99e645d418,7,3,1,6763,,,0,"Fix empty `Timestamp` column in cluster/node event tables

we use the filter parse_isotime
(https://github.com/openstack/horizon/blob/master/horizon/utils/filters.py#L32),
the function except string rather than datetime object.

But the python-openstacksdk
(https://github.com/openstack/python-openstacksdk/blob/master/openstack/cluster/v1/event.py#L31)
return datetime object parsed from ISO 8601 formatted string,
so we could remove the filter.

Change-Id: I7a4a8048073feafc261faa6797b296a486cd4671
Closes-Bug: #1566349
(cherry picked from commit af47677b68ba6789aa5323605a3f7ee2911b0051)
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/01/312501/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin_dashboard/cluster/nodes/event_tables.py'],1,97655ffd57c5b9279b305254a475da99e645d418,bug/1566349," verbose_name=_(""Timestamp""))","from horizon.utils import filters verbose_name=_(""Timestamp""), filters=(filters.parse_isotime,))",1,3
openstack%2Fproject-config~master~I2e3e89e0952c58c691ce3bf0059d49fd0284096a,openstack/project-config,master,I2e3e89e0952c58c691ce3bf0059d49fd0284096a,stop puppet-unit 3.3 and 3.4 jobs starting from newton,MERGED,2016-05-05 20:34:45.000000000,2016-05-06 07:04:01.000000000,2016-05-06 07:04:01.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6554}]","[{'number': 1, 'created': '2016-05-05 20:34:45.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2b7cc44edc04c8095d8bbaa9268a70cb3e788261', 'message': ""stop puppet-unit 3.3 and 3.4 jobs starting from newton\n\nRecent poll [1] showed us that a large majority of deployments\nare running Puppet 3.8 and only 1/25 deployment ran Puppet 3.4.\n\nThis patch stops testing puppet 3.3 and 3.4 starting from Newton, but\nwill still keep testing for our all stable branches, so we make sure we\ndon't break them when backporting.\n\nIt will help us to move forward with Puppet versions testing, reduce CI\nconsumption and bring new features that are not supported in Puppet 3.4.\n\n[1] https://goo.gl/JHb7Uc\n\nChange-Id: I2e3e89e0952c58c691ce3bf0059d49fd0284096a\n""}]",0,313149,2b7cc44edc04c8095d8bbaa9268a70cb3e788261,7,4,1,3153,,,0,"stop puppet-unit 3.3 and 3.4 jobs starting from newton

Recent poll [1] showed us that a large majority of deployments
are running Puppet 3.8 and only 1/25 deployment ran Puppet 3.4.

This patch stops testing puppet 3.3 and 3.4 starting from Newton, but
will still keep testing for our all stable branches, so we make sure we
don't break them when backporting.

It will help us to move forward with Puppet versions testing, reduce CI
consumption and bring new features that are not supported in Puppet 3.4.

[1] https://goo.gl/JHb7Uc

Change-Id: I2e3e89e0952c58c691ce3bf0059d49fd0284096a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/313149/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,2b7cc44edc04c8095d8bbaa9268a70cb3e788261,puppet/versions," # Starting from Newton, Puppet OpenStack stop testing on Puppet 3.3 and 3.4. - name: ^gate-puppet-.*-puppet-unit-3.(3|4)-.*$ branch: ^stable/(icehouse|juno|kilo|liberty|mitaka).*$ ",,4,0
openstack%2Fpython-openstackclient~master~I560ca78a3ab5e7b99087bfe1667de500f92c68de,openstack/python-openstackclient,master,I560ca78a3ab5e7b99087bfe1667de500f92c68de,Remove unnecessary type conversions in network unit tests,MERGED,2016-05-05 08:15:19.000000000,2016-05-06 07:00:35.000000000,2016-05-06 07:00:35.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-05-05 08:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e67db75b3974bd773faa836c57c566ceaf5b13a6', 'message': 'Remove unnecessary type conversions in network unit tests\n\nIn some tests, when comparing the results data with the\nexpected ones, many unnecessary type conversions are used.\nSo remove them to clean up.\n\nChange-Id: I560ca78a3ab5e7b99087bfe1667de500f92c68de\nPartial-bug: #1550633\n'}, {'number': 2, 'created': '2016-05-06 03:42:27.000000000', 'files': ['openstackclient/tests/network/v2/test_subnet.py', 'openstackclient/tests/network/v2/test_security_group.py', 'openstackclient/tests/network/v2/test_security_group_rule.py', 'openstackclient/tests/network/v2/test_network.py', 'openstackclient/tests/network/v2/test_router.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f91685f391cce2699ba6e4f2577a84e12d590aba', 'message': 'Remove unnecessary type conversions in network unit tests\n\nIn some tests, when comparing the results data with the\nexpected ones, many unnecessary type conversions are used.\nSo remove them to clean up.\n\nChange-Id: I560ca78a3ab5e7b99087bfe1667de500f92c68de\nPartial-bug: #1550633\n'}]",0,312855,f91685f391cce2699ba6e4f2577a84e12d590aba,21,4,2,14937,,,0,"Remove unnecessary type conversions in network unit tests

In some tests, when comparing the results data with the
expected ones, many unnecessary type conversions are used.
So remove them to clean up.

Change-Id: I560ca78a3ab5e7b99087bfe1667de500f92c68de
Partial-bug: #1550633
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/55/312855/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_subnet.py', 'openstackclient/tests/network/v2/test_security_group.py', 'openstackclient/tests/network/v2/test_security_group_rule.py', 'openstackclient/tests/network/v2/test_network.py', 'openstackclient/tests/network/v2/test_router.py']",5,e67db75b3974bd773faa836c57c566ceaf5b13a6,bug/1550633," self.assertEqual(self.columns, columns)"," self.assertEqual(tuple(self.columns), columns)",52,46
openstack%2Fproject-config~master~Ice60b74b48bcd6a06977d79b8931185ed9ac782b,openstack/project-config,master,Ice60b74b48bcd6a06977d79b8931185ed9ac782b,Add experimental centos-7 jobs to check-tripleo-jobs,MERGED,2016-05-05 20:19:51.000000000,2016-05-06 06:58:19.000000000,2016-05-06 06:58:19.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 20:19:51.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ed73bfa8516e5bd52dc5d5ddc9dc2c1f9351026b', 'message': 'Add experimental centos-7 jobs to check-tripleo-jobs\n\nNow that testing with puppet-aodh has finished, we are ready to add\nmore experimental jobs to validated triple-ci works under a centos-7\ndib.\n\nWe are also removing the experimental-tripleo job from puppet-aodh.\n\nChange-Id: Ice60b74b48bcd6a06977d79b8931185ed9ac782b\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,313146,ed73bfa8516e5bd52dc5d5ddc9dc2c1f9351026b,7,3,1,4162,,,0,"Add experimental centos-7 jobs to check-tripleo-jobs

Now that testing with puppet-aodh has finished, we are ready to add
more experimental jobs to validated triple-ci works under a centos-7
dib.

We are also removing the experimental-tripleo job from puppet-aodh.

Change-Id: Ice60b74b48bcd6a06977d79b8931185ed9ac782b
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/46/313146/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,ed73bfa8516e5bd52dc5d5ddc9dc2c1f9351026b,, experimental-tripleo: - gate-tripleo-ci-centos-7-upgrades - gate-tripleo-ci-centos-7-ha - gate-tripleo-ci-centos-7-nonha - gate-tripleo-ci-centos-7-containers, experimental-tripleo: - gate-tripleo-ci-centos-7-nonha,23,2
openstack%2Fopenstack-manuals~stable%2Fmitaka~I1b737c33cc4d15be130ec08b484230c9b77ec9eb,openstack/openstack-manuals,stable/mitaka,I1b737c33cc4d15be130ec08b484230c9b77ec9eb,Imported Translations from Zanata,MERGED,2016-05-06 06:31:21.000000000,2016-05-06 06:47:30.000000000,2016-05-06 06:47:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-06 06:31:21.000000000', 'files': ['doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/417a30a5bc61886726f27f0cbbeccc0e26050dca', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1b737c33cc4d15be130ec08b484230c9b77ec9eb\n'}]",0,313238,417a30a5bc61886726f27f0cbbeccc0e26050dca,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1b737c33cc4d15be130ec08b484230c9b77ec9eb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/313238/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po']",2,417a30a5bc61886726f27f0cbbeccc0e26050dca,zanata/translations,"""POT-Creation-Date: 2016-05-04 07:18+0000\n""""PO-Revision-Date: 2016-05-05 06:17+0000\n""msgid """" ""For more information about how to download and build images, see `OpenStack "" ""Virtual Machine Image Guide <http://docs.openstack.org/image-guide/>`__. For "" ""information about how to manage images, see the `OpenStack End User Guide "" ""<http://docs.openstack.org/user-guide/common/cli_manage_images.html>`__."" msgstr """" ""        `OpenStack Virtual "" ""Machine Image Guide <http://docs.openstack.org/image-guide/>`__  "" "".       `OpenStack End User Guide "" ""<http://docs.openstack.org/user-guide/common/cli_manage_images.html>`__  "" ""."" msgid """" ""For more information about how to manage shares, see the `Manage shares "" ""<http://docs.openstack.org/user-guide/cli_manage_shares.html>`__ in "" ""OpenStack End User Guide."" msgstr """" ""      OpenStack End User Guide  `Manage "" ""shares <http://docs.openstack.org/user-guide/cli_manage_shares.html>`__  "" ""."" msgid """" ""For more information about how to manage volumes, see the `Manage volumes "" ""<http://docs.openstack.org/user-guide/common/cli_manage_volumes.html>`__ in "" ""OpenStack End User Guide."" msgstr """" ""      OpenStack End User Guide  `Manage "" ""volumes <http://docs.openstack.org/user-guide/common/cli_manage_volumes."" ""html>`__  ."" ""The previous section used a combination of environment variables and command "" ""options to interact with the Identity service via the ``openstack`` client. "" ""To increase efficiency of client operations, OpenStack supports simple "" ""client environment scripts also known as OpenRC files. These scripts "" ""typically contain common options for all clients, but also support unique "" ""options. For more information, see the `OpenStack End User Guide <http://"" ""docs.openstack.org/user-guide/common/ "" ""cli_set_environment_variables_using_openstack_rc.html>`__."" msgstr """" ""  ``openstack``   Identity   "" ""       .  "" ""    , OpenStack OpenRC     "" ""   .     "" ""         .   "" "" `OpenStack End User Guide <http://docs.openstack.org/user-guide/"" ""common/ cli_set_environment_variables_using_openstack_rc.html>`__  "" ""."" msgid """"""This section creates the necessary virtual networks to support launching "" ""instances. Networking option 1 includes one provider (external) network with "" ""one instance that uses it. Networking option 2 includes one provider network "" ""with one instance that uses it and one self-service (private) network with "" ""one instance that uses it. The instructions in this section use command-line "" ""interface (CLI) tools on the controller node. For more information on the "" ""CLI tools, see the `OpenStack End User Guide <http://docs.openstack.org/user-"" ""guide/cli_launch_instances.html>`__. To use the dashboard, see the "" ""`OpenStack End User Guide <http://docs.openstack.org/user-guide/dashboard."" ""html>`__."" msgstr """" ""         "" "".   1   ()    "" "" .   2      "" ""      ()     "" ""  .        "" ""(CLI)  . CLI     `OpenStack End User "" ""Guide <http://docs.openstack.org/user-guide/cli_launch_instances.html>`__  "" "".   `OpenStack End User Guide <http://docs."" ""openstack.org/user-guide/dashboard.html>`__   ."" msgid """"","""POT-Creation-Date: 2016-05-04 01:03+0000\n""""PO-Revision-Date: 2016-04-29 10:37+0000\n""",585,4
openstack%2Fopenstack-ansible~kilo~Id90c16cccb641eac9768e11c85ee4b4fde14d52c,openstack/openstack-ansible,kilo,Id90c16cccb641eac9768e11c85ee4b4fde14d52c,Updates all SHAs for 11.2.16,MERGED,2016-05-05 18:08:12.000000000,2016-05-06 06:42:53.000000000,2016-05-06 06:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-05 18:08:12.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bca70f6649e90d97f0e71cb0c76925d52c2a7368', 'message': 'Updates all SHAs for 11.2.16\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nChange-Id: Id90c16cccb641eac9768e11c85ee4b4fde14d52c\n'}]",0,313091,bca70f6649e90d97f0e71cb0c76925d52c2a7368,7,3,1,6816,,,0,"Updates all SHAs for 11.2.16

This patch includes updates of any changed paste, policy and rootwrap
configurations. It also includes updates to the pip, wheel and
setuptools pins.

Change-Id: Id90c16cccb641eac9768e11c85ee4b4fde14d52c
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/91/313091/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml']",6,bca70f6649e90d97f0e71cb0c76925d52c2a7368,,openstack_release: 11.2.16,openstack_release: 11.2.15,20,20
openstack%2Fkolla~master~I3e9652e1cac156f822b388d2b9fd910180b4a892,openstack/kolla,master,I3e9652e1cac156f822b388d2b9fd910180b4a892,Deleting only images from kolla build,MERGED,2016-03-01 20:31:38.000000000,2016-05-06 06:40:34.000000000,2016-05-06 06:40:34.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 5638}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 11105}, {'_account_id': 13642}, {'_account_id': 14967}, {'_account_id': 16233}, {'_account_id': 16620}, {'_account_id': 17731}, {'_account_id': 18652}]","[{'number': 1, 'created': '2016-03-01 20:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/da94a4514d8cae51f8d03d894069cdb0e96742ea', 'message': 'Deleting only images from kolla\n\nGet only images from kolla repository.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nCloses-Bug: #1551933\n'}, {'number': 2, 'created': '2016-03-02 17:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b28b626935d4abe2beb00976f9e88e9dfcf1cbf9', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository, <none> images\nand OS defined on set up in the kolla-build.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nCloses-Bug: #1551933\n'}, {'number': 3, 'created': '2016-03-03 11:29:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a46cec048dcf691f63c5e7325234eb35bf2b1de6', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository, <none> images.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 4, 'created': '2016-03-03 12:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3c32cdb3f42810b681fa970af16b725780bf0823', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository, <none> images.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 5, 'created': '2016-03-04 20:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/242360897ae1f899bc4a68fb900b832951d9df3f', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 6, 'created': '2016-03-07 14:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/714eb708dbda1da80fc8aa99340ec08f1d7cdbe3', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 7, 'created': '2016-03-07 16:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1f5819ef68ced10359af6d5ab35e18cddc914fe2', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 8, 'created': '2016-05-05 13:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/31636db9b4fd077ceabee4da67f2499349fc7f31', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository.\n\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 9, 'created': '2016-05-05 15:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d3c9c3eb5ac41b664c8772106282cf886b2662b8', 'message': 'Deleting only images from kolla build\n\nDelete images from kolla repository.\n\nCo-Authored-By: Carlos Cesario <carloscesario@gmail.com>\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nDocImpact\nCloses-Bug: #1551933\n'}, {'number': 10, 'created': '2016-05-05 16:15:32.000000000', 'files': ['doc/operating-kolla.rst', 'tools/cleanup-images'], 'web_link': 'https://opendev.org/openstack/kolla/commit/902456406640975b63685e3abc99ec95de336c17', 'message': 'Deleting only images from kolla build\n\nCo-Authored-By: Carlos Cesario <carloscesario@gmail.com>\nChange-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892\nCloses-Bug: #1551933\n'}]",42,286823,902456406640975b63685e3abc99ec95de336c17,67,12,10,14967,,,0,"Deleting only images from kolla build

Co-Authored-By: Carlos Cesario <carloscesario@gmail.com>
Change-Id: I3e9652e1cac156f822b388d2b9fd910180b4a892
Closes-Bug: #1551933
",git fetch https://review.opendev.org/openstack/kolla refs/changes/23/286823/9 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-images'],1,da94a4514d8cae51f8d03d894069cdb0e96742ea,bug/1551933,"IMAGES=`docker images -a | grep -i -E ""ubuntu-source-|ubuntu-binary-|centos-source-|centos-binary-"" | awk '{print $3}'`",IMAGES=`docker images -a -q`,1,1
openstack%2Fneutron-dynamic-routing~master~I395ca9541bceda40bbc0c0870e58c18231ba44e9,openstack/neutron-dynamic-routing,master,I395ca9541bceda40bbc0c0870e58c18231ba44e9,Added alembic DB migration framework,MERGED,2016-04-28 11:41:13.000000000,2016-05-06 06:34:44.000000000,2016-05-06 06:34:44.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4187}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 14258}, {'_account_id': 14605}, {'_account_id': 15309}, {'_account_id': 17455}]","[{'number': 1, 'created': '2016-04-28 11:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/bf3392d823eeeb7cee7f784d86fabeddf03de76f', 'message': 'iAdded alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 2, 'created': '2016-04-28 11:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/260bc1eb9b29201a6e0e5e5cc6e8e9af23a8329c', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 3, 'created': '2016-04-29 14:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/48535484f1c292d42735722a09f20c8f512cf2e0', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 4, 'created': '2016-04-29 14:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/1552c9a6780f193078083be4014ba8cb0f9fd65d', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 5, 'created': '2016-04-29 15:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/5dbfbfe7624520d94f5127ef43e49fa8c91967a3', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 6, 'created': '2016-05-03 04:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/98c5205b5d5ba96b1940b2b543846820c17f615a', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 7, 'created': '2016-05-03 09:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/6f9fe7bc07ad4cdee82b1ec1fe523497ccacc5ba', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 8, 'created': '2016-05-03 10:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/da87e2dd3af072c025900f6a33222be628b3f814', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 9, 'created': '2016-05-03 14:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/a80e9162ae6f7ae02337d8e504701537eff1a6d6', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 10, 'created': '2016-05-03 15:50:57.000000000', 'files': ['neutron_dynamic_routing/db/migration/models/__init__.py', 'neutron_dynamic_routing/db/migration/models/head.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/env.py', 'neutron_dynamic_routing/db/migration/README', 'neutron_dynamic_routing/db/migration/__init__.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/script.py.mako', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/start_neutron_dynamic_routing.py', 'neutron_dynamic_routing/db/__init__.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/newton/expand/f399fa0f5f25_initial.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/CONTRACT_HEAD', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/newton/contract/61cc795e43e8_initial.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/__init__.py', 'setup.cfg', 'tox.ini', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/EXPAND_HEAD'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/61a933f105cad0a764417e1cf9cee9166df8926b', 'message': 'Added alembic DB migration framework\n\nThis patch adds alembic DB migration framework required by\nneutron-dynamic-routing repository for defining new data\nmodels to realize BGP dynamic routing functionality in neutron.\n\nBelow changes are done as part of this patch-set:\n - Added new alembic migration framework.\n - PEP8 changes for alembic migration check.\n\nChange-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}]",18,310749,61a933f105cad0a764417e1cf9cee9166df8926b,44,11,10,14605,,,0,"Added alembic DB migration framework

This patch adds alembic DB migration framework required by
neutron-dynamic-routing repository for defining new data
models to realize BGP dynamic routing functionality in neutron.

Below changes are done as part of this patch-set:
 - Added new alembic migration framework.
 - PEP8 changes for alembic migration check.

Change-Id: I395ca9541bceda40bbc0c0870e58c18231ba44e9
Implements: blueprint bgp-spinout
Partial-Bug: #1560003
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/49/310749/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_dynamic_routing/db/migration/models/__init__.py', 'neutron_dynamic_routing/db/migration/models/head.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/env.py', 'neutron_dynamic_routing/db/migration/README', 'neutron_dynamic_routing/db/migration/__init__.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/newton/expand/24fc7241aa5_initial.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/script.py.mako', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/start_neutron_dynamic_routing.py', 'neutron_dynamic_routing/db/__init__.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/newton/contract/48072cb59133_initial.py', 'neutron_dynamic_routing/db/migration/alembic_migrations/__init__.py', 'tox.ini', 'neutron_dynamic_routing/db/migration/alembic_migrations/versions/HEADS']",13,bf3392d823eeeb7cee7f784d86fabeddf03de76f,bp/bgp-spinout,48072cb59133 24fc7241aa5 ,,248,1
openstack%2Fproject-config~master~Ib762bf4aed5d6f027bbef3a873c6a4ca8786ad58,openstack/project-config,master,Ib762bf4aed5d6f027bbef3a873c6a4ca8786ad58,Add experimental-project-config-layout for ubuntu-precise,MERGED,2016-05-05 22:49:29.000000000,2016-05-06 06:32:04.000000000,2016-05-06 06:32:04.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-05-05 22:49:29.000000000', 'files': ['jenkins/jobs/infra.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f03b83352efa085073427229fabb562193ab6ca9', 'message': 'Add experimental-project-config-layout for ubuntu-precise\n\nThis is part of our effort to remove bare-precise from the gate.\n\nChange-Id: Ib762bf4aed5d6f027bbef3a873c6a4ca8786ad58\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,313182,f03b83352efa085073427229fabb562193ab6ca9,7,3,1,4162,,,0,"Add experimental-project-config-layout for ubuntu-precise

This is part of our effort to remove bare-precise from the gate.

Change-Id: Ib762bf4aed5d6f027bbef3a873c6a4ca8786ad58
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/313182/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/infra.yaml', 'zuul/layout.yaml']",2,f03b83352efa085073427229fabb562193ab6ca9,, experimental: - experimental-project-config-layout experimental: - experimental-project-config-layout,,18,0
openstack%2Fsenlin~master~I27df9979f94298ef1cdb75c19c1c83d13600e7fd,openstack/senlin,master,I27df9979f94298ef1cdb75c19c1c83d13600e7fd,Add tempest tests for receiver create/delete API,MERGED,2016-05-04 07:23:43.000000000,2016-05-06 06:22:35.000000000,2016-05-06 06:22:35.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-05-04 07:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e7ae0653df2c2e846ecf43bfc20808d0ee862c57', 'message': 'Add tempest tests for receiver create/delete API\n\nAdd tempest tests for receiver create/delete API and webhook\ntrigger API.\n\nBlueprint tempest-plugin-interface\nChange-Id: I27df9979f94298ef1cdb75c19c1c83d13600e7fd\n'}, {'number': 2, 'created': '2016-05-05 07:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d7baf3fb5870e1b709f8e31fa589b853fc1cf09e', 'message': 'Add tempest tests for receiver create/delete API\n\nAdd tempest tests for receiver create/delete API and webhook\ntrigger API.\n\nBlueprint tempest-plugin-interface\nChange-Id: I27df9979f94298ef1cdb75c19c1c83d13600e7fd\n'}, {'number': 3, 'created': '2016-05-05 07:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6052f2a707f80e618afebd27684f7e4561fe0fd5', 'message': 'Add tempest tests for receiver create/delete API\n\nAdd tempest tests for receiver create/delete API and webhook\ntrigger API.\n\nBlueprint tempest-plugin-interface\nChange-Id: I27df9979f94298ef1cdb75c19c1c83d13600e7fd\n'}, {'number': 4, 'created': '2016-05-05 07:43:03.000000000', 'files': ['senlin/tests/tempest/api/receivers/__init__.py', 'senlin/tests/tempest/api/receivers/test_receiver_create.py', 'senlin/tests/tempest/api/receivers/test_receiver_delete.py', 'senlin/tests/tempest/api/receivers/test_trigger_webhook.py', 'senlin/tests/tempest/common/clustering_client.py', 'senlin/tests/tempest/api/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6870cc7250cd466dc27499ee352194e32ac99843', 'message': 'Add tempest tests for receiver create/delete API\n\nAdd tempest tests for receiver create/delete API and webhook\ntrigger API.\n\nBlueprint tempest-plugin-interface\nChange-Id: I27df9979f94298ef1cdb75c19c1c83d13600e7fd\n'}]",4,312344,6870cc7250cd466dc27499ee352194e32ac99843,15,4,4,7404,,,0,"Add tempest tests for receiver create/delete API

Add tempest tests for receiver create/delete API and webhook
trigger API.

Blueprint tempest-plugin-interface
Change-Id: I27df9979f94298ef1cdb75c19c1c83d13600e7fd
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/312344/4 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/tempest/api/receivers/__init__.py', 'senlin/tests/tempest/api/receivers/test_receiver_create_delete.py', 'senlin/tests/tempest/api/receivers/test_trigger_webhook.py', 'senlin/tests/tempest/common/clustering_client.py', 'senlin/tests/tempest/api/base.py']",5,e7ae0653df2c2e846ecf43bfc20808d0ee862c57,bp/tempest-plugin-interface," @classmethod def create_receiver(cls, cluster_id, action, r_type, name=None, params=None): """"""Utility function that generates a Senlin receiver."""""" if name is None: name = data_utils.rand_name(""tempest-created-receiver"") body = { 'receiver': { 'name': name, 'cluster_id': cluster_id, 'type': r_type, 'action': action, 'params': params } } res = cls.client.create_obj('receivers', body) return res['body'] @classmethod def delete_receiver(cls, receiver_id, ignore_missing=False): """"""Utility function that deletes a Senlin receiver."""""" res = cls.client.delete_obj('receivers', receiver_id) if res['status'] == 404: if ignore_missing: return raise exceptions.NotFound()",,164,0
openstack%2Fopenstack-ansible~liberty~I65aec5d13b5b4d5e93dbbe8ad1c7bd4b0b523b97,openstack/openstack-ansible,liberty,I65aec5d13b5b4d5e93dbbe8ad1c7bd4b0b523b97,Updates all SHAs for 12.0.13,MERGED,2016-05-05 18:13:26.000000000,2016-05-06 06:19:42.000000000,2016-05-06 06:19:42.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-05 18:13:26.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/02f7e11582e6dd4db759018e03cccc3d20309167', 'message': 'Updates all SHAs for 12.0.13\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nThe temporary pin introduced in https://review.openstack.org/309511\nhas been removed now that the issue has been resolved upstream.\n\nChange-Id: I65aec5d13b5b4d5e93dbbe8ad1c7bd4b0b523b97\n'}]",0,313094,02f7e11582e6dd4db759018e03cccc3d20309167,7,3,1,6816,,,0,"Updates all SHAs for 12.0.13

This patch includes updates of any changed paste, policy and rootwrap
configurations. It also includes updates to the pip, wheel and
setuptools pins.

The temporary pin introduced in https://review.openstack.org/309511
has been removed now that the issue has been resolved upstream.

Change-Id: I65aec5d13b5b4d5e93dbbe8ad1c7bd4b0b523b97
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/313094/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/all.yml']",4,02f7e11582e6dd4db759018e03cccc3d20309167,,openstack_release: 12.0.13,openstack_release: 12.0.12,18,21
openstack%2Fpuppet-manila~stable%2Fmitaka~I4be1d633b2fab3d2b73576e88c334d4b74f5de2d,openstack/puppet-manila,stable/mitaka,I4be1d633b2fab3d2b73576e88c334d4b74f5de2d,Fix typo in metadata.json,MERGED,2016-05-05 22:11:22.000000000,2016-05-06 06:13:16.000000000,2016-05-06 06:13:16.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 10353}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-05 22:11:22.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/9d528ae58ca0c5339e2fdab443abbdf13edbb072', 'message': ""Fix typo in metadata.json\n\n  This commit fixes a simple typo in the metadata.json file.\n\n  I though I had smoke tested builds of every module before submitting\n  review, guess I missed one.  Modules won't build withoug this change.\n\nChange-Id: I4be1d633b2fab3d2b73576e88c334d4b74f5de2d\n""}]",0,313174,9d528ae58ca0c5339e2fdab443abbdf13edbb072,8,4,1,7423,,,0,"Fix typo in metadata.json

  This commit fixes a simple typo in the metadata.json file.

  I though I had smoke tested builds of every module before submitting
  review, guess I missed one.  Modules won't build withoug this change.

Change-Id: I4be1d633b2fab3d2b73576e88c334d4b74f5de2d
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/74/313174/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,9d528ae58ca0c5339e2fdab443abbdf13edbb072,," { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=5.3.1 <6.0.0"" },"," { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=5.3.1<6.0.0"" },",1,1
openstack%2Fpuppet-openstack_spec_helper~stable%2Fmitaka~I9b55dafc9ce4247d52c081e926e11d12c0b04064,openstack/puppet-openstack_spec_helper,stable/mitaka,I9b55dafc9ce4247d52c081e926e11d12c0b04064,Explicitly define the fact puppetversion,MERGED,2016-05-04 22:15:18.000000000,2016-05-06 05:58:43.000000000,2016-05-06 05:58:43.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 7745}]","[{'number': 1, 'created': '2016-05-04 22:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/b217c0fe110a28e0ee2f7d5edaa3d2f9d512c969', 'message': 'Explicitly define the fact puppetversion\n\n  This commit explicitly define\'s the ""puppetversion"" fact to the method\n  Puppet.version.\n\n  This is required to guarantee the fact exists in spec testing across\n  all combinations of puppet, facter, and rspec-puppet.[1][2]\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5683\n  [2] https://github.com/puppetlabs/puppetlabs-puppet_agent/blob/4587e24654b8e1d225adcc7b899aaaac3ba8488f/spec/classes/puppet_agent_windows_install_spec.rb#L18\n\nChange-Id: I9b55dafc9ce4247d52c081e926e11d12c0b04064\n'}, {'number': 2, 'created': '2016-05-05 18:27:39.000000000', 'files': ['lib/puppet-openstack_spec_helper/defaults.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/06351a143b9dd0e197cae9a893779bbb7520dd07', 'message': 'Explicitly define the fact puppetversion\n\n  This commit explicitly define\'s the ""puppetversion"" fact to the method\n  Puppet.version.\n\n  This is required to guarantee the fact exists in spec testing across\n  all combinations of puppet, facter, and rspec-puppet.[1][2]\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5683\n  [2] https://github.com/puppetlabs/puppetlabs-puppet_agent/blob/4587e24654b8e1d225adcc7b899aaaac3ba8488f/spec/classes/puppet_agent_windows_install_spec.rb#L18\n\nChange-Id: I9b55dafc9ce4247d52c081e926e11d12c0b04064\n(cherry picked from commit 5b126b95374cbe3898b0404c76a6f9802072f3e5)\n'}]",0,312769,06351a143b9dd0e197cae9a893779bbb7520dd07,14,4,2,7423,,,0,"Explicitly define the fact puppetversion

  This commit explicitly define's the ""puppetversion"" fact to the method
  Puppet.version.

  This is required to guarantee the fact exists in spec testing across
  all combinations of puppet, facter, and rspec-puppet.[1][2]

  [1] https://tickets.puppetlabs.com/browse/PUP-5683
  [2] https://github.com/puppetlabs/puppetlabs-puppet_agent/blob/4587e24654b8e1d225adcc7b899aaaac3ba8488f/spec/classes/puppet_agent_windows_install_spec.rb#L18

Change-Id: I9b55dafc9ce4247d52c081e926e11d12c0b04064
(cherry picked from commit 5b126b95374cbe3898b0404c76a6f9802072f3e5)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/69/312769/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet-openstack_spec_helper/defaults.rb'],1,b217c0fe110a28e0ee2f7d5edaa3d2f9d512c969,backport_puppetversion," { :os_service_default => '<SERVICE DEFAULT>', :puppetversion => Puppet.version }.merge(extra_facts)", { :os_service_default => '<SERVICE DEFAULT>' }.merge(extra_facts),4,1
openstack%2Fcharm-keystone~stable%2F16.04~I2e96eba9e55d9a7e3b9ade2090f88a74467ba334,openstack/charm-keystone,stable/16.04,I2e96eba9e55d9a7e3b9ade2090f88a74467ba334,Fix missing keystone user in cron job.,ABANDONED,2016-05-06 04:58:51.000000000,2016-05-06 05:39:24.000000000,,[{'_account_id': 20648}],"[{'number': 1, 'created': '2016-05-06 04:58:51.000000000', 'files': ['templates/keystone-token-flush'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b818e7b88d976bf6d81047d52fe4569d90406ec0', 'message': 'Fix missing keystone user in cron job.\n\nWhen use_syslog = False, the keystone-token-flush cronjob omits the\nkeystone username in the cron tab file, which causes cron to skip\nthe entry and report errors into the cron job. This change fixes\nthe problem.\n\nChange-Id: I2e96eba9e55d9a7e3b9ade2090f88a74467ba334\nCloses-Bug: 1578914\n'}]",0,313225,b818e7b88d976bf6d81047d52fe4569d90406ec0,3,1,1,8992,,,0,"Fix missing keystone user in cron job.

When use_syslog = False, the keystone-token-flush cronjob omits the
keystone username in the cron tab file, which causes cron to skip
the entry and report errors into the cron job. This change fixes
the problem.

Change-Id: I2e96eba9e55d9a7e3b9ade2090f88a74467ba334
Closes-Bug: 1578914
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/25/313225/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone-token-flush'],1,b818e7b88d976bf6d81047d52fe4569d90406ec0,bug/1578914,0 * * * * keystone /usr/bin/keystone-manage token_flush >> /var/log/keystone/keystone-token-flush.log 2>&1,0 * * * * /usr/bin/keystone-manage token_flush >> /var/log/keystone/keystone-token-flush.log 2>&1,1,1
openstack%2Fhorizon~master~I6de361ad3a602329abd7b09c485bd4c4fd7d5a76,openstack/horizon,master,I6de361ad3a602329abd7b09c485bd4c4fd7d5a76,Edit Extra Spec Value Fail,MERGED,2016-05-03 20:59:58.000000000,2016-05-06 05:13:27.000000000,2016-05-06 05:13:27.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 11778}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-05-03 20:59:58.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/volume_types/extras/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5fdc1402ccbb1dcdc683682613414ff1be0bcb6e', 'message': ""Edit Extra Spec Value Fail\n\nThis patch fixes the modal-header content when\nthe form is invalid.\n\nA wrong message was shown when the user didn't\nprovide a valid value for this form.\n\nChange-Id: I6de361ad3a602329abd7b09c485bd4c4fd7d5a76\nCloses-bug: #1570488\n""}]",0,312249,5fdc1402ccbb1dcdc683682613414ff1be0bcb6e,10,5,1,9155,,,0,"Edit Extra Spec Value Fail

This patch fixes the modal-header content when
the form is invalid.

A wrong message was shown when the user didn't
provide a valid value for this form.

Change-Id: I6de361ad3a602329abd7b09c485bd4c4fd7d5a76
Closes-bug: #1570488
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/312249/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/volumes/volume_types/extras/views.py'],1,5fdc1402ccbb1dcdc683682613414ff1be0bcb6e,bug/1570488," def form_invalid(self, form): context = super(EditView, self).get_context_data() context = self._populate_context(context) context['form'] = form context['modal_header'] = self.modal_header % self.kwargs['key'] return self.render_to_response(context)",,7,0
openstack%2Fsenlin~master~I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0,openstack/senlin,master,I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0,API documentation for profiles (1),MERGED,2016-04-21 10:36:35.000000000,2016-05-06 05:09:48.000000000,2016-05-06 05:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-04-21 10:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/62a0926f7bf9598a098641cc2be86d5e382025a6', 'message': 'API documentation for profiles (1)\n\nThis is the first patch for profile APIs. This patch is about profile\nlisting. Following patch will add docs for other operations.\n\nChange-Id: I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0\n'}, {'number': 2, 'created': '2016-04-21 13:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/690b0177c53f0b6856a2dc38207b67100e048263', 'message': 'API documentation for profiles (1)\n\nThis is the first patch for profile APIs. This patch is about profile\nlisting. Following patch will add docs for other operations.\n\nChange-Id: I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0\n'}, {'number': 3, 'created': '2016-04-22 12:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/24860b5002a10c49b6356288a575be9ccc0cb114', 'message': 'API documentation for profiles (1)\n\nThis is the first patch for profile APIs. This patch is about profile\nlisting. Following patch will add docs for other operations.\n\nChange-Id: I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0\n'}, {'number': 4, 'created': '2016-05-06 01:53:52.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/index.rst', 'api-ref/source/profile_types.inc', 'api-ref/source/profiles.inc', 'api-ref/source/samples/profile-list-response.json', 'api-ref/source/policy_types.inc'], 'web_link': 'https://opendev.org/openstack/senlin/commit/91ffe868193cb5f8949316f1af18efc0e4593a9b', 'message': 'API documentation for profiles (1)\n\nThis is the first patch for profile APIs. This patch is about profile\nlisting. Following patch will add docs for other operations.\n\nChange-Id: I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0\n'}]",2,308890,91ffe868193cb5f8949316f1af18efc0e4593a9b,14,3,4,8246,,,0,"API documentation for profiles (1)

This is the first patch for profile APIs. This patch is about profile
listing. Following patch will add docs for other operations.

Change-Id: I2f5a7152b15f3c900bdc9cd6cb418c30ff6487f0
",git fetch https://review.opendev.org/openstack/senlin refs/changes/90/308890/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/index.rst', 'api-ref/source/profiles.inc', 'api-ref/source/samples/profile-list-response.json']",4,62a0926f7bf9598a098641cc2be86d5e382025a6,api-doc-profile-1,"{ ""profiles"": [ { ""created_at"": ""2016-01-03T16:22:23"", ""domain"": null, ""id"": ""9e1c6f42-acf5-4688-be2c-8ce954ef0f23"", ""metadata"": {}, ""name"": ""pserver"", ""project"": ""42d9e9663331431f97b75e25136307ff"", ""spec"": { ""properties"": { ""flavor"": 1, ""image"": ""cirros-0.3.4-x86_64-uec"", ""key_name"": ""oskey"", ""name"": ""cirros_server"", ""networks"": [ { ""network"": ""private"" } ] }, ""type"": ""os.nova.server"", ""version"": 1.0 }, ""type"": ""os.nova.server-1.0"", ""updated_at"": null, ""user"": ""5e5bf8027826429c96af157f68dc9072"" } ] } ",,233,2
openstack%2Fneutron~master~I5d11005d0aca681af99a011812ea53f92f2a400d,openstack/neutron,master,I5d11005d0aca681af99a011812ea53f92f2a400d,"Partial revert ""DVR: Fix issue of SNAT rule for DVR with floating ip""",MERGED,2016-04-04 20:56:24.000000000,2016-05-06 04:56:45.000000000,2016-05-06 04:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6876}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14611}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-04 20:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca1415422ae14cc4a6465df94450fcaf5e251ab0', 'message': 'Revert ""DVR: Fix issue of SNAT rule for DVR with floating ip""\n\nThis reverts commit 1cea77b0aafbada6cad89a6fe0f5450004aef4e1.\n\nChange-Id: I5d11005d0aca681af99a011812ea53f92f2a400d\n'}, {'number': 2, 'created': '2016-04-06 07:12:39.000000000', 'files': ['neutron/tests/functional/agent/l3/test_dvr_router.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/agent/l3/router_info.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2412ca016b4b69ba86f8a8fac0c2a0cdc1efa75b', 'message': 'Partial revert ""DVR: Fix issue of SNAT rule for DVR with floating ip""\n\nCommit 1cea77b0aafbada6cad89a6fe0f5450004aef4e1 try to resolve 2 problems\n\n1) The prevent snat rule that is added for floating ip will be cleaned,\nwhen restart the l3 agent.\n2) Ping floating ip, but reply with fixed ip\n\nTo resolve 2), SNAT to shared gateway was introduced for internal traffic\nto floating ip inside the qrouter namespace. But there is a potential issue\nwhen multiple router SNAT to one address. The destination VM might not be\nable to differentiate the incommint request. To avoid the potential issue,\nrevert the code for 2), but reserve the code for 1) in this patch\n\nChange-Id: I5d11005d0aca681af99a011812ea53f92f2a400d\nCo-Authored-By: Hong Hui Xiao <xiaohhui@cn.ibm.com>\n'}]",0,301348,2412ca016b4b69ba86f8a8fac0c2a0cdc1efa75b,43,18,2,7448,,,0,"Partial revert ""DVR: Fix issue of SNAT rule for DVR with floating ip""

Commit 1cea77b0aafbada6cad89a6fe0f5450004aef4e1 try to resolve 2 problems

1) The prevent snat rule that is added for floating ip will be cleaned,
when restart the l3 agent.
2) Ping floating ip, but reply with fixed ip

To resolve 2), SNAT to shared gateway was introduced for internal traffic
to floating ip inside the qrouter namespace. But there is a potential issue
when multiple router SNAT to one address. The destination VM might not be
able to differentiate the incommint request. To avoid the potential issue,
revert the code for 2), but reserve the code for 1) in this patch

Change-Id: I5d11005d0aca681af99a011812ea53f92f2a400d
Co-Authored-By: Hong Hui Xiao <xiaohhui@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/48/301348/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/functional/agent/l3/test_dvr_router.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/agent/l3/dvr_edge_router.py']",5,ca1415422ae14cc4a6465df94450fcaf5e251ab0,Bug1549311, # NOTE DVR doesn't add the jump to float snat like the super class.," super(DvrEdgeRouter, self)._handle_router_snat_rules( ex_gw_port, interface_name) # NOTE: DVR adds the jump to float snat via super class, # but that is in the router namespace and not snat.",26,96
openstack%2Fhorizon~master~I1ef79478f1309f11a6a7c4772cb844299496708b,openstack/horizon,master,I1ef79478f1309f11a6a7c4772cb844299496708b,[Trivial] Wrong policy for Heat resource type details,MERGED,2016-03-24 08:40:27.000000000,2016-05-06 04:47:03.000000000,2016-05-06 04:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8358}, {'_account_id': 8871}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-03-24 08:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fc10e3c0d5efcf71d727850fb953dfeb01b9acea', 'message': '[Trivial] Wrong policy for Heat resource type details\n\nTrivialFix\n\nChange-Id: I1ef79478f1309f11a6a7c4772cb844299496708b\n'}, {'number': 2, 'created': '2016-03-25 12:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bc3e18f5b21b1a62c61135ba2211c2509ce0c084', 'message': '[Trivial] Wrong policy for Heat resource type details\n\nTrivialFix\n\nChange-Id: I1ef79478f1309f11a6a7c4772cb844299496708b\n'}, {'number': 3, 'created': '2016-05-05 06:47:08.000000000', 'files': ['openstack_dashboard/dashboards/project/stacks/resource_types/tabs.py', 'openstack_dashboard/dashboards/project/stacks/resource_types/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2f46511ff0678ddcf2aa5d6d3bd007d62db6367', 'message': '[Trivial] Wrong policy for Heat resource type details\n\nTrivialFix\n\nChange-Id: I1ef79478f1309f11a6a7c4772cb844299496708b\n'}]",0,296949,e2f46511ff0678ddcf2aa5d6d3bd007d62db6367,19,7,3,6914,,,0,"[Trivial] Wrong policy for Heat resource type details

TrivialFix

Change-Id: I1ef79478f1309f11a6a7c4772cb844299496708b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/296949/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/stacks/resource_types/tabs.py', 'openstack_dashboard/conf/heat_policy.json']",2,fc10e3c0d5efcf71d727850fb953dfeb01b9acea,resource_type_policy," ""cloudformation:DescribeResourceType"": ""rule:deny_stack_user"",",,2,1
openstack%2Fha-guide~master~I3442992e6ac9985264a0645b8f0944838f07d126,openstack/ha-guide,master,I3442992e6ac9985264a0645b8f0944838f07d126,Add a note of virtual node,ABANDONED,2016-04-20 10:00:33.000000000,2016-05-06 04:46:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-04-20 10:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e2cc69cce8a4790fd2ebfc4eb6eb9a333fe87ff2', 'message': ""Add a note of virtual node\n\nThe HA guide is organized based the installation guide, so the\nvirtual node cannot use the 'controller' as the hostname and\nthe '10.0.0.11' as the virtual IP.\n\nChange-Id: I3442992e6ac9985264a0645b8f0944838f07d126\nCloses-Bug: #1564466\n""}, {'number': 2, 'created': '2016-04-21 05:22:49.000000000', 'files': ['doc/ha-guide/source/install-ha-os.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/d472bc1e016a0bd0ba74cdae6725a6eaaaeff44a', 'message': ""Add a note of virtual node\n\nThe HA guide is organized based the installation guide, so the\nvirtual node cannot use the 'controller' as the hostname and\nthe '10.0.0.11' as the virtual IP.\n\nChange-Id: I3442992e6ac9985264a0645b8f0944838f07d126\nCloses-Bug: #1564466\n""}]",1,308237,d472bc1e016a0bd0ba74cdae6725a6eaaaeff44a,9,5,2,19779,,,0,"Add a note of virtual node

The HA guide is organized based the installation guide, so the
virtual node cannot use the 'controller' as the hostname and
the '10.0.0.11' as the virtual IP.

Change-Id: I3442992e6ac9985264a0645b8f0944838f07d126
Closes-Bug: #1564466
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/37/308237/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/install-ha-os.rst'],1,e2cc69cce8a4790fd2ebfc4eb6eb9a333fe87ff2,bug/1564466,".. note:: Before configuring the highly-available OpenStack cluster, ensure the IP of ``10.0.0.11`` and the hostname of ``controller`` are not in use. Once following the above installation guides, there is a controller node that use the ``controller` as its hostname and the ``10.0.0.11`` as its management interface IP address. In this case, Choose another IP and hostname which are not in use instead of keeping in step with the following example IP addresses. ",,10,0
openstack%2Fpython-monascaclient~master~Iccd67671424b61de521aaebe93212b693654b6e2,openstack/python-monascaclient,master,Iccd67671424b61de521aaebe93212b693654b6e2,Add --tenant-id option for some commands,MERGED,2016-04-15 09:15:22.000000000,2016-05-06 04:42:05.000000000,2016-05-06 04:42:05.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 6676}, {'_account_id': 11809}, {'_account_id': 13560}, {'_account_id': 14517}, {'_account_id': 18179}]","[{'number': 1, 'created': '2016-04-15 09:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/7b2dfc50e72a75f8d4c49ca1468d2deb6218b330', 'message': ""Add --tenant-id option for some commands\n\nmetric-name-list, metric-list, metric-statistics and measurement-list\ndon't support retrieving data of a specified tenant, while REST API\nalready supports this functionality. This patch enables this option.\n\nChange-Id: Iccd67671424b61de521aaebe93212b693654b6e2\n""}, {'number': 2, 'created': '2016-04-27 18:08:57.000000000', 'files': ['monascaclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/4568736584b831613d4f757f88105e7bf2d4d8ad', 'message': ""Add --tenant-id option for some commands\n\nmetric-name-list, metric-list, metric-statistics and measurement-list\ndon't support retrieving data of a specified tenant, while REST API\nalready supports this functionality. This patch enables this option.\n\nChange-Id: Iccd67671424b61de521aaebe93212b693654b6e2\n""}]",2,306307,4568736584b831613d4f757f88105e7bf2d4d8ad,16,7,2,6676,,,0,"Add --tenant-id option for some commands

metric-name-list, metric-list, metric-statistics and measurement-list
don't support retrieving data of a specified tenant, while REST API
already supports this functionality. This patch enables this option.

Change-Id: Iccd67671424b61de521aaebe93212b693654b6e2
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/07/306307/2 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/v2_0/shell.py'],1,7b2dfc50e72a75f8d4c49ca1468d2deb6218b330,impl-tenant-id,"@utils.arg('--tenant-id', metavar='<TENANT_ID>', help='Retrieve data of the specified tenant/project.') if args.tenant_id: fields['tenant_id'] = args.tenant_id@utils.arg('--tenant-id', metavar='<TENANT_ID>', help='Retrieve data of the specified tenant/project.') if args.tenant_id: fields['tenant_id'] = args.tenant_id@utils.arg('--tenant-id', metavar='<TENANT_ID>', help='Retrieve data of the specified tenant/project.') if args.tenant_id: fields['tenant_id'] = args.tenant_id@utils.arg('--tenant-id', metavar='<TENANT_ID>', help='Retrieve data of the specified tenant/project.') if args.tenant_id: fields['tenant_id'] = args.tenant_id",,16,0
openstack%2Fha-guide~master~I5dae9344b618f72cffcae511801667af8e03411e,openstack/ha-guide,master,I5dae9344b618f72cffcae511801667af8e03411e,"replaced ""mysql"" with ""mysqld""",ABANDONED,2016-03-19 20:51:38.000000000,2016-05-06 04:17:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 9162}]","[{'number': 1, 'created': '2016-03-19 20:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/6897c2acf45f095592caca2ad3dc4de33dfd28c8', 'message': 'replaced ""mysql"" with ""mysqld""\nClsoes-Bug:#1559235\n\nChange-Id: I5dae9344b618f72cffcae511801667af8e03411e\n'}, {'number': 2, 'created': '2016-03-20 01:05:13.000000000', 'files': ['doc/ha-guide/source/controller-ha-galera-manage.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/2ee55927dd53d9e3894a80d0406a859948a476c9', 'message': 'replaced ""mysql"" with ""mysqld""\n\nCloses-Bug: #1559235\n\nChange-Id: I5dae9344b618f72cffcae511801667af8e03411e\n'}]",1,294957,2ee55927dd53d9e3894a80d0406a859948a476c9,7,3,2,20460,,,0,"replaced ""mysql"" with ""mysqld""

Closes-Bug: #1559235

Change-Id: I5dae9344b618f72cffcae511801667af8e03411e
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/57/294957/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-galera-manage.rst'],1,6897c2acf45f095592caca2ad3dc4de33dfd28c8,bug/1559235, # systemctl start mysqld --wsrep-new-cluster, # systemctl start mysql --wsrep-new-cluster,1,1
openstack%2Fha-guide~master~Ibee1d51ed2583b4b5a42e5e5fc984e4dd3036adc,openstack/ha-guide,master,Ibee1d51ed2583b4b5a42e5e5fc984e4dd3036adc,"replaced ""MariaDB-Galera-server"" to ""mariadb-galera-server""",ABANDONED,2016-03-19 20:33:36.000000000,2016-05-06 04:17:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8358}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-19 20:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/6182387080f08acfae20abb2888e7b91548ba6d7', 'message': 'replaced ""MariaDB-Galera-server"" to ""mariadb-galera-server""\nCloses-Bug:#1559227\n\nChange-Id: Ibee1d51ed2583b4b5a42e5e5fc984e4dd3036adc\n'}, {'number': 2, 'created': '2016-03-20 01:03:04.000000000', 'files': ['doc/ha-guide/source/controller-ha-galera-install.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/f5bb6cfd64dd46cc240600e901800885f13f9490', 'message': 'replaced ""MariaDB-Galera-server"" to ""mariadb-galera-server""\n\nCloses-Bug:#1559227\n\nChange-Id: Ibee1d51ed2583b4b5a42e5e5fc984e4dd3036adc\n'}]",6,294955,f5bb6cfd64dd46cc240600e901800885f13f9490,11,5,2,20460,,,0,"replaced ""MariaDB-Galera-server"" to ""mariadb-galera-server""

Closes-Bug:#1559227

Change-Id: Ibee1d51ed2583b4b5a42e5e5fc984e4dd3036adc
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/55/294955/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-galera-install.rst'],1,6182387080f08acfae20abb2888e7b91548ba6d7,bug/1559227, # yum install galera mariadb-galera-server # zypper install galera mariadb-galera-server, # yum install galera MariaDB-Galera-server # zypper install galera MariaDB-Galera-server,2,2
openstack%2Fha-guide~master~Ib5093c9ee361a81c72565ebd216c8e9229116194,openstack/ha-guide,master,Ib5093c9ee361a81c72565ebd216c8e9229116194,Fix the incorrect bind-address for mySQL specified,ABANDONED,2016-03-31 15:53:10.000000000,2016-05-06 04:17:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 8358}, {'_account_id': 9162}, {'_account_id': 14947}, {'_account_id': 19779}, {'_account_id': 20810}, {'_account_id': 21211}]","[{'number': 1, 'created': '2016-03-31 15:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/2ccdd22dee08198c1c922210c616255a331ca919', 'message': 'Fix the incorrect bind-address for mySQL specified\n\nChange-Id: Ib5093c9ee361a81c72565ebd216c8e9229116194\nCloses-Bug: #1558567\n'}, {'number': 2, 'created': '2016-04-01 09:39:19.000000000', 'files': ['doc/ha-guide/source/controller-ha-galera-config.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/9a15462aadc9636daba00617cd04078046522899', 'message': 'Fix the incorrect bind-address for mySQL specified\n\nChange-Id: Ib5093c9ee361a81c72565ebd216c8e9229116194\nCloses-Bug: #1558567\n'}]",4,300047,9a15462aadc9636daba00617cd04078046522899,12,8,2,19779,,,0,"Fix the incorrect bind-address for mySQL specified

Change-Id: Ib5093c9ee361a81c72565ebd216c8e9229116194
Closes-Bug: #1558567
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/47/300047/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-galera-config.rst'],1,2ccdd22dee08198c1c922210c616255a331ca919,bug/1558567," bind-address=10.0.0.12 ``127.0.0.1``.Also, do not bind it to ``0.0.0.0``. It makes ``mySQL`` bind to all IP addresses on the machine including the virtual IP address, which will cause ``HAProxy`` not to start. Instead, bind it to the management IP address of the controller node to enable access by other nodes via the management network: bind-address=10.0.0.12"," bind-address=0.0.0.0 ``127.0.0.1``. Instead, bind it to ``0.0.0.0`` to ensure it listens on all available interfaces. bind-address=0.0.0.0",7,4
openstack%2Ftempest~master~I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc,openstack/tempest,master,I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc,Added test for router's port update with fixed IP.,MERGED,2015-07-16 02:12:29.000000000,2016-05-06 04:03:11.000000000,2016-05-06 04:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 4727}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7016}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 13770}, {'_account_id': 15736}, {'_account_id': 15739}]","[{'number': 1, 'created': '2015-07-16 02:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c03cf6cce2302b77e6715b031cfaf87c3dac8cb8', 'message': ""Added tests for dvr router for port update & multiple subnets.\n\nTests Added:\n1)test_dvr_router_port_update_with_fixed_ip\n  This test verifies that DVR router's port can be updated with\n  new fixed ip.\n2)test_dvr_router_with_multiple_subnets\n  This test verifies that DVR router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\n""}, {'number': 2, 'created': '2015-07-16 21:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/70cdd094da09e51669872f2a1e91f2af89fdc3dd', 'message': ""Added tests for dvr router for port update & multiple subnets.\n\nTests Added:\n1)test_dvr_router_port_update_with_fixed_ip\n  This test verifies that DVR router's port can be updated with\n  new fixed ip.\n2)test_dvr_router_with_multiple_subnets\n  This test verifies that DVR router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 3, 'created': '2015-07-17 01:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cf3a1544b140b6eb17110a988754007cf759558', 'message': ""Added tests for dvr router for port update & multiple subnets.\n\nTests Added:\n1)test_dvr_router_port_update_with_fixed_ip\n  This test verifies that DVR router's port can be updated with\n  new fixed ip.\n2)test_dvr_router_with_multiple_subnets\n  This test verifies that DVR router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 4, 'created': '2015-12-11 17:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/34699dcd65f144ddc84e2fd26273ef64da43bd66', 'message': ""Added tests for dvr router for port update & multiple subnets.\n\nTests Added:\n1)test_dvr_router_port_update_with_fixed_ip\n  This test verifies that DVR router's port can be updated with\n  new fixed ip.\n2)test_dvr_router_with_multiple_subnets\n  This test verifies that DVR router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 5, 'created': '2016-01-07 22:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e83574fc3bae3364777bf35a1d9a5d8b8ccb6b5', 'message': ""Added tests for dvr router for port update & multiple subnets.\n\nTests Added:\n1)test_dvr_router_port_update_with_fixed_ip\n  This test verifies that DVR router's port can be updated with\n  new fixed ip.\n2)test_dvr_router_with_multiple_subnets\n  This test verifies that DVR router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 6, 'created': '2016-03-04 23:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6da78df457237348184388a7ff2cf08776a2381e', 'message': ""Added tests for router for port update & multiple subnets.\n\nTests Added:\n1)test_router_port_update_with_fixed_ip\n  This test verifies that router's port can be updated with\n  new fixed ip.\n2)test_router_with_multiple_subnets\n  This test verifies that router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 7, 'created': '2016-03-06 23:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/43fe157d8b59d87a0259f870d9afac85fb345aa4', 'message': ""Added tests for router for port update & multiple subnets.\n\nTests Added:\n1)test_router_port_update_with_fixed_ip\n  This test verifies that router's port can be updated with\n  new fixed ip.\n2)test_router_with_multiple_subnets\n  This test verifies that router's interface can be added to\n  multiple subnets (One with IPV4 and other with IPV6 address)\n  per network.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}, {'number': 8, 'created': '2016-04-07 18:54:53.000000000', 'files': ['tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e1a1707c531cd8b61c9a2d7106ced666d12e3105', 'message': ""Added test for router's port update with fixed IP.\n\nTest Added:\n- test_router_port_update_with_fixed_ip\n  This test verifies that router's port can be updated with\n  new fixed ip.\n\nChange-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc\nRelated-Bug: #1465434\n""}]",30,202351,e1a1707c531cd8b61c9a2d7106ced666d12e3105,88,13,8,15739,,,0,"Added test for router's port update with fixed IP.

Test Added:
- test_router_port_update_with_fixed_ip
  This test verifies that router's port can be updated with
  new fixed ip.

Change-Id: I1d685c7ef9cd6f55958edbd25fd768cc2be2f3dc
Related-Bug: #1465434
",git fetch https://review.opendev.org/openstack/tempest refs/changes/51/202351/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/admin/test_routers_dvr_multiple_subnets.py'],1,c03cf6cce2302b77e6715b031cfaf87c3dac8cb8,test_router_multiple_subnets,"# Copyright 2015 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.network import base_routers as base from tempest.common.utils import data_utils from tempest import config from tempest import test CONF = config.CONF class DvrRouterMultipleSubnetsTest(base.BaseRouterTest): @classmethod def skip_checks(cls): super(DvrRouterMultipleSubnetsTest, cls).skip_checks() if not test.is_extension_enabled('dvr', 'network'): msg = ""DVR extension not enabled."" raise cls.skipException(msg) @classmethod def setup_clients(cls): super(DvrRouterMultipleSubnetsTest, cls).setup_clients() cls.client = cls.admin_client @classmethod def resource_setup(cls): super(DvrRouterMultipleSubnetsTest, cls).resource_setup() cls.name = data_utils.rand_name('router') cls.net_name = data_utils.rand_name('network') cls.network = cls.client.create_network(name=cls.net_name) cls.subnet = cls.client.create_subnet( network_id=cls.network['network']['id'], cidr=CONF.network.tenant_network_cidr, ip_version=4) cls.router = cls.client.create_router(cls.name, distributed=True) if 'distributed' not in cls.router['router']: msg = ""'distributed' attribute not found. DVR Possibly not enabled"" raise cls.skipException(msg) @classmethod def resource_cleanup(cls): super(DvrRouterMultipleSubnetsTest, cls).resource_cleanup() cls.client.delete_router(cls.router['router']['id']) cls.client.delete_subnet(cls.subnet['subnet']['id']) cls.client.delete_network(cls.network['network']['id']) @test.idempotent_id('96522edf-b4b5-45d9-8443-fa11c26e6eff') def test_dvr_router_port_update_with_fixed_ip(self): self.fixed_ip = [{'subnet_id': self.subnet['subnet']['id']}] v4_interface = self.client.add_router_interface_with_subnet_id( self.router['router']['id'], self.subnet['subnet']['id']) self._verify_add_interface(v4_interface) port = self.client.update_port(port_id=v4_interface['port_id'], fixed_ips=self.fixed_ip) self.assertEqual(self.subnet['subnet']['id'], port['port']['fixed_ips'][0]['subnet_id']) self.addCleanup(self.client.remove_router_interface_with_subnet_id, self.router['router']['id'], self.subnet['subnet']['id']) @test.idempotent_id('02295b0f-290b-438b-965e-596c61530861') def test_dvr_router_with_multiple_subnets(self): v6_subnet = self.client.create_subnet( network_id=self.network['network']['id'], cidr=CONF.network.tenant_network_v6_cidr, ip_version=6) v4_interface = self.client.add_router_interface_with_subnet_id( self.router['router']['id'], self.subnet['subnet']['id']) v6_interface = self.client.add_router_interface_with_subnet_id( self.router['router']['id'], v6_subnet['subnet']['id']) self.addCleanup(self.client.remove_router_interface_with_subnet_id, self.router['router']['id'], self.subnet['subnet']['id']) self.addCleanup(self.client.remove_router_interface_with_subnet_id, self.router['router']['id'], v6_subnet['subnet']['id']) self._verify_add_interface(v4_interface) self._verify_add_interface(v6_interface) def _verify_add_interface(self, interface): self.assertIn('port_id', interface) self.assertIn('subnet_id', interface) ",,94,0
openstack%2Fopenstack-ansible~master~I7d2aea8f6548feb381bf2354965f05fa0a9a99b8,openstack/openstack-ansible,master,I7d2aea8f6548feb381bf2354965f05fa0a9a99b8,Removed container_release property from environment files,MERGED,2016-05-02 18:00:08.000000000,2016-05-06 04:02:15.000000000,2016-05-06 04:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 19814}, {'_account_id': 20038}]","[{'number': 1, 'created': '2016-05-02 18:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/77cb4fe9fd3064233d0e3ee228aa0f98fd052526', 'message': 'Removed container_release property from environment files\n\nThis change removes the container_release property from environment\nfiles used to generate inventory.  This change is because the\nlxc_container_create role has been updated to build containers to the\nsame distribution and release as the host machine.\n\nThis change also removes the variable lxc_container_release from the\nlxc-containers-create.yml play as it is no longer used by the\nlxc_container_create role.\n\nChange-Id: I7d2aea8f6548feb381bf2354965f05fa0a9a99b8\nDepends-On: Iee304dd026e0865e0444259d2132122233d90f5f\n'}, {'number': 2, 'created': '2016-05-02 18:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8269b6d896c63b53cbf940ff53cd2d481dbf976f', 'message': 'Removed container_release property from environment files\n\nThis change removes the container_release property from environment\nfiles used to generate inventory.  This change is because the\nlxc_container_create role has been updated to build containers to the\nsame distribution and release as the host machine.\n\nThis change also removes the variable lxc_container_release from the\nlxc-containers-create.yml play as it is no longer used by the\nlxc_container_create role.\n\nChange-Id: I7d2aea8f6548feb381bf2354965f05fa0a9a99b8\nDepends-On: Iee304dd026e0865e0444259d2132122233d90f5f\n'}, {'number': 3, 'created': '2016-05-05 10:23:50.000000000', 'files': ['etc/openstack_deploy/env.d/haproxy.yml', 'etc/openstack_deploy/env.d/heat.yml', 'etc/openstack_deploy/env.d/ironic.yml', 'etc/openstack_deploy/env.d/extra_container.yml.example', 'releasenotes/notes/remove-container-release-fa49ff23ca8c1324.yaml', 'etc/openstack_deploy/env.d/aodh.yml', 'etc/openstack_deploy/env.d/galera.yml', 'etc/openstack_deploy/env.d/cinder.yml', 'etc/openstack_deploy/env.d/nova.yml', 'playbooks/lxc-containers-create.yml', 'etc/openstack_deploy/env.d/neutron.yml', 'etc/openstack_deploy/env.d/horizon.yml', 'etc/openstack_deploy/env.d/swift-remote.yml', 'etc/openstack_deploy/env.d/ceilometer.yml', 'etc/openstack_deploy/env.d/glance.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a0bceb9dff2f9705109eecc04c12ca290aab7f01', 'message': 'Removed container_release property from environment files\n\nThis change removes the container_release property from environment\nfiles used to generate inventory.  This change is because the\nlxc_container_create role has been updated to build containers to the\nsame distribution and release as the host machine.\n\nThis change also removes the variable lxc_container_release from the\nlxc-containers-create.yml play as it is no longer used by the\nlxc_container_create role.\n\nChange-Id: I7d2aea8f6548feb381bf2354965f05fa0a9a99b8\nDepends-On: Iee304dd026e0865e0444259d2132122233d90f5f\n'}]",0,311802,a0bceb9dff2f9705109eecc04c12ca290aab7f01,18,6,3,20038,,,0,"Removed container_release property from environment files

This change removes the container_release property from environment
files used to generate inventory.  This change is because the
lxc_container_create role has been updated to build containers to the
same distribution and release as the host machine.

This change also removes the variable lxc_container_release from the
lxc-containers-create.yml play as it is no longer used by the
lxc_container_create role.

Change-Id: I7d2aea8f6548feb381bf2354965f05fa0a9a99b8
Depends-On: Iee304dd026e0865e0444259d2132122233d90f5f
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/02/311802/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/openstack_deploy/env.d/haproxy.yml', 'etc/openstack_deploy/env.d/heat.yml', 'etc/openstack_deploy/env.d/ironic.yml', 'etc/openstack_deploy/env.d/extra_container.yml.example', 'etc/openstack_deploy/env.d/aodh.yml', 'etc/openstack_deploy/env.d/galera.yml', 'etc/openstack_deploy/env.d/cinder.yml', 'etc/openstack_deploy/env.d/nova.yml', 'playbooks/lxc-containers-create.yml', 'etc/openstack_deploy/env.d/neutron.yml', 'etc/openstack_deploy/env.d/horizon.yml', 'etc/openstack_deploy/env.d/swift-remote.yml', 'etc/openstack_deploy/env.d/ceilometer.yml', 'etc/openstack_deploy/env.d/glance.yml']",14,77cb4fe9fd3064233d0e3ee228aa0f98fd052526,remove_var_lxc_container_release,, container_release: trusty,0,29
openstack%2Fopenstack-manuals~master~Ibe0a5332405dab784d47d8d507b56a481b4b7602,openstack/openstack-manuals,master,Ibe0a5332405dab784d47d8d507b56a481b4b7602,[ha-guide] Changes after ha-guide is merged to manuals,MERGED,2016-05-05 15:44:10.000000000,2016-05-06 04:00:16.000000000,2016-05-06 04:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-05-05 15:44:10.000000000', 'files': ['projects.txt', 'README.rst', 'tools/sync-projects.sh'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eecafd59c176ea9d5c92712f4454633d72dfb675', 'message': '[ha-guide] Changes after ha-guide is merged to manuals\n\nChange-Id: Ibe0a5332405dab784d47d8d507b56a481b4b7602\n'}]",0,313027,eecafd59c176ea9d5c92712f4454633d72dfb675,7,3,1,16237,,,0,"[ha-guide] Changes after ha-guide is merged to manuals

Change-Id: Ibe0a5332405dab784d47d8d507b56a481b4b7602
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/313027/1 && git format-patch -1 --stdout FETCH_HEAD,"['projects.txt', 'README.rst', 'tools/sync-projects.sh']",3,eecafd59c176ea9d5c92712f4454633d72dfb675,newton,, ha-guide) copy_rst doc/common copy_rst_trans doc/common ;;,1,5
openstack%2Fmagnum~stable%2Fmitaka~I41438cbfaefd9d04d7e73a4f46f5ece1494b349c,openstack/magnum,stable/mitaka,I41438cbfaefd9d04d7e73a4f46f5ece1494b349c,Rename tenant to project in functional test,MERGED,2016-04-19 21:05:15.000000000,2016-05-06 03:43:43.000000000,2016-05-06 03:43:42.000000000,"[{'_account_id': 3}, {'_account_id': 9095}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 18386}]","[{'number': 1, 'created': '2016-04-19 21:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0d826b517b59420847e3a2d8537c5ab6ad0bdd58', 'message': 'Fix two issues that broke the gate\n\n* Rename tenant to project in functional test In particular,\n  rename ""admin_tenant_name"" to ""admin_project_name"" and\n  rename ""tenant_name"" to ""project_name"". These configs have been\n  renamed in tempest [1], so Magnum needs to adapt the change.\n* Temporarily remove ""subjectAltName"" from CSR config, because\n  it caused failure of certificate signing, possibly, due to a\n  bug or imcompatible change in pyOpenSSL 16.0.0.\n\n[1] https://review.openstack.org/#/c/301167/\n\nChange-Id: I41438cbfaefd9d04d7e73a4f46f5ece1494b349c\nCloses-Bug: #1568212\nCloses-Bug: #1567691\n(cherry picked from commit b8324f0d72806edfdba289cb74c441169ac68504)\n'}, {'number': 2, 'created': '2016-04-19 21:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/82c3114af3a1afa8dc54ba109af39165706f3b45', 'message': 'Rename tenant to project in functional test\n\nRename ""admin_tenant_name"" to ""admin_project_name"" and\nrename ""tenant_name"" to ""project_name"". These configs have been\nrenamed in tempest [1], so Magnum needs to adapt the change.\n\n[1] https://review.openstack.org/#/c/301167/\n\nChange-Id: I41438cbfaefd9d04d7e73a4f46f5ece1494b349c\nCloses-Bug: #1567691\n(partially pick from commit b8324f0d72806edfdba289cb74c441169ac68504)\n'}, {'number': 3, 'created': '2016-05-05 15:14:48.000000000', 'files': ['magnum/tests/contrib/gate_hook.sh', 'doc/source/dev/functional-test.rst', 'magnum/tests/functional/common/config.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/fff3c0c08c236c48eb077969716d5931ff997b09', 'message': 'Rename tenant to project in functional test\n\nRename ""admin_tenant_name"" to ""admin_project_name"" and\nrename ""tenant_name"" to ""project_name"". These configs have been\nrenamed in tempest [1], so Magnum needs to adapt the change.\n\nIn addition, enable the required devstack plugins in gate hook,\nsince they has been removed from project-config [2].\n\n[1] https://review.openstack.org/#/c/301167/\n[2] https://review.openstack.org/#/c/305475/\n\nChange-Id: I41438cbfaefd9d04d7e73a4f46f5ece1494b349c\nCloses-Bug: #1567691\n(partially pick from commit b8324f0d72806edfdba289cb74c441169ac68504)\n'}]",2,308035,fff3c0c08c236c48eb077969716d5931ff997b09,31,8,3,11536,,,0,"Rename tenant to project in functional test

Rename ""admin_tenant_name"" to ""admin_project_name"" and
rename ""tenant_name"" to ""project_name"". These configs have been
renamed in tempest [1], so Magnum needs to adapt the change.

In addition, enable the required devstack plugins in gate hook,
since they has been removed from project-config [2].

[1] https://review.openstack.org/#/c/301167/
[2] https://review.openstack.org/#/c/305475/

Change-Id: I41438cbfaefd9d04d7e73a4f46f5ece1494b349c
Closes-Bug: #1567691
(partially pick from commit b8324f0d72806edfdba289cb74c441169ac68504)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/35/308035/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/kubernetes/fragments/make-cert.sh', 'doc/source/dev/functional-test.rst', 'magnum/tests/functional/common/config.py', 'magnum/templates/kubernetes/fragments/make-cert-client.sh', 'magnum/templates/swarm/fragments/make-cert.py']",5,0d826b517b59420847e3a2d8537c5ab6ad0bdd58,tmp,# TODO(hongbin): This is a temporary work-around for a gate breakage. # Need to investigate the issue and revert this temporary fix. # Bug #1568212 - '\xac\x18\x05\x07' does not appear to be an IPv4 or IPv6 # address #subjectAltName = %(subject_alt_names)s # TODO(hongbin): This is a temporary work-around for a gate breakage. # Need to investigate the issue and revert this temporary fix. # Bug #1568212 - '\xac\x18\x05\x07' does not appear to be an IPv4 or # IPv6 address # params = { # 'subject_alt_names': _build_subject_alt_names(config) # } # fp.write(CSR_CONFIG_TEMPLATE % params) fp.write(CSR_CONFIG_TEMPLATE),subjectAltName = %(subject_alt_names)s params = { 'subject_alt_names': _build_subject_alt_names(config) } fp.write(CSR_CONFIG_TEMPLATE % params),25,10
openstack%2Fceilometer~master~Ida98861d4b1fe193c269b157f35dd57d0d52e6af,openstack/ceilometer,master,Ida98861d4b1fe193c269b157f35dd57d0d52e6af,event: verify signature before recording events for all dispatchers,MERGED,2016-04-30 12:28:31.000000000,2016-05-06 03:24:12.000000000,2016-05-06 03:24:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 8290}, {'_account_id': 8358}, {'_account_id': 15843}, {'_account_id': 18137}]","[{'number': 1, 'created': '2016-04-30 12:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/88439c0409f2dffb428422d6b811009109d65d16', 'message': 'event: verify signature before recording events for all dispatchers\n\nCurrently only a few dispatchers implement signature verification. This\nmove the signature verification a layer up so all event dispatchers just\nhave to record the event and not verify any signature.\n\nChange-Id: Ida98861d4b1fe193c269b157f35dd57d0d52e6af\n'}, {'number': 2, 'created': '2016-04-30 12:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d6ece9aa76791e6dc5dc8fb680544037ed95677a', 'message': 'event: verify signature before recording events for all dispatchers\n\nCurrently only a few dispatchers implement signature verification. This\nmove the signature verification a layer up so all event dispatchers just\nhave to record the event and not verify any signature.\n\nChange-Id: Ida98861d4b1fe193c269b157f35dd57d0d52e6af\n'}, {'number': 3, 'created': '2016-05-02 13:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d9736c574df0175a87f1ea54eaed085b4e957404', 'message': 'event: verify signature before recording events for all dispatchers\n\nCurrently only a few dispatchers implement signature verification. This\nmove the signature verification a layer up so all event dispatchers just\nhave to record the event and not verify any signature.\n\nChange-Id: Ida98861d4b1fe193c269b157f35dd57d0d52e6af\n'}, {'number': 4, 'created': '2016-05-02 16:14:51.000000000', 'files': ['ceilometer/collector.py', 'ceilometer/tests/functional/test_collector.py', 'ceilometer/tests/unit/dispatcher/test_db.py', 'ceilometer/dispatcher/database.py', 'ceilometer/dispatcher/http.py', 'ceilometer/dispatcher/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/984e2e1bb4ecebe38dda880527f7c24716adae29', 'message': 'event: verify signature before recording events for all dispatchers\n\nCurrently only a few dispatchers implement signature verification. This\nmove the signature verification a layer up so all event dispatchers just\nhave to record the event and not verify any signature.\n\nChange-Id: Ida98861d4b1fe193c269b157f35dd57d0d52e6af\n'}]",4,311518,984e2e1bb4ecebe38dda880527f7c24716adae29,28,9,4,1669,,,0,"event: verify signature before recording events for all dispatchers

Currently only a few dispatchers implement signature verification. This
move the signature verification a layer up so all event dispatchers just
have to record the event and not verify any signature.

Change-Id: Ida98861d4b1fe193c269b157f35dd57d0d52e6af
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/311518/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/unit/dispatcher/test_db.py', 'ceilometer/dispatcher/database.py', 'ceilometer/publisher/direct.py', 'ceilometer/dispatcher/http.py', 'ceilometer/dispatcher/__init__.py']",5,88439c0409f2dffb428422d6b811009109d65d16,jd/verify-sig-event,"from ceilometer.publisher import utils """"""Record events."""""" def verify_and_record_events(self, events): """"""Verify event signature and record them."""""" goods = [] for event in events: if utils.verify_signature( event, self.conf.publisher.telemetry_secret): goods.append(event) else: LOG.warning(_LW( 'event signature invalid, discarding event: %s'), event) return self.record_events(goods)"," """"""Recording events interface.""""""",45,42
openstack%2Fpuppet-tripleo~master~I0598007f90018f80a3266193bb24dbf112de49b7,openstack/puppet-tripleo,master,I0598007f90018f80a3266193bb24dbf112de49b7,Add dport/sport parameter to firewall rule,MERGED,2016-04-20 14:20:01.000000000,2016-05-06 03:10:21.000000000,2016-05-06 03:10:21.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-04-20 14:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5e9086cebb2f754113d17e19f056c7f40b146c00', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 2, 'created': '2016-04-20 21:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/035b8f24b16f3951035dbf2b98fd5b959e8bbdf2', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 3, 'created': '2016-04-20 21:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e27dd33ac8e25e47b1f64ffd9215ad37bbe454f1', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 4, 'created': '2016-04-27 18:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d574f05e8a62853de1be29cc2165095e331d6e1a', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 5, 'created': '2016-04-27 18:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5a921ed09b7635f46ddfd8ef7eb90d6104054e9f', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 6, 'created': '2016-04-28 16:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2faa691dd7a1e5e40fbde7df23b091039fb76086', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 7, 'created': '2016-05-05 13:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/69e0ac603336e9d77ad1b14229e74048e9896846', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nblueprint undercloud-elements\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 8, 'created': '2016-05-05 14:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e2287b3ae6e0dcfd1146e9e6fa2e1e3f257960be', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nblueprint undercloud-elements\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}, {'number': 9, 'created': '2016-05-05 17:17:11.000000000', 'files': ['spec/classes/tripleo_firewall_spec.rb', 'manifests/firewall/rule.pp', 'manifests/firewall/pre.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0bf0f72defc5260346717cf7c9d836342b34ebd6', 'message': 'Add dport/sport parameter to firewall rule\n\nThe port parameter to puppetlabs-firewall is actually deprecated[1].\nThis adds support for using the new parameter names dport and sport. The\nport parameter is still retained in puppet-tripleo for backwards\ncompatibily for anyone using that interface. It is marked deprecated in\nthe documentation, however no deprecation warning is needed because\nthere is already a warning from from puppetlabs-firewall.\n\nblueprint undercloud-elements\nChange-Id: I0598007f90018f80a3266193bb24dbf112de49b7\n'}]",5,308358,0bf0f72defc5260346717cf7c9d836342b34ebd6,32,5,9,7144,,,0,"Add dport/sport parameter to firewall rule

The port parameter to puppetlabs-firewall is actually deprecated[1].
This adds support for using the new parameter names dport and sport. The
port parameter is still retained in puppet-tripleo for backwards
compatibily for anyone using that interface. It is marked deprecated in
the documentation, however no deprecation warning is needed because
there is already a warning from from puppetlabs-firewall.

blueprint undercloud-elements
Change-Id: I0598007f90018f80a3266193bb24dbf112de49b7
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/58/308358/9 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/tripleo_firewall_spec.rb', 'manifests/firewall/rule.pp']",2,5e9086cebb2f754113d17e19f056c7f40b146c00,bp/undercloud-elements,"# [*dport*] # (optional) The destination port associated to the rule. # Defaults to undef # # [*sport*] # (optional) The source port associated to the rule. # Defaults to undef # $dport = undef, $sport = undef, 'dport' => $port, 'sport' => $port,",,23,4
openstack%2Fheat~master~I8f991ef15b3d2bfed0a290d9552c51db45e7e51e,openstack/heat,master,I8f991ef15b3d2bfed0a290d9552c51db45e7e51e,Unit tests: Eliminate deprecated use of ResourceDefinition.Diff,MERGED,2016-04-14 00:03:42.000000000,2016-05-06 03:02:20.000000000,2016-05-06 03:02:20.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-04-14 00:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6fd576c3a9d46560f9c4b837d6b1c5440ecfa943', 'message': ""Unit tests: Eliminate deprecated use of ResourceDefinition.Diff\n\nDon't treat the ResourceDefinition.Diff as a dict containing snippets of a\nCloudFormation template any more. This usage is deprecated.\n\nChange-Id: I8f991ef15b3d2bfed0a290d9552c51db45e7e51e\n""}, {'number': 2, 'created': '2016-05-02 00:42:41.000000000', 'files': ['heat/tests/autoscaling/test_heat_scaling_group.py', 'heat/tests/openstack/heat/test_instance_group.py', 'heat/tests/openstack/heat/test_resource_group.py', 'heat/tests/test_stack_update.py', 'heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/openstack/heat/test_instance_group_update_policy.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0496c3cad6cafbe16330bd038aec24bd2d40eef4', 'message': ""Unit tests: Eliminate deprecated use of ResourceDefinition.Diff\n\nDon't treat the ResourceDefinition.Diff as a dict containing snippets of a\nCloudFormation template any more. This usage is deprecated.\n\nChange-Id: I8f991ef15b3d2bfed0a290d9552c51db45e7e51e\n""}]",0,305534,0496c3cad6cafbe16330bd038aec24bd2d40eef4,9,3,2,4257,,,0,"Unit tests: Eliminate deprecated use of ResourceDefinition.Diff

Don't treat the ResourceDefinition.Diff as a dict containing snippets of a
CloudFormation template any more. This usage is deprecated.

Change-Id: I8f991ef15b3d2bfed0a290d9552c51db45e7e51e
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/305534/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/autoscaling/test_heat_scaling_group.py', 'heat/tests/openstack/heat/test_instance_group.py', 'heat/tests/openstack/heat/test_resource_group.py', 'heat/tests/test_stack_update.py', 'heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/openstack/heat/test_instance_group_update_policy.py', 'heat/tests/test_resource.py']",7,6fd576c3a9d46560f9c4b837d6b1c5440ecfa943,," self.assertFalse(diff.properties_changed()) self.assertTrue(diff.metadata_changed()) self.assertFalse(diff.update_policy_changed()) self.assertFalse(diff.properties_changed()) self.assertTrue(diff.metadata_changed()) self.assertFalse(diff.update_policy_changed()) self.assertFalse(diff.properties_changed()) self.assertTrue(diff.metadata_changed()) self.assertFalse(diff.update_policy_changed()) utmpl, mock.ANY, prop_diff).AndReturn(None) utmpl, mock.ANY, prop_diff).AndRaise(exception.UpdateReplace( utmpl, mock.ANY, prop_diff).AndRaise(exception.UpdateReplace())"," self.assertEqual({'Metadata': {'foo': 456}}, diff) self.assertEqual({'Metadata': {'foo': 123}}, diff) self.assertEqual({'Metadata': None}, diff) tmpl_diff = {'Properties': {'Foo': 'xyz'}} utmpl, tmpl_diff, prop_diff).AndReturn(None) tmpl_diff = {'Properties': {'Foo': 'xyz'}} utmpl, tmpl_diff, prop_diff).AndRaise(exception.UpdateReplace( tmpl_diff = {'Properties': {'Foo': 'xyz'}} utmpl, tmpl_diff, prop_diff).AndRaise(exception.UpdateReplace())",18,27
openstack%2Fneutron-dynamic-routing~master~I003e90754aae60461fe8c986fc288c93765d3029,openstack/neutron-dynamic-routing,master,I003e90754aae60461fe8c986fc288c93765d3029,Add BGP agent,ABANDONED,2016-04-29 07:35:19.000000000,2016-05-06 02:53:45.000000000,,"[{'_account_id': 3}, {'_account_id': 4187}, {'_account_id': 14605}, {'_account_id': 17455}, {'_account_id': 17609}]","[{'number': 1, 'created': '2016-04-29 07:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/25b36aa58f01a76c7a4c8e36519d97de66ed902b', 'message': 'Add BGP agent\n\nThis patch moves BGP agent codes from neutron repo to\nneutron-dynamic-routing repo\n\nChange-Id: I003e90754aae60461fe8c986fc288c93765d3029\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 2, 'created': '2016-04-30 05:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/18b87ad0e98f79494db9959545991aae24a078e3', 'message': 'Add BGP agent\n\nThis patch moves BGP agent codes from neutron repo to\nneutron-dynamic-routing repo. It includes some codes\nabout BGP server and BGP driver, because these codes\nare imported by BGP agent or in the same file with\nBGP agent, to make the moving work easier, I include\nthem in this patch.\n\nChange-Id: I003e90754aae60461fe8c986fc288c93765d3029\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 3, 'created': '2016-04-30 08:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/b1fb85c00d89c6a733d10a155375fb486be5d992', 'message': 'Add BGP agent\n\nThis patch moves BGP agent codes from neutron repo to\nneutron-dynamic-routing repo. It includes some codes\nabout BGP server and BGP driver, because these codes\nare imported by BGP agent or in the same file with\nBGP agent, to make the moving work easier, I include\nthem in this patch.\n\nChange-Id: I003e90754aae60461fe8c986fc288c93765d3029\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 4, 'created': '2016-05-03 06:26:27.000000000', 'files': ['neutron_dynamic_routing/services/bgp/agent/entry.py', 'neutron_dynamic_routing/cmd/eventlet/__init__.py', 'neutron_dynamic_routing/cmd/__init__.py', 'neutron_dynamic_routing/tests/unit/api/__init__.py', 'neutron_dynamic_routing/tests/unit/services/bgp/agent/__init__.py', 'neutron_dynamic_routing/services/bgp/agent/__init__.py', 'neutron_dynamic_routing/api/rpc/__init__.py', 'neutron_dynamic_routing/services/bgp/common/opts.py', 'neutron_dynamic_routing/api/rpc/agentnotifiers/bgp_dr_rpc_agent_api.py', 'neutron_dynamic_routing/tests/unit/api/rpc/__init__.py', 'neutron_dynamic_routing/extensions/__init__.py', 'neutron_dynamic_routing/services/bgp/driver/__init__.py', 'neutron_dynamic_routing/api/__init__.py', 'neutron_dynamic_routing/services/bgp/__init__.py', 'neutron_dynamic_routing/tests/unit/api/rpc/agentnotifiers/test_bgp_dr_rpc_agent_api.py', 'neutron_dynamic_routing/services/bgp/agent/config.py', 'neutron_dynamic_routing/services/bgp/common/constants.py', 'neutron_dynamic_routing/api/rpc/handlers/__init__.py', 'neutron_dynamic_routing/tests/unit/services/bgp/__init__.py', 'neutron_dynamic_routing/services/bgp/driver/exceptions.py', 'neutron_dynamic_routing/tests/unit/api/rpc/handlers/__init__.py', 'neutron_dynamic_routing/cmd/eventlet/agents/__init__.py', 'neutron_dynamic_routing/services/bgp/agent/bgp_dragent.py', 'neutron_dynamic_routing/extensions/bgp.py', 'neutron_dynamic_routing/tests/unit/api/rpc/handlers/test_bgp_speaker_rpc.py', 'neutron_dynamic_routing/tests/unit/services/bgp/agent/test_bgp_dragent.py', 'neutron_dynamic_routing/services/bgp/common/__init__.py', 'neutron_dynamic_routing/services/__init__.py', 'neutron_dynamic_routing/cmd/eventlet/agents/bgp_dragent.py', 'neutron_dynamic_routing/api/rpc/agentnotifiers/__init__.py', 'neutron_dynamic_routing/tests/unit/api/rpc/agentnotifiers/__init__.py', 'neutron_dynamic_routing/tests/unit/services/__init__.py', 'neutron_dynamic_routing/api/rpc/handlers/bgp_speaker_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/d659a4adafdb1168663fc7ee2ea065ef14515bc5', 'message': 'Add BGP agent\n\nThis patch moves BGP agent codes from neutron repo to\nneutron-dynamic-routing repo. It includes some codes\nabout BGP server and BGP driver, because these codes\nare imported by BGP agent or in the same file with\nBGP agent, to make the moving work easier, I include\nthem in this patch.\n\nChange-Id: I003e90754aae60461fe8c986fc288c93765d3029\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}]",23,311047,d659a4adafdb1168663fc7ee2ea065ef14515bc5,27,5,4,17455,,,0,"Add BGP agent

This patch moves BGP agent codes from neutron repo to
neutron-dynamic-routing repo. It includes some codes
about BGP server and BGP driver, because these codes
are imported by BGP agent or in the same file with
BGP agent, to make the moving work easier, I include
them in this patch.

Change-Id: I003e90754aae60461fe8c986fc288c93765d3029
Implements: blueprint bgp-spinout
Partial-Bug: #1560003
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/47/311047/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_dynamic_routing/services/bgp/agent/entry.py', 'neutron_dynamic_routing/cmd/eventlet/__init__.py', 'neutron_dynamic_routing/services/bgp/agent/config.py', 'neutron_dynamic_routing/services/bgp/common/constants.py', 'neutron_dynamic_routing/cmd/__init__.py', 'neutron_dynamic_routing/tests/unit/services/bgp/__init__.py', 'neutron_dynamic_routing/services/bgp/driver/exceptions.py', 'neutron_dynamic_routing/tests/unit/services/bgp/agent/__init__.py', 'neutron_dynamic_routing/cmd/eventlet/agents/__init__.py', 'neutron_dynamic_routing/services/bgp/agent/bgp_dragent.py', 'neutron_dynamic_routing/services/bgp/agent/__init__.py', 'neutron_dynamic_routing/extensions/bgp.py', 'neutron_dynamic_routing/tests/unit/services/bgp/agent/test_bgp_dragent.py', 'neutron_dynamic_routing/extensions/__init__.py', 'neutron_dynamic_routing/services/bgp/common/__init__.py', 'neutron_dynamic_routing/services/bgp/driver/__init__.py', 'neutron_dynamic_routing/services/__init__.py', 'neutron_dynamic_routing/cmd/eventlet/agents/bgp_dragent.py', 'neutron_dynamic_routing/services/bgp/__init__.py', 'neutron_dynamic_routing/tests/unit/services/__init__.py']",20,25b36aa58f01a76c7a4c8e36519d97de66ed902b,bp/bgp-spinout,,,1842,0
openstack%2Fneutron~master~I9ec137ef8c688b678a0c61f07e9a01382acbeb13,openstack/neutron,master,I9ec137ef8c688b678a0c61f07e9a01382acbeb13,OVS: Add support for IPv6 addresses as tunnel endpoints,MERGED,2015-12-14 12:55:54.000000000,2016-05-06 02:47:45.000000000,2016-05-06 02:47:45.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 8788}, {'_account_id': 9200}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11159}, {'_account_id': 11255}, {'_account_id': 11682}, {'_account_id': 11975}, {'_account_id': 13686}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14215}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 16800}, {'_account_id': 18369}]","[{'number': 1, 'created': '2015-12-14 12:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db46b1c8992cb5bb07c9c43df64137b3fdd9eea4', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nWork in progress, see bug/review comments for discussion\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 2, 'created': '2015-12-23 09:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b10333dcaad14d3074b4ae9bd2cb8a71f5cff84a', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating tunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 3, 'created': '2015-12-23 11:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd93945a90de18c7c3c4a66a4f07ca5c80cecdd8', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix two existing tests that fail because of the added check for\nIP version and subsequently valid IP addresses.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 4, 'created': '2015-12-23 11:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66432d9a45e6df79d61a7f6eb508e440070bcd53', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix two existing tests that fail because of the added check for\nIP version and subsequently valid IP addresses.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 5, 'created': '2016-01-02 13:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb57a7eadd9c3f4a582cfcb8822f66ae9a4fb1e3', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 6, 'created': '2016-01-29 08:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cb5af85f7c985768fca79cbc043218a9bc99e94', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 7, 'created': '2016-02-24 20:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d50c1df7159314db79e0f72783759e54ea413bd2', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 8, 'created': '2016-03-01 02:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88dc3da6b5f37c49f6086cbac6a52f09673421e7', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 9, 'created': '2016-03-03 22:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7049b5552fa6065e771fe1d448179c189963005', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 10, 'created': '2016-03-22 01:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5bf8f67f8d0fb0b576a23f875761772b59da8bbd', 'message': '[WIP] ovs: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 11, 'created': '2016-04-08 21:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e3bfff6f111ac66556510365cdfe296b6568ea8', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 12, 'created': '2016-04-11 14:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/201e1bbaea7c04ffb1cdc17dd86c59e629e4b2fb', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 13, 'created': '2016-04-14 15:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2392b8cfbcadbf6ed1768adfa68f1f18b8237301', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 14, 'created': '2016-04-25 22:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1cac654e348877a788ec6d30d1b02bd895c9c49', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 15, 'created': '2016-04-27 20:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/faa81068fd598bea759ca0aa957d4abf8d4a95d4', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 16, 'created': '2016-05-03 02:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb074a3e209ff88d3af124bcd7a563047fcb4ab8', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nDocImpact\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 17, 'created': '2016-05-03 14:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a4a7e95d0d712ffcef3830aafabb2b5b5479607', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 18, 'created': '2016-05-03 17:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3af621ae3995f08ae0683cd2627ae5317418fccd', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}, {'number': 19, 'created': '2016-05-04 01:08:37.000000000', 'files': ['neutron/tests/common/agents/ovs_agent.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'releasenotes/notes/ovs-ipv6-tunnel-endpoints-f41b4954a04c43f6.yaml', 'neutron/plugins/ml2/drivers/openvswitch/agent/common/config.py', 'neutron/tests/functional/agent/l2/base.py', 'neutron/tests/functional/agent/test_l2_ovs_agent.py', 'neutron/tests/functional/agent/test_ovs_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/773394a1887bec6ab4c2ff0308f0e830e9a9089f', 'message': 'OVS: Add support for IPv6 addresses as tunnel endpoints\n\nRemove IPv4 restriction for local_ip configuration statement.\n\nCheck for IP version mismatch of local_ip and remote_ip before creating\ntunnel.\n\nCreate hash of remote IPv6 address for OVS interface/port name with least\nposibility for collissions.\n\nFix existing tests that fail because of the added check for IP version\nand subsequently valid IP addresses in _setup_tunnel_port.\n\nDocImpact\n\nChange-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13\nCloses-Bug: #1525895\n'}]",61,257335,773394a1887bec6ab4c2ff0308f0e830e9a9089f,311,33,19,13686,,,0,"OVS: Add support for IPv6 addresses as tunnel endpoints

Remove IPv4 restriction for local_ip configuration statement.

Check for IP version mismatch of local_ip and remote_ip before creating
tunnel.

Create hash of remote IPv6 address for OVS interface/port name with least
posibility for collissions.

Fix existing tests that fail because of the added check for IP version
and subsequently valid IP addresses in _setup_tunnel_port.

DocImpact

Change-Id: I9ec137ef8c688b678a0c61f07e9a01382acbeb13
Closes-Bug: #1525895
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/257335/13 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/common/config.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",3,db46b1c8992cb5bb07c9c43df64137b3fdd9eea4,bug/1525895,"FAKE_IP6 = '2001:db8:42:42::10' def test_validate_local_ip_with_valid_ipv6(self): mock_get_device_by_ip = mock.patch.object( ip_lib.IPWrapper, 'get_device_by_ip').start() ovs_agent.validate_local_ip(FAKE_IP6) mock_get_device_by_ip.assert_called_once_with(FAKE_IP6) def test_validate_local_ip_with_invalid_ipv6(self): mock_get_device_by_ip = mock.patch.object( ip_lib.IPWrapper, 'get_device_by_ip').start() mock_get_device_by_ip.return_value = None with testtools.ExpectedException(SystemExit): ovs_agent.validate_local_ip(FAKE_IP6) mock_get_device_by_ip.assert_called_once_with(FAKE_IP6)",,28,2
openstack%2Fglance~stable%2Fmitaka~Iaa3cb727a9dc7099b768a87d90204f8f1e72406a,openstack/glance,stable/mitaka,Iaa3cb727a9dc7099b768a87d90204f8f1e72406a,use stable/mitaka upper-constraints,MERGED,2016-05-04 15:37:06.000000000,2016-05-06 02:47:16.000000000,2016-05-06 02:47:16.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 12000}]","[{'number': 1, 'created': '2016-05-04 15:37:06.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/b3d76750a5c835d5e7db6714009806d736c6706d', 'message': 'use stable/mitaka upper-constraints\n\nMove from master upper-constraints to stable/mitaka upper-constraints\n\nChange-Id: Iaa3cb727a9dc7099b768a87d90204f8f1e72406a\n'}]",0,312601,b3d76750a5c835d5e7db6714009806d736c6706d,8,4,1,10371,,,0,"use stable/mitaka upper-constraints

Move from master upper-constraints to stable/mitaka upper-constraints

Change-Id: Iaa3cb727a9dc7099b768a87d90204f8f1e72406a
",git fetch https://review.opendev.org/openstack/glance refs/changes/01/312601/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b3d76750a5c835d5e7db6714009806d736c6706d,,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/mitaka} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Ftacker~master~I148a125b5fde9c4db20a001d1c7846c56b97adf9,openstack/tacker,master,I148a125b5fde9c4db20a001d1c7846c56b97adf9,Fix the hacking rules,ABANDONED,2016-04-18 02:42:53.000000000,2016-05-06 02:33:12.000000000,,"[{'_account_id': 3}, {'_account_id': 13485}, {'_account_id': 19726}, {'_account_id': 19950}]","[{'number': 1, 'created': '2016-04-18 02:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/749e26b5842110f04a3317ab23fb3fd8ecedc95c', 'message': 'Fix the hacking rules\n\nbecause the Tacker project was referred from Neutron,but the\nhacking rules should be named corrected.\n\nChange-Id: I148a125b5fde9c4db20a001d1c7846c56b97adf9\n'}, {'number': 2, 'created': '2016-04-27 03:06:45.000000000', 'files': ['tacker/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/ea240fe880ecd48786e7f39107ed8a30b2dbdb92', 'message': 'Fix the hacking rules\n\nbecause the Tacker project was referred from Neutron,but the\nhacking rules should be named corrected.\n\nChange-Id: I148a125b5fde9c4db20a001d1c7846c56b97adf9\n'}]",0,306890,ea240fe880ecd48786e7f39107ed8a30b2dbdb92,9,4,2,19950,,,0,"Fix the hacking rules

because the Tacker project was referred from Neutron,but the
hacking rules should be named corrected.

Change-Id: I148a125b5fde9c4db20a001d1c7846c56b97adf9
",git fetch https://review.opendev.org/openstack/tacker refs/changes/90/306890/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/hacking/checks.py', 'HACKING.rst']",2,749e26b5842110f04a3317ab23fb3fd8ecedc95c,bug_fix,"- [T320] Validate that LOG messages, except debug ones, have translations","- [N320] Validate that LOG messages, except debug ones, have translations",2,2
openstack%2Fironic~master~Ib54741c8564e18f23c4f50bed190dfc66db7ba76,openstack/ironic,master,Ib54741c8564e18f23c4f50bed190dfc66db7ba76,Update resources only for specific node during deletion.,MERGED,2016-03-02 23:10:55.000000000,2016-05-06 02:15:33.000000000,2016-05-06 02:15:32.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7933}, {'_account_id': 10118}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 13636}, {'_account_id': 14525}, {'_account_id': 17998}, {'_account_id': 19686}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-02 23:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9fd6ff6429f640c53814fafe0004819c90065396', 'message': 'WIP Update resources only for specific instance.\n\nWhen terminating update resources for specific instance only.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 2, 'created': '2016-03-02 23:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/26b1cf373d84f467a13ee0d96ce3b5398b1d26cf', 'message': 'WIP Update resources only for specific instance.\n\nWhen terminating update resources for specific instance only.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 3, 'created': '2016-03-02 23:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f209847ae3c7b62f251bf3f291f8f69e1e043286', 'message': 'WIP Update resources only for specific instance.\n\nWhen terminating update resources for specific instance only.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 4, 'created': '2016-03-03 18:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9fbcc6b3085437f7ea0b151e930f40d613fa2a5b', 'message': 'Update resources only for specific instance.\n\nAt the moment during Ironic instance termination resources are\nupdated for all nodes. As result with high numner of nodes, removing N\ninstances initiates N x M requests, where M is the total number of nodes.\nThis commit allows to update resources per specific node on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 5, 'created': '2016-03-03 18:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/da2e93e7ca9a38e4774cd0dae5318e6e0bed4331', 'message': 'Update resources only for specific instance.\n\nAt the moment during Ironic instance termination resources are\nupdated for all nodes. As result with high numner of nodes, removing N\ninstances initiates N x M requests, where M is the total number of nodes.\nThis commit allows to update resources per specific node on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 6, 'created': '2016-03-04 11:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0535497b4b2e8c83b4f6857828a2b234e2ab2bf7', 'message': 'Update resources only for specific instance.\n\nAt the moment during Ironic instance termination resources are\nupdated for all nodes. As result with high numner of nodes, removing N\ninstances initiates N x M requests, where M is the total number of nodes.\nThis commit allows to update resources per specific node on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 7, 'created': '2016-03-22 16:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6b34430267e0298f52944507e61e726e180c538', 'message': 'Update resources only for specific instance.\n\nAt the moment during Ironic instance termination resources are\nupdated for all nodes. As result with high numner of nodes, removing N\ninstances initiates N x M requests, where M is the total number of nodes.\nThis commit allows to update resources per specific node on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 8, 'created': '2016-03-23 07:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4e93c8d5dfde701cebee430b1d1ad398acfae4f6', 'message': 'Update resources only for specific node during deletion.\n\nAt the moment during Nova instance termination resources are\nupdated for all Ironic nodes. As result with high number of nodes,\nremoving N instances initiates N x M requests, where M is the total\nnumber of nodes. This commit allows to update resources per specific\nnode on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 9, 'created': '2016-04-05 14:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bed0ebcf7c958f9d9b2d96d22831adaf942cd047', 'message': 'Update resources only for specific node during deletion.\n\nAt the moment during Nova instance termination resources are\nupdated for all Ironic nodes. As result with high number of nodes,\nremoving N instances initiates N x M requests, where M is the total\nnumber of nodes. This commit allows to update resources per specific\nnode on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 10, 'created': '2016-04-07 09:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3604da05bbb982c4109dd470887b91f2d3a97498', 'message': 'Update resources only for specific node during deletion.\n\nAt the moment during Nova instance termination resources are\nupdated for all Ironic nodes. As result with high number of nodes,\nremoving N instances initiates N x M requests, where M is the total\nnumber of nodes. This commit allows to update resources per specific\nnode on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 11, 'created': '2016-04-26 08:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8b513db0c0f006a3f0fa17329f31862171866481', 'message': 'Update resources only for specific node during deletion.\n\nAt the moment during Nova instance termination resources are\nupdated for all Ironic nodes. As result with high number of nodes,\nremoving N instances initiates N x M requests, where M is the total\nnumber of nodes. This commit allows to update resources per specific\nnode on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}, {'number': 12, 'created': '2016-04-29 19:16:12.000000000', 'files': ['ironic/nova/compute/manager.py', 'releasenotes/notes/node-deletion-update-resources-53862e48ab658f77.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/16d8819891c4bef58760c62c30aa2b68868087b9', 'message': 'Update resources only for specific node during deletion.\n\nAt the moment during Nova instance termination resources are\nupdated for all Ironic nodes. As result with high number of nodes,\nremoving N instances initiates N x M requests, where M is the total\nnumber of nodes. This commit allows to update resources per specific\nnode on termination.\n\nDepends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d\n\nChange-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76\nCloses-Bug: #1552446\n'}]",9,287498,16d8819891c4bef58760c62c30aa2b68868087b9,81,19,12,14525,,,0,"Update resources only for specific node during deletion.

At the moment during Nova instance termination resources are
updated for all Ironic nodes. As result with high number of nodes,
removing N instances initiates N x M requests, where M is the total
number of nodes. This commit allows to update resources per specific
node on termination.

Depends-On: Iffad4a6ab1aaa5fea591c19f6d330dc861c5675d

Change-Id: Ib54741c8564e18f23c4f50bed190dfc66db7ba76
Closes-Bug: #1552446
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/287498/10 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/compute/manager.py'],1,9fd6ff6429f640c53814fafe0004819c90065396,bug/1552446," def _update_resources(self, instance): """"""Update our resources for instance Updates the resources for instance while protecting against a race on :param instance: UUID of Nova instance to update_resources for. self._update_resources(instance)"," def _update_resources(self): """"""Update our resources Updates the resources while protecting against a race on self._update_resources()",5,4
openstack%2Fironic~master~Id8c64c9e060af36243ddd48700170cd71b357bdb,openstack/ironic,master,Id8c64c9e060af36243ddd48700170cd71b357bdb,Pass environment through to create-node.sh,MERGED,2016-05-05 18:34:36.000000000,2016-05-06 02:14:08.000000000,2016-05-06 02:14:08.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2016-05-05 18:34:36.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/57a0c291a9dc8e42be47b19696c836e3fd0a8eba', 'message': 'Pass environment through to create-node.sh\n\nThis patch passed the environment through to create-node.sh so that it\ncan be customised by changes in the local.conf such as:\n\nLIBVIRT_NIC_DRIVER=rtl8139\n\nChange-Id: Id8c64c9e060af36243ddd48700170cd71b357bdb\n'}]",0,313106,57a0c291a9dc8e42be47b19696c836e3fd0a8eba,9,4,1,6637,,,0,"Pass environment through to create-node.sh

This patch passed the environment through to create-node.sh so that it
can be customised by changes in the local.conf such as:

LIBVIRT_NIC_DRIVER=rtl8139

Change-Id: Id8c64c9e060af36243ddd48700170cd71b357bdb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/06/313106/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,57a0c291a9dc8e42be47b19696c836e3fd0a8eba,," sudo -E su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/create-node.sh $vm_name \"," sudo su $STACK_USER -c ""$IRONIC_SCRIPTS_DIR/create-node.sh $vm_name \",1,1
openstack%2Fopenstack-manuals~master~I160b804fca87525c0639ba4179cf56c9c9eaa9ec,openstack/openstack-manuals,master,I160b804fca87525c0639ba4179cf56c9c9eaa9ec,[network] Fixed non-existent filter PCIDeviceScheduler,MERGED,2016-05-03 20:51:56.000000000,2016-05-06 02:13:45.000000000,2016-05-06 02:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12171}, {'_account_id': 15334}]","[{'number': 1, 'created': '2016-05-03 20:51:56.000000000', 'files': ['doc/networking-guide/source/adv-config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d9a4b6ce506af0b92d4045cf03363be08a03b04e', 'message': '[network] Fixed non-existent filter PCIDeviceScheduler\n\nChanged to PciPassthroughFilter.\n\nChange-Id: I160b804fca87525c0639ba4179cf56c9c9eaa9ec\nCloses-Bug: 1577934\n'}]",0,312247,d9a4b6ce506af0b92d4045cf03363be08a03b04e,9,5,1,17973,,,0,"[network] Fixed non-existent filter PCIDeviceScheduler

Changed to PciPassthroughFilter.

Change-Id: I160b804fca87525c0639ba4179cf56c9c9eaa9ec
Closes-Bug: 1577934
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/312247/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/adv-config-sriov.rst'],1,d9a4b6ce506af0b92d4045cf03363be08a03b04e,bug/1577934, PciPassthroughFilter to the scheduler_default_filters parameter, PCIDeviceScheduler to the scheduler_default_filters parameter,1,1
openstack%2Fmagnum~master~Iac76aa8e075a2ab07e84d21d892542b5dca99bad,openstack/magnum,master,Iac76aa8e075a2ab07e84d21d892542b5dca99bad,Add the image create help to the function test,ABANDONED,2016-05-05 06:34:08.000000000,2016-05-06 01:51:16.000000000,,"[{'_account_id': 3}, {'_account_id': 10206}]","[{'number': 1, 'created': '2016-05-05 06:34:08.000000000', 'files': ['doc/source/dev/functional-test.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7a0f6c8c795a90637fc48d867d17bdb06b8e6934', 'message': 'Add the image create help to the function test\n\nNow the image is the newest image and the image often be update.\nAnd this will make the image in glance name is different everytime.\nIt will lead to the fail because the image fedora-atomic could not\nbe found when we do the fuction test. So we had better to add the\nhelp image to create the right image name.\n\nChange-Id: Iac76aa8e075a2ab07e84d21d892542b5dca99bad\nCloses-Bug: #1578511\n'}]",0,312836,7a0f6c8c795a90637fc48d867d17bdb06b8e6934,5,2,1,18386,,,0,"Add the image create help to the function test

Now the image is the newest image and the image often be update.
And this will make the image in glance name is different everytime.
It will lead to the fail because the image fedora-atomic could not
be found when we do the fuction test. So we had better to add the
help image to create the right image name.

Change-Id: Iac76aa8e075a2ab07e84d21d892542b5dca99bad
Closes-Bug: #1578511
",git fetch https://review.opendev.org/openstack/magnum refs/changes/36/312836/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/functional-test.rst'],1,7a0f6c8c795a90637fc48d867d17bdb06b8e6934,bug/1578511,"Create the necessary keypair, flavor and image:: cd ~ wget https://fedorapeople.org/groups/magnum/fedora-atomic-latest.qcow2 glance image-create --name fedora-atomic \ --visibility public \ --disk-format qcow2 \ --os-distro fedora-atomic \ --container-format bare < fedora-atomic-latest.qcow2",Create the necessary keypair and flavor::,8,1
openstack%2Fsenlin-dashboard~master~I217c1cf4c42f1551912a807c9b22408fef4c35b6,openstack/senlin-dashboard,master,I217c1cf4c42f1551912a807c9b22408fef4c35b6,Add node update action,MERGED,2016-04-06 14:56:26.000000000,2016-05-06 01:49:35.000000000,2016-05-06 01:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-04-06 14:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/9cede1a1105bb6ac238937f215c20a70bac2700c', 'message': 'Add node update action\n\nPartially implements blueprint add-node-panel\n\nChange-Id: I217c1cf4c42f1551912a807c9b22408fef4c35b6\n'}, {'number': 2, 'created': '2016-05-04 13:38:32.000000000', 'files': ['senlin_dashboard/cluster/nodes/templates/nodes/_update.html', 'senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/cluster/nodes/templates/nodes/update.html', 'senlin_dashboard/cluster/nodes/urls.py', 'senlin_dashboard/cluster/nodes/tables.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/f6df4b995644cda4445a79ce93350402a5f5c46c', 'message': 'Add node update action\n\nPartially implements blueprint add-node-panel\n\nChange-Id: I217c1cf4c42f1551912a807c9b22408fef4c35b6\n'}]",4,302300,f6df4b995644cda4445a79ce93350402a5f5c46c,11,4,2,6763,,,0,"Add node update action

Partially implements blueprint add-node-panel

Change-Id: I217c1cf4c42f1551912a807c9b22408fef4c35b6
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/00/302300/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/nodes/templates/nodes/_update.html', 'senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/nodes/forms.py', 'senlin_dashboard/cluster/nodes/templates/nodes/update.html', 'senlin_dashboard/cluster/nodes/urls.py', 'senlin_dashboard/cluster/nodes/tables.py']",7,9cede1a1105bb6ac238937f215c20a70bac2700c,bp/add-node-panel,"class UpdateNode(tables.LinkAction): name = ""update"" verbose_name = _(""Update Node"") url = ""horizon:cluster:nodes:update"" classes = (""ajax-modal"",) icon = ""pencil"" row_actions = (UpdateNode, DeleteNode,)"," row_actions = (DeleteNode,)",137,2
openstack%2Fnetworking-midonet~master~I62c20c37a25c7532e95943dd08186fd085e84f61,openstack/networking-midonet,master,I62c20c37a25c7532e95943dd08186fd085e84f61,devstack: Add a knob to configure NAT for public connectivity,MERGED,2016-03-29 17:22:17.000000000,2016-05-06 01:49:23.000000000,2016-05-06 01:49:23.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 8837}, {'_account_id': 19307}]","[{'number': 1, 'created': '2016-03-29 17:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/57d1dd8b9269be2aa0d69bd210b254c84617dec3', 'message': 'devstack: Add a knob to configure NAT for public connectivity\n\nChange-Id: I62c20c37a25c7532e95943dd08186fd085e84f61\n'}, {'number': 2, 'created': '2016-03-31 17:43:58.000000000', 'files': ['devstack/uplink/create_nat.sh', 'devstack/plugin.sh', 'devstack/uplink/delete_nat.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/98df68b8491ba2c179f28c8690a52acc923b257b', 'message': 'devstack: Add a knob to configure NAT for public connectivity\n\nChange-Id: I62c20c37a25c7532e95943dd08186fd085e84f61\n'}]",3,298883,98df68b8491ba2c179f28c8690a52acc923b257b,25,5,2,6854,,,0,"devstack: Add a knob to configure NAT for public connectivity

Change-Id: I62c20c37a25c7532e95943dd08186fd085e84f61
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/83/298883/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/uplink/create_nat.sh', 'devstack/plugin.sh', 'devstack/uplink/delete_nat.sh', 'devstack/settings']",4,57d1dd8b9269be2aa0d69bd210b254c84617dec3,bug/1564283,# Configure NAT for public network. # You need to configure PUBLIC_INTERFACE properly. MIDONET_USE_UPLINK_NAT=${MIDONET_USE_UPLINK_NAT:-False},,62,0
openstack%2Fopenstack-ansible~stable%2Fmitaka~I4abe7a699cff82fb22a1562d9bd9c6e479778e26,openstack/openstack-ansible,stable/mitaka,I4abe7a699cff82fb22a1562d9bd9c6e479778e26,Ensure that the sources-branch-updater updates the Ironic role,MERGED,2016-05-05 23:31:11.000000000,2016-05-06 01:35:50.000000000,2016-05-06 01:35:50.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 23:31:11.000000000', 'files': ['scripts/sources-branch-updater.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6c889f02633a1145f1a5fc1085042d32de383ab8', 'message': 'Ensure that the sources-branch-updater updates the Ironic role\n\nThis includes the ironic service in the list of services to check for\nupdates for the rootwrap filters and other carried files.\n\nChange-Id: I4abe7a699cff82fb22a1562d9bd9c6e479778e26\n(cherry picked from commit c4418499a24b78dc423fc065e6784fdb919da173)\n'}]",0,313188,6c889f02633a1145f1a5fc1085042d32de383ab8,6,2,1,6816,,,0,"Ensure that the sources-branch-updater updates the Ironic role

This includes the ironic service in the list of services to check for
updates for the rootwrap filters and other carried files.

Change-Id: I4abe7a699cff82fb22a1562d9bd9c6e479778e26
(cherry picked from commit c4418499a24b78dc423fc065e6784fdb919da173)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/88/313188/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/sources-branch-updater.sh'],1,6c889f02633a1145f1a5fc1085042d32de383ab8,,"OPENSTACK_SERVICE_LIST=${OPENSTACK_SERVICE_LIST:-""aodh ceilometer cinder glance heat ironic keystone neutron nova""}","OPENSTACK_SERVICE_LIST=${OPENSTACK_SERVICE_LIST:-""aodh ceilometer cinder glance heat keystone neutron nova""}",1,1
openstack%2Fhorizon~master~Idab7536e046ec4b49a70c9ae96f45a3f4c36b029,openstack/horizon,master,Idab7536e046ec4b49a70c9ae96f45a3f4c36b029,"Adjust width so as not to be hidden by ""help element",MERGED,2016-03-27 11:59:20.000000000,2016-05-06 01:26:51.000000000,2016-05-06 01:26:50.000000000,"[{'_account_id': 3}, {'_account_id': 11778}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-03-27 11:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f417d4d4279910fda9d3f7448cf68b10622c0bed', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\n'}, {'number': 2, 'created': '2016-03-29 23:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/17d852b66189c8ed544b71071480181baa597acc', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\nCloses-bug: #1557817\n'}, {'number': 3, 'created': '2016-04-11 05:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c3536db59021af897e17234e7812cf134b7cfcf2', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\nCloses-bug: #1557817\n'}, {'number': 4, 'created': '2016-04-18 06:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/46ef7197e3bd989ad2e59ba6404c029e8989d6ac', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\nCloses-bug: #1557817\n'}, {'number': 5, 'created': '2016-04-26 22:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/784caf2fe9e5c667157f70fe93f3e028a703050c', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\nCloses-bug: #1557817\n'}, {'number': 6, 'created': '2016-05-05 21:01:00.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-groups.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/configuration/configuration.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/details/details.html', 'openstack_dashboard/static/dashboard/scss/components/_modals.scss', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/networkports/ports.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/flavor/flavor.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/metadata/metadata.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/df1cbabfd114e05317d612d5e0b03d414db0dd49', 'message': 'Adjust width so as not to be hidden by ""help element\n\nAt the moment, a part of description written on the top of each step\nin ng-launch instance modal is hidden by help-element.\nThis patch will fix it by adjusting a description width.\n\nChange-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029\nCloses-bug: #1562495\nCloses-bug: #1557817\n'}]",1,298034,df1cbabfd114e05317d612d5e0b03d414db0dd49,29,5,6,17172,,,0,"Adjust width so as not to be hidden by ""help element

At the moment, a part of description written on the top of each step
in ng-launch instance modal is hidden by help-element.
This patch will fix it by adjusting a description width.

Change-Id: Idab7536e046ec4b49a70c9ae96f45a3f4c36b029
Closes-bug: #1562495
Closes-bug: #1557817
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/298034/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/security-groups/security-groups.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/configuration/configuration.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/details/details.html', 'openstack_dashboard/static/dashboard/scss/components/_modals.scss', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/networkports/ports.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/flavor/flavor.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/metadata/metadata.html']",10,f417d4d4279910fda9d3f7448cf68b10622c0bed,bug/1562495,"<p class=""step-description"" translate>",<p translate>,13,9
openstack%2Fneutron~stable%2Fmitaka~Id2b0463f49df52744e5bc3979a4cfd0ff06f9248,openstack/neutron,stable/mitaka,Id2b0463f49df52744e5bc3979a4cfd0ff06f9248,LinuxBridge agent's QoS driver bw limit for egress traffic,MERGED,2016-04-19 11:53:50.000000000,2016-05-06 01:26:38.000000000,2016-05-06 01:26:37.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 13995}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-04-19 11:53:50.000000000', 'files': ['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/agent/linux/test_tc_lib.py', 'neutron/tests/fullstack/test_qos.py', 'neutron/tests/functional/agent/linux/test_tc_lib.py', 'etc/neutron/rootwrap.d/linuxbridge-plugin.filters', 'neutron/agent/linux/tc_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/test_qos_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd77e8b837556c96cb0a3ad7480d6dc85df3834e', 'message': ""LinuxBridge agent's QoS driver bw limit for egress traffic\n\nQoS service plugin provides for now bandwidth limit rules for egress traffic\nonly (from VM point of view). QoS extension driver for Linuxbridge agent now\nconfigures limits in proper way on tap interface so limited is traffic which is\noutgoing from VM.\nLinuxbridge agent's QoS extension configures egress bandwidth limit and burst\nvalue in exactly same way how openvswitch is doing it with tc.\nOld methods in TcCommand class will stay untouched because they can be used\nlater to implement also ingress bandwidth limits in QoS.\n\nChange-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248\nCloses-bug: #1563720\n(cherry picked from commit 6dcdb15dce4952cdf3782d57431d0c5f7ba6e53b)\n""}]",0,307730,cd77e8b837556c96cb0a3ad7480d6dc85df3834e,25,10,1,11975,,,0,"LinuxBridge agent's QoS driver bw limit for egress traffic

QoS service plugin provides for now bandwidth limit rules for egress traffic
only (from VM point of view). QoS extension driver for Linuxbridge agent now
configures limits in proper way on tap interface so limited is traffic which is
outgoing from VM.
Linuxbridge agent's QoS extension configures egress bandwidth limit and burst
value in exactly same way how openvswitch is doing it with tc.
Old methods in TcCommand class will stay untouched because they can be used
later to implement also ingress bandwidth limits in QoS.

Change-Id: Id2b0463f49df52744e5bc3979a4cfd0ff06f9248
Closes-bug: #1563720
(cherry picked from commit 6dcdb15dce4952cdf3782d57431d0c5f7ba6e53b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/307730/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/agent/linux/test_tc_lib.py', 'neutron/tests/fullstack/test_qos.py', 'neutron/tests/functional/agent/linux/test_tc_lib.py', 'etc/neutron/rootwrap.d/linuxbridge-plugin.filters', 'neutron/agent/linux/tc_lib.py', 'neutron/tests/unit/plugins/ml2/drivers/linuxbridge/agent/extension_drivers/test_qos_driver.py']",7,cd77e8b837556c96cb0a3ad7480d6dc85df3834e,bug/1563720," tc_lib.TcCommand, ""set_filters_bw_limit"" tc_lib.TcCommand, ""update_filters_bw_limit"" tc_lib.TcCommand, ""delete_filters_bw_limit"""," tc_lib.TcCommand, ""set_bw_limit"" TEST_LATENCY_VALUE tc_lib.TcCommand, ""update_bw_limit"" TEST_LATENCY_VALUE tc_lib.TcCommand, ""delete_bw_limit""",272,86
openstack%2Ftempest~master~I76ad8bf1828da064de4f0c908509b115d6c948fa,openstack/tempest,master,I76ad8bf1828da064de4f0c908509b115d6c948fa,Fix the improper using of iter,ABANDONED,2016-02-03 03:51:58.000000000,2016-05-06 01:22:44.000000000,,"[{'_account_id': 3}, {'_account_id': 7350}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 20190}]","[{'number': 1, 'created': '2016-02-03 03:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/eaca56653f16ec24d31ba464147441f3523ecc8e', 'message': 'mproper use of iter while list is wanted\n\n<test_external_network_visibility> is intended to verify that user can\nsee external networks but not subnets.\n    # subnets_iter is a list (iterator) of lists. This flattens it to a\n    # list of UUIDs\n\n    public_subnets_iter = itertools.chain(*subnets_iter)\n                                    #zhufl: here use the iter in python\n    body = self.client.list_subnets()\n    subnets = [sub[\'id\'] for sub in body[\'subnets\']\n                 if sub[\'id\'] in ublic_subnets_iter]\n                                    #zhufl: but when using list\n                                    #       comprehension, iter will not\n                                    #       work properly, instead we\n                                    #       should use list here\n    self.assertEmpty(subnets, ""Public subnets visible"")\n\ne.g.\n    #different sequence of subnet item list will lead to different result\n    >>> pubsub = iter(\'pub_subnet\')\n    >>> subnets = [sub for sub in\n                    [\'internal_subnet1\',\'internal_subnet2\', \'pub_subnet\']\n                      if sub in pubsub]\n    >>> subnets\n    []\n\n    >>> pubsub = iter(\'public_subnet\')\n    >>> subnets = [sub for sub in\n                   [\'pub_subnet\', \'internal_subnet1\', internal_subnet2\']\n                      if sub in pubsub]\n    >>> subnets\n    [\'pub_subnet\']\n    >>>\n\n    so when using list comprehension, we should use list instead of iter\n\nChange-Id: I76ad8bf1828da064de4f0c908509b115d6c948fa\nCloses-Bug: #1541179\n'}, {'number': 2, 'created': '2016-02-16 01:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/004800d05039782ec1f74ae7ac02609743867622', 'message': 'Fix the improper using of iter\n\nThis correct the improper using of iter in list comprehension while\nlist is wanted instead.\n\nChange-Id: I76ad8bf1828da064de4f0c908509b115d6c948fa\nCloses-Bug: #1541179\n'}, {'number': 3, 'created': '2016-02-29 03:37:45.000000000', 'files': ['tempest/api/network/test_networks.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce35f8d64ce6d0eb803740dae9b53165f4c9642d', 'message': 'Fix the improper using of iter\n\nThis correct the improper using of iterator in list comprehension while\nlist is wanted instead.\n\nWhen using iterator in list comprehension, the items in iterator will be\nconsumed each time sequencely, but we expect them to be available all\ntime to make list comprehension working properly.\n\nChange-Id: I76ad8bf1828da064de4f0c908509b115d6c948fa\nCloses-Bug: #1541179\n'}]",0,275493,ce35f8d64ce6d0eb803740dae9b53165f4c9642d,18,6,3,20190,,,0,"Fix the improper using of iter

This correct the improper using of iterator in list comprehension while
list is wanted instead.

When using iterator in list comprehension, the items in iterator will be
consumed each time sequencely, but we expect them to be available all
time to make list comprehension working properly.

Change-Id: I76ad8bf1828da064de4f0c908509b115d6c948fa
Closes-Bug: #1541179
",git fetch https://review.opendev.org/openstack/tempest refs/changes/93/275493/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_networks.py'],1,eaca56653f16ec24d31ba464147441f3523ecc8e,bug/1541179, public_subnets_iter = list(itertools.chain(*subnets_iter)), public_subnets_iter = itertools.chain(*subnets_iter),1,1
openstack%2Fpuppet-ceph~master~I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb,openstack/puppet-ceph,master,I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb,allow to deployments on Ubuntu Xenial,MERGED,2016-05-02 16:47:49.000000000,2016-05-06 01:12:39.000000000,2016-05-06 00:26:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8797}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-02 16:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/efa42bb0a7ba45b203373ed16eeb75db79fe858a', 'message': 'allow to deployments on Ubuntu Xenial\n\n* Stop hardcoding the service_provider and use stdlib to find it.\n* Drop useless else conditionals, that overlaps with the one in\n  params.pp\n\nFrom this patch, deployments should work on Ubuntu 16.04 LTS, that uses\nsystemd by default.\n\nChange-Id: I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb\n'}, {'number': 2, 'created': '2016-05-02 18:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/6fb9acd4318b0e4f5b622f3a741f883b3602a902', 'message': 'allow to deployments on Ubuntu Xenial\n\n* Stop hardcoding the service_provider and use stdlib to find it.\n* Drop useless else conditionals, that overlaps with the one in\n  params.pp\n\nFrom this patch, deployments should work on Ubuntu 16.04 LTS, that uses\nsystemd by default.\n\nChange-Id: I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb\n'}, {'number': 3, 'created': '2016-05-02 19:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/a4855e12f1263464f35e84e4b66995c32051ae55', 'message': 'allow to deployments on Ubuntu Xenial\n\n* Stop hardcoding the service_provider and use stdlib to find it.\n* Drop useless else conditionals, that overlaps with the one in\n  params.pp\n\nFrom this patch, deployments should work on Ubuntu 16.04 LTS, that uses\nsystemd by default.\n\nChange-Id: I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb\n'}, {'number': 4, 'created': '2016-05-02 19:56:18.000000000', 'files': ['releasenotes/notes/systemd-8b86dee2f9df5a14.yaml', 'spec/defines/ceph_rgw_spec.rb', 'manifests/rgw.pp', 'manifests/mon.pp', 'spec/defines/ceph_mon_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/0117e4e06fa932c67e22408d9b8d2179f9d185e2', 'message': 'allow to deployments on Ubuntu Xenial\n\nFrom this patch, deployments should work on Ubuntu 16.04 LTS, that uses\nsystemd by default.\n\nInstead of using operatingsystem, use service_provider to determine\nwhether or not we want to run upstart scripts.\n\nChange-Id: I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb\n'}]",0,311786,0117e4e06fa932c67e22408d9b8d2179f9d185e2,35,4,4,3153,,,0,"allow to deployments on Ubuntu Xenial

From this patch, deployments should work on Ubuntu 16.04 LTS, that uses
systemd by default.

Instead of using operatingsystem, use service_provider to determine
whether or not we want to run upstart scripts.

Change-Id: I2435ad3153c667a9ffd01bd10b5c5b645d5b76fb
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/86/311786/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/systemd-8b86dee2f9df5a14.yaml', 'manifests/rgw.pp', 'manifests/params.pp', 'manifests/mon.pp']",4,efa42bb0a7ba45b203373ed16eeb75db79fe858a,xenial-support," include ::stdlib # if Ubuntu does not use systemd if $::service_provider == 'upstart' { provider => $::service_provider, # Everything else that is supported by puppet-ceph should run systemd. } else { provider => $::service_provider,"," if $::operatingsystem == 'Ubuntu' { $init = 'upstart' # workaround for bug https://projects.puppetlabs.com/issues/23187 provider => $::ceph::params::service_provider, } elsif $::osfamily in ['RedHat', 'Debian'] { $init = 'sysvinit' provider => $::ceph::params::service_provider, } else { fail(""operatingsystem = ${::operatingsystem} is not supported"")",26,25
openstack%2Fopenstack-manuals~master~Icc6761cdda2ca820447153fa7ec046e22cc98129,openstack/openstack-manuals,master,Icc6761cdda2ca820447153fa7ec046e22cc98129,[ha-guide] Migrate HA Guide into openstack-manuals,MERGED,2016-05-05 09:58:54.000000000,2016-05-06 01:12:23.000000000,2016-05-06 01:12:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6926}, {'_account_id': 9162}, {'_account_id': 10607}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-05 09:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d51e2c06bcd3d829a309c2046846a9753baca3ea', 'message': '[ha-guide] Migrate HA Guide into openstack-manuals\n\nDiscussion at mailing list:\nhttp://lists.openstack.org/pipermail/openstack-docs/2016-May/008532.html\n\nChange-Id: Icc6761cdda2ca820447153fa7ec046e22cc98129\n'}, {'number': 2, 'created': '2016-05-05 23:27:17.000000000', 'files': ['doc/ha-guide/source/controller-ha.rst', 'doc/ha-guide/source/locale/ha-guide.pot', 'doc/ha-guide/source/intro-ha-storage.rst', 'tools/build-all-rst.sh', 'doc/ha-guide/source/hardware-ha.rst', 'doc/ha-guide/source/intro-ha-compute.rst', 'doc/ha-guide/source/figures/keepalived-arch.jpg', 'doc/ha-guide/source/controller-ha-vip.rst', 'doc/ha-guide/source/intro-ha-controller.rst', 'doc/ha-guide/source/controller-ha-galera-config.rst', 'doc/ha-guide/source/install-ha.rst', 'doc/ha-guide/source/compute-node-ha-api.rst', 'doc/ha-guide/source/install-ha-os.rst', 'doc/ha-guide/source/storage-ha-backend.rst', 'doc/ha-guide/source/install-ha-ntp.rst', 'doc/ha-guide/source/networking-ha-metadata.rst', 'doc/ha-guide/source/common', 'doc/ha-guide/source/figures/Cluster-deployment-collapsed.png', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/figures/Cluster-deployment-segregated.png', 'doc/ha-guide/source/controller-ha-telemetry.rst', 'doc/ha-guide/source/noncore-ha.rst', 'doc/ha-guide/source/controller-ha-galera.rst', 'doc/ha-guide/source/controller-ha-rabbitmq.rst', 'doc/ha-guide/source/storage-ha-cinder.rst', 'doc/ha-guide/source/install-ha-memcached.rst', 'doc/ha-guide/source/intro-ha-other.rst', 'doc/ha-guide/source/index.rst', 'doc/ha-guide/source/intro-ha-concepts.rst', 'doc-tools-check-languages.conf', 'doc/ha-guide/source/networking-ha-lbaas.rst', 'doc/ha-guide/source/networking-ha-l3.rst', 'doc/ha-guide/source/storage-ha-manila.rst', 'doc/ha-guide/setup.py', 'doc/ha-guide/source/controller-ha-keystone.rst', 'doc/ha-guide/source/storage-ha-glance.rst', 'doc/ha-guide/source/controller-ha-memcached.rst', 'doc/ha-guide/source/storage-ha.rst', 'doc/ha-guide/source/networking-ha.rst', 'doc/ha-guide/source/intro-ha.rst', 'doc/ha-guide/source/controller-ha-galera-manage.rst', 'doc/ha-guide/source/intro-ha-arch-keepalived.rst', 'doc/ha-guide/source/networking-ha-dhcp.rst', 'doc/ha-guide/source/controller-ha-galera-install.rst', 'doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/conf.py', 'doc/ha-guide/source/intro-ha-arch-pacemaker.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/setup.cfg', 'doc/ha-guide/source/controller-ha-haproxy.rst', 'doc/ha-guide/source/hardware-ha-basic.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2809ad9edb07f0f87b8583f71d07f03d13c9d6b4', 'message': '[ha-guide] Migrate HA Guide into openstack-manuals\n\nDiscussion at mailing list:\nhttp://lists.openstack.org/pipermail/openstack-docs/2016-May/008532.html\n\nChange-Id: Icc6761cdda2ca820447153fa7ec046e22cc98129\n'}]",1,312879,2809ad9edb07f0f87b8583f71d07f03d13c9d6b4,13,6,2,10497,,,0,"[ha-guide] Migrate HA Guide into openstack-manuals

Discussion at mailing list:
http://lists.openstack.org/pipermail/openstack-docs/2016-May/008532.html

Change-Id: Icc6761cdda2ca820447153fa7ec046e22cc98129
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/312879/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/controller-ha.rst', 'doc/ha-guide/source/locale/ha-guide.pot', 'doc/ha-guide/source/intro-ha-storage.rst', 'tools/build-all-rst.sh', 'doc/ha-guide/source/hardware-ha.rst', 'doc/ha-guide/source/intro-ha-compute.rst', 'doc/ha-guide/source/figures/keepalived-arch.jpg', 'doc/ha-guide/source/controller-ha-vip.rst', 'doc/ha-guide/source/intro-ha-controller.rst', 'doc/ha-guide/source/controller-ha-galera-config.rst', 'doc/ha-guide/source/install-ha.rst', 'doc/ha-guide/source/compute-node-ha-api.rst', 'doc/ha-guide/source/install-ha-os.rst', 'doc/ha-guide/source/storage-ha-backend.rst', 'doc/ha-guide/source/install-ha-ntp.rst', 'doc/ha-guide/source/networking-ha-metadata.rst', 'doc/ha-guide/source/common', 'doc/ha-guide/source/figures/Cluster-deployment-collapsed.png', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/figures/Cluster-deployment-segregated.png', 'doc/ha-guide/source/controller-ha-telemetry.rst', 'doc/ha-guide/source/noncore-ha.rst', 'doc/ha-guide/source/controller-ha-galera.rst', 'doc/ha-guide/source/controller-ha-rabbitmq.rst', 'doc/ha-guide/source/storage-ha-cinder.rst', 'doc/ha-guide/source/install-ha-memcached.rst', 'doc/ha-guide/source/intro-ha-other.rst', 'doc/ha-guide/source/index.rst', 'doc/ha-guide/source/intro-ha-concepts.rst', 'doc-tools-check-languages.conf', 'doc/ha-guide/source/networking-ha-lbaas.rst', 'doc/ha-guide/source/networking-ha-l3.rst', 'doc/ha-guide/source/storage-ha-manila.rst', 'doc/ha-guide/setup.py', 'doc/ha-guide/source/controller-ha-keystone.rst', 'doc/ha-guide/source/storage-ha-glance.rst', 'doc/ha-guide/source/controller-ha-memcached.rst', 'doc/ha-guide/source/storage-ha.rst', 'doc/ha-guide/source/networking-ha.rst', 'doc/ha-guide/source/intro-ha.rst', 'doc/ha-guide/source/controller-ha-galera-manage.rst', 'doc/ha-guide/source/intro-ha-arch-keepalived.rst', 'doc/ha-guide/source/networking-ha-dhcp.rst', 'doc/ha-guide/source/controller-ha-galera-install.rst', 'doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/conf.py', 'doc/ha-guide/source/intro-ha-arch-pacemaker.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/setup.cfg', 'doc/ha-guide/source/controller-ha-haproxy.rst', 'doc/ha-guide/source/hardware-ha-basic.rst']",51,d51e2c06bcd3d829a309c2046846a9753baca3ea,ha-guide," ============== Hardware setup ============== The standard hardware requirements: - `Provider networks <http://docs.openstack.org/liberty/install-guide-ubuntu/overview.html#networking-option-1-provider-networks>`_ - `Self-service networks <http://docs.openstack.org/liberty/install-guide-ubuntu/overview.html#networking-option-2-self-service-networks>`_ However, OpenStack does not require a significant amount of resources and the following minimum requirements should support a proof-of-concept high availability environment with core services and several instances: [TODO: Verify that these numbers are good] +-------------------+------------+----------+-----------+------+ | Node type | Processor | Memory | Storage | NIC | +===================+============+==========+===========+======+ | controller node | 1-2 | 8 GB | 100 GB | 2 | +-------------------+------------+----------+-----------+------+ | compute node | 2-4+ | 8+ GB | 100+ GB | 2 | +-------------------+------------+----------+-----------+------+ For demonstrations and studying, you can set up a test environment on virtual machines (VMs). This has the following benefits: - One physical server can support multiple nodes, each of which supports almost any number of network interfaces. - Ability to take periodic ""snap shots"" throughout the installation process and ""roll back"" to a working configuration in the event of a problem. However, running an OpenStack environment on VMs degrades the performance of your instances, particularly if your hypervisor and/or processor lacks support for hardware acceleration of nested VMs. .. note:: When installing highly-available OpenStack on VMs, be sure that your hypervisor permits promiscuous mode and disables MAC address filtering on the external network. ",,12936,2
openstack%2Fpython-glanceclient~stable%2Fmitaka~I25fc8624797909d606590747f54b9cf649ade079,openstack/python-glanceclient,stable/mitaka,I25fc8624797909d606590747f54b9cf649ade079,Re-enable stacktracing when --debug is used,MERGED,2016-03-30 12:50:46.000000000,2016-05-06 01:05:16.000000000,2016-05-06 01:05:16.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 12000}]","[{'number': 1, 'created': '2016-03-30 12:50:46.000000000', 'files': ['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9fc5d56eebfefd0897dc4a0298d862ef12d3d4b2', 'message': 'Re-enable stacktracing when --debug is used\n\nCommit 1f89beb6098f4f6a8d8c2912392b273bc068b2e3 introduced the behaviour\nthat a stacktrace is printed if an exception is encountered.\n\nThis helped make the client more supportable:\n\n $ glance --debug image-list\n  .\n  .\n  .\n  File ""glanceclient/common/http.py"", line 337, in get_http_client\n    xxx\n NameError: global name \'xxx\' is not defined\n global name \'xxx\' is not defined\n\nThe behaviour was lost at some point. This patch re-enables it.\n\nChange-Id: I25fc8624797909d606590747f54b9cf649ade079\nCloses-bug: 1563830\n(cherry picked from commit ca0989c52376a1d499cd0cc176f60b7ff8257275)\n'}]",0,299372,9fc5d56eebfefd0897dc4a0298d862ef12d3d4b2,7,3,1,455,,,0,"Re-enable stacktracing when --debug is used

Commit 1f89beb6098f4f6a8d8c2912392b273bc068b2e3 introduced the behaviour
that a stacktrace is printed if an exception is encountered.

This helped make the client more supportable:

 $ glance --debug image-list
  .
  .
  .
  File ""glanceclient/common/http.py"", line 337, in get_http_client
    xxx
 NameError: global name 'xxx' is not defined
 global name 'xxx' is not defined

The behaviour was lost at some point. This patch re-enables it.

Change-Id: I25fc8624797909d606590747f54b9cf649ade079
Closes-bug: 1563830
(cherry picked from commit ca0989c52376a1d499cd0cc176f60b7ff8257275)
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/72/299372/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py']",2,9fc5d56eebfefd0897dc4a0298d862ef12d3d4b2,bug/1563830, if '--debug' in sys.argv[1:]: traceback.print_exc(), if options.debug: traceback.print_exc() if options.debug: traceback.print_exc() except Exception: # NOTE(kragniz) Print any exceptions raised to stderr if the # --debug flag is set if args.debug: traceback.print_exc() raise,25,10
openstack%2Fha-guide~master~Icc9e165f632ff4e9cbce6713ff84ea5dc8304543,openstack/ha-guide,master,Icc9e165f632ff4e9cbce6713ff84ea5dc8304543,Fix the configuration /etc/xinetd.d/galera-monitor,MERGED,2016-04-14 02:35:32.000000000,2016-05-06 01:00:57.000000000,2016-05-06 01:00:57.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-04-14 02:35:32.000000000', 'files': ['doc/ha-guide/source/controller-ha-galera-manage.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/65bf33bd063fc259b80bc6ef6a9ad1ed9f458c0d', 'message': ""Fix the configuration /etc/xinetd.d/galera-monitor\n\nCan't access the mariadb galera cluster by VIP. And the port\n9200 is down, which caused by the galera-monitor failure.\n\nThis patch fix the configuration of /etc/xinetd.d/galera-monitor\nto up the 9200 port.\n\nChange-Id: Icc9e165f632ff4e9cbce6713ff84ea5dc8304543\nCloses-Bug: #1570161\n""}]",0,305571,65bf33bd063fc259b80bc6ef6a9ad1ed9f458c0d,7,3,1,8358,,,0,"Fix the configuration /etc/xinetd.d/galera-monitor

Can't access the mariadb galera cluster by VIP. And the port
9200 is down, which caused by the galera-monitor failure.

This patch fix the configuration of /etc/xinetd.d/galera-monitor
to up the 9200 port.

Change-Id: Icc9e165f632ff4e9cbce6713ff84ea5dc8304543
Closes-Bug: #1570161
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/71/305571/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-galera-manage.rst'],1,65bf33bd063fc259b80bc6ef6a9ad1ed9f458c0d,bug/1570161, service galera-monitor {, service galera-monitor {,2,1
openstack%2Fha-guide~master~I0ef872914fc762abad30acd86afa670e0e78d04d,openstack/ha-guide,master,I0ef872914fc762abad30acd86afa670e0e78d04d,Update the haproxy config file about the option of galera_cluster,MERGED,2016-04-14 06:04:08.000000000,2016-05-06 00:57:59.000000000,2016-05-06 00:57:59.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 20003}]","[{'number': 1, 'created': '2016-04-14 06:04:08.000000000', 'files': ['doc/ha-guide/source/controller-ha-haproxy.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/b4a22f65c773bb58ea4f43a98c8bbd4f74fc0f56', 'message': 'Update the haproxy config file about the option of galera_cluster\n\nlisten galera_cluster option: httpchk -->  mysql-check\n\nChange-Id: I0ef872914fc762abad30acd86afa670e0e78d04d\nCloses-Bug: #1566771\n'}]",0,305618,b4a22f65c773bb58ea4f43a98c8bbd4f74fc0f56,8,4,1,8358,,,0,"Update the haproxy config file about the option of galera_cluster

listen galera_cluster option: httpchk -->  mysql-check

Change-Id: I0ef872914fc762abad30acd86afa670e0e78d04d
Closes-Bug: #1566771
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/18/305618/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-haproxy.rst'],1,b4a22f65c773bb58ea4f43a98c8bbd4f74fc0f56,bug/1566771, option mysql-check, option httpchk,1,1
openstack%2Fha-guide~master~Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4,openstack/ha-guide,master,Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4,cinder-api service should be active/active,MERGED,2016-04-23 07:11:57.000000000,2016-05-06 00:57:33.000000000,2016-05-06 00:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 16237}, {'_account_id': 20003}]","[{'number': 1, 'created': '2016-04-23 07:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/fed019219c2214e796dae3d7321ac4d7f6bf23ab', 'message': 'cinder-api service should be active/active\n\ncinder-api is an restful API designed to run in\nactive/active behind a load balancer.\n\nChange-Id: Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4\nClouse-Bug: #1571836\n'}, {'number': 2, 'created': '2016-04-23 08:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/44b09dbd8ba7c8b5b5d32e06c99718362a929cc7', 'message': 'cinder-api service should be active/active\n\ncinder-api is an restful API designed to run in\nactive/active behind a load balancer.\n\nChange-Id: Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4\nClouse-Bug: #1571836\n'}, {'number': 3, 'created': '2016-04-25 09:37:43.000000000', 'files': ['doc/ha-guide/source/intro-ha-storage.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/25d2f9ebee860d70e4b04647efd8139eda1db568', 'message': 'cinder-api service should be active/active\n\ncinder-api is an restful API designed to run in\nactive/active behind a load balancer.\n\nChange-Id: Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4\nClouse-Bug: #1571836\n'}]",0,309665,25d2f9ebee860d70e4b04647efd8139eda1db568,15,7,3,8358,,,0,"cinder-api service should be active/active

cinder-api is an restful API designed to run in
active/active behind a load balancer.

Change-Id: Ie0e59ff038d2b744bc5fa71db102a90dddd6b2f4
Clouse-Bug: #1571836
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/65/309665/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/locale/ha-guide.pot', 'doc/ha-guide/source/intro-ha-storage.rst']",2,fed019219c2214e796dae3d7321ac4d7f6bf23ab,bug/1571836,active/active mode involves:,active/passive mode involves:,2,2
openstack%2Fha-guide~master~I7cb48476760608cf9ecea238e5b9f73475e7d989,openstack/ha-guide,master,I7cb48476760608cf9ecea238e5b9f73475e7d989,Refactor ha-guide to fit Documentation style guide,MERGED,2016-04-27 04:38:27.000000000,2016-05-06 00:57:28.000000000,2016-05-06 00:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 16237}, {'_account_id': 17484}, {'_account_id': 19390}, {'_account_id': 19790}, {'_account_id': 19920}, {'_account_id': 20095}, {'_account_id': 20184}]","[{'number': 1, 'created': '2016-04-27 04:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e16ed4b4626e7464b67de11fe1476ba5c9d012dc', 'message': ""[install] Replaced '{' from line = 1 to line = 2\n\nChange-Id: I7cb48476760608cf9ecea238e5b9f73475e7d989\nCloses-Bug: #1574545\n""}, {'number': 2, 'created': '2016-04-27 05:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/25888ac88c83556491ba3201c09991b2c19393ee', 'message': ""[ha-guide] Moved '{' from line = 1 to line = 2\n\nChange-Id: I7cb48476760608cf9ecea238e5b9f73475e7d989\nCloses-Bug: #1574545\n""}, {'number': 3, 'created': '2016-04-27 10:56:44.000000000', 'files': ['doc/ha-guide/source/controller-ha-galera-manage.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/d566df6b5d3d72e8572c77dca32806fa8cbe4f75', 'message': 'Refactor ha-guide to fit Documentation style guide\n\nChange-Id: I7cb48476760608cf9ecea238e5b9f73475e7d989\nCloses-Bug: #1574545\n'}]",2,310343,d566df6b5d3d72e8572c77dca32806fa8cbe4f75,23,10,3,21204,,,0,"Refactor ha-guide to fit Documentation style guide

Change-Id: I7cb48476760608cf9ecea238e5b9f73475e7d989
Closes-Bug: #1574545
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/43/310343/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-galera-manage.rst'],1,e16ed4b4626e7464b67de11fe1476ba5c9d012dc,bug/1574545, service galera-monitor {, service galera-monitor {,2,1
openstack%2Fha-guide~master~I7c52a036c25d8d4b34b4b214dd552c2108853efe,openstack/ha-guide,master,I7c52a036c25d8d4b34b4b214dd552c2108853efe,Fix the inconsistent display of commands,MERGED,2016-04-12 06:31:56.000000000,2016-05-06 00:57:21.000000000,2016-05-06 00:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 8358}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 16237}, {'_account_id': 19779}, {'_account_id': 20156}]","[{'number': 1, 'created': '2016-04-12 06:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/7dea3c02de1b1bcd768c7ae820299089b2013c4b', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 2, 'created': '2016-04-13 01:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/12366f5744583325e63f7a14b7a2a03fc2171c57', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 3, 'created': '2016-04-20 04:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e2fc247fc942db7f5bcbab64ee35f6389089e164', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 4, 'created': '2016-04-22 17:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/de45975776180f1e44873593bec40a18d4800597', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 5, 'created': '2016-04-22 23:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/59862ebdcb5b0ad81e3698e07d5d8491e8c7e517', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 6, 'created': '2016-04-23 15:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/e8ae75580a228d5a7a2b9141d91644560f386c72', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}, {'number': 7, 'created': '2016-04-26 14:59:01.000000000', 'files': ['doc/ha-guide/source/controller-ha-pacemaker.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/fb2f5a13438ffe73496d6569b0112354cd8418c2', 'message': 'Fix the inconsistent display of commands\n\nChange-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe\nCloses-Bug: #1568698\n'}]",20,304407,fb2f5a13438ffe73496d6569b0112354cd8418c2,41,8,7,19779,,,0,"Fix the inconsistent display of commands

Change-Id: I7c52a036c25d8d4b34b4b214dd552c2108853efe
Closes-Bug: #1568698
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/07/304407/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-pacemaker.rst'],1,7dea3c02de1b1bcd768c7ae820299089b2013c4b,bug/1568698,"``Corosync`` is started as a regular system service.Either way, the service is usually named ``corosync``: - To start ``corosync`` by the LSB init script: .. code-block:: console # /etc/init.d/corosync start - Alternately, to start ``corosync`` by this way: .. code-block:: console # service corosync start - To start ``corosync`` by the upstart job: .. code-block:: console # start corosync - To start ``corosync`` by the systemd unit file: .. code-block:: console # systemctl start corosync You can now check the ``corosync`` connectivity with two tools.After the ``corosync`` service have been startedyou can start :command:`pacemakerd`, the Pacemaker master control process. Choose one from the following four ways to start it: - To start ``pacemaker`` by the LSB init script: .. code-block:: console # /etc/init.d/pacemaker start - Alternately, to start ``pacemaker`` by this way: .. code-block:: console # service pacemaker start - To start ``pacemaker`` by the upstart job: .. code-block:: console # start pacemaker - To start ``pacemaker`` by the systemd unit file: .. code-block:: console # systemctl start pacemaker After the ``pacemaker`` service have started,Use the :command:`crm_mon` utility to observe the status of ``pacemaker``:","Corosync is started as a regular system service.Either way, the service is usually named corosync: - :command:`# /etc/init.d/corosync start` (LSB) - :command:`# service corosync start` (LSB, alternate) - :command:`# start corosync` (upstart) - :command:`# systemctl start corosync` (systemd) You can now check the Corosync connectivity with two tools.After the Corosync services have been startedyou can start :command:`pacemakerd`, the Pacemaker master control process: - :command:`# /etc/init.d/pacemaker start` (LSB) - :command:`# service pacemaker start` (LSB, alternate) - :command:`# start pacemaker` (upstart) - :command:`# systemctl start pacemaker` (systemd) After the Pacemaker services have started,Use the :command:`crm_mon` utility to observe the status of Pacemaker:",51,15
openstack%2Ftempest~master~I1ff09499f15466afc75f93402dcf8a94b3b3cd7b,openstack/tempest,master,I1ff09499f15466afc75f93402dcf8a94b3b3cd7b,"create_server should not reject ""os:scheduler_hints"" parameter",ABANDONED,2016-05-05 07:04:10.000000000,2016-05-06 00:51:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 9732}, {'_account_id': 12017}, {'_account_id': 12024}]","[{'number': 1, 'created': '2016-05-05 07:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/99578a03cf6d183fce2e87b0c9935775d863ccfc', 'message': 'create_server interface should not reject ""os:scheduler_hints"" parameter\n\nThis is to allow the create_server caller to pass either ""scheduler_hints""\nor ""os:scheduler_hints"" parameter.\n\nChange-Id: I1ff09499f15466afc75f93402dcf8a94b3b3cd7b\nCloses-Bug: #1578514\n'}, {'number': 2, 'created': '2016-05-05 07:16:38.000000000', 'files': ['tempest/lib/services/compute/servers_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d6dc5bcc9cff2ac3cbfc41c33adde2f444164034', 'message': 'create_server should not reject ""os:scheduler_hints"" parameter\n\nThis is to allow the create_server caller to pass either\n""scheduler_hints"" or ""os:scheduler_hints"" parameter.\n\nChange-Id: I1ff09499f15466afc75f93402dcf8a94b3b3cd7b\nCloses-Bug: #1578514\n'}]",3,312840,d6dc5bcc9cff2ac3cbfc41c33adde2f444164034,8,5,2,20190,,,0,"create_server should not reject ""os:scheduler_hints"" parameter

This is to allow the create_server caller to pass either
""scheduler_hints"" or ""os:scheduler_hints"" parameter.

Change-Id: I1ff09499f15466afc75f93402dcf8a94b3b3cd7b
Closes-Bug: #1578514
",git fetch https://review.opendev.org/openstack/tempest refs/changes/40/312840/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/lib/services/compute/servers_client.py'],1,99578a03cf6d183fce2e87b0c9935775d863ccfc,bug/1578514," :param os:scheduler_hints: The parameter is set in the same level as the parameter 'server' for key in ['scheduler_hints', 'os:scheduler_hints']: if body.get(key): hints = {'os:scheduler_hints': body.pop(key)} break", if body.get('scheduler_hints'): hints = {'os:scheduler_hints': body.pop('scheduler_hints')},6,2
openstack%2Freleases~master~I52d760e96864cb6531ebcf4dfe1532c834ce5bd3,openstack/releases,master,I52d760e96864cb6531ebcf4dfe1532c834ce5bd3,Add Nova-specific milestones to the Newton release schedule,MERGED,2016-05-03 20:45:12.000000000,2016-05-06 00:50:34.000000000,2016-05-06 00:50:34.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-05-03 20:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fdd0ea623aaa2aa23ec7820f21cbfa15e1b91a16', 'message': 'Add Nova-specific milestones to the Newton release schedule\n\nThis is based on the wiki:\n\nhttps://wiki.openstack.org/wiki/Nova/Newton_Release_Schedule\n\nChange-Id: I52d760e96864cb6531ebcf4dfe1532c834ce5bd3\n'}, {'number': 2, 'created': '2016-05-05 18:13:23.000000000', 'files': ['doc/source/newton/schedule.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/b5f7682a8ec438f3a0ecea0780e69bd96fe2cfb4', 'message': 'Add Nova-specific milestones to the Newton release schedule\n\nThis is based on the wiki:\n\nhttps://wiki.openstack.org/wiki/Nova/Newton_Release_Schedule\n\nChange-Id: I52d760e96864cb6531ebcf4dfe1532c834ce5bd3\n'}]",0,312245,b5f7682a8ec438f3a0ecea0780e69bd96fe2cfb4,12,9,2,6873,,,0,"Add Nova-specific milestones to the Newton release schedule

This is based on the wiki:

https://wiki.openstack.org/wiki/Nova/Newton_Release_Schedule

Change-Id: I52d760e96864cb6531ebcf4dfe1532c834ce5bd3
",git fetch https://review.opendev.org/openstack/releases refs/changes/45/312245/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/newton/schedule.rst'],1,fdd0ea623aaa2aa23ec7820f21cbfa15e1b91a16,nova-newton-schedule,"| May 30-03 | R-18 | :ref:`n-1` | :ref:`n-nova-non-prio-s-fr` || Jun 27-01 | R-14 | | :ref:`n-nova-non-prio-ff` || Aug 01-05 | R-9 | | :ref:`n-nova-prio-spec-frz` |Nova ---- For reference, these are the `Nova review priorities for Newton`_. .. _Nova review priorities for Newton: https://specs.openstack.org/openstack/nova-specs/priorities/newton-priorities.html .. _n-nova-non-prio-s-fr: Nova non-priority spec approval freeze ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ All non-priority Nova specs must be approved by June 2nd, 2016. .. _n-nova-non-prio-ff: Nova non-priority feature freeze ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The deadline for non-priority features is June 30th, 2016. There may be a round of feature freeze exceptions but that will be at the discretion of the Nova core team. .. _n-nova-prio-spec-frz: Nova priority spec approval freeze ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ All priority Nova specs must be approved by August 4th, 2016. This is intentionally after the Nova midcycle meetup for Newton so there is some time for last minute adjustments to priority features.",| May 30-03 | R-18 | :ref:`n-1` | || Jun 27-01 | R-14 | | || Aug 01-05 | R-9 | | |,34,3
openstack%2Fcinder~master~Ica182122d3d4180616cfe630223c7d503f2eaebc,openstack/cinder,master,Ica182122d3d4180616cfe630223c7d503f2eaebc,Add ZTE Block Storage Driver,ABANDONED,2015-12-17 08:58:30.000000000,2016-05-06 00:48:02.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 6492}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 10439}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12184}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14377}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14865}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17405}, {'_account_id': 17717}, {'_account_id': 17718}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19151}, {'_account_id': 19371}, {'_account_id': 19798}, {'_account_id': 19852}, {'_account_id': 19904}, {'_account_id': 19917}]","[{'number': 1, 'created': '2015-12-17 08:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/621b891e512c5ea3080dfcde5fda0474f2cfba73', 'message': 'add zte cinder driver and unit test file.\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 2, 'created': '2015-12-18 15:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e907d15e836f5162300b2591be41cbd5be82d4c', 'message': 'Add zte cinder driver and unit test file\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 3, 'created': '2015-12-18 15:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8f24c148532d28a4e098722662a55414bcd3cfb', 'message': 'Add ZTE cinder driver and unit test file\n\nThis is cinder driver for ZTE KS3200 Storage.\n\nImplements: blueprint ""Add ZTE Block Storage Driver for ZTE ZXCLOUD\nStorage arrays with iSCSI""\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 4, 'created': '2015-12-18 15:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/afa84a3aaa7f330bd08ff7e717a6f0b1f7d92740', 'message': 'Add ZTE cinder driver and unit test file\n\nThis is cinder driver for ZTE KS3200 Storage.\n\nDocImpact\nImplements: blueprint ""Add ZTE Block Storage Driver for ZTE ZXCLOUD\nStorage arrays with iSCSI""\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 5, 'created': '2015-12-18 15:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/26cde5ef2f1a226b3bad31e8237ef74f01f30817', 'message': 'Add ZTE cinder driver and unit test file\n\nThis is cinder driver for ZTE KS3200 Storage.\n\nDocImpact\nImplements: blueprint ""Add ZTE Block Storage Driver for ZTE ZXCLOUD\nStorage arrays with iSCSI""\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 6, 'created': '2015-12-19 02:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/016088ea824f7555430e6d7e3c789caa0e482dbf', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements:  blueprint Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 7, 'created': '2015-12-19 07:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed9125dd3cb0a128a977a7dc21ac7723964ef7d3', 'message': ""Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: blueprint 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.'\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n""}, {'number': 8, 'created': '2015-12-20 11:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce3b056bb8268e21fb6724864ef993da07bbb52d', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 9, 'created': '2015-12-20 13:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e013cb87e78291a539f3596ace6f90f83acc3a40', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 10, 'created': '2015-12-21 06:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7fe91db901e3fff36b53725005ecdd4355dae522', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 11, 'created': '2015-12-21 10:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e70fdf45ee5ed9c3379d31820e95a6e0aac60b26', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 12, 'created': '2015-12-22 03:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5897c11d5e46c62f1249d2f237ccf55831667b27', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 13, 'created': '2015-12-22 08:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/62f26f2520a751c477c50c42c02d586176256e54', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 14, 'created': '2015-12-23 04:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f67fda27ad0c661d9aa0ec839e124e43ae47ed27', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 15, 'created': '2015-12-23 04:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/32bb8f1d9aeddb401d2fedd14781e1cd831764fd', 'message': 'Add ZTE Block Storage Driver for ZTE ZXCLOUD Storage arrays with iSCSI.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 16, 'created': '2015-12-23 09:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71e87e5702550c5dcadfbaab3b982a48d3fae420', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 17, 'created': '2015-12-24 04:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf85d02b8c7cafbe605d71b430bd56150407f775', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Icehouse:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 18, 'created': '2015-12-25 08:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc44ae92d0085150dd9883de313ee84846c9af52', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 19, 'created': '2015-12-25 09:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c91a2d6a74b2a810ef3e59f924c45ebac0697d8f', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 20, 'created': '2015-12-25 12:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8071de0d052f17627eb0640faa2c9fe323b538a1', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 21, 'created': '2015-12-25 15:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4058012669db82c4c66003cf1cba5843e976c16b', 'message': 'Add ZTE Block Storage Driver.\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 22, 'created': '2016-01-15 08:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a3d081431751ea24b436a3040d7ef72aa19e0cc2', 'message': 'Add ZTE Block Storage Driver\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 23, 'created': '2016-01-15 14:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1c029ff04cbe5b680d03265dcf96d561c62c668', 'message': 'Add ZTE Block Storage Driver\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 24, 'created': '2016-01-18 01:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f77610aaeb93a2cc67c3f9bf34a65b7732fd86ff', 'message': 'Add ZTE Block Storage Driver\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 25, 'created': '2016-01-18 06:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f38e6e63ad02026ce35df4dca39cb1e88191525a', 'message': 'Add ZTE Block Storage Driver\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}, {'number': 26, 'created': '2016-01-22 07:22:00.000000000', 'files': ['cinder/opts.py', 'cinder/volume/drivers/zte/zte_ks.py', 'cinder/volume/drivers/zte/zte_pub.py', 'tests-py3.txt', 'cinder/tests/unit/test_zte_ks.py', 'cinder/volume/drivers/zte/__init__.py', 'releasenotes/notes/zte_cinder_driver-76ba6d034e1b6f65.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0006d3ab00bac91c7ddfca65bffb09a0e0c836f', 'message': 'Add ZTE Block Storage Driver\n\nIt will support the minimum set of features required in Mitaka:\n * Volume Create/Delete\n * Volume Attach/Detach\n * Snapshot Create/Delete\n * Create Volume from Snapshot\n * Copy Image to Volume\n * Copy Volume to Image\n * Clone Volume\n * Extend Volume\n\nDocImpact\nImplements: bp zte-cinder-driver\n\nChange-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc\n'}]",116,258880,e0006d3ab00bac91c7ddfca65bffb09a0e0c836f,431,66,26,19791,,,0,"Add ZTE Block Storage Driver

It will support the minimum set of features required in Mitaka:
 * Volume Create/Delete
 * Volume Attach/Detach
 * Snapshot Create/Delete
 * Create Volume from Snapshot
 * Copy Image to Volume
 * Copy Volume to Image
 * Clone Volume
 * Extend Volume

DocImpact
Implements: bp zte-cinder-driver

Change-Id: Ica182122d3d4180616cfe630223c7d503f2eaebc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/80/258880/26 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/zte/zte_ks.py', 'cinder/volume/drivers/zte/zte_pub.py', 'tests-py3.txt', 'cinder/tests/unit/test_zte_ks.py', 'cinder/volume/drivers/zte/__init__.py']",5,621b891e512c5ea3080dfcde5fda0474f2cfba73,bp/Add,"# Copyright (c) 2012 Zte Technologies Co., Ltd. # Copyright (c) 2012 OpenStack LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",,1331,0
openstack%2Fneutron-dynamic-routing~master~I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9,openstack/neutron-dynamic-routing,master,I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9,Documentation,MERGED,2016-04-28 11:23:55.000000000,2016-05-06 00:31:12.000000000,2016-05-06 00:31:12.000000000,"[{'_account_id': 3}, {'_account_id': 4187}, {'_account_id': 7448}, {'_account_id': 14605}, {'_account_id': 17455}]","[{'number': 1, 'created': '2016-04-28 11:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/60fe16b31b2b3344a332c31bb5b2857eeecaffd8', 'message': 'Restructuring documentation framework\n\nThis patch restructures existing documents for better user\nexperience.\n\nBelow changes are done as part of this patch-set:\n - Re-structured/Reworded existing documents.\n - Identified and added dummy documents for required devrefs.\n\nChange-Id: I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9\n'}, {'number': 2, 'created': '2016-04-28 11:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/26af12c93451ede21546e0925fc08099c44aca29', 'message': 'Restructuring documentation framework\n\nThis patch restructures existing documents for better user\nexperience.\n\nBelow changes are done as part of this patch-set:\n - Re-structured/Reworded existing documents.\n - Identified and added dummy documents for required devrefs.\n\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n\nChange-Id: I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9\n'}, {'number': 3, 'created': '2016-04-28 11:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/77cccfea3ac7dd5911104d4ab0f7a62477689d13', 'message': 'Documentation\n\nThis patch restructures existing documents for better user\nexperience.\n\nBelow changes are done as part of this patch-set:\n - Re-structured/Reworded existing documents.\n - Identified and added dummy documents for required devrefs.\n\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n\nChange-Id: I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9\n'}, {'number': 4, 'created': '2016-05-05 15:29:49.000000000', 'files': ['doc/source/others/testing.rst', 'doc/source/contributing.rst', 'doc/source/design/agent-scheduler.rst', 'README.rst', 'doc/source/usage.rst', 'doc/source/design/command-lines.rst', 'doc/source/installation.rst', 'doc/source/design/drivers.rst', 'doc/source/others/alembic_migration.rst', 'doc/source/index.rst', 'doc/source/functionality/bgp-speaker.rst', 'doc/source/design/system-design.rst', 'doc/source/design/api.rst', 'doc/source/functionality/route-advertisement.rst'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/cf6cf44e4ba589ddf85749bca8ec1a2ec9df7243', 'message': 'Documentation\n\nThis patch restructures existing documents for better user\nexperience.\n\nBelow changes are done as part of this patch-set:\n - Re-structured/Reworded existing documents.\n - Identified and added dummy documents for required devrefs.\n\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n\nChange-Id: I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9\n'}]",1,310735,cf6cf44e4ba589ddf85749bca8ec1a2ec9df7243,17,5,4,14605,,,0,"Documentation

This patch restructures existing documents for better user
experience.

Below changes are done as part of this patch-set:
 - Re-structured/Reworded existing documents.
 - Identified and added dummy documents for required devrefs.

Implements: blueprint bgp-spinout
Partial-Bug: #1560003

Change-Id: I71d9f6107bca165d72b6f6e710ac6e0e6108fcf9
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/35/310735/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/others/testing.rst', 'doc/source/contributing.rst', 'doc/source/design/agent-scheduler.rst', 'README.rst', 'doc/source/usage.rst', 'doc/source/design/command-lines.rst', 'doc/source/installation.rst', 'doc/source/design/drivers.rst', 'doc/source/others/alembic_migration.rst', 'doc/source/index.rst', 'doc/source/functionality/bgp-speaker.rst', 'doc/source/design/system-design.rst', 'doc/source/design/api.rst', 'doc/source/functionality/route-advertisement.rst']",14,60fe16b31b2b3344a332c31bb5b2857eeecaffd8,bp/bgp-spinout,".. Copyright 2016 Huawei Technologies India Pvt Limited. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Convention for heading levels in Neutron devref: ======= Heading 0 (reserved for the title in a document) ------- Heading 1 ~~~~~~~ Heading 2 +++++++ Heading 3 ''''''' Heading 4 (Avoid deeper levels because they do not render well.) Route Advertisement =================== TODO: Coming Soon ",,380,19
openstack%2Fnova~master~Ib589507967742334ad93c6a68de4ee8d3bb42eec,openstack/nova,master,Ib589507967742334ad93c6a68de4ee8d3bb42eec,UEFI - instance terminates after boot,MERGED,2016-04-27 09:19:56.000000000,2016-05-06 00:30:21.000000000,2016-05-06 00:30:20.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14447}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-27 09:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc6cf6950f7141379eb15de4bb6447281b09605a', 'message': ""UEFI - instance terminates after boot\n\nWhen nvram element had specify template attribute which is path to boot\nloader variable, libvirt will copy the file into libvirt's nvram\nfolder. Then qemu will boot with boot loader and boot loader variable.\n\nNova will specify boot loader to template attribute in nvram element\ninstead of specify boot loader variable. This will cause RAM execute\nfailed at qemu process.\n\nWe can add option named override_master_nvram. If it didn't specify, we\nwill use the boot loader variable which is paired with boot loader in\nqemu config. If it had specify, We just use the boot loader variable\nwhich is paired with boot loader in this option.\n\nChange-Id: Ib589507967742334ad93c6a68de4ee8d3bb42eec\nCloses-Bug: #1574558\n""}, {'number': 2, 'created': '2016-05-05 02:35:22.000000000', 'files': ['nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/647a022baca76f38c73462b99145665cc8095f41', 'message': ""UEFI - instance terminates after boot\n\nWhen nvram element had specify template attribute which is path to boot\nloader variable, libvirt will copy the file into libvirt's nvram\nfolder. Then qemu will boot with boot loader and boot loader variable.\n\nNova will specify boot loader to template attribute in nvram element\ninstead of specify boot loader variable. This will cause RAM execute\nfailed at qemu process.\n\nQemu config have variable named nvram which save location of master\nnvram file. Therefore we didn't need to assign variable store file, just\nlet libvirt process to find relative variable store file with OVMF code file.\n\nChange-Id: Ib589507967742334ad93c6a68de4ee8d3bb42eec\nCloses-Bug: #1574558\n""}]",5,310381,647a022baca76f38c73462b99145665cc8095f41,38,14,2,14447,,,0,"UEFI - instance terminates after boot

When nvram element had specify template attribute which is path to boot
loader variable, libvirt will copy the file into libvirt's nvram
folder. Then qemu will boot with boot loader and boot loader variable.

Nova will specify boot loader to template attribute in nvram element
instead of specify boot loader variable. This will cause RAM execute
failed at qemu process.

Qemu config have variable named nvram which save location of master
nvram file. Therefore we didn't need to assign variable store file, just
let libvirt process to find relative variable store file with OVMF code file.

Change-Id: Ib589507967742334ad93c6a68de4ee8d3bb42eec
Closes-Bug: #1574558
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/310381/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,bc6cf6950f7141379eb15de4bb6447281b09605a,bug-1574558," with mock.patch.object(drvr, ""_has_uefi_support"", return_value=True) as mock_support: mock_support.assert_called_once_with() self.assertIsNone(cfg.os_nvram) @mock.patch.object(libvirt_utils, 'get_arch', return_value=arch.X86_64) def test_get_guest_config_with_uefi_override_nvram(self, mock_arch): self.flags(override_master_nvram={""/usr/share/OVMF/OVMF_CODE.fd"": ""fake_nvram""}, group='libvirt') drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) image_meta = objects.ImageMeta.from_dict({ ""disk_format"": ""raw"", ""properties"": {""hw_firmware_type"": ""uefi""}}) instance_ref = objects.Instance(**self.test_instance) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref, image_meta) with mock.patch.object(drvr, ""_has_uefi_support"", return_value=True) as mock_support: cfg = drvr._get_guest_config(instance_ref, [], image_meta, disk_info) mock_support.assert_called_once_with() self.assertEqual(cfg.os_loader_type, ""pflash"") self.assertEqual(cfg.os_nvram, ""fake_nvram"")"," with test.nested( mock.patch.object(drvr, ""_has_uefi_support"", return_value=True)):",66,10
openstack%2Ftripleo-heat-templates~stable%2Fliberty~If028c9d7764210363135c3e7cc16ae1fb897a77c,openstack/tripleo-heat-templates,stable/liberty,If028c9d7764210363135c3e7cc16ae1fb897a77c,Switch to POLL_TEMP_URL for config transport,ABANDONED,2015-12-15 02:54:35.000000000,2016-05-06 00:28:01.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6928}, {'_account_id': 7065}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 12715}]","[{'number': 1, 'created': '2015-12-15 02:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3812648d5af927fa008a4145767f80dcb61beb0e', 'message': 'Switch to POLL_TEMP_URL for config transport\n\nThis will allow the following:\n- reduced load on heat for large overclouds\n- a shorter os-collect-config poll interval without increasing load on\n  the undercloud\n- the ability to add config deployments outside the stack, allowing\n  workflow tools like mistral, ansible or tripleoclient to directly\n  deploy custom scripts and config to overcloud nodes\n\nChange-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c\nDepends-On: I9c475f0c489c67db5895924050186228403f2773\n(cherry picked from commit c26b541efb7c1cb16a7d7a2f2a12f52696c5146d)\n'}, {'number': 2, 'created': '2016-03-06 23:55:48.000000000', 'files': ['overcloud-resource-registry-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/133dfaaab023d049a4d27805e2f832d84ef7061c', 'message': 'Switch to POLL_TEMP_URL for config transport\n\nThis will allow the following:\n- reduced load on heat for large overclouds\n- a shorter os-collect-config poll interval without increasing load on\n  the undercloud\n- the ability to add config deployments outside the stack, allowing\n  workflow tools like mistral, ansible or tripleoclient to directly\n  deploy custom scripts and config to overcloud nodes\n\nChange-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c\nDepends-On: I1bad4a4a79cf297f5b6e439e0657269738b5f326\n(cherry picked from commit c26b541efb7c1cb16a7d7a2f2a12f52696c5146d)\n'}]",0,257657,133dfaaab023d049a4d27805e2f832d84ef7061c,35,9,2,4571,,,0,"Switch to POLL_TEMP_URL for config transport

This will allow the following:
- reduced load on heat for large overclouds
- a shorter os-collect-config poll interval without increasing load on
  the undercloud
- the ability to add config deployments outside the stack, allowing
  workflow tools like mistral, ansible or tripleoclient to directly
  deploy custom scripts and config to overcloud nodes

Change-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c
Depends-On: I1bad4a4a79cf297f5b6e439e0657269738b5f326
(cherry picked from commit c26b541efb7c1cb16a7d7a2f2a12f52696c5146d)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/57/257657/2 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-resource-registry-puppet.yaml'],1,3812648d5af927fa008a4145767f80dcb61beb0e,250593, SoftwareConfigTransport: POLL_TEMP_URL,,1,0
openstack%2Fnova~master~Iddb4e8e309f3b9f311716eeb4072134032b48cad,openstack/nova,master,Iddb4e8e309f3b9f311716eeb4072134032b48cad,Add os-interface functional negative tests,MERGED,2016-02-04 12:43:19.000000000,2016-05-06 00:05:04.000000000,2016-05-06 00:05:03.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-04 12:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9018be0e4587d395f50a020ab4334bdfaddde16', 'message': 'Add os-interface functional negative tests\n\nAs a result of discussion in the patch for tempest[1],\nsome negative tests for os-interface have been added\nto nova functional tests.\nLifecycle testing and other negative test cases\nfor os-interface will be added in subsequent patches.\n\n[1] https://review.openstack.org/#/c/257255/\n\nChange-Id: Iddb4e8e309f3b9f311716eeb4072134032b48cad\nImplements: blueprint functional-tests-for-nova\n'}, {'number': 2, 'created': '2016-02-16 10:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d431bd8cc4a91b62193194237746a667a409b0f', 'message': 'Add os-interface functional negative tests\n\nAs a result of discussion in the patch for tempest[1],\nsome negative tests for os-interface have been added\nto nova functional tests.\nLifecycle testing and other negative test cases\nfor os-interface will be added in subsequent patches.\n\n[1] https://review.openstack.org/#/c/257255/\n\nChange-Id: Iddb4e8e309f3b9f311716eeb4072134032b48cad\nImplements: blueprint functional-tests-for-nova\n'}, {'number': 3, 'created': '2016-04-04 06:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06602c1fc2f412ca30e84be420b90b3e0ab80474', 'message': 'Add os-interface functional negative tests\n\nAs a result of discussion in the patch for tempest[1],\nsome negative tests for os-interface have been added\nto nova functional tests.\nLifecycle testing and other negative test cases\nfor os-interface will be added in subsequent patches.\n\n[1] https://review.openstack.org/#/c/257255/\n\nChange-Id: Iddb4e8e309f3b9f311716eeb4072134032b48cad\nImplements: blueprint functional-tests-for-nova\n'}, {'number': 4, 'created': '2016-05-02 04:47:49.000000000', 'files': ['nova/tests/functional/wsgi/test_attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9df2e7a0e86e345c37a6906294dbca4deea22f5e', 'message': 'Add os-interface functional negative tests\n\nAs a result of discussion in the patch for tempest[1],\nsome negative tests for os-interface have been added\nto nova functional tests.\n\n[1] https://review.openstack.org/#/c/257255/\n\nChange-Id: Iddb4e8e309f3b9f311716eeb4072134032b48cad\n'}]",5,276197,9df2e7a0e86e345c37a6906294dbca4deea22f5e,48,14,4,7634,,,0,"Add os-interface functional negative tests

As a result of discussion in the patch for tempest[1],
some negative tests for os-interface have been added
to nova functional tests.

[1] https://review.openstack.org/#/c/257255/

Change-Id: Iddb4e8e309f3b9f311716eeb4072134032b48cad
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/276197/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/wsgi/test_attach_interfaces.py'],1,a9018be0e4587d395f50a020ab4334bdfaddde16,add-os-interface-functional-negative-tests,"# Copyright 2016 NTT Corporation. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers from nova.tests.unit import policy_fixture def create_request_body(): return { ""interfaceAttachment"": { ""port_id"": str(uuid.uuid4()), ""net_id"": str(uuid.uuid4()), ""fixed_ips"": [ { ""ip_address"": ""192.168.1.3"", ""subnet_id"": str(uuid.uuid4()) } ] } } class InterfaceFullstack(integrated_helpers._IntegratedTestBase): """"""Tests for port interfaces command. Extension: os-interface os-interface adds a set of functions to the port interfaces for the creation and deletion of port interfaces. POST /v2.1/{tenant_id}/servers/{server_id}/os-interface DELETE /v2.1/{tenant_id}/servers/{server_id}/os-interface/{attachment_id} Functional Test Scope: This test starts the wsgi stack for the nova api services, uses an in memory database to ensure the path through the wsgi layer to the database. """""" api_major_version = 'v2.1' _image_ref_parameter = 'imageRef' _flavor_ref_parameter = 'flavorRef' def setUp(self): super(InterfaceFullstack, self).setUp() self.useFixture(policy_fixture.RealPolicyFixture()) api_fixture = self.useFixture(nova_fixtures.OSAPIFixture()) self.api = api_fixture.api def test_interface_func_negative(self): """"""Test port interface edge conditions. - Bogus body is a 400 """""" # Create a server server = self._build_minimal_create_server_request() created_server = self.api.post_server({""server"": server}) created_server_id = created_server['id'] # Test for API failure conditions # bad body is 400 os_interface_url = '/servers/%s/os-interface' % created_server_id # Check in the case that both net_id and port_id are specified. body = create_request_body() del body['interfaceAttachment']['fixed_ips'] resp = self.api.api_post(os_interface_url, body, check_response_status=False) self.assertEqual(400, resp.status) # Check in the case that fixed_ips is specified, # but net_id is not specifed. body = create_request_body() del body['interfaceAttachment']['port_id'] del body['interfaceAttachment']['net_id'] resp = self.api.api_post(os_interface_url, body, check_response_status=False) self.assertEqual(400, resp.status) ",,96,0
openstack%2Fneutron~master~Ic1e316f2eb4e273e5b9fb045f1822d30af7bda68,openstack/neutron,master,Ic1e316f2eb4e273e5b9fb045f1822d30af7bda68,Preserve backward compatibility with OVS hybrid plugging,MERGED,2016-05-02 22:30:47.000000000,2016-05-06 00:04:43.000000000,2016-05-06 00:04:42.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-05-02 22:30:47.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/openvswitch/mech_driver/test_mech_openvswitch.py', 'neutron/plugins/ml2/drivers/openvswitch/mech_driver/mech_openvswitch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c7da2e3ca7ae4ca723fa26bda1a26d3fe95af95', 'message': 'Preserve backward compatibility with OVS hybrid plugging\n\nIn Liberty and before, the Neutron server never had to be\nconfigured with a firewall driver for the OVS hybrid IPtables filtering\nbridge to work. However, in Mitaka, some logic snuck in[1] that made it\nso if the driver was not defined, the hybrid plugging would be disabled.\nThis essentially broke anyone upgrading from Liberty to Mitaka who\nwas using OVS and did not have the firewall driver configured on the\nserver.\n\nThis patch adjusts the default if the driver is not defined on the\nserver to automatically set hyrbid plugging to true to preserve the\nLiberty behavior.\n\n1. I13e5cda8b5f3a13a60b14d80e54f198f32d7a529\n\nCloses-Bug: #1577584\nChange-Id: Ic1e316f2eb4e273e5b9fb045f1822d30af7bda68\n'}]",1,311881,7c7da2e3ca7ae4ca723fa26bda1a26d3fe95af95,25,8,1,7787,,,0,"Preserve backward compatibility with OVS hybrid plugging

In Liberty and before, the Neutron server never had to be
configured with a firewall driver for the OVS hybrid IPtables filtering
bridge to work. However, in Mitaka, some logic snuck in[1] that made it
so if the driver was not defined, the hybrid plugging would be disabled.
This essentially broke anyone upgrading from Liberty to Mitaka who
was using OVS and did not have the firewall driver configured on the
server.

This patch adjusts the default if the driver is not defined on the
server to automatically set hyrbid plugging to true to preserve the
Liberty behavior.

1. I13e5cda8b5f3a13a60b14d80e54f198f32d7a529

Closes-Bug: #1577584
Change-Id: Ic1e316f2eb4e273e5b9fb045f1822d30af7bda68
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/311881/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/openvswitch/mech_driver/test_mech_openvswitch.py', 'neutron/plugins/ml2/drivers/openvswitch/mech_driver/mech_openvswitch.py']",2,7c7da2e3ca7ae4ca723fa26bda1a26d3fe95af95,bug/1577584," hybrid_plug_required = (not cfg.CONF.SECURITYGROUP.firewall_driver or cfg.CONF.SECURITYGROUP.firewall_driver in ( IPTABLES_FW_DRIVER_FULL, 'iptables_hybrid')) and sg_enabled"," hybrid_plug_required = (cfg.CONF.SECURITYGROUP.firewall_driver in ( IPTABLES_FW_DRIVER_FULL, 'iptables_hybrid')) and sg_enabled",19,2
openstack%2Fopenstack-manuals~master~I1626438b76cf9d3bf23e4b9cabfd434c7f44a42a,openstack/openstack-manuals,master,I1626438b76cf9d3bf23e4b9cabfd434c7f44a42a,[ops-guide] Update networking guide link,MERGED,2016-05-05 15:50:52.000000000,2016-05-05 23:55:23.000000000,2016-05-05 23:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-05 15:50:52.000000000', 'files': ['doc/ops-guide/source/preface.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/78bf013e0324a2936b49da2cdf3e6ded3ee0efb0', 'message': '[ops-guide] Update networking guide link\n\nChange-Id: I1626438b76cf9d3bf23e4b9cabfd434c7f44a42a\n'}]",0,313033,78bf013e0324a2936b49da2cdf3e6ded3ee0efb0,7,3,1,16237,,,0,"[ops-guide] Update networking guide link

Change-Id: I1626438b76cf9d3bf23e4b9cabfd434c7f44a42a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/33/313033/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/preface.rst'],1,78bf013e0324a2936b49da2cdf3e6ded3ee0efb0,newton,`Networking Guide <http://docs.openstack.org/mitaka/networking-guide/>`_,`Networking Guide <http://docs.openstack.org/networking-guide/>`_,1,1
openstack%2Fsolum~master~I4f951d0d3ff67318adfe4dc5f22beabc85948730,openstack/solum,master,I4f951d0d3ff67318adfe4dc5f22beabc85948730,change workflow status from READY to DEPLOYMENT_COMPLETE,MERGED,2016-05-04 21:43:37.000000000,2016-05-05 23:44:14.000000000,2016-05-05 23:44:14.000000000,"[{'_account_id': 3}, {'_account_id': 2506}]","[{'number': 1, 'created': '2016-05-04 21:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d0903359355cf3f5a3aa1da86e4a6bbbc5b86338', 'message': 'change workflow status from READY to DEPLOYMENT_COMPLETE\n\nChange-Id: I4f951d0d3ff67318adfe4dc5f22beabc85948730\n'}, {'number': 2, 'created': '2016-05-04 21:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8b0d424bb662b3285bd4ef80c1e9a06ae7ea46e4', 'message': 'change workflow status from READY to DEPLOYMENT_COMPLETE\n\nChange-Id: I4f951d0d3ff67318adfe4dc5f22beabc85948730\nCloses-Bug: #1515681\n'}, {'number': 3, 'created': '2016-05-04 22:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1163184ae269a25f4fa172bf50d71da6c156c235', 'message': 'change workflow status from READY to DEPLOYMENT_COMPLETE\n\nChange-Id: I4f951d0d3ff67318adfe4dc5f22beabc85948730\nCloses-Bug: #1515681\n'}, {'number': 4, 'created': '2016-05-05 15:43:54.000000000', 'files': ['solum/tests/deployer/handlers/test_heat.py', 'solum/deployer/handlers/heat.py', 'solum/tests/objects/test_assembly.py', 'solum/objects/assembly.py', 'doc/source/getting_started/index.rst'], 'web_link': 'https://opendev.org/openstack/solum/commit/4aa05104062191c3c330b707e6f94082aaeac575', 'message': 'change workflow status from READY to DEPLOYMENT_COMPLETE\n\nChange-Id: I4f951d0d3ff67318adfe4dc5f22beabc85948730\nCloses-Bug: #1515681\n'}]",0,312763,4aa05104062191c3c330b707e6f94082aaeac575,11,2,4,7230,,,0,"change workflow status from READY to DEPLOYMENT_COMPLETE

Change-Id: I4f951d0d3ff67318adfe4dc5f22beabc85948730
Closes-Bug: #1515681
",git fetch https://review.opendev.org/openstack/solum refs/changes/63/312763/4 && git format-patch -1 --stdout FETCH_HEAD,"['solum/deployer/handlers/heat.py', 'solum/objects/assembly.py']",2,d0903359355cf3f5a3aa1da86e4a6bbbc5b86338,bug/1515681, DEPLOYMENT_COMPLETE = 'DEPLOYMENT_COMPLETE', READY = 'READY',8,7
openstack%2Fopenstack-ansible~master~I4abe7a699cff82fb22a1562d9bd9c6e479778e26,openstack/openstack-ansible,master,I4abe7a699cff82fb22a1562d9bd9c6e479778e26,Ensure that the sources-branch-updater updates the Ironic role,MERGED,2016-05-05 20:08:55.000000000,2016-05-05 23:31:12.000000000,2016-05-05 23:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 20:08:55.000000000', 'files': ['scripts/sources-branch-updater.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c4418499a24b78dc423fc065e6784fdb919da173', 'message': 'Ensure that the sources-branch-updater updates the Ironic role\n\nThis includes the ironic service in the list of services to check for\nupdates for the rootwrap filters and other carried files.\n\nChange-Id: I4abe7a699cff82fb22a1562d9bd9c6e479778e26\n'}]",0,313139,c4418499a24b78dc423fc065e6784fdb919da173,7,2,1,6816,,,0,"Ensure that the sources-branch-updater updates the Ironic role

This includes the ironic service in the list of services to check for
updates for the rootwrap filters and other carried files.

Change-Id: I4abe7a699cff82fb22a1562d9bd9c6e479778e26
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/39/313139/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/sources-branch-updater.sh'],1,c4418499a24b78dc423fc065e6784fdb919da173,,"OPENSTACK_SERVICE_LIST=${OPENSTACK_SERVICE_LIST:-""aodh ceilometer cinder glance heat ironic keystone neutron nova""}","OPENSTACK_SERVICE_LIST=${OPENSTACK_SERVICE_LIST:-""aodh ceilometer cinder glance heat keystone neutron nova""}",1,1
openstack%2Fneutron~master~Ie51d3dee788719bc480f92d3e003991a195d67c0,openstack/neutron,master,Ie51d3dee788719bc480f92d3e003991a195d67c0,[WIP]: some garbage messing with passing FDs,ABANDONED,2016-04-24 12:11:49.000000000,2016-05-05 23:20:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-24 12:11:49.000000000', 'files': ['neutron/agent/metadata/agent.py', 'myscript.sh', 'descriptor_passer.py', 'listen.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d36ad66b4cd4c6b249e0c24852bd8d503774f005', 'message': '[WIP]: some garbage messing with passing FDs\n\nChange-Id: Ie51d3dee788719bc480f92d3e003991a195d67c0\n'}]",0,309760,d36ad66b4cd4c6b249e0c24852bd8d503774f005,11,9,1,7787,,,0,"[WIP]: some garbage messing with passing FDs

Change-Id: Ie51d3dee788719bc480f92d3e003991a195d67c0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/309760/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/metadata/agent.py', 'myscript.sh', 'descriptor_passer.py', 'listen.py']",4,d36ad66b4cd4c6b249e0c24852bd8d503774f005,bug/1524916,"import socket import sys import os server_address = '/opt/stack/data/neutron/metadata_proxy_test' # Make sure the socket does not already exist try: os.unlink(server_address) except OSError: if os.path.exists(server_address): raise # Create a UDS socket sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) sock.bind(server_address) # Listen for incoming connections sock.listen(1) while True: # Wait for a connection connection, client_address = sock.accept() try: while True: data = connection.recv(1024) if data: print data else: break finally: # Clean up the connection connection.close() ",,107,1
openstack%2Fcinder~stable%2Fmitaka~I8c9484e436b6f0a2a5b7594c6f1c83441ddbd6db,openstack/cinder,stable/mitaka,I8c9484e436b6f0a2a5b7594c6f1c83441ddbd6db,http header value must be a string,ABANDONED,2016-05-05 23:01:16.000000000,2016-05-05 23:10:13.000000000,,"[{'_account_id': 7173}, {'_account_id': 14206}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-05-05 23:01:16.000000000', 'files': ['cinder/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/16b5b580114e02298bbdf6d48f7f2f8f977b722f', 'message': 'http header value must be a string\n\nChange the logic of how we encode the response headers to be\na utf-8 string for pre- and post python3.\n\nChange-Id: I8c9484e436b6f0a2a5b7594c6f1c83441ddbd6db\nCloses-Bug: #1550951\n(cherry picked from commit c20f335feee62328058a428803e84319a476600c)\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,313183,16b5b580114e02298bbdf6d48f7f2f8f977b722f,5,3,1,14288,,,0,"http header value must be a string

Change the logic of how we encode the response headers to be
a utf-8 string for pre- and post python3.

Change-Id: I8c9484e436b6f0a2a5b7594c6f1c83441ddbd6db
Closes-Bug: #1550951
(cherry picked from commit c20f335feee62328058a428803e84319a476600c)
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/83/313183/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/openstack/wsgi.py'],1,16b5b580114e02298bbdf6d48f7f2f8f977b722f,bug/1550951,"from oslo_utils import encodeutils if six.PY2: val = encodeutils.to_utf8(val) else: if isinstance(val, bytes): val = val.decode('utf-8') else: val = str(val) response.headers[hdr] = val", try: # python 2.x response.headers[hdr] = val.encode('utf-8') except Exception: # python 3.x response.headers[hdr] = six.text_type(val),10,6
openstack%2Fpuppet-neutron~master~If8bf8c2d183d6a849b92f0d277866769e5beafc3,openstack/puppet-neutron,master,If8bf8c2d183d6a849b92f0d277866769e5beafc3,Add oslo.messaging notitication related options,MERGED,2016-05-04 15:00:42.000000000,2016-05-05 23:05:25.000000000,2016-05-05 22:40:20.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8083}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-04 15:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f063d3437cba94cc73dc1b25c94c81c83074d6d4', 'message': 'Add oslo.messaging notitication related options\n\nAdd an ability to configure olso.messaging notification related options:\ndriver, transport_url and topics\n\nChange-Id: If8bf8c2d183d6a849b92f0d277866769e5beafc3\n'}, {'number': 2, 'created': '2016-05-04 15:11:20.000000000', 'files': ['spec/classes/neutron_init_spec.rb', 'releasenotes/notes/add_notification_opts-331f756075eaa50a.yaml', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/24e5df42ebbcf95262e5ed8ce9474731c7349925', 'message': 'Add oslo.messaging notitication related options\n\nAdd an ability to configure olso.messaging notification related options:\ndriver, transport_url and topics\n\nChange-Id: If8bf8c2d183d6a849b92f0d277866769e5beafc3\n'}]",0,312583,24e5df42ebbcf95262e5ed8ce9474731c7349925,25,5,2,7604,,,0,"Add oslo.messaging notitication related options

Add an ability to configure olso.messaging notification related options:
driver, transport_url and topics

Change-Id: If8bf8c2d183d6a849b92f0d277866769e5beafc3
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/83/312583/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_init_spec.rb', 'releasenotes/notes/add_notification_opts-331f756075eaa50a.yaml', 'manifests/init.pp']",3,f063d3437cba94cc73dc1b25c94c81c83074d6d4,notification_opts,"# [*notification_driver*] # (optional) Driver or drivers to handle sending notifications. # Value can be a string or a list. # Defaults to $::os_service_default. # # [*notification_topics*] # (optional) AMQP topic used for OpenStack notifications # Defaults to ::os_service_default # # [*transport_url*] # (optional) A URL representing the messaging driver to use for # notifications. # Defaults to $::os_service_default. # $notification_driver = $::os_service_default, $notification_topics = $::os_service_default, $transport_url = $::os_service_default, oslo::messaging::notifications { 'neutron_config': driver => $notification_driver, topics => $notification_topics, transport_url => $transport_url, } ",,47,0
openstack%2Fnetworking-ovn~master~Ib100e98caaee0747717f62479f56a9d7499df094,openstack/networking-ovn,master,Ib100e98caaee0747717f62479f56a9d7499df094,(WIP) start ovn worker in ovn plugin,ABANDONED,2016-05-05 07:48:16.000000000,2016-05-05 23:03:25.000000000,,"[{'_account_id': 3}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-05 07:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7d9c891817e3e380af3b57fdd49da3a3c3afa789', 'message': '(WIP) start ovn worker in ovn plugin\n\nPer 1cafff087194711399ad2a85a9f394f7204d7bdd, OvnWorker will not\nbe started. And this seems be the reason for recent Jenkins failure\nin gate-tempest-dsvm-networking-ovn.\n\nChange-Id: Ib100e98caaee0747717f62479f56a9d7499df094\n'}, {'number': 2, 'created': '2016-05-05 10:06:26.000000000', 'files': ['networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3a8fe435d9884b9e96df75e915986e3e6dde30c2', 'message': '(WIP) start ovn worker in ovn plugin\n\nPer 1cafff087194711399ad2a85a9f394f7204d7bdd, OvnWorker will not\nbe started. And this seems be the reason for recent Jenkins failure\nin gate-tempest-dsvm-networking-ovn.\n\nChange-Id: Ib100e98caaee0747717f62479f56a9d7499df094\n'}]",0,312850,3a8fe435d9884b9e96df75e915986e3e6dde30c2,8,2,2,13667,,,0,"(WIP) start ovn worker in ovn plugin

Per 1cafff087194711399ad2a85a9f394f7204d7bdd, OvnWorker will not
be started. And this seems be the reason for recent Jenkins failure
in gate-tempest-dsvm-networking-ovn.

Change-Id: Ib100e98caaee0747717f62479f56a9d7499df094
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/50/312850/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/plugin.py'],1,7d9c891817e3e380af3b57fdd49da3a3c3afa789,start_ovn_worker_in_ovn_plugin,"from oslo_service import service as common_servicefrom neutron import service plugin_workers_launcher = common_service.ProcessLauncher( cfg.CONF, wait_interval=1.0 ) workers = self.get_workers() service._start_workers(plugin_workers_launcher, workers)",,7,0
openstack%2Fnetworking-ovn~master~I1f847a20baf5b8381d460c827a373f850643a5cd,openstack/networking-ovn,master,I1f847a20baf5b8381d460c827a373f850643a5cd,Fix OVN plugin workers,ABANDONED,2016-05-05 18:21:43.000000000,2016-05-05 23:03:03.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-05 18:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/478d4155368e5dd17cb82fe772bc550938bfffb2', 'message': 'Fix OVN plugin workers\n\nThis patch set fixes the OVN plugin workers based on neutron\nworker refactoring [1]. The DCHP and L3 agent check workers\nare no longer started within the OVN worker which required\nrefactoring OVNPlugin initialization.\n\n[1] https://review.openstack.org/#/c/276842/\n\nChange-Id: I1f847a20baf5b8381d460c827a373f850643a5cd\nDepends-On: I2ee00cc11653816c1369076eb89bf52128ca2a0d\nCloses-Bug: #1578578\n'}, {'number': 2, 'created': '2016-05-05 20:15:48.000000000', 'files': ['networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/90f7de9b6a063f7c243a1b2429f74b36647dce1b', 'message': 'Fix OVN plugin workers\n\nThis patch set fixes the OVN plugin workers based on neutron\nworker refactoring [1]. The DCHP and L3 agent check workers\nare no longer started within the OVN worker which required\nrefactoring OVNPlugin initialization.\n\n[1] https://review.openstack.org/#/c/276842/\n\nChange-Id: I1f847a20baf5b8381d460c827a373f850643a5cd\nDepends-On: I2ee00cc11653816c1369076eb89bf52128ca2a0d\nCloses-Bug: #1578578\n'}]",0,313098,90f7de9b6a063f7c243a1b2429f74b36647dce1b,8,3,2,8410,,,0,"Fix OVN plugin workers

This patch set fixes the OVN plugin workers based on neutron
worker refactoring [1]. The DCHP and L3 agent check workers
are no longer started within the OVN worker which required
refactoring OVNPlugin initialization.

[1] https://review.openstack.org/#/c/276842/

Change-Id: I1f847a20baf5b8381d460c827a373f850643a5cd
Depends-On: I2ee00cc11653816c1369076eb89bf52128ca2a0d
Closes-Bug: #1578578
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/98/313098/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/plugin.py'],1,478d4155368e5dd17cb82fe772bc550938bfffb2,bug/1578578," self._setup_l3() # See doc/source/design/ovn_worker.rst for more details. self.add_worker(ovsdb_monitor.OvnWorker()) # Add periodic check worker to monitor the dhcp agents. # This worker requires access to an idl object (seflf._ovn) # since the DHCP agent scheduler calls port_update to # reschedule a network from a dead DHCP agent to an # active DHCP agent. This worker will be started # with the other OVN plugin workers. self.add_periodic_dhcp_agent_status_check() def _setup_l3(self): """"""Initialize components to support L3."""""" # Add periodic check worker for L3 agent. This worker # will be started with the other OVN plugin workers. if not config.is_ovn_l3(): self.add_periodic_l3_agent_status_check()", # start periodic check task to monitor the dhcp agents. # This task is created in the Ovn Worker and not in the parent # neutron process because # - dhcp agent scheduler calls port_update to reschedule a network # from a dead dhcp agent to active one and idl object # (self._ovn) is not created in the main neutron process plugin # object. # - Its created only in the worker processes. # - Ovn worker seems to be the right candidate. self.start_periodic_dhcp_agent_status_check() # start periodic check task for L3 agent if not config.is_ovn_l3(): self.start_periodic_l3_agent_status_check() def get_workers(self): # See doc/source/design/ovn_worker.rst for more details. return [ovsdb_monitor.OvnWorker()] ,17,19
openstack%2Fneutron~master~I2ee00cc11653816c1369076eb89bf52128ca2a0d,openstack/neutron,master,I2ee00cc11653816c1369076eb89bf52128ca2a0d,Start plugin workers,ABANDONED,2016-05-05 17:58:16.000000000,2016-05-05 23:02:23.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 8410}, {'_account_id': 10184}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-05-05 17:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9dfc19869e92779f50a519454aab97284d900238', 'message': 'Start plugin workers\n\nRecent neutron patch set [1] broke networking-ovn [2] because\nthe OVN plugin worker was not being started. This patch set\nstarts the plugin workers with the RPC workers.\n\n[1] https://review.openstack.org/#/c/276842/\n[2] https://bugs.launchpad.net/networking-ovn/+bug/1578578\n\nChange-Id: I2ee00cc11653816c1369076eb89bf52128ca2a0d\nRelated-Bug: #1569404\n'}, {'number': 2, 'created': '2016-05-05 18:00:28.000000000', 'files': ['neutron/server/wsgi_eventlet.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b431339d0dda435a2044613e263abe5bb4815a03', 'message': 'Start plugin workers\n\nRecent neutron patch set [1] broke networking-ovn [2] because\nthe OVN plugin worker was not being started. This patch set\nstarts the plugin workers with the RPC workers.\n\n[1] https://review.openstack.org/#/c/276842/\n[2] https://bugs.launchpad.net/networking-ovn/+bug/1578578\n\nChange-Id: I2ee00cc11653816c1369076eb89bf52128ca2a0d\nRelated-Bug: #1569404\nRelated-Bug: #1578578\n'}]",0,313088,b431339d0dda435a2044613e263abe5bb4815a03,16,7,2,8410,,,0,"Start plugin workers

Recent neutron patch set [1] broke networking-ovn [2] because
the OVN plugin worker was not being started. This patch set
starts the plugin workers with the RPC workers.

[1] https://review.openstack.org/#/c/276842/
[2] https://bugs.launchpad.net/networking-ovn/+bug/1578578

Change-Id: I2ee00cc11653816c1369076eb89bf52128ca2a0d
Related-Bug: #1569404
Related-Bug: #1578578
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/313088/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/server/wsgi_eventlet.py'],1,9dfc19869e92779f50a519454aab97284d900238,bug/1569404, service.start_plugin_workers(plugin_workers_launcher),,1,0
openstack%2Fheat~master~I1a73eed5f9b9fae608500d19be107db654750502,openstack/heat,master,I1a73eed5f9b9fae608500d19be107db654750502,Add Unicode support for stack names,ABANDONED,2014-12-25 01:55:18.000000000,2016-05-05 23:00:48.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 5706}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 14455}]","[{'number': 1, 'created': '2014-12-25 01:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e2ab20179b2031513753fc1c469339a1ae22d65', 'message': ""Add Unicode support for stack names\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some client side patches that will be committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nNote that if you are using devstack screen environment, you need to add\na '-U' argument to you screen session so that log messages will show up\ncorrectly.\n\npartial-bug: 1270761\npartial-bug: 1249234\n\nChange-Id: I1a73eed5f9b9fae608500d19be107db654750502\n""}, {'number': 2, 'created': '2014-12-25 06:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cdea99494f8e7d5e06e0ff9bbd197f112d7d2b8b', 'message': ""Add Unicode support for stack names\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some client side patches that will be committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nNote that if you are using devstack screen environment, you need to add\na '-U' argument to you screen session so that log messages will show up\ncorrectly.\n\npartial-bug: 1270761\npartial-bug: 1249234\n\nChange-Id: I1a73eed5f9b9fae608500d19be107db654750502\n""}, {'number': 3, 'created': '2014-12-25 06:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d1d46c5b0f8a85b0675c84347bf89612cad8fd05', 'message': ""Add Unicode support for stack names\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some client side patches that will be committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nNote that if you are using devstack screen environment, you need to add\na '-U' argument to you screen session so that log messages will show up\ncorrectly.\n\npartial-bug: 1270761\npartial-bug: 1249234\n\nChange-Id: I1a73eed5f9b9fae608500d19be107db654750502\n""}, {'number': 4, 'created': '2014-12-26 03:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6d7311c3d345dfc3ede9389d552c7d5ee63f4782', 'message': ""Add Unicode support for stack names\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some client side patches that will be committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nNote that if you are using devstack screen environment, you need to add\na '-U' argument to you screen session so that log messages will show up\ncorrectly.\n\npartial-bug: 1270761\npartial-bug: 1249234\n\nChange-Id: I1a73eed5f9b9fae608500d19be107db654750502\n""}, {'number': 5, 'created': '2014-12-29 01:48:24.000000000', 'files': ['heat/tests/test_parser.py', 'heat/common/identifier.py', 'heat/engine/stack.py', 'heat/tests/test_identifier.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/016df03aa0caaf2199b868727389d5ccdfcf6844', 'message': ""Add Unicode support for stack names\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some client side patches that will be committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nNote that if you are using devstack screen environment, you need to add\na '-U' argument to you screen session so that log messages will show up\ncorrectly.\n\npartial-bug: 1270761\npartial-bug: 1249234\n\nChange-Id: I1a73eed5f9b9fae608500d19be107db654750502\n""}]",4,143915,016df03aa0caaf2199b868727389d5ccdfcf6844,23,7,5,8246,,,0,"Add Unicode support for stack names

This patch adds support to stack names with Unicode characters. The
whole solution includes some client side patches that will be committed
as well. Tested using Chinese stack names and it seems work fine.

Note that if you are using devstack screen environment, you need to add
a '-U' argument to you screen session so that log messages will show up
correctly.

partial-bug: 1270761
partial-bug: 1249234

Change-Id: I1a73eed5f9b9fae608500d19be107db654750502
",git fetch https://review.opendev.org/openstack/heat refs/changes/15/143915/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parser.py', 'heat/common/identifier.py', 'heat/engine/stack.py', 'heat/tests/test_identifier.py']",4,3e2ab20179b2031513753fc1c469339a1ae22d65,bug/1270761," def test_stack_path(self): hi = identifier.HeatIdentifier('t', '\xe5\xeb\xc3\xd7', 'i', 'p') self.assertEqual('%E5%EB%C3%D7/i', hi.stack_path()) ",,21,13
openstack%2Fpython-heatclient~master~I60db4c613287c5f772c253fae48d38c69a684015,openstack/python-heatclient,master,I60db4c613287c5f772c253fae48d38c69a684015,Enable Unicode support to stack names,ABANDONED,2014-12-25 06:34:16.000000000,2016-05-05 23:00:23.000000000,,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-12-25 06:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7da93f47693e7ac40cb9aae3597168550687e02b', 'message': 'Enable Unicode support to stack names\n\nThe client side fix for https://review.openstack.org/#/c/143915/.\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some server side patches that was committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nCloses-bug: 1270761\nCloses-bug: 1249234\n\nChange-Id: I60db4c613287c5f772c253fae48d38c69a684015\n'}, {'number': 2, 'created': '2014-12-25 11:19:26.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/tests/fakes.py', 'heatclient/v1/stacks.py', 'heatclient/exc.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/71dc9fdd32e5d89e8d1fe935c2e3699def2d10f8', 'message': 'Enable Unicode support to stack names\n\nThe client side fix for https://review.openstack.org/#/c/143915/.\n\nThis patch adds support to stack names with Unicode characters. The\nwhole solution includes some server side patches that was committed\nas well. Tested using Chinese stack names and it seems work fine.\n\nCloses-bug: 1270761\nCloses-bug: 1249234\n\nChange-Id: I60db4c613287c5f772c253fae48d38c69a684015\n'}]",0,143936,71dc9fdd32e5d89e8d1fe935c2e3699def2d10f8,6,2,2,8246,,,0,"Enable Unicode support to stack names

The client side fix for https://review.openstack.org/#/c/143915/.

This patch adds support to stack names with Unicode characters. The
whole solution includes some server side patches that was committed
as well. Tested using Chinese stack names and it seems work fine.

Closes-bug: 1270761
Closes-bug: 1249234

Change-Id: I60db4c613287c5f772c253fae48d38c69a684015
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/36/143936/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/tests/fakes.py', 'heatclient/v1/stacks.py', 'heatclient/exc.py', 'heatclient/v1/shell.py']",5,7da93f47693e7ac40cb9aae3597168550687e02b,bug/1270761,"from oslo.utils import encodeutils print(six.text_type(e)) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) else: result = encodeutils.safe_decode(jsonutils.dumps(stack, indent=2)) raise exc.CommandError(six.text_type(err)) decode_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decode_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) {'id': decoded_id, 'resource': args.resource}) decoded_id = encodeutils.safe_decode(args.id) {'id': decoded_id, 'resource': args.resource}) decoded_id = encodeutils.safe_decode(args.id) {'id': decoded_id, 'resource': args.resource}) raise exc.CommandError(six.text_type(ex)) raise exc.CommandError(six.text_type(ex)) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id) decoded_id = encodeutils.safe_decode(args.id) raise exc.CommandError(_('Stack not found: %s') % decoded_id)"," print(e) raise exc.CommandError(_('Stack not found: %s') % args.id) else: result = jsonutils.dumps(stack, indent=2) raise exc.CommandError(str(err)) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id) {'id': args.id, 'resource': args.resource}) {'id': args.id, 'resource': args.resource}) {'id': args.id, 'resource': args.resource}) raise exc.CommandError(str(ex)) raise exc.CommandError(str(ex)) raise exc.CommandError(_('Stack not found: %s') % args.id) raise exc.CommandError(_('Stack not found: %s') % args.id)",106,53
openstack%2Fpython-heatclient~master~Icda66ff5abafe3492c19494af30946c610375171,openstack/python-heatclient,master,Icda66ff5abafe3492c19494af30946c610375171,List resource_types with support status and version,ABANDONED,2015-01-16 06:51:02.000000000,2016-05-05 22:59:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 6698}, {'_account_id': 8246}, {'_account_id': 10215}]","[{'number': 1, 'created': '2015-01-16 06:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/27d96ff0885eb49b04ca15181ac515ec99bf6f2f', 'message': ""List resource_types with support status\n\nThis is a client-side patch corresponding to the server side patch that\naddes 'support_status' to the resource_type list response, here:\n\nhttps://review.openstack.org/#/c/147761/\n\nPlease don't workflow +1 before the server side is accepted.\n\nChange-Id: Icda66ff5abafe3492c19494af30946c610375171\n""}, {'number': 2, 'created': '2015-01-18 12:41:06.000000000', 'files': ['heatclient/v1/resource_types.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e34cb67b2cdd5c43eb6c68697d3f03656aa414df', 'message': ""List resource_types with support status and version\n\nThis is a client-side patch corresponding to the server side patch\nthat adds 'support_status' and 'since' version to the resource_type\nlist response, here:\n\nhttps://review.openstack.org/#/c/147761/\n\nPlease don't workflow +1 before the server side is accepted.\n\nChange-Id: Icda66ff5abafe3492c19494af30946c610375171\n""}]",2,147763,e34cb67b2cdd5c43eb6c68697d3f03656aa414df,12,5,2,8246,,,0,"List resource_types with support status and version

This is a client-side patch corresponding to the server side patch
that adds 'support_status' and 'since' version to the resource_type
list response, here:

https://review.openstack.org/#/c/147761/

Please don't workflow +1 before the server side is accepted.

Change-Id: Icda66ff5abafe3492c19494af30946c610375171
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/63/147763/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/v1/resource_types.py', 'heatclient/v1/shell.py']",2,27d96ff0885eb49b04ca15181ac515ec99bf6f2f,rt-with-status," fields = ['name', 'support_status'] fmt = lambda x: '' if x.support_status == 'SUPPORTED' else x.support_status formatters = { 'support_status': fmt, } utils.print_list(types, fields, sortby_index=0, formatters=formatters)"," utils.print_list(types, ['resource_type'], sortby_index=0)",7,4
openstack%2Fheat~master~I64a1156ee3ce6a4d05007b39082e5033cf26f025,openstack/heat,master,I64a1156ee3ce6a4d05007b39082e5033cf26f025,Return support_status in resource type list,ABANDONED,2015-01-16 06:32:35.000000000,2016-05-05 22:59:40.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8246}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 13009}, {'_account_id': 13134}]","[{'number': 1, 'created': '2015-01-16 06:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3a1029857dbb385fea22f4e65bc2c421834115f9', 'message': 'Always return support_status in res type lists\n\nThis patch makes heat engine always return support_status when listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status, not matter\nfiltered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 2, 'created': '2015-01-16 08:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/923f5907590e82de7cd9af0a43dd70d2f966ac51', 'message': 'Always return support_status in res type lists\n\nThis patch makes heat engine always return support_status when listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status, not matter\nfiltered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 3, 'created': '2015-01-16 11:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/75b7896fa29e276cbb05f212f9efb5b5a7fe05d3', 'message': 'Always return support_status in res type lists\n\nThis patch makes heat engine always return support_status when listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status, not matter\nfiltered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 4, 'created': '2015-01-16 15:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ead834a032f9b9b1aca70c2b04695f444620253c', 'message': 'Always return support_status in res type lists\n\nThis patch makes heat engine always return support_status when listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status, not matter\nfiltered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 5, 'created': '2015-01-18 12:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2081164434afeecdf224454ac9bf9b08e54bb8be', 'message': 'Return support_status and version in res type list\n\nThis patch makes heat engine always return support_status and the\ninitial release version when the resource type was supported in listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status and version, not\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 6, 'created': '2015-01-18 14:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bf9a04a6abd8b8e5e447afe1cef9bdefc5812bf5', 'message': 'Return support_status and version in res type list\n\nThis patch makes heat engine always return support_status and the\ninitial release version when the resource type was supported in listing\nresource types. It comes with a client-side patch that will enable a\nlist of resource types to be shown with support_status and version, not\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 7, 'created': '2015-07-13 09:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/27375e6651d7cd7820e55581c0142e0ff53e1fed', 'message': 'WIP: Return support_status and version in res type list\n\nThis patch makes heat engine always return support_status of a resource\ntype. It comes with a client-side patch that will enable a list of\nresource types to be shown with support_status and version, no\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 8, 'created': '2015-07-13 09:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/71bb9ece36357945e381eca58c499e8745c4f581', 'message': 'WIP: Return support_status in resource type list\n\nThis patch makes heat engine always return support_status of a resource\ntype. It comes with a client-side patch that will enable a list of\nresource types to be shown with support_status and version, no\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 9, 'created': '2015-07-13 12:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9aab8574b5608c09d1a1b322ed48eff6a28766e3', 'message': 'WIP: Return support_status in resource type list\n\nThis patch makes heat engine always return support_status of a resource\ntype. It comes with a client-side patch that will enable a list of\nresource types to be shown with support_status and version, no\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}, {'number': 10, 'created': '2015-07-14 05:12:23.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/test_environment.py', 'heat/rpc/client.py', 'heat/engine/environment.py', 'heat/tests/engine/test_service_engine.py', 'heat/tests/api/openstack_v1/test_api_openstack_v1.py', 'doc/source/ext/resources.py', 'heat/engine/service.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bf2b2aa50281199ff4c12ef26507d35a363b0c04', 'message': 'Return support_status in resource type list\n\nThis patch makes heat engine always return support_status of a resource\ntype. It comes with a client-side patch that will enable a list of\nresource types to be shown with support_status and version, no\nmatter filtered or not.\n\nChange-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025\n'}]",0,147761,bf2b2aa50281199ff4c12ef26507d35a363b0c04,53,9,10,8246,,,0,"Return support_status in resource type list

This patch makes heat engine always return support_status of a resource
type. It comes with a client-side patch that will enable a list of
resource types to be shown with support_status and version, no
matter filtered or not.

Change-Id: I64a1156ee3ce6a4d05007b39082e5033cf26f025
",git fetch https://review.opendev.org/openstack/heat refs/changes/61/147761/7 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/test_environment.py', 'heat/engine/environment.py', 'heat/tests/test_api_openstack_v1.py']",4,3a1029857dbb385fea22f4e65bc2c421834115f9,rt-with-status," engine_response = [{'name': 'AWS::EC2::Instance', 'support_status': 'SUPPORTED'}, {'name': 'AWS::EC2::EIP', 'support_status': 'DEPRECATED'}, {'name': 'AWS::EC2::EIPAssociation', 'support_status': 'SUPPORTED'}]"," engine_response = ['AWS::EC2::Instance', 'AWS::EC2::EIP', 'AWS::EC2::EIPAssociation']",51,17
openstack%2Fkolla-kubernetes~master~I3ea82c1aabe64294e70b5af6ae0f1f21f23d9889,openstack/kolla-kubernetes,master,I3ea82c1aabe64294e70b5af6ae0f1f21f23d9889,Support for release notes,MERGED,2016-05-05 18:05:37.000000000,2016-05-05 22:55:53.000000000,2016-05-05 22:55:53.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2016-05-05 18:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/aaf135b98f3e0efdea0a345ba45c36a54077fe36', 'message': 'Support for release notes\n\nChange-Id: I3ea82c1aabe64294e70b5af6ae0f1f21f23d9889\n'}, {'number': 2, 'created': '2016-05-05 18:22:42.000000000', 'files': ['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', 'kolla_kubernetes/version.py', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/2100868fab8be50ffcddbcbf2a50de3d14d5d5e2', 'message': 'Support for release notes\n\nChange-Id: I3ea82c1aabe64294e70b5af6ae0f1f21f23d9889\n'}]",0,313090,2100868fab8be50ffcddbcbf2a50de3d14d5d5e2,9,3,2,5638,,,0,"Support for release notes

Change-Id: I3ea82c1aabe64294e70b5af6ae0f1f21f23d9889
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/90/313090/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py']",8,aaf135b98f3e0efdea0a345ba45c36a54077fe36,,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import os import sys from kolla.version import version_info as kolla_version sys.path.insert(0, os.path.abspath('../..')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'oslosphinx', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'Kolla Release Notes' copyright = u'2015, Kolla developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. version = kolla_version.canonical_version_string() # The full version, including alpha/beta/rc tags. release = kolla_version.version_string_with_vcs() # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'default' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. # html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'KollaReleaseNotesdoc' # -- Options for LaTeX output --------------------------------------------- # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'KollaReleaseNotes.tex', u'Kolla Release Notes Documentation', u'Kolla developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'kollareleasenotes', u'Kolla Release Notes Documentation', [u'Kolla developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'KollaReleaseNotes', u'Kolla Release Notes Documentation', u'Kolla developers', 'KollaReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False ",,279,0
openstack%2Fhorizon~master~I86868cd51e4d48206f8436957721c0aa5179a1eb,openstack/horizon,master,I86868cd51e4d48206f8436957721c0aa5179a1eb,Fix themable checkbox error state,MERGED,2016-03-14 19:29:43.000000000,2016-05-05 22:44:12.000000000,2016-05-05 22:44:11.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9622}, {'_account_id': 11778}, {'_account_id': 12071}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-03-14 19:29:43.000000000', 'files': ['horizon/templates/horizon/common/fields/_themable_checkbox.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7f550c511a29f75f93dd9a0aa8f7b6934c65e6c7', 'message': 'Fix themable checkbox error state\n\nThemable checkboxes are not using bootstrap form states correctly.\nWhen has-error is applied the label is not showing the error state.\n\nChange-Id: I86868cd51e4d48206f8436957721c0aa5179a1eb\nCloses-bug: #1557137\n'}]",0,292562,7f550c511a29f75f93dd9a0aa8f7b6934c65e6c7,7,6,1,9048,,,0,"Fix themable checkbox error state

Themable checkboxes are not using bootstrap form states correctly.
When has-error is applied the label is not showing the error state.

Change-Id: I86868cd51e4d48206f8436957721c0aa5179a1eb
Closes-bug: #1557137
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/292562/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/fields/_themable_checkbox.html'],1,7f550c511a29f75f93dd9a0aa8f7b6934c65e6c7,bug/1557137," <span class=""control-label"">{{ field.label }}</span>", <span>{{ field.label }}</span>,1,1
openstack%2Fneutron~master~Ibf6d07c96986f68a3c0730d37325bdc8d8e10407,openstack/neutron,master,Ibf6d07c96986f68a3c0730d37325bdc8d8e10407,Fail validate_string when the attribute contains illegal characters,ABANDONED,2016-04-14 11:01:54.000000000,2016-05-05 22:43:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20363}]","[{'number': 1, 'created': '2016-04-14 11:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a11d44833fc6c79e178438e7c0bcf84fee1252b3', 'message': 'Fail validate_string when the attribute contains illegal characters\n\nPrevent Cross-Site scripting and terminal controllers in the neutron\nstring attributes, using a regular expression in the _validate_string\nmethod to fail the command\n\nChange-Id: Ibf6d07c96986f68a3c0730d37325bdc8d8e10407\nCloses-Bug: #1486565\n'}, {'number': 2, 'created': '2016-04-14 11:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e2f2b7b3211d8342a25da05da19c2da430cbd5e', 'message': 'Fail validate_string when the attribute contains illegal characters\n\nPrevent Cross-Site scripting and terminal controllers in the neutron\nstring attributes, using a regular expression in the _validate_string\nmethod to fail the command\n\nChange-Id: Ibf6d07c96986f68a3c0730d37325bdc8d8e10407\nCloses-Bug: #1486565\n'}, {'number': 3, 'created': '2016-04-17 05:35:10.000000000', 'files': ['neutron/api/v2/attributes.py', 'neutron/tests/unit/api/v2/test_attributes.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/09d28a54b649fe85bbdb4e986284863c15c02bee', 'message': 'Fail validate_string when the attribute contains illegal characters\n\nPrevent Cross-Site scripting and terminal controllers in the neutron\nstring attributes, using a regular expression in the _validate_string\nmethod to fail the command\n\nChange-Id: Ibf6d07c96986f68a3c0730d37325bdc8d8e10407\nPartial-Bug: #1486565\n'}]",2,305756,09d28a54b649fe85bbdb4e986284863c15c02bee,38,11,3,20363,,,0,"Fail validate_string when the attribute contains illegal characters

Prevent Cross-Site scripting and terminal controllers in the neutron
string attributes, using a regular expression in the _validate_string
method to fail the command

Change-Id: Ibf6d07c96986f68a3c0730d37325bdc8d8e10407
Partial-Bug: #1486565
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/305756/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/v2/attributes.py', 'neutron/tests/unit/api/v2/test_attributes.py']",2,a11d44833fc6c79e178438e7c0bcf84fee1252b3,," # illegal cross site scripting characters msg = attributes._validate_string(""<script>alert()</script>"", None) self.assertEqual( ""'<script>alert()</script>' contains illegal characters"", msg) # illegal terminal control scripting characters msg = attributes._validate_string(""\E[37mhidden\x1b[f&"", None) self.assertEqual( ""'\E[37mhidden\x1b[f&' contains illegal characters"", msg) ",,23,0
openstack%2Fpuppet-openstack-integration~master~I0ff6c89299a353ff5eb842522c2e94a58c0e9cdc,openstack/puppet-openstack-integration,master,I0ff6c89299a353ff5eb842522c2e94a58c0e9cdc,cinder: deploy cinderv3 on ipv6/ssl,MERGED,2016-05-04 17:33:36.000000000,2016-05-05 22:31:06.000000000,2016-05-05 22:31:06.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-04 17:33:36.000000000', 'files': ['manifests/cinder.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/57ca8964b1a09f0710cf18eb7c8c98062b5d35f9', 'message': 'cinder: deploy cinderv3 on ipv6/ssl\n\nAdd missing endpoints for deploying all Cinder services in IPv6 & SSL.\n\nChange-Id: I0ff6c89299a353ff5eb842522c2e94a58c0e9cdc\n'}]",0,312652,57ca8964b1a09f0710cf18eb7c8c98062b5d35f9,9,3,1,3153,,,0,"cinder: deploy cinderv3 on ipv6/ssl

Add missing endpoints for deploying all Cinder services in IPv6 & SSL.

Change-Id: I0ff6c89299a353ff5eb842522c2e94a58c0e9cdc
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/52/312652/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/cinder.pp'],1,57ca8964b1a09f0710cf18eb7c8c98062b5d35f9,cinder/v3/https," public_url_v3 => ""${::openstack_integration::config::base_url}:8776/v3/%(tenant_id)s"", internal_url_v3 => ""${::openstack_integration::config::base_url}:8776/v3/%(tenant_id)s"", admin_url_v3 => ""${::openstack_integration::config::base_url}:8776/v3/%(tenant_id)s"",",,3,0
openstack%2Fpuppet-nova~master~I3416ae594e972e40ff0336779258a887987e46b1,openstack/puppet-nova,master,I3416ae594e972e40ff0336779258a887987e46b1,Fix default keystone auth_plugin for nova/neutron,MERGED,2016-05-04 01:52:08.000000000,2016-05-05 22:23:53.000000000,2016-05-05 22:23:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7604}, {'_account_id': 9500}, {'_account_id': 10873}, {'_account_id': 14007}]","[{'number': 1, 'created': '2016-05-04 01:52:08.000000000', 'files': ['spec/classes/nova_network_neutron_spec.rb', 'manifests/network/neutron.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/271a2587a38c6a396213c95aaa8a690fcc283091', 'message': ""Fix default keystone auth_plugin for nova/neutron\n\nThe 'password' plugin in keystoneauth is actually smart enough to\ndiscover which endpoint it should be using, defaulting to Identity V3.\nIf 'v3password' is used, the URL must have a version already encoded in\nit[1]. With just 'password', it will discover the right version by\nhitting the '/' endpoint [2]. So we should just use the 'password'\nplugin, which will let users use either unversioned or versioned\nendpoints as they wish.\n\nThis should be backwards compatible, as the 'password' plugin will use\nthe v3 endpoint when users have specified 'v3' in the URL.\n\n[1] https://bugs.launchpad.net/keystoneauth/+bug/1489927\n[2] http://paste.openstack.org/show/494119/\n\nChange-Id: I3416ae594e972e40ff0336779258a887987e46b1\n""}]",0,312300,271a2587a38c6a396213c95aaa8a690fcc283091,16,6,1,8482,,,0,"Fix default keystone auth_plugin for nova/neutron

The 'password' plugin in keystoneauth is actually smart enough to
discover which endpoint it should be using, defaulting to Identity V3.
If 'v3password' is used, the URL must have a version already encoded in
it[1]. With just 'password', it will discover the right version by
hitting the '/' endpoint [2]. So we should just use the 'password'
plugin, which will let users use either unversioned or versioned
endpoints as they wish.

This should be backwards compatible, as the 'password' plugin will use
the v3 endpoint when users have specified 'v3' in the URL.

[1] https://bugs.launchpad.net/keystoneauth/+bug/1489927
[2] http://paste.openstack.org/show/494119/

Change-Id: I3416ae594e972e40ff0336779258a887987e46b1
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/00/312300/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_network_neutron_spec.rb', 'manifests/network/neutron.pp']",2,271a2587a38c6a396213c95aaa8a690fcc283091,neutron_auth_plugin,"# Defaults to 'password' $neutron_auth_type = 'password',","# Defaults to 'v3password' $neutron_auth_type = 'v3password',",3,3
openstack%2Fopenstack-ansible~master~Id87fab39c929e0860abbc3755ad386aa6893b151,openstack/openstack-ansible,master,Id87fab39c929e0860abbc3755ad386aa6893b151,Enable SSL termination for all services,MERGED,2016-02-07 20:40:27.000000000,2016-05-05 22:23:12.000000000,2016-05-05 22:23:12.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 4268}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12402}, {'_account_id': 14805}, {'_account_id': 15993}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 19814}, {'_account_id': 20705}]","[{'number': 1, 'created': '2016-02-07 20:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9724704180dd3c6ad42d3b89f345855f5b0fef0c', 'message': '[WIP] Enable SSL terminiation for all services\n\nThis change makes it so that all services are expecting SSL terminiation\nby default. This is more indicitive of how a real world deployment will\nbe setup and is being added such that we can test a more production like\ndeployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-02-12 17:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f125871a89ac55541e207be20ea0f9714f42ea12', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2016-02-12 18:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9b10eb8d2b208f00724bccd1815c7931019441ec', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2016-02-16 15:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6aead60f517d4fd50e2ede6833b946a00a8735ed', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2016-02-16 19:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6ae8370032ffbb64e0e0a519ace28882f22ea0b6', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2016-02-18 21:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/43bb08e76e655273d70f1b222cfa643fddc28b2b', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2016-02-19 03:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9583a322d82fe88646ba5b707987e7c217603834', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2016-02-19 03:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a1e352c6c431cf4f68d695e7adfba81cce3e1645', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2016-03-01 19:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/eaf43d36ae80acb442d67ec9bc4c635ec481c08b', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2016-03-03 17:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/60952b514bc847bbd264e311737661831be86417', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2016-03-04 20:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/572745850656a0af57c8c1b9836857200b80b26a', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 12, 'created': '2016-03-07 18:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d3d3f5746564aa37dbd9a5b9a8245c72e03d96aa', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 13, 'created': '2016-03-08 04:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d2d130a56b1ff37aad828e9cda30b21553054f16', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 14, 'created': '2016-03-11 01:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bbce2ddff9d3815a4e88135e0534fa801f4c1c3c', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 15, 'created': '2016-03-17 13:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dcc4d10e42766ce1a8754734264f9269ced195f5', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 16, 'created': '2016-03-18 20:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8198f7f65296fc451f35ebcbc0d4c677713a8585', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 17, 'created': '2016-03-29 03:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1ad122117e894e62d833d7cedc2c87b4e8ad028f', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 18, 'created': '2016-03-29 15:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5d987d9d25e28eef1713f8e59d7397ca3e817932', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 19, 'created': '2016-04-04 14:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0d33d31de359c67765a7189c2a713f3ef86097a2', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 20, 'created': '2016-04-11 23:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/323bd03e929d9e62509a14e705b50551f1473955', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 21, 'created': '2016-04-12 00:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cb9ed9392fdb5ce817b70ffe49352684673c6b9d', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 22, 'created': '2016-04-15 00:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/da53328d599f7304bbe8e0f0296776bd91d4c33b', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 23, 'created': '2016-04-15 06:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2820727c47639d17118112564ec1010e956c7a10', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 24, 'created': '2016-04-15 06:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c63235fe166da9396ad18cbe8dcf326dea50efe6', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 25, 'created': '2016-04-15 06:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0d293c472602bfa70504166a3d527d5891f84067', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 26, 'created': '2016-04-15 07:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/67017d9f55f210403cade5494b07a53d9bc24dce', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 27, 'created': '2016-04-15 15:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3234a05d5072ae02a25d32a017b64ff8e500a72c', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I913b4140e258b56d56f5323d55fd633288b3ef6a\nDepends-On: I6273ffa453b4e5eb8a33767974d390a126296c47\nDepends-On: I33183e48407731c1d9684129fef20cea59f5dde8\nDepends-On: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nDepends-On: Ifde735a35af50befe12d9d17ba768e61c67eecf9\nDepends-On: Ib600b5693e7723a568a1abff3e563a7847851316\nDepends-On: Ibbeca3325947b549ae00d11e60bf719741b4b0e4\nDepends-On: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nDepends-On: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 28, 'created': '2016-04-18 16:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/551cb3a804599ab75308dedd1b22c9dab9d9b3ed', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 29, 'created': '2016-04-18 16:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/971fd35c66fefc29ec4a671e3a2b75335b9cd463', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 30, 'created': '2016-04-19 14:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/afd3eb823364cdef9f87d5b42b0368e658970030', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 31, 'created': '2016-04-19 21:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/15794c336759878c0f0fc3cbf1bfd85ad3195985', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 32, 'created': '2016-04-20 19:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d8b8a2f6f46c6dc007a83ee9a67453b9c8168b9b', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 33, 'created': '2016-04-22 16:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e1bbb2dd6b9fdc552e446f100388f9a04c4b95a1', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 34, 'created': '2016-04-23 15:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bdb690bfef457dd8e2fb7937de1f9b3f35b6c6f8', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 35, 'created': '2016-04-23 23:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7eb47c08a00c34bd6483d24c835ff1c681ec1224', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 36, 'created': '2016-04-24 05:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/36463c402e625a3197af0a11ae93a4b12ce0d843', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 37, 'created': '2016-04-27 08:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0677714fa8907c245232a5edd85358ff555944b', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 38, 'created': '2016-04-27 18:36:07.000000000', 'files': ['releasenotes/notes/haproxy_ssl_terminiation-cdf0092a5bfa34b5.yaml', 'playbooks/vars/configs/haproxy_config.yml', 'playbooks/roles/haproxy_server/tasks/haproxy_service_config.yml', 'doc/source/install-guide/configure-haproxy.rst', 'playbooks/roles/haproxy_server/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/haproxy-install.yml', 'playbooks/roles/haproxy_server/templates/service.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/92eb98e1d2f367609640f9207b30038565a22339', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nDepends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1\nDepends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00\nDepends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6\nDepends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859\nChange-Id: Id87fab39c929e0860abbc3755ad386aa6893b151\nCo-Authored-By: Logan V <logan2211@gmail.com>\nSigned-off-by: Logan V <logan2211@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",87,277199,92eb98e1d2f367609640f9207b30038565a22339,136,12,38,7353,,,0,"Enable SSL termination for all services

This change makes it so that all services are expecting SSL termination
at the load balancer by default. This is more indicative of how a real
world deployment will be setup and is being added such that we can test
a more production like deployment system by default.

The AIO will now terminate SSL in HAProxy using a self-signed cert.

Depends-On: I63cfecd6793ba2b28c294d939c9b1c466940cbd1
Depends-On: Iba63636d733fa1eb095564b8bf33a8159d9c2a00
Depends-On: Ib31a48dd480ecb376a6a8c5b35b09dfa5d2e58f6
Depends-On: Ibdeb8b981ca770ce4f56beeae05afd3379964859
Change-Id: Id87fab39c929e0860abbc3755ad386aa6893b151
Co-Authored-By: Logan V <logan2211@gmail.com>
Signed-off-by: Logan V <logan2211@gmail.com>
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/99/277199/8 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_nova/templates/nova.conf.j2', 'playbooks/roles/os_horizon/defaults/main.yml', 'playbooks/roles/os_keystone/templates/keystone.conf.j2', 'playbooks/roles/haproxy_server/defaults/main.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_keystone/defaults/main.yml', 'playbooks/roles/os_heat/templates/heat.conf.j2']",9,9724704180dd3c6ad42d3b89f345855f5b0fef0c,reimpl-ssl-all,{% if heat_ssl_external | bool %} secure_proxy_ssl_header = {{ heat_secure_proxy_ssl_header }} {% endif %},,29,7
openstack%2Fsearchlight-specs~master~I420ad464af283570da14e9358d098de74dbd6b13,openstack/searchlight-specs,master,I420ad464af283570da14e9358d098de74dbd6b13,Cross-region search spec,MERGED,2016-04-04 16:37:29.000000000,2016-05-05 22:21:42.000000000,2016-05-05 22:21:42.000000000,"[{'_account_id': 3}, {'_account_id': 5314}, {'_account_id': 7179}, {'_account_id': 7665}, {'_account_id': 10063}]","[{'number': 1, 'created': '2016-04-04 16:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/693a81d52adc54096b9aa5ebce718ade6e4b1e57', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 2, 'created': '2016-04-05 19:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/e35e5be856f6e4ed59e6442c49c9052194835979', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 3, 'created': '2016-04-05 19:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/e2b82e6a482db0107ec2898074273b8e762b2240', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 4, 'created': '2016-04-05 20:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/65b59f55d24278827d285d9a7fff5be1e35af7e6', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 5, 'created': '2016-04-07 00:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/fbb9b9aa6c0a76f97b3985c6a72080b1c36c9b1d', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 6, 'created': '2016-04-08 19:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/3305560d1ad2cb986f5285775816e28056cc4e73', 'message': 'WIP Cross-region search spec\n\nAt this point, this is a request for discussion rather than a full spec,\nso marking WIP for now.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n'}, {'number': 7, 'created': '2016-05-02 15:23:24.000000000', 'files': ['specs/newton/cross-region-search.rst'], 'web_link': 'https://opendev.org/openstack/searchlight-specs/commit/494dc23a83342f2a01d2d7057ac44235fb962ee6', 'message': ""Cross-region search spec\n\nCross-region search spec, following discussion at summit. Decision was\nto document the 'tribe' deployment method and add region-name to\nmappings but not to commit to making this the default for Newton.\n\nChange-Id: I420ad464af283570da14e9358d098de74dbd6b13\n""}]",52,301227,494dc23a83342f2a01d2d7057ac44235fb962ee6,36,5,7,10063,,,0,"Cross-region search spec

Cross-region search spec, following discussion at summit. Decision was
to document the 'tribe' deployment method and add region-name to
mappings but not to commit to making this the default for Newton.

Change-Id: I420ad464af283570da14e9358d098de74dbd6b13
",git fetch https://review.opendev.org/openstack/searchlight-specs refs/changes/27/301227/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/cross-region-search.rst'],1,693a81d52adc54096b9aa5ebce718ade6e4b1e57,cross-region-search,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================== Cross-Region Search =================== SearchLight currently is targeted at being deployed alongside nova, glance, cinder etc. as part of an Openstack control plane. There has been a lot of interest in allowing SearchLight to index and search resources across Openstack regions. Problem Description =================== A typical production Openstack deployment can provide scaling_ and resilience in several ways, some of which apply to all services and some specific to services that support a feature. **Availability zones** provide some ability to distribute resources (VMs, networks) across multiple machines that might, for instance be in separate racks with separate power supplies. AZs are represented in resource data and are already part of the indexing that SearchLight does. **Regions** can provide separation across geographical locations (different data centers, for instance). The only requirement to run multiple regions within a single Openstack deployment is that Keystone is configured to share data across the regions (with master-master database replication, for instance). All other services are isolated from one another, but Keystone is able to provide the URLs for, say, the ``nova-api`` deployments in each region. Typically a Keystone token will only allow operations on the region for which it was granted. **Multiple clouds** provide total isolation. Horizon supports this (though confusingly also refers to it as 'Region') this each cloud is totally separate with no knowledge of the other. In both the second and third options, the ability to search aggregated data can provide value. Referring to **region** separation: since a Nova deployments in a fictional Region-A is unaware of resources in a fictional Region-B, a user must make requests to each region to get information. This makes Horizon somewhat cumbersome (changing region triggers reloading pages to change the context, although authentication status is preserved). .. _scaling: http://docs.openstack.org/openstack-ops/content/scaling.html Proposed Change =============== These are the potential deployment options for multi-region clouds. For the sake of clarity, our cloud is divided into two regions, Region-APAC with a data-center in Australia and Region-EMEA with a datacenter in Germany. 1. Deploy Searchlight in the same fashion as Keystone. API endpoints can exist in both regions. Data will be duplicated between regions (by some external process - Elasticsearch explicitly does not support or recommend splitting clusters across geographical locations); Searchlight indexing will write to its local cluster and queries will be run against a local cluster. All region-aware resources will have a region id attached to them. 2. Searchlight will run in each location, but data will not be duplicated across locations (similar to how nova and glance work). To allow searching across regions, Elasticsearch is configured with a tribe_ node that acts as a federated search node; indexing operations are always performed locally. Since we're already using aliases (yay!) there will be no problems with conflicts as there can be with identical index names across clusters. Searches run against the tribe node. 3. Run Searchlight in both regions separately; either have clients make queries against both regions explicitly or have Searchlight's API echo requests to other regions. This would be the equivalent of a 'union' type query; some additional sorting would be required either client-side or as part of the proxying process. Paging becomes tricky. .. _tribe: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-tribe.html Option 2 seems like the most attractive from a functionality point of view. The devil will be in the detail; it requires first that Tribe is a long-term supported path, and more importantly that there is an adequate story for security. Tribe requires access to all Elasticsearch nodes in each cluster, which likely means it needs to support SSL at the transport level and that operators are able and willing to provide cross-data-center access. This is presumably already done with MySQL replication and so may not be a roadblock, but a simple PoC would be very useful. Alternatives ------------ Don't do multi-region searching. References ========== * Openstack scaling http://docs.openstack.org/openstack-ops/content/scaling.html * Elasticsearch 'tribe' nodes: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-tribe.html ",,99,0
openstack%2Fsyntribos~master~Ibe81e69f00ef3f29234037a421e40645cf1341e9,openstack/syntribos,master,Ibe81e69f00ef3f29234037a421e40645cf1341e9,Improved XML external entity tests,MERGED,2016-04-29 21:58:23.000000000,2016-05-05 22:12:17.000000000,2016-05-05 22:12:17.000000000,"[{'_account_id': 3}, {'_account_id': 15259}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18729}]","[{'number': 1, 'created': '2016-04-29 21:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/4765aa790068cb941f1441726b7132dff1ef2b9e', 'message': 'Improved XML external entity tests\n\n1) XML external entity tests are now only generated and run when the API method\nsupports XML.\n2) Supports timing attacks\n3) Now fuzzes permutations of XXE DTDs\n\nChange-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9\n'}, {'number': 2, 'created': '2016-04-29 22:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/3e5853ecae2e79009ba176b486bcd3e6756d6e1c', 'message': 'Improved XML external entity tests\n\n1) XML external entity tests are now only generated and run when the API method\nsupports XML.\n2) Supports timing attacks\n3) Now fuzzes permutations of XXE DTDs\n\nChange-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9\n'}, {'number': 3, 'created': '2016-04-29 22:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/c4e019122161005525070d6c2dc6332360f69438', 'message': 'Improved XML external entity tests\n\n1) XML external entity tests are now only generated and run when the API method\nsupports XML.\n2) Supports timing attacks\n3) Now fuzzes permutations of XXE DTDs\n\nChange-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9\n'}, {'number': 4, 'created': '2016-05-02 22:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/ff05e58f727220a7308a32c838c9bad4153543ef', 'message': 'Improved XML external entity tests\n\n1) XML external entity tests are now only generated and run when the API method\nsupports XML.\n2) Supports timing attacks\n3) Now fuzzes permutations of XXE DTDs\n\nChange-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9\n'}, {'number': 5, 'created': '2016-05-05 21:33:53.000000000', 'files': ['syntribos/runner.py', 'syntribos/tests/fuzz/config.py', 'syntribos/tests/fuzz/xml_external.py', 'syntribos/clients/http/models.py', 'data/xml-external.txt'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/7f7ad241efa5c7f117c98e811dbbe3c8695c2c0b', 'message': 'Improved XML external entity tests\n\n1) XML external entity tests are now only generated and run when the API method\nsupports XML.\n2) Supports timing attacks\n3) Now fuzzes permutations of XXE DTDs\n\nChange-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9\n'}]",9,311290,7f7ad241efa5c7f117c98e811dbbe3c8695c2c0b,16,5,5,17709,,,0,"Improved XML external entity tests

1) XML external entity tests are now only generated and run when the API method
supports XML.
2) Supports timing attacks
3) Now fuzzes permutations of XXE DTDs

Change-Id: Ibe81e69f00ef3f29234037a421e40645cf1341e9
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/90/311290/4 && git format-patch -1 --stdout FETCH_HEAD,"['data/xml-external-dtds.txt', 'syntribos/runner.py', 'syntribos/tests/fuzz/xml_external.py', 'syntribos/clients/http/models.py', 'data/xml-external.txt']",5,4765aa790068cb941f1441726b7132dff1ef2b9e,XML,&xxe;,"<?xml version=""1.0"" encoding=""ISO-8859-1""?><!DOCTYPE foo [ <!ELEMENT foo ANY ><!ENTITY xxe SYSTEM ""file:///etc/passwd"" >]><foo>&xxe;</foo> <?xml version=""1.0"" encoding=""ISO-8859-1""?><!DOCTYPE foo [ <!ELEMENT foo ANY ><!ENTITY xxe SYSTEM ""file:///etc/shadow"" >]><foo>&xxe;</foo> <?xml version=""1.0"" encoding=""ISO-8859-1""?><!DOCTYPE foo [ <!ELEMENT foo ANY ><!ENTITY xxe SYSTEM ""file:///c:/boot.ini"" >]><foo>&xxe;</foo> ",87,21
openstack%2Ftempest-lib~master~I6fad6dd48a4d306f69da27c6793de687bbf72add,openstack/tempest-lib,master,I6fad6dd48a4d306f69da27c6793de687bbf72add,Introduce scope in the auth API,ABANDONED,2015-07-16 17:05:03.000000000,2016-05-05 21:57:57.000000000,,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 7191}, {'_account_id': 8556}, {'_account_id': 15640}]","[{'number': 1, 'created': '2015-07-16 17:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/f008302c9cc7107f2b44a58f3565b5952774fadc', 'message': 'Introduce scope in the auth API\n\nWIP - do not merge\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 2, 'created': '2015-08-04 21:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/6306978115b2cbae04264bb9c4ce5ccb323ef725', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nWIP: missing unit tests to pass different scope and verify\nwhich auth_params are passed through.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 3, 'created': '2015-09-02 13:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/2d8b5228a12ec16dcdb35d4c7e0c7f8885745b96', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nWIP: missing unit tests to pass different scope and verify\nwhich auth_params are passed through.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 4, 'created': '2015-09-02 23:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/cf0a491503882dffc48c2c0519b144fa21edf830', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nWIP: missing unit tests to pass different scope and verify\nwhich auth_params are passed through.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 5, 'created': '2015-09-07 14:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/874dc43f32c864e5d5208c1e4a795ea243b2999c', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 6, 'created': '2015-09-07 23:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/06bb096322ec85c390022e294a3964e5b9dc64b8', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 7, 'created': '2015-09-09 18:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/991625ee2b5248f3c2c9c022eca7acb9ba56701c', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 8, 'created': '2015-09-09 19:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/f963bfab20101bb9b4d4d57bcca098a6e527f5f5', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 9, 'created': '2015-09-10 23:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/2ed96b820db7f0febe8f589b537057cb3fd22a83', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 10, 'created': '2015-09-17 14:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/820acb792560fc55fbaa2bfbff2edd731256a710', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 11, 'created': '2015-09-25 22:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/f4cd0ff98d0c4754e9ccf0fcbd493793d3a92fad', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 12, 'created': '2015-10-02 12:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/b181d877eb6807bc39ea178764caae3b8687e843', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}, {'number': 13, 'created': '2015-10-06 11:50:12.000000000', 'files': ['tempest_lib/tests/fake_identity.py', 'tempest_lib/tests/services/identity/v3/test_token_client.py', 'tempest_lib/services/identity/v3/token_client.py', 'tempest_lib/common/rest_client.py', 'tempest_lib/tests/fake_credentials.py', 'tempest_lib/auth.py', 'tempest_lib/services/identity/v2/token_client.py', 'tempest_lib/tests/fake_auth_provider.py', 'tempest_lib/tests/test_auth.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/39b0f1d530250a4679345979029a97f4fc97e515', 'message': 'Introduce scope in the auth API\n\nAdding the ability to select the scope of the authentication.\nWhen using identity v3, this makes it possible to use either\nproject scope or domain scope regardless of whether a project\nis included or not in the Credentials object.\n\nCloses-bug: #1475359\nChange-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add\n'}]",23,202705,39b0f1d530250a4679345979029a97f4fc97e515,57,8,13,1921,,,0,"Introduce scope in the auth API

Adding the ability to select the scope of the authentication.
When using identity v3, this makes it possible to use either
project scope or domain scope regardless of whether a project
is included or not in the Credentials object.

Closes-bug: #1475359
Change-Id: I6fad6dd48a4d306f69da27c6793de687bbf72add
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/05/202705/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/auth.py', 'tempest_lib/tests/test_auth.py']",2,f008302c9cc7107f2b44a58f3565b5952774fadc,bug/1475359," def _decorate_request(self, scope=None): def _get_auth(self, scope=None): def base_url(self, scope=None): self.auth_provider.cache = {None: 'bar'} self.assertEqual('bar', getattr(self.auth_provider, 'auth_data')) self.auth_provider.cache = {None: 'bar'} self.assertEqual(self.auth_provider.cache, {}) self.auth_provider.cache = {None: 'bar'} self.assertEqual(self.auth_provider.cache, {})"," def _decorate_request(self): def _get_auth(self): def base_url(self): self.auth_provider.cache = 'foo' self.assertEqual('foo', getattr(self.auth_provider, 'auth_data')) self.auth_provider.cache = 'foo' self.assertIsNone(self.auth_provider.cache) self.auth_provider.cache = 'foo' self.assertIsNone(self.auth_provider.cache)",70,41
openstack%2Fneutron~master~I7124974bac629fdb8946df6a7f84bd6b40f5af49,openstack/neutron,master,I7124974bac629fdb8946df6a7f84bd6b40f5af49,Avoid calling _get_subnet(s) multiple times in ipam driver,MERGED,2016-02-17 08:41:38.000000000,2016-05-05 21:54:28.000000000,2016-04-20 22:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6635}, {'_account_id': 6659}, {'_account_id': 6685}, {'_account_id': 7037}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10267}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 11682}, {'_account_id': 13768}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14215}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-17 08:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10d877eb7e11cf8b131bbb9046a1add659343e6d', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 2, 'created': '2016-02-17 12:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15ce2045034ff8621a2fead58f7e11ac3a2ac6ae', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 3, 'created': '2016-02-18 06:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31873ef9948ac307664a516fdc51b87b4f39980b', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 4, 'created': '2016-03-01 07:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/404af92b3523a304b6f7885ba6272a4b4d9ea148', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 5, 'created': '2016-03-03 05:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b554ca74084f25e4c8aad0ae4b4e77f7a04890ba', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nDocImpact\nAPIImpact\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 6, 'created': '2016-03-03 18:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b9dccb3463487bcf9c5e49d9838aaf163856fee', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nAPIImpact\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 7, 'created': '2016-03-08 08:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/098819e5907dafc49ecae17fcea9b0e501c5fd4e', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB, previously HTTPNotFound returned, but now InvalidInput returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 8, 'created': '2016-03-09 11:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86a56f91a9117d2a0deaf504881482914075e218', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead of that,\nif we call only _get_subents once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 9, 'created': '2016-03-14 06:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/468f34349a7f6cbeacf06f13e808eb5a621bda3d', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead of that,\nif we call only _get_subents once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 10, 'created': '2016-03-14 06:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/817d00a1c3eed8f1aa5c938dc579632a0204160e', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead if we call\nonly _get_subents once initially and store them in memory\nand use in-memory subnets when needed, we can avoid multiple\ncalls for DB access.\n\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 11, 'created': '2016-03-14 09:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e7b3ec0c2d7f8c5f35399c73aa18e8c75c1274c8', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subents are called multiple times. Instead of that,\nif we call only _get_subents once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 12, 'created': '2016-03-15 22:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11da1d2b9d189cc048d7f69fbed9ca8e289a3c11', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subents once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 13, 'created': '2016-03-17 17:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5d48cd62a5b9563b2c5e65c72ab02dc14868114', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 14, 'created': '2016-03-25 06:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c567956579f21c143da1fc9da937dbb6739030ca', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subents once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 15, 'created': '2016-04-06 06:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb63ea9dd6cf0b094db966b4f5c308754dd511f2', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 16, 'created': '2016-04-07 09:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/647d0092bef7d24f8a9f0c476fc00392e9d62611', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\nPlease see bug report for complete description.\n\nAPIImpact\nFor create_port/update_port, if subnet passed in fixed_ips not found in\nDB during checks in _test_fixed_ips_for_port, previously HTTPNotFound\nreturned, but now InvalidInput will be returned.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 17, 'created': '2016-04-13 13:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4415ddbfc5a63daa2db5c5ffdbfd9db85fa71721', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\n\nPlease see bug report for complete description.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 18, 'created': '2016-04-13 18:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a899d00cb951b36e86277e6d202f1f634fc3f40b', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\n\nPlease see bug report for complete description.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 19, 'created': '2016-04-14 06:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1d3a19767fc618ed02ba609d97ced8b76863a49', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\n\nPlease see bug report for complete description.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 20, 'created': '2016-04-15 22:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0089469637f95cd78168f2dfc61fc23e2a64c46c', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets are called multiple times. Instead of that,\nif we call only _get_subnets once initially and store them\nin memory and use in-memory subnets when needed,\nwe can avoid multiple calls for DB access.\n\nPlease see bug report for complete description.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}, {'number': 21, 'created': '2016-04-15 22:54:40.000000000', 'files': ['neutron/db/ipam_backend_mixin.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/ipam_pluggable_backend.py', 'neutron/tests/unit/db/test_ipam_pluggable_backend.py', 'neutron/db/ipam_non_pluggable_backend.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e174e619580173d43b398aa71587938a4313ca5b', 'message': 'Avoid calling _get_subnet(s) multiple times in ipam driver\n\nWhile allocating or updating ips for port, _get_subnet and\n_get_subnets were called multiple times resulting in multiple DB\ncalls.  This patch changes it to only call _get_subnets once\ninitially.\n\nCloses-bug: #1554414\nChange-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49\n'}]",55,281116,e174e619580173d43b398aa71587938a4313ca5b,315,30,21,10267,,,0,"Avoid calling _get_subnet(s) multiple times in ipam driver

While allocating or updating ips for port, _get_subnet and
_get_subnets were called multiple times resulting in multiple DB
calls.  This patch changes it to only call _get_subnets once
initially.

Closes-bug: #1554414
Change-Id: I7124974bac629fdb8946df6a7f84bd6b40f5af49
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/281116/10 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/ipam_backend_mixin.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/ipam_pluggable_backend.py', 'neutron/tests/unit/db/test_ipam_pluggable_backend.py', 'neutron/db/ipam_non_pluggable_backend.py']",5,10d877eb7e11cf8b131bbb9046a1add659343e6d,bug/1554414," device_owner, subnets): subnet = self._get_subnet_for_fixed_ip( context, fixed, network_id, subnets) net_id_filter = {'network_id': [network_id]} subnets = self._get_subnets(context, filters=net_id_filter) to_add = self._test_fixed_ips_for_port( context, network_id, changes.add, device_owner, subnets) p['device_owner'], subnets)"," device_owner): subnet = self._get_subnet_for_fixed_ip(context, fixed, network_id) to_add = self._test_fixed_ips_for_port(context, network_id, changes.add, device_owner) p['device_owner'])",28,16
openstack%2Freleases~master~I08be12c9757437490b37aa39a4aa7f73dd01de05,openstack/releases,master,I08be12c9757437490b37aa39a4aa7f73dd01de05,move sahara-tests deliverable file with the other independent projects,MERGED,2016-05-05 18:13:23.000000000,2016-05-05 21:52:57.000000000,2016-05-05 21:52:57.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-05 18:13:23.000000000', 'files': ['deliverables/_independent/sahara-tests.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/60f25ebd07d1a60f1c84dfdd67e2cdf74099c0e7', 'message': 'move sahara-tests deliverable file with the other independent projects\n\nChange-Id: I08be12c9757437490b37aa39a4aa7f73dd01de05\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,313093,60f25ebd07d1a60f1c84dfdd67e2cdf74099c0e7,6,2,1,2472,,,0,"move sahara-tests deliverable file with the other independent projects

Change-Id: I08be12c9757437490b37aa39a4aa7f73dd01de05
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/93/313093/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/sahara-tests.yaml'],1,60f25ebd07d1a60f1c84dfdd67e2cdf74099c0e7,nova-newton-schedule,,,0,0
openstack%2Fopenstack-ansible~stable%2Fmitaka~Ibfdd3c28a5f1dbf99474644979b5f58d329c81cb,openstack/openstack-ansible,stable/mitaka,Ibfdd3c28a5f1dbf99474644979b5f58d329c81cb,Increment release to 13.1.0,MERGED,2016-05-05 19:17:01.000000000,2016-05-05 21:52:21.000000000,2016-05-05 21:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 19:17:01.000000000', 'files': ['playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/abd856e526147bdf7c229ceb2c9d98f67fd5bbfe', 'message': 'Increment release to 13.1.0\n\nIn e971e15997aab2c9d8d1e0cf106a67ee703a3409 the minimum requirement\nfor paramiko changed. This invokes the requirement by the release\nteam to increment the minor release version.\n\nThis patch ensures that this increment is reflected.\n\nChange-Id: Ibfdd3c28a5f1dbf99474644979b5f58d329c81cb\n'}]",0,313120,abd856e526147bdf7c229ceb2c9d98f67fd5bbfe,6,2,1,6816,,,0,"Increment release to 13.1.0

In e971e15997aab2c9d8d1e0cf106a67ee703a3409 the minimum requirement
for paramiko changed. This invokes the requirement by the release
team to increment the minor release version.

This patch ensures that this increment is reflected.

Change-Id: Ibfdd3c28a5f1dbf99474644979b5f58d329c81cb
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/20/313120/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/group_vars/all.yml'],1,abd856e526147bdf7c229ceb2c9d98f67fd5bbfe,,openstack_release: 13.1.0,openstack_release: 13.0.2,1,1
openstack%2Fproject-config~master~I0dc0e6bbb9f695584945056528cfb7e02793bdcd,openstack/project-config,master,I0dc0e6bbb9f695584945056528cfb7e02793bdcd,Don't configure deb mirrors for ubuntu-precise,MERGED,2016-05-05 19:33:29.000000000,2016-05-05 21:49:07.000000000,2016-05-05 21:49:07.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 19:33:29.000000000', 'files': ['nodepool/scripts/configure_mirror.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/55dcb81a26e2ce57774c492717ad885a410dd703', 'message': ""Don't configure deb mirrors for ubuntu-precise\n\nSince this image is going to be short lived, we don't want to add\nubuntu-precise AFS mirrors for ubuntu packages.\n\nChange-Id: I0dc0e6bbb9f695584945056528cfb7e02793bdcd\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,313129,55dcb81a26e2ce57774c492717ad885a410dd703,7,3,1,4162,,,0,"Don't configure deb mirrors for ubuntu-precise

Since this image is going to be short lived, we don't want to add
ubuntu-precise AFS mirrors for ubuntu packages.

Change-Id: I0dc0e6bbb9f695584945056528cfb7e02793bdcd
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/29/313129/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/scripts/configure_mirror.sh'],1,55dcb81a26e2ce57774c492717ad885a410dd703,,"# NOTE(pabelanger): We don't actually have mirrors for ubuntu-precise, so skip # them. if [ ""$LSBDISTID"" == ""Ubuntu"" ] && [ ""$LSBDISTCODENAME"" != 'precise' ]; then","if [ ""$LSBDISTID"" == ""Ubuntu"" ] ; then",3,1
openstack%2Ftacker~master~I0d7018e086d6e68d432eefdc098527e38e7e27d7,openstack/tacker,master,I0d7018e086d6e68d432eefdc098527e38e7e27d7,Replace string format arguments with function parameters,MERGED,2016-05-04 07:00:26.000000000,2016-05-05 21:48:33.000000000,2016-05-05 21:48:33.000000000,"[{'_account_id': 3}, {'_account_id': 13485}, {'_account_id': 16511}, {'_account_id': 19950}]","[{'number': 1, 'created': '2016-05-04 07:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/4a96dbcfe4a7c0233aff10d622a6335414f0956c', 'message': 'Replace string format arguments with function parameters\n\nThere are files containing string format arguments inside logging\nmessages. Using logging function parameters should be preferred.\n\nChange-Id: I0d7018e086d6e68d432eefdc098527e38e7e27d7\nCloses-Bug: #1321274\n'}, {'number': 2, 'created': '2016-05-04 07:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1b77f4967c4c71ec120ceb5a6d73309fa5bf72e3', 'message': 'Replace string format arguments with function parameters\n\nThere are files containing string format arguments inside logging\nmessages. Using logging function parameters should be preferred.\n\nChange-Id: I0d7018e086d6e68d432eefdc098527e38e7e27d7\nCloses-Bug: #1321274\n'}, {'number': 3, 'created': '2016-05-05 02:46:30.000000000', 'files': ['tacker/vm/tosca/utils.py', 'tacker/common/rpc_compat.py', 'tacker/openstack/common/middleware/notifier.py', 'tacker/openstack/common/policy.py', 'tacker/openstack/common/processutils.py', 'tacker/openstack/common/loopingcall.py', 'tacker/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/48e1a87c8493483b6b7e0a5a21b650f2ab7ac52b', 'message': 'Replace string format arguments with function parameters\n\nThere are files containing string format arguments inside logging\nmessages. Using logging function parameters should be preferred.\n\nChange-Id: I0d7018e086d6e68d432eefdc098527e38e7e27d7\nCloses-Bug: #1321274\n'}]",10,312340,48e1a87c8493483b6b7e0a5a21b650f2ab7ac52b,13,4,3,19950,,,0,"Replace string format arguments with function parameters

There are files containing string format arguments inside logging
messages. Using logging function parameters should be preferred.

Change-Id: I0d7018e086d6e68d432eefdc098527e38e7e27d7
Closes-Bug: #1321274
",git fetch https://review.opendev.org/openstack/tacker refs/changes/40/312340/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/vm/tosca/utils.py', 'tacker/common/rpc_compat.py', 'tacker/openstack/common/middleware/notifier.py', 'tacker/openstack/common/policy.py', 'tacker/openstack/common/processutils.py', 'tacker/openstack/common/loopingcall.py', 'tacker/openstack/common/fileutils.py']",7,4a96dbcfe4a7c0233aff10d622a6335414f0956c,bug/1321274," LOG.debug(_(""Reloading cached file %s"") , filename)"," LOG.debug(_(""Reloading cached file %s"") % filename)",11,11
openstack%2Fsyntribos~master~Id01c4d73d0a3b0afa2b63138e1579dca39567863,openstack/syntribos,master,Id01c4d73d0a3b0afa2b63138e1579dca39567863,Moved request logic out of setupclass,ABANDONED,2016-04-29 21:58:23.000000000,2016-05-05 21:34:17.000000000,,"[{'_account_id': 3}, {'_account_id': 15515}]","[{'number': 1, 'created': '2016-04-29 21:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/bf2f1a52a8114ba512d1f2accae990df495c1be7', 'message': 'Moved request logic out of setupclass\n\nChange-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863\n'}, {'number': 2, 'created': '2016-04-29 21:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/3f5faa03760a51f59907bffc531be23e89b6f343', 'message': 'Moved request logic out of setupclass\n\nChange-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863\n'}, {'number': 3, 'created': '2016-04-29 22:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/952ef17f385d42ddc76af6bb912b8b47942f1c9f', 'message': 'Moved request logic out of setupclass\n\nChange-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863\n'}, {'number': 4, 'created': '2016-04-29 22:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/9a8fff11522b4850f5f3324bd20b1ec66c950419', 'message': 'Moved request logic out of setupclass\n\nChange-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863\n'}, {'number': 5, 'created': '2016-05-02 22:44:25.000000000', 'files': ['syntribos/tests/fuzz/base_fuzz.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/033e5caed816790f9268df2972595201d0a9667a', 'message': 'Moved request logic out of setupclass\n\nChange-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863\n'}]",0,311289,033e5caed816790f9268df2972595201d0a9667a,10,2,5,17709,,,0,"Moved request logic out of setupclass

Change-Id: Id01c4d73d0a3b0afa2b63138e1579dca39567863
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/89/311289/1 && git format-patch -1 --stdout FETCH_HEAD,['syntribos/tests/fuzz/base_fuzz.py'],1,bf2f1a52a8114ba512d1f2accae990df495c1be7,, cls.make_request() @classmethod def make_request(cls):,,4,0
openstack%2Fcinder~stable%2Fmitaka~I2ec1823eb49a357e04f7b167d1cd9fa2f16e097f,openstack/cinder,stable/mitaka,I2ec1823eb49a357e04f7b167d1cd9fa2f16e097f,Updated from global requirements,MERGED,2016-04-18 15:00:53.000000000,2016-05-05 21:16:33.000000000,2016-04-20 18:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 13144}]","[{'number': 1, 'created': '2016-04-18 15:00:53.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/70ad205543df04129c10bb72b408f4be8264660d', 'message': 'Updated from global requirements\n\nChange-Id: I2ec1823eb49a357e04f7b167d1cd9fa2f16e097f\n'}]",0,307246,70ad205543df04129c10bb72b408f4be8264660d,24,5,1,11131,,,0,"Updated from global requirements

Change-Id: I2ec1823eb49a357e04f7b167d1cd9fa2f16e097f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/46/307246/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,70ad205543df04129c10bb72b408f4be8264660d,openstack/requirements,"fixtures<2.0,>=1.3.1 # Apache-2.0/BSD",fixtures>=1.3.1 # Apache-2.0/BSD,1,1
openstack%2Fproject-config~master~I50ed7a28016125661e2bf43cff316cebc10bae46,openstack/project-config,master,I50ed7a28016125661e2bf43cff316cebc10bae46,retire puppet-unit-{node} jobs,MERGED,2016-05-05 14:16:53.000000000,2016-05-05 21:14:20.000000000,2016-05-05 21:14:20.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 6554}]","[{'number': 1, 'created': '2016-05-05 14:16:53.000000000', 'files': ['jenkins/jobs/puppet-module-jobs.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e9fd7e18c7629a444a31b25c07d31ec23b225ac6', 'message': 'retire puppet-unit-{node} jobs\n\nRetire puppet-unit-{node}, they were not used anywhere.\nThey were replaced some time ago by puppet-unit-{puppet_version}-{node}.\n\nThe job where running in experimental pipeline but was useless, since we\nhave all puppet-unit jobs running in check & gate.\n\nThis patch retires the job.\n\nChange-Id: I50ed7a28016125661e2bf43cff316cebc10bae46\n'}]",0,312987,e9fd7e18c7629a444a31b25c07d31ec23b225ac6,7,4,1,3153,,,0,"retire puppet-unit-{node} jobs

Retire puppet-unit-{node}, they were not used anywhere.
They were replaced some time ago by puppet-unit-{puppet_version}-{node}.

The job where running in experimental pipeline but was useless, since we
have all puppet-unit jobs running in check & gate.

This patch retires the job.

Change-Id: I50ed7a28016125661e2bf43cff316cebc10bae46
",git fetch https://review.opendev.org/openstack/project-config refs/changes/87/312987/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/puppet-module-jobs.yaml', 'zuul/layout.yaml']",2,e9fd7e18c7629a444a31b25c07d31ec23b225ac6,,, experimental: - gate-{name}-puppet-unit-centos-7,0,45
openstack%2Ftripleo-common~master~I86151052fe70a0439c7e0565c790f1873843a2a4,openstack/tripleo-common,master,I86151052fe70a0439c7e0565c790f1873843a2a4,Example yaml for building images,MERGED,2016-03-09 13:06:53.000000000,2016-05-05 21:10:25.000000000,2016-05-05 13:26:09.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 9712}, {'_account_id': 10239}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-03-09 13:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6668662706083a3d0b2e34b657e76907f261112a', 'message': 'Example yaml for building images\n\nThese yaml files show how to create image definitions that can be passed\nto the tripleo-build-images script. The files are additive. So, one would\nspecify by overcloud-images.yaml and then either overcloud-images-centos7\nor overcloud-images-rhel7 depending on the distro type.\n\nChange-Id: I86151052fe70a0439c7e0565c790f1873843a2a4\n'}, {'number': 2, 'created': '2016-03-14 19:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e12c32dbc7c217914567f19b7d02b43e7f1c9ace', 'message': 'Example yaml for building images\n\nThese yaml files show how to create image definitions that can be passed\nto the tripleo-build-images script. The files are additive. So, one would\nspecify by overcloud-images.yaml and then either overcloud-images-centos7\nor overcloud-images-rhel7 depending on the distro type.\n\nChange-Id: I86151052fe70a0439c7e0565c790f1873843a2a4\n'}, {'number': 3, 'created': '2016-03-28 15:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/af7608420613b001e51675c847dfb0eb266b262b', 'message': 'Example yaml for building images\n\nThese yaml files show how to create image definitions that can be passed\nto the tripleo-build-images script. The files are additive. So, one would\nspecify by overcloud-images.yaml and then either overcloud-images-centos7\nor overcloud-images-rhel7 depending on the distro type.\n\nChange-Id: I86151052fe70a0439c7e0565c790f1873843a2a4\n'}, {'number': 4, 'created': '2016-04-08 15:51:53.000000000', 'files': ['image-yaml/overcloud-images-centos7.yaml', 'image-yaml/overcloud-images-rhel7.yaml', 'image-yaml/overcloud-images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/06e18a50fbf2ea0acd7801a287366482f41a51bf', 'message': 'Example yaml for building images\n\nThese yaml files show how to create image definitions that can be passed\nto the tripleo-build-images script. The files are additive. So, one would\nspecify by overcloud-images.yaml and then either overcloud-images-centos7\nor overcloud-images-rhel7 depending on the distro type.\n\nChange-Id: I86151052fe70a0439c7e0565c790f1873843a2a4\n'}]",2,290468,06e18a50fbf2ea0acd7801a287366482f41a51bf,22,5,4,7065,,,0,"Example yaml for building images

These yaml files show how to create image definitions that can be passed
to the tripleo-build-images script. The files are additive. So, one would
specify by overcloud-images.yaml and then either overcloud-images-centos7
or overcloud-images-rhel7 depending on the distro type.

Change-Id: I86151052fe70a0439c7e0565c790f1873843a2a4
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/290468/4 && git format-patch -1 --stdout FETCH_HEAD,"['image-yaml/overcloud-images-centos7.yaml', 'image-yaml/overcloud-images-rhel7.yaml', 'image-yaml/overcloud-images.yaml']",3,6668662706083a3d0b2e34b657e76907f261112a,image-yaml,"disk_images: - imagename: overcloud arch: amd64 type: qcow2 elements: - sysctl hosts baremetal dhcp-all-interfaces os-collect-config overcloud-full overcloud-controller overcloud-compute overcloud-ceph-storage heat-config-puppet heat-config-script puppet-modules hiera os-net-config stable-interface-names grub2 element-manifest network-gateway dynamic-login undercloud-package-install pip-and-virtualenv-override packages: - python-psutil - python-debtcollector - plotnetcfg - sos - python-networking-cisco - python-UcsSdk - device-mapper-multipath - python-networking-bigswitch - openstack-neutron-bigswitch-lldp - openstack-neutron-bigswitch-agent options: - ""--min-tmpfs 5"" - imagename: ramdisk_agent arch: amd64 type: qcow2 elements: - ironic-agent dynamic-login element-manifest network-gateway epel undercloud-package-install pip-and-virtualenv-override packages: - python-hardware-detect options: - ""--min-tmpfs=5"" ",,57,0
openstack%2Fproject-config~master~I9802f50cae5dd461f76d8ba016a5f404fe74f4f3,openstack/project-config,master,I9802f50cae5dd461f76d8ba016a5f404fe74f4f3,Fix publishing location for translations,MERGED,2016-05-05 20:48:29.000000000,2016-05-05 21:10:16.000000000,2016-05-05 21:10:16.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2016-05-05 20:48:29.000000000', 'files': ['jenkins/jobs/translation-jobs.yaml', 'jenkins/scripts/upstream_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5988eab4ac802dfc1e3ed449e45053b22c29a6ce', 'message': 'Fix publishing location for translations\n\nWe want to publish to\ntarballs.openstack.org/translation-source/PROJECT/VERSION . Correctly\nconstruct path for it.\n\nChange-Id: I9802f50cae5dd461f76d8ba016a5f404fe74f4f3\n'}]",0,313152,5988eab4ac802dfc1e3ed449e45053b22c29a6ce,7,3,1,6547,,,0,"Fix publishing location for translations

We want to publish to
tarballs.openstack.org/translation-source/PROJECT/VERSION . Correctly
construct path for it.

Change-Id: I9802f50cae5dd461f76d8ba016a5f404fe74f4f3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/52/313152/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/translation-jobs.yaml', 'jenkins/scripts/upstream_translation_update.sh']",2,5988eab4ac802dfc1e3ed449e45053b22c29a6ce,fix-pot-tarball," # Copy all *.pot files to translation-source directory TARGET_PATH=.translation-source/$PROJECT/$ZANATA_VERSION/ mkdir -p $TARGET_PATH find . -path ""./.*"" -prune -o -name ""*.pot"" \ -exec cp -v {} $TARGET_PATH \; mv .translation-source translation-source"," # Copy all *.pot files to pot-files directory mkdir -p .pot-files/$ZANATA_VERSION/ find . -path ""./.*"" -prune -o -name ""*.pot"" -exec cp -v {} .pot-files \; mv .pot-files pot-files",9,7
openstack%2Fpuppet-swift~stable%2Fmitaka~I2ba7a14a99bdfd7fe0b257d656c9369930033464,openstack/puppet-swift,stable/mitaka,I2ba7a14a99bdfd7fe0b257d656c9369930033464,Prepare module for publication to the forge,MERGED,2016-05-03 20:18:10.000000000,2016-05-05 21:09:16.000000000,2016-05-05 21:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 20:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/945ba9e5fa99edef4dc89b51f84ae24ce00120f4', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I2ba7a14a99bdfd7fe0b257d656c9369930033464\n""}, {'number': 2, 'created': '2016-05-03 22:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/6cc5b66267df523f54d48fc94ce1d33e14a98bc8', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I2ba7a14a99bdfd7fe0b257d656c9369930033464\n""}, {'number': 3, 'created': '2016-05-04 18:27:43.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/765604551f26b69b4b967a7e1316c5a575408864', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I2ba7a14a99bdfd7fe0b257d656c9369930033464\n""}]",0,312232,765604551f26b69b4b967a7e1316c5a575408864,24,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I2ba7a14a99bdfd7fe0b257d656c9369930033464
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/32/312232/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,945ba9e5fa99edef4dc89b51f84ae24ce00120f4,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/rsync"", ""version_requirement"": "">=0.4.0 <1.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }, { ""name"": ""puppetlabs/xinetd"", ""version_requirement"": "">=1.5.0 <2.0.0"" }, { ""name"": ""puppetlabs/concat"", ""version_requirement"": "">=1.2.0 <2.0.0"" }, { ""name"": ""saz/memcached"", ""version_requirement"": "">=2.8.1 <3.0.0"" }"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/rsync"", ""version_requirement"": "">=0.2.0 <1.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }, { ""name"": ""puppetlabs/xinetd"", ""version_requirement"": "">=1.0.1 <2.0.0"" }, { ""name"": ""puppetlabs/concat"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""saz/memcached"", ""version_requirement"": "">=2.0.2 <3.0.0"" }",12,12
openstack%2Foslo.config~master~I3689c6faf60be49ce2bf19f45e977dd64798954b,openstack/oslo.config,master,I3689c6faf60be49ce2bf19f45e977dd64798954b,Update Beta development status from classifiers,MERGED,2016-05-02 17:43:56.000000000,2016-05-05 21:02:44.000000000,2016-05-05 21:02:44.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-05-02 17:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/c77d2609c22de1412a9de00f68678cb647ef9c0b', 'message': 'Remove Beta development status from classifiers\n\nRemove the Beta trove classifier to be in line with other Oslo\nprojects. While there is a Production/Stable status none of the other\nOslo projects use it.\n\nhttps://pypi.python.org/pypi?%3Aaction=list_classifiers\n\nChange-Id: I3689c6faf60be49ce2bf19f45e977dd64798954b\n'}, {'number': 2, 'created': '2016-05-04 16:06:30.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/ed2da1ffed01ee7b3f7ee2af7edf56ba1e68da18', 'message': 'Update Beta development status from classifiers\n\nUpdate the Beta trove classifier to be Production/Stable status.\nSee list of used classifiers at\n\nhttps://pypi.python.org/pypi?%3Aaction=list_classifiers\n\nChange-Id: I3689c6faf60be49ce2bf19f45e977dd64798954b\n'}]",1,311800,ed2da1ffed01ee7b3f7ee2af7edf56ba1e68da18,10,3,2,16051,,,0,"Update Beta development status from classifiers

Update the Beta trove classifier to be Production/Stable status.
See list of used classifiers at

https://pypi.python.org/pypi?%3Aaction=list_classifiers

Change-Id: I3689c6faf60be49ce2bf19f45e977dd64798954b
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/00/311800/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c77d2609c22de1412a9de00f68678cb647ef9c0b,mature_status,, Development Status :: 4 - Beta,0,1
openstack%2Foslo.service~master~Ie5bf4a871938873fe5300a28ddadfde33323951f,openstack/oslo.service,master,Ie5bf4a871938873fe5300a28ddadfde33323951f,[Trivial] Remove executable privilege of doc/source/conf.py,MERGED,2016-04-29 04:14:54.000000000,2016-05-05 20:54:48.000000000,2016-05-05 20:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7293}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-04-29 04:14:54.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/b83ec523b41ed35ee954cff82d01131d701f1255', 'message': '[Trivial] Remove executable privilege of doc/source/conf.py\n\nIt is a configuration file, rather than a script.\n\nChange-Id: Ie5bf4a871938873fe5300a28ddadfde33323951f\n'}]",0,311002,b83ec523b41ed35ee954cff82d01131d701f1255,8,4,1,6676,,,0,"[Trivial] Remove executable privilege of doc/source/conf.py

It is a configuration file, rather than a script.

Change-Id: Ie5bf4a871938873fe5300a28ddadfde33323951f
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/02/311002/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,b83ec523b41ed35ee954cff82d01131d701f1255,rm-x,,,0,0
openstack%2Fglance~master~I7d950f2579ae9d0596bd0e1d0b32604e9d905001,openstack/glance,master,I7d950f2579ae9d0596bd0e1d0b32604e9d905001,Remove unnecessary executable privilge of unit test file,MERGED,2016-04-29 03:47:11.000000000,2016-05-05 20:50:09.000000000,2016-05-05 20:50:09.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 8158}, {'_account_id': 12000}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-04-29 03:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3cc2090e4ab23aef40154edee0dac1cb2d4b4b3f', 'message': ""[Trivial] Remove unnecessary executable privilge of unit test file\n\nglance/tests/unit/test_cache_middleware.py is a test module, and\nit doesn't have main entry, hence the executable flag is not needed.\n\nChange-Id: I7d950f2579ae9d0596bd0e1d0b32604e9d905001\n""}, {'number': 2, 'created': '2016-05-05 16:33:38.000000000', 'files': ['glance/tests/unit/test_cache_middleware.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/bc0c03f33f94bd692a8d67d80b80e45ce99a6c2a', 'message': ""Remove unnecessary executable privilge of unit test file\n\nglance/tests/unit/test_cache_middleware.py is a test module, and\nit doesn't have main entry, hence the executable flag is not needed.\n\nChange-Id: I7d950f2579ae9d0596bd0e1d0b32604e9d905001\n""}]",0,310991,bc0c03f33f94bd692a8d67d80b80e45ce99a6c2a,16,5,2,6676,,,0,"Remove unnecessary executable privilge of unit test file

glance/tests/unit/test_cache_middleware.py is a test module, and
it doesn't have main entry, hence the executable flag is not needed.

Change-Id: I7d950f2579ae9d0596bd0e1d0b32604e9d905001
",git fetch https://review.opendev.org/openstack/glance refs/changes/91/310991/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_cache_middleware.py'],1,3cc2090e4ab23aef40154edee0dac1cb2d4b4b3f,rm-x,,,0,0
openstack%2Fdragonflow~master~I4f505ce7172b0971f442a81fba47259903d2e6b3,openstack/dragonflow,master,I4f505ce7172b0971f442a81fba47259903d2e6b3,test,ABANDONED,2016-04-14 08:28:26.000000000,2016-05-05 20:41:15.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-04-14 08:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e2ca2b8641501f8da60de3a2cdaa721769276f99', 'message': 'test\n\nChange-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3\nDepends-On: 276842\n'}, {'number': 2, 'created': '2016-04-14 08:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8ed50d19148d084fbf1b88810e6d7d23c7b0fcb5', 'message': 'test\n\nChange-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3\nDepends-On: I0544f1d47ae53d572adda872847a56fa0b202d2e\n'}, {'number': 3, 'created': '2016-04-14 19:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d0d4eba9f8532a0388e1ccc7216280f3a9f9f9f8', 'message': 'test\n\nChange-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3\nDepends-On: I0544f1d47ae53d572adda872847a56fa0b202d2e\n'}, {'number': 4, 'created': '2016-04-22 11:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/eb8d79c56f83ea9c129a1535d2a42718d7f16f9c', 'message': 'test\n\nChange-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3\nDepends-On: I0544f1d47ae53d572adda872847a56fa0b202d2e\n'}, {'number': 5, 'created': '2016-04-27 21:25:52.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d43a06a7a034877369a7d1b47ec62d16ed4b2d8f', 'message': 'test\n\nChange-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3\nDepends-On: I0544f1d47ae53d572adda872847a56fa0b202d2e\n'}]",0,305656,d43a06a7a034877369a7d1b47ec62d16ed4b2d8f,10,1,5,8601,,,0,"test

Change-Id: I4f505ce7172b0971f442a81fba47259903d2e6b3
Depends-On: I0544f1d47ae53d572adda872847a56fa0b202d2e
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/56/305656/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e2ca2b8641501f8da60de3a2cdaa721769276f99,test_neutron_change,,,1,0
openstack%2Finstack-undercloud~master~Iadc7940e56be19700977b0cdbd86aa010c105fb6,openstack/instack-undercloud,master,Iadc7940e56be19700977b0cdbd86aa010c105fb6,Use enable-packages-install element,MERGED,2016-01-05 17:59:30.000000000,2016-05-05 20:40:19.000000000,2016-05-05 20:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-01-05 17:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/9d04d265150ec4adb736df8a42f11a49baee1ff6', 'message': 'Use enable-packages-install element\n\nThere is already an element from tripleo-image-elements,\nenable-packages-install, to switch the default install type to package\ninstead of source. This patch updates instack-undercloud to use\nenable-packages-install and removes the duplicate\nundercloud-package-install.\n\nChange-Id: Iadc7940e56be19700977b0cdbd86aa010c105fb6\nDepends-On: I8f47b495218a72f5a78d68b7c2610116a5b4984c\n'}, {'number': 2, 'created': '2016-04-18 20:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/272ee18fe182efdb104c194df5a79b0ee445f765', 'message': 'Use enable-packages-install element\n\nThere is already an element from tripleo-image-elements,\nenable-packages-install, to switch the default install type to package\ninstead of source. This patch updates instack-undercloud to use\nenable-packages-install and removes the duplicate\nundercloud-package-install.\n\nChange-Id: Iadc7940e56be19700977b0cdbd86aa010c105fb6\nDepends-On: I8f47b495218a72f5a78d68b7c2610116a5b4984c\nDepends-On: I8185aa56ea5225870bab50576023588af37ebedd\n'}, {'number': 3, 'created': '2016-05-05 12:59:11.000000000', 'files': ['json-files/centos-7-undercloud-packages.json', 'elements/undercloud-package-install/environment.d/00-package-install', 'json-files/rhel-7-undercloud-packages.json'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/3083c864c9beac7edf9a4efa6242e51c688d2fc0', 'message': 'Use enable-packages-install element\n\nThere is already an element from tripleo-image-elements,\nenable-packages-install, to switch the default install type to package\ninstead of source. This patch updates instack-undercloud to use\nenable-packages-install and removes the duplicate\nundercloud-package-install.\n\nblueprint undercloud-elements\nChange-Id: Iadc7940e56be19700977b0cdbd86aa010c105fb6\nDepends-On: I8f47b495218a72f5a78d68b7c2610116a5b4984c\nDepends-On: I8185aa56ea5225870bab50576023588af37ebedd\n'}]",1,263829,3083c864c9beac7edf9a4efa6242e51c688d2fc0,35,8,3,7144,,,0,"Use enable-packages-install element

There is already an element from tripleo-image-elements,
enable-packages-install, to switch the default install type to package
instead of source. This patch updates instack-undercloud to use
enable-packages-install and removes the duplicate
undercloud-package-install.

blueprint undercloud-elements
Change-Id: Iadc7940e56be19700977b0cdbd86aa010c105fb6
Depends-On: I8f47b495218a72f5a78d68b7c2610116a5b4984c
Depends-On: I8185aa56ea5225870bab50576023588af37ebedd
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/29/263829/1 && git format-patch -1 --stdout FETCH_HEAD,"['json-files/centos-7-undercloud-packages.json', 'elements/undercloud-package-install/environment.d/00-package-install', 'json-files/rhel-7-undercloud-packages.json']",3,9d04d265150ec4adb736df8a42f11a49baee1ff6,cull-elements," ""enable-packages-install"","," ""undercloud-package-install"",",2,56
openstack%2Fpuppet-aodh~stable%2Fmitaka~I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060,openstack/puppet-aodh,stable/mitaka,I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060,Prepare module for publication to the forge,MERGED,2016-05-03 22:00:56.000000000,2016-05-05 20:39:45.000000000,2016-05-05 20:39:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8083}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 22:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/82a70e36f42f0c785eaeaa029616f5a610a0a5f0', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060\n""}, {'number': 2, 'created': '2016-05-03 22:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/700fe81daa78037e4644274e009b4f77f6be1d80', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060\n""}, {'number': 3, 'created': '2016-05-03 22:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/e040e6bbbc06937900ac93cd6af5a28f34e0cb2a', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060\n""}, {'number': 4, 'created': '2016-05-03 23:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/cb6e5da2aa6d50887575aa4e184fd4ab3cd64ff3', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060\n""}, {'number': 5, 'created': '2016-05-04 18:28:12.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/abc5a72b1c750b31e7525ebc6a9ae7b8db658205', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060\n""}]",5,312266,abc5a72b1c750b31e7525ebc6a9ae7b8db658205,24,5,5,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I8d4a6e3a3100c6689c5a9d4d6c110ebdc1c6d060
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/66/312266/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,82a70e36f42f0c785eaeaa029616f5a610a0a5f0,prep_for_forge," ""version"": ""8.0.1"", ""requirements"": [ { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ], ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"", ""22"", ""23""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""6.5"", ""7""] }, { ""operatingsystemrelease"": [""12.04"", ""14.04""] ""description"": ""Installs and configures OpenStack Aodh."", { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">= 4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", ""description"": ""Installs and configures OpenStack Aodh."", ""operatingsystemrelease"": [""8""] }, { ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"",""22""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">= 4.2.0 <5.0.0"" },",17,13
openstack%2Fpuppet-openstack_extras~stable%2Fmitaka~Ice2dfa08a4bfe8163195f5b45b945fcede6c635c,openstack/puppet-openstack_extras,stable/mitaka,Ice2dfa08a4bfe8163195f5b45b945fcede6c635c,Prepare module for publication to the forge,MERGED,2016-05-03 20:40:17.000000000,2016-05-05 20:39:39.000000000,2016-05-05 20:39:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 20:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/eecd7d341c17e02e92bfbcf9907a93ae472582d0', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ice2dfa08a4bfe8163195f5b45b945fcede6c635c\n""}, {'number': 2, 'created': '2016-05-03 22:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/47524b874671a19a7e8c1ebdfff1e99ee8858ef1', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ice2dfa08a4bfe8163195f5b45b945fcede6c635c\n""}, {'number': 3, 'created': '2016-05-04 18:27:52.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/309667e7f4d795903edb759b9ee206c2b2516bf7', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ice2dfa08a4bfe8163195f5b45b945fcede6c635c\n""}]",0,312243,309667e7f4d795903edb759b9ee206c2b2516bf7,17,3,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Ice2dfa08a4bfe8163195f5b45b945fcede6c635c
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/43/312243/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,eecd7d341c17e02e92bfbcf9907a93ae472582d0,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apt"", ""version_requirement"": "">=2.2.0 <3.0.0"" }, { ""name"": ""puppetlabs/corosync"", ""version_requirement"": "">=0.8.0 <1.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/apt"", ""version_requirement"": "">=1.8.0 <3.0.0"" }, { ""name"": ""puppetlabs/corosync"", ""version_requirement"": "">=0.1.0 <1.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }",9,9
openstack%2Fkeystone~stable%2Fmitaka~If74aaf07b77399f1648843280153c7523de5eb38,openstack/keystone,stable/mitaka,If74aaf07b77399f1648843280153c7523de5eb38,Allow 'domain' property for local.group,MERGED,2016-05-05 17:42:52.000000000,2016-05-05 20:29:11.000000000,2016-05-05 20:29:11.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-05 17:42:52.000000000', 'files': ['keystone/federation/utils.py', 'keystone/tests/unit/contrib/federation/test_utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/053ad79a548359e3149f0320c005ea72d3f2fe34', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n(cherry picked from commit 7567c5edf214bfbbee6d6acf7c130cd857324fc0)\n""}]",0,313083,053ad79a548359e3149f0320c005ea72d3f2fe34,6,2,1,18940,,,0,"Allow 'domain' property for local.group

The JSON schema missed the domain property for the local group
description, but it is requested by the code explicitly.

Change-Id: If74aaf07b77399f1648843280153c7523de5eb38
Closes-Bug: 1575057
(cherry picked from commit 7567c5edf214bfbbee6d6acf7c130cd857324fc0)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/83/313083/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/federation/utils.py', 'keystone/tests/unit/contrib/federation/test_utils.py']",2,053ad79a548359e3149f0320c005ea72d3f2fe34,mapping_validator_tests, def test_mapping_with_group_name_and_domain(self): mapping = mapping_fixtures.MAPPING_GROUP_NAMES mapping_utils.validate_mapping_structure(mapping) ,,13,1
openstack%2Fastara-neutron~stable%2Fliberty~Ie8ca7d0af012367fd669ca5c5afec649f2954e39,openstack/astara-neutron,stable/liberty,Ie8ca7d0af012367fd669ca5c5afec649f2954e39,Backport Mitaka option to disable auto added resources.  The default value for the new configuration option preserves the original behavior at the time of Liberty release.,MERGED,2016-04-20 19:31:14.000000000,2016-05-05 20:21:28.000000000,2016-05-05 20:21:28.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 8005}]","[{'number': 1, 'created': '2016-04-20 19:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-neutron/commit/3b526c195cb87a28b47083f3e0a06751c90184be', 'message': 'Backport Mitaka option to disable auto added resources.\n\nChange-Id: Ie8ca7d0af012367fd669ca5c5afec649f2954e39\n'}, {'number': 2, 'created': '2016-04-20 22:15:09.000000000', 'files': ['akanda/neutron/plugins/decorators.py'], 'web_link': 'https://opendev.org/openstack/astara-neutron/commit/10dd21be3b0690ef796aeccfe9191ab006c2285e', 'message': 'Backport Mitaka option to disable auto added resources.  The default\nvalue for the new configuration option preserves the original behavior\nat the time of Liberty release.\n\nChange-Id: Ie8ca7d0af012367fd669ca5c5afec649f2954e39\n'}]",0,308544,10dd21be3b0690ef796aeccfe9191ab006c2285e,14,3,2,2592,,,0,"Backport Mitaka option to disable auto added resources.  The default
value for the new configuration option preserves the original behavior
at the time of Liberty release.

Change-Id: Ie8ca7d0af012367fd669ca5c5afec649f2954e39
",git fetch https://review.opendev.org/openstack/astara-neutron refs/changes/44/308544/1 && git format-patch -1 --stdout FETCH_HEAD,['akanda/neutron/plugins/decorators.py'],1,3b526c195cb87a28b47083f3e0a06751c90184be,auto_add_backport," help='List of allowed subnet cidrs for non-admin users'), cfg.BoolOpt( 'astara_auto_add_resources', default=True, help='Attempt to auto add resources to speed up network construction' ) if cfg.CONF.astara_auto_add_resources: _add_ipv6_subnet(context, net) if cfg.CONF.astara_auto_add_resources: _add_subnet_to_router(context, subnet)"," help='List of allowed subnet cidrs for non-admin users') _add_ipv6_subnet(context, net) _add_subnet_to_router(context, subnet)",10,3
openstack%2Fproject-config~master~I8b0c78b28cf04607862e2882fb0fcdec816c5b81,openstack/project-config,master,I8b0c78b28cf04607862e2882fb0fcdec816c5b81,NPM Jobs now run on Xenial,MERGED,2016-05-04 20:53:05.000000000,2016-05-05 20:11:03.000000000,2016-05-05 20:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 20:53:05.000000000', 'files': ['jenkins/jobs/macros.yaml', 'jenkins/jobs/javascript.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8f9ef6c442987e2302b5709f807bcc4382ec42bf', 'message': 'NPM Jobs now run on Xenial\n\nThis updates the our javascript builds to run on xenial.\n\nChange-Id: I8b0c78b28cf04607862e2882fb0fcdec816c5b81\n'}]",0,312742,8f9ef6c442987e2302b5709f807bcc4382ec42bf,7,3,1,9717,,,0,"NPM Jobs now run on Xenial

This updates the our javascript builds to run on xenial.

Change-Id: I8b0c78b28cf04607862e2882fb0fcdec816c5b81
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/312742/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/macros.yaml', 'jenkins/jobs/javascript.yaml']",2,8f9ef6c442987e2302b5709f807bcc4382ec42bf,npm, node: ubuntu-xenial node: ubuntu-xenial node: ubuntu-xenial node: ubuntu-xenial node: ubuntu-xenial, node: ubuntu-trusty node: ubuntu-trusty node: ubuntu-trusty node: ubuntu-trusty node: ubuntu-trusty,16,11
openstack%2Fneutron~master~I879bf097f3f54bff83408299b39f5dcfc298adba,openstack/neutron,master,I879bf097f3f54bff83408299b39f5dcfc298adba,Use switch-case instead of if-then-elif,MERGED,2016-04-16 15:38:43.000000000,2016-05-05 20:11:03.000000000,2016-04-18 08:34:45.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9845}, {'_account_id': 11682}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 17523}]","[{'number': 1, 'created': '2016-04-16 15:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c050a3372c68e0497d110e112988165763a8f4d', 'message': 'Use switch-case instea of if-then-elif\n\nMakes the gate hook more compact and align if statement\nsyntax.\n\nChange-Id: I879bf097f3f54bff83408299b39f5dcfc298adba\n'}, {'number': 2, 'created': '2016-04-16 15:39:12.000000000', 'files': ['neutron/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d2bb27444f9db927aca82e788959db241264eb4', 'message': 'Use switch-case instead of if-then-elif\n\nMake the gate hook more compact and align if statement\nsyntax.\n\nChange-Id: I879bf097f3f54bff83408299b39f5dcfc298adba\n'}]",0,306759,2d2bb27444f9db927aca82e788959db241264eb4,21,10,2,748,,,0,"Use switch-case instead of if-then-elif

Make the gate hook more compact and align if statement
syntax.

Change-Id: I879bf097f3f54bff83408299b39f5dcfc298adba
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/306759/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/contrib/gate_hook.sh'],1,7c050a3372c68e0497d110e112988165763a8f4d,switch-case,"case $VENV in ""dsvm-functional""|""dsvm-fullstack"") ;; ""api""|""api-pecan""|""full-pecan""|""dsvm-scenario"") if [[ ""$VENV"" =~ ""pecan"" ]]; then load_conf_hook pecan fi ;; *) echo ""Unrecognized environment $VENV"". exit 1 esac","if [ ""$VENV"" == ""dsvm-functional"" ] || [ ""$VENV"" == ""dsvm-fullstack"" ] then elif [ ""$VENV"" == ""api"" -o ""$VENV"" == ""api-pecan"" -o ""$VENV"" == ""full-pecan"" -o ""$VENV"" == ""dsvm-scenario"" ] then if [ ""$VENV"" == ""api-pecan"" -o ""$VENV"" == ""full-pecan"" ] then load_conf_hook pecan fifi",13,9
openstack%2Fopenstack-doc-tools~master~I25eb76c97fe79a4bde966e409b17a70e6dd98ece,openstack/openstack-doc-tools,master,I25eb76c97fe79a4bde966e409b17a70e6dd98ece,DO NOT MERGE: Testing requirements job,ABANDONED,2016-05-04 19:56:56.000000000,2016-05-05 20:00:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 19:56:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/abcbd1e88a908fa711cd56e44b0fa8f6a067e3c7', 'message': 'DO NOT MERGE: Testing requirements job\n\nChange-Id: I25eb76c97fe79a4bde966e409b17a70e6dd98ece\n'}]",0,312722,abcbd1e88a908fa711cd56e44b0fa8f6a067e3c7,4,2,1,6547,,,0,"DO NOT MERGE: Testing requirements job

Change-Id: I25eb76c97fe79a4bde966e409b17a70e6dd98ece
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/22/312722/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,abcbd1e88a908fa711cd56e44b0fa8f6a067e3c7,testing,lxml,lxml>=2.3 # BSD,1,1
openstack%2Fpuppet-openstack-guide~master~I5f40a5c881a255f917619759ae4ef65ed03e2605,openstack/puppet-openstack-guide,master,I5f40a5c881a255f917619759ae4ef65ed03e2605,add functional testing doc,ABANDONED,2016-05-03 23:18:20.000000000,2016-05-05 19:54:53.000000000,,"[{'_account_id': 3}, {'_account_id': 15519}]","[{'number': 1, 'created': '2016-05-03 23:18:20.000000000', 'files': ['doc/source/functional-testing.rst'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-guide/commit/7b60dad7d9187cb6aa56715b283130b5d48205f3', 'message': 'add functional testing doc\n\nChange-Id: I5f40a5c881a255f917619759ae4ef65ed03e2605\n'}]",1,312282,7b60dad7d9187cb6aa56715b283130b5d48205f3,4,2,1,6721,,,0,"add functional testing doc

Change-Id: I5f40a5c881a255f917619759ae4ef65ed03e2605
",git fetch https://review.opendev.org/openstack/puppet-openstack-guide refs/changes/82/312282/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/functional-testing.rst'],1,7b60dad7d9187cb6aa56715b283130b5d48205f3,docs_migration,"The best reference for getting started with beaker can be found `here <https://github.com/puppetlabs/beaker/wiki>`__. Running local tests ------------------- The following script can invoked from any if the modules' directories to run their beaker tests. It assumes that both bundler as well as rubygems (and ruby) are already installed on the system. It will prepare the system and run beaker tests on the system. It's suggested to use a virtual machine for development. | .. code:: bash #!/bin/bash if [ -f /usr/bin/yum ]; then sudo yum -y install libxml2-devel libxslt-devel ruby-devel sudo yum -y groupinstall ""Development Tools"" OS_TYPE='centos7' elif [ -f /usr/bin/apt-get ]; then sudo apt-get update sudo apt-get install -y libxml2-dev libxslt-dev zlib1g-dev git ruby ruby-dev build-essential OS_TYPE='trusty' fi echo """" | sudo tee -a /etc/ssh/sshd_config echo ""Match address 127.0.0.1"" | sudo tee -a /etc/ssh/sshd_config echo "" PermitRootLogin without-password"" | sudo tee -a /etc/ssh/sshd_config echo """" | sudo tee -a /etc/ssh/sshd_config echo ""Match address ::1"" | sudo tee -a /etc/ssh/sshd_config echo "" PermitRootLogin without-password"" | sudo tee -a /etc/ssh/sshd_config mkdir -p .ssh ssh-keygen -f ~/.ssh/id_rsa -b 2048 -C ""beaker key"" -P """" sudo mkdir -p /root/.ssh sudo rm /root/.ssh/authorized_keys cat ~/.ssh/id_rsa.pub | sudo tee -a /root/.ssh/authorized_keys if [ -f /usr/bin/yum ]; then sudo systemctl restart sshd elif [ -f /usr/bin/apt-get ]; then sudo service ssh restart fi sudo gem install bundler --no-rdoc --no-ri --verbose mkdir .bundled_gems export GEM_HOME=`pwd`/.bundled_gems bundle install export BEAKER_set=nodepool-$OS_TYPE export BEAKER_debug=yes bundle exec rspec spec/acceptance | The last command runs beaker tests by installing & testing the OpenStack service. ",,54,0
openstack%2Fpuppet-openstack-guide~master~Idb36e5c2451e1cae3e088ec87b28e57a89cb5dd7,openstack/puppet-openstack-guide,master,Idb36e5c2451e1cae3e088ec87b28e57a89cb5dd7,add ci doc,ABANDONED,2016-05-03 23:27:49.000000000,2016-05-05 19:54:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6721}, {'_account_id': 10873}, {'_account_id': 15519}]","[{'number': 1, 'created': '2016-05-03 23:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-guide/commit/2ce7458105a10fa1471012d08619e7e991de7253', 'message': 'add ci + tripleo-puppet-ci docs\n\nChange-Id: Idb36e5c2451e1cae3e088ec87b28e57a89cb5dd7\n'}, {'number': 2, 'created': '2016-05-03 23:29:57.000000000', 'files': ['doc/source/ci.rst'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-guide/commit/b14613d2cebeef30cb03651f49c2a3c8b7cbf2c2', 'message': 'add ci doc\n\nChange-Id: Idb36e5c2451e1cae3e088ec87b28e57a89cb5dd7\n'}]",0,312285,b14613d2cebeef30cb03651f49c2a3c8b7cbf2c2,10,4,2,6721,,,0,"add ci doc

Change-Id: Idb36e5c2451e1cae3e088ec87b28e57a89cb5dd7
",git fetch https://review.opendev.org/openstack/puppet-openstack-guide refs/changes/85/312285/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ci.rst', 'doc/source/tripleo-puppet-ci.rst']",2,2ce7458105a10fa1471012d08619e7e991de7253,docs_migration,"TripleO Puppet CI ----------------- A description of our TripleO Puppet CI job, what it does, and how to interpret results. The job is loosely based around our TripleO devtest scripts with some extra Puppet environment variables which are described here in detail: http://docs.openstack.org/developer/tripleo-incubator/puppet.html If you are a developer looking to setup your own TripleO Puppet environment the above link is probably what you want. The Environment (where the CI jobs run) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ TripleO CI is built around a normal OpenStack cloud which is attached to nodepool and is used to spin up Jenkins slaves for each job. This Jenkins slave is used to build images, and launch various devtest scripts from the tripleo-incubator project, etc. Because the Jenkins slave is itself a virtual machine (and we aren't running nested virt in our OpenStack cloud) we need to have something else to provide extra fake ""baremetal"" virtual machines for testing. We use a separate cluster of test environment (testenv) machines for this which are essentially baremetal machines with pre-created virtual machine groups. So while the Jenkins slave is used to build images, and launch various scripts driving the CI process the actual VMs themselves are running on a separate testenv ""cloud"" that is hosted on a separate baremetal server. For over a year now our CI clouds have been running jobs in this fashion with a split OpenStack and testenv based configuration which supports everything we need to test TripleO in various deployments (including HA). Eventually the goal is to be able to host our TripleO CI needs entirely on OpenStack itself. This effort is described here: `QuintupleO <http://specs.openstack.org/openstack/tripleo-specs/specs/juno/tripleo-on-openstack.html>`__. Simply put this is adding a couple extra features to various OpenStack components (Nova, and Neutron) to support booting ""baremetal"" instances in the OpenStack cloud itself. How does a Puppet CI job work ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The following steps describe how Puppet CI jobs flow in TripleO. - Jenkins slave is launched - A test environment is acquired from the Geard broker. This provides a set of fake ""baremetal"" VMs for testing. - A ""seed"" image is built. The seed is a special kind of undercloud (to launch baremetal instances) that runs entirely in a virtual machine. - The seed VM is launched. Ironic on the seed is configured to use the rest of the fake ""baremetal"" VMs in the testenv in order to spawn its instances. - Overcloud images are built, one controller image, and one compute image. At this time we are pre-installing OpenStack packages into our images. This aligns well with the normal TripleO process and allows our CI jobs to run because testenv machines have no external network connectivity they cannot download packages at deployment time currently. - Puppet modules get installed into image at image build time via the `puppet-modules <http://git.openstack.org/cgit/openstack/tripleo-puppet-elements/tree/elements/puppet-modules>`__ element. Although the CI job for puppet uses packages to install most things Puppet modules are installed via Git directly by setting DIB\_INSTALLTYPE\_puppet\_modules=source. - The Overcloud is created by Heat. This is where most of the interesting puppet stuff happens and is driven by the tripleo-heat-templates project (which contains most of the TripleO Puppet work). During the Heat stack creation process the following happens: - ""Baremetal"" nodes are deployed via Nova and Ironic - Once the node boots a metadata agent called os-collect-config gathers metadata provided by Heat and invokes puppet hooks. This process may occur multiple times depending on the node/role and is controlled by Heat dependencies which gradually supply metadata to drive specific puppet deployment tasks. - When each Puppet Heat deployment task is finished it signals back to Heat to indicate it has finished along with any SUCCESS or FAILURE state. - Heat continues this process to until all resources reach a completion state or an error occurs. - Once Heat finished running the Overcloud is configured by the normal TripleO cloud configuration tools (os-cloud-config). This process creates neutron networks, keystone tenants, etc. - After the overcloud has been configured an instance is booted on the Overcloud as a test to make sure everything is working. The instance is booted using a volume backend (this helps us test Cinder is working). The instance is then assigned a floating IP which we ping test to ensure connectivity. - If all this works the job is a success. Interpreting results (when things go wrong) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The first place to start when trying to interpret output of a failed TripleO CI job is the console.log file for the job. This script contains the high level output from our test scripts and should give you a general idea of where the job is failing. Things to look for in this file include: - Did the seed image build? (this is a disk-image-create command to create the seed image) - Did the seed image launch and get configured successfully? - Did the Overcloud images build? (right now we build two overcloud images: one for compute, and one image for the controller) - Did the Overcloud 'heat stack-create' command complete successfully? (this is where most of the Puppet work happens and a failure here may indicate a Puppet issue). If you notice that the Heat stack for the Overcloud failed to get created successfully the next step is too look at the output of the **'heat event-list overcloud**' and **'heat resource-list overcloud**' commands in console.log. These should help indicate the node/role that had configuration errors at deployment time. So for example if you see a Heat event fail for one of the Compute nodes might then look at the specific logs for that node to determine more information about the failure (for example if a service fails to start, etc.) The 'logs' directory contains sub directories for each role that was created. NOTE: if you don't see logs for a specific role it likely means Ironic deployment didn't complete successfully (probably not a puppet specific issue) or... perhaps there is an issue related to capturing log output in our CI job (it happens). So you've identified what you think is a puppet error and you've found the relevant node logs for that machine... **the log to check is probably the os-collect-config.log file**. Since os-collect-config collects metadata, and runs os-refresh-config puppet hooks it contains the direct output from the 'puppet apply' commands that get executed along with each Heat deployment. This output should help indicate where the exact problem occurred. You may also need to look at other OpenStack service logs on this node to determine more information and help diagnose specific configuration related issues. How do I make changes to the Puppet CI ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ We have our own CI project called `tripleo-ci <http://git.openstack.org/cgit/openstack-infra/tripleo-ci/>`__. The toci\_gate\_test.sh script in this project is used to drive our CI configuration directly and corresponds to the TripleO CI jobs we configure in openstack-infra via Zuul. Useful links ~~~~~~~~~~~~ - `JobTemplate <http://git.openstack.org/cgit/openstack-infra/project-config/tree/jenkins/jobs/tripleo.yaml>`__ - `JobParameters <http://git.openstack.org/cgit/openstack-infra/project-config/tree/jenkins/jobs/projects.yaml#n315>`__ - `Zuul <http://git.openstack.org/cgit/openstack-infra/project-config/tree/zuul/layout.yaml#n2628>`__ ",,176,0
openstack%2Fpuppet-ironic~stable%2Fmitaka~Id157b4b828958cfac945aecdff46d2fb1be5f984,openstack/puppet-ironic,stable/mitaka,Id157b4b828958cfac945aecdff46d2fb1be5f984,Prepare module for publication to the forge,MERGED,2016-05-03 20:34:35.000000000,2016-05-05 19:53:40.000000000,2016-05-05 19:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2016-05-03 20:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/d45acfa2f6314ac9e01322b29e1b2bd2395a3631', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Id157b4b828958cfac945aecdff46d2fb1be5f984\n""}, {'number': 2, 'created': '2016-05-03 22:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/b170dfe2a1ca307aaae34f4c21f9cb1c9d5d3786', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Id157b4b828958cfac945aecdff46d2fb1be5f984\n""}, {'number': 3, 'created': '2016-05-04 18:27:49.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/64e4b9844d9e8f0c3b0caa3edf6ce0e43225e228', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Id157b4b828958cfac945aecdff46d2fb1be5f984\n""}]",1,312242,64e4b9844d9e8f0c3b0caa3edf6ce0e43225e228,24,5,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Id157b4b828958cfac945aecdff46d2fb1be5f984
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/42/312242/3 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,d45acfa2f6314ac9e01322b29e1b2bd2395a3631,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",8,8
openstack%2Fpuppet-keystone~stable%2Fmitaka~I1ea0317e69a1243798ca997bcdc98595a54563ca,openstack/puppet-keystone,stable/mitaka,I1ea0317e69a1243798ca997bcdc98595a54563ca,Prepare module for publication to the forge,MERGED,2016-05-03 16:04:21.000000000,2016-05-05 19:48:05.000000000,2016-05-05 19:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2016-05-03 16:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e68e711d077d39d830005cc171774f6f197e9174', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I1ea0317e69a1243798ca997bcdc98595a54563ca\n""}, {'number': 2, 'created': '2016-05-03 22:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ee4d1268e6267815ba72b7c93946086900e2e004', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I1ea0317e69a1243798ca997bcdc98595a54563ca\n""}, {'number': 3, 'created': '2016-05-04 18:27:15.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/30032ac35b1ce9f693190f1e2a4cdfc6ac18e55b', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I1ea0317e69a1243798ca997bcdc98595a54563ca\n""}]",0,312141,30032ac35b1ce9f693190f1e2a4cdfc6ac18e55b,23,6,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I1ea0317e69a1243798ca997bcdc98595a54563ca
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/41/312141/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,e68e711d077d39d830005cc171774f6f197e9174,prep_for_forge," ""version"": ""8.0.1"", ""description"": ""Installs and configures OpenStack Keystone (Identity)."", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.8.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] ""description"": ""Installs and configures OpenStack Keystone (Identity)."", { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.2.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",10,10
openstack%2Fpuppet-openstacklib~stable%2Fmitaka~I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43,openstack/puppet-openstacklib,stable/mitaka,I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43,Prepare module for publication to the forge,MERGED,2016-05-03 15:56:47.000000000,2016-05-05 19:46:24.000000000,2016-05-05 19:46:24.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 8971}, {'_account_id': 13908}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 15:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/52ada3d8442266a17cdf82d9c5afdaebb78f4b60', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\nChange-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43\n""}, {'number': 2, 'created': '2016-05-03 15:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/efc0077c5662bdbeda6cf0f5cc904aee5f36fcc5', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\nChange-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43\n""}, {'number': 3, 'created': '2016-05-03 16:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/08394ec9953e75ba6cdf19695437640ff090395b', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43\n""}, {'number': 4, 'created': '2016-05-03 22:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/14bf22af9a67c0fe1df1a26459a984efac0b1650', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43\n""}, {'number': 5, 'created': '2016-05-04 18:27:11.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/f2fd10dd5927ab106331ed4a5172df6f127aacc5', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43\n""}]",0,312133,f2fd10dd5927ab106331ed4a5172df6f127aacc5,27,6,5,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I92b0f8757d2b7f45bfd5a3ae4f4ac50366f8fb43
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/33/312133/4 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,52ada3d8442266a17cdf82d9c5afdaebb78f4b60,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""7"", ""8""] ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.8.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/mysql"", ""version_requirement"": "">=3.6.0 <4.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=5.3.1 <6.0.0"" }, { ""name"": ""puppetlabs/postgresql"", ""version_requirement"": "">=4.6.0 <5.0.0"" }"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""7""] ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/mysql"", ""version_requirement"": "">=3.0.0 <4.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=2.0.2 <6.0.0"" }, { ""name"": ""puppetlabs/postgresql"", ""version_requirement"": "">=3.3.0 <4.0.0"" }",13,13
openstack%2Fpuppet-ceilometer~stable%2Fmitaka~I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee,openstack/puppet-ceilometer,stable/mitaka,I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee,Prepare module for publication to the forge,MERGED,2016-05-03 20:24:05.000000000,2016-05-05 19:43:40.000000000,2016-05-05 19:09:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 20:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/f2c29d32c89aa5c9bfeb4a9cb9ce900044ac806e', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee\n""}, {'number': 2, 'created': '2016-05-03 22:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/9682943e74dd9d6bbf4ff253e4a538abd6ea4991', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee\n""}, {'number': 3, 'created': '2016-05-04 18:27:46.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/092b22ac11b2f7d09a1f94b541b770cc41833ae8', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee\n""}]",0,312236,092b22ac11b2f7d09a1f94b541b770cc41833ae8,19,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I7f8ae588f2f16c8cbdf50feec8c662e34dd5efee
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/36/312236/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,f2c29d32c89aa5c9bfeb4a9cb9ce900044ac806e,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.8.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",9,9
openstack%2Fpython-openstackclient~master~I837652013f94b0d1ed3f4b40fe14ce5a47c687b6,openstack/python-openstackclient,master,I837652013f94b0d1ed3f4b40fe14ce5a47c687b6,bump timeout to prevent gate failures,MERGED,2016-05-05 16:20:24.000000000,2016-05-05 19:42:44.000000000,2016-05-05 19:42:44.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-05 16:20:24.000000000', 'files': ['functional/tests/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/461a203f2d0e653eabe9a023cfdbe90669ff0618', 'message': 'bump timeout to prevent gate failures\n\nattempt to fix the transient gate failures by increasing the\ntimeout\n\nChange-Id: I837652013f94b0d1ed3f4b40fe14ce5a47c687b6\n'}]",0,313044,461a203f2d0e653eabe9a023cfdbe90669ff0618,7,3,1,6482,,,0,"bump timeout to prevent gate failures

attempt to fix the transient gate failures by increasing the
timeout

Change-Id: I837652013f94b0d1ed3f4b40fe14ce5a47c687b6
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/44/313044/1 && git format-patch -1 --stdout FETCH_HEAD,['functional/tests/compute/v2/test_server.py'],1,461a203f2d0e653eabe9a023cfdbe90669ff0618,gate_timeout," def wait_for_status(self, expected_status='ACTIVE', wait=900, interval=30):"," def wait_for_status(self, expected_status='ACTIVE', wait=600, interval=30):",1,1
openstack%2Fpython-openstackclient~master~I49fac32a3322dae31a9dd24c6447ab55b000aff1,openstack/python-openstackclient,master,I49fac32a3322dae31a9dd24c6447ab55b000aff1,Fix incorrect format returned when data is None,ABANDONED,2016-04-04 04:48:57.000000000,2016-05-05 19:40:37.000000000,,"[{'_account_id': 3}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-04-04 04:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/593ff70159bc8add42af6483f506e36b5aa624fd', 'message': ""Fix incorrect format returned when data is None\n\nWhen result data is None type, openstack client will display\n'None' in stdout. This is not the same as other client handles\nvalue display as '-'. This fix aim to correct returned format\nas another client.\n\nChange-Id: I49fac32a3322dae31a9dd24c6447ab55b000aff1\nCloses-Bug: #1538002\n""}, {'number': 2, 'created': '2016-04-04 07:03:41.000000000', 'files': ['openstackclient/tests/network/v2/fakes.py', 'openstackclient/tests/network/v2/test_subnet.py', 'openstackclient/tests/identity/v3/fakes.py', 'openstackclient/tests/volume/v2/fakes.py', 'openstackclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/029c69f89c67c157de2251c907263f3f3b3d7b89', 'message': ""Fix incorrect format returned when data is None\n\nWhen result data is None type, openstack client will display\n'None' in stdout. This is not the same as other client handles\nvalue display as '-'. This fix aim to correct returned format\nas another client.\n\nChange-Id: I49fac32a3322dae31a9dd24c6447ab55b000aff1\nCloses-Bug: #1538002\n""}]",0,300934,029c69f89c67c157de2251c907263f3f3b3d7b89,6,2,2,19741,,,0,"Fix incorrect format returned when data is None

When result data is None type, openstack client will display
'None' in stdout. This is not the same as other client handles
value display as '-'. This fix aim to correct returned format
as another client.

Change-Id: I49fac32a3322dae31a9dd24c6447ab55b000aff1
Closes-Bug: #1538002
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/34/300934/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/utils.py'],1,593ff70159bc8add42af6483f506e36b5aa624fd,bug/1538002, if data is None: data = '-',,2,0
openstack%2Ftripleo-quickstart~master~I5bde5b96ea335b4a2e0f7081ce8296cabc3134e3,openstack/tripleo-quickstart,master,I5bde5b96ea335b4a2e0f7081ce8296cabc3134e3,Template network-environment.yml with undercloud-scripts tag,MERGED,2016-05-04 20:37:14.000000000,2016-05-05 19:34:53.000000000,2016-05-05 19:34:53.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 8745}, {'_account_id': 9592}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-05-04 20:37:14.000000000', 'files': ['playbooks/roles/tripleo/undercloud/tasks/post-install.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/78b9beba39c6f88b5291498f47c8be02bbde8797', 'message': 'Template network-environment.yml with undercloud-scripts tag\n\nWe need to have the network-environment.yml file for the\nability to run with the default tags, and then run each\nscript on the undercloud manually.\n\nChange-Id: I5bde5b96ea335b4a2e0f7081ce8296cabc3134e3\nCloses-Bug: 1578368\n'}]",0,312730,78b9beba39c6f88b5291498f47c8be02bbde8797,14,5,1,12715,,,0,"Template network-environment.yml with undercloud-scripts tag

We need to have the network-environment.yml file for the
ability to run with the default tags, and then run each
script on the undercloud manually.

Change-Id: I5bde5b96ea335b4a2e0f7081ce8296cabc3134e3
Closes-Bug: 1578368
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/30/312730/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/tripleo/undercloud/tasks/post-install.yml'],1,78b9beba39c6f88b5291498f47c8be02bbde8797,bug/1578368, tags: - undercloud-scripts,,2,0
openstack%2Fpuppet-nova~stable%2Fmitaka~Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0,openstack/puppet-nova,stable/mitaka,Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0,Prepare module for publication to the forge,MERGED,2016-05-03 18:43:29.000000000,2016-05-05 19:27:19.000000000,2016-05-05 19:27:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 18:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5a4fbd097493b5ad73249c2874d55be7ff400311', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0\n""}, {'number': 2, 'created': '2016-05-03 22:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5652332425c1786a8b5d9b78a6debc646e0d34b7', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0\n""}, {'number': 3, 'created': '2016-05-04 18:27:22.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d8ccff21911d27e8367db1bc684ed543981de01c', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0\n""}]",0,312204,d8ccff21911d27e8367db1bc684ed543981de01c,20,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Idba76a7876ca5c39c28e0ae06bd5954e800a3ca0
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/04/312204/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,5a4fbd097493b5ad73249c2874d55be7ff400311,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.8.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=5.3.1 <6.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""dprince/qpid"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=2.0.2 <6.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",10,11
openstack%2Fpuppet-sahara~stable%2Fmitaka~Ic4458192b8594c78b7851bb1b8aac0a4e3a66079,openstack/puppet-sahara,stable/mitaka,Ic4458192b8594c78b7851bb1b8aac0a4e3a66079,Prepare module for publication to the forge,MERGED,2016-05-03 20:05:55.000000000,2016-05-05 19:26:00.000000000,2016-05-05 18:51:01.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 20:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/a44894c27e5ad56fb2371a194b4cc36c65fb58c7', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ic4458192b8594c78b7851bb1b8aac0a4e3a66079\n""}, {'number': 2, 'created': '2016-05-03 22:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/636c6ea269d6e91a4b767ad612119c1e619bf7c4', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ic4458192b8594c78b7851bb1b8aac0a4e3a66079\n""}, {'number': 3, 'created': '2016-05-04 18:27:39.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/ea2efa73cc1d4e0f259303c7c1a7c90dc5df584f', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ic4458192b8594c78b7851bb1b8aac0a4e3a66079\n""}]",0,312228,ea2efa73cc1d4e0f259303c7c1a7c90dc5df584f,19,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Ic4458192b8594c78b7851bb1b8aac0a4e3a66079
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/28/312228/3 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,a44894c27e5ad56fb2371a194b4cc36c65fb58c7,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystem"": ""Debian"", ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"", ""22"", ""23""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""6.5"", ""7""] }, { ""operatingsystem"": ""Ubuntu"", ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }, { ""name"": ""puppetlabs/postgresql"", ""version_requirement"": "">=4.6.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""20""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystem"": ""Debian"", ""operatingsystemrelease"": [""8""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }, { ""name"": ""puppetlabs/postgresql"", ""version_requirement"": "">=3.0.0"" },",17,13
openstack%2Fproject-config~master~I3c5e145115206b773466a74d63fad84da17f25e5,openstack/project-config,master,I3c5e145115206b773466a74d63fad84da17f25e5,Translations: Publish pot files to tarballs.o.o,MERGED,2016-04-22 19:21:38.000000000,2016-05-05 19:22:14.000000000,2016-05-05 19:22:13.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-04-22 19:21:38.000000000', 'files': ['jenkins/jobs/translation-jobs.yaml', 'jenkins/scripts/upstream_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a36d40fc3d0988ab14ebf54d9e972b2aa8e5cda', 'message': 'Translations: Publish pot files to tarballs.o.o\n\nPublish all pot files to\ntarballs.openstack.org/translation-source/{name}/VERSION\n\nThis way we have always the most recent pot files available for\nreviewers and can remove them from the git repositories in a followup.\n\nChange-Id: I3c5e145115206b773466a74d63fad84da17f25e5\n'}]",0,309560,4a36d40fc3d0988ab14ebf54d9e972b2aa8e5cda,10,4,1,6547,,,0,"Translations: Publish pot files to tarballs.o.o

Publish all pot files to
tarballs.openstack.org/translation-source/{name}/VERSION

This way we have always the most recent pot files available for
reviewers and can remove them from the git repositories in a followup.

Change-Id: I3c5e145115206b773466a74d63fad84da17f25e5
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/309560/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/translation-jobs.yaml', 'jenkins/scripts/upstream_translation_update.sh']",2,4a36d40fc3d0988ab14ebf54d9e972b2aa8e5cda,publish-pots," # Copy all *.pot files to pot-files directory mkdir -p .pot-files/$ZANATA_VERSION/ # Exclude . directories find . -path ""./.*"" -prune -o -name ""*.pot"" -exec cp -v {} .pot-files \; mv .pot-files pot-files",,11,0
openstack%2Fpuppet-horizon~stable%2Fmitaka~If22e792acf1a82a1768257fc2a05ad1d115ab6a4,openstack/puppet-horizon,stable/mitaka,If22e792acf1a82a1768257fc2a05ad1d115ab6a4,Prepare module for publication to the forge,MERGED,2016-05-03 19:58:24.000000000,2016-05-05 19:18:01.000000000,2016-05-05 18:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/2d2dccbcaa054c6da874d9ef32fbc790848180bb', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: If22e792acf1a82a1768257fc2a05ad1d115ab6a4\n""}, {'number': 2, 'created': '2016-05-03 22:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/1522611ee467109a463a4e1342ef6407c411370a', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: If22e792acf1a82a1768257fc2a05ad1d115ab6a4\n""}, {'number': 3, 'created': '2016-05-04 18:27:36.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/1440c412e7d55014bc32c8c5df5471fe3a31773d', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: If22e792acf1a82a1768257fc2a05ad1d115ab6a4\n""}]",0,312223,1440c412e7d55014bc32c8c5df5471fe3a31773d,20,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: If22e792acf1a82a1768257fc2a05ad1d115ab6a4
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/23/312223/2 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,2d2dccbcaa054c6da874d9ef32fbc790848180bb,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.8.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }, { ""name"": ""saz/memcached"", ""version_requirement"": "">=2.8.1 <3.0.0"" }"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/apache"", ""version_requirement"": "">=1.2.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }, { ""name"": ""saz/memcached"", ""version_requirement"": "">=2.0.2 <3.0.0"" }",9,9
openstack%2Fpython-swiftclient~master~I4616492752b620de0bf90672142f1071ec9bac83,openstack/python-swiftclient,master,I4616492752b620de0bf90672142f1071ec9bac83,Default to v3 auth if we find a (user|project)-domain-(name|id) option,MERGED,2016-04-27 21:47:38.000000000,2016-05-05 19:16:45.000000000,2016-05-05 19:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9216}]","[{'number': 1, 'created': '2016-04-27 21:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/aea20d4ac9ad654d55f7215585bac429af5791f1', 'message': 'Default to v3 auth if we find a (user|project)-domain-(name|id) option\n\nChange-Id: I4616492752b620de0bf90672142f1071ec9bac83\n'}, {'number': 2, 'created': '2016-05-03 21:46:39.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_shell.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/67f629cdeb4e4c9fcb858167091f1c00c69c87f4', 'message': 'Default to v3 auth if we find a (user|project)-domain-(name|id) option\n\nChange-Id: I4616492752b620de0bf90672142f1071ec9bac83\n'}]",4,310596,67f629cdeb4e4c9fcb858167091f1c00c69c87f4,13,3,2,15343,,,0,"Default to v3 auth if we find a (user|project)-domain-(name|id) option

Change-Id: I4616492752b620de0bf90672142f1071ec9bac83
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/96/310596/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_shell.py']",2,aea20d4ac9ad654d55f7215585bac429af5791f1,detect-v3," self.defaults['auth-version'] = '3' self._test_options(opts, os_opts, flags=self.flags) for o in ('user-domain-name', 'user-domain-id', 'project-domain-name', 'project-domain-id'): os_opts.pop(o) self.defaults['auth-version'] = '2.0' # ...except when it should be 3 self.defaults['auth-version'] = '3' keys = ('username', 'user-domain-name', 'password', 'project-name', 'auth-url') os_opts = self._build_os_opts(keys) self._test_options(opts, os_opts) keys = ('username', 'user-domain-id', 'password', 'project-name', 'auth-url') os_opts = self._build_os_opts(keys) self._test_options(opts, os_opts) keys = ('username', 'project-domain-name', 'password', 'project-name', 'auth-url') os_opts = self._build_os_opts(keys) self._test_options(opts, os_opts) keys = ('username', 'project-domain-id', 'password', 'project-name', 'auth-url') os_opts = self._build_os_opts(keys) self._test_options(opts, os_opts) ",,44,7
openstack%2Fkolla-kubernetes~master~I0fe6be730286193431e9b25f1f8ed59b56faae39,openstack/kolla-kubernetes,master,I0fe6be730286193431e9b25f1f8ed59b56faae39,Update for successful pep8,MERGED,2016-05-05 16:50:39.000000000,2016-05-05 19:16:06.000000000,2016-05-05 19:16:06.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 10419}]","[{'number': 1, 'created': '2016-05-05 16:50:39.000000000', 'files': ['kolla_kubernetes/tests/base.py', 'kolla_kubernetes/tests/test_kolla_kubernetes.py', 'kolla_kubernetes/tests/__init__.py', 'kolla_kubernetes/__init__.py'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/0e278fdc0793c9d6f4c33ce5776febdad79f251d', 'message': 'Update for successful pep8\n\nTrivial-Fix\nChange-Id: I0fe6be730286193431e9b25f1f8ed59b56faae39\n'}]",0,313054,0e278fdc0793c9d6f4c33ce5776febdad79f251d,8,4,1,11105,,,0,"Update for successful pep8

Trivial-Fix
Change-Id: I0fe6be730286193431e9b25f1f8ed59b56faae39
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/54/313054/1 && git format-patch -1 --stdout FETCH_HEAD,"['kolla_kubernetes/tests/base.py', 'kolla_kubernetes/tests/__init__.py', 'kolla_kubernetes/tests/test_kolla_kubernetes.py', 'kolla_kubernetes/__init__.py']",4,0e278fdc0793c9d6f4c33ce5776febdad79f251d,,,,2,2
openstack%2Fopenstack-ansible-security~liberty~I33a6f9ab1aecf28e82ea756e41c482820758157f,openstack/openstack-ansible-security,liberty,I33a6f9ab1aecf28e82ea756e41c482820758157f,Add dependencies for paramiko 2.0,MERGED,2016-05-05 14:50:05.000000000,2016-05-05 19:15:17.000000000,2016-05-05 19:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-05 14:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/feabcbaeba5e5a137a8a6698cf39c4a87fc577c9', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I33a6f9ab1aecf28e82ea756e41c482820758157f\n(cherry picked from commit 19999b4ed8b87c3965a830a751a91cd324c424bd)\n'}, {'number': 2, 'created': '2016-05-05 15:34:34.000000000', 'files': ['.gitignore', 'test-requirements.txt', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', 'run_tests.sh', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/mitaka.rst', 'other-requirements.txt', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/3bf6b329d2436f8051d0eb83b85de729ba34dc87', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nBackport note:\nRelease notes instrumentation has been added to the commit as neither\nthis patch nor one focused on releasenotes alone will merge\nindependently.\n\nChange-Id: I33a6f9ab1aecf28e82ea756e41c482820758157f\n(cherry picked from commit 19999b4ed8b87c3965a830a751a91cd324c424bd)\n'}]",0,313007,3bf6b329d2436f8051d0eb83b85de729ba34dc87,11,4,2,17068,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Backport note:
Release notes instrumentation has been added to the commit as neither
this patch nor one focused on releasenotes alone will merge
independently.

Change-Id: I33a6f9ab1aecf28e82ea756e41c482820758157f
(cherry picked from commit 19999b4ed8b87c3965a830a751a91cd324c424bd)
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/07/313007/2 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,feabcbaeba5e5a137a8a6698cf39c4a87fc577c9,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fpuppet-neutron~stable%2Fmitaka~I0166d294fb9a775d046145a4da302324f4f0f642,openstack/puppet-neutron,stable/mitaka,I0166d294fb9a775d046145a4da302324f4f0f642,Prepare module for publication to the forge,MERGED,2016-05-03 19:33:28.000000000,2016-05-05 19:10:00.000000000,2016-05-05 19:10:00.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 19:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c23ef6d72ba3719eef845cef2c8937d997b0a600', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0166d294fb9a775d046145a4da302324f4f0f642\n""}, {'number': 2, 'created': '2016-05-03 22:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0bb460633357f1640e37e4ec2064e5ecb091bf0b', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0166d294fb9a775d046145a4da302324f4f0f642\n""}, {'number': 3, 'created': '2016-05-04 18:27:29.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/dee072b3c7633f5e4aa28e55e83fd1d5ad99e321', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0166d294fb9a775d046145a4da302324f4f0f642\n""}]",0,312213,dee072b3c7633f5e4aa28e55e83fd1d5ad99e321,19,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I0166d294fb9a775d046145a4da302324f4f0f642
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/13/312213/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,c23ef6d72ba3719eef845cef2c8937d997b0a600,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",8,8
openstack%2Fpuppet-tempest~stable%2Fmitaka~I4d3e5785102eb1046ab6d66434ce9534a2354630,openstack/puppet-tempest,stable/mitaka,I4d3e5785102eb1046ab6d66434ce9534a2354630,Prepare module for publication to the forge,MERGED,2016-05-03 20:51:27.000000000,2016-05-05 19:09:53.000000000,2016-05-05 19:09:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 20:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/672fbca4c994175a958a4281efe156b78ad4f156', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I4d3e5785102eb1046ab6d66434ce9534a2354630\n""}, {'number': 2, 'created': '2016-05-03 22:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/aa40269b7048d04fd28a5c5e5e49362757356822', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I4d3e5785102eb1046ab6d66434ce9534a2354630\n""}, {'number': 3, 'created': '2016-05-04 18:27:56.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/dbafafa1f47a66e08cd8e7694a739dade1d58fdf', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I4d3e5785102eb1046ab6d66434ce9534a2354630\n""}]",0,312246,dbafafa1f47a66e08cd8e7694a739dade1d58fdf,15,3,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I4d3e5785102eb1046ab6d66434ce9534a2354630
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/46/312246/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,672fbca4c994175a958a4281efe156b78ad4f156,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" }, { ""name"": ""puppetlabs/vcsrepo"", ""version_requirement"": "">=1.3.0 <2.0.0""},"," ""version"": ""8.0.0"", {""name"": ""pe"",""version_requirement"": ""3.x""}, {""name"": ""puppet"",""version_requirement"": ""3.x""} ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" }, { ""name"": ""puppetlabs/vcsrepo"", ""version_requirement"": "">=0.1.2 <2.0.0""},",9,9
openstack%2Fpuppet-heat~stable%2Fmitaka~I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36,openstack/puppet-heat,stable/mitaka,I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36,Prepare module for publication to the forge,MERGED,2016-05-03 19:42:14.000000000,2016-05-05 19:09:50.000000000,2016-05-05 18:58:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 19:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/e4d23cb9868cde879a61af7a2a6e637e86d0fe0e', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36\n""}, {'number': 2, 'created': '2016-05-03 22:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/6e69a6547a657f5dea492ebb6b21945c0c703f32', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36\n""}, {'number': 3, 'created': '2016-05-04 18:27:33.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/67220bc853347c1bcb87c7f2687105964a15deb1', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36\n""}]",0,312220,67220bc853347c1bcb87c7f2687105964a15deb1,19,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I0805a1f7f581bb1a2d4d98ebb15668bf521e7a36
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/20/312220/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,e4d23cb9868cde879a61af7a2a6e637e86d0fe0e,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",8,8
openstack%2Fpuppet-glance~stable%2Fmitaka~I58a62f6dee8cadefa992a7528cb69644955a6cb5,openstack/puppet-glance,stable/mitaka,I58a62f6dee8cadefa992a7528cb69644955a6cb5,Prepare module for publication to the forge,MERGED,2016-05-03 18:54:48.000000000,2016-05-05 19:09:06.000000000,2016-05-05 19:09:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 18:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6142a5aebebbd2da3c7ced9433326ab5fa46c5a7', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I58a62f6dee8cadefa992a7528cb69644955a6cb5\n""}, {'number': 2, 'created': '2016-05-03 22:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/89acaecf6d5bf227e0de582ab327f28c68f833de', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I58a62f6dee8cadefa992a7528cb69644955a6cb5\n""}, {'number': 3, 'created': '2016-05-04 18:27:25.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7315a7615698167e57f494cd1f2c51e109478a93', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I58a62f6dee8cadefa992a7528cb69644955a6cb5\n""}]",0,312205,7315a7615698167e57f494cd1f2c51e109478a93,25,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I58a62f6dee8cadefa992a7528cb69644955a6cb5
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/05/312205/3 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,6142a5aebebbd2da3c7ced9433326ab5fa46c5a7,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.2.0 <5.0.0"" },",8,8
openstack%2Fproject-config~master~I45b8b194f73a832363d9f2310683de7f4fde5d79,openstack/project-config,master,I45b8b194f73a832363d9f2310683de7f4fde5d79,Add experimental ubuntu-precise infra jobs,MERGED,2016-05-05 17:09:31.000000000,2016-05-05 19:00:55.000000000,2016-05-05 19:00:54.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 17:09:31.000000000', 'files': ['jenkins/jobs/infra.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/97f228f83d8f20af248ef0ca8dc771c7ca660c91', 'message': 'Add experimental ubuntu-precise infra jobs\n\nIn an effort to replace bare-precise, lets add some experimental jobs\nto bindep and system-config to test ubuntu-precise.\n\nChange-Id: I45b8b194f73a832363d9f2310683de7f4fde5d79\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,313064,97f228f83d8f20af248ef0ca8dc771c7ca660c91,7,3,1,4162,,,0,"Add experimental ubuntu-precise infra jobs

In an effort to replace bare-precise, lets add some experimental jobs
to bindep and system-config to test ubuntu-precise.

Change-Id: I45b8b194f73a832363d9f2310683de7f4fde5d79
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/313064/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/infra.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",3,97f228f83d8f20af248ef0ca8dc771c7ca660c91,, experimental: - gate-{name}-bindep-fallback-ubuntu-precise experimental: - gate-infra-puppet-apply-ubuntu-precise,,6,0
openstack%2Fnova-specs~master~Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7,openstack/nova-specs,master,Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7,API changes for the multi-attach volume feature,ABANDONED,2015-11-30 13:20:07.000000000,2016-05-05 19:00:52.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 9562}]","[{'number': 1, 'created': '2015-11-30 13:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/96ff86766f73271ad86e928b18524f22d20654a6', 'message': 'API changes for the multi-attach volume feature\n\nThe API changes for the multiple volume attachment feature support in Nova.\n\nIt is a follow up spec for the Add support for shared volumes between guests:\nhttps://review.openstack.org/#/c/212508/\n\nChange-Id: Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7\n'}, {'number': 2, 'created': '2015-11-30 13:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dd2ed3e467e69a3e39d61da50d958a20d2f658ef', 'message': 'API changes for the multi-attach volume feature\n\nThe API changes for the multiple volume attachment feature support in Nova.\n\nIt is a follow up spec for the Add support for shared volumes between guests:\nhttps://review.openstack.org/#/c/212508/\n\nChange-Id: Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7\n'}, {'number': 3, 'created': '2015-12-02 22:42:23.000000000', 'files': ['specs/backlog/approved/multi-attach-volume-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a2da43df74694aba5fa0fa5e59db07a13b6a8c8b', 'message': 'API changes for the multi-attach volume feature\n\nThe API changes for the multiple volume attachment feature support in Nova.\n\nIt is a follow up spec for the Add support for shared volumes between guests:\nhttps://review.openstack.org/#/c/212508/\n\nChange-Id: Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7\n'}]",4,251349,a2da43df74694aba5fa0fa5e59db07a13b6a8c8b,12,3,3,9562,,,0,"API changes for the multi-attach volume feature

The API changes for the multiple volume attachment feature support in Nova.

It is a follow up spec for the Add support for shared volumes between guests:
https://review.openstack.org/#/c/212508/

Change-Id: Icd2a9b94234d3e95d800dc605ad6d7baff59eeb7
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/49/251349/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/approved/multi-attach-volume-api.rst'],1,96ff86766f73271ad86e928b18524f22d20654a6,bp/volume-multi-attach,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== API changes for Cinder Volume Multi-attach support ================================================== https://blueprints.launchpad.net/nova/+spec/multi-attach-volume Currently, Nova only allows a volume to be attached to a single host or instance. There are times when a user may want to be able to attach the same volume to multiple instances. Problem description =================== There is support for attaching a volume multiple times in Cinder and Nova is also modified to support this functionality. We need to address these changes on the Nova API also in order to provide the 'multiattach' flag in the API response, where the volume details are shown. Proposed change =============== As the volume attach and detach functions are fixed to support the multiple volume attachments we need to add the 'multiattach' flag to the corresponding Nova API responds to show which Cinder volume was created in a way to support this operation. Alternatives ------------ The only alternative is to not show the status of this flag on the Nova API. It's not a preferred solution long term. Data model impact ----------------- None REST API impact --------------- Adding ""multiattach"" flag to the API exposes the volume's capability for supporting multiple attachments at the same time. The ""multiattach"" flag will be introduced with new microversion in the v2.1 API. Add multiattach flag to response for GET /v2.1/{tenant_id}/os-volumes as well as for GET /v2.1/{tenant_id}/os-volumes/detail and GET os-volumes/{volume_id}. Example response:: { ""volumes"": [ { ""id"": ""521752a6-acf6-4b2d-bc7a-119f9148cd8c"", ""display_name"": ""vol-001"", ""display_description"": ""Another volume."", ""size"": 30, ""volume_type"": ""289da7f8-6440-407c-9fb4-7db01ec49164"", ""metadata"": { ""contents"": ""junk"" }, ""availability_zone"": ""us-east1"", ""snapshot_id"": null, ""attachments"": [], ""created_at"": ""2012-02-14T20:53:07Z"", ""multiattach"": false }, { ""id"": ""76b8950a-8594-4e5b-8dce-0dfa9c696358"", ""display_name"": ""vol-002"", ""display_description"": ""Yet another volume."", ""size"": 25, ""volume_type"": ""96c3bda7-c82a-4f50-be73-ca7621794835"", ""metadata"": {}, ""availability_zone"": ""us-east2"", ""snapshot_id"": null, ""attachments"": [], ""created_at"": ""2012-03-15T19:10:03Z"", ""multiattach"": true } ] } Add 'multiattach' flag to response for POST /v2.1/{tenant_id}/os-volumes/{volume_id}. Response has the 'multiattach' flag in the same form as the response example above. Updated JSON schema for the request:: { 'type': 'object', 'properties': { 'volume': { 'type': 'object', 'properties': { 'volume_type': {'type': 'string'}, 'metadata': {'type': 'object'}, 'snapshot_id': {'type': 'string'}, 'size': { 'type': ['integer', 'string'], 'pattern': '^[0-9]+$', 'minimum': 1 }, 'availability_zone': {'type': 'string'}, 'display_name': {'type': 'string'}, 'display_description': {'type': 'string'}, 'multiattach': {'type': 'boolean'} }, 'additionalProperties': False, }, }, 'required': ['volume'], 'additionalProperties': False, } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Last part of the multi-attach implementation work. Assignee(s) ----------- Primary assignee: ildiko-vancsa Work Items ---------- 1. REST API update. Dependencies ============ * Implementation of the corresponding blueprint: https://blueprints.launchpad.net/nova/+spec/multi-attach-volume Testing ======= Functional tests will be added to validate the API responses. Documentation Impact ==================== API reference needs to be updated. References ========== * This is the cinder wiki page that discusses the approach to multi-attach https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume ",,195,0
openstack%2Fheat~master~I484b7c8cb4a4e71817be6bea764f23b68a39b2d4,openstack/heat,master,I484b7c8cb4a4e71817be6bea764f23b68a39b2d4,Replace SD RPC polling by long RPC call,MERGED,2016-02-17 12:10:36.000000000,2016-05-05 18:58:54.000000000,2016-04-10 23:23:16.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8399}, {'_account_id': 8833}, {'_account_id': 16203}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-02-17 12:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a98d4db884c0abb41fe0adf9d603167985677f22', 'message': 'WIP: replace SD RPC polling by long RPC call\n\nThis changes the way SoftwareDeployment updates its internal status.\nInstead of querying the deployment status in a loop using RPC client, it\nmakes a single call, which returns once the status has been updated.\n\nThis removes the overhead of using messages every second for this. The\ntradeoff is that we now rely on 2 engines being up.\n\nChange-Id: I484b7c8cb4a4e71817be6bea764f23b68a39b2d4\n'}, {'number': 2, 'created': '2016-02-24 12:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d0f82e435dae7e553f0387a8c0f5314dbd4c3432', 'message': 'Replace SD RPC polling by long RPC call\n\nThis changes the way SoftwareDeployment updates its internal status.\nInstead of querying the deployment status in a loop using RPC client, it\nmakes a single call, which returns once the status has been updated.\n\nCloses-Bug: #1549219\nChange-Id: I484b7c8cb4a4e71817be6bea764f23b68a39b2d4\n'}, {'number': 3, 'created': '2016-03-23 23:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/39cf62d460e504d9638913853e84a97f8b057f8b', 'message': 'Replace SD RPC polling by long RPC call\n\nThis changes the way SoftwareDeployment updates its internal status.\nInstead of querying the deployment status in a loop using RPC client, it\nmakes a single call, which returns once the status has been updated.\n\nCloses-Bug: #1549219\nChange-Id: I484b7c8cb4a4e71817be6bea764f23b68a39b2d4\n'}, {'number': 4, 'created': '2016-04-05 19:19:54.000000000', 'files': ['heat/engine/service_software_config.py', 'heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/tests/engine/service/test_software_config.py', 'heat/engine/resources/openstack/heat/software_deployment.py', 'heat/engine/service.py', 'heat/tests/openstack/heat/test_software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a709637a17166cb12e5d94944837bac6451b2851', 'message': 'Replace SD RPC polling by long RPC call\n\nThis changes the way SoftwareDeployment updates its internal status.\nInstead of querying the deployment status in a loop using RPC client, it\nmakes a single call, which returns once the status has been updated.\n\nCloses-Bug: #1549219\nChange-Id: I484b7c8cb4a4e71817be6bea764f23b68a39b2d4\n'}]",5,281220,a709637a17166cb12e5d94944837bac6451b2851,31,10,4,7385,,,0,"Replace SD RPC polling by long RPC call

This changes the way SoftwareDeployment updates its internal status.
Instead of querying the deployment status in a loop using RPC client, it
makes a single call, which returns once the status has been updated.

Closes-Bug: #1549219
Change-Id: I484b7c8cb4a4e71817be6bea764f23b68a39b2d4
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/281220/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/service_software_config.py', 'heat/rpc/client.py', 'heat/engine/resources/openstack/heat/software_deployment.py', 'heat/engine/service.py', 'heat/tests/openstack/heat/test_software_deployment.py']",5,a98d4db884c0abb41fe0adf9d603167985677f22,bug/1549219,from oslo_utils import timeutils self.stack.created_time = timeutils.utcnow() self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd self.rpc_client.check_software_deployment.return_value = sd, self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd self.rpc_client.show_software_deployment.return_value = sd,46,11
openstack%2Fpuppet-nova~master~If5ea135b294995634506b745f80442e34b101a59,openstack/puppet-nova,master,If5ea135b294995634506b745f80442e34b101a59,Conditionally fall back to redhat service provider,MERGED,2016-05-03 23:21:59.000000000,2016-05-05 18:58:28.000000000,2016-05-05 18:13:42.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 23:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7112ceedb1c5b69bb591f7736e8cd31d77c36e5d', 'message': 'Conditionally fall back to redhat service provider\n\n  This commit partially reverts Change-Id:\n  Ic06ffc377f8982337d977bebb96ef7f6196e5c22 and puts in place\n  conditionals to work around an issue in Puppet 4.0 through 4.4\n  installations where the systemd service provider does not function\n  because of a bug managing statically enabled services[1].\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5353\n\nCloses-Bug: #1577827\nChange-Id: If5ea135b294995634506b745f80442e34b101a59\n'}, {'number': 2, 'created': '2016-05-04 22:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/4e0b506e64f352d44e33d6abd963e57c9f235510', 'message': 'Conditionally fall back to redhat service provider\n\n  This commit partially reverts Change-Id:\n  Ic06ffc377f8982337d977bebb96ef7f6196e5c22 and puts in place\n  conditionals to work around an issue in Puppet 4.0 through 4.4\n  installations where the systemd service provider does not function\n  because of a bug managing statically enabled services[1].\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5353\n\nCloses-Bug: #1577827\nDepends-On: I9b55dafc9ce4247d52c081e926e11d12c0b04064\nChange-Id: If5ea135b294995634506b745f80442e34b101a59\n'}, {'number': 3, 'created': '2016-05-04 22:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/2de098d345a58645fd27dafcb4ecc4cc7cc6ab56', 'message': 'Conditionally fall back to redhat service provider\n\n  This commit partially reverts Change-Id:\n  Ic06ffc377f8982337d977bebb96ef7f6196e5c22 and puts in place\n  conditionals to work around an issue in Puppet 4.0 through 4.4\n  installations where the systemd service provider does not function\n  because of a bug managing statically enabled services[1].\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5353\n\nCloses-Bug: #1577827\nDepends-On: I9b55dafc9ce4247d52c081e926e11d12c0b04064\nChange-Id: If5ea135b294995634506b745f80442e34b101a59\n'}, {'number': 4, 'created': '2016-05-05 16:55:29.000000000', 'files': ['releasenotes/notes/fallback_to_redhat_intelligently-d3a158ae263f6103.yaml', 'releasenotes/notes/stop_service_provider-557dea3058c3bcec.yaml', 'manifests/params.pp', 'manifests/compute/libvirt.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/b108a7c36bbc733b3aa90786540e978f5c0ec059', 'message': 'Conditionally fall back to redhat service provider\n\n  This commit partially reverts Change-Id:\n  Ic06ffc377f8982337d977bebb96ef7f6196e5c22 and puts in place\n  conditionals to work around an issue in Puppet 4.0 through 4.4\n  installations where the systemd service provider does not function\n  because of a bug managing statically enabled services[1].\n\n  [1] https://tickets.puppetlabs.com/browse/PUP-5353\n\nCloses-Bug: #1577827\nChange-Id: If5ea135b294995634506b745f80442e34b101a59\n'}]",1,312284,b108a7c36bbc733b3aa90786540e978f5c0ec059,32,5,4,7423,,,0,"Conditionally fall back to redhat service provider

  This commit partially reverts Change-Id:
  Ic06ffc377f8982337d977bebb96ef7f6196e5c22 and puts in place
  conditionals to work around an issue in Puppet 4.0 through 4.4
  installations where the systemd service provider does not function
  because of a bug managing statically enabled services[1].

  [1] https://tickets.puppetlabs.com/browse/PUP-5353

Closes-Bug: #1577827
Change-Id: If5ea135b294995634506b745f80442e34b101a59
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/84/312284/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fallback_to_redhat_intelligently-d3a158ae263f6103.yaml', 'releasenotes/notes/stop_service_provider-557dea3058c3bcec.yaml', 'manifests/params.pp', 'manifests/compute/libvirt.pp']",4,7112ceedb1c5b69bb591f7736e8cd31d77c36e5d,bug/1577827," ensure => running, enable => true, name => $::nova::params::messagebus_service_name, provider => $::nova::params::special_service_provider, ensure => running, enable => true, name => $libvirt_service_name, provider => $::nova::params::special_service_provider, require => Package['libvirt'], ensure => running, enable => true, name => $virtlock_service_name, provider => $::nova::params::special_service_provider, require => Package['libvirt'] ensure => running, enable => true, name => $virtlog_service_name, provider => $::nova::params::special_service_provider, require => Package['libvirt']"," ensure => running, enable => true, name => $::nova::params::messagebus_service_name, ensure => running, enable => true, name => $libvirt_service_name, require => Package['libvirt'], ensure => running, enable => true, name => $virtlock_service_name, require => Package['libvirt'] ensure => running, enable => true, name => $virtlog_service_name, require => Package['libvirt']",49,33
openstack%2Fopenstack-ansible-os_heat~master~I83486554e90e052982715c241dc9c5efc849cfed,openstack/openstack-ansible-os_heat,master,I83486554e90e052982715c241dc9c5efc849cfed,Remove py_from_git role,MERGED,2016-05-04 08:13:14.000000000,2016-05-05 18:58:21.000000000,2016-05-05 18:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-04 08:13:14.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tests/test-prep.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/75c2484d9963b5d2cef93cfdf09372bec14de91e', 'message': 'Remove py_from_git role\n\nThe py_from_git role is removed as it is no longer required.\n\nChange-Id: I83486554e90e052982715c241dc9c5efc849cfed\n'}]",0,312365,75c2484d9963b5d2cef93cfdf09372bec14de91e,12,3,1,6816,,,0,"Remove py_from_git role

The py_from_git role is removed as it is no longer required.

Change-Id: I83486554e90e052982715c241dc9c5efc849cfed
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/65/312365/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tests/test-prep.yml']",2,75c2484d9963b5d2cef93cfdf09372bec14de91e,py_from_git_begone," post_tasks: - { name: ""openstack1"", service: ""openstack1"", address: ""10.100.100.102"", groups: ""all,all_containers,heat_all,heat_api,heat_engine,heat_api_cfn,heat_api_cloudwatch,heat_engine_container,heat_apis_container,keystone_all"" } "," # The $HOME directory is mocked to work with tox # by defining the 'ansible_env' hash. This should # NEVER be done outside of testing. ansible_env: ## NEVER DO THIS OUTSIDE OF TESTING HOME: ""/tmp"" - role: ""py_from_git"" git_repo: ""https://github.com/lxc/python2-lxc"" git_dest: ""/opt/lxc_python2"" git_install_branch: ""master"" post_tasks: # THIS TASK IS ONLY BEING DONE BECAUSE THE TOX SHARED LXC LIB IS NOT USABLE ON A # HOST MACHINE THAT MAY NOT HAVE ACCESS TO THE VENV. - name: Ensure the lxc lib is on the host command: /usr/local/bin/pip install /opt/lxc_python2 - { name: ""openstack1"", service: ""openstack1"", address: ""10.100.100.102"", groups: ""all,all_containers,heat_all,heat_api,heat_engine,heat_api_cfn,heat_api_cloudwatch,heat_engine_container,heat_apis_container,keystone_all"" }",1,18
openstack%2Fpuppet-gnocchi~stable%2Fmitaka~Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd,openstack/puppet-gnocchi,stable/mitaka,Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd,Prepare module for publication to the forge,MERGED,2016-05-03 21:57:17.000000000,2016-05-05 18:58:05.000000000,2016-05-05 18:58:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 21:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/bebd17e721ef3cdfd26c0164392cea4e66203b0a', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd\n""}, {'number': 2, 'created': '2016-05-03 22:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/1fc491dab7ed807a13158e1085e25069dd7eb78d', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd\n""}, {'number': 3, 'created': '2016-05-04 18:28:09.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/c519d72db3839af84cb27bcc1459918399c1adf4', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd\n""}]",0,312264,c519d72db3839af84cb27bcc1459918399c1adf4,14,3,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Ia7203f5c8aa999264bc5f53cdf2455afe6a2f4cd
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/64/312264/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,bebd17e721ef3cdfd26c0164392cea4e66203b0a,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"", ""22"", ""23""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""6.5"", ""7""] }, { ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.5.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""8""] }, { ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""20""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",14,14
openstack%2Fopenstack-ansible-os_horizon~master~Id1bfc1efd3187d1398a888129be26cd3ec2e6cc9,openstack/openstack-ansible-os_horizon,master,Id1bfc1efd3187d1398a888129be26cd3ec2e6cc9,Remove py_from_git role,MERGED,2016-05-04 08:15:10.000000000,2016-05-05 18:57:51.000000000,2016-05-05 18:57:51.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-04 08:15:10.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tests/test-prep.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/f30714d6be5f5aebfa765c0832e4df80ed50c1bb', 'message': 'Remove py_from_git role\n\nThe py_from_git role is removed as it is no longer required.\n\nChange-Id: Id1bfc1efd3187d1398a888129be26cd3ec2e6cc9\n'}]",0,312366,f30714d6be5f5aebfa765c0832e4df80ed50c1bb,12,3,1,6816,,,0,"Remove py_from_git role

The py_from_git role is removed as it is no longer required.

Change-Id: Id1bfc1efd3187d1398a888129be26cd3ec2e6cc9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/66/312366/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tests/test-prep.yml']",2,f30714d6be5f5aebfa765c0832e4df80ed50c1bb,py_from_git_begone, post_tasks:," - role: ""py_from_git"" git_repo: ""https://github.com/lxc/python2-lxc"" git_dest: ""/opt/lxc_python2"" git_install_branch: ""master"" post_tasks: # THIS TASK IS ONLY BEING DONE BECAUSE THE TOX SHARED LXC LIB IS NOT USABLE ON A # HOST MACHINE THAT MAY NOT HAVE ACCESS TO THE VENV. - name: Ensure the lxc lib is on the host command: /usr/local/bin/pip install /opt/lxc_python2",0,12
openstack%2Fpuppet-trove~stable%2Fmitaka~I67e19c514696ae108581e46a89615cd883fceaed,openstack/puppet-trove,stable/mitaka,I67e19c514696ae108581e46a89615cd883fceaed,Prepare module for publication to the forge,MERGED,2016-05-03 21:12:27.000000000,2016-05-05 18:51:07.000000000,2016-05-05 18:51:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 21:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/50923d9dd4b2b2ddf5e3789deb1497cf5a31ce5b', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I67e19c514696ae108581e46a89615cd883fceaed\n""}, {'number': 2, 'created': '2016-05-03 22:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/e1da4520e8503bee1de1e6388537ef376afbaac2', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I67e19c514696ae108581e46a89615cd883fceaed\n""}, {'number': 3, 'created': '2016-05-04 18:27:59.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/a6d5e589fcb32be1a19b8057a05ebcef5fe27621', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I67e19c514696ae108581e46a89615cd883fceaed\n""}]",0,312252,a6d5e589fcb32be1a19b8057a05ebcef5fe27621,15,3,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I67e19c514696ae108581e46a89615cd883fceaed
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/52/312252/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,50923d9dd4b2b2ddf5e3789deb1497cf5a31ce5b,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",8,8
openstack%2Fpuppet-cinder~stable%2Fmitaka~I3982dfc591c23a270bc551d261b69ae5cce2e7f0,openstack/puppet-cinder,stable/mitaka,I3982dfc591c23a270bc551d261b69ae5cce2e7f0,Prepare module for publication to the forge,MERGED,2016-05-03 18:37:19.000000000,2016-05-05 18:50:51.000000000,2016-05-05 18:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 18:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/64dc347044c573242cb1d331b849462a94cbe6da', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I3982dfc591c23a270bc551d261b69ae5cce2e7f0\n""}, {'number': 2, 'created': '2016-05-03 22:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/a358bfbc1b2d7457b595bb4eb21f844187702b7c', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I3982dfc591c23a270bc551d261b69ae5cce2e7f0\n""}, {'number': 3, 'created': '2016-05-04 18:27:19.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/a534deea122487751a401ff11a9d73d86cae058b', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: I3982dfc591c23a270bc551d261b69ae5cce2e7f0\n""}]",0,312202,a534deea122487751a401ff11a9d73d86cae058b,19,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: I3982dfc591c23a270bc551d261b69ae5cce2e7f0
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/02/312202/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,64dc347044c573242cb1d331b849462a94cbe6da,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystemrelease"": [""21"", ""22"", ""23""] ""operatingsystemrelease"": [""6.5"", ""7""] ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=5.3.1 <6.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystemrelease"": [""20""] ""operatingsystemrelease"": [""6.5"",""7""] ""operatingsystemrelease"": [""12.04"",""14.04""] { ""name"": ""dprince/qpid"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/rabbitmq"", ""version_requirement"": "">=2.0.2 <6.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",9,10
openstack%2Fkeystonemiddleware~master~Ib98d3de771d88feea72ea9598d094b77cde6093e,openstack/keystonemiddleware,master,Ib98d3de771d88feea72ea9598d094b77cde6093e,Update config options,MERGED,2016-05-05 02:12:30.000000000,2016-05-05 18:32:29.000000000,2016-05-05 18:32:29.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-05-05 02:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/dc1cfd50f4f7033d7a2fb52a8ad1dd2a7a781761', 'message': 'Update config options\n\nThe config options in the architecture page needed to be updated. This\nincludes new values and correct text for old values.\n\nChange-Id: Ib98d3de771d88feea72ea9598d094b77cde6093e\n'}, {'number': 2, 'created': '2016-05-05 02:18:38.000000000', 'files': ['doc/source/middlewarearchitecture.rst', 'keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5ef2e510d19d1e9ef31635f85c798dad395c26d4', 'message': 'Update config options\n\nThe config options in the architecture page needed to be updated. This\nincludes new values and correct text for old values. We also note in the\ncode that the revocation event list is only valid for PKI tokens.\n\nChange-Id: Ib98d3de771d88feea72ea9598d094b77cde6093e\n'}]",4,312809,5ef2e510d19d1e9ef31635f85c798dad395c26d4,10,5,2,9500,,,0,"Update config options

The config options in the architecture page needed to be updated. This
includes new values and correct text for old values. We also note in the
code that the revocation event list is only valid for PKI tokens.

Change-Id: Ib98d3de771d88feea72ea9598d094b77cde6093e
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/09/312809/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/middlewarearchitecture.rst'],1,dc1cfd50f4f7033d7a2fb52a8ad1dd2a7a781761,," # Determines the frequency at which the list of revoked tokens # is retrieved from the Identity service (in seconds). A high # number of revocation events combined with a low cache duration # may significantly reduce performance. Only valid for PKI tokens. # (integer value) #revocation_cache_time = 10 # If true, the revocation list will be checked for cached # tokens. This requires that PKI tokens are configured on the # identity server. # (boolean value) #check_revocations_for_cached = false # Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported # by Python standard hashlib.new(). The hashes will be tried in the # order given, so put the preferred one first for performance. The # result of the first hash will be stored in the cache. This will # typically be set to multiple values only while migrating from a # less secure algorithm to a more secure one. Once all the old # tokens are expired this option should be set to a single value # for better performance. (list value) #hash_algorithms = md5 # Authentication type to load (unknown value) # Deprecated group/name - [DEFAULT]/auth_plugin #auth_type = <None> # Config Section from which to load plugin specific options # (unknown value) #auth_section = <None>"," # Value only used for unit testing (integer value) #revocation_cache_time=1 # The plugin used for authentication, such as password, token (string # value) #auth_plugin=password",30,5
openstack%2Fmagnum~stable%2Fliberty~Ie194c5b4e3555572eba61767621e53b0b06b9ece,openstack/magnum,stable/liberty,Ie194c5b4e3555572eba61767621e53b0b06b9ece,Gate: Fixed an empty service catalog error,ABANDONED,2016-04-19 20:31:02.000000000,2016-05-05 18:19:08.000000000,,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12175}]","[{'number': 1, 'created': '2016-04-19 20:31:02.000000000', 'files': ['magnum/tests/contrib/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/19a39b471ad3046a1837665844531b2ade71fa47', 'message': 'Gate: Fixed an empty service catalog error\n\nAfter python-novaclient upgrade from 2.X to 3.X, the gate started\nfailing with the error below:\n\nnova keypair-add --pub-key /home/jenkins/.ssh/id_rsa.pub default\nERROR (EmptyCatalog): The service catalog is empty.\n\nThis commit temporarily works around it by unseting OS_AUTH_TYPE\nvariable.\n\nSee: https://bugs.launchpad.net/python-keystoneclient/+bug/1519624\n\nChange-Id: Ie194c5b4e3555572eba61767621e53b0b06b9ece\nCloses-Bug: #1528059\n(cherry picked from commit 9afd7790cf0004a2b7f9c4f238fcc94f92742113)\n'}]",0,308022,19a39b471ad3046a1837665844531b2ade71fa47,6,3,1,11536,,,0,"Gate: Fixed an empty service catalog error

After python-novaclient upgrade from 2.X to 3.X, the gate started
failing with the error below:

nova keypair-add --pub-key /home/jenkins/.ssh/id_rsa.pub default
ERROR (EmptyCatalog): The service catalog is empty.

This commit temporarily works around it by unseting OS_AUTH_TYPE
variable.

See: https://bugs.launchpad.net/python-keystoneclient/+bug/1519624

Change-Id: Ie194c5b4e3555572eba61767621e53b0b06b9ece
Closes-Bug: #1528059
(cherry picked from commit 9afd7790cf0004a2b7f9c4f238fcc94f92742113)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/22/308022/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/contrib/post_test_hook.sh'],1,19a39b471ad3046a1837665844531b2ade71fa47,bug/1528059,unset OS_AUTH_TYPE,,1,0
openstack%2Fkeystonemiddleware~master~I9471721220c99f9c4ed055840ed626bb7750eb3f,openstack/keystonemiddleware,master,I9471721220c99f9c4ed055840ed626bb7750eb3f,Fix D401 PEP257 violation and enable H403,MERGED,2016-05-04 22:09:48.000000000,2016-05-05 18:06:59.000000000,2016-05-05 18:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-05-04 22:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8c4c80b14dfe0ca2296c268f4e5077a4174fbd1f', 'message': 'Fix D401 PEP257 violation.\n\nCurrently tox ignores D401.\n401: First line should be in imperative mood.\nThis change removes it and make keystonemiddleware docstrings compliant\nwith it.\n\nChange-Id: I9471721220c99f9c4ed055840ed626bb7750eb3f\n'}, {'number': 2, 'created': '2016-05-05 15:52:34.000000000', 'files': ['keystonemiddleware/ec2_token.py', 'keystonemiddleware/s3_token.py', 'keystonemiddleware/auth_token/_memcache_crypt.py', 'keystonemiddleware/auth_token/_user_plugin.py', 'keystonemiddleware/audit.py', 'keystonemiddleware/auth_token/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/92983b1da80f8ae4d7c3eddc5b43d8c8b0e5f23a', 'message': 'Fix D401 PEP257 violation and enable H403\n\nCurrently tox ignores D401 and H403:\n401: First line should be in imperative mood.\n403: multi line docstrings should end on a new line\n\nThis change makes keystonemiddleware docstrings compliant with D401.\nH403 is already passing, so this commit also enables it.\n\nChange-Id: I9471721220c99f9c4ed055840ed626bb7750eb3f\n'}]",0,312767,92983b1da80f8ae4d7c3eddc5b43d8c8b0e5f23a,12,3,2,9301,,,0,"Fix D401 PEP257 violation and enable H403

Currently tox ignores D401 and H403:
401: First line should be in imperative mood.
403: multi line docstrings should end on a new line

This change makes keystonemiddleware docstrings compliant with D401.
H403 is already passing, so this commit also enables it.

Change-Id: I9471721220c99f9c4ed055840ed626bb7750eb3f
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/67/312767/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/ec2_token.py', 'keystonemiddleware/s3_token.py', 'keystonemiddleware/auth_token/_memcache_crypt.py', 'keystonemiddleware/auth_token/_user_plugin.py', 'keystonemiddleware/audit.py', 'keystonemiddleware/auth_token/__init__.py', 'tox.ini']",7,8c4c80b14dfe0ca2296c268f4e5077a4174fbd1f,,"ignore = D100,D101,D102,D103,D104,D105,D200,D202,D209,D301,D204,D400","# D401: First line should be in imperative mood # H403: multi line docstrings should end on a new line ignore = D100,D101,D102,D103,D104,D105,D200,D202,D209,D301,D204,D400,D401,H403",9,11
openstack%2Fkeystone~master~I4d5d88ea45c00fe874382c06a0626ea6aaeb87c9,openstack/keystone,master,I4d5d88ea45c00fe874382c06a0626ea6aaeb87c9,Fixes example in the mapping combinations docs,MERGED,2016-05-05 15:53:25.000000000,2016-05-05 17:58:12.000000000,2016-05-05 17:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-05-05 15:53:25.000000000', 'files': ['doc/source/federation/mapping_combinations.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/70b798641a5b23277f6c22cd368875b9eb3bca9e', 'message': 'Fixes example in the mapping combinations docs\n\nWhen reviewing If74aaf07b77399f1648843280153c7523de5eb38 I noticed that\none of the examples was incorrect.\n\nChange-Id: I4d5d88ea45c00fe874382c06a0626ea6aaeb87c9\nRelated-Bug: #1575057\n'}]",0,313034,70b798641a5b23277f6c22cd368875b9eb3bca9e,7,3,1,7725,,,0,"Fixes example in the mapping combinations docs

When reviewing If74aaf07b77399f1648843280153c7523de5eb38 I noticed that
one of the examples was incorrect.

Change-Id: I4d5d88ea45c00fe874382c06a0626ea6aaeb87c9
Related-Bug: #1575057
",git fetch https://review.opendev.org/openstack/keystone refs/changes/34/313034/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/federation/mapping_combinations.rst'],1,70b798641a5b23277f6c22cd368875b9eb3bca9e,bug/1575057," ""name"": ""{3}"", ""domain"": { ""id"": ""0cd5e9"" }"," ""name"": ""{3}""",4,1
openstack%2Fproject-config~master~I273ee78ff5f581d6adb5e2f4b03da2b78b07faf9,openstack/project-config,master,I273ee78ff5f581d6adb5e2f4b03da2b78b07faf9,add tarball jobs to puppet-tripleo,MERGED,2016-05-05 17:09:00.000000000,2016-05-05 17:56:21.000000000,2016-05-05 17:56:17.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 17:09:00.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b2a0c444acb1e6aabbdb3cc31fde4217a48c2487', 'message': 'add tarball jobs to puppet-tripleo\n\nWe want to start releasing puppet-tripleo on tarballs.openstack.org.\nThis patch adds the required jobs.\n\nChange-Id: I273ee78ff5f581d6adb5e2f4b03da2b78b07faf9\n'}]",0,313063,b2a0c444acb1e6aabbdb3cc31fde4217a48c2487,7,3,1,3153,,,0,"add tarball jobs to puppet-tripleo

We want to start releasing puppet-tripleo on tarballs.openstack.org.
This patch adds the required jobs.

Change-Id: I273ee78ff5f581d6adb5e2f4b03da2b78b07faf9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/313063/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,b2a0c444acb1e6aabbdb3cc31fde4217a48c2487,tripleo/tarball, - name: puppet-tarball-jobs,,3,0
openstack%2Fironic~master~Ice489ba642bf093fe7015aa97e6a92717f676118,openstack/ironic,master,Ice489ba642bf093fe7015aa97e6a92717f676118,Fix VirtualBox cannot set boot device when powered on,MERGED,2016-03-10 02:33:55.000000000,2016-05-05 17:52:34.000000000,2016-05-05 17:52:34.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6610}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 11076}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 14525}, {'_account_id': 17998}, {'_account_id': 19686}, {'_account_id': 20311}, {'_account_id': 20671}]","[{'number': 1, 'created': '2016-03-10 02:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ab8e216434b99fc4db28fb17202270d5e78fdc4c', 'message': 'fix bug virtualbox baremetal machine cannot boot from local disk\n\nBecause virtualbox do not support changing VMs  boot sequence when is running, so I power it off before changing its boot sequence.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nClose-Bug: #1554908\n'}, {'number': 2, 'created': '2016-03-11 02:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f710028559c9f49dd7df1bee67e31c4f4c1832e9', 'message': 'fix bug virtualbox baremetal machine cannot boot from local disk\n\nWhen deploying baremetal machine with virtualbox driver,it fails on\nbooting from local harddisk. The root cause is virtualbox boot device\ncannot be set when the virtualbox VM is power on.\n\nI power off the VMs before setting boot device in virtualbox driver.\nmeanwhile, I should check power status in agent, because for the most\nof the drivers, it do not need to power off machine when setting\nboot devices, and agent will call soft_power_off to shut down the\nmachine. However, for the drivers like virtualbox which shut down\nthe machine before calling agent to reboot_and_finish_deploy will case\nagent soft shut down a powered off machine. Timeout mechanism wil\nensure the success of deployment but an excepthon will be thrown out.\n\nSo modification in virtualbox drivers to ensure setting boot device on\nan power off machine. Modification in agent ensures agent can handle\nthe scenario that machine has been shut down before calling agent to\nfinish deployment.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n'}, {'number': 3, 'created': '2016-03-11 08:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bb63d50016b95d53cc5ab4d5bcdaace9bbfa0eaf', 'message': 'fix bug virtualbox baremetal machine cannot boot from local disk\n\nWhen deploying baremetal machine with virtualbox driver,it fails on\nbooting from local harddisk. The root cause is virtualbox boot device\ncannot be set when the virtualbox VM is power on.\n\nI power off the VMs before setting boot device in virtualbox driver.\nmeanwhile, I should check power status in agent, because for the most\nof the drivers, it do not need to power off machine when setting\nboot devices, and agent will call soft_power_off to shut down the\nmachine. However, for the drivers like virtualbox which shut down\nthe machine before calling agent to reboot_and_finish_deploy will case\nagent soft shut down a powered off machine. Timeout mechanism will\nensure the success of deployment but an excepthon will be thrown out.\n\nSo modification in virtualbox drivers to ensure setting boot device on\nan power off machine. Modification in agent ensures agent can handle\nthe scenario that machine has been shut down before calling agent to\nfinish deployment.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n'}, {'number': 4, 'created': '2016-03-16 02:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/037d6589688ad324ae7246b0956a1e4ebb937ff1', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nwhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: when the VMs is powered on, we store the target boot\ndevice in driver_internal_info, and set the target boot device\nbefore netxt starting up. For the  get_boot_device call, if\nthe VMs is powered off, we call remotebox lib to get its boot\ndevice, otherwise, we return the target boot device from\ndriver_internal_info. Returning target boot device when VMs\nis powered on will avoid the problem that even users set the\ntarget boot device while return the last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 5, 'created': '2016-03-16 03:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6e87b7d93425cd330e8074abd7e5e1f6f12f1c29', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: when the VMs is powered on, we store the target boot\ndevice in driver_internal_info, and set the target boot device\nbefore netxt starting up. For the  get_boot_device call, if\nthe VMs is powered off, we call remotebox lib to get its boot\ndevice, otherwise, we return the target boot device from\ndriver_internal_info. Returning target boot device when VMs\nis powered on will avoid the problem that even users set the\ntarget boot device while return the last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 6, 'created': '2016-03-17 15:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52db5926a2810bea201d40f52cd7dc7f39cef298', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: when the VMs is powered on, we store the target boot\ndevice in driver_internal_info, and set the target boot device\nbefore netxt starting up. For the  get_boot_device call, if\nthe VMs is powered off, we call remotebox lib to get its boot\ndevice, otherwise, we return the target boot device from\ndriver_internal_info. Returning target boot device when VMs\nis powered on will avoid the problem that even users set the\ntarget boot device while return the last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 7, 'created': '2016-03-18 01:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f0719bca5e24ac360801477313bd3f8e1c51b9fc', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: when the VMs is powered on, we store the target boot\ndevice in driver_internal_info, and set the target boot device\nbefore netxt starting up. For the  get_boot_device call, if\nthe VMs is powered off, we call remotebox lib to get its boot\ndevice, otherwise, we return the target boot device from\ndriver_internal_info. Returning target boot device when VMs\nis powered on will avoid the problem that even users set the\ntarget boot device while return the last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 8, 'created': '2016-03-18 03:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e9348281048c037fd92dffd44121d80999af6143', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before netxt starting up\nwe set the boot device and clean target_boot_device information,\nif the tar_boot_device is None, we just skip setting boot device.\nFor the  get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current bootdevice.\nReturning target boot device when VMs is powered on will avoidthe\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 9, 'created': '2016-03-18 03:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a15896ceb53a0f762e8683328731b028711c30b7', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before netxt starting up\nwe set the boot device and clean target_boot_device information,\nif the tar_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current bootdevice.\nReturning target boot device when VMs is powered on will avoidthe\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 10, 'created': '2016-03-23 02:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b698af34666ddc471a7191bdc93a93eaebcf803f', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before netxt starting up\nwe set the boot device and clean target_boot_device information,\nif the tar_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current bootdevice.\nReturning target boot device when VMs is powered on will avoidthe\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 11, 'created': '2016-03-23 11:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b92c7a550843b49c548d60d895e6e4e09f4257d2', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 12, 'created': '2016-04-27 03:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b357e39e41687d7873a6606b32e0a928acb2e2d', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 13, 'created': '2016-04-27 06:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a964b2b1eb91c86fa76766b2c436bfb043cf086c', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 14, 'created': '2016-04-27 06:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9524f59342a7d0b9f078f75b749a943dc1058223', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal hardisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_deivce and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 15, 'created': '2016-04-28 04:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/13b7ba483700130fb695520fb29a715f8123b0af', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, Ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal harddisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_device and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}, {'number': 16, 'created': '2016-04-29 01:02:07.000000000', 'files': ['ironic/tests/unit/drivers/modules/test_virtualbox.py', 'ironic/drivers/modules/virtualbox.py', 'releasenotes/notes/fix-virtualbox-localboot-not-working-558a3dec72b5116b.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d76f12f4f91a01cab447ba0833816852cba873d3', 'message': ""Fix VirtualBox cannot set boot device when powered on\n\nWhen the VirtualBox VMs is powered on, Ironic cannot set the boot\ndevice. As a result, VirtualBox driver cannot finish deploying\nlocal harddisk boot VMs and also set and get Virtualbox VMs's\nboot devices correctly.\n\nSolution: We get boot device from set_boot_device and store the\ntarget boot device in driver_internal_info. Before next starting up\nwe set the boot device and clean target_boot_device information,\nif the target_boot_device is None, we just skip setting boot device.\nFor the get_boot_device call, if the VMs is powered off, we call\nremotebox to get current boot device. otherwise, we return the target\nboot device from driver_internal_info(if target_boot_device\nis not None) or we call remotebox  to return the current boot device.\nReturning target boot device when VMs is powered on will avoid the\nproblem that even users set the target boot device while returning\nthe last boot device.\n\nChange-Id: Ice489ba642bf093fe7015aa97e6a92717f676118\nCloses-Bug: #1554908\n""}]",134,290951,d76f12f4f91a01cab447ba0833816852cba873d3,100,16,16,20671,,,0,"Fix VirtualBox cannot set boot device when powered on

When the VirtualBox VMs is powered on, Ironic cannot set the boot
device. As a result, VirtualBox driver cannot finish deploying
local harddisk boot VMs and also set and get Virtualbox VMs's
boot devices correctly.

Solution: We get boot device from set_boot_device and store the
target boot device in driver_internal_info. Before next starting up
we set the boot device and clean target_boot_device information,
if the target_boot_device is None, we just skip setting boot device.
For the get_boot_device call, if the VMs is powered off, we call
remotebox to get current boot device. otherwise, we return the target
boot device from driver_internal_info(if target_boot_device
is not None) or we call remotebox  to return the current boot device.
Returning target boot device when VMs is powered on will avoid the
problem that even users set the target boot device while returning
the last boot device.

Change-Id: Ice489ba642bf093fe7015aa97e6a92717f676118
Closes-Bug: #1554908
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/290951/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/agent_base_vendor.py', 'ironic/drivers/modules/virtualbox.py']",2,ab8e216434b99fc4db28fb17202270d5e78fdc4c,BUG1554908,"from ironic.conductor import utils as manager_utils manager_utils.node_power_action(task, states.POWER_OFF)",,17,11
openstack%2Fpuppet-neutron~master~I641f78a631911d87623d90340848c3892ae706df,openstack/puppet-neutron,master,I641f78a631911d87623d90340848c3892ae706df,Add logging class,MERGED,2016-05-04 10:51:15.000000000,2016-05-05 17:45:39.000000000,2016-05-05 17:45:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7604}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-04 10:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a32c54b22416bbaabce52c670f48955ef5d309cc', 'message': ""Add logging class\n\n- Add logging class to manage olso.log related options\n- Add option 'manage_logging' for init class to make it possible to evaluate\n  logging class separately from init class in one catalog\n- Deprecate 'verbose' option\n\nChange-Id: I641f78a631911d87623d90340848c3892ae706df\n""}, {'number': 2, 'created': '2016-05-04 15:04:03.000000000', 'files': ['spec/classes/neutron_logging_spec.rb', 'manifests/logging.pp', 'manifests/init.pp', 'releasenotes/notes/add_logging_class-f34440ca42c07a89.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2471f3ad03973333e8e34202185798951f975c0b', 'message': ""Add logging class\n\n- Add logging class to manage olso.log related options\n- Add option 'manage_logging' for init class to make it possible to evaluate\n  logging class separately from init class in one catalog\n- Deprecate 'verbose' option\n\nChange-Id: I641f78a631911d87623d90340848c3892ae706df\n""}]",0,312446,2471f3ad03973333e8e34202185798951f975c0b,18,5,2,7604,,,0,"Add logging class

- Add logging class to manage olso.log related options
- Add option 'manage_logging' for init class to make it possible to evaluate
  logging class separately from init class in one catalog
- Deprecate 'verbose' option

Change-Id: I641f78a631911d87623d90340848c3892ae706df
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/46/312446/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_logging_spec.rb', 'manifests/logging.pp', 'manifests/init.pp', 'releasenotes/notes/add_logging_class-f34440ca42c07a89.yaml']",4,a32c54b22416bbaabce52c670f48955ef5d309cc,logging_class,--- features: - Add logging class to manage olso.log related options init class can still be used for managing the limited number of options Add option 'manage_logging' for init class to make it possible to evaluate logging class separately from init class in one catalog deprecations: - 'verbose' option is deprecated and will be removed in future ,,336,27
openstack%2Fkeystone~master~If74aaf07b77399f1648843280153c7523de5eb38,openstack/keystone,master,If74aaf07b77399f1648843280153c7523de5eb38,Allow 'domain' property for local.group,MERGED,2016-04-26 09:32:04.000000000,2016-05-05 17:42:53.000000000,2016-05-05 17:23:51.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 18940}]","[{'number': 1, 'created': '2016-04-26 09:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bc8e51fd66ec77f392353a27196cad0a802a40ad', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 2, 'created': '2016-04-26 10:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/913e7e3751039f9c87815f166bffb354c57c3e4e', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 3, 'created': '2016-04-26 21:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ef6e2615971b87e18cea538dea2cb56408b24fab', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 4, 'created': '2016-04-27 19:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7135b960a5d280df07e15ad9cd8d2a59f597b904', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 5, 'created': '2016-05-03 17:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5adaeac8a13dcfb4a732961cee0eebc246dc1b7c', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 6, 'created': '2016-05-04 13:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d376230500ad08272d4f445a1619825006e72f0', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}, {'number': 7, 'created': '2016-05-05 10:03:17.000000000', 'files': ['keystone/federation/utils.py', 'keystone/tests/unit/contrib/federation/test_utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7567c5edf214bfbbee6d6acf7c130cd857324fc0', 'message': ""Allow 'domain' property for local.group\n\nThe JSON schema missed the domain property for the local group\ndescription, but it is requested by the code explicitly.\n\nChange-Id: If74aaf07b77399f1648843280153c7523de5eb38\nCloses-Bug: 1575057\n""}]",11,310147,7567c5edf214bfbbee6d6acf7c130cd857324fc0,52,5,7,18940,,,0,"Allow 'domain' property for local.group

The JSON schema missed the domain property for the local group
description, but it is requested by the code explicitly.

Change-Id: If74aaf07b77399f1648843280153c7523de5eb38
Closes-Bug: 1575057
",git fetch https://review.opendev.org/openstack/keystone refs/changes/47/310147/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/federation/utils.py'],1,bc8e51fd66ec77f392353a27196cad0a802a40ad,mapping_validator_tests," ""domain"": { ""type"": ""object"", ""properties"": { ""id"": {""type"": ""string""}, ""name"": {""type"": ""string""} }, ""additionalProperties"": False, },",,8,0
openstack%2Fkeystone~master~I0e8ade7414dbc92ca9334242c1369e0f51d2eba5,openstack/keystone,master,I0e8ade7414dbc92ca9334242c1369e0f51d2eba5,do not search file on real environment,MERGED,2016-04-25 08:20:53.000000000,2016-05-05 17:30:45.000000000,2016-05-05 17:30:44.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6676}, {'_account_id': 11022}, {'_account_id': 13478}, {'_account_id': 16523}, {'_account_id': 17645}, {'_account_id': 17860}, {'_account_id': 18338}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-04-25 08:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f59486340c6e39146594f6b2cd4892b3f41e696a', 'message': 'do not search file on real environment\n\nKeystone cannot pass tox -epy27 on an environment which has\ninstalled keystone service because we do not prevent oslo.config\nsearching all possible directories for configuration file, the\nfailed test is:\n\nkeystone.tests.unit.test_cli.CliNoConfigTestCase.test_cli\n\nUnit test code should not rely on or be affected by real\nenvironment, this patch mocks the oslo.config search diretories to\nour unit test config_files directory. So it can succeed in every\nenvironment, Cheers!\n\nChange-Id: I0e8ade7414dbc92ca9334242c1369e0f51d2eba5\nCloses-Bug: #1574493\n'}, {'number': 2, 'created': '2016-04-25 14:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/27cb99b7ed0e82527b712cdca420bac437395980', 'message': 'do not search file on real environment\n\nKeystone cannot pass tox -epy27 on an environment which has\ninstalled keystone service because we do not prevent oslo.config\nsearching all possible directories for configuration file, the\nfailed test is:\n\nkeystone.tests.unit.test_cli.CliNoConfigTestCase.test_cli\n\nUnit test code should not rely on or be affected by real\nenvironment, this patch mocks the oslo.config search directories to\nour unit test config_files directory. So it can succeed in every\nenvironment, Cheers!\n\nChange-Id: I0e8ade7414dbc92ca9334242c1369e0f51d2eba5\nCloses-Bug: #1574493\n'}, {'number': 3, 'created': '2016-05-05 02:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d232cd673c11c1389afc0ae6e491e1c869bba850', 'message': 'do not search file on real environment\n\nKeystone cannot pass tox -epy27 on an environment which has\ninstalled keystone service because we do not prevent oslo.config\nsearching all possible directories for configuration file, the\nfailed test is:\n\nkeystone.tests.unit.test_cli.CliNoConfigTestCase.test_cli\n\nUnit test code should not rely on or be affected by real\nenvironment, this patch mocks the oslo.config find_config_files to\nempty as we expected, so it can succeed in every environment.\n\nChange-Id: I0e8ade7414dbc92ca9334242c1369e0f51d2eba5\nCloses-Bug: #1574493\n'}, {'number': 4, 'created': '2016-05-05 02:21:53.000000000', 'files': ['keystone/tests/unit/test_cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2183b47af24adc224a45e5ddfdbca1166a39a059', 'message': 'do not search file on real environment\n\nKeystone cannot pass tox -epy27 on an environment which has\ninstalled keystone service because we do not prevent oslo.config\nsearching all possible directories for configuration file, the\nfailed test is:\n\nkeystone.tests.unit.test_cli.CliNoConfigTestCase.test_cli\n\nUnit test code should not rely on or be affected by real\nenvironment, this patch mocks the oslo.config find_config_files to\nempty as we expected, so it can succeed in every environment.\n\nChange-Id: I0e8ade7414dbc92ca9334242c1369e0f51d2eba5\nCloses-Bug: #1574493\n'}]",3,309882,2183b47af24adc224a45e5ddfdbca1166a39a059,25,11,4,6676,,,0,"do not search file on real environment

Keystone cannot pass tox -epy27 on an environment which has
installed keystone service because we do not prevent oslo.config
searching all possible directories for configuration file, the
failed test is:

keystone.tests.unit.test_cli.CliNoConfigTestCase.test_cli

Unit test code should not rely on or be affected by real
environment, this patch mocks the oslo.config find_config_files to
empty as we expected, so it can succeed in every environment.

Change-Id: I0e8ade7414dbc92ca9334242c1369e0f51d2eba5
Closes-Bug: #1574493
",git fetch https://review.opendev.org/openstack/keystone refs/changes/82/309882/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_cli.py'],1,f59486340c6e39146594f6b2cd4892b3f41e696a,bug/1574493,"from keystone.tests.unit import core self.useFixture(mockpatch.Patch( 'oslo_config.cfg._get_config_dirs', return_value=[core.TESTCONF]))",,4,0
openstack%2Fneutron~master~I58e242f05ffb9a33bda5aeb93344861769845d2e,openstack/neutron,master,I58e242f05ffb9a33bda5aeb93344861769845d2e,DVR: Use IPDevice class consistently,MERGED,2016-04-22 20:56:23.000000000,2016-05-05 17:24:10.000000000,2016-05-05 17:24:09.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12860}, {'_account_id': 13667}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-22 20:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b6b8a0021c7fd921699d59a15874b40e3ce0014', 'message': 'DVR: Use IPDevice class consistently\n\ncreate_rtr_2_fip_link() only creates IPDevice class instances\nafter it determines the VETH pair does not exist.  Change to\nalways create them as instead of using int_dev[0].  This is\nalso setup for a follow-on patch.\n\nChange-Id: I58e242f05ffb9a33bda5aeb93344861769845d2e\nPartial-Bug: #1566383\n'}, {'number': 2, 'created': '2016-04-24 02:19:50.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9bec4be6ba06087ebfa20007dcbc2cb646a5345', 'message': 'DVR: Use IPDevice class consistently\n\ncreate_rtr_2_fip_link() only creates IPDevice class instances\nafter it determines the VETH pair does not exist.  Change to\nalways create them as instead of using int_dev[0].  This is\nalso setup for a follow-on patch.\n\nPartial-Bug: #1566383\nChange-Id: I58e242f05ffb9a33bda5aeb93344861769845d2e\n'}]",2,309591,b9bec4be6ba06087ebfa20007dcbc2cb646a5345,24,12,2,1131,,,0,"DVR: Use IPDevice class consistently

create_rtr_2_fip_link() only creates IPDevice class instances
after it determines the VETH pair does not exist.  Change to
always create them as instead of using int_dev[0].  This is
also setup for a follow-on patch.

Partial-Bug: #1566383
Change-Id: I58e242f05ffb9a33bda5aeb93344861769845d2e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/309591/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_fip_ns.py', 'neutron/tests/unit/agent/l3/test_dvr_fip_ns.py']",2,2b6b8a0021c7fd921699d59a15874b40e3ce0014,bug/1566383," def _test_create_rtr_2_fip_link(self, dev_exists, IPDevice, IPWrapper): device = IPDevice() device.exists.return_value = dev_exists if not dev_exists: ip_wrapper.add_veth.assert_called_with(rtr_2_fip_name, fip_2_rtr_name, fip_ns_name) device.link.set_mtu.assert_called_with(2000) self.assertEqual(2, device.link.set_mtu.call_count) self.assertEqual(2, device.link.set_up.call_count) def test_create_rtr_2_fip_link(self): self._test_create_rtr_2_fip_link(False) def test_create_rtr_2_fip_link_already_exists(self): self._test_create_rtr_2_fip_link(True)"," @mock.patch.object(ip_lib, 'device_exists') def test_create_rtr_2_fip_link(self, device_exists, IPDevice, IPWrapper): device_exists.return_value = False ip_wrapper.add_veth.assert_called_with(rtr_2_fip_name, fip_2_rtr_name, fip_ns_name) device = IPDevice() device.link.set_mtu.assert_called_with(2000) self.assertEqual(2, device.link.set_mtu.call_count) @mock.patch.object(ip_lib, 'IPWrapper') @mock.patch.object(ip_lib, 'IPDevice') @mock.patch.object(ip_lib, 'device_exists') def test_create_rtr_2_fip_link_already_exists(self, device_exists, IPDevice, IPWrapper): ri = mock.Mock() ri.router_id = _uuid() ri.rtr_fip_subnet = None device_exists.return_value = True self.fip_ns.local_subnets = allocator = mock.Mock() pair = lla.LinkLocalAddressPair('169.254.31.28/31') allocator.allocate.return_value = pair self.fip_ns.create_rtr_2_fip_link(ri) ip_wrapper = IPWrapper() self.assertFalse(ip_wrapper.add_veth.called)",28,40
openstack%2Fkeystone~stable%2Fmitaka~I1f093dad0b9427027edf4dc1a9f563e99aedad0c,openstack/keystone,stable/mitaka,I1f093dad0b9427027edf4dc1a9f563e99aedad0c,Add conflict validation for idp update,MERGED,2016-05-05 12:32:57.000000000,2016-05-05 17:22:56.000000000,2016-05-05 17:22:56.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-05 12:32:57.000000000', 'files': ['keystone/tests/unit/test_v3_federation.py', 'keystone/federation/backends/sql.py', 'keystone/federation/V8_backends/sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f04d7d8611bba611cdea3cb7cbab1af3c16bdc8', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n(cherry picked from commit bfcbb3cd7679dd13d5ededd2f3b765d40e0bca7d)\n'}]",0,312923,9f04d7d8611bba611cdea3cb7cbab1af3c16bdc8,6,2,1,11022,,,0,"Add conflict validation for idp update

Remote IDs conflicts can happen during an identity provider
update (similar to what happens during create).

This patch adds the same conflict handling, so a 500 is not
returned by keystone.

Change-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c
Closes-Bug: 1558670
(cherry picked from commit bfcbb3cd7679dd13d5ededd2f3b765d40e0bca7d)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/23/312923/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_federation.py', 'keystone/federation/backends/sql.py', 'keystone/federation/V8_backends/sql.py']",3,9f04d7d8611bba611cdea3cb7cbab1af3c16bdc8,bug/1558670,"from oslo_log import logimport sixfrom keystone.i18n import _ LOG = log.getLogger(__name__) _CONFLICT_LOG_MSG = 'Conflict %(conflict_type)s: %(details)s' def _handle_idp_conflict(self, e): conflict_type = 'identity_provider' details = six.text_type(e) LOG.debug(self._CONFLICT_LOG_MSG, {'conflict_type': conflict_type, 'details': details}) if 'remote_id' in details: msg = _('Duplicate remote ID: %s') else: msg = _('Duplicate entry: %s') msg = msg % e.value raise exception.Conflict(type=conflict_type, details=msg) try: with sql.session_for_write() as session: idp_ref = self._get_idp(session, idp_id) old_idp = idp_ref.to_dict() old_idp.update(idp) new_idp = IdentityProviderModel.from_dict(old_idp) for attr in IdentityProviderModel.mutable_attributes: setattr(idp_ref, attr, getattr(new_idp, attr)) return idp_ref.to_dict() except sql.DBDuplicateEntry as e: self._handle_idp_conflict(e)"," with sql.session_for_write() as session: idp_ref = self._get_idp(session, idp_id) old_idp = idp_ref.to_dict() old_idp.update(idp) new_idp = IdentityProviderModel.from_dict(old_idp) for attr in IdentityProviderModel.mutable_attributes: setattr(idp_ref, attr, getattr(new_idp, attr)) return idp_ref.to_dict()",86,26
openstack%2Fpython-swiftclient~master~Iafafe3c553d00652adb91ceefd0de1479cbcb5da,openstack/python-swiftclient,master,Iafafe3c553d00652adb91ceefd0de1479cbcb5da,Pull option processing out to service.py,MERGED,2016-05-03 21:46:29.000000000,2016-05-05 17:22:12.000000000,2016-05-05 17:22:12.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9216}]","[{'number': 1, 'created': '2016-05-03 21:46:29.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_shell.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/c3766319b93d60e30f55747f6cfc9ca915ff603c', 'message': 'Pull option processing out to service.py\n\n...because it seems silly that we do nearly the same thing in two\ndifferent places\n\nChange-Id: Iafafe3c553d00652adb91ceefd0de1479cbcb5da\n'}]",0,312263,c3766319b93d60e30f55747f6cfc9ca915ff603c,9,3,1,15343,,,0,"Pull option processing out to service.py

...because it seems silly that we do nearly the same thing in two
different places

Change-Id: Iafafe3c553d00652adb91ceefd0de1479cbcb5da
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/63/312263/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_shell.py', 'swiftclient/service.py']",3,c3766319b93d60e30f55747f6cfc9ca915ff603c,option-parsing, # tolerate sloppy auth_version if options.get('auth_version') == '3.0': options['auth_version'] = '3' elif options.get('auth_version') == '2': options['auth_version'] = '2.0' ,,46,35
openstack%2Fpython-swiftclient~master~If001e07978c0bae729ac0cd9b2c2934092c98447,openstack/python-swiftclient,master,If001e07978c0bae729ac0cd9b2c2934092c98447,Parse options to dict,MERGED,2016-05-03 21:46:29.000000000,2016-05-05 17:21:56.000000000,2016-05-05 17:21:56.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9216}]","[{'number': 1, 'created': '2016-05-03 21:46:29.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/5b714f104d7564ff06525465d0eaabaa12a8cbb0', 'message': 'Parse options to dict\n\nThis is a first step toward unifying the options parsing magic between\nshell.py and service.py\n\nChange-Id: If001e07978c0bae729ac0cd9b2c2934092c98447\n'}]",1,312262,5b714f104d7564ff06525465d0eaabaa12a8cbb0,7,3,1,15343,,,0,"Parse options to dict

This is a first step toward unifying the options parsing magic between
shell.py and service.py

Change-Id: If001e07978c0bae729ac0cd9b2c2934092c98447
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/62/312262/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_shell.py']",2,5b714f104d7564ff06525465d0eaabaa12a8cbb0,option-parsing," actual = actual_opts.get(key) actual = actual_opts.get(""os_"" + key) self.assertIn('os_options', actual_opts) actual_os_opts_dict = actual_opts['os_options'] self.assertEqual(actual_opts.get(pair[0]), actual_opts.get(pair[1]))"," actual = getattr(actual_opts, key) actual = getattr(actual_opts, ""os_"" + key) self.assertTrue(hasattr(actual_opts, 'os_options')) actual_os_opts_dict = getattr(actual_opts, 'os_options') self.assertEqual(getattr(actual_opts, pair[0]), getattr(actual_opts, pair[1]))",119,127
openstack%2Fdevstack-plugin-ceph~master~I18f8927f42710e9365c246c55f26f53403965ee1,openstack/devstack-plugin-ceph,master,I18f8927f42710e9365c246c55f26f53403965ee1,Add release key for installing packages from ceph.com,MERGED,2016-05-04 19:22:33.000000000,2016-05-05 17:21:35.000000000,2016-05-05 17:21:35.000000000,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 9236}]","[{'number': 1, 'created': '2016-05-04 19:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/854d3c166476734f25befc5129e4670b0184c489', 'message': 'Add release key for installing packages from ceph.com\n\nIn commit bb773e7285ee909860e98207a38b87ae22cad03a the key for\nverifying release packages from ceph.com was removed when support for\nthe ceph package mirrors was added. However, it is still needed for\nnon-gate case of fetching packages from ceph.com, so this adds it\nback in that case.\n\nChange-Id: I18f8927f42710e9365c246c55f26f53403965ee1\n'}, {'number': 2, 'created': '2016-05-05 05:40:28.000000000', 'files': ['devstack/lib/ceph'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/fe06350c48de1389f336ba598ea428bf78871b1b', 'message': 'Add release key for installing packages from ceph.com\n\nIn commit bb773e7285ee909860e98207a38b87ae22cad03a the key for\nverifying release packages from ceph.com was removed when support for\nthe ceph package mirrors was added. However, it is still needed for\nnon-gate case of fetching packages from ceph.com, so this adds it\nback in that case.\n\nCloses-Bug: #1578494\n\nChange-Id: I18f8927f42710e9365c246c55f26f53403965ee1\n'}]",2,312710,fe06350c48de1389f336ba598ea428bf78871b1b,11,3,2,4690,,,0,"Add release key for installing packages from ceph.com

In commit bb773e7285ee909860e98207a38b87ae22cad03a the key for
verifying release packages from ceph.com was removed when support for
the ceph package mirrors was added. However, it is still needed for
non-gate case of fetching packages from ceph.com, so this adds it
back in that case.

Closes-Bug: #1578494

Change-Id: I18f8927f42710e9365c246c55f26f53403965ee1
",git fetch https://review.opendev.org/openstack/devstack-plugin-ceph refs/changes/10/312710/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ceph'],1,854d3c166476734f25befc5129e4670b0184c489,bug/1578494, # install the release key for ceph.com package authentication wget -q -O- 'https://download.ceph.com/keys/release.asc' \ | sudo apt-key add -,,4,0
openstack%2Fopenstack-ansible~liberty~Ic3c688de7c547eda73bbd0b4893010e18f401a86,openstack/openstack-ansible,liberty,Ic3c688de7c547eda73bbd0b4893010e18f401a86,Updates all SHAs for 12.0.12,MERGED,2016-04-22 16:57:34.000000000,2016-05-05 17:20:19.000000000,2016-05-05 17:20:19.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 15993}]","[{'number': 1, 'created': '2016-04-22 16:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b968666f08ac669f22cdfd6d068d3ab5aeecaeaf', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}, {'number': 2, 'created': '2016-04-22 17:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bb5ddd23bff231c8f75c969fc2289f671c3aba1e', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}, {'number': 3, 'created': '2016-04-22 17:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e5be1b0e80c8a512be078e0e62e58130ccff80a8', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nThe wheel pin is permanently set to 0.26.0 in order to match the\nupper-constraint in OpenStack Liberty which remains static once a\nbranch becomes stable.\n\nThe sources-branch-updater script has been changed to ensure that\nthis constraint always remains constant.\n\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}, {'number': 4, 'created': '2016-05-03 14:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7b10638599b6ad0bf5cd23991833d0ee91c0fb06', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nThe wheel pin is permanently set to 0.26.0 in order to match the\nupper-constraint in OpenStack Liberty which remains static once a\nbranch becomes stable.\n\nThe sources-branch-updater script has been changed to ensure that\nthis constraint always remains constant.\n\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}, {'number': 5, 'created': '2016-05-05 11:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/782f5647297ab5a873e412fbcaf61f543206d09e', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nThe wheel pin is permanently set to 0.26.0 in order to match the\nupper-constraint in OpenStack Liberty which remains static once a\nbranch becomes stable.\n\nThe sources-branch-updater script has been changed to ensure that\nthis constraint always remains constant.\n\nDepends-On: Icea4cb2ac3229a65d010594c03c7fbbe4c8e2d72\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}, {'number': 6, 'created': '2016-05-05 14:54:47.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'global-requirement-pins.txt', 'scripts/sources-branch-updater.sh', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/353513de22112601cea02c062fdf4dc094421ec0', 'message': 'Updates all SHAs for 12.0.12\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nThe wheel pin is permanently set to 0.26.0 in order to match the\nupper-constraint in OpenStack Liberty which remains static once a\nbranch becomes stable.\n\nThe sources-branch-updater script has been changed to ensure that\nthis constraint always remains constant.\n\nThe python package python-openstackclient is temporarily pinned to\n1.7.2 in order to ensure that it can be co-installed with other\nupper-constrained packages in the utility container. This pin can\nbe removed once https://review.openstack.org/312581 merges.\n\nChange-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86\n'}]",0,309511,353513de22112601cea02c062fdf4dc094421ec0,19,5,6,6816,,,0,"Updates all SHAs for 12.0.12

This patch includes updates of any changed paste, policy and rootwrap
configurations. It also includes updates to the pip, wheel and
setuptools pins.

The wheel pin is permanently set to 0.26.0 in order to match the
upper-constraint in OpenStack Liberty which remains static once a
branch becomes stable.

The sources-branch-updater script has been changed to ensure that
this constraint always remains constant.

The python package python-openstackclient is temporarily pinned to
1.7.2 in order to ensure that it can be co-installed with other
upper-constrained packages in the utility container. This pin can
be removed once https://review.openstack.org/312581 merges.

Change-Id: Ic3c688de7c547eda73bbd0b4893010e18f401a86
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/11/309511/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml']",6,b968666f08ac669f22cdfd6d068d3ab5aeecaeaf,309511,openstack_release: 12.0.12,openstack_release: 12.0.10,23,23
openstack%2Fopenstack-manuals~master~I90da3e27cdd008c17c6e4df188d88a609451a14a,openstack/openstack-manuals,master,I90da3e27cdd008c17c6e4df188d88a609451a14a,[User Guides] Adds DVR/SNAT ha to Networking Guide,ABANDONED,2016-03-23 19:24:16.000000000,2016-05-05 17:20:03.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9515}, {'_account_id': 13770}]","[{'number': 1, 'created': '2016-03-23 19:24:16.000000000', 'files': ['doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.svg', 'doc/networking-guide/source/scenario-dvr-ovs.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-hw.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-networks.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-networks.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.png', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.graffle', 'doc/networking-guide/source/scenario-dvr-snat-ha-ovs.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.graffle'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0368bd2ff25bb45ac314086e6daa7081d7cfc684', 'message': '[User Guides] Adds DVR/SNAT ha to Networking Guide\n\nDVR/SNAT ha is a new feature in Mitaka release,\npatch adds necessary scenario to networking guide.\n\nChange-Id: I90da3e27cdd008c17c6e4df188d88a609451a14a\n'}]",21,296711,0368bd2ff25bb45ac314086e6daa7081d7cfc684,10,8,1,13770,,,0,"[User Guides] Adds DVR/SNAT ha to Networking Guide

DVR/SNAT ha is a new feature in Mitaka release,
patch adds necessary scenario to networking guide.

Change-Id: I90da3e27cdd008c17c6e4df188d88a609451a14a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/296711/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network1.svg', 'doc/networking-guide/source/scenario-dvr-ovs.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-hw.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-networks.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-networks.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.graffle', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.png', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-services.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-general.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.svg', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-network2.png', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute2.graffle', 'doc/networking-guide/source/scenario-dvr-snat-ha-ovs.rst', 'doc/networking-guide/source/figures/scenario-dvr-snat-ha-compute1.graffle']",24,0368bd2ff25bb45ac314086e6daa7081d7cfc684,dvr_ha,,,1631,1
openstack%2Ftempest~master~I931d891b42bb1925ca032bc7b262c90c4d5fee71,openstack/tempest,master,I931d891b42bb1925ca032bc7b262c90c4d5fee71,DVRHA tests,ABANDONED,2015-09-24 18:16:21.000000000,2016-05-05 17:19:16.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 13770}, {'_account_id': 15739}]","[{'number': 1, 'created': '2015-09-24 18:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/856c1b0dcc60a90b22ab99bb488444eaf145a74c', 'message': 'This set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}, {'number': 2, 'created': '2015-12-16 02:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7e94b1d35de249acd67e60f90a547b0a82b85e8f', 'message': 'DVRHA tests\n\nTest 1:\nThis set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}, {'number': 3, 'created': '2016-01-27 23:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee4feec5fca16875ded59c50f5fe240ee0b40f9b', 'message': 'DVRHA tests\n\nTest 1:\nThis set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}, {'number': 4, 'created': '2016-04-13 05:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a15526a6734bd1c58de762b53dde85d8425f89d', 'message': 'DVRHA tests\n\nTest 1:\nThis set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}, {'number': 6, 'created': '2016-04-14 00:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c8d94d64ae0bccaa519f9ade8924848fa4052b7', 'message': 'DVRHA tests\n\nTest 1:\nThis set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}, {'number': 7, 'created': '2016-04-15 23:10:31.000000000', 'files': ['tempest/api/network/admin/test_routers_dvr.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/075bc9cf56549a31c5f7cb541fd3180f4a58ca96', 'message': 'DVRHA tests\n\nTest 1:\nThis set of tests checks possible transitions of\na state machine representing dvrha router.\n\nThe possible states are:\n\nrouter exists\nrouter exists and has external gateway\nrouter exists and has internal network\nrouter exists and has external gateway and internal network\nrouter does not exist (deletion)\n\nChange-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71\n'}]",0,227450,075bc9cf56549a31c5f7cb541fd3180f4a58ca96,29,5,6,13770,,,0,"DVRHA tests

Test 1:
This set of tests checks possible transitions of
a state machine representing dvrha router.

The possible states are:

router exists
router exists and has external gateway
router exists and has internal network
router exists and has external gateway and internal network
router does not exist (deletion)

Change-Id: I931d891b42bb1925ca032bc7b262c90c4d5fee71
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/227450/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/admin/test_routers_dvr.py'],1,856c1b0dcc60a90b22ab99bb488444eaf145a74c,dvrha_testing,"from tempest_lib.exceptions import NotImplemented from tempest import configCONF = config.CONF class RouterTestDVRBase(base.BaseRouterTest): super(RouterTestDVRBase, cls).resource_setup() import time time.sleep(2) class RoutersTestDVR(RouterTestDVRBase): @classmethod def resource_setup(cls): super(RoutersTestDVR, cls).resource_setup() # noinspection PyMethodOverriding,PyMethodOverriding class RoutersTestDVRHA(RouterTestDVRBase): @classmethod def resource_setup(cls): super(RoutersTestDVRHA, cls).resource_setup() # Next we check if deployment supports dvrha routers cls.dvrHaImplemented = True name = data_utils.rand_name('dvrha-pretest-check') try: router = cls.admin_client.create_router(name, distributed=True, ha=True) except NotImplemented: msg = ""DVRHA routed not implemented in this setup"" raise cls.skipException(msg) import time time.sleep(2) if router: cls.admin_client.delete_router(router['router']['id']) def setUp(self): super(RoutersTestDVRHA, self).setUp() network_name = data_utils.rand_name('dvrha-internal-network-') self.internal_network = self.admin_client.create_network( name=network_name) self.addCleanup(self.admin_client.delete_network, self.internal_network['network']['id']) subnet_name = data_utils.rand_name('dvrha-internal-subnet-') self.internal_subnet = self.admin_client.create_subnet( network_id=self.internal_network['network']['id'], ip_version=4, cidr=""103.0.0.0/24"", name=subnet_name ) self.addCleanup(self.admin_client.delete_subnet, self.internal_subnet['subnet']['id']) def tearDown(self): super(RoutersTestDVRHA, self).tearDown() def _get_ha_interface_list_for_router(self, router): port_list = self.admin_client.list_ports( device_owner=""network:router_ha_interface"", device_id=router['router']['id']) return port_list['ports'] def _get_external_gateway(self, router): port_list = self.admin_client.list_ports( device_owner=""network:router_gateway"", device_id=router['router']['id']) return port_list['ports'] def _check_dvr_ha_interfaces_are_present(self, router): """""" Returns True if at least two ha interfaces are found for the router. One for each dvr_snat node """""" ha_count = len(self._get_ha_interface_list_for_router(router)) self.assertGreater(ha_count, 1) def _check_dvr_ha_interfaces_are_not_present(self, router): ha_count = len(self._get_ha_interface_list_for_router(router)) self.assertLess(ha_count, 1) def _check_snat_external_gateway_is_present(self, router): """""" Return True if more than one port exists which is flagged as network:router_gateway """""" gw_count = len(self. _get_external_gateway(router)) self.assertGreater(gw_count, 0) def _check_snat_external_gateway_is_not_present(self, router): gw_count = len(self. _get_external_gateway(router)) self.assertLess(gw_count, 1) def _get_internal_subnet_snat_ports(self, router): port_list = self.admin_client.list_ports( device_owner=""network:router_centralized_snat"", network_id=self.internal_subnet['subnet']['network_id'], device_id=router['router']['id']) return port_list['ports'] def _check_snat_internal_gateways_are_present(self, router): i_snat_port_count = len(self._get_internal_subnet_snat_ports(router)) self.assertGreater(i_snat_port_count, 0) def _check_snat_internal_gateways_are_not_present(self, router): i_snat_port_count = len(self._get_internal_subnet_snat_ports(router)) self.assertLess(i_snat_port_count, 1) def _set_external_gateway(self, router): self.admin_client.update_router_with_snat_gw_info( router['router']['id'], external_gateway_info={ 'network_id': CONF.network.public_network_id, 'enable_snat': True}) def _clear_external_gateway(self, router): self.admin_client.update_router_with_snat_gw_info( router['router']['id'], external_gateway_info={} ) def _create_router(self, name): router = self.admin_client.create_router(name, distributed=True, ha=True) return router def _delete_router(self, router): self.admin_client.delete_router(router['router']['id']) def _add_interface_to_router(self, router): self.admin_client.add_router_interface_with_subnet_id( router['router']['id'], self.internal_subnet['subnet']['id']) def _remove_interface_from_router(self, router): self.admin_client.remove_router_interface_with_subnet_id( router['router']['id'], self.internal_subnet['subnet']['id']) def _get_internal_subnet_ports(self, router): port_list = self.admin_client.list_ports( device_owner=""network:router_interface_distributed"", network_id=self.internal_subnet['subnet']['network_id'], device_id=router['router']['id']) return port_list['ports'] def _check_internal_interfaces_are_present(self, router): intern_port_count = len(self._get_internal_subnet_ports(router)) self.assertGreater(intern_port_count, 0) def _check_internal_interfaces_are_not_present(self, router): intern_port_count = len(self._get_internal_subnet_ports(router)) self.assertLess(intern_port_count, 1) def _schedule_router_for_deletion_at_end_of_test(self, router): self.addCleanup(self.admin_client.delete_router, router['router']['id']) def _create_internal_subnet(self, ip_cidr): network_name = data_utils.rand_name('dvrha-internal-network-') network = self.admin_client.create_network(name=network_name) subnet_name = data_utils.rand_name('dvrha-internal-subnet-') subnet = self.admin_client.create_subnet( network_id=network['network']['id'], ip_version=4, cidr=ip_cidr, name=subnet_name ) return subnet @test.idempotent_id('033c7209-0c9f-46b6-8091-1cf475cc9ad1') def test_dvr_ha_router_state_machine_path_1(self): name = data_utils.rand_name('router_path_1') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router) @test.idempotent_id('1cb14b07-52c9-4dcb-baab-a1b01f962a8c') def test_dvr_ha_router_state_machine_path_2(self): name = data_utils.rand_name('router_path_2') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._set_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router) self._check_snat_external_gateway_is_not_present(router) @test.idempotent_id('b0f2d322-6669-46d8-a842-1915980d52ab') def test_dvr_ha_router_state_machine_path_3(self): name = data_utils.rand_name('router_path_3') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._set_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._clear_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self._check_snat_external_gateway_is_not_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router) @test.idempotent_id('4509fd8e-f459-4b88-9b18-f3d4a4e43f5a') def test_dvr_ha_router_state_machine_path_4(self): name = data_utils.rand_name('router_path_4') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._set_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._add_interface_to_router(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._check_internal_interfaces_are_present(router) self._check_snat_internal_gateways_are_present(router) self._remove_interface_from_router(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._check_internal_interfaces_are_not_present(router) self._check_snat_internal_gateways_are_not_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router) self._check_snat_external_gateway_is_not_present(router) @test.idempotent_id('aa664521-7569-454d-8151-ca8de8c9948f') def test_dvr_ha_router_state_machine_path_5(self): name = data_utils.rand_name('router_path_5') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._add_interface_to_router(router) self._check_internal_interfaces_are_present(router) self._remove_interface_from_router(router) self._check_internal_interfaces_are_not_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router) @test.idempotent_id('8b66ee8e-5563-4b55-9ebb-3f82aae7333d') def test_dvr_ha_router_state_machine_path_6(self): name = data_utils.rand_name('router_path_6') router = self._create_router(name) self.assertTrue(router['router']['distributed']) self.assertTrue(router['router']['ha']) self._check_dvr_ha_interfaces_are_present(router) self._add_interface_to_router(router) self._check_internal_interfaces_are_present(router) self._set_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self. _check_snat_external_gateway_is_present(router) self._check_internal_interfaces_are_present(router) self._check_snat_internal_gateways_are_present(router) self._clear_external_gateway(router) self._check_dvr_ha_interfaces_are_present(router) self._check_snat_external_gateway_is_not_present(router) self._check_snat_internal_gateways_are_not_present(router) self._check_internal_interfaces_are_present(router) self._remove_interface_from_router(router) self._check_internal_interfaces_are_not_present(router) self._delete_router(router) self._check_dvr_ha_interfaces_are_not_present(router)","class RoutersTestDVR(base.BaseRouterTest): super(RoutersTestDVR, cls).resource_setup()",296,2
openstack%2Ffuel-ostf~stable%2Fmitaka~I64a11b4e1a12cd48109be625bbf4325d1d42686b,openstack/fuel-ostf,stable/mitaka,I64a11b4e1a12cd48109be625bbf4325d1d42686b,[Murano] Update service_type and auth strategy for murano,MERGED,2016-04-14 15:47:13.000000000,2016-05-05 17:15:57.000000000,2016-05-05 10:58:33.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10136}, {'_account_id': 13505}, {'_account_id': 13919}, {'_account_id': 13962}, {'_account_id': 14614}, {'_account_id': 14691}, {'_account_id': 17270}, {'_account_id': 18796}, {'_account_id': 18913}, {'_account_id': 19016}, {'_account_id': 20656}, {'_account_id': 21649}]","[{'number': 1, 'created': '2016-04-14 15:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/5eea1012021b64f53b233311917a9c0a4fe52a43', 'message': '[Murano] Update service_type and auth strategy for murano\n\n- Replace application_catalog to application-catalog\n- Use http_client attribute to get auth_token from muranoclient\n\nChange-Id: I64a11b4e1a12cd48109be625bbf4325d1d42686b\nCloses-Bug: #1558189\n(cherry picked from commit 60c3b3c6b910f8312d912e322e9ff3159958e3aa)\n'}, {'number': 2, 'created': '2016-04-28 17:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b094c33718ef7545adc09701cec7f1e551eaf71d', 'message': '[Murano] Update service_type and auth strategy for murano\n\n- Replace application_catalog to application-catalog\n- Use http_client attribute to get auth_token from muranoclient\n\nChange-Id: I64a11b4e1a12cd48109be625bbf4325d1d42686b\nCloses-Bug: #1558189\n(cherry picked from commit 60c3b3c6b910f8312d912e322e9ff3159958e3aa)\n'}, {'number': 3, 'created': '2016-05-04 12:54:59.000000000', 'files': ['fuel_health/nmanager.py', 'fuel_health/muranomanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/5ddbe9ee6b23b2b60f621c0a7a2095996f706bd5', 'message': '[Murano] Update service_type and auth strategy for murano\n\n- Replace application_catalog to application-catalog\n- Use http_client attribute to get auth_token from muranoclient\n\nChange-Id: I64a11b4e1a12cd48109be625bbf4325d1d42686b\nCloses-Bug: #1558189\n(cherry picked from commit 60c3b3c6b910f8312d912e322e9ff3159958e3aa)\n'}]",0,305949,5ddbe9ee6b23b2b60f621c0a7a2095996f706bd5,43,22,3,13962,,,0,"[Murano] Update service_type and auth strategy for murano

- Replace application_catalog to application-catalog
- Use http_client attribute to get auth_token from muranoclient

Change-Id: I64a11b4e1a12cd48109be625bbf4325d1d42686b
Closes-Bug: #1558189
(cherry picked from commit 60c3b3c6b910f8312d912e322e9ff3159958e3aa)
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/49/305949/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/nmanager.py', 'fuel_health/muranomanager.py']",2,5eea1012021b64f53b233311917a9c0a4fe52a43,bug/1558189," service_type='application-catalog', self.headers = { 'X-Auth-Token': self.murano_client.http_client.auth_token, 'content-type': 'application/json' } "," service_type='application_catalog', self.headers = {'X-Auth-Token': self.murano_client.auth_token, 'content-type': 'application/json'}",7,4
openstack%2Fopenstack-ansible-os_heat~master~I1b53521570bd71bdca3d482345403bbc8133df7b,openstack/openstack-ansible-os_heat,master,I1b53521570bd71bdca3d482345403bbc8133df7b,Multi-distro pattern for os_heat role,MERGED,2016-05-02 14:10:26.000000000,2016-05-05 17:14:40.000000000,2016-05-05 17:14:40.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-02 14:10:26.000000000', 'files': ['tasks/main.yml', 'tasks/install-apt.yml', 'vars/debian.yml', 'tasks/heat_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/c05704194bed5c1eb4498ad19bd37539dc852f21', 'message': 'Multi-distro pattern for os_heat role\n\nThis is an implementation of a pattern for multi-distro support\n\nThis allows for support of distros other than Ubuntu\n\nChange-Id: I1b53521570bd71bdca3d482345403bbc8133df7b\n'}]",0,311749,c05704194bed5c1eb4498ad19bd37539dc852f21,14,4,1,19814,,,0,"Multi-distro pattern for os_heat role

This is an implementation of a pattern for multi-distro support

This allows for support of distros other than Ubuntu

Change-Id: I1b53521570bd71bdca3d482345403bbc8133df7b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/49/311749/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/install-apt.yml', 'tasks/main.yml', 'vars/debian.yml', 'tasks/heat_install.yml', 'defaults/main.yml']",5,c05704194bed5c1eb4498ad19bd37539dc852f21,implement_multi_distro,,heat_apt_packages: - rsync - libxslt1.1 ,75,32
openstack%2Fhorizon~master~Ie4195fdccc4d61f8d879f4d7838b644ec79d32ea,openstack/horizon,master,Ie4195fdccc4d61f8d879f4d7838b644ec79d32ea,WIP: clean up some Angular unit tests,ABANDONED,2016-03-07 17:37:04.000000000,2016-05-05 17:13:14.000000000,,"[{'_account_id': 3}, {'_account_id': 14124}]","[{'number': 1, 'created': '2016-03-07 17:37:04.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/129d6f64ebc3a711a823c44d4c837a1358eef603', 'message': 'WIP: clean up some Angular unit tests\n\nThere are some minor unit test holes in some of the features, such as\nthe Launch Instance source-step controller.  This patch fills in those\ngaps.\n\nChange-Id: Ie4195fdccc4d61f8d879f4d7838b644ec79d32ea\n'}]",0,289474,129d6f64ebc3a711a823c44d4c837a1358eef603,4,2,1,14124,,,0,"WIP: clean up some Angular unit tests

There are some minor unit test holes in some of the features, such as
the Launch Instance source-step controller.  This patch fills in those
gaps.

Change-Id: Ie4195fdccc4d61f8d879f4d7838b644ec79d32ea
",git fetch https://review.opendev.org/openstack/horizon refs/changes/74/289474/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.spec.js'],1,129d6f64ebc3a711a823c44d4c837a1358eef603,source-tests," it(""doesn't change default if no image matching"", function() { scope.launchContext = { imageId: 'image-there-is-not-one' }; deferred.resolve(); $browser.defer.flush(); expect(ctrl.tableData.allocated[0]).toBeUndefined(); expect(scope.model.newInstanceSpec.source_type.type).toBe('image'); expect(ctrl.currentBootSource).toBe('image'); }); it(""doesn't change anything if volume not found"", function() { scope.launchContext = { volumeId: 'volume-no-se-existe' }; deferred.resolve(); $browser.defer.flush(); expect(ctrl.tableData.allocated[0]).toBeUndefined(); expect(scope.model.newInstanceSpec.source_type.type).toBe('image'); expect(ctrl.currentBootSource).toBe('image'); }); describe('destroy', function () { it('closes watches', function() { scope.$emit('$destroy'); expect(true).toBe(true); }); }); ",,29,0
openstack%2Fhorizon~master~Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d,openstack/horizon,master,Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d,Adding default option for decode filter,ABANDONED,2016-02-03 16:04:56.000000000,2016-05-05 17:12:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9647}, {'_account_id': 14124}, {'_account_id': 17645}]","[{'number': 1, 'created': '2016-02-03 16:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b57f0f19ab0c8d6db2257668ff83d9b2d65ad49e', 'message': 'Adding default option for decode filter\n\nThis adds an optional parameter to the decode filter that is given the\nkey to the default value if no matching key is found for the input.  For\nexample, if you have a mapping with A=Apple, J=Jacks, and you are given\n\'K\', usually the filter would return \'K.\'  If you supply a default, e.g.\n\'A\', then \'K\' would return \'Apple\'.\n\nThis is to accommodate values such as ""None"" or other cases where values\naren\'t found.  The reason for providing a key and not a value is that it\nmakes it easy to use the same mechansim for localization as for the rest\nof the mapping.\n\nChange-Id: Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d\n'}, {'number': 2, 'created': '2016-02-04 23:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d199ccaa251174e1e6d12e723ecdbd402d361439', 'message': 'Adding default option for decode filter\n\nThis adds an optional parameter to the decode filter that is given the\nkey to the default value if no matching key is found for the input.  For\nexample, if you have a mapping with A=Apple, J=Jacks, and you are given\n\'K\', usually the filter would return \'K.\'  If you supply a default, e.g.\n\'A\', then \'K\' would return \'Apple\'.\n\nThis is to accommodate values such as ""None"" or other cases where values\naren\'t found.  The reason for providing a key and not a value is that it\nmakes it easy to use the same mechansim for localization as for the rest\nof the mapping.\n\nChange-Id: Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d\n'}, {'number': 3, 'created': '2016-03-02 15:05:05.000000000', 'files': ['horizon/static/framework/util/filters/filters.spec.js', 'horizon/static/framework/util/filters/filters.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3382bcb59d291a785efdefa5a5c60e5e5b9ff65d', 'message': 'Adding default option for decode filter\n\nThis adds an optional parameter to the decode filter that is given the\nkey to the default value if no matching key is found for the input.  For\nexample, if you have a mapping with A=Apple, J=Jacks, and you are given\n\'K\', usually the filter would return \'K.\'  If you supply a default, e.g.\n\'A\', then \'K\' would return \'Apple\'.\n\nThis is to accommodate values such as ""None"" or other cases where values\naren\'t found.  The reason for providing a key and not a value is that it\nmakes it easy to use the same mechansim for localization as for the rest\nof the mapping.\n\nChange-Id: Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d\n'}]",5,275788,3382bcb59d291a785efdefa5a5c60e5e5b9ff65d,24,6,3,14124,,,0,"Adding default option for decode filter

This adds an optional parameter to the decode filter that is given the
key to the default value if no matching key is found for the input.  For
example, if you have a mapping with A=Apple, J=Jacks, and you are given
'K', usually the filter would return 'K.'  If you supply a default, e.g.
'A', then 'K' would return 'Apple'.

This is to accommodate values such as ""None"" or other cases where values
aren't found.  The reason for providing a key and not a value is that it
makes it easy to use the same mechansim for localization as for the rest
of the mapping.

Change-Id: Ib5cfe998118daec90c49c8c0f3a4af898db2cc4d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/88/275788/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/filters/filters.spec.js', 'horizon/static/framework/util/filters/filters.js']",2,b57f0f19ab0c8d6db2257668ff83d9b2d65ad49e,decode-updated," return function (input, mapping, def) { return angular.isDefined(val) ? val : angular.isDefined(def) ? mapping[def] : input;"," return function (input, mapping) { return angular.isDefined(val) ? val : input;",9,3
openstack%2Ffuel-web~stable%2Fmitaka~Ia3837f1724d435eb02093fbc1f395a11d5c24007,openstack/fuel-web,stable/mitaka,Ia3837f1724d435eb02093fbc1f395a11d5c24007,Deployment graphs are deleted together with parent entity,ABANDONED,2016-05-05 15:03:02.000000000,2016-05-05 17:04:28.000000000,,"[{'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 15:03:02.000000000', 'files': ['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun/objects/deployment_graph.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/97cee16500ce17b50b887cd726dff1a3d4698bd0', 'message': 'Deployment graphs are deleted together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: Ia3837f1724d435eb02093fbc1f395a11d5c24007\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}]",0,313014,97cee16500ce17b50b887cd726dff1a3d4698bd0,9,2,1,19158,,,0,"Deployment graphs are deleted together with parent entity

When Release, Plugin or Cluster is deleted, related
deployment graphs are deleted as well.

Note, that current DeploymentGraph deletion schema works if
DeploymentGraph have only relation to parent
otherwise unwanted relations may be affected by graph cleanup.

Change-Id: Ia3837f1724d435eb02093fbc1f395a11d5c24007
Closes-Bug: #1567471
Closes-Bug: #1557632
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/14/313014/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun/objects/deployment_graph.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py']",7,97cee16500ce17b50b887cd726dff1a3d4698bd0,bug/1567471," @classmethod def delete(cls, instance): """"""Delete plugin. :param instance: Plugin model instance :type instance: models.Plugin """""" DeploymentGraph.delete_for_parent(instance) super(Plugin, cls).delete(instance) ",,62,0
openstack%2Ffuel-library~master~I5fec43c2fef66c8395a7d3141d486f1db20b50de,openstack/fuel-library,master,I5fec43c2fef66c8395a7d3141d486f1db20b50de,Fix erratum,MERGED,2016-04-29 14:20:13.000000000,2016-05-05 16:57:34.000000000,2016-05-04 07:51:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 13344}, {'_account_id': 14985}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-29 14:20:13.000000000', 'files': ['deployment/puppet/openstack_tasks/examples/roles/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd19bec8810f1f6ceb5e4b522ad977da269cb27b', 'message': 'Fix erratum\n\nFix erratum in top-role-mongo & ironic-conductor tasks.\n\nChange-Id: I5fec43c2fef66c8395a7d3141d486f1db20b50de\n'}]",0,311128,bd19bec8810f1f6ceb5e4b522ad977da269cb27b,34,9,1,16771,,,0,"Fix erratum

Fix erratum in top-role-mongo & ironic-conductor tasks.

Change-Id: I5fec43c2fef66c8395a7d3141d486f1db20b50de
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/311128/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/examples/roles/tasks.yaml'],1,bd19bec8810f1f6ceb5e4b522ad977da269cb27b,yaql_erratum," $.get('use_syslog'), $.debug, $.ceilometer, $.roles) $.get('amqp_hosts'), $.debug, $.verbose, $.get('use_syslog'),"," $.get('use_syslog'), $.gebug, $.ceilometer, $.roles) $.get('amqp_hosts'), $.gebug, $.verbose, $.get('use_syslog'),",2,2
openstack%2Ffuel-web~master~Ibdb2cf85732c0293314298e6a342b071ece18cc3,openstack/fuel-web,master,Ibdb2cf85732c0293314298e6a342b071ece18cc3,Remove 'nodes' from deployment 9.0 serializer output,MERGED,2016-04-21 11:28:09.000000000,2016-05-05 16:48:15.000000000,2016-05-05 16:48:05.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8829}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12661}, {'_account_id': 18205}, {'_account_id': 19158}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-21 11:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6cd90fa0382cef93240e8d92a8f7bcd751ca2e9e', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. However this approach introduces a drawback\nsuch that now separate fixtures must be introduced for each new release.\nThis issue is closely connected with the bug [1] and is know issue with\nNailgun testing infrastructure.\n\n[1]: https://bugs.launchpad.net/fuel/+bug/1517874\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nCloses-Bug: #1531128\n""}, {'number': 2, 'created': '2016-04-22 08:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/26f7ba7bed0f99968c38d9d0cb9992f98e8b9ebf', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. Mapping that stores compatible fixtures for\ndifferent releases added to fixman.load_fake_deployment_tasks. For\nnewton release 9.0 deployment tasks fixture will be used.\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nPartial-Bug: 1517874\nCloses-Bug: #1531128\n""}, {'number': 3, 'created': '2016-04-25 11:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aceed17aef86d6bbe1ece48d3f892118748379fe', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. Mapping that stores compatible fixtures for\ndifferent releases added to fixman.load_fake_deployment_tasks. For\nnewton release 9.0 deployment tasks fixture will be used.\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nPartial-Bug: 1517874\nCloses-Bug: #1531128\n""}, {'number': 4, 'created': '2016-04-26 08:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1b207613916901ccaf448f03efd159c7ecacf284', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. Mapping that stores compatible fixtures for\ndifferent releases added to fixman.load_fake_deployment_tasks. For\nnewton release 9.0 deployment tasks fixture will be used.\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nPartial-Bug: 1517874\nCloses-Bug: #1531128\n""}, {'number': 5, 'created': '2016-04-26 13:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d53afbb972ac6d175b1020f44616e1608af8e4ea', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. Mapping that stores compatible fixtures for\ndifferent releases added to fixman.load_fake_deployment_tasks. For\nnewton release 9.0 deployment tasks fixture will be used.\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nPartial-Bug: 1517874\nCloses-Bug: #1531128\nDepends-On: I795f944ca3b1fc49fae07ddc36c2eabcfcc968ed\n""}, {'number': 6, 'created': '2016-04-27 08:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d772ae6be632f38d3cc61712a2dbf2fc5835f7f8', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. In order to support (and get to\nstate where they more or less reflect actual production\nenvironment) execution of tests utilizing the serializer, separate\nfixture deployment tasks has been created. The only difference with fixture for\nother release versions is that 'upload_nodes_info' task is skipped. Since the\nfixture is uploaded on release creation; method that\nsupplies test environment with proper fixture in accordance to release\nversion being used is added. Mapping that stores compatible fixtures for\ndifferent releases added to fixman.load_fake_deployment_tasks. For\nnewton release 9.0 deployment tasks fixture will be used.\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nPartial-Bug: 1517874\nCloses-Bug: #1531128\nDepends-On: I795f944ca3b1fc49fae07ddc36c2eabcfcc968ed\n""}, {'number': 7, 'created': '2016-04-28 12:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd844fb7fd57cd89c33e2993d73b222a01f08d27', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. Deployment tasks fixture\nchanged: 'nodes' references in yaql expressions changed to\n'network_metadata.nodes'\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nCloses-Bug: #1531128\n""}, {'number': 8, 'created': '2016-05-05 10:12:15.000000000', 'files': ['nailgun/nailgun/fixtures/deployment_tasks.yaml', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_90.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3a8b82887b8a507a122382428bee7b6ca938908d', 'message': ""Remove 'nodes' from deployment 9.0 serializer output\n\nNow serialized deployment info for environments >= 9.0 does not contain\n'nodes' field; it is removed from the output of the serializer.\n\nUnit and integration tests are updated. Deployment tasks fixture\nchanged: 'nodes' references in yaql expressions changed to\n'network_metadata.nodes'\n\nChange-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3\nCloses-Bug: #1531128\n""}]",3,308931,3a8b82887b8a507a122382428bee7b6ca938908d,114,13,8,8931,,,0,"Remove 'nodes' from deployment 9.0 serializer output

Now serialized deployment info for environments >= 9.0 does not contain
'nodes' field; it is removed from the output of the serializer.

Unit and integration tests are updated. Deployment tasks fixture
changed: 'nodes' references in yaql expressions changed to
'network_metadata.nodes'

Change-Id: Ibdb2cf85732c0293314298e6a342b071ece18cc3
Closes-Bug: #1531128
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/31/308931/8 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_fixture_uploading.py', 'nailgun/nailgun/db/sqlalchemy/fixman.py', 'nailgun/nailgun/fixtures/deployment_tasks_90.yaml', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_90.py']",7,6cd90fa0382cef93240e8d92a8f7bcd751ca2e9e,bug/1517874,"from nailgun.db.sqlalchemy import modelsfrom nailgun.orchestrator.deployment_serializers import \ get_serializer_for_clusterfrom nailgun.orchestrator.orchestrator_graph import AstuteGraph def test_remove_nodes_from_common_attrs(self): cluster_db = self.env.clusters[0] serializer = self.create_serializer(cluster_db) common_attrs = serializer.get_common_attrs(cluster_db) self.assertNotIn('nodes', common_attrs) # This test is replaced as 'nodes' field is no longer present in # data serialized by 9.0 version serializer def test_network_not_mapped_to_nics_w_template(self): # delete and restore management network to break the default # networks to interfaces mapping resp = self.app.get( reverse('NetworkGroupCollectionHandler', kwargs=self.env.clusters[0]), headers=self.default_headers, expect_errors=False ) management = None for ng in jsonutils.loads(resp.body): if ng['name'] == 'management': management = ng break self.app.delete( reverse( 'NetworkGroupHandler', kwargs={'obj_id': management.pop('id')} ), headers=self.default_headers ) self.app.post( reverse('NetworkGroupCollectionHandler'), jsonutils.dumps(management), headers=self.default_headers, expect_errors=False, ) resp = self.app.get( reverse('NetworkGroupCollectionHandler', kwargs=self.env.clusters[0]), headers=self.default_headers, expect_errors=False ) # management network is not mapped to any interfaces in DB now cluster_db = self.db.query(models.Cluster).get(self.cluster['id']) objects.Cluster.prepare_for_deployment(cluster_db) serializer = get_serializer_for_cluster(cluster_db) self.serialized_for_astute = serializer( AstuteGraph(cluster_db)).serialize(cluster_db, cluster_db.nodes) network_roles = [ 'management', 'swift/api', 'neutron/api', 'sahara/api', 'ceilometer/api', 'cinder/api', 'keystone/api', 'glance/api', 'heat/api', 'nova/api', 'murano/api', 'horizon', 'mgmt/memcache', 'mgmt/database', 'mgmt/messaging', 'neutron/mesh', 'mgmt/vip', 'mgmt/corosync', 'mongo/db', 'nova/migration' ] for node_data in self.serialized_for_astute: nodes = node_data['network_metadata']['nodes'] for node_name, node_attrs in nodes.items(): # IPs must be serialized for these roles which are tied to # management network for role in network_roles: self.assertIsNotNone(node_attrs['network_roles'][role]) ",,374,7
openstack%2Fpython-barbicanclient~master~I1ec4050c9f9e0906635eff764add16b4b804804e,openstack/python-barbicanclient,master,I1ec4050c9f9e0906635eff764add16b4b804804e,Censoring secrets payload value from debug log,MERGED,2016-04-07 22:21:55.000000000,2016-05-05 16:42:22.000000000,2016-05-05 16:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 10873}, {'_account_id': 16046}]","[{'number': 1, 'created': '2016-04-07 22:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/31292ee9ad36740fff9abe2bf87c2196a5fd6f01', 'message': 'Censoring secrets payload value from debug log\n\nAdded utility method to censor dict values by keys.\n\nChange-Id: I1ec4050c9f9e0906635eff764add16b4b804804e\nCloses-Bug: 1567029\n'}, {'number': 2, 'created': '2016-04-08 16:33:09.000000000', 'files': ['barbicanclient/base.py', 'barbicanclient/containers.py', 'barbicanclient/tests/test_base.py', 'barbicanclient/secrets.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/d1340572c500f13442d467fc6863b1be796060fd', 'message': 'Censoring secrets payload value from debug log\n\nAdded utility method to censor dict values by keys.\n\nChange-Id: I1ec4050c9f9e0906635eff764add16b4b804804e\nCloses-Bug: #1567029\n'}]",1,303101,d1340572c500f13442d467fc6863b1be796060fd,9,3,2,1091,,,0,"Censoring secrets payload value from debug log

Added utility method to censor dict values by keys.

Change-Id: I1ec4050c9f9e0906635eff764add16b4b804804e
Closes-Bug: #1567029
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/01/303101/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/base.py', 'barbicanclient/containers.py', 'barbicanclient/tests/test_base.py', 'barbicanclient/secrets.py']",4,31292ee9ad36740fff9abe2bf87c2196a5fd6f01,bug/1567029," LOG.debug(""Request body: {0}"".format(base.censored_copy(secret_dict, ['payload'])))"," LOG.debug(""Request body: {0}"".format(secret_dict))",22,3
openstack%2Fopenstack-manuals~master~I7478cc99adec8c1f421c043fd2daaba6ef4ca913,openstack/openstack-manuals,master,I7478cc99adec8c1f421c043fd2daaba6ef4ca913,Remove work around for fix released problem,MERGED,2016-05-05 10:59:35.000000000,2016-05-05 16:41:53.000000000,2016-05-05 16:41:52.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9382}, {'_account_id': 16237}, {'_account_id': 17106}]","[{'number': 1, 'created': '2016-05-05 10:59:35.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/07396af70a606b056b177bc0a3a3df1cf03469f0', 'message': 'Remove work around for fix released problem\n\nChange-Id: I7478cc99adec8c1f421c043fd2daaba6ef4ca913\n'}]",0,312895,07396af70a606b056b177bc0a3a3df1cf03469f0,9,5,1,10497,,,0,"Remove work around for fix released problem

Change-Id: I7478cc99adec8c1f421c043fd2daaba6ef4ca913
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/95/312895/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,07396af70a606b056b177bc0a3a3df1cf03469f0,doc8,"ignore-path = doc/*/target,doc/*/build*,doc/install-guide/source/swift-controller-include.txt","# TODO(samos123): remove sriov from ignore when fix for #1487302 is in doc8 ignore-path = doc/*/target,doc/*/build*,doc/networking-guide/source/adv-config-sriov.rst,doc/install-guide/source/swift-controller-include.txt",1,2
openstack%2Ftosca-parser~master~I1e38665aa5c022f31106f49b5c0813ed181710ff,openstack/tosca-parser,master,I1e38665aa5c022f31106f49b5c0813ed181710ff,tosca.nodes.nfv.CP definition is error,MERGED,2016-04-27 07:06:42.000000000,2016-05-05 16:36:59.000000000,2016-05-05 16:36:59.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 7514}, {'_account_id': 12455}, {'_account_id': 16059}, {'_account_id': 16511}]","[{'number': 1, 'created': '2016-04-27 07:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/dce2ca9ceed10b092270ca21670478d719a8f275', 'message': 'tosca.nodes.nfv.CP definition is error\n\nThe virtualLink requirement of tosca.nodes.nfv.CP defined below:\n   - virtualLink:\n       capability: tosca.capabilities.VirtualLinkable\nBut the tosca.capabilities.VirtualLinkable does not exsit in simple\ntosca(which is tosca.capabilities.Linkable), it should be\ntosca.capabilities.nfv.VirtualLinkable in nfv tosca.\n\nAdditionally, the attribute definition of IP_address in CP does not\nneed because the parent node type tosca.nodes.network.Port\nalso includes the same attributes ip_address.\n\nbugs: https://bugs.launchpad.net/tosca-parser/+bug/1574715\n\nChange-Id: I1e38665aa5c022f31106f49b5c0813ed181710ff\nSigned-off-by: shangxdy <shang.xiaodong@zte.com.cn>\n'}, {'number': 2, 'created': '2016-04-27 07:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/7275040e9d1b85ad0a186c7aec81dafa8e2944b0', 'message': 'tosca.nodes.nfv.CP definition is error\n\nThe virtualLink requirement of tosca.nodes.nfv.CP defined below:\n   - virtualLink:\n       capability: tosca.capabilities.VirtualLinkable\nBut the tosca.capabilities.VirtualLinkable does not exsit in simple\ntosca(which is tosca.capabilities.Linkable), it should be\ntosca.capabilities.nfv.VirtualLinkable in nfv tosca.\n\nAdditionally, the attribute definition of IP_address in CP does not\nneed because the parent node type tosca.nodes.network.Port\nalso includes the same attributes ip_address.\n\nbugs: https://bugs.launchpad.net/tosca-parser/+bug/1574715\n\nChange-Id: I1e38665aa5c022f31106f49b5c0813ed181710ff\nSigned-off-by: shangxdy <shang.xiaodong@zte.com.cn>\n'}, {'number': 3, 'created': '2016-05-05 13:50:46.000000000', 'files': ['toscaparser/extensions/nfv/TOSCA_nfv_definition_1_0.yaml'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/63352ebb536796f81758cffdc0d03e61fdd686ac', 'message': 'tosca.nodes.nfv.CP definition is error\n\nThe virtualLink requirement of tosca.nodes.nfv.CP defined below:\n   - virtualLink:\n       capability: tosca.capabilities.VirtualLinkable\nBut the tosca.capabilities.VirtualLinkable does not exsit in simple\ntosca(which is tosca.capabilities.Linkable), it should be\ntosca.capabilities.nfv.VirtualLinkable in nfv tosca.\n\nAdditionally, the attribute definition of IP_address in CP does not\nneed because the parent node type tosca.nodes.network.Port\nalso includes the same attributes ip_address, it will be changede to\naddress according to the new spce.\n\nbugs: https://bugs.launchpad.net/tosca-parser/+bug/1574715\n\nChange-Id: I1e38665aa5c022f31106f49b5c0813ed181710ff\nSigned-off-by: shangxdy <shang.xiaodong@zte.com.cn>\n'}]",14,310359,63352ebb536796f81758cffdc0d03e61fdd686ac,26,7,3,16059,,,0,"tosca.nodes.nfv.CP definition is error

The virtualLink requirement of tosca.nodes.nfv.CP defined below:
   - virtualLink:
       capability: tosca.capabilities.VirtualLinkable
But the tosca.capabilities.VirtualLinkable does not exsit in simple
tosca(which is tosca.capabilities.Linkable), it should be
tosca.capabilities.nfv.VirtualLinkable in nfv tosca.

Additionally, the attribute definition of IP_address in CP does not
need because the parent node type tosca.nodes.network.Port
also includes the same attributes ip_address, it will be changede to
address according to the new spce.

bugs: https://bugs.launchpad.net/tosca-parser/+bug/1574715

Change-Id: I1e38665aa5c022f31106f49b5c0813ed181710ff
Signed-off-by: shangxdy <shang.xiaodong@zte.com.cn>
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/59/310359/1 && git format-patch -1 --stdout FETCH_HEAD,['toscaparser/extensions/nfv/TOSCA_nfv_definition_1_0.yaml'],1,dce2ca9ceed10b092270ca21670478d719a8f275,bug-nfv-cp-definition, capability: tosca.capabilities.nfv.VirtualLinkable,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may capability: tosca.capabilities.VirtualLinkable attributes: IP_address: type: string required: false",2,6
openstack%2Ffuel-library~stable%2F6.1~I813845c08617ecb7ac728ffe5665e2120e267cd3,openstack/fuel-library,stable/6.1,I813845c08617ecb7ac728ffe5665e2120e267cd3,Excluded upstart log files from OS logrotate job processing,MERGED,2016-05-05 10:09:15.000000000,2016-05-05 16:31:17.000000000,2016-05-05 16:30:26.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}, {'_account_id': 13505}, {'_account_id': 14689}, {'_account_id': 14985}, {'_account_id': 19234}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 10:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/08c235186a22e42a8f7d1c629de013a9bf094b86', 'message': ""Excluded upstart log files from OS logrotate job processing\n\nUpstart log files contain stdout output from started daemons.\nThere are two logrotate cron jobs: fuel-logrotate in root's\ncrontab nd logrotate cron job. The first one runs every 30\nminutes, second one -- daily. Both jobs are responsible for\nrotating Upstart's logs, second job doesn't do it properly:\nit renames existing log file to log.1 file, but openstack\nprocesses can't understand job's signal about changed log\nfile and still writes logs to renamed files (bug #1297705).\nTo solve this issue we need to exclude upstart dir\nconfiguration from daily runed logrotate job's objects.\n\nChange-Id: I813845c08617ecb7ac728ffe5665e2120e267cd3\nCloses-bug: #1499349\n""}, {'number': 2, 'created': '2016-05-05 12:08:48.000000000', 'files': ['deployment/puppet/openstack/manifests/logrotate.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/85536fadc87dba0a22a001e516905e989daadae4', 'message': ""Excluded upstart log files from OS logrotate job processing\n\nUpstart log files contain stdout output from started daemons.\nThere are two logrotate cron jobs: fuel-logrotate in root's\ncrontab and logrotate cron job. The first one runs every 30\nminutes, second one -- daily. Both jobs are responsible for\nrotating Upstart's logs, but second job doesn't rotate them\nproperly. logrotate cron job renames existing .log file to\n.log.1 file, but some openstack processes doesn't understand\nsignals about changed log file. They still write their logs\nto renamed files (bug #1297705).\nTo solve this issue we need to exclude upstart dir\nconfiguration from daily logrotate job config.\n\nChange-Id: I813845c08617ecb7ac728ffe5665e2120e267cd3\nCloses-bug: #1499349\n""}]",0,312884,85536fadc87dba0a22a001e516905e989daadae4,41,13,2,19234,,,0,"Excluded upstart log files from OS logrotate job processing

Upstart log files contain stdout output from started daemons.
There are two logrotate cron jobs: fuel-logrotate in root's
crontab and logrotate cron job. The first one runs every 30
minutes, second one -- daily. Both jobs are responsible for
rotating Upstart's logs, but second job doesn't rotate them
properly. logrotate cron job renames existing .log file to
.log.1 file, but some openstack processes doesn't understand
signals about changed log file. They still write their logs
to renamed files (bug #1297705).
To solve this issue we need to exclude upstart dir
configuration from daily logrotate job config.

Change-Id: I813845c08617ecb7ac728ffe5665e2120e267cd3
Closes-bug: #1499349
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/84/312884/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/logrotate.pp'],1,08c235186a22e42a8f7d1c629de013a9bf094b86,bug/1499349," line => 'tabooext + .nodaily upstart',"," line => 'tabooext + .nodaily',",1,1
openstack%2Fglance~master~I3053a637bc0fd418138fbb8195b7ddec9f34f333,openstack/glance,master,I3053a637bc0fd418138fbb8195b7ddec9f34f333,Closes-Bug: #1521581,ABANDONED,2016-01-15 06:37:18.000000000,2016-05-05 16:26:35.000000000,,[{'_account_id': 12000}],"[{'number': 1, 'created': '2016-01-15 06:37:18.000000000', 'files': ['glance/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/2361a262a7ba039c6bd979480977c498fc2fdec1', 'message': 'Closes-Bug: #1521581\n\nChange-Id: I3053a637bc0fd418138fbb8195b7ddec9f34f333\n'}]",0,267964,2361a262a7ba039c6bd979480977c498fc2fdec1,5,1,1,19954,,,0,"Closes-Bug: #1521581

Change-Id: I3053a637bc0fd418138fbb8195b7ddec9f34f333
",git fetch https://review.opendev.org/openstack/glance refs/changes/64/267964/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,2361a262a7ba039c6bd979480977c498fc2fdec1,bug/1521581," 'readonly': true,"," 'readonly' true,",1,1
openstack%2Fmonasca-api~master~I9c1f2e38a2c0bcc20c7079080afd67126ee21908,openstack/monasca-api,master,I9c1f2e38a2c0bcc20c7079080afd67126ee21908,Return 422 when updating with invalid notification method,MERGED,2016-05-02 23:09:33.000000000,2016-05-05 16:17:26.000000000,2016-05-05 16:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12133}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 18179}]","[{'number': 1, 'created': '2016-05-02 23:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/98df1391ae55d15f69e0bbf648ba01cc21052f41', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}, {'number': 2, 'created': '2016-05-03 16:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/15955f56e369ba4bd171e2da65a43a93549b4452', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}, {'number': 3, 'created': '2016-05-03 18:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e54ab72385095492d1b3bd98e8242b9b75e436a7', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\ntest_patch_alarm_definition_with_invalid_actions is added too.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}, {'number': 4, 'created': '2016-05-03 19:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/790caeca4e7f54c59c0aee62821b18431433b2d7', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\ntest_patch_alarm_definition_with_invalid_actions is added too.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}, {'number': 5, 'created': '2016-05-03 19:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/dc3ff8782adc321bbcce40a9ff43601afe270d15', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\ntest_patch_alarm_definition_with_invalid_actions is added too.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}, {'number': 6, 'created': '2016-05-03 19:38:09.000000000', 'files': ['java/src/main/java/monasca/api/app/AlarmDefinitionService.java', 'monasca_api/common/repositories/sqla/alarm_definitions_repository.py', 'monasca_tempest_tests/tests/api/test_alarm_definitions.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ad2deb38fcf214c2b0dc8fc1b1da40333e6efa89', 'message': 'Return 422 when updating with invalid notification method\n\nPython api returned 500 and java api returned 400 when updating\nalarm definition with an invalid notification method. Change both\nto return 422 in this case for both updating and patching alarm\ndefinition.\n\ntest_patch_alarm_definition_with_invalid_actions is added too.\n\nChange-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908\n'}]",2,311887,ad2deb38fcf214c2b0dc8fc1b1da40333e6efa89,25,8,6,18179,,,0,"Return 422 when updating with invalid notification method

Python api returned 500 and java api returned 400 when updating
alarm definition with an invalid notification method. Change both
to return 422 in this case for both updating and patching alarm
definition.

test_patch_alarm_definition_with_invalid_actions is added too.

Change-Id: I9c1f2e38a2c0bcc20c7079080afd67126ee21908
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/87/311887/5 && git format-patch -1 --stdout FETCH_HEAD,"['java/src/main/java/monasca/api/app/AlarmDefinitionService.java', 'monasca_api/common/repositories/sqla/alarm_definitions_repository.py']",2,98df1391ae55d15f69e0bbf648ba01cc21052f41,bug/alarm-action, raise exceptions.InvalidUpdateException(, raise exceptions.RepositoryException(,2,2
openstack%2Freleases~master~I4796aed06196e8df60b868d8f78f18a3a4c919c1,openstack/releases,master,I4796aed06196e8df60b868d8f78f18a3a4c919c1,Release OpenStack-Ansible Kilo/11.2.15,MERGED,2016-05-05 15:47:35.000000000,2016-05-05 16:15:15.000000000,2016-05-05 16:15:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-05-05 15:47:35.000000000', 'files': ['deliverables/_independent/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/983ef24e4a42eb24bceeb8654c5314acca3ac154', 'message': 'Release OpenStack-Ansible Kilo/11.2.15\n\nChange-Id: I4796aed06196e8df60b868d8f78f18a3a4c919c1\n'}]",0,313028,983ef24e4a42eb24bceeb8654c5314acca3ac154,6,2,1,6816,,,0,"Release OpenStack-Ansible Kilo/11.2.15

Change-Id: I4796aed06196e8df60b868d8f78f18a3a4c919c1
",git fetch https://review.opendev.org/openstack/releases refs/changes/28/313028/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/openstack-ansible.yaml'],1,983ef24e4a42eb24bceeb8654c5314acca3ac154,, - version: 11.2.15 projects: - repo: openstack/openstack-ansible hash: 4981ed929613d6ad448dc9b566b458c85491c5f7,,4,0
openstack%2Fsahara-dashboard~stable%2Fmitaka~I386f64b9d907349ee5355ae2f2d04c1a695cb586,openstack/sahara-dashboard,stable/mitaka,I386f64b9d907349ee5355ae2f2d04c1a695cb586,testcommit to test unit running,ABANDONED,2016-05-04 12:39:37.000000000,2016-05-05 16:13:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7132}]","[{'number': 1, 'created': '2016-05-04 12:39:37.000000000', 'files': ['testfile'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/732abbb90c99c61f6533d314f43b80a09302e46e', 'message': 'testcommit to test unit running\n\nChange-Id: I386f64b9d907349ee5355ae2f2d04c1a695cb586\n'}]",0,312483,732abbb90c99c61f6533d314f43b80a09302e46e,4,2,1,12038,,,0,"testcommit to test unit running

Change-Id: I386f64b9d907349ee5355ae2f2d04c1a695cb586
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/83/312483/1 && git format-patch -1 --stdout FETCH_HEAD,['testfile'],1,732abbb90c99c61f6533d314f43b80a09302e46e,,just to test ,,1,0
openstack%2Foctavia~stable%2Fmitaka~If3f315005fcd22afc2f24da527da08175e230bb1,openstack/octavia,stable/mitaka,If3f315005fcd22afc2f24da527da08175e230bb1,Replace the os.open method with safer way,MERGED,2016-04-21 21:20:21.000000000,2016-05-05 16:01:25.000000000,2016-05-05 15:57:19.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6732}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 10477}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 14556}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-04-21 21:20:21.000000000', 'files': ['octavia/amphorae/backends/agent/api_server/keepalived.py', 'octavia/amphorae/backends/agent/api_server/plug.py', 'octavia/amphorae/backends/agent/api_server/certificate_update.py', 'octavia/controller/worker/tasks/compute_tasks.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server_sysvinit.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py', 'octavia/amphorae/backends/agent/api_server/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/8744ad4795c2383224f68bb2a6a39d05c3e15d88', 'message': 'Replace the os.open method with safer way\n\nWrite files using a safer open for writing operations[1].\nModifided the file permission from 666 to 644 in base.j2 to make sure\nconsistenacy between docs and real file permission.\nEdited unit tests based on the new method.\n\n[1] https://security.openstack.org/guidelines/\n            dg_apply-restrictive-file-permissions.html\n\nCloses-Bug: #1548552\nChange-Id: If3f315005fcd22afc2f24da527da08175e230bb1\n(cherry picked from commit bd049810219c89e7c57ea055a2b10441afef8009)\n'}]",0,309183,8744ad4795c2383224f68bb2a6a39d05c3e15d88,16,11,1,11628,,,0,"Replace the os.open method with safer way

Write files using a safer open for writing operations[1].
Modifided the file permission from 666 to 644 in base.j2 to make sure
consistenacy between docs and real file permission.
Edited unit tests based on the new method.

[1] https://security.openstack.org/guidelines/
            dg_apply-restrictive-file-permissions.html

Closes-Bug: #1548552
Change-Id: If3f315005fcd22afc2f24da527da08175e230bb1
(cherry picked from commit bd049810219c89e7c57ea055a2b10441afef8009)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/83/309183/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/agent/api_server/keepalived.py', 'octavia/amphorae/backends/agent/api_server/plug.py', 'octavia/amphorae/backends/agent/api_server/certificate_update.py', 'octavia/controller/worker/tasks/compute_tasks.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server_sysvinit.py', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py', 'octavia/amphorae/backends/agent/api_server/listener.py']",7,8744ad4795c2383224f68bb2a6a39d05c3e15d88,write-security,"import stat flags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC # mode 00600 mode = stat.S_IRUSR | stat.S_IWUSR with os.fdopen(os.open(name, flags, mode), 'w') as file: file = util.init_path(listener_id) # mode 00755 mode = (stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH) if not os.path.exists(file): with os.fdopen(os.open(file, flags, mode), 'w') as text_file: file = _cert_file_path(listener_id, filename) flags = os.O_WRONLY | os.O_CREAT # mode 00600 mode = stat.S_IRUSR | stat.S_IWUSR with os.fdopen(os.open(file, flags, mode), 'w') as crt_file:"," with open(name, 'w') as file: if not os.path.exists(util.init_path(listener_id)): with open(util.init_path(listener_id), 'w') as text_file: # make init.d script executable file = util.init_path(listener_id) permcmd = (""chmod 755 {file}"".format(file=file)) subprocess.check_output(permcmd.split(), stderr=subprocess.STDOUT) with open(_cert_file_path(listener_id, filename), 'w') as crt_file: os.fchmod(crt_file.fileno(), 0o600) # only accessible by owner",213,157
openstack%2Ffuel-qa~stable%2Fmitaka~Ia6c350b36be10b8172fca4927e709c95e9d9a5a3,openstack/fuel-qa,stable/mitaka,Ia6c350b36be10b8172fca4927e709c95e9d9a5a3,Test network bonding with DPDK,MERGED,2016-05-05 12:31:09.000000000,2016-05-05 15:56:10.000000000,2016-05-05 15:56:10.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-05-05 12:31:09.000000000', 'files': ['fuelweb_test/tests/test_dpdk.py', 'fuelweb_test/tests/test_bonding_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/79c6c2bf3572de28eb19eb925652f97cda19955c', 'message': 'Test network bonding with DPDK\n\nTest enabling of DPDK for NICs bond which is used\nby private network.\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n(cherry picked from commit c604e312c918e659e0721b05bc32f736ae2fa4da)\n'}]",0,312920,79c6c2bf3572de28eb19eb925652f97cda19955c,10,7,1,11081,,,0,"Test network bonding with DPDK

Test enabling of DPDK for NICs bond which is used
by private network.

Change-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3
Implements: blueprint test-ovs-dpdk
(cherry picked from commit c604e312c918e659e0721b05bc32f736ae2fa4da)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/20/312920/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_dpdk.py', 'fuelweb_test/tests/test_bonding_base.py']",2,79c6c2bf3572de28eb19eb925652f97cda19955c,bp/test-ovs-dpdk," 'assigned_networks': [], 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, 'assigned_networks': [], 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, class BondingTestDPDK(BondingTest): def __init__(self): super(BondingTestDPDK, self).__init__() self.BOND_CONFIG = [ { 'mac': None, 'mode': 'active-backup', 'name': 'bond0', 'slaves': [ {'name': iface_alias('eth3')}, {'name': iface_alias('eth2')} ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, { 'mac': None, 'mode': 'active-backup', 'name': 'bond1', 'slaves': [ {'name': iface_alias('eth1')}, {'name': iface_alias('eth0')} ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, { 'mac': None, 'mode': 'active-backup', 'name': 'bond2', 'slaves': [ {'name': iface_alias('eth5')}, {'name': iface_alias('eth4')}, ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, ] self.INTERFACES = { 'bond0': [ 'public', 'management', 'storage', ], 'bond1': ['fuelweb_admin'], 'bond2': ['private'], }", 'assigned_networks': [] 'assigned_networks': [],200,30
openstack%2Fnetworking-midonet~master~Ic5dfe5d74d054a179268979d4a19089d71cc7f9c,openstack/networking-midonet,master,Ic5dfe5d74d054a179268979d4a19089d71cc7f9c,Deprecate python-midonetclient mirror,ABANDONED,2016-02-22 10:29:42.000000000,2016-05-05 15:54:58.000000000,,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7505}, {'_account_id': 18602}]","[{'number': 1, 'created': '2016-02-22 10:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/742f449b8599e2e9e0b55d1a63433bd621da8ab1', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 2, 'created': '2016-02-22 11:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/25d9e81756cd1fb9714efb44dc5d60c07615347c', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 3, 'created': '2016-02-22 11:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/bfc308a060ff77714a7bfc1696dc04154e2611f1', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 4, 'created': '2016-02-22 11:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/2c4bbef6cf0bdad9cfb852b971425f000b8ea11e', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 5, 'created': '2016-02-22 14:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/3258564d11092f27d1e41c792b73d3c60fa2e089', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 6, 'created': '2016-02-23 09:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/3c46fa50637ecbf0ee039643843b8a855bff5005', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 7, 'created': '2016-02-23 10:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/6e3d24d0d44a1905c91b4a02c867302351936e26', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient\ndependency in 'requirements.txt', que can get rid of the mirror we\nhave to work synchronized on the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\n""}, {'number': 8, 'created': '2016-04-04 11:52:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/21df4153b3c403799155f36edee32f436e5128eb', 'message': ""Deprecate python-midonetclient mirror\n\nUsing the 'subdirectory' query param in the python-midonetclient dependency in\n'requirements.txt', que can get rid of the mirror we have to work synchronized\non the midonetclient working branch.\n\nChange-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}]",1,283026,21df4153b3c403799155f36edee32f436e5128eb,20,4,8,7505,,,0,"Deprecate python-midonetclient mirror

Using the 'subdirectory' query param in the python-midonetclient dependency in
'requirements.txt', que can get rid of the mirror we have to work synchronized
on the midonetclient working branch.

Change-Id: Ic5dfe5d74d054a179268979d4a19089d71cc7f9c
Signed-off-by: Jaume Devesa <devvesa@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/26/283026/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,742f449b8599e2e9e0b55d1a63433bd621da8ab1,deprecate_mirror,-e git+https://github.com/midonet/midonet/#egg=python-midonetclient&subdirectory=python-midonetclient,-e git://github.com/midonet/python-midonetclient.git@master#egg=midonetclient,1,1
openstack%2Fkuryr~master~I8f868d3b69c1c1b432cdfa6647073c0701935272,openstack/kuryr,master,I8f868d3b69c1c1b432cdfa6647073c0701935272,Remove oslosphinx reference in conf.py,ABANDONED,2016-03-04 09:03:03.000000000,2016-05-05 15:54:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 8279}, {'_account_id': 9820}, {'_account_id': 11278}, {'_account_id': 11343}, {'_account_id': 14352}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-03-04 09:03:03.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/15dcc7e5718c850e4109cd786ea2c3b18da97d30', 'message': ""Remove oslosphinx reference in conf.py\n\nWhen running `make html` it fails because it can not find 'oslosphinx'\nmodule. However, this module does not seem to be needed at all: removing\nthe line and running `make html` again it does not give any problem and\ngenerates the documentation.\n\nChange-Id: I8f868d3b69c1c1b432cdfa6647073c0701935272\n""}]",0,288313,15dcc7e5718c850e4109cd786ea2c3b18da97d30,11,8,1,7505,,,0,"Remove oslosphinx reference in conf.py

When running `make html` it fails because it can not find 'oslosphinx'
module. However, this module does not seem to be needed at all: removing
the line and running `make html` again it does not give any problem and
generates the documentation.

Change-Id: I8f868d3b69c1c1b432cdfa6647073c0701935272
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/13/288313/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,15dcc7e5718c850e4109cd786ea2c3b18da97d30,no_oslosphinx,," 'oslosphinx',",0,1
openstack%2Fopenstack-ansible-os_horizon~master~I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef,openstack/openstack-ansible-os_horizon,master,I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef,Enable IPv6 support in Horizon,MERGED,2016-05-04 20:52:50.000000000,2016-05-05 15:45:30.000000000,2016-05-05 15:45:30.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 18784}]","[{'number': 1, 'created': '2016-05-04 20:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/e45f8f4b376eb2f37229ace22c019c092fce23d6', 'message': 'Enable IPv6 support in Horizon\n\nThis patch creates a variable to control IPv6 support in Horizon\nand enables it by default.\n\nRelease notes are included.\n\nChange-Id: I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef\n'}, {'number': 2, 'created': '2016-05-04 21:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/a3f37059ed9b4c7afa5b44cd21ef53bb0def4801', 'message': 'Enable IPv6 support in Horizon\n\nThis patch creates a variable to control IPv6 support in Horizon\nand enables it by default.\n\nRelease notes are included.\n\nDepends-On: I8ca656ceebf04aade2b3e9a677cf2ccd2c52f388\nChange-Id: I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef\n'}, {'number': 3, 'created': '2016-05-04 21:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/bf35d30d8594b93fa57646487a1ed9ef5bf18110', 'message': 'Enable IPv6 support in Horizon\n\nThis patch creates a variable to control IPv6 support in Horizon\nand enables it by default.\n\nRelease notes are included.\n\nDepends-On: I2d5300d4d5b02df3351ab52b1be32dd60241d34b\nChange-Id: I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef\n'}, {'number': 4, 'created': '2016-05-05 12:30:37.000000000', 'files': ['defaults/main.yml', 'templates/horizon_local_settings.py.j2', 'releasenotes/notes/make-ipv6-a-toggle-63d9c839e204cdda.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/1111f3d629332091f8d12c4d672fe065b3e5047e', 'message': 'Enable IPv6 support in Horizon\n\nThis patch creates a variable to control IPv6 support in Horizon\nand enables it by default.\n\nRelease notes are included.\n\nDepends-On: I2d5300d4d5b02df3351ab52b1be32dd60241d34b\nChange-Id: I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef\n'}]",1,312741,1111f3d629332091f8d12c4d672fe065b3e5047e,17,6,4,538,,,0,"Enable IPv6 support in Horizon

This patch creates a variable to control IPv6 support in Horizon
and enables it by default.

Release notes are included.

Depends-On: I2d5300d4d5b02df3351ab52b1be32dd60241d34b
Change-Id: I4133d97f3a0aa4886b4b6f6ca3d6fb151231b0ef
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/41/312741/1 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/main.yml', 'releasenotes/notes/make-ipv6-a-toggle-63d9c839e204cdda.yaml', 'templates/horizon_local_settings.py.j2']",3,e45f8f4b376eb2f37229ace22c019c092fce23d6,horizon-ipv6-toggle," 'enable_ipv6': {{ horizon_enable_ipv6 | bool }},"," 'enable_ipv6': False,",17,1
openstack%2Fpython-openstackclient~master~Ib1e821ea524eb33c0ba73643164228c7b83253b4,openstack/python-openstackclient,master,Ib1e821ea524eb33c0ba73643164228c7b83253b4,"Add a unit test for ""flavor create"" command",MERGED,2016-05-04 11:03:22.000000000,2016-05-05 15:44:36.000000000,2016-05-05 15:44:35.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-05-04 11:03:22.000000000', 'files': ['openstackclient/tests/compute/v2/fakes.py', 'openstackclient/tests/compute/v2/test_flavor.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/68224eafc3967fcb843eae0cd6e2b67d46821018', 'message': 'Add a unit test for ""flavor create"" command\n\nThere was not a unit test for ""flavor create"" command\nin the ""test_flavor.py"".So I add the unit test.\n\nChange-Id: Ib1e821ea524eb33c0ba73643164228c7b83253b4\n'}]",1,312448,68224eafc3967fcb843eae0cd6e2b67d46821018,11,3,1,21514,,,0,"Add a unit test for ""flavor create"" command

There was not a unit test for ""flavor create"" command
in the ""test_flavor.py"".So I add the unit test.

Change-Id: Ib1e821ea524eb33c0ba73643164228c7b83253b4
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/48/312448/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/fakes.py', 'openstackclient/tests/compute/v2/test_flavor.py']",2,68224eafc3967fcb843eae0cd6e2b67d46821018,add-unit-test-for-flavor-create,"class TestFlavorCreate(TestFlavor): flavor = compute_fakes.FakeFlavor.create_one_flavor( attrs={'links': 'flavor-links'}) columns = ( 'OS-FLV-DISABLED:disabled', 'OS-FLV-EXT-DATA:ephemeral', 'disk', 'id', 'name', 'os-flavor-access:is_public', 'ram', 'rxtx_factor', 'swap', 'vcpus', ) data = ( flavor.disabled, flavor.ephemeral, flavor.disk, flavor.id, flavor.name, flavor.is_public, flavor.ram, flavor.rxtx_factor, flavor.swap, flavor.vcpus, ) def setUp(self): super(TestFlavorCreate, self).setUp() self.flavors_mock.create.return_value = self.flavor self.cmd = flavor.CreateFlavor(self.app, None) def test_flavor_create_default_options(self): arglist = [ self.flavor.name ] verifylist = [ ('name', self.flavor.name), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) default_args = ( self.flavor.name, 256, 1, 0, 'auto', 0, 0, 1.0, True ) columns, data = self.cmd.take_action(parsed_args) self.flavors_mock.create.assert_called_once_with(*default_args) self.assertEqual(self.columns, columns) self.assertEqual(self.data, data) def test_flavor_create_all_options(self): arglist = [ self.flavor.name, '--id', self.flavor.id, '--ram', str(self.flavor.ram), '--disk', str(self.flavor.disk), '--ephemeral', str(self.flavor.ephemeral), '--swap', str(self.flavor.swap), '--vcpus', str(self.flavor.vcpus), '--rxtx-factor', str(self.flavor.rxtx_factor), '--public', ] verifylist = [ ('name', self.flavor.name), ('id', self.flavor.id), ('ram', self.flavor.ram), ('disk', self.flavor.disk), ('ephemeral', self.flavor.ephemeral), ('swap', self.flavor.swap), ('vcpus', self.flavor.vcpus), ('rxtx_factor', self.flavor.rxtx_factor), ('public', True), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) args = ( self.flavor.name, self.flavor.ram, self.flavor.vcpus, self.flavor.disk, self.flavor.id, self.flavor.ephemeral, self.flavor.swap, self.flavor.rxtx_factor, self.flavor.is_public, ) columns, data = self.cmd.take_action(parsed_args) self.flavors_mock.create.assert_called_once_with(*args) self.assertEqual(self.columns, columns) self.assertEqual(self.data, data) def test_flavor_create_other_options(self): self.flavor.is_public = False arglist = [ self.flavor.name, '--id', self.flavor.id, '--ram', str(self.flavor.ram), '--disk', str(self.flavor.disk), '--ephemeral', str(self.flavor.ephemeral), '--swap', str(self.flavor.swap), '--vcpus', str(self.flavor.vcpus), '--rxtx-factor', str(self.flavor.rxtx_factor), '--private', ] verifylist = [ ('name', self.flavor.name), ('id', self.flavor.id), ('ram', self.flavor.ram), ('disk', self.flavor.disk), ('ephemeral', self.flavor.ephemeral), ('swap', self.flavor.swap), ('vcpus', self.flavor.vcpus), ('rxtx_factor', self.flavor.rxtx_factor), ('public', False), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) args = ( self.flavor.name, self.flavor.ram, self.flavor.vcpus, self.flavor.disk, self.flavor.id, self.flavor.ephemeral, self.flavor.swap, self.flavor.rxtx_factor, self.flavor.is_public, ) columns, data = self.cmd.take_action(parsed_args) self.flavors_mock.create.assert_called_once_with(*args) self.assertEqual(self.columns, columns) self.assertEqual(self.data, data) def test_flavor_create_no_options(self): arglist = [] verifylist = None self.assertRaises(tests_utils.ParserException, self.check_parser, self.cmd, arglist, verifylist) ",,162,2
openstack%2Fopenstack-ansible-os_swift~stable%2Fmitaka~I8bfa92003ce06ee4f065663e054cd2d04f458ec6,openstack/openstack-ansible-os_swift,stable/mitaka,I8bfa92003ce06ee4f065663e054cd2d04f458ec6,Remove XFS filesystem from the daily mlocate cron job,MERGED,2016-04-27 12:38:29.000000000,2016-05-05 15:41:46.000000000,2016-05-05 15:41:46.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-04-27 12:38:29.000000000', 'files': ['releasenotes/notes/swift-reconfigure-xfs-from-mlocate-e4844e6c0469afd6.yaml', 'templates/mlocate-crond-daily.sh.j2', 'tasks/swift_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/5fafb38f896d5eae1836bb06e59c6ffaf43867b8', 'message': 'Remove XFS filesystem from the daily mlocate cron job\n\nThis fix removes the XFS filesystem from the daily cron job.\nIt will help to remove unnecessary disk IO due to updatedb/mlocate\nswift object indexing inside the /srv/node folders.\n\nChange-Id: I8bfa92003ce06ee4f065663e054cd2d04f458ec6\nCloses-Bug: #1572307\n(cherry picked from commit db4ad90762bd9df437a39950ad97173f65a93b64)\n'}]",0,310442,5fafb38f896d5eae1836bb06e59c6ffaf43867b8,11,3,1,14552,,,0,"Remove XFS filesystem from the daily mlocate cron job

This fix removes the XFS filesystem from the daily cron job.
It will help to remove unnecessary disk IO due to updatedb/mlocate
swift object indexing inside the /srv/node folders.

Change-Id: I8bfa92003ce06ee4f065663e054cd2d04f458ec6
Closes-Bug: #1572307
(cherry picked from commit db4ad90762bd9df437a39950ad97173f65a93b64)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/42/310442/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/swift-reconfigure-xfs-from-mlocate-e4844e6c0469afd6.yaml', 'templates/mlocate-crond-daily.sh.j2', 'tasks/swift_pre_install.yml']",3,5fafb38f896d5eae1836bb06e59c6ffaf43867b8,bug/1572307," - name: Configure mlocate for cron.daily template: src: ""mlocate-crond-daily.sh.j2"" dest: ""/etc/cron.daily/mlocate"" mode: ""0755"" owner: ""root"" group: ""root"" tags: - swift-crond",,36,0
openstack%2Fopenstack-ansible-repo_server~master~I5b0ab466a7374d3012ff60e2da677b0c30c966b2,openstack/openstack-ansible-repo_server,master,I5b0ab466a7374d3012ff60e2da677b0c30c966b2,Reorganize test playbooks,MERGED,2016-05-04 01:55:39.000000000,2016-05-05 15:31:38.000000000,2016-05-05 15:31:38.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-05-04 01:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/68e07cf75647b461d7e09c508aafb812a1f297d1', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional playbook output\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 2, 'created': '2016-05-04 02:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/3fa622914ce563bf0a9dda35d631ad6764ad0a05', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional playbook output\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 3, 'created': '2016-05-04 02:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/8a597b505deacbeb4fba8860dd2e1bbe35dc9f74', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional playbook output\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 4, 'created': '2016-05-04 02:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/0989cb992c7639abc7151603e33c615811d1ccff', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional playbook output\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 5, 'created': '2016-05-04 03:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/a74e0a2a040e17f4d64a4e4d4ddf29d205e22756', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional playbook output\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 6, 'created': '2016-05-04 17:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/e51e2e76179071e48108396cce5584f055e2058b', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 7, 'created': '2016-05-04 18:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/a530820c666ee4383f733d794aa04b2a1b854d35', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 8, 'created': '2016-05-04 18:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/cbf40726725a6e6bf73a647f075316352c3afa16', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 9, 'created': '2016-05-04 19:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/7f327557cc302b6219e8c02b24a132457f33529e', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 10, 'created': '2016-05-04 21:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/11a4e79647f76e14d4b2e415136f8594adc2b75f', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 11, 'created': '2016-05-04 23:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/c5f5db202abdfc1e157c41da768eebf2338b75ee', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}, {'number': 12, 'created': '2016-05-05 00:06:58.000000000', 'files': ['tests/test-prepare-host.yml', 'tests/inventory', 'tests/test-prepare-containers.yml', 'tests/test-repo-server-functional.yml', 'tests/test-install-repo-server.yml', 'tests/group_vars/all_containers.yml', 'tests/test-prepare-keys.yml', 'tests/test.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/954770e1da75d93c7d8ef823613fa07f3f0961a9', 'message': ""Reorganize test playbooks\n\nThe following changes have been made to reorganize the structure of this\nrole's test playbooks, bringing them into line with other\nOpenStack-Ansible roles:\n  - move each playbook to an individual file\n  - rename playbooks descriptively\n  - define hosts and groups directly in the inventory file\n  - include group vars required by containers\n  - reduce lxc network dhcp network range to avoid conflicts with static\n    container addresses\n  - enable verbose logging for functional test output\n  - remove unnecessary delegations in functional test playbook\n\nChange-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2\n""}]",3,312302,954770e1da75d93c7d8ef823613fa07f3f0961a9,32,5,12,14805,,,0,"Reorganize test playbooks

The following changes have been made to reorganize the structure of this
role's test playbooks, bringing them into line with other
OpenStack-Ansible roles:
  - move each playbook to an individual file
  - rename playbooks descriptively
  - define hosts and groups directly in the inventory file
  - include group vars required by containers
  - reduce lxc network dhcp network range to avoid conflicts with static
    container addresses
  - enable verbose logging for functional test output
  - remove unnecessary delegations in functional test playbook

Change-Id: I5b0ab466a7374d3012ff60e2da677b0c30c966b2
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/02/312302/12 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-prepare-host.yml', 'tests/inventory', 'tests/test-install-repo-server.yml', 'tests/group_vars/all_containers.yml', 'tests/test-container-create.yml', 'tests/test-prepare-keys.yml', 'tests/test.yml', 'tests/test-functional.yml', 'tox.ini']",9,68e07cf75647b461d7e09c508aafb812a1f297d1,reorganize_tests, -vv \,,251,149
openstack%2Ffuel-web~master~Ia3837f1724d435eb02093fbc1f395a11d5c24007,openstack/fuel-web,master,Ia3837f1724d435eb02093fbc1f395a11d5c24007,Deployment graphs are deleted together with parent entity,ABANDONED,2016-05-05 15:02:30.000000000,2016-05-05 15:29:27.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 15:02:30.000000000', 'files': ['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun/objects/deployment_graph.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c3174e0b306025c54e98924792989d845211840d', 'message': 'Deployment graphs are deleted together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: Ia3837f1724d435eb02093fbc1f395a11d5c24007\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}]",0,313013,c3174e0b306025c54e98924792989d845211840d,13,3,1,19158,,,0,"Deployment graphs are deleted together with parent entity

When Release, Plugin or Cluster is deleted, related
deployment graphs are deleted as well.

Note, that current DeploymentGraph deletion schema works if
DeploymentGraph have only relation to parent
otherwise unwanted relations may be affected by graph cleanup.

Change-Id: Ia3837f1724d435eb02093fbc1f395a11d5c24007
Closes-Bug: #1567471
Closes-Bug: #1557632
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/13/313013/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun/objects/deployment_graph.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py']",7,c3174e0b306025c54e98924792989d845211840d,bug/1567471," @classmethod def delete(cls, instance): """"""Delete plugin. :param instance: Plugin model instance :type instance: models.Plugin """""" DeploymentGraph.delete_for_parent(instance) super(Plugin, cls).delete(instance) ",,62,0
openstack%2Fkolla~master~I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1,openstack/kolla,master,I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1,Exclude the docker registry image from cleanup-images,ABANDONED,2016-04-28 06:36:14.000000000,2016-05-05 15:22:14.000000000,,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 14027}, {'_account_id': 16233}, {'_account_id': 17731}]","[{'number': 1, 'created': '2016-04-28 06:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dab8750bc56787683aae94203f9018039f516462', 'message': 'Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1576049\n'}, {'number': 2, 'created': '2016-05-02 09:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ea2392c424e77166d0dc5d27358a19c0a597be16', 'message': '[WIP] Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}, {'number': 3, 'created': '2016-05-02 10:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dbf6bfb59539a736946141b682498b8bc30eb531', 'message': '[WIP] Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}, {'number': 4, 'created': '2016-05-02 12:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/73b3457a1404ed55911a611a088c26c2b9eb8f39', 'message': '[WIP] Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}, {'number': 5, 'created': '2016-05-05 09:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f93932792ed74cb145166a1ec92a98c1e772721b', 'message': '[WIP] Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}, {'number': 6, 'created': '2016-05-05 14:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bc73dcb287a745f5e1f2017c3df99bc02ddc06ca', 'message': 'Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}, {'number': 7, 'created': '2016-05-05 14:34:46.000000000', 'files': ['tools/cleanup-images'], 'web_link': 'https://opendev.org/openstack/kolla/commit/90709a4048d407f5baa66a25dc4f8f4e56e7ae88', 'message': 'Exclude the docker registry image from cleanup-images\n\nChange-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1\nCloses-Bug: 1551933\n'}]",6,310677,90709a4048d407f5baa66a25dc4f8f4e56e7ae88,24,7,7,14027,,,0,"Exclude the docker registry image from cleanup-images

Change-Id: I9f8d244641b9e2e4ff94af2e9ef5afc51752f5c1
Closes-Bug: 1551933
",git fetch https://review.opendev.org/openstack/kolla refs/changes/77/310677/6 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-images'],1,dab8750bc56787683aae94203f9018039f516462,bug/1551933,IMAGES=$(docker images -a | tail -n +2 | awk '!/registry/{print $3;}'),IMAGES=`docker images -a -q`,1,1
openstack%2Fneutron~master~Iac50da009b18f7658d509af5ba622eff1ab96849,openstack/neutron,master,Iac50da009b18f7658d509af5ba622eff1ab96849,Match job name for scenario tests,MERGED,2016-04-15 23:30:57.000000000,2016-05-05 15:18:40.000000000,2016-04-18 08:34:33.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 11682}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-15 23:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16686af4c20dbb32a450790352046e400e445c0f', 'message': 'Match job name for scenario tests\n\nChange-Id: Iac50da009b18f7658d509af5ba622eff1ab96849\nDepends-on: I77827d2e6e07fbfb39727d823628094d730fcdd8\n'}, {'number': 2, 'created': '2016-04-16 15:28:48.000000000', 'files': ['neutron/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a5514ce6676237e4917f9cdd2fc6d7589c537bf', 'message': 'Match job name for scenario tests\n\nChange-Id: Iac50da009b18f7658d509af5ba622eff1ab96849\nDepends-on: I77827d2e6e07fbfb39727d823628094d730fcdd8\n'}]",0,306659,8a5514ce6676237e4917f9cdd2fc6d7589c537bf,25,10,2,748,,,0,"Match job name for scenario tests

Change-Id: Iac50da009b18f7658d509af5ba622eff1ab96849
Depends-on: I77827d2e6e07fbfb39727d823628094d730fcdd8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/306659/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/contrib/gate_hook.sh'],1,16686af4c20dbb32a450790352046e400e445c0f,neutron-scenario-tests,"elif [ ""$VENV"" == ""dsvm-scenario"" ]","elif [ ""$VENV"" == ""dsvm-plus"" ] # TODO(armax): this branch needs to be revised, in light # to the latest refactoring of the api job.",1,3
openstack%2Ftripleo-heat-templates~master~I2b137cbd6597222a72cf46830f34a93f002c70ef,openstack/tripleo-heat-templates,master,I2b137cbd6597222a72cf46830f34a93f002c70ef,Remove calls to ::mysql from the manifests,MERGED,2016-04-28 18:28:19.000000000,2016-05-05 15:16:41.000000000,2016-05-05 15:02:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 6994}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-04-28 18:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90e34abd07c40dcc30e73e1ebbca5bbeabdea231', 'message': ""Remove calls to ::mysql from the manifests\n\nThe database will be created by the roles so we don't need to call\n::mysql from the manifest.\n\nChange-Id: I2b137cbd6597222a72cf46830f34a93f002c70ef\nDepends-On: I6c752cb53090e7ef8e0319bade462f2453ed7660\n""}, {'number': 2, 'created': '2016-04-29 15:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e94d4c8791efbcc3296b5b801080e39999ec6ac6', 'message': ""Remove calls to ::mysql from the manifests\n\nThe database will be created by the roles so we don't need to call\n::mysql from the manifest.\n\nChange-Id: I2b137cbd6597222a72cf46830f34a93f002c70ef\nDepends-On: I6c752cb53090e7ef8e0319bade462f2453ed7660\n""}, {'number': 3, 'created': '2016-05-04 13:24:11.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/afc4915c17b1f77654443278a96ba60834204c9d', 'message': ""Remove calls to ::mysql from the manifests\n\nThe database will be created by the roles so we don't need to call\n::mysql from the manifest.\n\nChange-Id: I2b137cbd6597222a72cf46830f34a93f002c70ef\nDepends-On: Id065a9180f1f1a41ab225ec5f755498ec7d9a827\n""}]",3,310879,afc4915c17b1f77654443278a96ba60834204c9d,47,7,3,6796,,,0,"Remove calls to ::mysql from the manifests

The database will be created by the roles so we don't need to call
::mysql from the manifest.

Change-Id: I2b137cbd6597222a72cf46830f34a93f002c70ef
Depends-On: Id065a9180f1f1a41ab225ec5f755498ec7d9a827
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/310879/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",2,90e34abd07c40dcc30e73e1ebbca5bbeabdea231,bp/refactor-puppet-manifests,," class { '::keystone::db::mysql': require => Exec['galera-ready'], } class { '::glance::db::mysql': require => Exec['galera-ready'], }",0,8
openstack%2Fkolla~master~Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8,openstack/kolla,master,Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8,Deletes fake containers on cleanup,MERGED,2016-05-04 16:34:49.000000000,2016-05-05 15:07:37.000000000,2016-05-05 15:07:37.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 7488}, {'_account_id': 14027}, {'_account_id': 16233}, {'_account_id': 16993}, {'_account_id': 17731}, {'_account_id': 18009}]","[{'number': 1, 'created': '2016-05-04 16:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9d3048a9f017004f28ae0d888db0503ef96dcb1b', 'message': 'Deletes fake containers on cleanup\nrelated-bug: 1576277\n\nChange-Id: Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8\n'}, {'number': 2, 'created': '2016-05-04 16:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/be443e803ec2d42c66d546b2c9ca6958df067525', 'message': 'Deletes fake containers on cleanup\nCloses-Bug: 1576277\n\nChange-Id: Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8\n'}, {'number': 3, 'created': '2016-05-05 08:24:47.000000000', 'files': ['tools/cleanup-containers'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0fda8badd2e16edc65a624c34f0d09809bf9b22c', 'message': 'Deletes fake containers on cleanup\n\nCloses-Bug: #1576277\n\nChange-Id: Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8\n'}]",2,312629,0fda8badd2e16edc65a624c34f0d09809bf9b22c,16,8,3,19370,,,0,"Deletes fake containers on cleanup

Closes-Bug: #1576277

Change-Id: Ie68d1d5da620f26a0aa21aa5c6473bc464994ed8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/29/312629/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-containers'],1,9d3048a9f017004f28ae0d888db0503ef96dcb1b,bug/1576277," fake_containers=$(docker ps -a --filter ""name=neutron_openvswitch_agent_fake_*"" --filter ""name=nova_compute_fake_*"" --format ""{{.Names}}"") containers_to_kill=""${containers_to_kill} ${ceph_osd_containers} ${ceph_osd_bootstrap} ${fake_containers}"""," containers_to_kill=""${containers_to_kill} ${ceph_osd_containers} ${ceph_osd_bootstrap}""",2,1
openstack%2Feslint-config-openstack~master~Iaddc5e106da307e9ead62d2a37876805aaa86746,openstack/eslint-config-openstack,master,Iaddc5e106da307e9ead62d2a37876805aaa86746,Enable no-self-assign,MERGED,2016-03-16 15:10:52.000000000,2016-05-05 15:06:20.000000000,2016-05-05 15:06:20.000000000,"[{'_account_id': 3}, {'_account_id': 9622}, {'_account_id': 16628}, {'_account_id': 21738}]","[{'number': 1, 'created': '2016-03-16 15:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/eslint-config-openstack/commit/740749c2e9c594db09108d93583b38f01bb3598c', 'message': 'Enable no-self-assign\n\nThis will throw an error on all variants of a = a;\n\nhttp://eslint.org/docs/rules/no-self-assign\n\nChange-Id: Iaddc5e106da307e9ead62d2a37876805aaa86746\n'}, {'number': 2, 'created': '2016-05-04 19:40:18.000000000', 'files': ['.eslintrc'], 'web_link': 'https://opendev.org/openstack/eslint-config-openstack/commit/5b3112fe99297dee77fd298efd03f762f63aac84', 'message': 'Enable no-self-assign\n\nThis will throw an error on all variants of a = a;\n\nhttp://eslint.org/docs/rules/no-self-assign\n\nChange-Id: Iaddc5e106da307e9ead62d2a37876805aaa86746\n'}]",0,293490,5b3112fe99297dee77fd298efd03f762f63aac84,12,4,2,9717,,,0,"Enable no-self-assign

This will throw an error on all variants of a = a;

http://eslint.org/docs/rules/no-self-assign

Change-Id: Iaddc5e106da307e9ead62d2a37876805aaa86746
",git fetch https://review.opendev.org/openstack/eslint-config-openstack refs/changes/90/293490/1 && git format-patch -1 --stdout FETCH_HEAD,['.eslintrc'],1,740749c2e9c594db09108d93583b38f01bb3598c,eslint_2.4.0, no-self-assign: 2, no-self-assign: 0,1,1
openstack%2Fmurano~master~I39350e795a087c27ade2bce229b4177a2fb11164,openstack/murano,master,I39350e795a087c27ade2bce229b4177a2fb11164,"Fix typo in word ""settings"" in docs about using glare",MERGED,2016-04-21 12:16:10.000000000,2016-05-05 15:02:30.000000000,2016-05-05 15:02:30.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13323}, {'_account_id': 14107}, {'_account_id': 16237}, {'_account_id': 17591}, {'_account_id': 20364}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-04-21 12:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/261120790d1d7d07993700bc954a7c550d1453c9', 'message': 'Fix typo in word ""settings"" in docs about using glare\n\nChange-Id: I39350e795a087c27ade2bce229b4177a2fb11164\n'}, {'number': 2, 'created': '2016-04-21 12:17:27.000000000', 'files': ['doc/source/draft/admin-guide/using_glare.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/aaf9e54d6effbb14da0fd7c1f9f5a2cdff82af27', 'message': 'Fix typo in word ""settings"" in docs about using glare\n\nChange-Id: I39350e795a087c27ade2bce229b4177a2fb11164\n'}]",0,308948,aaf9e54d6effbb14da0fd7c1f9f5a2cdff82af27,22,12,2,20773,,,0,"Fix typo in word ""settings"" in docs about using glare

Change-Id: I39350e795a087c27ade2bce229b4177a2fb11164
",git fetch https://review.opendev.org/openstack/murano refs/changes/48/308948/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/murano/class-configs/io.murano.Environment.yaml', 'doc/source/draft/admin-guide/using_glare.rst']",2,261120790d1d7d07993700bc954a7c550d1453c9,, to the ``local_settings.py`` file, to the ``local_settins.py`` file,9,1
openstack%2Fmurano~master~I7f684c41846701d42b35d767fcb2335b10156e76,openstack/murano,master,I7f684c41846701d42b35d767fcb2335b10156e76,Skip test_migrations on Python 3,MERGED,2016-05-04 12:31:36.000000000,2016-05-05 15:02:24.000000000,2016-05-05 15:02:24.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7225}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-05-04 12:31:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/df4c52dcfce82b43e634d9bb0d346724e3bdd9e1', 'message': 'Skip test_migrations on Python 3\n\nThe unit test fails for an unknown reason. Skip the test to fix it\nlater, it will be fixed later when other parts of the code will be\nported to Python 3.\n\nWith this change, all unit tests of the tox.ini whitelist should pass\non Python 3 and so it becomes possible to make the Python 3 check job\nvoting to avoid Python 3 regressions.\n\nBlueprint: murano-python-3-support\nChange-Id: I7f684c41846701d42b35d767fcb2335b10156e76\n'}]",0,312480,df4c52dcfce82b43e634d9bb0d346724e3bdd9e1,14,7,1,9107,,,0,"Skip test_migrations on Python 3

The unit test fails for an unknown reason. Skip the test to fix it
later, it will be fixed later when other parts of the code will be
ported to Python 3.

With this change, all unit tests of the tox.ini whitelist should pass
on Python 3 and so it becomes possible to make the Python 3 check job
voting to avoid Python 3 regressions.

Blueprint: murano-python-3-support
Change-Id: I7f684c41846701d42b35d767fcb2335b10156e76
",git fetch https://review.opendev.org/openstack/murano refs/changes/80/312480/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,df4c52dcfce82b43e634d9bb0d346724e3bdd9e1,bp/murano-python-3-support,, murano/tests/unit/db/migration/test_migrations.py \,0,1
openstack%2Fpython-muranoclient~master~I0856b902cb98bc2f5894c328c06d03e425efebf2,openstack/python-muranoclient,master,I0856b902cb98bc2f5894c328c06d03e425efebf2,Updated from global requirements,MERGED,2016-04-30 18:08:31.000000000,2016-05-05 14:52:12.000000000,2016-05-05 14:52:12.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-04-30 18:08:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/603d6342960b03235b3b1136227ab154eb7b07ca', 'message': 'Updated from global requirements\n\nChange-Id: I0856b902cb98bc2f5894c328c06d03e425efebf2\n'}]",0,311550,603d6342960b03235b3b1136227ab154eb7b07ca,13,4,1,11131,,,0,"Updated from global requirements

Change-Id: I0856b902cb98bc2f5894c328c06d03e425efebf2
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/50/311550/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,603d6342960b03235b3b1136227ab154eb7b07ca,openstack/requirements,iso8601>=0.1.11 # MIT,iso8601>=0.1.9 # MIT,1,1
openstack%2Fpython-keystoneclient~master~Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2,openstack/python-keystoneclient,master,Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2,Replace tempest-lib with tempest.lib,MERGED,2016-04-28 20:25:53.000000000,2016-05-05 14:50:52.000000000,2016-05-05 14:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 21609}]","[{'number': 1, 'created': '2016-04-28 20:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/27e0b13eeb5a6d8fb5bf37391f3e638b0ab3c186', 'message': 'Replace tempest-lib with tempest.lib\n\ntempest-lib is deprecated, replace it with tempest.lib.\n\nCloses_Bug: #1553047\nChange-Id: Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2\n'}, {'number': 2, 'created': '2016-04-28 20:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/85366d55d4df53d81b52a674df8b3802ddb8e855', 'message': 'Replace tempest-lib with tempest.lib\n\ntempest-lib is deprecated, replace it with tempest.lib.\n\nCloses-Bug: #1553047\nChange-Id: Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2\n'}, {'number': 3, 'created': '2016-04-28 22:11:12.000000000', 'files': ['test-requirements.txt', 'keystoneclient/tests/functional/test_access.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/74287cbe3759c06cecc0ef6b369dcfe7278eba3b', 'message': 'Replace tempest-lib with tempest.lib\n\ntempest-lib is deprecated, replace it with tempest.lib.\n\nCloses-Bug: #1553047\nChange-Id: Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2\n'}]",0,310911,74287cbe3759c06cecc0ef6b369dcfe7278eba3b,12,5,3,13998,,,0,"Replace tempest-lib with tempest.lib

tempest-lib is deprecated, replace it with tempest.lib.

Closes-Bug: #1553047
Change-Id: Ib03938b133f2aca1e73ec5df5815cff9dfe7b2e2
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/11/310911/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'keystoneclient/tests/functional/test_access.py']",2,27e0b13eeb5a6d8fb5bf37391f3e638b0ab3c186,bug/1553047,from tempest.lib import base,from tempest_lib import base,2,2
openstack%2Fopenstack-ansible-security~master~I33a6f9ab1aecf28e82ea756e41c482820758157f,openstack/openstack-ansible-security,master,I33a6f9ab1aecf28e82ea756e41c482820758157f,Add dependencies for paramiko 2.0,MERGED,2016-05-03 07:58:02.000000000,2016-05-05 14:50:05.000000000,2016-05-03 12:37:44.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-03 07:58:02.000000000', 'files': ['run_tests.sh', 'other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/19999b4ed8b87c3965a830a751a91cd324c424bd', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I33a6f9ab1aecf28e82ea756e41c482820758157f\n'}]",0,311983,19999b4ed8b87c3965a830a751a91cd324c424bd,11,3,1,6816,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Change-Id: I33a6f9ab1aecf28e82ea756e41c482820758157f
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/83/311983/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,19999b4ed8b87c3965a830a751a91cd324c424bd,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fmurano~stable%2Fmitaka~I1555d279739a5c1683568626384a06c2d2f95098,openstack/murano,stable/mitaka,I1555d279739a5c1683568626384a06c2d2f95098,Updated from global requirements,MERGED,2016-04-29 22:37:10.000000000,2016-05-05 14:48:21.000000000,2016-05-05 14:48:21.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-04-29 22:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7f7a8fffbf45a6f629a664c9cf5cc665ce79a1bf', 'message': 'Updated from global requirements\n\nChange-Id: I1555d279739a5c1683568626384a06c2d2f95098\n'}, {'number': 2, 'created': '2016-04-29 23:04:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/b05f8fb026ee31c44edc6c31cc8ba228f531f90f', 'message': 'Updated from global requirements\n\nChange-Id: I1555d279739a5c1683568626384a06c2d2f95098\n'}]",0,311314,b05f8fb026ee31c44edc6c31cc8ba228f531f90f,21,4,2,11131,,,0,"Updated from global requirements

Change-Id: I1555d279739a5c1683568626384a06c2d2f95098
",git fetch https://review.opendev.org/openstack/murano refs/changes/14/311314/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7f7a8fffbf45a6f629a664c9cf5cc665ce79a1bf,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3 # BSD,1,1
openstack%2Fpython-keystoneclient~master~Ibe618dcd646912060b1785d8d72fd526dd4a083b,openstack/python-keystoneclient,master,Ibe618dcd646912060b1785d8d72fd526dd4a083b,Add federation related tests,MERGED,2016-03-15 16:51:31.000000000,2016-05-05 14:48:05.000000000,2016-05-05 14:48:04.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-03-15 16:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7aba67a44ca6b2d733463f05e8f46de6795da1a4', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 2, 'created': '2016-03-15 18:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f7a61272a0d558ba90731d31bbd1abbf5fdf33de', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 3, 'created': '2016-03-28 17:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/bbc90729a19daea43fd73e66c0b27d01fe61d85d', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 4, 'created': '2016-03-28 19:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6d9153aeae8974b662c86572217788fbdb8686dc', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 5, 'created': '2016-03-28 20:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6488f9952272650cedc41d0c1f19738f6df726d8', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 6, 'created': '2016-04-26 20:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/22baa19c2517b0e9b819e5b9fb669f1b3ca1d464', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}, {'number': 7, 'created': '2016-04-29 14:55:40.000000000', 'files': ['keystoneclient/tests/functional/v3/test_federation.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f663c66c103b44c9d1b2b94f46f753e8db73804d', 'message': 'Add federation related tests\n\nThis patch adds the test_federation file with some tests\nfor Identity Providers, the tests are not supposed to be\nexhaustive, they are rather simple and intend to cover\nthe basic actions in the Identity Provider handling.\n\nMore complete tests should be added later.\n\nChange-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b\n'}]",23,293040,f663c66c103b44c9d1b2b94f46f753e8db73804d,29,8,7,11022,,,0,"Add federation related tests

This patch adds the test_federation file with some tests
for Identity Providers, the tests are not supposed to be
exhaustive, they are rather simple and intend to cover
the basic actions in the Identity Provider handling.

More complete tests should be added later.

Change-Id: Ibe618dcd646912060b1785d8d72fd526dd4a083b
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/40/293040/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/functional/v3/test_federation.py'],1,7aba67a44ca6b2d733463f05e8f46de6795da1a4,federation_tests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from keystoneclient.tests.functional import base from keystoneauth1.exceptions import http class TestIdentityProviders(base.V3ClientTestCase): def setUp(self): super(TestIdentityProviders, self).setUp() self.idp_list = [] def tearDown(self): super(TestIdentityProviders, self).tearDown() self._delete_idp_list() def _delete_idp(self, idp_id): self.client.federation.identity_providers.delete(idp_id) def _delete_idp_list(self): for idp in self.idp_list: self._delete_idp(idp.id) def test_idp_create(self): idp_id = uuid.uuid4().hex # Create an identity provider just passing an ID idp = self.client.federation.identity_providers.create(id=idp_id) self.idp_list.append(idp) self.assertEqual(idp_id, idp.id) self.assertEqual([], idp.remote_ids) self.assertFalse(idp.enabled) # Create an enabled identity provider idp_id = uuid.uuid4().hex idp = self.client.federation.identity_providers.create( id=idp_id, enabled=True) self.idp_list.append(idp) self.assertEqual(idp_id, idp.id) self.assertEqual([], idp.remote_ids) self.assertTrue(idp.enabled) # Create an enabled identity provider with remote IDs idp_id = uuid.uuid4().hex remote_ids = [uuid.uuid4().hex, uuid.uuid4().hex] idp = self.client.federation.identity_providers.create( id=idp_id, enabled=True, remote_ids=remote_ids) self.idp_list.append(idp) self.assertEqual(idp_id, idp.id) self.assertIn(remote_ids[0], idp.remote_ids) self.assertIn(remote_ids[1], idp.remote_ids) self.assertTrue(idp.enabled) def test_idp_list(self): list_before = self.client.federation.identity_providers.list() list_before_length = len(list_before) idp_id = uuid.uuid4().hex idp1 = self.client.federation.identity_providers.create(id=idp_id) self.idp_list.append(idp1) idp_id = uuid.uuid4().hex idp2 = self.client.federation.identity_providers.create(id=idp_id) self.idp_list.append(idp2) list_after = self.client.federation.identity_providers.list() list_after_length = len(list_after) self.assertEqual(list_before_length + 2, list_after_length) def test_idp_get(self): idp_id = uuid.uuid4().hex remote_ids = [uuid.uuid4().hex, uuid.uuid4().hex] idp_create = self.client.federation.identity_providers.create( id=idp_id, enabled=True, remote_ids=remote_ids) self.idp_list.append(idp_create) idp_get = self.client.federation.identity_providers.get(idp_id) self.assertEqual(idp_create.id, idp_get.id) self.assertEqual(idp_create.enabled, idp_get.enabled) self.assertIn(idp_create.remote_ids[0], idp_get.remote_ids) self.assertIn(idp_create.remote_ids[1], idp_get.remote_ids) def test_idp_delete(self): idp_id = uuid.uuid4().hex idp_create = self.client.federation.identity_providers.create(id=idp_id) # Get should not raise an error self.client.federation.identity_providers.get(idp_id) # Delete it self._delete_idp(idp_id) # Now get should raise an error self.assertRaises( http.NotFound, self.client.federation.identity_providers.get, idp_id) ",,112,0
openstack%2Ftuning-box~master~I88bd963e2322e9cca7de25afe4c08ad7c47925ef,openstack/tuning-box,master,I88bd963e2322e9cca7de25afe4c08ad7c47925ef,Bump version in RPM spec,MERGED,2016-05-05 14:26:35.000000000,2016-05-05 14:45:37.000000000,2016-05-05 14:43:47.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 14:26:35.000000000', 'files': ['specs/tuning-box.spec'], 'web_link': 'https://opendev.org/openstack/tuning-box/commit/97890f10d6756aaea2f8d3f1af6ca114cfee0938', 'message': 'Bump version in RPM spec\n\nChange-Id: I88bd963e2322e9cca7de25afe4c08ad7c47925ef\n'}]",0,312995,97890f10d6756aaea2f8d3f1af6ca114cfee0938,10,3,1,708,,,0,"Bump version in RPM spec

Change-Id: I88bd963e2322e9cca7de25afe4c08ad7c47925ef
",git fetch https://review.opendev.org/openstack/tuning-box refs/changes/95/312995/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/tuning-box.spec'],1,97890f10d6756aaea2f8d3f1af6ca114cfee0938,,%{!?version: %define version 0.1.0},%{!?version: %define version 0.0.1},1,1
openstack%2Fopenstack-ansible-os_nova~stable%2Fmitaka~I0994dcd713391235946b4d9aa762b518bd0eddae,openstack/openstack-ansible-os_nova,stable/mitaka,I0994dcd713391235946b4d9aa762b518bd0eddae,Add dependencies for paramiko 2.0,MERGED,2016-05-05 13:47:14.000000000,2016-05-05 14:43:41.000000000,2016-05-05 14:43:41.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 13:47:14.000000000', 'files': ['run_tests.sh', 'other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/bc56eac0bf4ce4875dc78a06d28bf188a8e22d9b', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I0994dcd713391235946b4d9aa762b518bd0eddae\n(cherry picked from commit 85b92f8c4495a9827e21133b9006459ca7504734)\n'}]",0,312960,bc56eac0bf4ce4875dc78a06d28bf188a8e22d9b,6,2,1,6816,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Change-Id: I0994dcd713391235946b4d9aa762b518bd0eddae
(cherry picked from commit 85b92f8c4495a9827e21133b9006459ca7504734)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/60/312960/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,bc56eac0bf4ce4875dc78a06d28bf188a8e22d9b,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fpuppet-openstack-integration~stable%2Fmitaka~Ie8c4ff54b4a94af9e3cc6d45a017f3b9edd56801,openstack/puppet-openstack-integration,stable/mitaka,Ie8c4ff54b4a94af9e3cc6d45a017f3b9edd56801,run_tests.sh: run testr outside .tox,MERGED,2016-05-04 23:40:01.000000000,2016-05-05 14:39:35.000000000,2016-05-05 14:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2016-05-04 23:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/10dcb414e4e52d99c9937e6aa38d1468ef6b5c8c', 'message': 'run_tests.sh: run testr outside .tox\n\nA patch in Tempest [1] is forcing us to run testr outside tox\nenvironment.\nThis patch is a partial backport of:\nhttps://github.com/openstack/puppet-openstack-integration/commit/9c5c8689d34df7bf5853e2cc03078228c4ec007e\n\nBut without the plugin bits, (feature only in current master), so we can\nrun testr again and get the testrepository.subunit file for\nopenstackhealth.\n\n[1] https://review.openstack.org/#/c/311256/\n\nChange-Id: Ie8c4ff54b4a94af9e3cc6d45a017f3b9edd56801\n'}, {'number': 2, 'created': '2016-05-05 13:15:17.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/34cdb8f6cd00333eb72eb853c6a90d91777722a2', 'message': 'run_tests.sh: run testr outside .tox\n\nA patch in Tempest [1] is forcing us to run testr outside tox\nenvironment.\nThis patch is a partial backport of:\nhttps://github.com/openstack/puppet-openstack-integration/commit/9c5c8689d34df7bf5853e2cc03078228c4ec007e\n\nBut without the plugin bits, (feature only in current master), so we can\nrun testr again and get the testrepository.subunit file for\nopenstackhealth.\n\n[1] https://review.openstack.org/#/c/311256/\n\nChange-Id: Ie8c4ff54b4a94af9e3cc6d45a017f3b9edd56801\n'}]",0,312787,34cdb8f6cd00333eb72eb853c6a90d91777722a2,9,2,2,3153,,,0,"run_tests.sh: run testr outside .tox

A patch in Tempest [1] is forcing us to run testr outside tox
environment.
This patch is a partial backport of:
https://github.com/openstack/puppet-openstack-integration/commit/9c5c8689d34df7bf5853e2cc03078228c4ec007e

But without the plugin bits, (feature only in current master), so we can
run testr again and get the testrepository.subunit file for
openstackhealth.

[1] https://review.openstack.org/#/c/311256/

Change-Id: Ie8c4ff54b4a94af9e3cc6d45a017f3b9edd56801
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/87/312787/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,10dcb414e4e52d99c9937e6aa38d1468ef6b5c8c,testr,testr last --subunit > /tmp/openstack/tempest/testrepository.subunit,/tmp/openstack/tempest/.tox/all/bin/testr last --subunit > /tmp/openstack/tempest/testrepository.subunit,1,1
openstack%2Fmurano-specs~master~I73c1d4f6b04726bda54b92a9bd75b1a2d09f89a1,openstack/murano-specs,master,I73c1d4f6b04726bda54b92a9bd75b1a2d09f89a1,Fix tables in env-template spec,MERGED,2016-05-05 07:55:10.000000000,2016-05-05 14:39:27.000000000,2016-05-05 14:39:27.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 13323}, {'_account_id': 13962}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-05-05 07:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/b4f85a026a705fd59d57330ddb1974e61b31add2', 'message': 'Fix tables in env-template spec\n\nSeveral tables in spec were broken. This commit\nfixes these issues\n\nChange-Id: I73c1d4f6b04726bda54b92a9bd75b1a2d09f89a1\n'}, {'number': 2, 'created': '2016-05-05 12:22:19.000000000', 'files': ['specs/kilo/blueprint-template.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/31a29de0cca80e6f9f3d9b72cbc93f8afdae9d37', 'message': 'Fix tables in env-template spec\n\nSeveral tables in spec were broken. This commit\nfixes these issues\n\nChange-Id: I73c1d4f6b04726bda54b92a9bd75b1a2d09f89a1\n'}]",1,312851,31a29de0cca80e6f9f3d9b72cbc93f8afdae9d37,15,5,2,13149,,,0,"Fix tables in env-template spec

Several tables in spec were broken. This commit
fixes these issues

Change-Id: I73c1d4f6b04726bda54b92a9bd75b1a2d09f89a1
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/51/312851/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/blueprint-template.rst'],1,b4f85a026a705fd59d57330ddb1974e61b31add2,fix-env-temp,+----------------+-----------------------------------------------------------++----------------+-----------------------------------------------------------++==========+============================================+======================================++----------------+-----------------------------------------------------------+,+-----------+-----------------------------------------------------------++-----------+-----------------------------------------------------------++==========+================================+==================================================++-----------+-----------------------------------------------------------+,4,4
openstack%2Ftripleo-quickstart~master~Iad781a91b59f612c8d8791fec97616ebbcaee4f4,openstack/tripleo-quickstart,master,Iad781a91b59f612c8d8791fec97616ebbcaee4f4,remove old inventory file when running quickstart.sh,MERGED,2016-05-05 14:10:36.000000000,2016-05-05 14:32:14.000000000,2016-05-05 14:32:13.000000000,"[{'_account_id': 3}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-05-05 14:10:36.000000000', 'files': ['quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4e137de9e68c94e589bfb23620b267d86f5badb1', 'message': 'remove old inventory file when running quickstart.sh\n\nthis avoid problems caused by using the inventory file generated by a\nprevious quickstart.sh invocation.\n\nChange-Id: Iad781a91b59f612c8d8791fec97616ebbcaee4f4\n'}]",0,312978,4e137de9e68c94e589bfb23620b267d86f5badb1,8,2,1,8745,,,0,"remove old inventory file when running quickstart.sh

this avoid problems caused by using the inventory file generated by a
previous quickstart.sh invocation.

Change-Id: Iad781a91b59f612c8d8791fec97616ebbcaee4f4
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/78/312978/1 && git format-patch -1 --stdout FETCH_HEAD,['quickstart.sh'],1,4e137de9e68c94e589bfb23620b267d86f5badb1,bug/remove-inventory,# Clear out inventory file to avoid tripping over data # from a previous invocation rm -f $ANSIBLE_INVENTORY ,,4,0
openstack%2Fopenstack-manuals~master~Ieff230fb698a41613b716f3fd605b9151a0f2f07,openstack/openstack-manuals,master,Ieff230fb698a41613b716f3fd605b9151a0f2f07,Correct the error page name,MERGED,2016-05-05 13:59:47.000000000,2016-05-05 14:30:17.000000000,2016-05-05 14:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-05 13:59:47.000000000', 'files': ['doc/ops-guide/source/ops_user_facing_operations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/93de23dbde8ea2963a9bd94fc20decec2d985d56', 'message': ""Correct the error page name\n\nThere should be 'Volumes' page, and add 'guilabel' for the name.\n\nChange-Id: Ieff230fb698a41613b716f3fd605b9151a0f2f07\n""}]",0,312973,93de23dbde8ea2963a9bd94fc20decec2d985d56,7,3,1,14151,,,0,"Correct the error page name

There should be 'Volumes' page, and add 'guilabel' for the name.

Change-Id: Ieff230fb698a41613b716f3fd605b9151a0f2f07
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/73/312973/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_user_facing_operations.rst'],1,93de23dbde8ea2963a9bd94fc20decec2d985d56,volumes-page,"next to the :guilabel:`volume` name on the dashboard :guilabel:`Volumes` page,","next to the :guilabel:`volume` name on the **dashboard** volume page,",1,1
openstack%2Ffuel-main~master~If614549621374cf4714f08152c914b85a448b534,openstack/fuel-main,master,If614549621374cf4714f08152c914b85a448b534,Always create /etc/fuel_build_id flag,MERGED,2016-05-05 09:26:25.000000000,2016-05-05 14:30:07.000000000,2016-05-05 13:54:39.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 10288}, {'_account_id': 12817}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 09:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6eae4d65cf6b4e447ba997c5d4c293c3c251fe52', 'message': ""Always create /etc/fuel_build_id flag\n\nWe need always create /etc/fuel_build_id flag-file since\nit's used for preprovisioned master node detection. The absense\nof this file means that we are on clean CentOS and should use\nonline repos.\n\nChange-Id: If614549621374cf4714f08152c914b85a448b534\nCloses-bug: #1578548\n""}, {'number': 2, 'created': '2016-05-05 09:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cbb0dcca3d4128d604abf010483ec4047795fcba', 'message': ""Always create /etc/fuel_build_id flag\n\nWe need always create /etc/fuel_build_id flag-file since\nit's used for preprovisioned master node detection. The absence\nof this file means that we are on clean CentOS and should use\nonline repos.\n\nChange-Id: If614549621374cf4714f08152c914b85a448b534\nCloses-bug: #1578548\n""}, {'number': 3, 'created': '2016-05-05 11:36:47.000000000', 'files': ['iso/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/656137de077d3b4c68d34d795ca30d66dd3a5709', 'message': ""Always create /etc/fuel_build_id flag\n\nWe need always create /etc/fuel_build_id flag-file since\nit's used for preprovisioned master node detection. The absence\nof this file means that we are on clean CentOS and should use\nonline repos.\n\nChange-Id: If614549621374cf4714f08152c914b85a448b534\nCloses-bug: #1578548\n""}]",0,312874,656137de077d3b4c68d34d795ca30d66dd3a5709,23,6,3,12817,,,0,"Always create /etc/fuel_build_id flag

We need always create /etc/fuel_build_id flag-file since
it's used for preprovisioned master node detection. The absence
of this file means that we are on clean CentOS and should use
online repos.

Change-Id: If614549621374cf4714f08152c914b85a448b534
Closes-bug: #1578548
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/74/312874/2 && git format-patch -1 --stdout FETCH_HEAD,['iso/module.mk'],1,6eae4d65cf6b4e447ba997c5d4c293c3c251fe52,,,ifdef BUILD_IDendif,0,2
openstack%2Fmurano~stable%2Fmitaka~I8265a69938658e89e4fc36824502c75a75a75c66,openstack/murano,stable/mitaka,I8265a69938658e89e4fc36824502c75a75a75c66,Revert the destroy execution order,MERGED,2016-05-04 13:53:53.000000000,2016-05-05 14:27:22.000000000,2016-05-05 14:27:22.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-05-04 13:53:53.000000000', 'files': ['murano/dsl/executor.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/3443d01e09e079801b0660c82f5b57b230cc97d6', 'message': 'Revert the destroy execution order\n\nRestores back the order of .destroy execution so that\nchild objects get destroyed first and Environment get\ndestroyed last.\n\nBoth orders have their cons and pros. With\nthe current order Environment and thus Heat stack\nare delete first so if the app sends a command to\nmurano-agent in its destroy method it will never\nreceive an answer since the VM of the agent was\nalready terminated. This broke Kubernetes and might\nbroke other apps as well.  However the downside is that\napps are going to perform uninstall of the software\non VM that is going to be terminated anyway which\ntakes time. But until we implement a controllable\nresource deallocation this looks like a safer approach.\n\nChange-Id: I8265a69938658e89e4fc36824502c75a75a75c66\nCloses-Bug: #1576703\n(cherry picked from commit 440b4b104996337bf07be75ffb412ddf5adc9a5d)\n'}]",0,312508,3443d01e09e079801b0660c82f5b57b230cc97d6,10,5,1,7226,,,0,"Revert the destroy execution order

Restores back the order of .destroy execution so that
child objects get destroyed first and Environment get
destroyed last.

Both orders have their cons and pros. With
the current order Environment and thus Heat stack
are delete first so if the app sends a command to
murano-agent in its destroy method it will never
receive an answer since the VM of the agent was
already terminated. This broke Kubernetes and might
broke other apps as well.  However the downside is that
apps are going to perform uninstall of the software
on VM that is going to be terminated anyway which
takes time. But until we implement a controllable
resource deallocation this looks like a safer approach.

Change-Id: I8265a69938658e89e4fc36824502c75a75a75c66
Closes-Bug: #1576703
(cherry picked from commit 440b4b104996337bf07be75ffb412ddf5adc9a5d)
",git fetch https://review.opendev.org/openstack/murano refs/changes/08/312508/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/dsl/executor.py'],1,3443d01e09e079801b0660c82f5b57b230cc97d6,bug/1576703, for val in six.itervalues(data): for res in self._list_potential_object_ids(val): yield res, for val in six.itervalues(data): for res in self._list_potential_object_ids(val): yield res,3,3
openstack%2Fopenstack-manuals~master~Iea220c8fc2b924ddf2dc073533107df838ecc995,openstack/openstack-manuals,master,Iea220c8fc2b924ddf2dc073533107df838ecc995,Correct the wrong web form name,MERGED,2016-05-05 13:49:04.000000000,2016-05-05 14:26:32.000000000,2016-05-05 14:26:31.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-05 13:49:04.000000000', 'files': ['doc/ops-guide/source/ops_user_facing_operations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/19d95da3aadab6c074fb0ba0ccfde63035237e23', 'message': 'Correct the wrong web form name\n\nThere should be ""Create Volume"" web form, not \'create volume\'.\n\nChange-Id: Iea220c8fc2b924ddf2dc073533107df838ecc995\n'}]",0,312961,19d95da3aadab6c074fb0ba0ccfde63035237e23,6,2,1,14151,,,0,"Correct the wrong web form name

There should be ""Create Volume"" web form, not 'create volume'.

Change-Id: Iea220c8fc2b924ddf2dc073533107df838ecc995
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/312961/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_user_facing_operations.rst'],1,19d95da3aadab6c074fb0ba0ccfde63035237e23,Create-Volume,Either put these into the **Create Volume** web form or use the command,Either put these into the **create volume** web form or use the command,1,1
openstack%2Fopenstack-ansible~kilo~I080ccc1e94bcdbc8578fab747ad51132e24dd368,openstack/openstack-ansible,kilo,I080ccc1e94bcdbc8578fab747ad51132e24dd368,Set ansible forks inside juno-container-cleanup.sh,ABANDONED,2016-04-27 12:25:00.000000000,2016-05-05 14:24:52.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14552}]","[{'number': 1, 'created': '2016-04-27 12:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d0677b6b203ea48ff87472f27cb256754e3eff7a', 'message': 'Set ansible forks inside juno-container-cleanup.sh\n\nThis fix sets the ansible forks to either the number of processors\nvisible to the OS or to the value set from the envrionment variable\nFORKS used in order to run the upgrade process.\nRunning ansible inside the juno-container-cleanup.sh without --forks\nparameter will result in a sgnificant run time, when reaching a certain\nthreshold of nodes within the control plane.\n\nChange-Id: I080ccc1e94bcdbc8578fab747ad51132e24dd368\nCloses-Bug: #1575629\n'}, {'number': 2, 'created': '2016-04-27 12:28:28.000000000', 'files': ['scripts/upgrade-utilities/scripts/juno-container-cleanup.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/26677bde271ad4779c953421d4c4e6fb35b6512b', 'message': 'Set ansible forks inside juno-container-cleanup.sh\n\nThis fix sets the ansible forks to either the number of processors\nvisible to the OS or to the value set from the envrionment variable\nFORKS used in order to run the upgrade process.\nRunning ansible inside the juno-container-cleanup.sh without --forks\nparameter will result in a sgnificant run time, when reaching a certain\nthreshold of nodes within the control plane.\n\nChange-Id: I080ccc1e94bcdbc8578fab747ad51132e24dd368\nCloses-Bug: #1575629\n'}]",3,310434,26677bde271ad4779c953421d4c4e6fb35b6512b,10,4,2,14552,,,0,"Set ansible forks inside juno-container-cleanup.sh

This fix sets the ansible forks to either the number of processors
visible to the OS or to the value set from the envrionment variable
FORKS used in order to run the upgrade process.
Running ansible inside the juno-container-cleanup.sh without --forks
parameter will result in a sgnificant run time, when reaching a certain
threshold of nodes within the control plane.

Change-Id: I080ccc1e94bcdbc8578fab747ad51132e24dd368
Closes-Bug: #1575629
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/310434/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/upgrade-utilities/scripts/juno-container-cleanup.sh'],1,d0677b6b203ea48ff87472f27cb256754e3eff7a,bug/1575629,"set NUMCPUS=$(egrep '^processor.*:' /proc/cpuinfo |wc -l) export FORKS=${FORKS:=$NUMCPUS} openstack-ansible --$FORKS lxc-hosts-setup.yml openstack-ansible --$FORKS lxc-containers-destroy.yml -e container_group=""rsyslog_all"" openstack-ansible --$FORKS lxc-containers-destroy.yml -e container_group=""nova_api_ec2"" openstack-ansible --$FORKS lxc-containers-destroy.yml -e container_group=""nova_spice_console"""," openstack-ansible lxc-hosts-setup.yml openstack-ansible lxc-containers-destroy.yml -e container_group=""rsyslog_all"" openstack-ansible lxc-containers-destroy.yml -e container_group=""nova_api_ec2"" openstack-ansible lxc-containers-destroy.yml -e container_group=""nova_spice_console""",7,4
openstack%2Fdesignate-tempest-plugin~master~I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4,openstack/designate-tempest-plugin,master,I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4,Add recordset_client's methods and tests to Designate tempest plugin,MERGED,2016-04-15 13:10:44.000000000,2016-05-05 14:24:41.000000000,2016-05-05 14:24:41.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 11662}, {'_account_id': 15699}]","[{'number': 1, 'created': '2016-04-15 13:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/2dc56538c9ad73a531175d326493a3e9930d7a9e', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\nPartially-Implements: blueprint designate-tempest-plugin\n""}, {'number': 2, 'created': '2016-04-15 13:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/bcb4cae6997f97edc4034dec76d8da096978df1f', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\nPartially-Implements: blueprint designate-tempest-plugin\n""}, {'number': 3, 'created': '2016-04-18 07:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/95e42ccc255d2e6ff3b12e63a2b53f0718d550ae', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 4, 'created': '2016-04-18 07:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/a2c835436f8b3973d07447abd7395ccdf69ab7ef', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 5, 'created': '2016-04-19 07:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/2d00a03afafb5d69ab66038cacf81e4d047f065d', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 6, 'created': '2016-04-20 02:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/9a75bb06d48dfb62ea5a3e4f999e0679ed32523f', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 7, 'created': '2016-04-21 05:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/8128a512cdcc0387cec2d6057ae3655bd025a3ea', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 8, 'created': '2016-04-21 07:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/66a529cf96b35a9236a313cef79cd367b31bdfb9', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 9, 'created': '2016-05-04 15:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/ae79f575f9abe5e2bdd197d94f6071386147f3b3', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 10, 'created': '2016-05-04 15:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/52c1dda4beadaef1265cdfff85c706b1fb9f0f6a', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 11, 'created': '2016-05-04 16:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/a84a2d3befde440314ef68830c6ca86e5cda8f94', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}, {'number': 12, 'created': '2016-05-04 16:19:13.000000000', 'files': ['designate_tempest_plugin/services/dns/v2/json/recordset_client.py', 'designate_tempest_plugin/clients.py', 'designate_tempest_plugin/services/dns/json/base.py', 'designate_tempest_plugin/tests/api/v2/test_recordset.py', 'designate_tempest_plugin/data_utils.py', 'designate_tempest_plugin/common/waiters.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/de24d967f3329d0dcb7a54034ba15710ff49c23c', 'message': ""Add recordset_client's methods and tests to Designate tempest plugin\n\nPartially-Implements: blueprint designate-tempest-plugin\n\nChange-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4\n""}]",20,306409,de24d967f3329d0dcb7a54034ba15710ff49c23c,31,4,12,15699,,,0,"Add recordset_client's methods and tests to Designate tempest plugin

Partially-Implements: blueprint designate-tempest-plugin

Change-Id: I55ebc5210f7b1e50b59411658a1ae4d1f39a3ff4
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/09/306409/12 && git format-patch -1 --stdout FETCH_HEAD,"['designate_tempest_plugin/services/dns/v2/json/recordset_client.py', 'designate_tempest_plugin/clients.py', 'designate_tempest_plugin/services/dns/json/base.py', 'designate_tempest_plugin/tests/api/v2/test_recordset.py', 'designate_tempest_plugin/data_utils.py']",5,2dc56538c9ad73a531175d326493a3e9930d7a9e,bp/designate-tempest-plugin,"import randomdef rand_ip(): return ""."".join(str(random.randrange(0, 256)) for _ in range(4)) def rand_ipv6(): def hexes(n): return """".join(random.choice(""1234567890abcdef"") for _ in range(n)) result = "":"".join(hexes(4) for _ in range(8)) return result.replace(""0000"", ""0"") def rand_zone_data(name=None, email=None, ttl=None, description=None): """"""Generate random zone data, with optional overrides :return: A ZoneModel """""" if name is None: name = rand_zone_name(prefix='testdomain', suffix='.com.') if email is None: email = (""admin@"" + name).strip('.') if description is None: description = rand_zone_name(prefix='Description ', suffix='') if ttl is None: ttl = random.randint(1200, 8400), return { 'name': name, 'email': email, 'ttl': random.randint(1200, 8400), 'description': description} def rand_recordset_data(record_type, zone_name, name=None, records=None, ttl=None): """"""Generate random recordset data, with optional overrides :return: A RecordsetModel """""" if name is None: name = rand_zone_name(prefix=record_type, suffix='.' + zone_name) if records is None: records = [rand_ip()] if ttl is None: ttl = random.randint(1200, 8400) return { 'type': record_type, 'name': name, 'records': records, 'ttl': ttl} def rand_a_recordset(zone_name, ip=None, **kwargs): if ip is None: ip = rand_ip() return rand_recordset_data('A', zone_name, records=[ip], **kwargs) def rand_aaaa_recordset(zone_name, ip=None, **kwargs): if ip is None: ip = rand_ipv6() return rand_recordset_data('AAAA', zone_name, records=[ip], **kwargs) def rand_cname_recordset(zone_name, cname=None, **kwargs): if cname is None: cname = zone_name return rand_recordset_data('CNAME', zone_name, records=[cname], **kwargs) def rand_mx_recordset(zone_name, pref=None, host=None, **kwargs): if pref is None: pref = str(random.randint(0, 65535)) if host is None: host = rand_zone_name(prefix='mail', suffix='.' + zone_name) data = ""{0} {1}"".format(pref, host) return rand_recordset_data('MX', zone_name, records=[data], **kwargs) def rand_blacklist_data(): data = { ""pattern"": rand_zone_name() } return data def rand_pool_data(): ns_zone = rand_zone_data().name data = { ""name"": rand_zone_name(), } records = [] for i in range(0, 2): records.append(""ns%s.%s"" % (i, ns_zone)) ns_records = [{""hostname"": x, ""priority"": random.randint(1, 999)} for x in records] data[""ns_records""] = ns_records return data def rand_spf_recordset(zone_name, data=None, **kwargs): data = data or ""v=spf1 +all"" return rand_recordset_data('SPF', zone_name, records=[data], **kwargs) def rand_srv_recordset(zone_name, data=None): data = data or ""10 0 8080 %s.%s"" % (rand_zone_name(suffix=''), zone_name) return rand_recordset_data('SRV', zone_name, name=""_sip._tcp.%s"" % zone_name, records=[data]) def rand_sshfp_recordset(zone_name, algorithm_number=None, fingerprint_type=None, fingerprint=None, **kwargs): algorithm_number = algorithm_number or 2 fingerprint_type = fingerprint_type or 1 fingerprint = fingerprint or \ ""123456789abcdef67890123456789abcdef67890"" data = ""%s %s %s"" % (algorithm_number, fingerprint_type, fingerprint) return rand_recordset_data('SSHFP', zone_name, records=[data], **kwargs) def rand_txt_recordset(zone_name, data=None, **kwargs): data = data or ""v=spf1 +all"" return rand_recordset_data('TXT', zone_name, records=[data], **kwargs) def wildcard_ns_recordset(zone_name): name = ""*.{0}"".format(zone_name) records = [""ns.example.com.""] return rand_recordset_data('NS', zone_name, name, records)",,403,2
openstack%2Fvitrage~master~I94e68caedb35ecbf400f3e78532f7dddeb12c37a,openstack/vitrage,master,I94e68caedb35ecbf400f3e78532f7dddeb12c37a,remove vitrage-dashboard,MERGED,2016-05-05 14:01:22.000000000,2016-05-05 14:21:10.000000000,2016-05-05 14:21:10.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-05-05 14:01:22.000000000', 'files': ['devstack/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/1ed9591944bff4948986e51efa4f69575e3e5496', 'message': 'remove vitrage-dashboard\n\nChange-Id: I94e68caedb35ecbf400f3e78532f7dddeb12c37a\n'}]",0,312974,1ed9591944bff4948986e51efa4f69575e3e5496,6,2,1,19134,,,0,"remove vitrage-dashboard

Change-Id: I94e68caedb35ecbf400f3e78532f7dddeb12c37a
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/74/312974/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/gate_hook.sh'],1,1ed9591944bff4948986e51efa4f69575e3e5496,eyalb/tempest,,DEVSTACK_LOCAL_CONFIG+=$'\nenable_plugin vitrage-dashboard git://git.openstack.org/openstack/vitrage-dashboard',0,1
openstack%2Fironic-specs~master~Id6a084a9c8f910a16cc12b102c4cb51f1691e12e,openstack/ironic-specs,master,Id6a084a9c8f910a16cc12b102c4cb51f1691e12e,Add newton priorities doc,MERGED,2016-04-30 17:52:09.000000000,2016-05-05 14:20:28.000000000,2016-05-05 14:20:28.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 14760}, {'_account_id': 16530}, {'_account_id': 16635}]","[{'number': 1, 'created': '2016-04-30 17:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/11939cc7d024059e30d59be12c2db5862e208fb4', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}, {'number': 2, 'created': '2016-04-30 17:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7ba16616758c317c74a118ea994d8895bd69c842', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}, {'number': 3, 'created': '2016-05-02 14:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c6fb2463a64d52748413a54cb06050c46f0413e9', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}, {'number': 4, 'created': '2016-05-03 21:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ea2fde8b4b68a73b9465c999c1006d482b1f30d7', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}, {'number': 5, 'created': '2016-05-04 12:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/aa58c4d17b5e1b50257a003878069dd7cfecbdda', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}, {'number': 6, 'created': '2016-05-04 15:17:18.000000000', 'files': ['priorities/newton-priorities.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/67c8de2e94c36c69ca48a14895af208ce1027f12', 'message': 'Add newton priorities doc\n\nChange-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e\n'}]",35,311530,67c8de2e94c36c69ca48a14895af208ce1027f12,44,15,6,10343,,,0,"Add newton priorities doc

Change-Id: Id6a084a9c8f910a16cc12b102c4cb51f1691e12e
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/30/311530/6 && git format-patch -1 --stdout FETCH_HEAD,['priorities/newton-priorities.rst'],1,11939cc7d024059e30d59be12c2db5862e208fb4,newton-priorities,".. _newton-priorities: ========================= Newton Project Priorities ========================= This is a list of development priorities the Ironic team is prioritizing for Newton development, in no particular order. +-----------------------------------------+----------------------------------+ | Priority | Primary Contacts | +=========================================+==================================+ | `Upgrade testing`_ | jlvillal | +-----------------------------------------+----------------------------------+ | `Network isolation`_ | jroll | +-----------------------------------------+----------------------------------+ | `Node search and claims API`_ | jroll | +-----------------------------------------+----------------------------------+ | `Multiple compute hosts`_ | jroll | +-----------------------------------------+----------------------------------+ | `Gate improvements`_ | jroll | +-----------------------------------------+----------------------------------+ | `Generic boot-from-volume`_ | TheJulia | +-----------------------------------------+----------------------------------+ | `Driver composition`_ | dtantsur | +-----------------------------------------+----------------------------------+ Upgrade testing --------------- We claim to support upgrading Ironic from release to release (and cycle to cycle), however we don't have testing to prove that. This item is specifically to get cold upgrade testing working, which is necessary for some of the heavier changes, like network isolation and multi-compute. Network isolation ----------------- This feature was designed in Liberty, and much of the code was written. The code was not ready in time to land in Liberty. We need to complete this work in Mitaka, along with the Nova side of the work. This is one of our biggest feature asks from users. Node search and claims API -------------------------- This lays the groundwork for the work being done in Nova to allow the Ironic driver to utilize multiple compute hosts. The search API also helps users query nodes much more intelligently, and the claims endpoint will help clients other than Nova schedule to nodes more easily. Multiple compute hosts ---------------------- This is an effort to allow the Ironic virt driver in Nova scale across many compute hosts. Currently only one compute host is supported. This shrinks the failure domain of the nova-compute service in an Ironic deployment, and also helps schedule Ironic resources more efficiently. Note that this work is in the Nova codebase, but is an Ironic effort. Gate improvements ----------------- There exist other gaps in our gate testing, as well as some refactoring we wish to do. This includes: * Switching to tinyipa instead of the CoreOS image. * Switching to virtualbmc instead of the SSH driver. * Testing local boot * Testing agent driver with partition images * Getting grenade-partial running to test live upgrades (even if it isn't stable yet) Generic boot-from-volume ------------------------ This work allows generic hardware to boot from NFS or cinder volumes, allowing diskless nodes to be managed by ironic. Driver composition ------------------ This work refactors the way that drivers are composed internally, as well as allowing operators to mix and match drivers for each interface rather than guessing at which driver is which combination. This allows us to stop exploding our driver matrix with every interface addition. ",,86,0
openstack%2Fopenstack-ansible~kilo~Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,openstack/openstack-ansible,kilo,Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,Add release note for paramiko issue workaround,MERGED,2016-05-05 13:36:06.000000000,2016-05-05 14:17:20.000000000,2016-05-05 14:17:20.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-05 13:36:06.000000000', 'files': ['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4981ed929613d6ad448dc9b566b458c85491c5f7', 'message': 'Add release note for paramiko issue workaround\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)\n'}]",0,312954,4981ed929613d6ad448dc9b566b458c85491c5f7,7,3,1,6816,,,0,"Add release note for paramiko issue workaround

Change Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve
the issue with the Paramkino 2.0 update, but did not include a release note to
be explicit that this is a known issue and to inform deployers how to work
around it.

This patch adds a release note to do that.

Change-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8
Closes-Bug: #1577469
(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/54/312954/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'],1,4981ed929613d6ad448dc9b566b458c85491c5f7,bug/1577469,"--- issues: - Paramiko version 2.0 Python requires the Python cryptography library. New system packages must be installed for this library. For OpenStack-Ansible versions <12.0.12, <11.2.15, <13.0.2 the system packages must be installed on the **deployment host** manually by executing ``apt-get install -y build-essential libssl-dev libffi-dev``. ",,6,0
openstack%2Fopenstack-ansible~liberty~Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,openstack/openstack-ansible,liberty,Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,Add release note for paramiko issue workaround,MERGED,2016-05-05 13:35:56.000000000,2016-05-05 14:17:13.000000000,2016-05-05 14:17:13.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-05 13:35:56.000000000', 'files': ['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2c8e9a5e1c417256931c6e74d55dcd2540914a90', 'message': 'Add release note for paramiko issue workaround\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)\n'}]",0,312953,2c8e9a5e1c417256931c6e74d55dcd2540914a90,7,3,1,6816,,,0,"Add release note for paramiko issue workaround

Change Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve
the issue with the Paramkino 2.0 update, but did not include a release note to
be explicit that this is a known issue and to inform deployers how to work
around it.

This patch adds a release note to do that.

Change-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8
Closes-Bug: #1577469
(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/53/312953/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'],1,2c8e9a5e1c417256931c6e74d55dcd2540914a90,bug/1577469,"--- issues: - Paramiko version 2.0 Python requires the Python cryptography library. New system packages must be installed for this library. For OpenStack-Ansible versions <12.0.12, <11.2.15, <13.0.2 the system packages must be installed on the **deployment host** manually by executing ``apt-get install -y build-essential libssl-dev libffi-dev``. ",,6,0
openstack%2Fopenstack-ansible~stable%2Fmitaka~Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,openstack/openstack-ansible,stable/mitaka,Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,Add release note for paramiko issue workaround,MERGED,2016-05-05 13:35:37.000000000,2016-05-05 14:16:50.000000000,2016-05-05 14:16:49.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-05-05 13:35:37.000000000', 'files': ['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b218ed9375efa546aa044c69d01451e895dc08bc', 'message': 'Add release note for paramiko issue workaround\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)\n'}]",0,312952,b218ed9375efa546aa044c69d01451e895dc08bc,7,3,1,6816,,,0,"Add release note for paramiko issue workaround

Change Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve
the issue with the Paramkino 2.0 update, but did not include a release note to
be explicit that this is a known issue and to inform deployers how to work
around it.

This patch adds a release note to do that.

Change-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8
Closes-Bug: #1577469
(cherry picked from commit 6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/52/312952/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'],1,b218ed9375efa546aa044c69d01451e895dc08bc,bug/1577469,"--- issues: - Paramiko version 2.0 Python requires the Python cryptography library. New system packages must be installed for this library. For OpenStack-Ansible versions <12.0.12, <11.2.15, <13.0.2 the system packages must be installed on the **deployment host** manually by executing ``apt-get install -y build-essential libssl-dev libffi-dev``. ",,6,0
openstack%2Foslo.log~master~I2b6ea35fbf171232fea0cc54265f8be3dc61457f,openstack/oslo.log,master,I2b6ea35fbf171232fea0cc54265f8be3dc61457f,Fix example issue,MERGED,2016-05-04 07:46:13.000000000,2016-05-05 14:14:16.000000000,2016-05-05 14:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 9459}, {'_account_id': 9796}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-05-04 07:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/28d8d3c5e62a5def460cd9e19faf0effd55cf2a4', 'message': 'Fix example issue\n\nexample LOG.exception(""An Exception occurred"") in both usage.py and\nusage_helper.py failed when use py34.\n\nfix it by raising exception before calling LOG.exception().\n\nChange-Id: I2b6ea35fbf171232fea0cc54265f8be3dc61457f\nCloses-Bug: #1578071\n'}, {'number': 2, 'created': '2016-05-04 07:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/7c7e0945186014a5f9ded5e8303dde72e5cf12cc', 'message': 'Fix example issue\n\nexample LOG.exception(""An Exception occurred"") in both usage.py,\nusage_helper.py and usage_i18n.py failed when use py34.\n\nfix it by raising exception before calling LOG.exception().\n\nChange-Id: I2b6ea35fbf171232fea0cc54265f8be3dc61457f\nCloses-Bug: #1578071\n'}, {'number': 3, 'created': '2016-05-05 01:33:25.000000000', 'files': ['doc/source/examples/usage_helper.py', 'doc/source/examples/usage_i18n.py', 'doc/source/examples/usage.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c63991fb4d0f02c27a10cc93b08a0d3901026755', 'message': 'Fix example issue\n\nexample LOG.exception(""An Exception occurred"") in both usage.py,\nusage_helper.py and usage_i18n.py failed when use py34.\n\nfix it by raising exception before calling LOG.exception().\n\nChange-Id: I2b6ea35fbf171232fea0cc54265f8be3dc61457f\nCloses-Bug: #1578071\n'}]",2,312351,c63991fb4d0f02c27a10cc93b08a0d3901026755,13,5,3,9459,,,0,"Fix example issue

example LOG.exception(""An Exception occurred"") in both usage.py,
usage_helper.py and usage_i18n.py failed when use py34.

fix it by raising exception before calling LOG.exception().

Change-Id: I2b6ea35fbf171232fea0cc54265f8be3dc61457f
Closes-Bug: #1578071
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/51/312351/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/examples/usage_helper.py', 'doc/source/examples/usage.py']",2,28d8d3c5e62a5def460cd9e19faf0effd55cf2a4,bug/1578071," try: raise Exception('This is exceptional') except Exception: LOG.exception(""An Exception occurred"")"," LOG.exception(""An Exception occurred"")",8,2
openstack%2Ftripleo-quickstart~master~I49f6565a4a6b157cb11df30a9548b697fc11d615,openstack/tripleo-quickstart,master,I49f6565a4a6b157cb11df30a9548b697fc11d615,fix some formatting errors in our inventory template,MERGED,2016-05-05 13:10:52.000000000,2016-05-05 14:13:41.000000000,2016-05-05 14:13:41.000000000,"[{'_account_id': 3}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-05-05 13:10:52.000000000', 'files': ['playbooks/roles/rebuild-inventory/templates/inventory.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/db10f7948e06c946c6e9139fcc3eb493ed58a915', 'message': 'fix some formatting errors in our inventory template\n\nthere were some missing spaces here that in some situations could\nresult in invalid inventory file entries.  If you started with an\ninventory that looked like this:\n\n    [virthost]\n    myhostname ansible_user=alice\n\nYou would end up with something like this in the generated inventory\nfile:\n\n    myhostnameansible_user=alice\n\nChange-Id: I49f6565a4a6b157cb11df30a9548b697fc11d615\n'}]",0,312938,db10f7948e06c946c6e9139fcc3eb493ed58a915,7,2,1,8745,,,0,"fix some formatting errors in our inventory template

there were some missing spaces here that in some situations could
result in invalid inventory file entries.  If you started with an
inventory that looked like this:

    [virthost]
    myhostname ansible_user=alice

You would end up with something like this in the generated inventory
file:

    myhostnameansible_user=alice

Change-Id: I49f6565a4a6b157cb11df30a9548b697fc11d615
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/38/312938/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/rebuild-inventory/templates/inventory.j2'],1,db10f7948e06c946c6e9139fcc3eb493ed58a915,bug/inventory-formatting,%} ansible_user={{ hostvars[host]['ansible_user'] }} {% endif %}%} ansible_private_key_file={{ hostvars[host]['ansible_private_key_file'] }},%}ansible_user={{ hostvars[host]['ansible_user'] }} {% endif %}%}ansible_private_key_file={{ hostvars[host]['ansible_private_key_file'] }},2,2
openstack%2Fopenstack-ansible-security~master~I362ad1244932124cc8eaa27624aae8f19d4888b9,openstack/openstack-ansible-security,master,I362ad1244932124cc8eaa27624aae8f19d4888b9,Removing equal signs in docs,MERGED,2016-05-04 14:53:31.000000000,2016-05-05 14:12:55.000000000,2016-05-05 14:10:31.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 15993}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-05-04 14:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/60e48e1b59fe158a7b9eb4c922f174ea13f73580', 'message': 'Removing equal signs in docs\n\nThis patch removes some documentation errors where equal signs\nwere used instead of colons.\n\nChange-Id: I362ad1244932124cc8eaa27624aae8f19d4888b9\n'}, {'number': 2, 'created': '2016-05-05 12:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/79be9d0e9ceb8d4c90a0bc48fcb225eb4ae84793', 'message': 'Removing equal signs in docs\n\nThis patch removes some documentation errors where equal signs\nwere used instead of colons.\n\nChange-Id: I362ad1244932124cc8eaa27624aae8f19d4888b9\n'}, {'number': 3, 'created': '2016-05-05 13:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/30522b981ca0a20b0135f93ec2be9379cb3b081a', 'message': 'Removing equal signs in docs\n\nThis patch removes some documentation errors where equal signs\nwere used instead of colons.\n\nChange-Id: I362ad1244932124cc8eaa27624aae8f19d4888b9\n'}, {'number': 4, 'created': '2016-05-05 13:33:11.000000000', 'files': ['doc/source/developer-notes/V-38610.rst', 'doc/source/developer-notes/V-38608.rst', 'doc/source/developer-notes/V-38464.rst', 'doc/source/developer-notes/V-38613.rst', 'doc/source/developer-notes/V-38470.rst', 'doc/source/developer-notes/V-38468.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/6f8b686fe57dd43ae204e84bd63e5833ebf8ddfc', 'message': 'Removing equal signs in docs\n\nThis patch removes some documentation errors where equal signs\nwere used instead of colons.\n\nChange-Id: I362ad1244932124cc8eaa27624aae8f19d4888b9\n'}]",0,312580,6f8b686fe57dd43ae204e84bd63e5833ebf8ddfc,18,6,4,538,,,0,"Removing equal signs in docs

This patch removes some documentation errors where equal signs
were used instead of colons.

Change-Id: I362ad1244932124cc8eaa27624aae8f19d4888b9
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/80/312580/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer-notes/V-38610.rst', 'doc/source/developer-notes/V-38608.rst', 'doc/source/developer-notes/V-38464.rst', 'doc/source/developer-notes/V-38613.rst', 'doc/source/developer-notes/V-38470.rst', 'doc/source/developer-notes/V-38468.rst']",6,60e48e1b59fe158a7b9eb4c922f174ea13f73580,doc-variable-cleanup, disk_full_action: SYSLOG, disk_full_action = SYSLOG,6,6
openstack%2Ffuel-library~master~Ifac069347be758ac2c12b890a3b4751db1a12e21,openstack/fuel-library,master,Ifac069347be758ac2c12b890a3b4751db1a12e21,Limit number of metadata workers,MERGED,2016-04-29 10:30:46.000000000,2016-05-05 14:04:46.000000000,2016-05-05 08:28:39.000000000,"[{'_account_id': 3}, {'_account_id': 5948}, {'_account_id': 7125}, {'_account_id': 7249}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13344}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-29 10:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/05baf1494fd79d74f58d549d00d0c053fefa232a', 'message': 'Limit number of metadata workers\n\nmetadata_workers option from Nova is not used, so currently a number of\nmetadata workers on all nodes is equal to number of CPUs.\nThis patch limits a number of workers using following schemes:\n- for controllers: min(max($::processorcount, 2), $workers_max)\n- for computes (DVR): min($::processorcount / 8 + 1, $workers_max))\n\nChange-Id: Ifac069347be758ac2c12b890a3b4751db1a12e21\nCloses-bug: #1575724\n'}, {'number': 2, 'created': '2016-05-01 08:24:23.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/openstack_controller/openstack_controller.pp', 'tests/noop/spec/hosts/openstack-network/agents/metadata_spec.rb', 'deployment/puppet/openstack_tasks/examples/openstack-network/tasks.yaml', 'deployment/puppet/openstack_tasks/manifests/openstack_network/agents/metadata.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7394062ec83f5ee32b042af8c04829b9a12e6838', 'message': 'Limit number of metadata workers\n\nmetadata_workers option from Nova is not used, so currently a number of\nmetadata workers on all nodes is equal to number of CPUs.\nThis patch limits a number of workers using following schemes:\n- for controllers: min(max($::processorcount, 2), $workers_max)\n- for computes (DVR): min($::processorcount / 8 + 1, $workers_max))\n\nChange-Id: Ifac069347be758ac2c12b890a3b4751db1a12e21\nCloses-bug: #1575724\n'}]",0,311079,7394062ec83f5ee32b042af8c04829b9a12e6838,67,14,2,7604,,,0,"Limit number of metadata workers

metadata_workers option from Nova is not used, so currently a number of
metadata workers on all nodes is equal to number of CPUs.
This patch limits a number of workers using following schemes:
- for controllers: min(max($::processorcount, 2), $workers_max)
- for computes (DVR): min($::processorcount / 8 + 1, $workers_max))

Change-Id: Ifac069347be758ac2c12b890a3b4751db1a12e21
Closes-bug: #1575724
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/311079/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/manifests/openstack_controller/openstack_controller.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/tasks.yaml', 'tests/noop/spec/hosts/openstack-network/agents/metadata_spec.rb', 'deployment/puppet/openstack_tasks/manifests/openstack_network/agents/metadata.pp']",4,05baf1494fd79d74f58d549d00d0c053fefa232a,bug/1575724," $neutron_config = hiera_hash('neutron_config') $workers_max = hiera('workers_max', 16) if $compute { $metadata_workers = pick($neutron_config['workers'], min($::processorcount / 8 + 1, $workers_max)) } else { $metadata_workers = pick($neutron_config['workers'], min(max($::processorcount, 2), $workers_max)) } debug => $debug, shared_secret => $shared_secret, metadata_ip => $nova_endpoint, metadata_workers => $metadata_workers, manage_service => true, enabled => true,"," $neutron_config = hiera_hash('neutron_config') debug => $debug, shared_secret => $shared_secret, metadata_ip => $nova_endpoint, manage_service => true, enabled => true,",31,8
openstack%2Fnova~master~I75d09832980a88752b061309e80c3fcfce1f2fcc,openstack/nova,master,I75d09832980a88752b061309e80c3fcfce1f2fcc,libvirt: Fix ssh driver to to prevent prompting,MERGED,2016-03-16 09:09:11.000000000,2016-05-05 13:56:27.000000000,2016-05-03 10:54:48.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5280}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 15286}]","[{'number': 1, 'created': '2016-03-16 09:09:11.000000000', 'files': ['nova/virt/libvirt/volume/remotefs.py', 'nova/tests/unit/virt/libvirt/volume/test_remotefs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b274a85e968242cfb9bf44925a7266ecd4ce2243', 'message': 'libvirt: Fix ssh driver to to prevent prompting\n\nThis patch fix the bug which was resolved in\nthis patch Ib1e38f397afaac96a2e1a8717c87a4b6756419db\nbut got lost after the merge of this\nI586a9faa2a7afa3f195239df305898b6da4fb583 patch\n\nChange-Id: I75d09832980a88752b061309e80c3fcfce1f2fcc\n'}]",0,293328,b274a85e968242cfb9bf44925a7266ecd4ce2243,30,9,1,12171,,,0,"libvirt: Fix ssh driver to to prevent prompting

This patch fix the bug which was resolved in
this patch Ib1e38f397afaac96a2e1a8717c87a4b6756419db
but got lost after the merge of this
I586a9faa2a7afa3f195239df305898b6da4fb583 patch

Change-Id: I75d09832980a88752b061309e80c3fcfce1f2fcc
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/293328/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/volume/remotefs.py', 'nova/tests/unit/virt/libvirt/volume/test_remotefs.py']",2,b274a85e968242cfb9bf44925a7266ecd4ce2243,fix_ssh_driver," @mock.patch('nova.utils.ssh_execute') def test_remove_remote_file_ssh(self, mock_ssh_execute): mock_ssh_execute.assert_called_once_with( 'host', 'rm', 'dest', @mock.patch('nova.utils.ssh_execute') def test_remove_remote_dir_ssh(self, mock_ssh_execute): mock_ssh_execute.assert_called_once_with( 'host', 'rm', '-rf', 'dest', on_completion=None, @mock.patch('nova.utils.ssh_execute') def test_create_remote_file_ssh(self, mock_ssh_execute): mock_ssh_execute.assert_called_once_with('host', 'touch', 'dest_dir', on_completion=None, on_execute=None) @mock.patch('nova.utils.ssh_execute') def test_create_remote_dir_ssh(self, mock_ssh_execute): mock_ssh_execute.assert_called_once_with('host', 'mkdir', '-p', 'dest_dir', on_completion=None, on_execute=None)"," @mock.patch('nova.utils.execute') def test_remove_remote_file_ssh(self, mock_execute): mock_execute.assert_called_once_with( 'ssh', 'host', 'rm', 'dest', @mock.patch('nova.utils.execute') def test_remove_remote_dir_ssh(self, mock_execute): mock_execute.assert_called_once_with( 'ssh', 'host', 'rm', '-rf', 'dest', on_completion=None, @mock.patch('nova.utils.execute') def test_create_remote_file_ssh(self, mock_execute): mock_execute.assert_called_once_with('ssh', 'host', 'touch', 'dest_dir', on_completion=None, on_execute=None) @mock.patch('nova.utils.execute') def test_create_remote_dir_ssh(self, mock_execute): mock_execute.assert_called_once_with('ssh', 'host', 'mkdir', '-p', 'dest_dir', on_completion=None, on_execute=None)",28,28
openstack%2Fopenstack-ansible-galera_server~stable%2Fmitaka~Iaf4dcd2b317394c41e7d774abde50d3548fc117f,openstack/openstack-ansible-galera_server,stable/mitaka,Iaf4dcd2b317394c41e7d774abde50d3548fc117f,Role tests should test against the same branch,MERGED,2016-05-04 18:23:36.000000000,2016-05-05 13:56:01.000000000,2016-05-05 13:56:01.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-05-04 18:23:36.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tests/test-prep.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/26ec8e8847a0e50baccffe1d3bc13974646f42e2', 'message': 'Role tests should test against the same branch\n\nAll dependent roles used in testing must be the\nsame branch as the role under test.\n\nThe py_from_git role is removed as it is no longer required.\n\nChange-Id: Iaf4dcd2b317394c41e7d774abde50d3548fc117f\n'}]",0,312677,26ec8e8847a0e50baccffe1d3bc13974646f42e2,10,3,1,6816,,,0,"Role tests should test against the same branch

All dependent roles used in testing must be the
same branch as the role under test.

The py_from_git role is removed as it is no longer required.

Change-Id: Iaf4dcd2b317394c41e7d774abde50d3548fc117f
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/77/312677/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tests/test-prep.yml']",2,26ec8e8847a0e50baccffe1d3bc13974646f42e2,role_deps_same_branch, post_tasks:," - role: ""py_from_git"" git_repo: ""https://github.com/lxc/python2-lxc"" git_dest: ""/opt/lxc_python2"" git_install_branch: ""master"" post_tasks: # THIS TASK IS ONLY BEING DONE BECAUSE THE TOX SHARED LXC LIB IS NOT USABLE ON A # HOST MACHINE THAT MAY NOT HAVE ACCESS TO THE VENV. - name: Ensure the lxc lib is on the host command: /usr/local/bin/pip install /opt/lxc_python2",6,18
openstack%2Fopenstack-ansible-plugins~master~Ia40e2e08be4d384eb3e5992502daaebe3d338d32,openstack/openstack-ansible-plugins,master,Ia40e2e08be4d384eb3e5992502daaebe3d338d32,Adjust release note for config template,MERGED,2016-05-03 07:34:03.000000000,2016-05-05 13:54:09.000000000,2016-05-04 20:30:49.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-03 07:34:03.000000000', 'files': ['releasenotes/notes/config_template-MultiStrOps-support-c28e33fd5044e14d.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/79f3735ee0e2e5a924904f6f8b6d479a42bd96c3', 'message': ""Adjust release note for config template\n\nThe config template release note has a stand alone 'fixes' note which,\nwhen rendered, makes no sense as it stands alone. As the bug is\nclearly attached to the milestone it is unnecessary to mention the\nbug fixed so that line has been removed.\n\nChange-Id: Ia40e2e08be4d384eb3e5992502daaebe3d338d32\n""}]",0,311945,79f3735ee0e2e5a924904f6f8b6d479a42bd96c3,12,3,1,6816,,,0,"Adjust release note for config template

The config template release note has a stand alone 'fixes' note which,
when rendered, makes no sense as it stands alone. As the bug is
clearly attached to the milestone it is unnecessary to mention the
bug fixed so that line has been removed.

Change-Id: Ia40e2e08be4d384eb3e5992502daaebe3d338d32
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/45/311945/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/config_template-MultiStrOps-support-c28e33fd5044e14d.yaml'],1,79f3735ee0e2e5a924904f6f8b6d479a42bd96c3,," The ability to support MultiStrOps has been added to the config_template action plugin. This change updates the parser to use the ``set()`` type to determine if values within a given key are to be rendered as ``MultiStrOps``. If an override is used in an INI config file the set type is defined using the standard yaml construct of ""?"" as the item marker."," The ability to support MultiStrOps has been added to the config_template action plugin. This change updates the parser to use the ``set()`` type to determine if values within a given key are to be rendered as ``MultiStrOps``. If an override is used in an INI config file the set type is defined using the standard yaml construct of ""?"" as the item marker.fixes: - Resolves issue https://bugs.launchpad.net/openstack-ansible/+bug/1542513",6,9
openstack%2Fproject-config~master~I428d5d661475d4aaf33381563752f058f8461da3,openstack/project-config,master,I428d5d661475d4aaf33381563752f058f8461da3,Zuul: Create api-ref-jobs and api-guide-jobs templates,MERGED,2016-05-04 20:38:36.000000000,2016-05-05 13:52:33.000000000,2016-05-05 13:52:33.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}]","[{'number': 1, 'created': '2016-05-04 20:38:36.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a951fc2fa3866b2df01f9902b994fed02d6c1d77', 'message': 'Zuul: Create api-ref-jobs and api-guide-jobs templates\n\nCreate templates and use them.\n\nNote that we have already job-templates with the same name for jenkins.\n\nChange-Id: I428d5d661475d4aaf33381563752f058f8461da3\n'}]",0,312731,a951fc2fa3866b2df01f9902b994fed02d6c1d77,7,3,1,6547,,,0,"Zuul: Create api-ref-jobs and api-guide-jobs templates

Create templates and use them.

Note that we have already job-templates with the same name for jenkins.

Change-Id: I428d5d661475d4aaf33381563752f058f8461da3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/312731/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,a951fc2fa3866b2df01f9902b994fed02d6c1d77,api-ref-template, - name: api-ref-jobs check: - gate-{name}-api-ref gate: - gate-{name}-api-ref post: - '{name}-api-ref' - name: api-guide-jobs check: - gate-{name}-api-guide gate: - gate-{name}-api-guide post: - '{name}-api-guide' - name: api-guide-jobs - name: api-ref-jobs - name: api-guide-jobs - name: api-ref-jobs, - gate-barbican-api-guide - gate-barbican-api-guide post: - barbican-api-guide - gate-ironic-api-ref - gate-ironic-api-ref - ironic-api-ref - gate-nova-api-guide - gate-nova-api-ref - gate-nova-api-guide - gate-nova-api-ref - nova-api-guide - nova-api-ref,20,13
openstack%2Fkolla~stable%2Fliberty~Ieda226e652d67f5b5667112f4f2556f3171366d3,openstack/kolla,stable/liberty,Ieda226e652d67f5b5667112f4f2556f3171366d3,Remove dependencies on kazoo and friends,MERGED,2016-05-04 22:50:58.000000000,2016-05-05 13:51:24.000000000,2016-05-05 13:51:23.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 3098}]","[{'number': 1, 'created': '2016-05-04 22:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f3baa254cf6f8aab21d5351d880b8b84e88e093b', 'message': 'Remove dependencies on kazoo and friends\n\nSince kolla-mesos has been retired, there is no need in the code\nbase to keep the zookeeper implementation.  As a result, just remove\nit.  If we were to keep it we need virtualenvs for that part of the\ncode base which installs the python dependencies related to it\nfor from-binary installs.\n\nThis just simplifies the implementation tremendously and culls dead\ncode.\n\nCloses-Bug: #1577194\n(cherry picked from commit 025d57f82005a4ea92950f9b4d717c88f647d15f)\n\nConflicts:\n\tdocker/base/Dockerfile.j2\n\tdocker/kolla-toolbox/Dockerfile.j2\n\nChange-Id: Ieda226e652d67f5b5667112f4f2556f3171366d3\n'}, {'number': 2, 'created': '2016-05-04 22:56:42.000000000', 'files': ['docker/base/set_configs.py', 'docker/base/Dockerfile.j2', 'tests/test_set_config.py', 'docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/362fd8c67d59322d1aa487bddc30ea9019c9ba18', 'message': 'Remove dependencies on kazoo and friends\n\nSince kolla-mesos has been retired, there is no need in the code\nbase to keep the zookeeper implementation.  As a result, just remove\nit.  If we were to keep it we need virtualenvs for that part of the\ncode base which installs the python dependencies related to it\nfor from-binary installs.\n\nThis just simplifies the implementation tremendously and culls dead\ncode.\n\nCloses-Bug: #1577194\n(cherry picked from commit 025d57f82005a4ea92950f9b4d717c88f647d15f)\n\nConflicts:\n\tdocker/base/Dockerfile.j2\n\tdocker/kolla-toolbox/Dockerfile.j2\n\nChange-Id: Ieda226e652d67f5b5667112f4f2556f3171366d3\n'}]",0,312776,362fd8c67d59322d1aa487bddc30ea9019c9ba18,8,3,2,2834,,,0,"Remove dependencies on kazoo and friends

Since kolla-mesos has been retired, there is no need in the code
base to keep the zookeeper implementation.  As a result, just remove
it.  If we were to keep it we need virtualenvs for that part of the
code base which installs the python dependencies related to it
for from-binary installs.

This just simplifies the implementation tremendously and culls dead
code.

Closes-Bug: #1577194
(cherry picked from commit 025d57f82005a4ea92950f9b4d717c88f647d15f)

Conflicts:
	docker/base/Dockerfile.j2
	docker/kolla-toolbox/Dockerfile.j2

Change-Id: Ieda226e652d67f5b5667112f4f2556f3171366d3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/76/312776/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/set_configs.py', 'docker/base/Dockerfile.j2', 'tests/test_set_config.py', 'docker/kolla-toolbox/Dockerfile.j2']",4,f3baa254cf6f8aab21d5351d880b8b84e88e093b,bug/1577194, && yum clean all, && yum clean all \ && rpm -e --nodeps pytz python-babel,5,139
openstack%2Fcinder~master~I5b8d1411e0917ecb7e70eb5a6b139d75437ba032,openstack/cinder,master,I5b8d1411e0917ecb7e70eb5a6b139d75437ba032,Move and rename tempest_tests to cinder/tests/tempest,MERGED,2016-05-02 10:23:14.000000000,2016-05-05 13:49:35.000000000,2016-05-04 05:08:40.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 3153}, {'_account_id': 6637}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10115}, {'_account_id': 10384}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12393}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16308}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-05-02 10:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/091ed678e691f92146d295cfda759e1be43bac88', 'message': ""Also package tempest_tests\n\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nAs it is required to in\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 2, 'created': '2016-05-02 10:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/000fbe89e41ee9cecb298b9af96f142715dc2ff3', 'message': ""Also package tempest_tests\n\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 3, 'created': '2016-05-02 16:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08fd74eb5b1bcb6d9a2f664dc8be768275c2f016', 'message': ""rename tempest_tests to cinder_tempest_plugin\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 4, 'created': '2016-05-03 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c90c678cb72eefc7772b86e25e37fee9eeabe81', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 5, 'created': '2016-05-03 13:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2fd21492f517c687116a1224fb13e6d1ce263d91', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 6, 'created': '2016-05-03 14:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/331858a88b8945984ec7dbdb883effe29cbbce12', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 7, 'created': '2016-05-03 16:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20b76ca3be1b977bd71def85f43bf29a486c2330', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 8, 'created': '2016-05-03 16:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/da5ad3aa59323fd86b95eb5a44b3470d1a46efbd', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nWith the current setup.cfg, the folder tempest_tests is not\nbeing packaged, making it more difficult for package maintainer like\nmyself to run tempest tests. Please allow this change, so that I don't\nhave to carry such a patch in the RDO package.\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}, {'number': 9, 'created': '2016-05-03 17:56:57.000000000', 'files': ['cinder/tests/tempest/services/__init__.py', 'cinder/tests/tempest/api/__init__.py', 'cinder/tests/tempest/plugin.py', 'cinder/tests/tempest/README.rst', 'cinder/tests/tempest/scenario/__init__.py', 'tempest_tests/tests/__init__.py', 'cinder/tests/tempest/api/volume/__init__.py', 'cinder/tests/tempest/__init__.py', 'cinder/tests/tempest/api/volume/test_volume_placeholder.py', 'setup.cfg', 'cinder/tests/tempest/config.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/427f0f06b3dbccad13da3b941c74423b4a97ca92', 'message': ""Move and rename tempest_tests to cinder/tests/tempest\n\nTo avoid conflicts, it needs to be done and\nthe subdirs 'api' and 'scenario' directly under\nthe cinder/tests/tempest directory\n\nCloses-Bug: #1577016\n\nChange-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032\n""}]",1,311715,427f0f06b3dbccad13da3b941c74423b4a97ca92,181,46,9,12393,,,0,"Move and rename tempest_tests to cinder/tests/tempest

To avoid conflicts, it needs to be done and
the subdirs 'api' and 'scenario' directly under
the cinder/tests/tempest directory

Closes-Bug: #1577016

Change-Id: I5b8d1411e0917ecb7e70eb5a6b139d75437ba032
",git fetch https://review.opendev.org/openstack/cinder refs/changes/15/311715/8 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,091ed678e691f92146d295cfda759e1be43bac88,bug/1577016, tempest_tests,,1,0
openstack%2Fopenstack-ansible-os_nova~master~I0994dcd713391235946b4d9aa762b518bd0eddae,openstack/openstack-ansible-os_nova,master,I0994dcd713391235946b4d9aa762b518bd0eddae,Add dependencies for paramiko 2.0,MERGED,2016-05-03 07:56:04.000000000,2016-05-05 13:47:14.000000000,2016-05-04 18:33:35.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-03 07:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8cdf55cba153a8c353f0dab661fa0263eb799506', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I0994dcd713391235946b4d9aa762b518bd0eddae\n'}, {'number': 2, 'created': '2016-05-04 08:35:14.000000000', 'files': ['run_tests.sh', 'other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/85b92f8c4495a9827e21133b9006459ca7504734', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I0994dcd713391235946b4d9aa762b518bd0eddae\n'}]",0,311969,85b92f8c4495a9827e21133b9006459ca7504734,21,2,2,6816,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Change-Id: I0994dcd713391235946b4d9aa762b518bd0eddae
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/69/311969/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,8cdf55cba153a8c353f0dab661fa0263eb799506,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fproject-config~master~I564fd0375563eb9d336ef9545a183692504c664d,openstack/project-config,master,I564fd0375563eb9d336ef9545a183692504c664d,openstack-manuals has stable branch.,MERGED,2016-05-04 17:52:51.000000000,2016-05-05 13:45:41.000000000,2016-05-05 13:45:41.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 14643}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-04 17:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/036f3055a760c6575e06a077a545f1ee35ee4e05', 'message': ""Add stable/mitaka to #openstack-doc\n\nWe now have a mitaka branch, let's announce changes to the channel.\n\nChange-Id: I564fd0375563eb9d336ef9545a183692504c664d\n""}, {'number': 2, 'created': '2016-05-04 18:24:55.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9274bc787b504a5a4e16187fd797906289860d64', 'message': 'openstack-manuals has stable branch.\n\nWe now have a stable/mitaka branch, update config for it:\n* Add stable/mitaka to #openstack-doc\n* Add translation jobs for mitaka branch\n\nChange-Id: I564fd0375563eb9d336ef9545a183692504c664d\n'}]",0,312660,9274bc787b504a5a4e16187fd797906289860d64,13,7,2,6547,,,0,"openstack-manuals has stable branch.

We now have a stable/mitaka branch, update config for it:
* Add stable/mitaka to #openstack-doc
* Add translation jobs for mitaka branch

Change-Id: I564fd0375563eb9d336ef9545a183692504c664d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/312660/2 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,036f3055a760c6575e06a077a545f1ee35ee4e05,mitaka, - stable/mitaka,,1,0
openstack%2Fvitrage~master~Ibd8ad984d017991f9422952f76613f254a3b44ac,openstack/vitrage,master,Ibd8ad984d017991f9422952f76613f254a3b44ac,test only topology change to admin password,MERGED,2016-05-05 13:29:55.000000000,2016-05-05 13:43:21.000000000,2016-05-05 13:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-05-05 13:29:55.000000000', 'files': ['devstack/gate_hook.sh', 'devstack/post_test_hook.sh', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/3f5edb97d37202781219f2ea39f4f2444259f8e7', 'message': 'test only topology\nchange to admin password\n\nChange-Id: Ibd8ad984d017991f9422952f76613f254a3b44ac\n'}]",0,312946,3f5edb97d37202781219f2ea39f4f2444259f8e7,6,2,1,19134,,,0,"test only topology
change to admin password

Change-Id: Ibd8ad984d017991f9422952f76613f254a3b44ac
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/46/312946/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/gate_hook.sh', 'devstack/post_test_hook.sh', 'devstack/plugin.sh']",3,3f5edb97d37202781219f2ea39f4f2444259f8e7,eyalb/tempest, iniset $VITRAGE_CONF service_credentials password $ADMIN_PASSWORD, iniset $VITRAGE_CONF service_credentials password $SERVICE_PASSWORD,8,8
openstack%2Fopenstack-manuals~master~Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073,openstack/openstack-manuals,master,Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073,[ops-guide] Cleanup ops lay of land chapter,MERGED,2016-05-04 14:28:12.000000000,2016-05-05 13:39:30.000000000,2016-05-05 13:39:25.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 14643}, {'_account_id': 16237}, {'_account_id': 19779}, {'_account_id': 21242}]","[{'number': 1, 'created': '2016-05-04 14:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9639caecbdb045759a64989986c81730101f8480', 'message': '[ops-guide] Cleanup ops lay of land chapter\n\nChange-Id: Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073\nImplements: blueprint ops-guide-rst\n'}, {'number': 2, 'created': '2016-05-05 01:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/260c11b2b4cd2ee311bcb098b6c968a9a9d33ea2', 'message': '[ops-guide] Cleanup ops lay of land chapter\n\nChange-Id: Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073\nImplements: blueprint ops-guide-rst\n'}, {'number': 3, 'created': '2016-05-05 04:15:13.000000000', 'files': ['doc/ops-guide/source/ops_lay_of_the_land.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39a194dc2a307c847101a85e4eb75ea9a083f2ec', 'message': '[ops-guide] Cleanup ops lay of land chapter\n\nChange-Id: Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073\nImplements: blueprint ops-guide-rst\n'}]",1,312570,39a194dc2a307c847101a85e4eb75ea9a083f2ec,17,8,3,10497,,,0,"[ops-guide] Cleanup ops lay of land chapter

Change-Id: Ie0691fdb4ba1ae1092c79ea1c32cb9e1d4ef5073
Implements: blueprint ops-guide-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/312570/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_lay_of_the_land.rst'],1,9639caecbdb045759a64989986c81730101f8480,bp/ops-guide-rst," this file.make by passing the :option:`--debug` flag to them For example:credentials to get an :term:`authentication token`.#. Look at your OpenStack service :term:`catalog`:To see a list of projects that have been added to the cloud, run:To see a list of running instances, run:information. From here, you can use the `OpenStack Administrator"," this file.passwordssecurity issues passwordsmake by passing the :option:`--debug` flag to them.API (application programming interface) API calls, inspectingcommand-line tools inspecting API calls For example:credentials to get an authentication token.#. Look at your OpenStack service catalog:To see a list of projects that have been added to the cloud,projects obtaining list of currentuser management listing usersworking environment users and projects run:To see a list of running instances,instances list of runningworking environment running instances run:information. From here, you can use the `Administrator",7,12
openstack%2Fopenstack-doc-tools~master~Iadb4d8609dffe9e3e449b6fe09db939ea7fca943,openstack/openstack-doc-tools,master,Iadb4d8609dffe9e3e449b6fe09db939ea7fca943,Remove DocBook XML translation support,MERGED,2016-05-02 10:58:45.000000000,2016-05-05 13:38:40.000000000,2016-05-05 13:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-02 10:58:45.000000000', 'files': ['os_doc_tools/handle_pot.py', 'setup.cfg', 'bin/doc-tools-check-languages'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/992fb6cdb492d6b817845a718fbdb998d8415c8a', 'message': 'Remove DocBook XML translation support\n\nRemove commands and scripting for translation of DocBook XML.\n\nimplements bp docbook-removal\n\nChange-Id: Iadb4d8609dffe9e3e449b6fe09db939ea7fca943\n'}]",0,311716,992fb6cdb492d6b817845a718fbdb998d8415c8a,9,5,1,6547,,,0,"Remove DocBook XML translation support

Remove commands and scripting for translation of DocBook XML.

implements bp docbook-removal

Change-Id: Iadb4d8609dffe9e3e449b6fe09db939ea7fca943
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/16/311716/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_doc_tools/handle_pot.py', 'setup.cfg', 'bin/doc-tools-check-languages']",3,992fb6cdb492d6b817845a718fbdb998d8415c8a,bp/docbook-removal,,"function setup_directories { language=$1 for directory in ${DIRECTORIES[""$language""]} ; do echo "" $directory"" openstack-generate-docbook -l $language -b $directory -r $DOC_DIR done } function setup_language { language=$1 echo ""Setting up files for $language"" echo ""======================="" echo "" Directories:"" setup_directories $language if [ -n ""$POM_FILE"" ] ; then cp $POM_FILE generated/$language/pom.xml fi } BUILD_XML=0 args+=(""--only-book $book"") BUILD_XML=1 if [ ""$BUILD_XML"" -eq ""1"" ] ; then setup_language $language openstack-doc-test ${args[@]} if [[ $? -eq 0 ]] ; then echo ""... succeeded"" else echo ""... failed"" BUILD_FAIL=1 fi fi",0,318
openstack%2Fapi-site~master~I42d5451300f95774a3ec4df66bc95cb36795844d,openstack/api-site,master,I42d5451300f95774a3ec4df66bc95cb36795844d,Adds migrated RST + YAML files from WADL,MERGED,2016-05-01 04:41:35.000000000,2016-05-05 13:36:57.000000000,2016-05-05 13:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 15293}, {'_account_id': 17207}]","[{'number': 1, 'created': '2016-05-01 04:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d9948b7ad054512779f917f70a164eeb17731679', 'message': 'Adds migrated RST + YAML files from WADL\n\nContains .inc files which have all the contents of the .rst files\nbut are grouped together for easier editing.\nContains parameters.yaml, which has all parameters in one file.\nContains separated-out YAML files that are pointed to from the\n.inc and .rst files.\nContains request and response samples (JSON and XML) that are\npointed to from the .inc and .rst files.\n\nChange-Id: I42d5451300f95774a3ec4df66bc95cb36795844d\n'}, {'number': 2, 'created': '2016-05-01 09:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/b1989f5b746f3d13cdbc18a4ec5411dbca78ad92', 'message': 'Adds migrated RST + YAML files from WADL\n\nContains .inc files which have all the contents of the .rst files\nbut are grouped together for easier editing.\nContains parameters.yaml, which has all parameters in one file.\nContains separated-out YAML files that are pointed to from the\n.inc and .rst files.\nContains request and response samples (JSON and XML) that are\npointed to from the .inc and .rst files.\n\nChange-Id: I42d5451300f95774a3ec4df66bc95cb36795844d\n'}, {'number': 3, 'created': '2016-05-02 18:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/0bb26efc4f923479cb2680de3f7f389e5cc83204', 'message': 'Adds migrated RST + YAML files from WADL\n\nContains .inc files which have all the contents of the .rst files\nbut are grouped together for easier editing.\nContains parameters.yaml, which has all parameters in one file.\nContains request and response samples (JSON and XML) that are\npointed to from the .inc files.\n\nChange-Id: I42d5451300f95774a3ec4df66bc95cb36795844d\n'}, {'number': 4, 'created': '2016-05-02 22:43:03.000000000', 'files': ['api-ref/source/blockstorage/v2/samples/volumes/volume-replica-promote-request.json', 'api-ref/source/identity/v3/samples/OS-KDS/group-key-show-response.json', 'api-ref/source/clustering/v1/samples/profile-update-request.json', 'api-ref/source/telemetry/v2/samples/capabilities-list-response.xml', 'api-ref/source/share/v1/samples/manila-share-instance-actions-force-delete-request.json', 'api-ref/source/blockstorage/v2/capabilities-v2.inc', 'api-ref/source/share/v1/samples/manila-share-update-metadata-response.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-status-tree.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-create-response.json', 'api-ref/source/share/v1/samples/manila-share-set-metadata-request.json', 'api-ref/source/identity/v2/samples/admin/endpoints-list-response.json', 'api-ref/source/image/v2/samples/image-member-update-request.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-groups-list-response.json', 'api-ref/source/orchestration/v1/samples/deployment-update-request.json', 'api-ref/source/identity/v3/domains.inc', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-delete-request-json-http.txt', 'api-ref/source/blockstorage/v2/parameters.yaml', 'api-ref/source/share/v1/samples/manila-availability-zones-list-response.json', 'api-ref/source/orchestration/v1/samples/template-validate-request.json', 'api-ref/source/identity/v3-ext/identity_v3_OS-ENDPOINT-POLICY-ext.inc', 'api-ref/source/share/v1/share-limits.inc', 'api-ref/source/data-processing/v1.1/samples/image-registry/images-list-response.json', 'api-ref/source/identity/v3/samples/admin/projects-list-response.json', 'api-ref/source/networking/v2/samples/service-type-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-response.xml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-show-response.json', 'api-ref/source/share/v1/samples/manila-extensions-list-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-associate-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-update-request.json', 'api-ref/source/image/v1/shared-images.inc', 'api-ref/source/share/v1/samples/manila-pools-list-detailed-response.json', 'api-ref/source/database/v1/samples/db-list-cfg-groups-request-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-create-request.json', 'api-ref/source/image/v2/samples/image-versions-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-show-response.xml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-request.xml', 'api-ref/source/orchestration/v1/samples/deployment-create-response.json', 'api-ref/source/identity/v2/samples/admin/extension-show-response.json', 'api-ref/source/share/v1/samples/manila-share-type-revoke-access-request.json', 'api-ref/source/clustering/v1/samples/cluster-scale-in-nodes-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-request.json', 'api-ref/source/database/v1/samples/db-list-databases-response.json', 'api-ref/source/networking/v2/samples/networks/version-show-response.json', 'api-ref/source/networking/v2/samples/networks/network-provider-create-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-create-request.json', 'api-ref/source/telemetry/v2/samples/sample-create-request.json', 'api-ref/source/blockstorage/v2/quota-sets.inc', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-create-response.json', 'api-ref/source/identity/v3/samples/admin/service-create-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-detailed-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos_show_response.xml', 'api-ref/source/identity/v3/samples/admin/domain-user-roles-list-response.json', 'api-ref/source/identity/v2-ext/ksadm-admin.inc', 'api-ref/source/database/v1/samples/db-instance-resize-instance-request-json-http.txt', 'api-ref/source/objectstorage/v1/parameters.yaml', 'api-ref/source/database/v1/samples/db-list-databases-request-json-http.txt', 'api-ref/source/networking/v2/samples/subnets/subnets-create-bulk-request.json', 'api-ref/source/networking/v2/samples/ports/port-update-request.json', 'api-ref/source/clustering/v1/samples/nodes-list-response.json', 'api-ref/source/orchestration/v1/software-config.inc', 'api-ref/source/networking/v2-ext/subnetpools-ext.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-request.xml', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplate-create-request.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-show-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-grant-access-response.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-show-response.json', 'api-ref/source/image/v2/samples/image-member-create-response.json', 'api-ref/source/networking/v2/samples/lbaas/member-update-request.json', 'api-ref/source/database/v1/samples/db-create-instance-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-user-name-unscoped-request.json', 'api-ref/source/blockstorage/v2/volumes-v2-volumes.inc', 'api-ref/source/database/v1/samples/db-delete-config-group-request-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-create-response.json', 'api-ref/source/share/v1/samples/manila-security-services-list-detailed-response.json', 'api-ref/source/clustering/v1/clustering-v1-policies.inc', 'api-ref/source/networking/v2/networks.inc', 'api-ref/source/database/v1/samples/db-config-group-instances-request-json-http.txt', 'api-ref/source/baremetal/v1/baremetal-api-v1-drivers.inc', 'api-ref/source/identity/v3/samples/admin/groups-list-response.json', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-show-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-delete-response-json-http.txt', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-update-response.json', 'api-ref/source/identity/v3/samples/admin/project-update-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-update-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-scoped-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-create-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-show-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-update-request.json', 'api-ref/source/image/v2/samples/schemas-image-members-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-types-list-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-force-delete-request.json', 'api-ref/source/database/v1/samples/db-instance-restart-request-json-http.txt', 'api-ref/source/share/v1/samples/manila-share-network-remove-security-service-response.json', 'api-ref/source/orchestration/v1/samples/resource-metadata-response.json', 'api-ref/source/blockstorage/v2/volumes-v2-extensions.inc', 'api-ref/source/networking/v2/samples/networks/network-update-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rules-list-response.json', 'api-ref/source/blockstorage/v1/volumes-v1-versions.inc', 'api-ref/source/database/v1/api-versions.inc', 'api-ref/source/image/v2/samples/schema-metadef-resource-type-associations-list-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-delete-response-json-http.txt', 'api-ref/source/baremetal/v1/samples/drivers-list-response.json', 'api-ref/source/database/v1/samples/db-create-config-grp-response-json-http.txt', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-response.json', 'api-ref/source/database/v1/samples/db-patch-config-grp-request.json', 'api-ref/source/data-processing/v1.1/plugins.inc', 'api-ref/source/networking/v2/samples/ports/ports-bulk-create-request.json', 'api-ref/source/share/v1/share-share-instance-export-locations.inc', 'api-ref/source/share/v1/samples/manila-snapshot-create-response.json', 'api-ref/source/identity/v3/samples/admin/role-assignments-list-response.json', 'api-ref/source/data-processing/v1.1/jobbinary-internals.inc', 'api-ref/source/blockstorage/v1/samples/volumes/volumes-list-response.json', 'api-ref/source/image/v2/image-tags.inc', 'api-ref/source/orchestration/v1/samples/events-list-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-update-response.json', 'api-ref/source/telemetry/v2/events.inc', 'api-ref/source/identity/v3/samples/admin/domain-config-update-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/update-response.json', 'api-ref/source/orchestration/v1/samples/resource-type-template-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-accept-response.json', 'api-ref/source/identity/v3/policies.inc', 'api-ref/source/networking/v2/samples/lbaas/members-list-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-update-response.json', 'api-ref/source/clustering/v1/samples/profiles-list-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-delete-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-response.json', 'api-ref/source/image/v2/samples/metadef-property-update-request.json', 'api-ref/source/database/v1/samples/db-list-parameters-request-json-http.txt', 'api-ref/source/database/v1/samples/db-config-group-instances-response.json', 'api-ref/source/identity/v3/samples/admin/project-show-response.json', 'api-ref/source/blockstorage/v2/volume-type-access.inc', 'api-ref/source/database/v1/samples/db-version-response.json', 'api-ref/source/database/v1/samples/db-instances-index-request-json-http.txt', 'api-ref/source/clustering/v1/samples/node-recover-request.json', 'api-ref/source/image/v2/samples/schema-metadef-tag-show-response.json', 'api-ref/source/share/v1/samples/manila-security-service-update-response.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-create-request.json', 'api-ref/source/database/v1/samples/db-delete-root-response-json-http.txt', 'api-ref/source/networking/v2/samples/qos/policy-create-request.json', 'api-ref/source/database/v1/samples/db-flavors-request-json-http.txt', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-show-response.json', 'api-ref/source/clustering/v1/samples/policy-type-show-response.json', 'api-ref/source/database/v1/samples/db-attach-config-grp-request.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-create-response.json', 'api-ref/source/networking/v2/samples/routers/router-remove-interface-response.json', 'api-ref/source/share/v1/consistency-group-snapshots.inc', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-response.xml', 'api-ref/source/image/v2/images-images-v2.inc', 'api-ref/source/networking/v2/samples/lbaas/vip-create-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-show-response.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/role-assignments-list-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-import-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-replica-reenable-request.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-update-request.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/member-create-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-create-response.json', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-create-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profiles-list-response.json', 'api-ref/source/share/v1/samples/manila-share-networks-list-detailed-response.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-create-response.json', 'api-ref/source/share/v1/samples/manila-quota-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/role-create-request.json', 'api-ref/source/telemetry/v2/samples/alarm-show-response.json', 'api-ref/source/clustering/v1/clustering-v1-clusters.inc', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-request.json', 'api-ref/source/clustering/v1/samples/build-show-response.json', 'api-ref/source/database/v1/samples/db-patch-config-grp-response-json-http.txt', 'api-ref/source/networking/v2-ext/metering-labels-ext.inc', 'api-ref/source/clustering/v1/clustering-v1-profiles.inc', 'api-ref/source/identity/v2/samples/admin/versions-list-response.json', 'api-ref/source/telemetry/v2/samples/event-show-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-hdfs-response.json', 'api-ref/source/identity/v3/samples/admin/users-list-response.json', 'api-ref/source/image/v2/samples/schema-metadef-property-show-response.json', 'api-ref/source/telemetry/v2/resources.inc', 'api-ref/source/identity/v3/samples/admin/credential-update-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-show-response.json', 'api-ref/source/database/v1/samples/db-instance-eject-replica-request-json-http.txt', 'api-ref/source/blockstorage/v2/qos-specs-v2-qos-specs.inc', 'api-ref/source/identity/v3/samples/admin/credential-show-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-create-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-show-response.xml', 'api-ref/source/networking/v2/samples/qos/policy-create-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-response.xml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-response.xml', 'api-ref/source/identity/v2/samples/admin/user-update-response.json', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-create-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-unmanage-request.json', 'api-ref/source/database/v1/samples/db-list-users-response.json', 'api-ref/source/baremetal/v1/samples/nodes-list-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-delete-request-json-http.txt', 'api-ref/source/telemetry/v2/samples.inc', 'api-ref/source/database/v1/samples/db-create-databases-response-json-http.txt', 'api-ref/source/identity/v2/samples/OS-KSADM/tenantwithoutid-create-request.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-unset-request.json', 'api-ref/source/networking/v2-ext/networks-vlan-transparency-ext.inc', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-response.xml', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplate-show-response.json', 'api-ref/source/share/v1/pools.inc', 'api-ref/source/database/v1/samples/db-instance-restart-request.json', 'api-ref/source/telemetry/v2/samples/sample-show-response.json', 'api-ref/source/orchestration/v1/samples/deployment-metadata-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplateWithOnlyId-create-request.json', 'api-ref/source/image/v2/samples/metadef-tag-update-request.json', 'api-ref/source/data-processing/v1.1/samples/jobs/jobs-list-response.json', 'api-ref/source/share/v1/samples/manila-share-show-metadata-response.json', 'api-ref/source/image/v2/samples/image-member-create-request.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-delete-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-create-response.json', 'api-ref/source/image/v2/samples/image-members-list-response.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-execute-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-create-request.json', 'api-ref/source/networking/v2/samples/routers/router-show-response.json', 'api-ref/source/identity/v3/samples/admin/region-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSEC2/ec2Credentials-show-response.json', 'api-ref/source/identity/v3/samples/admin/policy-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-create-response.json', 'api-ref/source/data-processing/v1.1/job-executions.inc', 'api-ref/source/orchestration/v1/samples/event-show-response.json', 'api-ref/source/clustering/v1/samples/node-show-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rules-list-request-json-http.txt', 'api-ref/source/database/v1/samples/db-update-config-grp-request.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-update-request.json', 'api-ref/source/database/v1/samples/db-list-cfg-groups-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-request-json-http.txt', 'api-ref/source/image/v2/samples/image-create-response.json', 'api-ref/source/networking/v2/samples/networks/versions-list-response.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-register-request.json', 'api-ref/source/networking/v2-ext/lbaas.inc', 'api-ref/source/orchestration/v1/samples/deployments-list-response.json', 'api-ref/source/baremetal/v1/baremetal-api-v1-nodes.inc', 'api-ref/source/database/v1/samples/db-versions-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-details-response.json', 'api-ref/source/objectstorage/v1/samples/goodbyeworld.txt', 'api-ref/source/baremetal/v1/baremetal-api-v1-chassis.inc', 'api-ref/source/database/v1/samples/db-instance-promote-replica-request.json', 'api-ref/source/identity/v3/samples/admin/domain-show-response.json', 'api-ref/source/networking/v2/ports.inc', 'api-ref/source/orchestration/v1/samples/stack-show-output-response.json', 'api-ref/source/database/v1/samples/db-delete-databases-response-json-http.txt', 'api-ref/source/image/v2/samples/schema-image-show-response.json', 'api-ref/source/networking/v2/samples/tag/tag-update-response.json', 'api-ref/source/objectstorage/v1/samples/objects-list-response.json', 'api-ref/source/database/v1/samples/db-delete-users-request-json-http.txt', 'api-ref/source/share/v1/samples/manila-share-actions-list-access-rules-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-show-response.json', 'api-ref/source/identity/v2-admin/admin-users.inc', 'api-ref/source/orchestration/v1/stacks.inc', 'api-ref/source/share/v1/samples/manila-snapshots-list-response.json', 'api-ref/source/identity/v2/identity-auth.inc', 'api-ref/source/image/v2/samples/metadef-property-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitors-list-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-response.xml', 'api-ref/source/networking/v2/samples/quotas/quotas-list-for-tenant-response.json', 'api-ref/source/identity/v3/samples/admin/service-create-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/show-response.json', 'api-ref/source/identity/v2/samples/client/authenticate-response.json', 'api-ref/source/share/v1/share-versions.inc', 'api-ref/source/database/v1/samples/db-attach-config-grp-response-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-show-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-token-show-response.json', 'api-ref/source/networking/v2/samples/ports/ports-list-response.json', 'api-ref/source/identity/v2-ext/kscatalog.inc', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-detailed-response.xml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/authorize-update-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-create-request.json', 'api-ref/source/clustering/v1/samples/profile-show-response.json', 'api-ref/source/orchestration/v1/samples/config-create-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-request.xml', 'api-ref/source/database/v1/samples/db-attach-config-grp-request-json-http.txt', 'api-ref/source/clustering/v1/samples/receiver-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-show-response.json', 'api-ref/source/image/v1/parameters.yaml', 'api-ref/source/identity/v3/samples/admin/policy-create-request.json', 'api-ref/source/blockstorage/v2/samples/limits/limits-show-response.xml', 'api-ref/source/identity/v2-ext/ksec2-admin.inc', 'api-ref/source/identity/v3/samples/admin/group-create-response.json', 'api-ref/source/image/v2/samples/metadef-namespaces-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-image-metadata-unset-request.json', 'api-ref/source/identity/v2/samples/client/authenticate-credentials-request.json', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithenabledonly-show-response.json', 'api-ref/source/share/v1/samples/manila-share-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-manage/volume-manage-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-create-response.json', 'api-ref/source/database/v1/samples/db-versions-request-json-http.txt', 'api-ref/source/identity/v3/samples/admin/endpoint-update-response.json', 'api-ref/source/database/v1/samples/db-version-request-json-http.txt', 'api-ref/source/identity/v2-ext/parameters.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-response.json', 'api-ref/source/image/v2/samples/schemas-images-list-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-update-request.json', 'api-ref/source/identity/v3/samples/admin/role-create-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-list-access-rules-response.json', 'api-ref/source/blockstorage/v2/volumes-v2-versions.inc', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-request.xml', 'api-ref/source/clustering/v1/samples/node-update-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backups-list-detailed-response.json', 'api-ref/source/database/v1/samples/db-instance-resize-flavor-request.json', 'api-ref/source/clustering/v1/samples/cluster-policy-attach-request.json', 'api-ref/source/telemetry/v2/samples/alarms-list-response.xml', 'api-ref/source/share/v1/samples/manila-pools-list-response.json', 'api-ref/source/identity/v3/samples/admin/credential-update-response.json', 'api-ref/source/share/v1/samples/manila-share-network-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-request.xml', 'api-ref/source/share/v1/share-share-servers.inc', 'api-ref/source/networking/v2/samples/routers/router-add-interface-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/update-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-show-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-project-scoped-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-defaults-response.xml', 'api-ref/source/clustering/v1/samples/node-create-request.json', 'api-ref/source/database/v1/samples/db-detach-config-grp-request-json-http.txt', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-create-request.json', 'api-ref/source/networking/v2/samples/quotas/quotas-update-response.json', 'api-ref/source/clustering/v1/samples/cluster-recover-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-response.json', 'api-ref/source/database/v1/samples/db-show-parameter-details-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-add-response.json', 'api-ref/source/image/v2/samples/image-details-deactivate-response.json', 'api-ref/source/identity/v3-ext/trust.inc', 'api-ref/source/identity/v3/samples/admin/service-show-response.json', 'api-ref/source/objectstorage/v1/storage-object-services.inc', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-detailed-response.xml', 'api-ref/source/image/v2/samples/metadef-tag-update-response.json', 'api-ref/source/data-processing/v1.1/jobbinaries.inc', 'api-ref/source/database/v1/samples/db-create-instance-response-json-http.txt', 'api-ref/source/database/v1/samples/db-config-group-details-response.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-templates-list-response.json', 'api-ref/source/database/v1/samples/db-detach-config-grp-request.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-swift-request.json', 'api-ref/source/networking/v2/samples/lbaas/listener-create-response.json', 'api-ref/source/clustering/v1/samples/policy-show-response.json', 'api-ref/source/identity/v2-admin/parameters.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewalls-list-response.json', 'api-ref/source/clustering/v1/samples/policy-create-request.json', 'api-ref/source/share/v1/samples/manila-share-actions-grant-access-request.json', 'api-ref/source/identity/v2/samples/admin/authenticate-token-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-request.json', 'api-ref/source/share/v1/samples/manila-share-update-request.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-from-src-request.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-update-response.json', 'api-ref/source/image/v1/samples/images-list-details-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-update-request.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-request.json', 'api-ref/source/share/v1/samples/manila-share-server-show-response.json', 'api-ref/source/database/v1/samples/db-list-datastore-versions.json', 'api-ref/source/share/v1/samples/manila-share-type-create-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-list-response.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-update-request.json', 'api-ref/source/blockstorage/v2/samples/capabilities/backend-capabilities-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-response.xml', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-show-response.json', 'api-ref/source/data-processing/v1.1/job-types.inc', 'api-ref/source/share/v1/samples/manila-share-types-extra-specs-list-response.json', 'api-ref/source/database/v1/samples/db-config-group-instances-response-json-http.txt', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-update-request.json', 'api-ref/source/orchestration/v1/samples/resource-show-response.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-create-request.json', 'api-ref/source/orchestration/v1/samples/config-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/listener-create-request.json', 'api-ref/source/identity/v3/samples/admin/identity-version-response.json', 'api-ref/source/clustering/v1/samples/policy-update-response.json', 'api-ref/source/networking/v2-ext/vpnaas.inc', 'api-ref/source/identity/v3/samples/admin/project-user-roles-list-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-action-suspend-request.json', 'api-ref/source/database/v1/samples/db-flavors-by-id-response.json', 'api-ref/source/identity/v3/samples/admin/credential-create-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-response.xml', 'api-ref/source/database/v1/samples/db-create-databases-request-json-http.txt', 'api-ref/source/networking/v2-ext/extensions.inc', 'api-ref/source/identity/v3/samples/OS-INHERIT/user-roles-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-types-list-response.xml', 'api-ref/source/share/v1/share-share-instances.inc', 'api-ref/source/clustering/v1/samples/receiver-show-response.json', 'api-ref/source/telemetry/v2/samples/samples-list-response.json', 'api-ref/source/orchestration/v1/samples/stack-show-snapshot-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-revoke-access-request.json', 'api-ref/source/identity/v2/samples/admin/extensions-list-response.json', 'api-ref/source/share/v1/samples/manila-share-manage-response.json', 'api-ref/source/image/v2/samples/metadef-resource-types-list-response.json', 'api-ref/source/blockstorage/v1/volumes-v1-volumes.inc', 'api-ref/source/orchestration/v1/samples/stack-outputs-list-response.json', 'api-ref/source/database/v1/samples/db-list-parameters-response.json', 'api-ref/source/image/v2/samples/metadef-tag-create-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-show-response.xml', 'api-ref/source/database/v1/samples/db-instance-promote-replica-request-json-http.txt', 'api-ref/source/clustering/v1/samples/senlin-versions-list-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-response.json', 'api-ref/source/share/v1/samples/manila-share-instance-actions-reset-state-request.json', 'api-ref/source/networking/v2/samples/ports/port-bind-create-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-delete-request.json', 'api-ref/source/identity/v2/samples/admin/authenticate-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/extensions-list-response.xml', 'api-ref/source/networking/v2/samples/flavors/service-profile-show-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-actions-unmanage-request.json', 'api-ref/source/identity/v2/samples/OS-KSS3/s3Credentials-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-update-request.json', 'api-ref/source/clustering/v1/samples/cluster-update-request.json', 'api-ref/source/identity/v3/samples/admin/domain-update-request.json', 'api-ref/source/identity/v3/samples/admin/role-create-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-request.json', 'api-ref/source/identity/v2/versions.inc', 'api-ref/source/database/v1/samples/db-update-config-grp-request-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/job-executions/list-response.json', 'api-ref/source/identity/v2-admin/admin-tenants.inc', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-extend-request.json', 'api-ref/source/database/v1/samples/db-list-datastore-versions-request-json-http.txt', 'api-ref/source/orchestration/v1/samples/template-show-response.json', 'api-ref/source/data-processing/v1.1/samples/event-log/cluster-progress-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-create-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-create-request.json', 'api-ref/source/baremetal/v1/samples/chassis-show-response.json', 'api-ref/source/database/v1/samples/db-instance-restart-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-scale-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-request.xml', 'api-ref/source/share/v1/samples/manila-share-manage-request.json', 'api-ref/source/clustering/v1/samples/cluster-create-response.json', 'api-ref/source/identity/v3/samples/OS-TRUST/trust-create-response.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-execute-request.json', 'api-ref/source/image/v1/samples/image-members-add-request.json', 'api-ref/source/networking/v2-ext/security-groups.inc', 'api-ref/source/networking/v2/samples/networks/networks-multi-list-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-show-response.json', 'api-ref/source/orchestration/v1/samples/resource-types-list-response.json', 'api-ref/source/clustering/v1/samples/events-list-response.json', 'api-ref/source/database/v1/samples/db-delete-users-response-json-http.txt', 'api-ref/source/image/v2/samples/metadef-namespace-update-response.json', 'api-ref/source/objectstorage/v1/samples/helloworld.txt', 'api-ref/source/share/v1/samples/manila-quota-update-request.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-show-response.json', 'api-ref/source/share/v1/samples/manila-share-networks-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/version-show-response.xml', 'api-ref/source/clustering/v1/clustering-v1-policy_types.inc', 'api-ref/source/blockstorage/v2/samples/user-quotas-show-response.xml', 'api-ref/source/share/v1/samples/manila-share-network-show-response.json', 'api-ref/source/blockstorage/v2/samples/host-attach-request.json', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-create-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-detailed-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-request.xml', 'api-ref/source/image/v1/samples/image-memberships-list-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-update-response.json', 'api-ref/source/orchestration/v1/heat-versions.inc', 'api-ref/source/blockstorage/v2/samples/volumes/version-show-response.json', 'api-ref/source/identity/v3/samples/admin/role-assignments-effective-list-response.json', 'api-ref/source/networking/v2/samples/ports/port-create-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshots-list-response.json', 'api-ref/source/blockstorage/v2/ext-backups.inc', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-image-metadata-set-request.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-response.xml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-show-response.json', 'api-ref/source/database/v1/samples/db-detach-replica-request-json-http.txt', 'api-ref/source/clustering/v1/samples/profile-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-request.json', 'api-ref/source/image/v2/samples/metadef-resource-type-assoc-create-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-force-delete-request.json', 'api-ref/source/image/v2/samples/schema-metadef-properties-list-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/request-token-create-response.txt', 'api-ref/source/identity/v2-admin/admin-tokens.inc', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-response.txt', 'api-ref/source/blockstorage/v2/samples/os-vol-image-meta/image-metadata-show-request.json', 'api-ref/source/clustering/v1/clustering-v1-events.inc', 'api-ref/source/share/v1/samples/manila-snapshot-actions-force-delete-request.json', 'api-ref/source/clustering/v1/samples/receivers-list-response.json', 'api-ref/source/share/v1/samples/manila-service-disable-request.json', 'api-ref/source/image/v2/samples/metadef-tags-list-response.json', 'api-ref/source/baremetal/v1/parameters.yaml', 'api-ref/source/clustering/v1/samples/cluster-resize-request.json', 'api-ref/source/identity/v3/samples/admin/policy-show-response.json', 'api-ref/source/database/v1/database-instance-actions.inc', 'api-ref/source/telemetry/v2/samples/capabilities-list-response.json', 'api-ref/source/database/v1/samples/db-instances-index-response.json', 'api-ref/source/database/v1/samples/db-list-parameters-response-json-http.txt', 'api-ref/source/clustering/v1/samples/receiver-create-response.json', 'api-ref/source/image/v2/samples/metadef-object-update-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/version-v2-show-response.json', 'api-ref/source/identity/v3/samples/admin/region-create-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-export-response.json', 'api-ref/source/identity/v3/samples/admin/region-update-response.json', 'api-ref/source/networking/v2-ext/networking-ip-availability-ext.inc', 'api-ref/source/networking/v2/samples/routers/floatingip-disassociate-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-force-detach-request.json', 'api-ref/source/database/v1/configurations.inc', 'api-ref/source/clustering/v1/samples/profile-type-show-response.json', 'api-ref/source/identity/v3/samples/admin/endpoint-create-response.json', 'api-ref/source/blockstorage/v2/consistencygroups-v2.inc', 'api-ref/source/telemetry/v2/samples/samples-list-response.xml', 'api-ref/source/orchestration/v1/samples/stack-find-response.json', 'api-ref/source/image/v2/metadef-resourcetype.inc', 'api-ref/source/share/v1/samples/manila-share-types-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-show-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshots-list-response.xml', 'api-ref/source/identity/v2/samples/OS-KSVALIDATE/token-validate-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volumes-list-response.xml', 'api-ref/source/identity/v3/samples/admin/user-groups-list-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-show-request-json-http.txt', 'api-ref/source/database/v1/samples/db-instance-promote-replica-response-json-http.txt', 'api-ref/source/share/v1/share-type.inc', 'api-ref/source/identity/v2/samples/OS-KSEC2/ec2Credentials-create-request.json', 'api-ref/source/identity/v3/samples/admin/group-update-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-scoped-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpools-list-response.json', 'api-ref/source/objectstorage/v1/storage-account-services.inc', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-create-response.json', 'api-ref/source/database/v1/samples/db-patch-config-grp-request-json-http.txt', 'api-ref/source/share/v1/share-os-share-manage.inc', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-token-create-response.txt', 'api-ref/source/share/v1/samples/manila-share-actions-extend-request.json', 'api-ref/source/networking/v2/samples/networks/network-show-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-associate-request.json', 'api-ref/source/telemetry/v2/alarms.inc', 'api-ref/source/identity/v3-ext/kds.inc', 'api-ref/source/share/v1/samples/manila-share-create-request.json', 'api-ref/source/database/v1/parameters.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-update-request.json', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-response-json-http.txt', 'api-ref/source/clustering/v1/samples/policy-update-request.json', 'api-ref/source/share/v1/samples/manila-snapshot-manage-response.json', 'api-ref/source/telemetry/v2/samples/resource-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-create-request.json', 'api-ref/source/clustering/v1/samples/action-show-response.json', 'api-ref/source/database/v1/samples/db-list-databases-response-json-http.txt', 'api-ref/source/orchestration/v1/samples/template-versions-response.json', 'api-ref/source/image/v2/samples/image-show-response.json', 'api-ref/source/orchestration/v1/samples/deployment-create-request.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-create-response.json', 'api-ref/source/clustering/v1/samples/cluster-policies-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-response.xml', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-detailed-response.xml', 'api-ref/source/share/v1/share-security-services.inc', 'api-ref/source/identity/v3/samples/admin/user-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-list-response.json', 'api-ref/source/database/v1/samples/db-show-parameter-details.json', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-response.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-add-request.json', 'api-ref/source/database/v1/samples/db-detach-replica-request.json', 'api-ref/source/blockstorage/v1/parameters.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/role-show-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-update-request.json', 'api-ref/source/image/v2/samples/schema-image-member-show-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/services-list-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-show-response.json', 'api-ref/source/image/v2/samples/metadef-property-create-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-delete-response-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-create-request.json', 'api-ref/source/identity/v3-ext/inherit.inc', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-response.xml', 'api-ref/source/database/v1/datastores.inc', 'api-ref/source/blockstorage/v2/os-vol-transfer-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/show-response.json', 'api-ref/source/orchestration/v1/samples/stack-snapshots-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-response-json.txt', 'api-ref/source/image/v2/samples/image-member-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfers-list-detailed-response.json', 'api-ref/source/image/v1/versions.inc', 'api-ref/source/image/v2/samples/task-show-response.json', 'api-ref/source/networking/v2-ext/network-provider.inc', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-action-check-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-create-request.json', 'api-ref/source/identity/v3/samples/admin/auth-password-explicit-unscoped-request.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-create-request.json', 'api-ref/source/database/v1/database-instances.inc', 'api-ref/source/identity/v2/samples/admin/version-show-response.json', 'api-ref/source/share/v1/samples/manila-share-create-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-create-request.json', 'api-ref/source/networking/v2-ext/security_group_rules.inc', 'api-ref/source/share/v1/samples/manila-share-network-add-security-service-request.json', 'api-ref/source/identity/v3/regions-v3.inc', 'api-ref/source/database/v1/samples/db-create-instance-request-json-http.txt', 'api-ref/source/networking/v2/samples/qos/rule_types-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-create-request.xml', 'api-ref/source/telemetry/v2/samples/meters-list-response.json', 'api-ref/source/identity/v3/samples/admin/token-validate-request.txt', 'api-ref/source/identity/v3/samples/admin/project-group-roles-list-response.json', 'api-ref/source/identity/v3/samples/admin/domain-group-update-request.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-create-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-show-response.xml', 'api-ref/source/identity/v2/samples/admin/user-show-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-create-response.json', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-update-response.json', 'api-ref/source/networking/v2/samples/networks/networks-bulk-create-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/clusters-list-response.json', 'api-ref/source/orchestration/v1/samples/config-show-response.json', 'api-ref/source/networking/v2/samples/flavors/flavors-list-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-request.xml', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-list-detailed-response.json', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-show-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-user-name-unscoped-response-HTTP.txt', 'api-ref/source/share/v1/share-snapshots.inc', 'api-ref/source/database/v1/samples/db-create-config-grp-request-json-http.txt', 'api-ref/source/objectstorage/v1/storage_info.inc', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-show-response.json', 'api-ref/source/clustering/v1/samples/node-create-response.json', 'api-ref/source/identity/v3/samples/admin/domain-update-response.json', 'api-ref/source/identity/v3/samples/admin/policy-create-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-list-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos_show_response.json', 'api-ref/source/identity/v3-ext/parameters.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-update-response.json', 'api-ref/source/networking/v2/samples/networks/networks-multi-show-response.json', 'api-ref/source/image/v2/samples/images-list-response.json', 'api-ref/source/image/v2/samples/image-member-details-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-response.xml', 'api-ref/source/share/v1/samples/manila-share-instances-list-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-show-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-update-response.json', 'api-ref/source/identity/v3/samples/admin/project-create-request.json', 'api-ref/source/image/v2/metadefs-namespaces-v2.inc', 'api-ref/source/image/v2/samples/schema-metadef-namespaces-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-associate-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-create-request.json', 'api-ref/source/networking/v2/samples/ports/port-bind-show-response.json', 'api-ref/source/share/v1/samples/manila-service-disable-response.json', 'api-ref/source/clustering/v1/samples/profile-create-request.json', 'api-ref/source/identity/v2/samples/OS-KSADM/tenant-show-response.json', 'api-ref/source/blockstorage/v2/os-vol-pool-v2.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-status-reset-request.json', 'api-ref/source/identity/v3/identity_v3_OS-OAUTH1.inc', 'api-ref/source/orchestration/v1/samples/deployment-show-response.json', 'api-ref/source/database/v1/samples/db-create-users-request-json-http.txt', 'api-ref/source/image/v2/samples/metadef-object-details-response.json', 'api-ref/source/networking/v2-ext/tag-ext.inc', 'api-ref/source/identity/v3/samples/admin/domains-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/listener-update-request.json', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-show-response.json', 'api-ref/source/identity/v3/samples/admin/group-show-response.json', 'api-ref/source/clustering/v1/clustering-v1-build-info.inc', 'api-ref/source/database/v1/samples/db-config-group-details-response-json-http.txt', 'api-ref/source/clustering/v1/samples/clusters-list-response.json', 'api-ref/source/identity/v3/samples/admin/credentials-list-response.json', 'api-ref/source/baremetal/v1/samples/chassis-list-response.json', 'api-ref/source/database/v1/samples/db-instance-eject-replica-response-json-http.txt', 'api-ref/source/clustering/v1/samples/event-show-response.json', 'api-ref/source/networking/v2/service-type.inc', 'api-ref/source/telemetry/v2/capabilities.inc', 'api-ref/source/networking/v2/samples/firewalls/firewall-create-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/service-show-response.json', 'api-ref/source/identity/v2/samples/admin/token-validate-response.json', 'api-ref/source/networking/v2/samples/lbaas/vips-list-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-update-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/multiple-clusters-create-request.json', 'api-ref/source/identity/v3/roles.inc', 'api-ref/source/share/v1/share-quota-sets.inc', 'api-ref/source/networking/v2/samples/networks/network-provider-update-response.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-create-response.json', 'api-ref/source/identity/v3/samples/admin/policies-list-response.json', 'api-ref/source/image/v1/samples/images-list-response.json', 'api-ref/source/clustering/v1/clustering-v1-actions.inc', 'api-ref/source/identity/v2/samples/OS-KSADM/user-update-request.json', 'api-ref/source/database/v1/flavors.inc', 'api-ref/source/networking/v2/samples/vpn/ikepolicies-list-response.json', 'api-ref/source/identity/v3/samples/admin/project-enable-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-response.json', 'api-ref/source/networking/v2/samples/networks/network-create-response.json', 'api-ref/source/share/v1/share-share-networks.inc', 'api-ref/source/identity/v3/domains-config-v3.inc', 'api-ref/source/share/v1/samples/manila-versions-response.json', 'api-ref/source/networking/v2/samples/lbaas/listeners-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-create-request.json', 'api-ref/source/image/v2/samples/metadef-properties-list-response.json', 'api-ref/source/networking/v2/samples/quotas/quotas-list-response.json', 'api-ref/source/identity/v3/samples/admin/identity-versions-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-show-response.json', 'api-ref/source/image/v2/samples/schema-metadef-namespace-show-response.json', 'api-ref/source/share/v1/samples/manila-security-service-create-response.json', 'api-ref/source/networking/v2/samples/routers/router-remove-interface-request.json', 'api-ref/source/orchestration/v1/samples/stack-abandon-response.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/create-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-labels-list-response.json', 'api-ref/source/networking/v2/samples/routers/floating-ips-list-response.json', 'api-ref/source/blockstorage/v2/os-cgsnapshots-v2.inc', 'api-ref/source/image/v1/images-images-v1.inc', 'api-ref/source/networking/v2/versions-networks-v2.inc', 'api-ref/source/identity/v3/samples/admin/domain-create-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-import-request.json', 'api-ref/source/database/v1/samples/db-flavors-by-id-request-json-http.txt', 'api-ref/source/networking/v2/samples/lbaas/pool-list-resp.json', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-request-with-domain.json', 'api-ref/source/database/v1/samples/db-instance-eject-replica-request.json', 'api-ref/source/networking/v2/samples/networks/networks-vlan-transparent-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-response.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-scale-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-update-request.json', 'api-ref/source/database/v1/samples/db-enable-root-user-response.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-show-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-update-response.json', 'api-ref/source/identity/v3/samples/admin/role-update-response.json', 'api-ref/source/networking/v2/samples/qos/policy-show-response.json', 'api-ref/source/image/v2/samples/image-update-request.json', 'api-ref/source/orchestration/v1/samples/stacks-list-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-create-response.json', 'api-ref/source/networking/v2/samples/networks/network-multi-create-response.json', 'api-ref/source/share/v1/share-share-export-locations.inc', 'api-ref/source/networking/v2/samples/subnets/subnetpool-create-response.json', 'api-ref/source/identity/v3/samples/OS-ENDPOINT-POLICY/policy-endpoint-associations-list-response.json', 'api-ref/source/identity/v3/samples/admin/region-update-request.json', 'api-ref/source/identity/v2/samples/admin/user-create-request.json', 'api-ref/source/image/v1/samples/image-versions-response.json', 'api-ref/source/data-processing/v1.1/clustertemplate.inc', 'api-ref/source/identity/v3/samples/OS-KDS/ticket-generate-request.json', 'api-ref/source/objectstorage/v1/samples/containers-list-http-response.txt', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-request.json', 'api-ref/source/telemetry/v2/samples/statistics-list-response.xml', 'api-ref/source/data-processing/v1.1/samples/jobs/job-update-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-sources-list-response.json', 'api-ref/source/clustering/v1/samples/node-check-request.json', 'api-ref/source/networking/v2/samples/ports/ports-bind-show-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-request.json', 'api-ref/source/identity/v3/samples/admin/auth-token-unscoped-request.json', 'api-ref/source/orchestration/v1/stack-resources.inc', 'api-ref/source/identity/v3/samples/admin/region-create-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-show-response.json', 'api-ref/source/share/v1/parameters.yaml', 'api-ref/source/telemetry/v2/samples/resources-list-response.xml', 'api-ref/source/blockstorage/v2/volume-manage.inc', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-register-response.json', 'api-ref/source/blockstorage/v2/os-vol-image-meta-v2.inc', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-unset-request.xml', 'api-ref/source/database/v1/samples/db-instances-index-response-json-http.txt', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-request.xml', 'api-ref/source/networking/v2-ext/flavors-framework-v2.0.inc', 'api-ref/source/database/v1/samples/db-instance-resize-volume-request.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-update-response.json', 'api-ref/source/identity/v3/credentials.inc', 'api-ref/source/image/v2/samples/metadef-object-create-response.json', 'api-ref/source/blockstorage/v2/ext-backups-actions-v2.inc', 'api-ref/source/orchestration/v1/general-info.inc', 'api-ref/source/networking/v2/samples/routers/floatingip-disassociate-request.json', 'api-ref/source/networking/v2/samples/routers/router-update-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-remove-rule-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancers-list-response.json', 'api-ref/source/identity/v3/service-catalog.inc', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-create-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-defaults-response.json', 'api-ref/source/clustering/v1/samples/cluster-scale-out-nodes-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-update-request.xml', 'api-ref/source/identity/v3/samples/OS-KDS/group-create-request.json', 'api-ref/source/identity/v3/samples/admin/endpoint-create-request.json', 'api-ref/source/image/v2/samples/tasks-list-response.json', 'api-ref/source/database/v1/samples/db-instance-resize-volume-response-json-http.txt', 'api-ref/source/orchestration/v1/samples/stack-show-response.json', 'api-ref/source/networking/v2/samples/qos/policy-update-response.json', 'api-ref/source/database/v1/samples/db-version-response-json-http.txt', 'api-ref/source/identity/v3/samples/admin/service-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-detailed-response.json', 'api-ref/source/blockstorage/v2/volumes-v2-snapshots.inc', 'api-ref/source/blockstorage/v1/samples/volumes/version-show-response.json', 'api-ref/source/database/v1/samples/db-instance-resize-flavor-response-json-http.txt', 'api-ref/source/image/v2/os-tasks-v2.inc', 'api-ref/source/share/v1/samples/manila-limits-response.json', 'api-ref/source/orchestration/v1/stack-templates.inc', 'api-ref/source/share/v1/samples/manila-security-service-show-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithoutid-create-request.json', 'api-ref/source/blockstorage/v1/volumes-v1-types.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-response.xml', 'api-ref/source/database/v1/samples/db-list-datastore-versions-response-json-http.txt', 'api-ref/source/image/v2/samples/metadef-object-update-request.json', 'api-ref/source/share/v1/samples/manila-share-type-set-response.json', 'api-ref/source/identity/v3/samples/admin/user-projects-list-response.json', 'api-ref/source/share/v1/share-shares.inc', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-insert-rule-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-show-response.json', 'api-ref/source/data-processing/v1.1/imageregistry.inc', 'api-ref/source/share/v1/samples/manila-share-types-default-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-create-response.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/role-assignments-effective-list-response.json', 'api-ref/source/clustering/v1/samples/policies-list-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-update-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-create-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-create-request.json', 'api-ref/source/identity/v3/samples/admin/regions-list-response.json', 'api-ref/source/orchestration/v1/samples/deployment-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-response.xml', 'api-ref/source/networking/v2/samples/lbaas/pool-update-response.json', 'api-ref/source/database/v1/samples/db-delete-databases-request-json-http.txt', 'api-ref/source/orchestration/v1/samples/stack-update-request.json', 'api-ref/source/telemetry/v2/samples/alarms-list-response.json', 'api-ref/source/image/v2/image-data.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/update-request.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-manage/volume-manage-request.json', 'api-ref/source/share/v1/samples/manila-quota-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-show-response.xml', 'api-ref/source/networking/v2/samples/firewalls/firewall-create-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-show-response.json', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-create-request.json', 'api-ref/source/database/v1/samples/db-delete-instance-response-json-http.txt', 'api-ref/source/clustering/v1/samples/cluster-check-request.json', 'api-ref/source/image/v2/metadefs-namespaces-tags-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/list-response.json', 'api-ref/source/identity/v2/samples/OS-KSS3/credentialswiths3-list-response.json', 'api-ref/source/share/v1/consistency-groups.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-types-list-response.json', 'api-ref/source/database/v1/samples/db-delete-instance-request-json-http.txt', 'api-ref/source/networking/v2/samples/lbaas/pools-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-members-list-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/user-roles-list-response.json', 'api-ref/source/image/v2/samples/schema-metadef-resource-type-association-show-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-associate-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-request.json', 'api-ref/source/image/v2/samples/image-create-request.json', 'api-ref/source/networking/v2/parameters.yaml', 'api-ref/source/data-processing/v1.1/samples/job-executions/cancel-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/service-create-request.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpoint-show-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-create-request.json', 'api-ref/source/networking/v2/samples/network-ip-availability/network-ip-availability-list.json', 'api-ref/source/share/v1/migrate-share.inc', 'api-ref/source/share/v1/samples/manila-share-type-create-request.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-show-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpoints-list-response.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-update-response.json', 'api-ref/source/networking/v2/samples/networks/network-create-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-remove-rule-response.json', 'api-ref/source/orchestration/v1/samples/resource-schema-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-unmanage-request.json', 'api-ref/source/blockstorage/v1/os-quota-sets-v1.inc', 'api-ref/source/database/v1/samples/db-list-cfg-groups-response-json-http.txt', 'api-ref/source/identity/v2-ext/kss3-admin.inc', 'api-ref/source/networking/v2/samples/subnets/subnet-create-response.json', 'api-ref/source/blockstorage/v2/samples/limits/limits-show-response.json', 'api-ref/source/identity/v3/samples/admin/project-update-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-create-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-response.xml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-request.json', 'api-ref/source/share/v1/samples/manila-share-show-response.json', 'api-ref/source/data-processing/v1.1/node-group-template.inc', 'api-ref/source/database/v1/samples/db-flavors-response-json-http.txt', 'api-ref/source/image/v2/samples/metadef-objects-list-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-show-response.xml', 'api-ref/source/data-processing/v1.1/clusters.inc', 'api-ref/source/networking/v2/samples/routers/router-add-interface-response.json', 'api-ref/source/telemetry/v2/meters.inc', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-update-request.json', 'api-ref/source/identity/v3/samples/OS-KDS/key-create-response.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connections-list-response.json', 'api-ref/source/orchestration/v1/samples/heat-versions-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-update-preview-response.json', 'api-ref/source/baremetal/v1/samples/driver-get-response.json', 'api-ref/source/clustering/v1/samples/actions-list-response.json', 'api-ref/source/clustering/v1/samples/profile-types-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-request-json.txt', 'api-ref/source/identity/v3/samples/OS-INHERIT/group-roles-domain-list-response.json', 'api-ref/source/share/v1/samples/manila-security-service-create-request.json', 'api-ref/source/share/v1/samples/manila-export-location-list-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-show-response.json', 'api-ref/source/networking/v2/samples/routers/routers-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-response-xml.txt', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-show-response.json', 'api-ref/source/image/v2/members.inc', 'api-ref/source/share/v1/samples/manila-snapshot-manage-request.json', 'api-ref/source/image/v1/members.inc', 'api-ref/source/share/v1/samples/manila-share-servers-list-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-create-response.json', 'api-ref/source/blockstorage/v2/samples/os-vol-image-meta/image-metadata-show-response.json', 'api-ref/source/networking/v2/samples/extensions/extensions-list-response.json', 'api-ref/source/baremetal/v1/samples/chassis-list-details-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-create-request.json', 'api-ref/source/database/v1/samples/db-detach-replica-response-json-http.txt', 'api-ref/source/share/v1/samples/manila-security-services-list-response.json', 'api-ref/source/share/v1/share-services.inc', 'api-ref/source/telemetry/v2/samples/resources-list-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-show-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rules-list-response.json', 'api-ref/source/clustering/v1/samples/profile-create-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-show-request-json-http.txt', 'api-ref/source/identity/v2/samples/admin/tenants-list-request-JSON.txt', 'api-ref/source/share/v1/samples/manila-share-type-set-request.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-response.xml', 'api-ref/source/identity/v3/samples/admin/user-create-request.json', 'api-ref/source/share/v1/samples/manila-snapshot-show-response.json', 'api-ref/source/telemetry/v2/samples/events-list-response.json', 'api-ref/source/database/v1/samples/db-create-databases-request.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-update-response.json', 'api-ref/source/clustering/v1/samples/node-update-response.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-tokens-list-response.json', 'api-ref/source/networking/v2/samples/extensions/extension-show-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-groups-list-request-json-http.txt', 'api-ref/source/database/v1/samples/db-create-users-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicies-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-update-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rules-list-response.json', 'api-ref/source/identity/v2/samples/admin/tenant-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-response.xml', 'api-ref/source/database/v1/samples/db-instance-resize-instance-response-json-http.txt', 'api-ref/source/identity/v3/samples/admin/endpoint-show-response.json', 'api-ref/source/clustering/v1/clustering-v1-profile_types.inc', 'api-ref/source/identity/v2/samples/OS-KSADM/tenant-update-request.json', 'api-ref/source/baremetal/v1/samples/chassis-create-request.json', 'api-ref/source/identity/v3/samples/admin/user-update-response.json', 'api-ref/source/networking/v2/samples/network-ip-availability/network-ip-availability-show.json', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-update-request.json', 'api-ref/source/image/v2/samples/task-create-request.json', 'api-ref/source/networking/v2/samples/routers/router-update-response.json', 'api-ref/source/networking/v2/samples/networks/networks-bulk-create-response.json', 'api-ref/source/identity/v3/samples/admin/role-assignments-effective-list-response.txt', 'api-ref/source/database/v1/samples/db-versions-response-json-http.txt', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-request.xml', 'api-ref/source/networking/v2/samples/security-groups/security-group-delete-request-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/extensions-list-response.json', 'api-ref/source/data-processing/v1.1/jobs.inc', 'api-ref/source/data-processing/v1.1/samples/plugins/plugins-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/listener-update-response.json', 'api-ref/source/data-processing/v1.1/datasources.inc', 'api-ref/source/blockstorage/v2/limits.inc', 'api-ref/source/identity/v3/samples/admin/role-update-request.json', 'api-ref/source/identity/v3/samples/admin/endpoint-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-delete-request.xml', 'api-ref/source/database/v1/samples/db-datastore-parameters-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSEC2/credentialswithec2-list-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/user-show-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/users-list-response.json', 'api-ref/source/orchestration/v1/samples/stack-create-response.json', 'api-ref/source/image/v2/metadefs-namespaces-properties-v2.inc', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-response.json', 'api-ref/source/data-processing/v1.1/samples/job-types/job-types-list-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-response.json', 'api-ref/source/identity/v3/users.inc', 'api-ref/source/blockstorage/v2/volumes-v2-types.inc', 'api-ref/source/networking/v2/samples/security-groups/security-group-update-request.json', 'api-ref/source/image/v2/image-schemas.inc', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-request.xml', 'api-ref/source/objectstorage/v1/storage_endpoints.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/update-response.json', 'api-ref/source/baremetal/v1/samples/node-states-show-response.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-response.xml', 'api-ref/source/identity/v3/samples/admin/group-users-list-response.json', 'api-ref/source/orchestration/v1/samples/resources-list-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-request.xml', 'api-ref/source/data-processing/v1.1/samples/plugins/plugin-show-response.json', 'api-ref/source/database/v1/samples/db-create-instance-request.json', 'api-ref/source/orchestration/v1/service-status.inc', 'api-ref/source/database/v1/samples/db-enable-root-user-request-json-http.txt', 'api-ref/source/identity/v2-admin/admin-versions.inc', 'api-ref/source/telemetry/v2/samples/statistics-list-response.json', 'api-ref/source/networking/v2/samples/networks/network-update-request.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/listener-show-response.json', 'api-ref/source/clustering/v1/samples/cluster-policy-detach-request.json', 'api-ref/source/identity/v3/samples/OS-KDS/ticket-generate-response.json', 'api-ref/source/objectstorage/v1/samples/capabilities-list-response.json', 'api-ref/source/database/v1/samples/db-detach-config-grp-response-json-http.txt', 'api-ref/source/orchestration/v1/samples/stack-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-action-cancel-update-request.json', 'api-ref/source/objectstorage/v1/samples/endpoints-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-request.json', 'api-ref/source/orchestration/v1/stack-actions.inc', 'api-ref/source/blockstorage/v1/samples/volumes/volume-create-request.xml', 'api-ref/source/objectstorage/v1/samples/objects-list-response.xml', 'api-ref/source/database/v1/samples/db-delete-root-request-json-http.txt', 'api-ref/source/blockstorage/v2/samples/backups/backup-create-response.json', 'api-ref/source/blockstorage/v1/volumes-v1-snapshots.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-insert-rule-response.json', 'api-ref/source/networking/v2/samples/networks/network-provider-show-response.json', 'api-ref/source/database/v1/samples/db-flavors-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-show-response.xml', 'api-ref/source/data-processing/v1.1/samples/clusters/multiple-clusters-create-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-create-request.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-create-response.json', 'api-ref/source/identity/v3/samples/admin/role-show-response.json', 'api-ref/source/share/v1/share-extensions.inc', 'api-ref/source/orchestration/v1/samples/stack-snapshot-request.json', 'api-ref/source/clustering/v1/samples/cluster-update-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-actions-reset-state-request.json', 'api-ref/source/networking/v2/samples/networks/networks-provider-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/member-create-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-request.xml', 'api-ref/source/identity/v3/groups.inc', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-request-xml.txt', 'api-ref/source/baremetal/v1/samples/nodes-list-details-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/versions-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backups-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/vip-create-request.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-show-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-update-request.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-update-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-create-response.json', 'api-ref/source/identity/v2/parameters.yaml', 'api-ref/source/image/v2/samples/metadef-property-create-response.json', 'api-ref/source/share/v1/samples/manila-share-types-list-access-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-response-json-http.txt', 'api-ref/source/networking/v2/samples/qos/policy-update-request.json', 'api-ref/source/identity/v3/samples/admin/group-create-request.json', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplates-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-create-response.json', 'api-ref/source/blockstorage/v2/volumes-v2-volumes-actions.inc', 'api-ref/source/networking/v2-ext/layer3-ext.inc', 'api-ref/source/share/v1/samples/manila-services-list-response.json', 'api-ref/source/share/v1/samples/manila-share-network-update-request.json', 'api-ref/source/image/v2/samples/schema-metadef-tags-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/vip-show-response.json', 'api-ref/source/telemetry/v2/samples/sample-create-request.xml', 'api-ref/source/orchestration/v1/samples/stack-snapshot-response.json', 'api-ref/source/telemetry/v2/samples/resource-show-response.xml', 'api-ref/source/clustering/v1/clustering-v1-cluster_policies.inc', 'api-ref/source/share/v1/samples/manila-share-actions-shrink-request.json', 'api-ref/source/share/v1/samples/manila-service-enable-request.json', 'api-ref/source/share/v1/samples/manila-shares-list-detailed-response.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-show-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-response.json', 'api-ref/source/clustering/v1/samples/cluster-policy-show-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-create-request.json', 'api-ref/source/share/v1/samples/manila-share-network-remove-security-service-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-show-response.json', 'api-ref/source/image/v2/versions-images.inc', 'api-ref/source/identity/v3/samples/admin/domain-create-request.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/user-roles-domain-list-response.json', 'api-ref/source/identity/v3/samples/admin/user-password-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-create-response.json', 'api-ref/source/identity/v2/samples/admin/UserUpdatePasswordRequest.json', 'api-ref/source/orchestration/v1/samples/template-validate-response.json', 'api-ref/source/clustering/v1/clustering-v1-receivers.inc', 'api-ref/source/database/v1/samples/db-instance-resize-instance-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-show-response.json', 'api-ref/source/telemetry/v2/samples/meters-list-response.xml', 'api-ref/source/clustering/v1/samples/cluster-create-request.json', 'api-ref/source/image/v2/samples/metadef-tag-add-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-create-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-response.json', 'api-ref/source/image/v2/parameters.yaml', 'api-ref/source/networking/v2-ext/networks-multi-provider-ext.inc', 'api-ref/source/networking/v2/samples/ports/port-create-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rules-list-response.json', 'api-ref/source/orchestration/v1/samples/stack-adopt-request.json', 'api-ref/source/identity/v2/samples/OS-KSADM/credentials-show-response.json', 'api-ref/source/networking/v2-ext/extraroute.inc', 'api-ref/source/networking/v2-ext/quotas.inc', 'api-ref/source/telemetry/v2/parameters.yaml', 'api-ref/source/identity/v2/samples/admin/users-list-response.json', 'api-ref/source/data-processing/v1.1/samples/plugins/plugin-version-show-response.json', 'api-ref/source/identity/v3/samples/OS-KDS/group-create-response.json', 'api-ref/source/database/v1/samples/db-list-users-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-update-response.json', 'api-ref/source/networking/v2/samples/networks/network-multi-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/member-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-request.json', 'api-ref/source/identity/v3/samples/admin/project-create-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-groups-list-response.json', 'api-ref/source/identity/v3/samples/admin/services-list-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-show-response.xml', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-hdfs-request.json', 'api-ref/source/image/v2/samples/metadef-property-details-response.json', 'api-ref/source/clustering/v1/samples/cluster-add-nodes-request.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-response.json', 'api-ref/source/database/v1/samples/db-create-users-response-json-http.txt', 'api-ref/source/baremetal/v1/baremetal-api-v1-ports.inc', 'api-ref/source/data-processing/v1.1/samples/jobs/job-update-request.json', 'api-ref/source/database/v1/user-management.inc', 'api-ref/source/networking/v2/samples/lbaas/member-update-response.json', 'api-ref/source/identity/v3/projects.inc', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-create-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-create-request.xml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-types-list-response.xml', 'api-ref/source/clustering/v1/clustering-v1-webhooks.inc', 'api-ref/source/clustering/v1/samples/policy-types-list-response.json', 'api-ref/source/clustering/v1/samples/policy-create-response.json', 'api-ref/source/identity/v2/samples/OS-KSVALIDATE/endpoints-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-update-request.json', 'api-ref/source/networking/v2/samples/ports/ports-bulk-create-response.json', 'api-ref/source/share/v1/samples/manila-share-update-metadata-request.json', 'api-ref/source/share/v1/samples/manila-share-type-grant-access-request.json', 'api-ref/source/share/v1/share-actions.inc', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfers-list-response.json', 'api-ref/source/identity/v3/samples/admin/credential-create-request.json', 'api-ref/source/image/v2/samples/schema-metadef-object-show-response.json', 'api-ref/source/clustering/v1/samples/cluster-delete-nodes-request.json', 'api-ref/source/orchestration/v1/parameters.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-update-response.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-show-response.json', 'api-ref/source/share/v1/samples/manila-shares-list-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-show-response.json', 'api-ref/source/orchestration/v1/samples/build-info-response.json', 'api-ref/source/database/v1/samples/db-enable-root-user-response-json-http.txt', 'api-ref/source/share/v1/samples/manila-share-actions-reset-state-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-show-response.json', 'api-ref/source/image/v2/samples/metadef-tag-details-response.json', 'api-ref/source/networking/v2/samples/lbaas/pools-list-response2.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-update-request.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-show-response.json', 'api-ref/source/image/v2/metadefs-namespaces-objects-v2.inc', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-defaults-show-response.json', 'api-ref/source/clustering/v1/parameters.yaml', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-defaults-show-response.xml', 'api-ref/source/identity/v3/samples/admin/auth-password-explicit-unscoped-response.json', 'api-ref/source/baremetal/v1/samples/node-show-response.json', 'api-ref/source/identity/v3/samples/OS-TRUST/trust-create-request.json', 'api-ref/source/share/v1/samples/manila-share-network-create-request.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-response.json', 'api-ref/source/database/v1/samples/db-instance-status-detail-request-json-http.txt', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithenabledonly-enable-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-show-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-update-request.json', 'api-ref/source/networking/v2/samples/routers/router-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-detailed-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policies-list-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-update-request.json', 'api-ref/source/image/v2/samples/metadef-object-create-request.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/group-roles-list-response.json', 'api-ref/source/networking/v2/samples/ports/port-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSS3/s3Credentials-show-response.json', 'api-ref/source/telemetry/v2/samples/sample-show-response.xml', 'api-ref/source/share/v1/samples/manila-services-list-with-filters-response.json', 'api-ref/source/objectstorage/v1/samples/objects-list-http-response-json.txt', 'api-ref/source/networking/v2-ext/parameters.yaml', 'api-ref/source/identity/v3/samples/admin/policy-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/pool-create-request.json', 'api-ref/source/database/v1/samples/db-list-users-request-json-http.txt', 'api-ref/source/blockstorage/v2/samples/backups/backup-restore-response.json', 'api-ref/source/identity/v3/parameters.yaml', 'api-ref/source/share/v1/samples/manila-service-enable-response.json', 'api-ref/source/identity/v2-ext/ksvalidate.inc', 'api-ref/source/identity/v3/samples/admin/auth-password-project-scoped-request.json', 'api-ref/source/identity/v3/samples/admin/domain-config-update-response.json', 'api-ref/source/identity/v3/authenticate-v3.inc', 'api-ref/source/share/v1/samples/manila-share-network-update-response.json', 'api-ref/source/baremetal/v1/samples/chassis-update-request.json', 'api-ref/source/networking/v2/samples/subnets/subnets-list-response.json', 'api-ref/source/identity/v3/samples/admin/role-assignments-list-response.txt', 'api-ref/source/image/v2/samples/schema-metadef-objects-list-response.json', 'api-ref/source/identity/v3/samples/admin/service-update-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-request.xml', 'api-ref/source/identity/v3/samples/admin/roles-list-response.json', 'api-ref/source/identity/v2-admin/admin-extensions.inc', 'api-ref/source/networking/v2/samples/qos/policies-list-response.json', 'api-ref/source/objectstorage/v1/samples/objects-list-http-response-xml.txt', 'api-ref/source/telemetry/v2/samples/alarm-show-response.xml', 'api-ref/source/identity/v2/samples/OS-KSADM/roles-list-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-accept-request.json', 'api-ref/source/networking/v2/samples/tag/tag-update-request.json', 'api-ref/source/identity/v2/identity-api-extensions.inc', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-create-response.json', 'api-ref/source/networking/v2/samples/networks/networks-list-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-detail-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-unscoped-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-templates-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/versions-list-response.json', 'api-ref/source/identity/v2/samples/admin/authenticate-credentials-request.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-update-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-create-request.json', 'api-ref/source/share/v1/samples/manila-share-set-metadata-response.json', 'api-ref/source/database/v1/samples/db-show-parameter-details-request-json-http.txt', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-show-request-json-http.txt', 'api-ref/source/image/v2/samples/metadef-resource-type-create-request.json', 'api-ref/source/image/v2/schemas-metadefs-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/list-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-response.xml', 'api-ref/source/data-processing/v1.1/samples/job-binaries/create-response.json', 'api-ref/source/orchestration/v1/samples/stack-action-resume-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-create-request.xml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-delete-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/job-binaries/create-request.json', 'api-ref/source/orchestration/v1/build-info.inc', 'api-ref/source/share/v1/samples/manila-share-show-instance-response.json', 'api-ref/source/networking/v2/samples/lbaas/vip-update-response.json', 'api-ref/source/share/v1/share-availability-zones.inc', 'api-ref/source/database/v1/samples/db-instance-status-detail-response-json-http.txt', 'api-ref/source/image/v2/samples/image-update-response.json', 'api-ref/source/identity/v3/samples/admin/group-update-request.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-delete-request.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-create-request.json', 'api-ref/source/image/v2/samples/metadef-tag-create-request.json', 'api-ref/source/identity/v3/samples/admin/user-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-attach-request.json', 'api-ref/source/networking/v2/samples/quotas/quotas-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-add-request.xml', 'api-ref/source/clustering/v1/samples/cluster-policy-update-request.json', 'api-ref/source/share/v1/samples/manila-share-network-add-security-service-response.json', 'api-ref/source/identity/v2/samples/admin/roles-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-delete-response.json', 'api-ref/source/identity/v2/samples/admin/tenants-list-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-show-request-json-http.txt', 'api-ref/source/share/v1/share-metadata.inc', 'api-ref/source/share/v1/samples/manila-snapshots-list-detailed-response.json', 'api-ref/source/share/v1/samples/manila-security-service-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/versions-response.xml', 'api-ref/source/identity/v3/samples/admin/endpoints-list-response.json', 'api-ref/source/database/v1/samples/db-create-config-grp-response.json', 'api-ref/source/clustering/v1/senlin-versions.inc', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-show-response.xml', 'api-ref/source/networking/v2-ext/port-binding.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-response.xml', 'api-ref/source/image/v1/samples/shared-images-list-response.json', 'api-ref/source/blockstorage/v2/samples/scheduler-stats/pools-list-detailed-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-show-response.json', 'api-ref/source/networking/v2-ext/fwaas-v2.0.inc', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rules-list-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-labels-list-request-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-update-request.json', 'api-ref/source/database/v1/samples/db-instance-resize-volume-request-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/vpnservices-list-response.json', 'api-ref/source/orchestration/v1/samples/services-list-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rules-list-request-json-http.txt', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-update-request.json', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-request-json-http.txt', 'api-ref/source/share/v1/samples/manila-security-services-list-for-share-network-response.json', 'api-ref/source/database/v1/samples/db-instance-status-detail-response.json', 'api-ref/source/data-processing/v1.1/event-log.inc', 'api-ref/source/data-processing/v1.1/parameters.yaml', 'api-ref/source/networking/v2/samples/lbaas/vip-update-request.json', 'api-ref/source/identity/v2/samples/admin/user-create-response.json', 'api-ref/source/networking/v2/samples/routers/router-create-request.json', 'api-ref/source/objectstorage/v1/samples/containers-list-http-request.txt', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-add-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-delete-request-json-http.txt', 'api-ref/source/orchestration/v1/stack-events.inc', 'api-ref/source/database/v1/samples/db-flavors-by-id-response-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-show-response.json', 'api-ref/source/objectstorage/v1/samples/endpoints-list-response-headers.json', 'api-ref/source/objectstorage/v1/storage-container-services.inc', 'api-ref/source/identity/v3/samples/admin/domain-group-roles-list-response.json', 'api-ref/source/networking/v2-ext/qos-ext.inc', 'api-ref/source/share/v1/samples/manila-export-location-show-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-request.json', 'api-ref/source/networking/v2/subnets.inc', 'api-ref/source/orchestration/v1/samples/stack-preview-response.json', 'api-ref/source/identity/v3/samples/admin/user-create-response.json', 'api-ref/source/database/v1/samples/db-update-config-grp-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-swift-response.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-create-request.json', 'api-ref/source/database/v1/databases.inc', 'api-ref/source/clustering/v1/clustering-v1-nodes.inc', 'api-ref/source/database/v1/samples/db-config-group-details-request-json-http.txt', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-show-response.xml', 'api-ref/source/networking/v2/samples/ports/port-show-response.json', 'api-ref/source/identity/v3/samples/OS-KDS/key-create-request.json', 'api-ref/source/share/v1/samples/manila-share-server-show-details-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-list-response.xml', 'api-ref/source/identity/v3/samples/OS-ENDPOINT-POLICY/policy-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-show-response.xml', 'api-ref/source/database/v1/samples/db-delete-config-group-response-json-http.txt', 'api-ref/source/database/v1/samples/db-create-config-grp-request.json', 'api-ref/source/networking/v2/samples/subnets/subnets-create-bulk-response.json', 'api-ref/source/identity/v2/samples/admin/user-update-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-restore-request.json', 'api-ref/source/clustering/v1/samples/cluster-show-response.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/ac4cc65cb5345cabfd80cbbf517e9504f3dc88b8', 'message': 'Adds migrated RST + YAML files from WADL\n\nContains .inc files which have all the contents of the .rst files\nbut are grouped together for easier editing.\nContains parameters.yaml, which has all parameters in one file.\nContains request and response samples (JSON and XML) that are\npointed to from the .inc files.\n\nChange-Id: I42d5451300f95774a3ec4df66bc95cb36795844d\n'}]",1,311596,ac4cc65cb5345cabfd80cbbf517e9504f3dc88b8,33,6,4,964,,,0,"Adds migrated RST + YAML files from WADL

Contains .inc files which have all the contents of the .rst files
but are grouped together for easier editing.
Contains parameters.yaml, which has all parameters in one file.
Contains request and response samples (JSON and XML) that are
pointed to from the .inc files.

Change-Id: I42d5451300f95774a3ec4df66bc95cb36795844d
",git fetch https://review.opendev.org/openstack/api-site refs/changes/96/311596/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/blockstorage/v2/samples/volumes/volume-replica-promote-request.json', 'api-ref/source/data-processing/v1.1/showClusterTemplate.yaml', 'api-ref/source/identity/v3-ext/checkRoleForUser.yaml', 'api-ref/source/networking/v2-ext/createFloatingIp.yaml', 'api-ref/source/identity/v3/samples/OS-KDS/group-key-show-response.json', 'api-ref/source/share/v1/samples/manila-share-instance-actions-force-delete-request.json', 'api-ref/source/share/v1/samples/manila-share-update-metadata-response.json', 'api-ref/source/share/v1/samples/manila-share-set-metadata-request.json', 'api-ref/source/image/v1/updateImage-v1.yaml', 'api-ref/source/image/v2/samples/image-member-update-request.json', 'api-ref/source/orchestration/v1/samples/deployment-update-request.json', 'api-ref/source/identity/v3/domains.inc', 'api-ref/source/identity/v2-ext/listRoles.yaml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-delete-request-json-http.txt', 'api-ref/source/blockstorage/v2/parameters.yaml', 'api-ref/source/networking/v2-ext/listQuotasForTenant.yaml', 'api-ref/source/identity/v3-ext/identity_v3_OS-ENDPOINT-POLICY-ext.inc', 'api-ref/source/identity/v3-ext/listRoleAssignments.yaml', 'api-ref/source/networking/v2-ext/listExtensions.yaml', 'api-ref/source/networking/v2-ext/createVIP.yaml', 'api-ref/source/image/v2/showImage-v2.yaml', 'api-ref/source/networking/v2-ext/createVpnEndpointGroup.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/images-list-response.json', 'api-ref/source/identity/v3/deleteCredential.yaml', 'api-ref/source/identity/v3/samples/admin/projects-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-response.xml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-show-response.json', 'api-ref/source/data-processing/v1.1/showPlugin.yaml', 'api-ref/source/image/v1/shared-images.inc', 'api-ref/source/identity/v3/showCredential.yaml', 'api-ref/source/share/v1/samples/manila-pools-list-detailed-response.json', 'api-ref/source/identity/v3/showRegion.yaml', 'api-ref/source/orchestration/v1/stack_action_cancel_update.yaml', 'api-ref/source/database/v1/samples/db-list-cfg-groups-request-json-http.txt', 'api-ref/source/identity/v3/listDomainUserRoles.yaml', 'api-ref/source/baremetal/v1/updatePort.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-create-request.json', 'api-ref/source/image/v2/updateImage-v2.yaml', 'api-ref/source/image/v2/samples/image-versions-response.json', 'api-ref/source/blockstorage/v2/listVolumes.yaml', 'api-ref/source/blockstorage/v2/updateVolumeTypeExtraSpecs.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-request.xml', 'api-ref/source/identity/v2/samples/admin/extension-show-response.json', 'api-ref/source/blockstorage/v2/resetVolume.yaml', 'api-ref/source/clustering/v1/samples/cluster-scale-in-nodes-request.json', 'api-ref/source/database/v1/samples/db-list-databases-response.json', 'api-ref/source/networking/v2/samples/networks/version-show-response.json', 'api-ref/source/identity/v3/addUserToGroup.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-create-request.json', 'api-ref/source/database/v1/showInstanceById.yaml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-create-request.json', 'api-ref/source/identity/v3/samples/admin/service-create-response.json', 'api-ref/source/networking/v2-ext/deleteHealthMonitor.yaml', 'api-ref/source/identity/v3/samples/admin/domain-user-roles-list-response.json', 'api-ref/source/identity/v2-ext/ksadm-admin.inc', 'api-ref/source/networking/v2-ext/deleteVpnEndpointGroup.yaml', 'api-ref/source/database/v1/samples/db-instance-resize-instance-request-json-http.txt', 'api-ref/source/networking/v2-ext/showPolicy.yaml', 'api-ref/source/networking/v2/samples/subnets/subnets-create-bulk-request.json', 'api-ref/source/telemetry/v2/listSamplesforMeter.yaml', 'api-ref/source/networking/v2/samples/ports/port-update-request.json', 'api-ref/source/identity/v3-ext/deletePolicyAndEndpointAssociation.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-grant-access-response.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-show-response.json', 'api-ref/source/database/v1/samples/db-create-instance-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-user-name-unscoped-request.json', 'api-ref/source/blockstorage/v2/volumes-v2-volumes.inc', 'api-ref/source/database/v1/samples/db-delete-config-group-request-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-create-response.json', 'api-ref/source/clustering/v1/clustering-v1-policies.inc', 'api-ref/source/share/v1/createShareNetwork.yaml', 'api-ref/source/networking/v2-ext/showIPSecPolicy.yaml', 'api-ref/source/image/v2/showMetadefNamespacesSchema.yaml', 'api-ref/source/data-processing/v1.1/deleteClusterTemplate.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-show-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-delete-response-json-http.txt', 'api-ref/source/image/v2/deleteNamespace-v2.yaml', 'api-ref/source/networking/v2-ext/showIKEPolicy.yaml', 'api-ref/source/identity/v3/listRoles.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-update-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-scoped-request.json', 'api-ref/source/share/v1/showShareServerDetails.yaml', 'api-ref/source/identity/v2-ext/createService.yaml', 'api-ref/source/database/v1/samples/db-instance-restart-request-json-http.txt', 'api-ref/source/networking/v2-ext/listSecGroupRules.yaml', 'api-ref/source/share/v1/samples/manila-share-network-remove-security-service-response.json', 'api-ref/source/orchestration/v1/samples/resource-metadata-response.json', 'api-ref/source/objectstorage/v1/updateObjectMeta.yaml', 'api-ref/source/data-processing/v1.1/listJobTypes.yaml', 'api-ref/source/networking/v2/samples/networks/network-update-response.json', 'api-ref/source/blockstorage/v1/volumes-v1-versions.inc', 'api-ref/source/database/v1/api-versions.inc', 'api-ref/source/image/v2/samples/schema-metadef-resource-type-associations-list-response.json', 'api-ref/source/database/v1/samples/db-create-config-grp-response-json-http.txt', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-response.json', 'api-ref/source/identity/v3-ext/getPolicyAndServiceRegionAssociation.yaml', 'api-ref/source/orchestration/v1/stack_delete.yaml', 'api-ref/source/database/v1/samples/db-patch-config-grp-request.json', 'api-ref/source/identity/v3-ext/listRolesForGroup-domain.yaml', 'api-ref/source/data-processing/v1.1/plugins.inc', 'api-ref/source/orchestration/v1/stack_preview.yaml', 'api-ref/source/identity/v3/grantDomainUserRole.yaml', 'api-ref/source/share/v1/share-share-instance-export-locations.inc', 'api-ref/source/identity/v2-ext/listCredentials.yaml', 'api-ref/source/data-processing/v1.1/job-binary-internals-list.yaml', 'api-ref/source/telemetry/v2/showEvent.yaml', 'api-ref/source/baremetal/v1/createPort.yaml', 'api-ref/source/identity/v3/samples/admin/role-assignments-list-response.json', 'api-ref/source/blockstorage/v2/showQuota.yaml', 'api-ref/source/telemetry/v2/listMeters.yaml', 'api-ref/source/data-processing/v1.1/job-executions-show.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volumes-list-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-update-response.json', 'api-ref/source/telemetry/v2/events.inc', 'api-ref/source/image/v2/deleteProperty-v2.yaml', 'api-ref/source/clustering/v1/listPolicyType.yaml', 'api-ref/source/identity/v3/deleteService.yaml', 'api-ref/source/identity/v3/samples/admin/domain-config-update-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/update-response.json', 'api-ref/source/share/v1/share-listShareTypes.yaml', 'api-ref/source/networking/v2-ext/createHealthMonitor.yaml', 'api-ref/source/networking/v2-ext/createLoadBalancerv2.yaml', 'api-ref/source/share/v1/resetSnapshotState.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-accept-response.json', 'api-ref/source/identity/v3/policies.inc', 'api-ref/source/networking/v2/samples/lbaas/members-list-response.json', 'api-ref/source/clustering/v1/samples/profiles-list-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-delete-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-response.json', 'api-ref/source/share/v1/share-updateSnapshot.yaml', 'api-ref/source/image/v2/samples/metadef-property-update-request.json', 'api-ref/source/blockstorage/v2/volume-type-access.inc', 'api-ref/source/database/v1/samples/db-instances-index-request-json-http.txt', 'api-ref/source/identity/v3/showDomain.yaml', 'api-ref/source/database/v1/promoteToReplicaSource.yaml', 'api-ref/source/networking/v2-ext/listPools.yaml', 'api-ref/source/image/v2/samples/schema-metadef-tag-show-response.json', 'api-ref/source/share/v1/samples/manila-security-service-update-response.json', 'api-ref/source/orchestration/v1/template_version_list.yaml', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-create-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-show-response.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-create-response.json', 'api-ref/source/networking/v2-ext/createVTNetwork.yaml', 'api-ref/source/share/v1/consistency-group-snapshots.inc', 'api-ref/source/image/v2/images-images-v2.inc', 'api-ref/source/networking/v2-ext/createDscpMarkingRule.yaml', 'api-ref/source/networking/v2/samples/lbaas/vip-create-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-show-response.json', 'api-ref/source/image/v2/listTasks-v2.yaml', 'api-ref/source/identity/v3/createProject.yaml', 'api-ref/source/share/v1/unsetExtraSpecShareType.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-replica-reenable-request.json', 'api-ref/source/identity/v3/updateGroup.yaml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-create-response.json', 'api-ref/source/orchestration/v1/resource_signal.yaml', 'api-ref/source/networking/v2/samples/flavors/service-profiles-list-response.json', 'api-ref/source/share/v1/samples/manila-quota-update-response.json', 'api-ref/source/telemetry/v2/samples/alarm-show-response.json', 'api-ref/source/share/v1/share-listSnapshots.yaml', 'api-ref/source/database/v1/createInstance.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-request.json', 'api-ref/source/blockstorage/v2/acceptVolumeTransfer.yaml', 'api-ref/source/database/v1/samples/db-patch-config-grp-response-json-http.txt', 'api-ref/source/networking/v2-ext/updatePoolv2.yaml', 'api-ref/source/identity/v3-ext/listPolicyEndpointAssociations.yaml', 'api-ref/source/clustering/v1/clustering-v1-profiles.inc', 'api-ref/source/identity/v2/samples/admin/versions-list-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-hdfs-response.json', 'api-ref/source/image/v2/samples/schema-metadef-property-show-response.json', 'api-ref/source/data-processing/v1.1/job-executions-list.yaml', 'api-ref/source/identity/v3/samples/admin/credential-update-request.json', 'api-ref/source/image/v1/removeMember-v1.yaml', 'api-ref/source/networking/v2-ext/listSubnetPools.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-show-response.json', 'api-ref/source/blockstorage/v2/showQuotaDefaults.yaml', 'api-ref/source/orchestration/v1/stack_template.yaml', 'api-ref/source/blockstorage/v2/qos-specs-v2-qos-specs.inc', 'api-ref/source/orchestration/v1/template_validate.yaml', 'api-ref/source/share/v1/osUnmanageShare.yaml', 'api-ref/source/identity/v2/samples/admin/user-update-response.json', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-create-response.json', 'api-ref/source/database/v1/samples/db-list-users-response.json', 'api-ref/source/baremetal/v1/samples/nodes-list-response.json', 'api-ref/source/identity/v2-ext/updateUserCredential.yaml', 'api-ref/source/networking/v2-ext/deleteDscpMarkingRule.yaml', 'api-ref/source/database/v1/samples/db-create-databases-response-json-http.txt', 'api-ref/source/blockstorage/v2/listExtensions-cinder-v2.yaml', 'api-ref/source/networking/v2-ext/deleteHealthMonitorv2.yaml', 'api-ref/source/orchestration/v1/stack_list_outputs.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-response.xml', 'api-ref/source/blockstorage/v2/deleteVolumeTransfer.yaml', 'api-ref/source/data-processing/v1.1/createJob.yaml', 'api-ref/source/database/v1/samples/db-instance-restart-request.json', 'api-ref/source/orchestration/v1/samples/deployment-metadata-response.json', 'api-ref/source/identity/v3-ext/deleteKey.yaml', 'api-ref/source/clustering/v1/getVersions-senlin-v1.yaml', 'api-ref/source/image/v2/samples/metadef-tag-update-request.json', 'api-ref/source/networking/v2-ext/showLoadBalancerv2.yaml', 'api-ref/source/baremetal/v1/listPorts.yaml', 'api-ref/source/image/v2/samples/image-member-create-request.json', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-delete-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-create-response.json', 'api-ref/source/share/v1/listShareNetworks.yaml', 'api-ref/source/data-processing/v1.1/samples/jobs/job-execute-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-create-request.json', 'api-ref/source/blockstorage/v2/unmanageVolume.yaml', 'api-ref/source/identity/v3/samples/admin/policy-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-create-response.json', 'api-ref/source/data-processing/v1.1/job-executions.inc', 'api-ref/source/identity/v3/checkUserInGroup.yaml', 'api-ref/source/orchestration/v1/samples/event-show-response.json', 'api-ref/source/clustering/v1/samples/node-show-response.json', 'api-ref/source/share/v1/listPools.yaml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rules-list-request-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-update-request.json', 'api-ref/source/image/v2/samples/image-create-response.json', 'api-ref/source/database/v1/deleteDatabase.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-register-request.json', 'api-ref/source/image/v2/deleteImageMember-v2.yaml', 'api-ref/source/networking/v2-ext/lbaas.inc', 'api-ref/source/image/v2/samples/metadef-namespace-details-response.json', 'api-ref/source/share/v1/listConsistencyGroupsDetails.yaml', 'api-ref/source/baremetal/v1/baremetal-api-v1-chassis.inc', 'api-ref/source/database/v1/samples/db-instance-promote-replica-request.json', 'api-ref/source/identity/v3/samples/admin/domain-show-response.json', 'api-ref/source/networking/v2/ports.inc', 'api-ref/source/share/v1/showShareTypeAccess.yaml', 'api-ref/source/objectstorage/v1/samples/objects-list-response.json', 'api-ref/source/database/v1/samples/db-delete-users-request-json-http.txt', 'api-ref/source/identity/v3/listUserProjects.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-list-access-rules-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-show-response.json', 'api-ref/source/identity/v2/identity-auth.inc', 'api-ref/source/image/v2/samples/metadef-property-update-response.json', 'api-ref/source/networking/v2/samples/quotas/quotas-list-for-tenant-response.json', 'api-ref/source/identity/v3/samples/admin/service-create-request.json', 'api-ref/source/blockstorage/v2/showBackendCapabilities.yaml', 'api-ref/source/data-processing/v1.1/job-executions-cancel.yaml', 'api-ref/source/image/v1/listVersions-image-v1.yaml', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-show-response.json', 'api-ref/source/networking/v2-ext/createFirewallRule.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-detailed-response.xml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/authorize-update-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-create-request.json', 'api-ref/source/identity/v3/createAccessToken.yaml', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-request.xml', 'api-ref/source/database/v1/samples/db-attach-config-grp-request-json-http.txt', 'api-ref/source/clustering/v1/samples/receiver-create-request.json', 'api-ref/source/identity/v3/listDomains.yaml', 'api-ref/source/networking/v2-ext/deleteIKEPolicy.yaml', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-show-response.json', 'api-ref/source/networking/v2-ext/showFirewall.yaml', 'api-ref/source/image/v1/parameters.yaml', 'api-ref/source/database/v1/attachConfigGroup.yaml', 'api-ref/source/identity/v2-ext/ksec2-admin.inc', 'api-ref/source/image/v2/samples/metadef-namespaces-list-response.json', 'api-ref/source/networking/v2-ext/updatePool.yaml', 'api-ref/source/data-processing/v1.1/createClusterTemplate.yaml', 'api-ref/source/clustering/v1/listActions.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithenabledonly-show-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-response.json', 'api-ref/source/database/v1/samples/db-versions-request-json-http.txt', 'api-ref/source/identity/v3/samples/admin/endpoint-update-response.json', 'api-ref/source/database/v1/samples/db-version-request-json-http.txt', 'api-ref/source/data-processing/v1.1/listNodeGroupTemplates.yaml', 'api-ref/source/data-processing/v1.1/showCluster.yaml', 'api-ref/source/networking/v2-ext/createBandwidthLimitRule.yaml', 'api-ref/source/networking/v2/samples/subnets/subnet-update-request.json', 'api-ref/source/database/v1/updateConfigGroup.yaml', 'api-ref/source/networking/v2-ext/createHealthMonitorv2.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-list-access-rules-response.json', 'api-ref/source/identity/v3/validateToken.yaml', 'api-ref/source/blockstorage/v2/volumes-v2-versions.inc', 'api-ref/source/clustering/v1/samples/node-update-request.json', 'api-ref/source/database/v1/restartInstance.yaml', 'api-ref/source/telemetry/v2/samples/alarms-list-response.xml', 'api-ref/source/baremetal/v1/listNodes.yaml', 'api-ref/source/share/v1/samples/manila-pools-list-response.json', 'api-ref/source/image/v2/showMetadefResTypeAssocSchema.yaml', 'api-ref/source/share/v1/samples/manila-share-network-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-request.xml', 'api-ref/source/networking/v2/samples/routers/router-add-interface-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/update-request.json', 'api-ref/source/blockstorage/v2/listConsistencyGroups.yaml', 'api-ref/source/blockstorage/v2/deleteQuotas.yaml', 'api-ref/source/clustering/v1/samples/node-create-request.json', 'api-ref/source/database/v1/samples/db-detach-config-grp-request-json-http.txt', 'api-ref/source/blockstorage/v1/showSnapshotMetadata.yaml', 'api-ref/source/clustering/v1/samples/cluster-recover-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-response.json', 'api-ref/source/database/v1/samples/db-show-parameter-details-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-add-response.json', 'api-ref/source/identity/v3-ext/trust.inc', 'api-ref/source/objectstorage/v1/storage-object-services.inc', 'api-ref/source/networking/v2-ext/associateFlavor.yaml', 'api-ref/source/networking/v2/networks-showVersionDetails.yaml', 'api-ref/source/image/v2/samples/metadef-tag-update-response.json', 'api-ref/source/image/v2/showTag-v2.yaml', 'api-ref/source/share/v1/removeShareTypeAccess.yaml', 'api-ref/source/database/v1/samples/db-config-group-details-response.json', 'api-ref/source/database/v1/samples/db-detach-config-grp-request.json', 'api-ref/source/blockstorage/v2/showVolumeTypes.yaml', 'api-ref/source/clustering/v1/updateProfile.yaml', 'api-ref/source/data-processing/v1.1/job-executions-update.yaml', 'api-ref/source/identity/v2-admin/admin-createUser.yaml', 'api-ref/source/identity/v2/listTenants.yaml', 'api-ref/source/identity/v3/checkDomainGroupRole.yaml', 'api-ref/source/data-processing/v1.1/addTags.yaml', 'api-ref/source/networking/v2/samples/lbaas/listener-create-response.json', 'api-ref/source/baremetal/v1/listPortsDetail.yaml', 'api-ref/source/identity/v2-admin/parameters.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewalls-list-response.json', 'api-ref/source/share/v1/addShareTypeAccess.yaml', 'api-ref/source/clustering/v1/samples/policy-create-request.json', 'api-ref/source/share/v1/samples/manila-share-actions-grant-access-request.json', 'api-ref/source/identity/v2/samples/admin/authenticate-token-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-request.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-from-src-request.json', 'api-ref/source/image/v1/samples/images-list-details-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-request.json', 'api-ref/source/identity/v3/authenticatePasswordScoped.yaml', 'api-ref/source/data-processing/v1.1/job-binary-internals-show.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-response.xml', 'api-ref/source/networking/v2-ext/listIKEPolicies.yaml', 'api-ref/source/data-processing/v1.1/job-types.inc', 'api-ref/source/share/v1/updateConsistencyGroup.yaml', 'api-ref/source/share/v1/samples/manila-share-types-extra-specs-list-response.json', 'api-ref/source/database/v1/samples/db-config-group-instances-response-json-http.txt', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-update-request.json', 'api-ref/source/identity/v3/revokeAccessToken.yaml', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-create-request.json', 'api-ref/source/orchestration/v1/samples/config-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/listener-create-request.json', 'api-ref/source/orchestration/v1/stack_restore_snapshot.yaml', 'api-ref/source/clustering/v1/samples/policy-update-response.json', 'api-ref/source/networking/v2/listNetworks.yaml', 'api-ref/source/networking/v2-ext/vpnaas.inc', 'api-ref/source/identity/v3/samples/admin/project-user-roles-list-response.json', 'api-ref/source/share/v1/listSharesDetails.yaml', 'api-ref/source/blockstorage/v2/deleteCGsnapshot.yaml', 'api-ref/source/image/v2/updateProperty-v2.yaml', 'api-ref/source/orchestration/v1/samples/stack-action-suspend-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-types-list-response.xml', 'api-ref/source/identity/v3-ext/listRolesForUser.yaml', 'api-ref/source/database/v1/deleteInstance.yaml', 'api-ref/source/clustering/v1/samples/receiver-show-response.json', 'api-ref/source/telemetry/v2/samples/samples-list-response.json', 'api-ref/source/networking/v2-ext/updateMember.yaml', 'api-ref/source/share/v1/listDefaultShareTypes.yaml', 'api-ref/source/networking/v2-ext/updateVIP.yaml', 'api-ref/source/data-processing/v1.1/showJobBinaryData.yaml', 'api-ref/source/data-processing/v1.1/runJob.yaml', 'api-ref/source/share/v1/samples/manila-share-manage-response.json', 'api-ref/source/networking/v2-ext/listFirewallRules.yaml', 'api-ref/source/identity/v2-admin/admin-updateUser.yaml', 'api-ref/source/orchestration/v1/samples/stack-outputs-list-response.json', 'api-ref/source/image/v2/samples/metadef-tag-create-response.json', 'api-ref/source/networking/v2-ext/showExtension.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-show-response.xml', 'api-ref/source/telemetry/v2/updateAlarmState.yaml', 'api-ref/source/clustering/v1/samples/senlin-versions-list-response.json', 'api-ref/source/identity/v2-admin/admin-validateToken.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-response.json', 'api-ref/source/networking/v2-ext/createIKEPolicy.yaml', 'api-ref/source/share/v1/samples/manila-share-instance-actions-reset-state-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/extensions-list-response.xml', 'api-ref/source/networking/v2-ext/updateHealthMonitor.yaml', 'api-ref/source/identity/v3/createUser.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-actions-unmanage-request.json', 'api-ref/source/baremetal/v1/showDriver.yaml', 'api-ref/source/identity/v3/samples/admin/role-create-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-request.json', 'api-ref/source/identity/v2-admin/admin-tenants.inc', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-create-request.json', 'api-ref/source/orchestration/v1/samples/template-show-response.json', 'api-ref/source/data-processing/v1.1/samples/event-log/cluster-progress-response.json', 'api-ref/source/networking/v2-ext/deleteFlavor.yaml', 'api-ref/source/networking/v2/createNetwork.yaml', 'api-ref/source/database/v1/samples/db-instance-restart-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-scale-request.json', 'api-ref/source/image/v2/listResourceTypeAssocs-v2.yaml', 'api-ref/source/share/v1/samples/manila-share-manage-request.json', 'api-ref/source/image/v2/showImageSchema.yaml', 'api-ref/source/orchestration/v1/software_deployment_show.yaml', 'api-ref/source/networking/v2-ext/security-groups.inc', 'api-ref/source/networking/v2/samples/subnets/subnet-show-response.json', 'api-ref/source/orchestration/v1/samples/resource-types-list-response.json', 'api-ref/source/identity/v2-ext/getUserCredential.yaml', 'api-ref/source/identity/v2/listVersions-v2.yaml', 'api-ref/source/database/v1/samples/db-delete-users-response-json-http.txt', 'api-ref/source/database/v1/ejectReplicaSource.yaml', 'api-ref/source/networking/v2-ext/showDscpMarkingRule.yaml', 'api-ref/source/share/v1/quota-sets-showQuota.yaml', 'api-ref/source/share/v1/share-listSnapshotsDetails.yaml', 'api-ref/source/share/v1/updateShareNetwork.yaml', 'api-ref/source/networking/v2-ext/showSecGroupRule.yaml', 'api-ref/source/objectstorage/v1/samples/helloworld.txt', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/version-show-response.xml', 'api-ref/source/clustering/v1/clustering-v1-policy_types.inc', 'api-ref/source/database/v1/deleteConfigGroup.yaml', 'api-ref/source/networking/v2-ext/showPort.yaml', 'api-ref/source/networking/v2/networks-listVersions.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-create-response.json', 'api-ref/source/objectstorage/v1/deleteContainer.yaml', 'api-ref/source/orchestration/v1/heat-versions.inc', 'api-ref/source/blockstorage/v2/samples/volumes/version-show-response.json', 'api-ref/source/blockstorage/v1/deleteSnapshot.yaml', 'api-ref/source/identity/v2-ext/enableUser.yaml', 'api-ref/source/identity/v2-ext/deleteEndpointTemplate.yaml', 'api-ref/source/identity/v3/samples/admin/role-assignments-effective-list-response.json', 'api-ref/source/image/v2/deleteImageTag-v2.yaml', 'api-ref/source/networking/v2/samples/ports/port-create-request.json', 'api-ref/source/networking/v2-ext/showMeteringLabelRule.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshots-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-image-metadata-set-request.json', 'api-ref/source/identity/v3/listUsers.yaml', 'api-ref/source/networking/v2-ext/showMeteringLabel.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-show-response.json', 'api-ref/source/database/v1/samples/db-detach-replica-request-json-http.txt', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-request.json', 'api-ref/source/image/v2/samples/metadef-resource-type-assoc-create-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-force-delete-request.json', 'api-ref/source/identity/v2-ext/createUser.yaml', 'api-ref/source/blockstorage/v2/showVolumeTransfer.yaml', 'api-ref/source/networking/v2/bulkCreatePorts.yaml', 'api-ref/source/blockstorage/v1/deleteVolume.yaml', 'api-ref/source/clustering/v1/clustering-v1-events.inc', 'api-ref/source/blockstorage/v2/updateVolumeMetadata.yaml', 'api-ref/source/identity/v2-ext/updateUser.yaml', 'api-ref/source/share/v1/samples/manila-service-disable-request.json', 'api-ref/source/baremetal/v1/parameters.yaml', 'api-ref/source/clustering/v1/samples/cluster-resize-request.json', 'api-ref/source/networking/v2-ext/updateServiceProfile.yaml', 'api-ref/source/clustering/v1/createReceiver.yaml', 'api-ref/source/database/v1/database-instance-actions.inc', 'api-ref/source/identity/v3/showProject.yaml', 'api-ref/source/telemetry/v2/samples/capabilities-list-response.json', 'api-ref/source/database/v1/samples/db-list-parameters-response-json-http.txt', 'api-ref/source/networking/v2/samples/subnets/subnet-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/version-v2-show-response.json', 'api-ref/source/identity/v3/samples/admin/region-create-request.json', 'api-ref/source/identity/v3/samples/admin/region-update-response.json', 'api-ref/source/clustering/v1/deleteProfile.yaml', 'api-ref/source/networking/v2/samples/routers/floatingip-disassociate-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-force-detach-request.json', 'api-ref/source/database/v1/configurations.inc', 'api-ref/source/data-processing/v1.1/listDataSources.yaml', 'api-ref/source/clustering/v1/samples/profile-type-show-response.json', 'api-ref/source/blockstorage/v2/consistencygroups-v2.inc', 'api-ref/source/orchestration/v1/software_config_show.yaml', 'api-ref/source/blockstorage/v2/promotereplicaVolume.yaml', 'api-ref/source/orchestration/v1/samples/stack-find-response.json', 'api-ref/source/image/v2/metadef-resourcetype.inc', 'api-ref/source/share/v1/samples/manila-share-types-list-response.json', 'api-ref/source/image/v2/createTags-v2.yaml', 'api-ref/source/image/v2/showObject-v2.yaml', 'api-ref/source/clustering/v1/createCluster.yaml', 'api-ref/source/identity/v2/samples/OS-KSVALIDATE/token-validate-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/volumes-list-response.xml', 'api-ref/source/networking/v2-ext/deleteListenerv2.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-show-request-json-http.txt', 'api-ref/source/share/v1/share-type.inc', 'api-ref/source/identity/v2/samples/OS-KSEC2/ec2Credentials-create-request.json', 'api-ref/source/identity/v3/samples/admin/group-update-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-scoped-response.json', 'api-ref/source/networking/v2-ext/listIPSecSiteConnections.yaml', 'api-ref/source/networking/v2/samples/subnets/subnetpools-list-response.json', 'api-ref/source/objectstorage/v1/storage-account-services.inc', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-token-create-response.txt', 'api-ref/source/share/v1/samples/manila-share-actions-extend-request.json', 'api-ref/source/networking/v2/samples/networks/network-show-response.json', 'api-ref/source/identity/v3-ext/kds.inc', 'api-ref/source/database/v1/parameters.yaml', 'api-ref/source/identity/v3-ext/checkPolicyForEndpoint.yaml', 'api-ref/source/networking/v2-ext/updateIPSecSiteConnection.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-update-request.json', 'api-ref/source/clustering/v1/samples/policy-update-request.json', 'api-ref/source/share/v1/listShares.yaml', 'api-ref/source/networking/v2-ext/deleteVPNService.yaml', 'api-ref/source/networking/v2-ext/deleteFirewall.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-manage-response.json', 'api-ref/source/share/v1/grantAccess.yaml', 'api-ref/source/networking/v2-ext/listVTNetworks.yaml', 'api-ref/source/telemetry/v2/deleteAlarm.yaml', 'api-ref/source/blockstorage/v1/createVolume.yaml', 'api-ref/source/networking/v2-ext/listFlavors.yaml', 'api-ref/source/networking/v2-ext/createPolicy.yaml', 'api-ref/source/database/v1/samples/db-list-databases-response-json-http.txt', 'api-ref/source/database/v1/createDatabase.yaml', 'api-ref/source/orchestration/v1/samples/deployment-create-request.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-create-response.json', 'api-ref/source/clustering/v1/samples/cluster-policies-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-response.xml', 'api-ref/source/share/v1/share-security-services.inc', 'api-ref/source/identity/v3/samples/admin/user-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-list-response.json', 'api-ref/source/blockstorage/v2/updateConsistencyGroup.yaml', 'api-ref/source/networking/v2/samples/vpn/ikepolicy-update-response.json', 'api-ref/source/blockstorage/v1/showQuotaUser.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-add-request.json', 'api-ref/source/blockstorage/v1/parameters.yaml', 'api-ref/source/identity/v3/revokeTokens.yaml', 'api-ref/source/blockstorage/v2/listBackupsDetails.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/role-show-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-update-request.json', 'api-ref/source/networking/v2-ext/updateTags.yaml', 'api-ref/source/image/v2/samples/schema-image-member-show-response.json', 'api-ref/source/share/v1/deleteShare.yaml', 'api-ref/source/image/v2/samples/metadef-property-create-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-delete-response-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-create-request.json', 'api-ref/source/blockstorage/v2/listSnapshotsDetail.yaml', 'api-ref/source/networking/v2/listPorts.yaml', 'api-ref/source/orchestration/v1/samples/stack-snapshots-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-response-json.txt', 'api-ref/source/networking/v2-ext/deleteTags.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-create-request.json', 'api-ref/source/telemetry/v2/listResources.yaml', 'api-ref/source/identity/v2/samples/admin/version-show-response.json', 'api-ref/source/image/v2/showMetadefResTypeAssocsSchema.yaml', 'api-ref/source/networking/v2-ext/createPool.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-create-request.xml', 'api-ref/source/networking/v2-ext/showRouter.yaml', 'api-ref/source/telemetry/v2/samples/meters-list-response.json', 'api-ref/source/identity/v3/samples/admin/token-validate-request.txt', 'api-ref/source/networking/v2-ext/deleteRouterInterface.yaml', 'api-ref/source/identity/v3/samples/admin/domain-group-update-request.json', 'api-ref/source/networking/v2/bulkCreateNetwork.yaml', 'api-ref/source/image/v2/createImage-v2.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-show-response.xml', 'api-ref/source/identity/v2/samples/admin/user-show-response.json', 'api-ref/source/image/v2/showMetadefNamespaceSchema.yaml', 'api-ref/source/identity/v3/checkProjectGroupRole.yaml', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-update-response.json', 'api-ref/source/share/v1/share-createSnapshot.yaml', 'api-ref/source/identity/v2-ext/showServiceByName.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-request.xml', 'api-ref/source/networking/v2-ext/listFirewalls.yaml', 'api-ref/source/image/v1/deleteImage-v1.yaml', 'api-ref/source/share/v1/share-snapshots.inc', 'api-ref/source/objectstorage/v1/storage_info.inc', 'api-ref/source/clustering/v1/samples/node-create-response.json', 'api-ref/source/identity/v3/samples/admin/policy-create-response.json', 'api-ref/source/image/v1/listVersions-image-null-v1.yaml', 'api-ref/source/database/v1/listConfigInstances.yaml', 'api-ref/source/identity/v3-ext/parameters.yaml', 'api-ref/source/networking/v2-ext/updateFloatingIp.yaml', 'api-ref/source/networking/v2/showSubnet.yaml', 'api-ref/source/networking/v2/samples/networks/networks-multi-show-response.json', 'api-ref/source/orchestration/v1/software_deployment_metadata.yaml', 'api-ref/source/image/v2/samples/image-member-details-response.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-show-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-update-response.json', 'api-ref/source/objectstorage/v1/updateAccountMeta.yaml', 'api-ref/source/clustering/v1/showPolicyType.yaml', 'api-ref/source/image/v2/metadefs-namespaces-v2.inc', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-associate-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-create-request.json', 'api-ref/source/networking/v2/samples/ports/port-bind-show-response.json', 'api-ref/source/share/v1/samples/manila-service-disable-response.json', 'api-ref/source/identity/v3/listCredentials.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/tenant-show-response.json', 'api-ref/source/identity/v3/updateDomainConfigGroupOption.yaml', 'api-ref/source/networking/v2-ext/updateVPNService.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-status-reset-request.json', 'api-ref/source/identity/v2-ext/revokeUserCredentials.yaml', 'api-ref/source/database/v1/samples/db-create-users-request-json-http.txt', 'api-ref/source/networking/v2-ext/tag-ext.inc', 'api-ref/source/identity/v3/samples/admin/domains-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/listener-update-request.json', 'api-ref/source/networking/v2-ext/showHealthMonitorv2.yaml', 'api-ref/source/data-processing/v1.1/job-executions-delete.yaml', 'api-ref/source/image/v2/createNamespace-v2.yaml', 'api-ref/source/clustering/v1/clustering-v1-build-info.inc', 'api-ref/source/clustering/v1/samples/clusters-list-response.json', 'api-ref/source/database/v1/samples/db-instance-eject-replica-response-json-http.txt', 'api-ref/source/networking/v2-ext/listVpnEndpointGroups.yaml', 'api-ref/source/identity/v3/createCredential.yaml', 'api-ref/source/clustering/v1/showReceiver.yaml', 'api-ref/source/networking/v2/service-type.inc', 'api-ref/source/database/v1/isRootEnabled.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-create-response.json', 'api-ref/source/data-processing/v1.1/deleteDataSource.yaml', 'api-ref/source/identity/v2/samples/admin/token-validate-response.json', 'api-ref/source/data-processing/v1.1/job-binaries-update.yaml', 'api-ref/source/networking/v2/samples/routers/floatingip-update-request.json', 'api-ref/source/database/v1/listFlavors.yaml', 'api-ref/source/identity/v3/roles.inc', 'api-ref/source/share/v1/share-quota-sets.inc', 'api-ref/source/identity/v3/samples/admin/policies-list-response.json', 'api-ref/source/image/v1/samples/images-list-response.json', 'api-ref/source/clustering/v1/clustering-v1-actions.inc', 'api-ref/source/orchestration/v1/stack_events_find.yaml', 'api-ref/source/database/v1/flavors.inc', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-response.json', 'api-ref/source/orchestration/v1/event_show.yaml', 'api-ref/source/networking/v2/samples/lbaas/listeners-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-create-request.json', 'api-ref/source/image/v2/samples/metadef-properties-list-response.json', 'api-ref/source/networking/v2/samples/quotas/quotas-list-response.json', 'api-ref/source/networking/v2-ext/updateExtraRoutes.yaml', 'api-ref/source/networking/v2-ext/showMultiNetwork.yaml', 'api-ref/source/orchestration/v1/resource_type_get.yaml', 'api-ref/source/orchestration/v1/samples/stack-abandon-response.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/create-response.json', 'api-ref/source/baremetal/v1/createChassis.yaml', 'api-ref/source/blockstorage/v2/os-cgsnapshots-v2.inc', 'api-ref/source/image/v1/images-images-v1.inc', 'api-ref/source/orchestration/v1/stack_action_check.yaml', 'api-ref/source/networking/v2/versions-networks-v2.inc', 'api-ref/source/identity/v3/samples/admin/domain-create-response.json', 'api-ref/source/database/v1/samples/db-flavors-by-id-request-json-http.txt', 'api-ref/source/networking/v2/samples/lbaas/pool-list-resp.json', 'api-ref/source/identity/v2-ext/getEndpoint.yaml', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-request-with-domain.json', 'api-ref/source/database/v1/samples/db-instance-eject-replica-request.json', 'api-ref/source/identity/v3-ext/associatePolicyAndServiceRegion.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-scale-response.json', 'api-ref/source/share/v1/updateConsistencyGroupSnapshot.yaml', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-update-request.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-update-response.json', 'api-ref/source/networking/v2-ext/createRouter.yaml', 'api-ref/source/networking/v2/samples/qos/policy-show-response.json', 'api-ref/source/image/v2/samples/image-update-request.json', 'api-ref/source/identity/v3/createDomain.yaml', 'api-ref/source/networking/v2-ext/listFloatingIps.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-create-response.json', 'api-ref/source/share/v1/share-share-export-locations.inc', 'api-ref/source/blockstorage/v2/listQoSAssociations.yaml', 'api-ref/source/networking/v2/samples/subnets/subnetpool-create-response.json', 'api-ref/source/clustering/v1/listPolicies.yaml', 'api-ref/source/image/v1/samples/image-versions-response.json', 'api-ref/source/telemetry/v2/samples/statistics-list-response.xml', 'api-ref/source/networking/v2/updateNetwork.yaml', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-sources-list-response.json', 'api-ref/source/clustering/v1/samples/node-check-request.json', 'api-ref/source/image/v2/showImagesSchema.yaml', 'api-ref/source/orchestration/v1/stack-resources.inc', 'api-ref/source/identity/v3/samples/admin/region-create-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-show-response.json', 'api-ref/source/share/v1/parameters.yaml', 'api-ref/source/telemetry/v2/samples/resources-list-response.xml', 'api-ref/source/blockstorage/v2/volume-manage.inc', 'api-ref/source/networking/v2-ext/updateRouter.yaml', 'api-ref/source/blockstorage/v2/reenablereplicaVolume.yaml', 'api-ref/source/blockstorage/v2/os-vol-image-meta-v2.inc', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-unset-request.xml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-request.xml', 'api-ref/source/database/v1/samples/db-instance-resize-volume-request.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-update-response.json', 'api-ref/source/image/v2/samples/metadef-object-create-response.json', 'api-ref/source/identity/v3/showGroup.yaml', 'api-ref/source/share/v1/quota-sets-updateQuota.yaml', 'api-ref/source/share/v1/showShareNetwork.yaml', 'api-ref/source/networking/v2/samples/routers/floatingip-disassociate-request.json', 'api-ref/source/data-processing/v1.1/updateNodeGroupTemplate.yaml', 'api-ref/source/networking/v2-ext/associateHealthMonitor.yaml', 'api-ref/source/clustering/v1/listEvents.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-remove-rule-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancers-list-response.json', 'api-ref/source/identity/v2-admin/admin-listUserGlobalRoles.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-create-response.json', 'api-ref/source/image/v2/deleteTag-v2.yaml', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-update-request.xml', 'api-ref/source/identity/v3/samples/admin/endpoint-create-request.json', 'api-ref/source/image/v2/samples/tasks-list-response.json', 'api-ref/source/networking/v2-ext/createSecGroup.yaml', 'api-ref/source/database/v1/listInstances.yaml', 'api-ref/source/networking/v2-ext/updateSecGroup.yaml', 'api-ref/source/networking/v2/samples/qos/policy-update-response.json', 'api-ref/source/database/v1/samples/db-version-response-json-http.txt', 'api-ref/source/identity/v3-ext/assignRoleToGroup-domain.yaml', 'api-ref/source/identity/v3/samples/admin/service-update-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/version-show-response.json', 'api-ref/source/image/v2/os-tasks-v2.inc', 'api-ref/source/identity/v2-ext/deleteTenant.yaml', 'api-ref/source/share/v1/samples/manila-limits-response.json', 'api-ref/source/orchestration/v1/stack-templates.inc', 'api-ref/source/share/v1/samples/manila-security-service-show-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithoutid-create-request.json', 'api-ref/source/image/v2/showMetadefTagsSchema.yaml', 'api-ref/source/blockstorage/v1/volumes-v1-types.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-response.xml', 'api-ref/source/image/v2/samples/metadef-object-update-request.json', 'api-ref/source/share/v1/samples/manila-share-type-set-response.json', 'api-ref/source/blockstorage/v2/listConsistencyGroupsDetail.yaml', 'api-ref/source/blockstorage/v2/attachVolume.yaml', 'api-ref/source/share/v1/share-shares.inc', 'api-ref/source/share/v1/extendShare.yaml', 'api-ref/source/data-processing/v1.1/imageregistry.inc', 'api-ref/source/networking/v2-ext/deleteTag.yaml', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-create-response.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/role-assignments-effective-list-response.json', 'api-ref/source/clustering/v1/samples/policies-list-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-create-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-create-request.json', 'api-ref/source/identity/v3-ext/listRolesForGroup.yaml', 'api-ref/source/networking/v2-ext/deleteRouter.yaml', 'api-ref/source/identity/v2-ext/createRole.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-response.xml', 'api-ref/source/networking/v2/samples/lbaas/pool-update-response.json', 'api-ref/source/database/v1/samples/db-delete-databases-request-json-http.txt', 'api-ref/source/blockstorage/v1/showVersionDetailsv1.yaml', 'api-ref/source/image/v2/image-data.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/update-request.json', 'api-ref/source/identity/v3/revokeDomainGroupRole.yaml', 'api-ref/source/share/v1/samples/manila-quota-show-response.json', 'api-ref/source/networking/v2-ext/remove_ruleFirewallPolicy.yaml', 'api-ref/source/share/v1/share-unmanageSnapshot.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-show-response.xml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-show-response.json', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-create-request.json', 'api-ref/source/image/v2/metadefs-namespaces-tags-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/list-response.json', 'api-ref/source/identity/v3/listRegions.yaml', 'api-ref/source/telemetry/v2/showAlarmHistory.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-types-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/pools-list-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/user-roles-list-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-associate-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-request.json', 'api-ref/source/identity/v3-ext/checkRoleForGroup.yaml', 'api-ref/source/networking/v2/samples/network-ip-availability/network-ip-availability-list.json', 'api-ref/source/networking/v2-ext/updateFirewallPolicy.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-show-response.json', 'api-ref/source/identity/v2-admin/admin-showUser.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpoints-list-response.json', 'api-ref/source/networking/v2/samples/subnets/subnet-create-response.json', 'api-ref/source/blockstorage/v2/samples/limits/limits-show-response.json', 'api-ref/source/identity/v2-admin/admin-getVersionInfo.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-create-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-response.xml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-request.json', 'api-ref/source/share/v1/force-deleteShare.yaml', 'api-ref/source/share/v1/samples/manila-share-show-response.json', 'api-ref/source/data-processing/v1.1/node-group-template.inc', 'api-ref/source/image/v2/samples/metadef-objects-list-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-create-request.json', 'api-ref/source/orchestration/v1/stack_event_list.yaml', 'api-ref/source/networking/v2/samples/routers/router-add-interface-response.json', 'api-ref/source/telemetry/v2/meters.inc', 'api-ref/source/orchestration/v1/samples/heat-versions-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-update-preview-response.json', 'api-ref/source/blockstorage/v1/listVersionsv1.yaml', 'api-ref/source/baremetal/v1/samples/driver-get-response.json', 'api-ref/source/clustering/v1/samples/actions-list-response.json', 'api-ref/source/clustering/v1/samples/profile-types-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-request-json.txt', 'api-ref/source/share/v1/samples/manila-export-location-list-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-show-response.json', 'api-ref/source/share/v1/listConsistencyGroupsnapshots.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-manage-request.json', 'api-ref/source/blockstorage/v2/updateSnapshot.yaml', 'api-ref/source/database/v1/disableRoot.yaml', 'api-ref/source/blockstorage/v2/disassociateQoSSpecAll.yaml', 'api-ref/source/image/v2/samples/metadef-namespace-create-response.json', 'api-ref/source/blockstorage/v2/samples/os-vol-image-meta/image-metadata-show-response.json', 'api-ref/source/networking/v2/samples/extensions/extensions-list-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-create-request.json', 'api-ref/source/database/v1/samples/db-detach-replica-response-json-http.txt', 'api-ref/source/identity/v3-ext/checkRoleForUser-domain.yaml', 'api-ref/source/share/v1/samples/manila-security-services-list-response.json', 'api-ref/source/telemetry/v2/samples/resources-list-response.json', 'api-ref/source/identity/v3/samples/admin/domain-config-group-show-response.json', 'api-ref/source/clustering/v1/samples/profile-create-response.json', 'api-ref/source/identity/v3/checkProjectUserRole.yaml', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-response.xml', 'api-ref/source/identity/v3/samples/admin/user-create-request.json', 'api-ref/source/telemetry/v2/samples/events-list-response.json', 'api-ref/source/database/v1/samples/db-create-databases-request.json', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-tokens-list-response.json', 'api-ref/source/networking/v2-ext/listMembers.yaml', 'api-ref/source/networking/v2/samples/extensions/extension-show-response.json', 'api-ref/source/networking/v2-ext/showBandwidthLimitRule.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-update-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rules-list-response.json', 'api-ref/source/identity/v2/samples/admin/tenant-show-response.json', 'api-ref/source/objectstorage/v1/showObject.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-response.xml', 'api-ref/source/database/v1/samples/db-instance-resize-instance-response-json-http.txt', 'api-ref/source/identity/v2-ext/createTenant.yaml', 'api-ref/source/identity/v3/listProjectUserRoles.yaml', 'api-ref/source/orchestration/v1/stack_abandon.yaml', 'api-ref/source/objectstorage/v1/showContainerMeta.yaml', 'api-ref/source/identity/v3/samples/admin/user-update-response.json', 'api-ref/source/image/v2/updateNamespace-v2.yaml', 'api-ref/source/networking/v2/samples/network-ip-availability/network-ip-availability-show.json', 'api-ref/source/image/v2/samples/task-create-request.json', 'api-ref/source/networking/v2/samples/networks/networks-bulk-create-response.json', 'api-ref/source/identity/v3/samples/admin/role-assignments-effective-list-response.txt', 'api-ref/source/networking/v2-ext/createMeteringLabelRule.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-request.xml', 'api-ref/source/networking/v2-ext/updateTag.yaml', 'api-ref/source/blockstorage/v2/restoreBackup.yaml', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/extensions-list-response.json', 'api-ref/source/data-processing/v1.1/updateClusterTemplate.yaml', 'api-ref/source/data-processing/v1.1/samples/plugins/plugins-list-response.json', 'api-ref/source/blockstorage/v1/listVolumes.yaml', 'api-ref/source/data-processing/v1.1/datasources.inc', 'api-ref/source/blockstorage/v1/deleteVolumeType.yaml', 'api-ref/source/database/v1/samples/db-datastore-parameters-response.json', 'api-ref/source/identity/v2/samples/OS-KSEC2/credentialswithec2-list-response.json', 'api-ref/source/networking/v2-ext/updateIPSecPolicy.yaml', 'api-ref/source/identity/v2-admin/admin-listRolesForUserOnTenant.yaml', 'api-ref/source/image/v2/showTask-v2.yaml', 'api-ref/source/identity/v2-ext/grantCredentialToUser.yaml', 'api-ref/source/baremetal/v1/showVendorMethods.yaml', 'api-ref/source/image/v2/metadefs-namespaces-properties-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-types/job-types-list-response.json', 'api-ref/source/identity/v3/users.inc', 'api-ref/source/networking/v2-ext/showPool.yaml', 'api-ref/source/share/v1/force-deleteShareInstance.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-update-request.json', 'api-ref/source/image/v2/image-schemas.inc', 'api-ref/source/networking/v2-ext/showHealthMonitor.yaml', 'api-ref/source/networking/v2-ext/updateHealthMonitorv2.yaml', 'api-ref/source/data-processing/v1.1/scaleCluster.yaml', 'api-ref/source/objectstorage/v1/storage_endpoints.inc', 'api-ref/source/baremetal/v1/samples/node-states-show-response.json', 'api-ref/source/networking/v2-ext/showFirewallPolicy.yaml', 'api-ref/source/identity/v3/revokeDomainUserRole.yaml', 'api-ref/source/blockstorage/v1/updateSnapshotMetadata.yaml', 'api-ref/source/orchestration/v1/samples/resources-list-response.json', 'api-ref/source/identity/v3-ext/checkRoleForGroup-domain.yaml', 'api-ref/source/image/v2/showMetadefPropertySchema.yaml', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-request.json', 'api-ref/source/data-processing/v1.1/samples/plugins/plugin-show-response.json', 'api-ref/source/database/v1/samples/db-create-instance-request.json', 'api-ref/source/orchestration/v1/service-status.inc', 'api-ref/source/image/v2/listTags-v2.yaml', 'api-ref/source/identity/v2-admin/admin-versions.inc', 'api-ref/source/networking/v2/samples/networks/network-update-request.json', 'api-ref/source/networking/v2-ext/ListNetworkIpAvailability.yaml', 'api-ref/source/blockstorage/v1/showVolume.yaml', 'api-ref/source/clustering/v1/samples/cluster-policy-detach-request.json', 'api-ref/source/identity/v3/samples/OS-KDS/ticket-generate-response.json', 'api-ref/source/orchestration/v1/samples/stack-create-request.json', 'api-ref/source/networking/v2-ext/showLoadBalancerStatusTree.yaml', 'api-ref/source/blockstorage/v2/createCGsnapshot.yaml', 'api-ref/source/objectstorage/v1/samples/endpoints-list-response.json', 'api-ref/source/identity/v2-ext/listUsersForTenant.yaml', 'api-ref/source/orchestration/v1/resource_event_list.yaml', 'api-ref/source/networking/v2-ext/deleteSecGroup.yaml', 'api-ref/source/blockstorage/v1/updateVolumeTypeExtraSpecs.yaml', 'api-ref/source/orchestration/v1/resource_metadata.yaml', 'api-ref/source/blockstorage/v1/volumes-v1-snapshots.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-response.json', 'api-ref/source/clustering/v1/updateCluster.yaml', 'api-ref/source/identity/v2-ext/listUserGlobalRoles.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-insert-rule-response.json', 'api-ref/source/networking/v2/samples/networks/network-provider-show-response.json', 'api-ref/source/networking/v2/bulkCreateSubnet.yaml', 'api-ref/source/database/v1/createUser.yaml', 'api-ref/source/database/v1/listUsers.yaml', 'api-ref/source/networking/v2-ext/createSecGroupRule.yaml', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-create-response.json', 'api-ref/source/orchestration/v1/stack_delete_snapshot.yaml', 'api-ref/source/identity/v3/samples/admin/role-show-response.json', 'api-ref/source/share/v1/share-extensions.inc', 'api-ref/source/blockstorage/v2/createVolumeTransfer.yaml', 'api-ref/source/orchestration/v1/samples/stack-snapshot-request.json', 'api-ref/source/data-processing/v1.1/job-binary-internals-update.yaml', 'api-ref/source/objectstorage/v1/copyObject.yaml', 'api-ref/source/clustering/v1/showAction.yaml', 'api-ref/source/networking/v2/samples/networks/networks-provider-list-response.json', 'api-ref/source/networking/v2-ext/updateDscpMarkingRule.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-request.xml', 'api-ref/source/data-processing/v1.1/listImages.yaml', 'api-ref/source/identity/v3/groups.inc', 'api-ref/source/baremetal/v1/samples/nodes-list-details-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/versions-response.json', 'api-ref/source/networking/v2/samples/lbaas/vip-create-request.json', 'api-ref/source/share/v1/updateShare.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-show-response.json', 'api-ref/source/networking/v2-ext/createSubnetPool.yaml', 'api-ref/source/networking/v2-ext/createFirewall.yaml', 'api-ref/source/image/v2/samples/metadef-property-create-response.json', 'api-ref/source/identity/v3/samples/admin/group-create-request.json', 'api-ref/source/image/v2/showProperty-v2.yaml', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplates-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-create-response.json', 'api-ref/source/networking/v2-ext/layer3-ext.inc', 'api-ref/source/networking/v2-ext/listMembersv2.yaml', 'api-ref/source/share/v1/samples/manila-share-network-update-request.json', 'api-ref/source/data-processing/v1.1/showPluginVersion.yaml', 'api-ref/source/networking/v2/samples/lbaas/vip-show-response.json', 'api-ref/source/orchestration/v1/samples/stack-snapshot-response.json', 'api-ref/source/blockstorage/v1/showVolumeType.yaml', 'api-ref/source/blockstorage/v2/showQuotaUser.yaml', 'api-ref/source/networking/v2-ext/updateLoadBalancerv2.yaml', 'api-ref/source/identity/v3-ext/revokeRoleFromGroup.yaml', 'api-ref/source/share/v1/samples/manila-shares-list-detailed-response.json', 'api-ref/source/clustering/v1/samples/cluster-policy-show-response.json', 'api-ref/source/share/v1/samples/manila-share-network-remove-security-service-request.json', 'api-ref/source/image/v2/versions-images.inc', 'api-ref/source/identity/v2-ext/grantGlobalRoleToUser.yaml', 'api-ref/source/identity/v3/samples/admin/domain-create-request.json', 'api-ref/source/database/v1/listParameters.yaml', 'api-ref/source/identity/v3/samples/OS-INHERIT/user-roles-domain-list-response.json', 'api-ref/source/orchestration/v1/stack_find.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-create-response.json', 'api-ref/source/networking/v2-ext/updateFlavor.yaml', 'api-ref/source/share/v1/listExtensions.yaml', 'api-ref/source/identity/v2-ext/grantRoleToUserOnTenant.yaml', 'api-ref/source/telemetry/v2/samples/meters-list-response.xml', 'api-ref/source/blockstorage/v1/deleteQuotasUser.yaml', 'api-ref/source/image/v2/samples/metadef-tag-add-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-create-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-response.json', 'api-ref/source/baremetal/v1/deletePort.yaml', 'api-ref/source/clustering/v1/updateNode.yaml', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rules-list-response.json', 'api-ref/source/baremetal/v1/showChassis.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/credentials-show-response.json', 'api-ref/source/blockstorage/v2/listCGsnapshotsDetail-v2.yaml', 'api-ref/source/telemetry/v2/addSamplesToMeter.yaml', 'api-ref/source/identity/v2/samples/admin/users-list-response.json', 'api-ref/source/networking/v2-ext/listVPNServices.yaml', 'api-ref/source/blockstorage/v2/updateVolume.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-request.json', 'api-ref/source/identity/v3/samples/admin/project-create-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-groups-list-response.json', 'api-ref/source/identity/v3/samples/admin/services-list-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-show-response.xml', 'api-ref/source/identity/v3/showUnauthorizedRequestToken.yaml', 'api-ref/source/image/v2/samples/metadef-property-details-response.json', 'api-ref/source/baremetal/v1/baremetal-api-v1-ports.inc', 'api-ref/source/networking/v2-ext/listBandwidthLimitRules.yaml', 'api-ref/source/networking/v2/samples/lbaas/member-update-response.json', 'api-ref/source/networking/v2-ext/showFlavor.yaml', 'api-ref/source/identity/v3/projects.inc', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-create-request.xml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-types-list-response.xml', 'api-ref/source/clustering/v1/clustering-v1-webhooks.inc', 'api-ref/source/clustering/v1/samples/policy-types-list-response.json', 'api-ref/source/networking/v2-ext/deleteMember.yaml', 'api-ref/source/clustering/v1/samples/policy-create-response.json', 'api-ref/source/image/v2/listVersions-image-v2.yaml', 'api-ref/source/networking/v2/samples/lbaas/pool-update-request.json', 'api-ref/source/networking/v2-ext/showListenerv2.yaml', 'api-ref/source/networking/v2/samples/ports/ports-bulk-create-response.json', 'api-ref/source/networking/v2-ext/createPoolv2.yaml', 'api-ref/source/share/v1/samples/manila-share-update-metadata-request.json', 'api-ref/source/share/v1/samples/manila-share-type-grant-access-request.json', 'api-ref/source/share/v1/share-actions.inc', 'api-ref/source/clustering/v1/samples/cluster-delete-nodes-request.json', 'api-ref/source/blockstorage/v2/showConsistencyGroup.yaml', 'api-ref/source/identity/v3/authenticatePasswordUnscoped.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-show-response.json', 'api-ref/source/data-processing/v1.1/job-binary-internals-delete.yaml', 'api-ref/source/share/v1/manageShare.yaml', 'api-ref/source/networking/v2/samples/routers/floatingip-show-response.json', 'api-ref/source/identity/v3-ext/generateTicket.yaml', 'api-ref/source/blockstorage/v2/deleteQoSSpec.yaml', 'api-ref/source/identity/v3/removeUserFromGroup.yaml', 'api-ref/source/networking/v2/updateSubnet.yaml', 'api-ref/source/networking/v2-ext/showVTNetwork.yaml', 'api-ref/source/share/v1/listPoolsDetails.yaml', 'api-ref/source/share/v1/updateSecurityService.yaml', 'api-ref/source/networking/v2/samples/lbaas/pools-list-response2.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-update-request.json', 'api-ref/source/clustering/v1/updatePolicy.yaml', 'api-ref/source/data-processing/v1.1/job-binary-internals-data.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-update-request.json', 'api-ref/source/identity/v2/showExtension.yaml', 'api-ref/source/image/v2/metadefs-namespaces-objects-v2.inc', 'api-ref/source/networking/v2-ext/createMember.yaml', 'api-ref/source/clustering/v1/parameters.yaml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-defaults-show-response.xml', 'api-ref/source/identity/v3/deleteRole.yaml', 'api-ref/source/networking/v2-ext/createIPSecPolicy.yaml', 'api-ref/source/identity/v3/samples/OS-TRUST/trust-create-request.json', 'api-ref/source/identity/v3/deleteDomainConfigGroupOption.yaml', 'api-ref/source/identity/v3/showDomainConfigGroup.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-response.json', 'api-ref/source/database/v1/samples/db-instance-status-detail-request-json-http.txt', 'api-ref/source/identity/v2/samples/OS-KSADM/userwithenabledonly-enable-request.json', 'api-ref/source/identity/v2-ext/listCredentialsByType.yaml', 'api-ref/source/networking/v2/samples/routers/router-create-response.json', 'api-ref/source/blockstorage/v2/createVolumeTypeAccessExt.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshots-list-detailed-response.json', 'api-ref/source/identity/v3/grantDomainGroupRole.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policies-list-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-update-request.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/group-roles-list-response.json', 'api-ref/source/share/v1/listShareServers.yaml', 'api-ref/source/networking/v2/samples/ports/port-update-response.json', 'api-ref/source/telemetry/v2/samples/sample-show-response.xml', 'api-ref/source/identity/v3/updateRegion.yaml', 'api-ref/source/networking/v2-ext/updateMemberv2.yaml', 'api-ref/source/networking/v2-ext/showTag.yaml', 'api-ref/source/image/v2/deleteImage-v2.yaml', 'api-ref/source/share/v1/samples/manila-services-list-with-filters-response.json', 'api-ref/source/share/v1/exportLocationShow.yaml', 'api-ref/source/objectstorage/v1/samples/objects-list-http-response-json.txt', 'api-ref/source/networking/v2-ext/parameters.yaml', 'api-ref/source/database/v1/samples/db-list-users-request-json-http.txt', 'api-ref/source/blockstorage/v2/showCGsnapshot.yaml', 'api-ref/source/objectstorage/v1/showContainerDetails.yaml', 'api-ref/source/networking/v2-ext/removeSubnetPool.yaml', 'api-ref/source/share/v1/samples/manila-service-enable-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-project-scoped-request.json', 'api-ref/source/identity/v3/samples/admin/domain-config-update-response.json', 'api-ref/source/baremetal/v1/samples/chassis-update-request.json', 'api-ref/source/identity/v3/samples/admin/service-update-request.json', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-request.xml', 'api-ref/source/identity/v2-admin/admin-extensions.inc', 'api-ref/source/objectstorage/v1/samples/objects-list-http-response-xml.txt', 'api-ref/source/identity/v3/listGroupUsers.yaml', 'api-ref/source/networking/v2-ext/showVPNService.yaml', 'api-ref/source/identity/v2/identity-api-extensions.inc', 'api-ref/source/orchestration/v1/stack_update.yaml', 'api-ref/source/networking/v2/samples/networks/networks-list-response.json', 'api-ref/source/data-processing/v1.1/listJobBinaries.yaml', 'api-ref/source/share/v1/listConsistencyGroupsnapshotMembers.yaml', 'api-ref/source/identity/v2/samples/admin/authenticate-credentials-request.json', 'api-ref/source/share/v1/share-deleteSnapshot.yaml', 'api-ref/source/image/v1/listImages-v1.yaml', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-update-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-create-request.json', 'api-ref/source/blockstorage/v1/listVolumesDetail.yaml', 'api-ref/source/identity/v3/authenticate.yaml', 'api-ref/source/image/v2/samples/metadef-resource-type-create-request.json', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/list-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-response.xml', 'api-ref/source/data-processing/v1.1/samples/job-binaries/create-response.json', 'api-ref/source/orchestration/v1/samples/stack-action-resume-request.json', 'api-ref/source/data-processing/v1.1/job-binaries-delete.yaml', 'api-ref/source/share/v1/share-availability-zones.inc', 'api-ref/source/identity/v3-ext/revokeRoleFromUser.yaml', 'api-ref/source/identity/v3/listEndpoints.yaml', 'api-ref/source/clustering/v1/showEvent.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-tags-delete-request.json', 'api-ref/source/data-processing/v1.1/samples/jobs/job-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-attach-request.json', 'api-ref/source/identity/v3/showService.yaml', 'api-ref/source/share/v1/samples/manila-share-network-add-security-service-response.json', 'api-ref/source/blockstorage/v1/showSnapshot.yaml', 'api-ref/source/identity/v2/samples/admin/roles-list-response.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-delete-response.json', 'api-ref/source/networking/v2-ext/showVpnEndpointGroup.yaml', 'api-ref/source/identity/v2/samples/admin/tenants-list-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-show-request-json-http.txt', 'api-ref/source/identity/v3/listServices.yaml', 'api-ref/source/share/v1/samples/manila-snapshots-list-detailed-response.json', 'api-ref/source/share/v1/samples/manila-security-service-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/versions-response.xml', 'api-ref/source/database/v1/samples/db-create-config-grp-response.json', 'api-ref/source/identity/v2-ext/createEndpointTemplate.yaml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-show-response.xml', 'api-ref/source/networking/v2-ext/port-binding.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-response.xml', 'api-ref/source/blockstorage/v2/showSnapshot.yaml', 'api-ref/source/image/v2/showImageMemberSchema.yaml', 'api-ref/source/image/v1/samples/shared-images-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-show-response.json', 'api-ref/source/data-processing/v1.1/listClusterTemplates.yaml', 'api-ref/source/database/v1/samples/db-instance-resize-volume-request-json-http.txt', 'api-ref/source/networking/v2/samples/security-groups/security-group-rules-list-request-json-http.txt', 'api-ref/source/share/v1/unSetShareMetadata.yaml', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-request-json-http.txt', 'api-ref/source/share/v1/exportLocationList.yaml', 'api-ref/source/data-processing/v1.1/event-log.inc', 'api-ref/source/identity/v2/samples/admin/user-create-response.json', 'api-ref/source/data-processing/v1.1/showImage.yaml', 'api-ref/source/image/v1/listImagesDetailed-v1.yaml', 'api-ref/source/networking/v2/samples/routers/router-create-request.json', 'api-ref/source/objectstorage/v1/samples/containers-list-http-request.txt', 'api-ref/source/database/v1/listDatastoreVersions.yaml', 'api-ref/source/database/v1/samples/db-flavors-by-id-response-json-http.txt', 'api-ref/source/objectstorage/v1/samples/endpoints-list-response-headers.json', 'api-ref/source/identity/v3/listAuthorizedAccessTokens.yaml', 'api-ref/source/blockstorage/v2/showBackup.yaml', 'api-ref/source/networking/v2-ext/qos-ext.inc', 'api-ref/source/share/v1/samples/manila-export-location-show-response.json', 'api-ref/source/networking/v2-ext/listMultiNetworks.yaml', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-request.json', 'api-ref/source/telemetry/v2/listSamplesStatistics.yaml', 'api-ref/source/orchestration/v1/service_status_list.yaml', 'api-ref/source/networking/v2-ext/listHealthMonitors.yaml', 'api-ref/source/data-processing/v1.1/unregisterImage.yaml', 'api-ref/source/database/v1/databases.inc', 'api-ref/source/database/v1/samples/db-config-group-details-request-json-http.txt', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-show-response.xml', 'api-ref/source/blockstorage/v2/forceDeleteBackup.yaml', 'api-ref/source/identity/v3/samples/OS-KDS/key-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-show-response.xml', 'api-ref/source/image/v1/listSharedImages-v1.yaml', 'api-ref/source/database/v1/samples/db-delete-config-group-response-json-http.txt', 'api-ref/source/networking/v2/showNetwork.yaml', 'api-ref/source/identity/v2/samples/admin/user-update-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-restore-request.json', 'api-ref/source/identity/v3/listGroups.yaml', 'api-ref/source/networking/v2-ext/showFirewallRule.yaml', 'api-ref/source/clustering/v1/samples/profile-update-request.json', 'api-ref/source/telemetry/v2/listAlarms.yaml', 'api-ref/source/telemetry/v2/samples/capabilities-list-response.xml', 'api-ref/source/blockstorage/v2/capabilities-v2.inc', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-status-tree.json', 'api-ref/source/data-processing/v1.1/createDataSource.yaml', 'api-ref/source/image/v2/showMetadefObjectsSchema.yaml', 'api-ref/source/networking/v2/samples/vpn/vpnservice-create-response.json', 'api-ref/source/identity/v2/samples/admin/endpoints-list-response.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-groups-list-response.json', 'api-ref/source/objectstorage/v1/showAccountMeta.yaml', 'api-ref/source/image/v2/deleteAllTags-v2.yaml', 'api-ref/source/share/v1/samples/manila-availability-zones-list-response.json', 'api-ref/source/orchestration/v1/samples/template-validate-request.json', 'api-ref/source/clustering/v1/triggerWebhook.yaml', 'api-ref/source/identity/v2-admin/admin-deleteUser.yaml', 'api-ref/source/share/v1/share-limits.inc', 'api-ref/source/telemetry/v2/showSample.yaml', 'api-ref/source/orchestration/v1/stack_show_output.yaml', 'api-ref/source/share/v1/listServices.yaml', 'api-ref/source/identity/v2-ext/getEndpointTemplate.yaml', 'api-ref/source/image/v2/listNamespaces-v2.yaml', 'api-ref/source/networking/v2/samples/service-type-response.json', 'api-ref/source/blockstorage/v1/showQuotaDetailUser.yaml', 'api-ref/source/blockstorage/v2/createConsistencyGroup.yaml', 'api-ref/source/identity/v3/showEndpoint.yaml', 'api-ref/source/share/v1/samples/manila-extensions-list-response.json', 'api-ref/source/networking/v2/samples/flavors/flavor-associate-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-update-request.json', 'api-ref/source/networking/v2-ext/listServiceProfiles.yaml', 'api-ref/source/telemetry/v2/listSamples.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-show-response.xml', 'api-ref/source/orchestration/v1/samples/deployment-create-response.json', 'api-ref/source/identity/v3/listProjectGroupRoles.yaml', 'api-ref/source/share/v1/samples/manila-share-type-revoke-access-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-request.json', 'api-ref/source/blockstorage/v2/listCGsnapshots.yaml', 'api-ref/source/data-processing/v1.1/deleteNodeGroupTemplate.yaml', 'api-ref/source/identity/v2-admin/admin-listUsers.yaml', 'api-ref/source/networking/v2/samples/networks/network-provider-create-response.json', 'api-ref/source/telemetry/v2/samples/sample-create-request.json', 'api-ref/source/blockstorage/v2/quota-sets.inc', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-create-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-detailed-response.json', 'api-ref/source/blockstorage/v2/deleteConsistencyGroup.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos_show_response.xml', 'api-ref/source/objectstorage/v1/parameters.yaml', 'api-ref/source/database/v1/samples/db-list-databases-request-json-http.txt', 'api-ref/source/clustering/v1/samples/nodes-list-response.json', 'api-ref/source/orchestration/v1/software-config.inc', 'api-ref/source/identity/v3/listConsumers.yaml', 'api-ref/source/networking/v2-ext/subnetpools-ext.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-request.xml', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplate-create-request.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-show-response.json', 'api-ref/source/image/v2/samples/image-member-create-response.json', 'api-ref/source/networking/v2/samples/lbaas/member-update-request.json', 'api-ref/source/share/v1/samples/manila-security-services-list-detailed-response.json', 'api-ref/source/identity/v3/deleteProject.yaml', 'api-ref/source/networking/v2/networks.inc', 'api-ref/source/database/v1/samples/db-config-group-instances-request-json-http.txt', 'api-ref/source/baremetal/v1/baremetal-api-v1-drivers.inc', 'api-ref/source/identity/v3/samples/admin/groups-list-response.json', 'api-ref/source/share/v1/force-deleteConsistencyGroup.yaml', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-response.json', 'api-ref/source/objectstorage/v1/showObjectMeta.yaml', 'api-ref/source/networking/v2-ext/deleteFirewallPolicy.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-update-response.json', 'api-ref/source/identity/v3/samples/admin/project-update-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-create-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-show-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-update-request.json', 'api-ref/source/image/v2/samples/schemas-image-members-list-response.json', 'api-ref/source/share/v1/listShareInstances.yaml', 'api-ref/source/identity/v2-ext/deleteUser.yaml', 'api-ref/source/objectstorage/v1/listEndpoints.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/volume-types-list-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-force-delete-request.json', 'api-ref/source/share/v1/revokeAccess.yaml', 'api-ref/source/blockstorage/v2/listVolumeTransferDetails.yaml', 'api-ref/source/blockstorage/v2/deleteQuotasUser.yaml', 'api-ref/source/clustering/v1/clusterAction.yaml', 'api-ref/source/blockstorage/v2/volumes-v2-extensions.inc', 'api-ref/source/orchestration/v1/resource_show.yaml', 'api-ref/source/clustering/v1/nodeAction.yaml', 'api-ref/source/identity/v2-ext/checkToken.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-rules-list-response.json', 'api-ref/source/identity/v3/deleteUser.yaml', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-response.json', 'api-ref/source/networking/v2/samples/security-groups/security-group-delete-response-json-http.txt', 'api-ref/source/baremetal/v1/samples/drivers-list-response.json', 'api-ref/source/identity/v3/showRoleOfAccessToken.yaml', 'api-ref/source/image/v2/createObject-v2.yaml', 'api-ref/source/networking/v2-ext/resetQuota.yaml', 'api-ref/source/networking/v2/samples/ports/ports-bulk-create-request.json', 'api-ref/source/blockstorage/v2/createVolumeMetadata.yaml', 'api-ref/source/share/v1/samples/manila-snapshot-create-response.json', 'api-ref/source/data-processing/v1.1/jobbinary-internals.inc', 'api-ref/source/image/v2/showImageMembersSchema.yaml', 'api-ref/source/image/v2/createProperty-v2.yaml', 'api-ref/source/image/v2/image-tags.inc', 'api-ref/source/orchestration/v1/samples/events-list-response.json', 'api-ref/source/share/v1/share-deleteShareType.yaml', 'api-ref/source/share/v1/createConsistencyGroup.yaml', 'api-ref/source/networking/v2-ext/listDscpMarkingRules.yaml', 'api-ref/source/orchestration/v1/samples/resource-type-template-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-update-response.json', 'api-ref/source/networking/v2-ext/showMemberv2.yaml', 'api-ref/source/networking/v2/updatePort.yaml', 'api-ref/source/share/v1/resetShareInstanceState.yaml', 'api-ref/source/database/v1/samples/db-list-parameters-request-json-http.txt', 'api-ref/source/database/v1/listConfigDefaults.yaml', 'api-ref/source/database/v1/samples/db-config-group-instances-response.json', 'api-ref/source/identity/v3/samples/admin/project-show-response.json', 'api-ref/source/database/v1/samples/db-version-response.json', 'api-ref/source/identity/v2-admin/admin-deleteToken.yaml', 'api-ref/source/clustering/v1/samples/node-recover-request.json', 'api-ref/source/database/v1/samples/db-delete-root-response-json-http.txt', 'api-ref/source/blockstorage/v2/showVolume.yaml', 'api-ref/source/networking/v2-ext/listIPSecPolicies.yaml', 'api-ref/source/networking/v2/samples/qos/policy-create-request.json', 'api-ref/source/database/v1/samples/db-flavors-request-json-http.txt', 'api-ref/source/identity/v2-admin/admin-checkToken.yaml', 'api-ref/source/clustering/v1/samples/policy-type-show-response.json', 'api-ref/source/identity/v2-ext/validateToken.yaml', 'api-ref/source/identity/v3-ext/showPolicyForEndpoint.yaml', 'api-ref/source/blockstorage/v1/createVolumeType.yaml', 'api-ref/source/database/v1/samples/db-attach-config-grp-request.json', 'api-ref/source/networking/v2/samples/routers/router-remove-interface-response.json', 'api-ref/source/identity/v3/showDomainConfig.yaml', 'api-ref/source/identity/v3-ext/createKey.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-update-response.xml', 'api-ref/source/identity/v3-ext/createGroup.yaml', 'api-ref/source/identity/v3/samples/OS-INHERIT/role-assignments-list-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-import-response.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-update-request.json', 'api-ref/source/image/v2/createTask-v2.yaml', 'api-ref/source/database/v1/listVersions-dbaas-v1.yaml', 'api-ref/source/image/v1/addMember-v1.yaml', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/member-create-request.json', 'api-ref/source/share/v1/resetConsistencyGroupSnapshotState.yaml', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-create-response.json', 'api-ref/source/share/v1/samples/manila-share-networks-list-detailed-response.json', 'api-ref/source/networking/v2-ext/deletePoolv2.yaml', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-create-response.json', 'api-ref/source/identity/v3/deleteProjectSubtree.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/role-create-request.json', 'api-ref/source/clustering/v1/clustering-v1-clusters.inc', 'api-ref/source/data-processing/v1.1/job-binaries-show.yaml', 'api-ref/source/networking/v2/createPort.yaml', 'api-ref/source/clustering/v1/samples/build-show-response.json', 'api-ref/source/networking/v2-ext/metering-labels-ext.inc', 'api-ref/source/identity/v3/createService.yaml', 'api-ref/source/telemetry/v2/samples/event-show-response.json', 'api-ref/source/identity/v3/samples/admin/users-list-response.json', 'api-ref/source/networking/v2-ext/deleteIPSecPolicy.yaml', 'api-ref/source/telemetry/v2/resources.inc', 'api-ref/source/orchestration/v1/resource_list.yaml', 'api-ref/source/blockstorage/v2/removeVolumeTypeAccessExt.yaml', 'api-ref/source/share/v1/enableService.yaml', 'api-ref/source/database/v1/listConfigGroups.yaml', 'api-ref/source/identity/v2-ext/deleteRole.yaml', 'api-ref/source/data-processing/v1.1/showNodeGroupTemplate.yaml', 'api-ref/source/identity/v3/listDomainGroupRoles.yaml', 'api-ref/source/database/v1/samples/db-instance-eject-replica-request-json-http.txt', 'api-ref/source/identity/v3/samples/admin/credential-show-response.json', 'api-ref/source/database/v1/showParameterDetails.yaml', 'api-ref/source/orchestration/v1/stack_adopt.yaml', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-create-request.json', 'api-ref/source/clustering/v1/listProfiles.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-show-response.xml', 'api-ref/source/image/v2/showMetadefTagSchema.yaml', 'api-ref/source/networking/v2/samples/qos/policy-create-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-response.xml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-response.xml', 'api-ref/source/identity/v3/listUserGroups.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-unmanage-request.json', 'api-ref/source/networking/v2-ext/createIPSecSiteConnection.yaml', 'api-ref/source/clustering/v1/listProfileTypes.yaml', 'api-ref/source/telemetry/v2/showAlarm.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-rule-delete-request-json-http.txt', 'api-ref/source/telemetry/v2/samples.inc', 'api-ref/source/identity/v2/samples/OS-KSADM/tenantwithoutid-create-request.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-unset-request.json', 'api-ref/source/networking/v2-ext/networks-vlan-transparency-ext.inc', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplate-show-response.json', 'api-ref/source/share/v1/pools.inc', 'api-ref/source/orchestration/v1/software_deployment_create.yaml', 'api-ref/source/blockstorage/v2/manageExisting.yaml', 'api-ref/source/telemetry/v2/samples/sample-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpointTemplateWithOnlyId-create-request.json', 'api-ref/source/data-processing/v1.1/samples/jobs/jobs-list-response.json', 'api-ref/source/share/v1/samples/manila-share-show-metadata-response.json', 'api-ref/source/image/v2/samples/image-members-list-response.json', 'api-ref/source/blockstorage/v2/createVolumeType.yaml', 'api-ref/source/identity/v2-ext/revokeGlobalRoleFromUser.yaml', 'api-ref/source/identity/v2-ext/revokeRoleFromUserOnTenant.yaml', 'api-ref/source/networking/v2/samples/routers/router-show-response.json', 'api-ref/source/share/v1/removeSecurityService.yaml', 'api-ref/source/identity/v3/samples/admin/region-show-response.json', 'api-ref/source/blockstorage/v1/updateVolumeType.yaml', 'api-ref/source/identity/v2/samples/OS-KSEC2/ec2Credentials-show-response.json', 'api-ref/source/share/v1/resetShareState.yaml', 'api-ref/source/database/v1/samples/db-update-config-grp-request.json', 'api-ref/source/share/v1/deleteConsistencyGroup.yaml', 'api-ref/source/database/v1/samples/db-list-cfg-groups-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-request-json-http.txt', 'api-ref/source/networking/v2/samples/networks/versions-list-response.json', 'api-ref/source/identity/v2-ext/deleteEndpoint.yaml', 'api-ref/source/orchestration/v1/samples/deployments-list-response.json', 'api-ref/source/baremetal/v1/baremetal-api-v1-nodes.inc', 'api-ref/source/database/v1/samples/db-versions-response.json', 'api-ref/source/objectstorage/v1/samples/goodbyeworld.txt', 'api-ref/source/objectstorage/v1/showAccountDetails.yaml', 'api-ref/source/identity/v3/deleteGroup.yaml', 'api-ref/source/blockstorage/v2/createConsistencyGroupFromSource.yaml', 'api-ref/source/orchestration/v1/samples/stack-show-output-response.json', 'api-ref/source/database/v1/samples/db-delete-databases-response-json-http.txt', 'api-ref/source/image/v2/samples/schema-image-show-response.json', 'api-ref/source/networking/v2-ext/listQuotas.yaml', 'api-ref/source/networking/v2/samples/tag/tag-update-response.json', 'api-ref/source/share/v1/createConsistencyGroupSnapshot.yaml', 'api-ref/source/image/v2/createResourceTypeAssoc-v2.yaml', 'api-ref/source/identity/v2-admin/admin-users.inc', 'api-ref/source/orchestration/v1/stacks.inc', 'api-ref/source/share/v1/samples/manila-snapshots-list-response.json', 'api-ref/source/networking/v2/deleteNetwork.yaml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitors-list-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-response.xml', 'api-ref/source/identity/v3/checkDomainUserRole.yaml', 'api-ref/source/data-processing/v1.1/samples/job-binary-internals/show-response.json', 'api-ref/source/identity/v2/samples/client/authenticate-response.json', 'api-ref/source/identity/v3/showRole.yaml', 'api-ref/source/share/v1/share-versions.inc', 'api-ref/source/database/v1/samples/db-attach-config-grp-response-json-http.txt', 'api-ref/source/identity/v3/samples/OS-OAUTH1/access-token-show-response.json', 'api-ref/source/networking/v2/samples/ports/ports-list-response.json', 'api-ref/source/share/v1/deleteConsistencyGroupSnapshot.yaml', 'api-ref/source/identity/v2-ext/kscatalog.inc', 'api-ref/source/clustering/v1/samples/profile-show-response.json', 'api-ref/source/orchestration/v1/samples/config-create-response.json', 'api-ref/source/identity/v3-ext/associatePolicyAndService.yaml', 'api-ref/source/networking/v2-ext/createListenerv2.yaml', 'api-ref/source/image/v2/deactivateImage-v2.yaml', 'api-ref/source/blockstorage/v2/listSnapshots.yaml', 'api-ref/source/identity/v3/samples/admin/policy-create-request.json', 'api-ref/source/blockstorage/v2/samples/limits/limits-show-response.xml', 'api-ref/source/identity/v3/samples/admin/group-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-image-metadata-unset-request.json', 'api-ref/source/identity/v2/samples/client/authenticate-credentials-request.json', 'api-ref/source/share/v1/samples/manila-share-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-manage/volume-manage-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-create-response.json', 'api-ref/source/identity/v2-ext/parameters.yaml', 'api-ref/source/data-processing/v1.1/updateCluster.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-create-response.json', 'api-ref/source/image/v2/samples/schemas-images-list-response.json', 'api-ref/source/networking/v2/showPort.yaml', 'api-ref/source/identity/v3-ext/listRolesForUser-domain.yaml', 'api-ref/source/identity/v3/samples/admin/role-create-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-request.xml', 'api-ref/source/blockstorage/v2/samples/backups/backups-list-detailed-response.json', 'api-ref/source/database/v1/samples/db-instance-resize-flavor-request.json', 'api-ref/source/clustering/v1/samples/cluster-policy-attach-request.json', 'api-ref/source/identity/v3/samples/admin/credential-update-response.json', 'api-ref/source/share/v1/share-share-servers.inc', 'api-ref/source/blockstorage/v1/samples/volumes/volume-type-show-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-project-scoped-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-defaults-response.xml', 'api-ref/source/clustering/v1/showPolicy.yaml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-create-request.json', 'api-ref/source/networking/v2/samples/quotas/quotas-update-response.json', 'api-ref/source/image/v2/deleteResourceTypeAssoc-v2.yaml', 'api-ref/source/blockstorage/v2/deleteBackup.yaml', 'api-ref/source/image/v2/samples/image-details-deactivate-response.json', 'api-ref/source/identity/v3/samples/admin/service-show-response.json', 'api-ref/source/blockstorage/v1/updateQuota.yaml', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-detailed-response.xml', 'api-ref/source/share/v1/share-createShareType.yaml', 'api-ref/source/image/v2/showImageFile-v2.yaml', 'api-ref/source/data-processing/v1.1/jobbinaries.inc', 'api-ref/source/database/v1/samples/db-create-instance-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-templates-list-response.json', 'api-ref/source/image/v2/listResourceTypes-v2.yaml', 'api-ref/source/networking/v2-ext/listHealthMonitorsv2.yaml', 'api-ref/source/share/v1/deleteShareServer.yaml', 'api-ref/source/clustering/v1/deletePolicy.yaml', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-swift-request.json', 'api-ref/source/data-processing/v1.1/listClusters.yaml', 'api-ref/source/baremetal/v1/createNode.yaml', 'api-ref/source/identity/v3/createPolicy.yaml', 'api-ref/source/clustering/v1/samples/policy-show-response.json', 'api-ref/source/identity/v3/showPolicy.yaml', 'api-ref/source/share/v1/samples/manila-share-update-request.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-update-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-update-request.json', 'api-ref/source/share/v1/samples/manila-share-server-show-response.json', 'api-ref/source/database/v1/samples/db-list-datastore-versions.json', 'api-ref/source/share/v1/samples/manila-share-type-create-response.json', 'api-ref/source/image/v2/deleteObject-v2.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-list-response.json', 'api-ref/source/blockstorage/v2/samples/capabilities/backend-capabilities-response.json', 'api-ref/source/data-processing/v1.1/createNodeGroupTemplate.yaml', 'api-ref/source/baremetal/v1/updateNode.yaml', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-show-response.json', 'api-ref/source/identity/v2/authenticate-v2.0.yaml', 'api-ref/source/image/v2/showNamespace-v2.yaml', 'api-ref/source/networking/v2-ext/listMeteringLabels.yaml', 'api-ref/source/networking/v2-ext/listRouters.yaml', 'api-ref/source/orchestration/v1/samples/resource-show-response.json', 'api-ref/source/identity/v3/samples/admin/identity-version-response.json', 'api-ref/source/networking/v2-ext/deleteMeteringLabel.yaml', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-response.json', 'api-ref/source/share/v1/forceshare-deleteSnapshot.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumers-create-request.json', 'api-ref/source/database/v1/samples/db-flavors-by-id-response.json', 'api-ref/source/data-processing/v1.1/job-executions-refresh.yaml', 'api-ref/source/identity/v3/samples/admin/credential-create-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-response.xml', 'api-ref/source/identity/v2-ext/listEndpoints.yaml', 'api-ref/source/database/v1/samples/db-create-databases-request-json-http.txt', 'api-ref/source/networking/v2-ext/extensions.inc', 'api-ref/source/identity/v3/samples/OS-INHERIT/user-roles-list-response.json', 'api-ref/source/share/v1/share-share-instances.inc', 'api-ref/source/identity/v3-ext/deleteGroup.yaml', 'api-ref/source/orchestration/v1/samples/stack-show-snapshot-response.json', 'api-ref/source/share/v1/samples/manila-share-actions-revoke-access-request.json', 'api-ref/source/networking/v2-ext/listPoolsv2.yaml', 'api-ref/source/identity/v2/samples/admin/extensions-list-response.json', 'api-ref/source/blockstorage/v2/listQoSSpecs.yaml', 'api-ref/source/identity/v3-ext/deletePolicyAndServiceRegionAssociation.yaml', 'api-ref/source/orchestration/v1/listVersions-heat-v1.yaml', 'api-ref/source/baremetal/v1/showPort.yaml', 'api-ref/source/image/v2/samples/metadef-resource-types-list-response.json', 'api-ref/source/share/v1/listSecurityServices.yaml', 'api-ref/source/blockstorage/v1/volumes-v1-volumes.inc', 'api-ref/source/database/v1/samples/db-list-parameters-response.json', 'api-ref/source/share/v1/unmanageShare.yaml', 'api-ref/source/database/v1/samples/db-instance-promote-replica-request-json-http.txt', 'api-ref/source/share/v1/showSecurityService.yaml', 'api-ref/source/networking/v2/samples/routers/floatingip-update-response.json', 'api-ref/source/identity/v3-ext/revokeRoleFromUser-domain.yaml', 'api-ref/source/networking/v2/samples/ports/port-bind-create-update-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-delete-request.json', 'api-ref/source/identity/v2/samples/admin/authenticate-response.json', 'api-ref/source/networking/v2/samples/subnets/subnetpool-update-request.json', 'api-ref/source/identity/v2-ext/createEndpoint.yaml', 'api-ref/source/networking/v2/samples/flavors/service-profile-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSS3/s3Credentials-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-update-request.json', 'api-ref/source/clustering/v1/samples/cluster-update-request.json', 'api-ref/source/identity/v3/samples/admin/domain-update-request.json', 'api-ref/source/blockstorage/v2/showQuotaDetailUser.yaml', 'api-ref/source/identity/v2/versions.inc', 'api-ref/source/data-processing/v1.1/removeTags.yaml', 'api-ref/source/database/v1/samples/db-update-config-grp-request-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/job-executions/list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-extend-request.json', 'api-ref/source/database/v1/samples/db-list-datastore-versions-request-json-http.txt', 'api-ref/source/share/v1/listConsistencyGroupsnapshot.yaml', 'api-ref/source/identity/v3/grantProjectUserRole.yaml', 'api-ref/source/networking/v2/samples/flavors/service-profile-create-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-create-request.json', 'api-ref/source/share/v1/createSecurityService.yaml', 'api-ref/source/baremetal/v1/samples/chassis-show-response.json', 'api-ref/source/identity/v3/createEndpoint.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-request.xml', 'api-ref/source/clustering/v1/samples/cluster-create-response.json', 'api-ref/source/identity/v3/samples/OS-TRUST/trust-create-response.json', 'api-ref/source/share/v1/listConsistencyGroupsnapshotsDetails.yaml', 'api-ref/source/data-processing/v1.1/samples/jobs/job-execute-request.json', 'api-ref/source/image/v1/samples/image-members-add-request.json', 'api-ref/source/networking/v2/samples/networks/networks-multi-list-response.json', 'api-ref/source/clustering/v1/samples/events-list-response.json', 'api-ref/source/image/v2/samples/metadef-namespace-update-response.json', 'api-ref/source/objectstorage/v1/updateContainerMeta.yaml', 'api-ref/source/identity/v2-ext/listEndpointsForToken.yaml', 'api-ref/source/share/v1/samples/manila-quota-update-request.json', 'api-ref/source/share/v1/samples/manila-share-networks-list-response.json', 'api-ref/source/networking/v2-ext/deletePort.yaml', 'api-ref/source/blockstorage/v2/samples/user-quotas-show-response.xml', 'api-ref/source/image/v2/storeImageFile-v2.yaml', 'api-ref/source/share/v1/samples/manila-share-network-show-response.json', 'api-ref/source/blockstorage/v2/samples/host-attach-request.json', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-groups-list-detailed-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-request.xml', 'api-ref/source/image/v1/samples/image-memberships-list-response.json', 'api-ref/source/telemetry/v2/createAlarm.yaml', 'api-ref/source/networking/v2/samples/flavors/flavor-update-response.json', 'api-ref/source/blockstorage/v2/updateVolumeType.yaml', 'api-ref/source/blockstorage/v2/ext-backups.inc', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-create-response.json', 'api-ref/source/identity/v3/createConsumer.yaml', 'api-ref/source/blockstorage/v1/deleteQuotas.yaml', 'api-ref/source/blockstorage/v2/deleteSnapshot.yaml', 'api-ref/source/share/v1/createShare.yaml', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-response.xml', 'api-ref/source/baremetal/v1/showDriverProperties.yaml', 'api-ref/source/networking/v2-ext/showSecGroup.yaml', 'api-ref/source/clustering/v1/samples/profile-update-response.json', 'api-ref/source/networking/v2-ext/updatePort.yaml', 'api-ref/source/share/v1/quota-sets-listDefaultQuotas.yaml', 'api-ref/source/identity/v3/createGroup.yaml', 'api-ref/source/image/v2/samples/schema-metadef-properties-list-response.json', 'api-ref/source/data-processing/v1.1/updateDataSource.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/request-token-create-response.txt', 'api-ref/source/database/v1/patchConfigGroup.yaml', 'api-ref/source/identity/v2-admin/admin-tokens.inc', 'api-ref/source/networking/v2-ext/listLoadBalancersv2.yaml', 'api-ref/source/networking/v2/samples/lbaas/loadbalancer-update-response.txt', 'api-ref/source/blockstorage/v2/associateQoSSpec.yaml', 'api-ref/source/blockstorage/v2/samples/os-vol-image-meta/image-metadata-show-request.json', 'api-ref/source/share/v1/samples/manila-snapshot-actions-force-delete-request.json', 'api-ref/source/clustering/v1/samples/receivers-list-response.json', 'api-ref/source/baremetal/v1/listDrivers.yaml', 'api-ref/source/networking/v2-ext/deleteMeteringLabelRule.yaml', 'api-ref/source/image/v2/samples/metadef-tags-list-response.json', 'api-ref/source/identity/v3/samples/admin/policy-show-response.json', 'api-ref/source/blockstorage/v2/showVolumeMetadata.yaml', 'api-ref/source/blockstorage/v2/createBackup.yaml', 'api-ref/source/blockstorage/v2/listVolumeTransfer.yaml', 'api-ref/source/database/v1/samples/db-instances-index-response.json', 'api-ref/source/identity/v3/deleteRegion.yaml', 'api-ref/source/clustering/v1/samples/receiver-create-response.json', 'api-ref/source/image/v2/samples/metadef-object-update-response.json', 'api-ref/source/image/v2/addImageTag-v2.yaml', 'api-ref/source/networking/v2-ext/deleteSecGroupRule.yaml', 'api-ref/source/identity/v2-ext/showRoleByName.yaml', 'api-ref/source/orchestration/v1/resource_type_list.yaml', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-export-response.json', 'api-ref/source/networking/v2-ext/networking-ip-availability-ext.inc', 'api-ref/source/identity/v3/samples/admin/endpoint-create-response.json', 'api-ref/source/clustering/v1/createNode.yaml', 'api-ref/source/identity/v2/listExtensions.yaml', 'api-ref/source/share/v1/setExtraSpecShareType.yaml', 'api-ref/source/telemetry/v2/samples/samples-list-response.xml', 'api-ref/source/identity/v3/updateConsumer.yaml', 'api-ref/source/data-processing/v1.1/showClusterProgress.yaml', 'api-ref/source/networking/v2-ext/createFirewallPolicy.yaml', 'api-ref/source/blockstorage/v2/listVolumeTypeAccessExt.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-show-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshots-list-response.xml', 'api-ref/source/identity/v3/updateEndpoint.yaml', 'api-ref/source/identity/v3/samples/admin/user-groups-list-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-response.json', 'api-ref/source/database/v1/samples/db-instance-promote-replica-response-json-http.txt', 'api-ref/source/networking/v2-ext/listVIPs.yaml', 'api-ref/source/identity/v3/deletePolicy.yaml', 'api-ref/source/orchestration/v1/stack_show_snapshot.yaml', 'api-ref/source/database/v1/showFlavorById.yaml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-create-response.json', 'api-ref/source/database/v1/samples/db-patch-config-grp-request-json-http.txt', 'api-ref/source/share/v1/share-os-share-manage.inc', 'api-ref/source/identity/v3/showUser.yaml', 'api-ref/source/data-processing/v1.1/job-binaries-create.yaml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-associate-request.json', 'api-ref/source/telemetry/v2/alarms.inc', 'api-ref/source/blockstorage/v2/updateSnapshotMetadata.yaml', 'api-ref/source/share/v1/samples/manila-share-create-request.json', 'api-ref/source/database/v1/samples/db-list-cfg-defaults-response-json-http.txt', 'api-ref/source/identity/v2-ext/listEndpointTemplates.yaml', 'api-ref/source/data-processing/v1.1/job-binary-internals-create.yaml', 'api-ref/source/telemetry/v2/samples/resource-show-response.json', 'api-ref/source/blockstorage/v2/createQoSSpec.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-create-request.json', 'api-ref/source/orchestration/v1/build_info_show.yaml', 'api-ref/source/clustering/v1/samples/action-show-response.json', 'api-ref/source/share/v1/listExtraSpecsShareType.yaml', 'api-ref/source/orchestration/v1/stack_resources_find.yaml', 'api-ref/source/orchestration/v1/samples/template-versions-response.json', 'api-ref/source/image/v2/samples/image-show-response.json', 'api-ref/source/share/v1/showShareServer.yaml', 'api-ref/source/identity/v2-ext/showRoleByID.yaml', 'api-ref/source/orchestration/v1/stack_list_snapshot.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-detailed-response.xml', 'api-ref/source/share/v1/listAccessRules.yaml', 'api-ref/source/database/v1/samples/db-show-parameter-details.json', 'api-ref/source/networking/v2-ext/updateVpnEndpointGroup.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volumes-list-response.json', 'api-ref/source/database/v1/listConfigDetails.yaml', 'api-ref/source/blockstorage/v2/showVolumeType.yaml', 'api-ref/source/database/v1/samples/db-detach-replica-request.json', 'api-ref/source/identity/v3-ext/getPolicyAndServiceAssociation.yaml', 'api-ref/source/networking/v2-ext/showProviderNetwork.yaml', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-show-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/services-list-response.json', 'api-ref/source/networking/v2-ext/disassociateFlavor.yaml', 'api-ref/source/objectstorage/v1/createOrReplaceObject.yaml', 'api-ref/source/blockstorage/v2/samples/user-quotas-show-response.json', 'api-ref/source/data-processing/v1.1/registerImage.yaml', 'api-ref/source/identity/v3-ext/inherit.inc', 'api-ref/source/identity/v3/authenticateTokenUnscoped.yaml', 'api-ref/source/blockstorage/v1/listSnapshots.yaml', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-response.xml', 'api-ref/source/database/v1/datastores.inc', 'api-ref/source/networking/v2-ext/updateListenerv2.yaml', 'api-ref/source/blockstorage/v2/os-vol-transfer-v2.inc', 'api-ref/source/data-processing/v1.1/samples/job-binaries/show-response.json', 'api-ref/source/clustering/v1/showCluster.yaml', 'api-ref/source/blockstorage/v2/deleteVolume.yaml', 'api-ref/source/image/v2/samples/image-member-update-response.json', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfers-list-detailed-response.json', 'api-ref/source/image/v1/versions.inc', 'api-ref/source/image/v2/samples/task-show-response.json', 'api-ref/source/networking/v2-ext/network-provider.inc', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-create-request.json', 'api-ref/source/orchestration/v1/samples/stack-action-check-request.json', 'api-ref/source/blockstorage/v1/samples/volumes/volume-create-request.json', 'api-ref/source/identity/v3/samples/admin/auth-password-explicit-unscoped-request.json', 'api-ref/source/database/v1/database-instances.inc', 'api-ref/source/share/v1/samples/manila-share-create-response.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-create-request.json', 'api-ref/source/networking/v2-ext/security_group_rules.inc', 'api-ref/source/share/v1/samples/manila-share-network-add-security-service-request.json', 'api-ref/source/share/v1/showShareInstance.yaml', 'api-ref/source/identity/v3/regions-v3.inc', 'api-ref/source/database/v1/samples/db-create-instance-request-json-http.txt', 'api-ref/source/networking/v2/samples/qos/rule_types-list-response.json', 'api-ref/source/blockstorage/v2/updateQuota.yaml', 'api-ref/source/share/v1/deleteSecurityService.yaml', 'api-ref/source/identity/v3/samples/admin/project-group-roles-list-response.json', 'api-ref/source/networking/v2/samples/qos/dscp_marking_rule-create-request.json', 'api-ref/source/baremetal/v1/deleteNode.yaml', 'api-ref/source/networking/v2/removePort.yaml', 'api-ref/source/networking/v2/samples/flavors/flavor-create-response.json', 'api-ref/source/networking/v2/samples/networks/networks-bulk-create-request.json', 'api-ref/source/data-processing/v1.1/samples/clusters/clusters-list-response.json', 'api-ref/source/orchestration/v1/samples/config-show-response.json', 'api-ref/source/share/v1/setShareMetadata.yaml', 'api-ref/source/networking/v2/samples/flavors/flavors-list-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-list-detailed-response.json', 'api-ref/source/blockstorage/v2/createVolume.yaml', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-show-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-user-name-unscoped-response-HTTP.txt', 'api-ref/source/database/v1/samples/db-create-config-grp-request-json-http.txt', 'api-ref/source/networking/v2/samples/networks/network-vlan-transparent-show-response.json', 'api-ref/source/identity/v3/samples/admin/domain-update-response.json', 'api-ref/source/networking/v2-ext/deleteMemberv2.yaml', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-list-response.json', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-response.json', 'api-ref/source/identity/v2-admin/admin-showTenantByName.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos_show_response.json', 'api-ref/source/networking/v2-ext/createMeteringLabel.yaml', 'api-ref/source/clustering/v1/createPolicy.yaml', 'api-ref/source/orchestration/v1/stack_create.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-update-response.json', 'api-ref/source/identity/v3/showDomainConfigGroupOption.yaml', 'api-ref/source/image/v2/samples/images-list-response.json', 'api-ref/source/blockstorage/v1/samples/volumes/snapshot-metadata-update-response.xml', 'api-ref/source/share/v1/samples/manila-share-instances-list-response.json', 'api-ref/source/blockstorage/v2/showQoSDetails.yaml', 'api-ref/source/identity/v3/samples/admin/project-create-request.json', 'api-ref/source/image/v2/samples/schema-metadef-namespaces-list-response.json', 'api-ref/source/share/v1/listShareNetworksDetails.yaml', 'api-ref/source/networking/v2-ext/listListenersv2.yaml', 'api-ref/source/identity/v3/deleteDomain.yaml', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-list-response.json', 'api-ref/source/baremetal/v1/updateChassis.yaml', 'api-ref/source/clustering/v1/samples/profile-create-request.json', 'api-ref/source/blockstorage/v2/os-vol-pool-v2.inc', 'api-ref/source/identity/v3/identity_v3_OS-OAUTH1.inc', 'api-ref/source/identity/v3/updateDomainConfigGroup.yaml', 'api-ref/source/orchestration/v1/samples/deployment-show-response.json', 'api-ref/source/image/v2/samples/metadef-object-details-response.json', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-show-response.json', 'api-ref/source/identity/v3/samples/admin/group-show-response.json', 'api-ref/source/networking/v2-ext/createMultiNetwork.yaml', 'api-ref/source/networking/v2-ext/disassociateHealthMonitor.yaml', 'api-ref/source/database/v1/samples/db-config-group-details-response-json-http.txt', 'api-ref/source/identity/v3/samples/admin/credentials-list-response.json', 'api-ref/source/baremetal/v1/samples/chassis-list-response.json', 'api-ref/source/baremetal/v1/deleteChassis.yaml', 'api-ref/source/clustering/v1/samples/event-show-response.json', 'api-ref/source/telemetry/v2/capabilities.inc', 'api-ref/source/networking/v2-ext/deletePolicy.yaml', 'api-ref/source/networking/v2-ext/updatePolicy.yaml', 'api-ref/source/share/v1/shrinkShare.yaml', 'api-ref/source/share/v1/share-manageSnapshot.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/service-show-response.json', 'api-ref/source/networking/v2/samples/lbaas/vips-list-response.json', 'api-ref/source/data-processing/v1.1/createMultipleClusters.yaml', 'api-ref/source/identity/v3/showConsumer.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/multiple-clusters-create-request.json', 'api-ref/source/clustering/v1/deleteReceiver.yaml', 'api-ref/source/share/v1/quota-sets-deleteQuota.yaml', 'api-ref/source/identity/v2-admin/admin-authenticate.yaml', 'api-ref/source/networking/v2/samples/networks/network-provider-update-response.json', 'api-ref/source/blockstorage/v2/listPools.yaml', 'api-ref/source/data-processing/v1.1/samples/clusters/cluster-create-response.json', 'api-ref/source/image/v2/updateObject-v2.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/user-update-request.json', 'api-ref/source/networking/v2/samples/vpn/ikepolicies-list-response.json', 'api-ref/source/identity/v3/samples/admin/project-enable-request.json', 'api-ref/source/networking/v2/samples/networks/network-create-response.json', 'api-ref/source/share/v1/share-share-networks.inc', 'api-ref/source/clustering/v1/showProfileType.yaml', 'api-ref/source/identity/v3/domains-config-v3.inc', 'api-ref/source/share/v1/samples/manila-versions-response.json', 'api-ref/source/identity/v3/samples/admin/identity-versions-response.json', 'api-ref/source/share/v1/listConsistencyGroups.yaml', 'api-ref/source/networking/v2-ext/createServiceProfile.yaml', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-show-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-show-response.json', 'api-ref/source/identity/v3/createRegion.yaml', 'api-ref/source/image/v2/samples/schema-metadef-namespace-show-response.json', 'api-ref/source/share/v1/samples/manila-security-service-create-response.json', 'api-ref/source/identity/v2-ext/deleteUserCredential.yaml', 'api-ref/source/networking/v2/samples/routers/router-remove-interface-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-labels-list-response.json', 'api-ref/source/networking/v2/samples/routers/floating-ips-list-response.json', 'api-ref/source/share/v1/showConsistencyGroup.yaml', 'api-ref/source/blockstorage/v2/listVolumesDetail.yaml', 'api-ref/source/networking/v2-ext/showIPSecSiteConnection.yaml', 'api-ref/source/blockstorage/v2/samples/backups/backup-record-import-request.json', 'api-ref/source/identity/v3/deleteEndpoint.yaml', 'api-ref/source/networking/v2/samples/networks/networks-vlan-transparent-list-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-update-response.json', 'api-ref/source/data-processing/v1.1/createCluster.yaml', 'api-ref/source/database/v1/samples/db-enable-root-user-response.json', 'api-ref/source/image/v2/reactivateImage-v2.yaml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-response.json', 'api-ref/source/networking/v2/samples/lbaas/pool-show-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-update-response.json', 'api-ref/source/identity/v3/samples/admin/role-update-response.json', 'api-ref/source/orchestration/v1/samples/stacks-list-response.json', 'api-ref/source/networking/v2/samples/networks/network-multi-create-response.json', 'api-ref/source/networking/v2-ext/deleteFloatingIp.yaml', 'api-ref/source/networking/v2/listServiceProviders.yaml', 'api-ref/source/identity/v3/samples/OS-ENDPOINT-POLICY/policy-endpoint-associations-list-response.json', 'api-ref/source/identity/v3/samples/admin/region-update-request.json', 'api-ref/source/image/v2/addTag-v2.yaml', 'api-ref/source/networking/v2-ext/createProviderNetwork.yaml', 'api-ref/source/identity/v2/samples/admin/user-create-request.json', 'api-ref/source/data-processing/v1.1/clustertemplate.inc', 'api-ref/source/identity/v3/samples/OS-KDS/ticket-generate-request.json', 'api-ref/source/objectstorage/v1/samples/containers-list-http-response.txt', 'api-ref/source/database/v1/resizeInstance.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-show-request.json', 'api-ref/source/identity/v3/updateDomain.yaml', 'api-ref/source/identity/v2-admin/admin-listTenants.yaml', 'api-ref/source/data-processing/v1.1/samples/jobs/job-update-response.json', 'api-ref/source/networking/v2-ext/addRouterInterface.yaml', 'api-ref/source/networking/v2-ext/updateSubnetPool.yaml', 'api-ref/source/blockstorage/v2/deleteVolumeType.yaml', 'api-ref/source/networking/v2/samples/ports/ports-bind-show-response.json', 'api-ref/source/blockstorage/v2/samples/user-quotas-update-request.json', 'api-ref/source/identity/v3/samples/admin/auth-token-unscoped-request.json', 'api-ref/source/networking/v2-ext/ShowNetworkIpAvailability.yaml', 'api-ref/source/data-processing/v1.1/deleteCluster.yaml', 'api-ref/source/data-processing/v1.1/samples/image-registry/image-register-response.json', 'api-ref/source/database/v1/samples/db-instances-index-response-json-http.txt', 'api-ref/source/clustering/v1/listNodes.yaml', 'api-ref/source/networking/v2-ext/flavors-framework-v2.0.inc', 'api-ref/source/identity/v3/credentials.inc', 'api-ref/source/identity/v3-ext/showGroupKey.yaml', 'api-ref/source/baremetal/v1/listChassisDetail.yaml', 'api-ref/source/blockstorage/v2/ext-backups-actions-v2.inc', 'api-ref/source/orchestration/v1/general-info.inc', 'api-ref/source/blockstorage/v2/setVolumeimagemetadata.yaml', 'api-ref/source/networking/v2/samples/routers/router-update-request.json', 'api-ref/source/identity/v3-ext/assignRoleToGroup.yaml', 'api-ref/source/clustering/v1/listReceivers.yaml', 'api-ref/source/identity/v3/service-catalog.inc', 'api-ref/source/baremetal/v1/showNode.yaml', 'api-ref/source/blockstorage/v1/showQuota.yaml', 'api-ref/source/share/v1/showShare.yaml', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-defaults-response.json', 'api-ref/source/clustering/v1/samples/cluster-scale-out-nodes-request.json', 'api-ref/source/identity/v3/samples/OS-KDS/group-create-request.json', 'api-ref/source/identity/v3/updateRole.yaml', 'api-ref/source/database/v1/samples/db-instance-resize-volume-response-json-http.txt', 'api-ref/source/data-processing/v1.1/showDataSource.yaml', 'api-ref/source/orchestration/v1/samples/stack-show-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-user-show-detailed-response.json', 'api-ref/source/blockstorage/v2/volumes-v2-snapshots.inc', 'api-ref/source/networking/v2-ext/deleteFirewallRule.yaml', 'api-ref/source/database/v1/samples/db-instance-resize-flavor-response-json-http.txt', 'api-ref/source/identity/v3-ext/createTrust.yaml', 'api-ref/source/identity/v3/createRole.yaml', 'api-ref/source/database/v1/samples/db-list-datastore-versions-response-json-http.txt', 'api-ref/source/identity/v2-ext/updateTenant.yaml', 'api-ref/source/image/v2/listObjects-v2.yaml', 'api-ref/source/database/v1/createRoot.yaml', 'api-ref/source/identity/v3/samples/admin/user-projects-list-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-insert-rule-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-show-response.json', 'api-ref/source/share/v1/samples/manila-share-types-default-list-response.json', 'api-ref/source/networking/v2-ext/insert_ruleFirewallPolicy.yaml', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-template-update-response.json', 'api-ref/source/identity/v3/samples/admin/regions-list-response.json', 'api-ref/source/image/v1/showImage-v1.yaml', 'api-ref/source/orchestration/v1/samples/deployment-update-response.json', 'api-ref/source/blockstorage/v2/forcedetachVolume.yaml', 'api-ref/source/share/v1/force-deleteConsistencyGroupSnapshot.yaml', 'api-ref/source/orchestration/v1/samples/stack-update-request.json', 'api-ref/source/telemetry/v2/samples/alarms-list-response.json', 'api-ref/source/networking/v2-ext/showFloatingIp.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-update-response.json', 'api-ref/source/orchestration/v1/resource_type_template.yaml', 'api-ref/source/networking/v2-ext/deleteIPSecSiteConnection.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-manage/volume-manage-request.json', 'api-ref/source/share/v1/listLimits.yaml', 'api-ref/source/image/v2/createImageMember-v2.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-create-request.json', 'api-ref/source/database/v1/samples/db-delete-instance-response-json-http.txt', 'api-ref/source/telemetry/v2/showAlarmState.yaml', 'api-ref/source/clustering/v1/samples/cluster-check-request.json', 'api-ref/source/identity/v3/listRolesOfAccessToken.yaml', 'api-ref/source/identity/v2/samples/OS-KSS3/credentialswiths3-list-response.json', 'api-ref/source/networking/v2-ext/updateIKEPolicy.yaml', 'api-ref/source/share/v1/consistency-groups.inc', 'api-ref/source/networking/v2-ext/showServiceProfile.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-response.json', 'api-ref/source/database/v1/samples/db-delete-instance-request-json-http.txt', 'api-ref/source/clustering/v1/listClusters.yaml', 'api-ref/source/networking/v2/samples/lbaas/pool-members-list-response.json', 'api-ref/source/share/v1/addSecurityService.yaml', 'api-ref/source/image/v2/samples/schema-metadef-resource-type-association-show-response.json', 'api-ref/source/telemetry/v2/showResource.yaml', 'api-ref/source/blockstorage/v2/versionDetails.yaml', 'api-ref/source/networking/v2-ext/createPort.yaml', 'api-ref/source/image/v2/samples/image-create-request.json', 'api-ref/source/networking/v2/parameters.yaml', 'api-ref/source/data-processing/v1.1/samples/job-executions/cancel-response.json', 'api-ref/source/data-processing/v1.1/showJob.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/service-create-request.json', 'api-ref/source/identity/v2/samples/OS-KSCATALOG/endpoint-show-response.json', 'api-ref/source/networking/v2/samples/routers/floatingip-create-request.json', 'api-ref/source/networking/v2-ext/listMeteringLabelRules.yaml', 'api-ref/source/share/v1/migrate-share.inc', 'api-ref/source/share/v1/samples/manila-share-type-create-request.json', 'api-ref/source/blockstorage/v2/extendVolume.yaml', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-update-response.json', 'api-ref/source/networking/v2/samples/networks/network-create-request.json', 'api-ref/source/share/v1/deleteShareNetwork.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-policy-remove-rule-response.json', 'api-ref/source/orchestration/v1/samples/resource-schema-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-unmanage-request.json', 'api-ref/source/networking/v2-ext/deleteLoadBalancerv2.yaml', 'api-ref/source/blockstorage/v1/os-quota-sets-v1.inc', 'api-ref/source/database/v1/samples/db-list-cfg-groups-response-json-http.txt', 'api-ref/source/identity/v2-ext/kss3-admin.inc', 'api-ref/source/clustering/v1/deleteCluster.yaml', 'api-ref/source/clustering/v1/deleteNode.yaml', 'api-ref/source/identity/v3/samples/admin/project-update-response.json', 'api-ref/source/baremetal/v1/listNodesDetail.yaml', 'api-ref/source/database/v1/samples/db-flavors-response-json-http.txt', 'api-ref/source/database/v1/detachConfigGroup.yaml', 'api-ref/source/image/v2/updateImageMember-v2.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-show-response.xml', 'api-ref/source/database/v1/listDatabases.yaml', 'api-ref/source/data-processing/v1.1/clusters.inc', 'api-ref/source/identity/v2/showVersionInfo-v2.0.yaml', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rule-update-request.json', 'api-ref/source/baremetal/v1/listChassis.yaml', 'api-ref/source/identity/v3/samples/OS-KDS/key-create-response.json', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connections-list-response.json', 'api-ref/source/image/v1/showImageHeaders-v1.yaml', 'api-ref/source/image/v2/listProperties-v2.yaml', 'api-ref/source/networking/v2/samples/flavors/flavor-update-request.json', 'api-ref/source/identity/v3/samples/OS-INHERIT/group-roles-domain-list-response.json', 'api-ref/source/share/v1/samples/manila-security-service-create-request.json', 'api-ref/source/networking/v2/samples/routers/routers-list-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-response-xml.txt', 'api-ref/source/blockstorage/v2/unsetVolumeimagemetadata.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-show-response.json', 'api-ref/source/image/v2/members.inc', 'api-ref/source/image/v1/members.inc', 'api-ref/source/share/v1/samples/manila-share-servers-list-response.json', 'api-ref/source/baremetal/v1/showLogicalDiskProperties.yaml', 'api-ref/source/baremetal/v1/samples/chassis-list-details-response.json', 'api-ref/source/orchestration/v1/software_config_delete.yaml', 'api-ref/source/share/v1/share-services.inc', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rules-list-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-show-request-json-http.txt', 'api-ref/source/identity/v2/samples/admin/tenants-list-request-JSON.txt', 'api-ref/source/share/v1/samples/manila-share-type-set-request.json', 'api-ref/source/share/v1/samples/manila-snapshot-show-response.json', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-update-response.json', 'api-ref/source/clustering/v1/samples/node-update-response.json', 'api-ref/source/identity/v3/authenticateTokenScoped.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-groups-list-request-json-http.txt', 'api-ref/source/database/v1/samples/db-create-users-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicies-list-response.json', 'api-ref/source/orchestration/v1/stack_update_preview.yaml', 'api-ref/source/identity/v3/deleteDomainConfigGroup.yaml', 'api-ref/source/networking/v2-ext/createVPNService.yaml', 'api-ref/source/image/v2/showImageMember-v2.yaml', 'api-ref/source/objectstorage/v1/createContainer.yaml', 'api-ref/source/image/v2/updateTag-v2.yaml', 'api-ref/source/identity/v3/samples/admin/endpoint-show-response.json', 'api-ref/source/clustering/v1/clustering-v1-profile_types.inc', 'api-ref/source/identity/v2/samples/OS-KSADM/tenant-update-request.json', 'api-ref/source/blockstorage/v2/showSnapshotMetadata.yaml', 'api-ref/source/baremetal/v1/samples/chassis-create-request.json', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-update-request.json', 'api-ref/source/networking/v2/samples/routers/router-update-response.json', 'api-ref/source/identity/v3-ext/revokeRoleFromGroup-domain.yaml', 'api-ref/source/database/v1/samples/db-versions-response-json-http.txt', 'api-ref/source/image/v2/listImageMembers-v2.yaml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-update-response.json', 'api-ref/source/blockstorage/v2/listBackups.yaml', 'api-ref/source/networking/v2/samples/security-groups/security-group-delete-request-json-http.txt', 'api-ref/source/database/v1/deleteUser.yaml', 'api-ref/source/networking/v2-ext/listSecGroups.yaml', 'api-ref/source/data-processing/v1.1/jobs.inc', 'api-ref/source/share/v1/updateShareMetadata.yaml', 'api-ref/source/networking/v2/samples/lbaas/listener-update-response.json', 'api-ref/source/blockstorage/v2/limits.inc', 'api-ref/source/identity/v3/samples/admin/role-update-request.json', 'api-ref/source/identity/v3/samples/admin/endpoint-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-delete-request.xml', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-show-response.json', 'api-ref/source/data-processing/v1.1/updateJob.yaml', 'api-ref/source/blockstorage/v2/showAbsoluteLimits.yaml', 'api-ref/source/identity/v2/samples/OS-KSADM/user-show-response.json', 'api-ref/source/orchestration/v1/software_config_create.yaml', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-update-response.json', 'api-ref/source/identity/v2/samples/OS-KSADM/users-list-response.json', 'api-ref/source/orchestration/v1/samples/stack-create-response.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-create-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-response.json', 'api-ref/source/networking/v2-ext/deleteProviderNetwork.yaml', 'api-ref/source/blockstorage/v2/volumes-v2-types.inc', 'api-ref/source/identity/v3/showAuthorizedAccessToken.yaml', 'api-ref/source/telemetry/v2/listCapabilities.yaml', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-update-request.xml', 'api-ref/source/data-processing/v1.1/samples/job-binaries/update-response.json', 'api-ref/source/networking/v2-ext/createFlavor.yaml', 'api-ref/source/image/v1/replaceMember-v1.yaml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-update-response.xml', 'api-ref/source/identity/v3/samples/admin/group-users-list-response.json', 'api-ref/source/identity/v2-ext/updateEndpointTemplate.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-update-request.xml', 'api-ref/source/networking/v2-ext/deletePool.yaml', 'api-ref/source/networking/v2/createSubnet.yaml', 'api-ref/source/database/v1/detachReplica.yaml', 'api-ref/source/database/v1/samples/db-enable-root-user-request-json-http.txt', 'api-ref/source/blockstorage/v1/createSnapshot.yaml', 'api-ref/source/blockstorage/v2/setQoSKey.yaml', 'api-ref/source/telemetry/v2/listEvents.yaml', 'api-ref/source/identity/v3/updateService.yaml', 'api-ref/source/telemetry/v2/samples/statistics-list-response.json', 'api-ref/source/networking/v2/samples/vpn/vpnservice-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/listener-show-response.json', 'api-ref/source/orchestration/v1/stack_action_suspend.yaml', 'api-ref/source/objectstorage/v1/samples/capabilities-list-response.json', 'api-ref/source/identity/v3/updateUser.yaml', 'api-ref/source/database/v1/samples/db-detach-config-grp-response-json-http.txt', 'api-ref/source/orchestration/v1/samples/stack-action-cancel-update-request.json', 'api-ref/source/orchestration/v1/stack_action_resume.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-metadata-update-request.json', 'api-ref/source/clustering/v1/showClusterPolicy.yaml', 'api-ref/source/orchestration/v1/stack-actions.inc', 'api-ref/source/blockstorage/v1/samples/volumes/volume-create-request.xml', 'api-ref/source/identity/v3/revokeProjectUserRole.yaml', 'api-ref/source/objectstorage/v1/samples/objects-list-response.xml', 'api-ref/source/database/v1/samples/db-delete-root-request-json-http.txt', 'api-ref/source/identity/v3/grantProjectGroupRole.yaml', 'api-ref/source/blockstorage/v2/samples/backups/backup-create-response.json', 'api-ref/source/networking/v2-ext/showMember.yaml', 'api-ref/source/database/v1/samples/db-flavors-response.json', 'api-ref/source/networking/v2-ext/updateProviderNetwork.yaml', 'api-ref/source/blockstorage/v2/samples/consistencygroups/consistency-group-show-response.xml', 'api-ref/source/data-processing/v1.1/samples/clusters/multiple-clusters-create-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-create-request.json', 'api-ref/source/orchestration/v1/stack_snapshot.yaml', 'api-ref/source/clustering/v1/samples/cluster-update-response.json', 'api-ref/source/share/v1/samples/manila-snapshot-actions-reset-state-request.json', 'api-ref/source/orchestration/v1/software_deployment_update.yaml', 'api-ref/source/networking/v2/samples/lbaas/member-create-response.json', 'api-ref/source/objectstorage/v1/samples/account-containers-list-http-request-xml.txt', 'api-ref/source/blockstorage/v2/samples/backups/backups-list-response.json', 'api-ref/source/blockstorage/v2/disassociateQoSSpec.yaml', 'api-ref/source/blockstorage/v1/listSnapshotsDetail.yaml', 'api-ref/source/identity/v2-ext/listServices.yaml', 'api-ref/source/identity/v3/samples/admin/domain-config-group-update-request.json', 'api-ref/source/objectstorage/v1/infoDiscoverability.yaml', 'api-ref/source/share/v1/resetConsistencyGroupState.yaml', 'api-ref/source/networking/v2/samples/flavors/service-profile-update-response.json', 'api-ref/source/blockstorage/v2/samples/cgsnapshots/cgsnapshots-create-response.json', 'api-ref/source/identity/v2/parameters.yaml', 'api-ref/source/share/v1/samples/manila-share-types-list-access-response.json', 'api-ref/source/database/v1/samples/db-check-root-user-response-json-http.txt', 'api-ref/source/share/v1/disableService.yaml', 'api-ref/source/networking/v2/samples/qos/policy-update-request.json', 'api-ref/source/share/v1/listSecurityServicesDetails.yaml', 'api-ref/source/share/v1/migrateShare.yaml', 'api-ref/source/blockstorage/v2/listVersions.yaml', 'api-ref/source/database/v1/createConfigGroup.yaml', 'api-ref/source/blockstorage/v2/volumes-v2-volumes-actions.inc', 'api-ref/source/share/v1/samples/manila-services-list-response.json', 'api-ref/source/image/v2/showMetadefObjectSchema.yaml', 'api-ref/source/image/v2/samples/schema-metadef-tags-list-response.json', 'api-ref/source/telemetry/v2/samples/sample-create-request.xml', 'api-ref/source/identity/v3/deleteDomainConfig.yaml', 'api-ref/source/networking/v2-ext/showSubnetPool.yaml', 'api-ref/source/telemetry/v2/samples/resource-show-response.xml', 'api-ref/source/clustering/v1/showBuild.yaml', 'api-ref/source/clustering/v1/clustering-v1-cluster_policies.inc', 'api-ref/source/share/v1/listAvailabilityZones.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-shrink-request.json', 'api-ref/source/share/v1/samples/manila-service-enable-request.json', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-show-response.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-show-response.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-create-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-rule-show-response.json', 'api-ref/source/identity/v3-ext/associatePolicyAndEndpoint.yaml', 'api-ref/source/database/v1/resizeVolume.yaml', 'api-ref/source/identity/v3/samples/admin/user-password-update-request.json', 'api-ref/source/identity/v2/samples/admin/UserUpdatePasswordRequest.json', 'api-ref/source/orchestration/v1/samples/template-validate-response.json', 'api-ref/source/clustering/v1/clustering-v1-receivers.inc', 'api-ref/source/database/v1/samples/db-instance-resize-instance-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-show-response.json', 'api-ref/source/identity/v3/updateProject.yaml', 'api-ref/source/clustering/v1/samples/cluster-create-request.json', 'api-ref/source/image/v2/parameters.yaml', 'api-ref/source/networking/v2-ext/networks-multi-provider-ext.inc', 'api-ref/source/networking/v2/samples/ports/port-create-response.json', 'api-ref/source/orchestration/v1/samples/stack-adopt-request.json', 'api-ref/source/networking/v2-ext/extraroute.inc', 'api-ref/source/networking/v2-ext/quotas.inc', 'api-ref/source/telemetry/v2/parameters.yaml', 'api-ref/source/identity/v2-admin/admin-showTenantById.yaml', 'api-ref/source/data-processing/v1.1/samples/plugins/plugin-version-show-response.json', 'api-ref/source/identity/v3/samples/OS-KDS/group-create-response.json', 'api-ref/source/database/v1/samples/db-list-users-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/cluster-templates/cluster-template-update-response.json', 'api-ref/source/networking/v2/samples/networks/network-multi-create-request.json', 'api-ref/source/networking/v2/samples/lbaas/member-show-response.json', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-hdfs-request.json', 'api-ref/source/identity/v3/revokeProjectGroupRole.yaml', 'api-ref/source/clustering/v1/samples/cluster-add-nodes-request.json', 'api-ref/source/blockstorage/v2/samples/os-quota-sets/quotas-update-response.json', 'api-ref/source/database/v1/samples/db-create-users-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/jobs/job-update-request.json', 'api-ref/source/database/v1/user-management.inc', 'api-ref/source/networking/v2-ext/listFirewallPolicies.yaml', 'api-ref/source/networking/v2-ext/deleteServiceProfile.yaml', 'api-ref/source/networking/v2-ext/createMemberv2.yaml', 'api-ref/source/networking/v2/samples/vpn/vpn-endpoint-group-create-request.json', 'api-ref/source/networking/v2/listSubnets.yaml', 'api-ref/source/identity/v3/updateCredential.yaml', 'api-ref/source/identity/v2/samples/OS-KSVALIDATE/endpoints-list-response.json', 'api-ref/source/networking/v2-ext/listPolicies.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfers-list-response.json', 'api-ref/source/identity/v3/samples/admin/credential-create-request.json', 'api-ref/source/image/v2/listImages-v2.yaml', 'api-ref/source/image/v2/samples/schema-metadef-object-show-response.json', 'api-ref/source/data-processing/v1.1/deleteJob.yaml', 'api-ref/source/orchestration/v1/parameters.yaml', 'api-ref/source/identity/v3/samples/OS-OAUTH1/consumer-update-response.json', 'api-ref/source/clustering/v1/showNode.yaml', 'api-ref/source/share/v1/samples/manila-shares-list-response.json', 'api-ref/source/data-processing/v1.1/listPlugins.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-show-response.json', 'api-ref/source/orchestration/v1/samples/build-info-response.json', 'api-ref/source/orchestration/v1/software_deployment_delete.yaml', 'api-ref/source/database/v1/samples/db-enable-root-user-response-json-http.txt', 'api-ref/source/networking/v2/removeSubnet.yaml', 'api-ref/source/identity/v2-ext/showServiceByID.yaml', 'api-ref/source/share/v1/samples/manila-share-actions-reset-state-request.json', 'api-ref/source/networking/v2/samples/firewalls/firewall-show-response.json', 'api-ref/source/blockstorage/v1/showQuotaDefaults.yaml', 'api-ref/source/image/v2/samples/metadef-tag-details-response.json', 'api-ref/source/identity/v3/updateDomainConfig.yaml', 'api-ref/source/share/v1/share-showSnapshot.yaml', 'api-ref/source/blockstorage/v2/samples/volumes/volume-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-show-response.json', 'api-ref/source/identity/v3/updatePolicy.yaml', 'api-ref/source/orchestration/v1/software_deployment_index.yaml', 'api-ref/source/blockstorage/v1/samples/os-quota-sets/quotas-defaults-show-response.json', 'api-ref/source/identity/v3/samples/admin/auth-password-unscoped-request.json', 'api-ref/source/identity/v3/samples/admin/auth-password-explicit-unscoped-response.json', 'api-ref/source/baremetal/v1/samples/node-show-response.json', 'api-ref/source/identity/v3/listRoleAssignments.yaml', 'api-ref/source/share/v1/samples/manila-share-network-create-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/snapshot-metadata-show-response.json', 'api-ref/source/networking/v2/samples/lbaas/healthmonitor-update-request.json', 'api-ref/source/identity/v2-ext/listUsers.yaml', 'api-ref/source/blockstorage/v1/listVolumeTypes.yaml', 'api-ref/source/image/v2/samples/metadef-object-create-request.json', 'api-ref/source/identity/v3-ext/assignRoleToUser-domain.yaml', 'api-ref/source/identity/v2/samples/OS-KSS3/s3Credentials-show-response.json', 'api-ref/source/identity/v3/listPolicies.yaml', 'api-ref/source/objectstorage/v1/deleteObject.yaml', 'api-ref/source/orchestration/v1/stack_show.yaml', 'api-ref/source/networking/v2-ext/deleteVIP.yaml', 'api-ref/source/blockstorage/v2/showImageMetadataForVolume.yaml', 'api-ref/source/blockstorage/v1/updateQuotaUser.yaml', 'api-ref/source/identity/v3/samples/admin/policy-update-request.json', 'api-ref/source/networking/v2/samples/lbaas/pool-create-request.json', 'api-ref/source/blockstorage/v2/samples/backups/backup-restore-response.json', 'api-ref/source/clustering/v1/listClusterPolicies.yaml', 'api-ref/source/identity/v3/parameters.yaml', 'api-ref/source/identity/v2-ext/ksvalidate.inc', 'api-ref/source/identity/v3/authenticate-v3.inc', 'api-ref/source/share/v1/samples/manila-share-network-update-response.json', 'api-ref/source/networking/v2/samples/subnets/subnets-list-response.json', 'api-ref/source/telemetry/v2/updateAlarm.yaml', 'api-ref/source/identity/v3/samples/admin/role-assignments-list-response.txt', 'api-ref/source/image/v2/samples/schema-metadef-objects-list-response.json', 'api-ref/source/identity/v3/samples/admin/roles-list-response.json', 'api-ref/source/identity/v3/checkToken.yaml', 'api-ref/source/networking/v2/samples/qos/policies-list-response.json', 'api-ref/source/telemetry/v2/samples/alarm-show-response.xml', 'api-ref/source/identity/v2/samples/OS-KSADM/roles-list-response.json', 'api-ref/source/identity/v3-ext/deletePolicyAndServiceAssociation.yaml', 'api-ref/source/blockstorage/v2/samples/os-volume-transfer/volume-transfer-accept-request.json', 'api-ref/source/networking/v2-ext/listPorts.yaml', 'api-ref/source/blockstorage/v2/unsetQoSKey.yaml', 'api-ref/source/networking/v2-ext/showPoolv2.yaml', 'api-ref/source/networking/v2/samples/tag/tag-update-request.json', 'api-ref/source/image/v1/createImage-v1.yaml', 'api-ref/source/networking/v2/samples/vpn/ipsecpolicy-create-response.json', 'api-ref/source/share/v1/showShareMetadata.yaml', 'api-ref/source/blockstorage/v1/samples/os-user-quotas/user-quotas-show-detail-response.json', 'api-ref/source/identity/v3/samples/admin/auth-token-unscoped-response.json', 'api-ref/source/data-processing/v1.1/samples/node-group-templates/node-group-templates-list-response.json', 'api-ref/source/networking/v2-ext/listProviderNetworks.yaml', 'api-ref/source/blockstorage/v1/samples/volumes/versions-list-response.json', 'api-ref/source/identity/v3/authenticatePasswordExplicitUnscoped.yaml', 'api-ref/source/identity/v3/changeUserPassword.yaml', 'api-ref/source/networking/v2-ext/updateFirewallRule.yaml', 'api-ref/source/identity/v3-ext/assignRoleToUser.yaml', 'api-ref/source/share/v1/samples/manila-share-set-metadata-response.json', 'api-ref/source/database/v1/samples/db-show-parameter-details-request-json-http.txt', 'api-ref/source/blockstorage/v2/updateQuotaUser.yaml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-show-request-json-http.txt', 'api-ref/source/image/v2/schemas-metadefs-v2.inc', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-create-request.xml', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-delete-response-json-http.txt', 'api-ref/source/data-processing/v1.1/samples/job-binaries/create-request.json', 'api-ref/source/orchestration/v1/build-info.inc', 'api-ref/source/share/v1/samples/manila-share-show-instance-response.json', 'api-ref/source/networking/v2/samples/lbaas/vip-update-response.json', 'api-ref/source/database/v1/samples/db-instance-status-detail-response-json-http.txt', 'api-ref/source/image/v2/samples/image-update-response.json', 'api-ref/source/identity/v3/samples/admin/group-update-request.json', 'api-ref/source/image/v2/samples/metadef-tag-create-request.json', 'api-ref/source/identity/v3/samples/admin/user-update-request.json', 'api-ref/source/networking/v2-ext/showVIP.yaml', 'api-ref/source/networking/v2-ext/deleteBandwidthLimitRule.yaml', 'api-ref/source/networking/v2/samples/quotas/quotas-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-add-request.xml', 'api-ref/source/clustering/v1/samples/cluster-policy-update-request.json', 'api-ref/source/share/v1/share-metadata.inc', 'api-ref/source/identity/v3/samples/admin/endpoints-list-response.json', 'api-ref/source/clustering/v1/showProfile.yaml', 'api-ref/source/clustering/v1/senlin-versions.inc', 'api-ref/source/identity/v2-ext/deleteService.yaml', 'api-ref/source/identity/v3/enableProject.yaml', 'api-ref/source/identity/v3-ext/getPolicyAndEndpointAssociation.yaml', 'api-ref/source/identity/v2-admin/admin-listEndpointsForToken.yaml', 'api-ref/source/blockstorage/v2/samples/scheduler-stats/pools-list-detailed-response.json', 'api-ref/source/networking/v2-ext/fwaas-v2.0.inc', 'api-ref/source/networking/v2/samples/qos/bandwidth_limit_rules-list-response.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-labels-list-request-json-http.txt', 'api-ref/source/networking/v2/samples/vpn/ipsec-site-connection-update-request.json', 'api-ref/source/networking/v2/samples/vpn/vpnservices-list-response.json', 'api-ref/source/orchestration/v1/samples/services-list-response.json', 'api-ref/source/image/v2/showMetadefPropertiesSchema.yaml', 'api-ref/source/identity/v3/samples/admin/domain-config-group-option-update-request.json', 'api-ref/source/share/v1/samples/manila-security-services-list-for-share-network-response.json', 'api-ref/source/database/v1/samples/db-instance-status-detail-response.json', 'api-ref/source/data-processing/v1.1/parameters.yaml', 'api-ref/source/networking/v2/samples/lbaas/vip-update-request.json', 'api-ref/source/blockstorage/v2/samples/volumes/volume-type-access-add-request.json', 'api-ref/source/networking/v2/samples/metering-labels/metering-label-rule-delete-request-json-http.txt', 'api-ref/source/orchestration/v1/stack-events.inc', 'api-ref/source/networking/v2/samples/security-groups/security-group-show-response.json', 'api-ref/source/networking/v2-ext/updateBandwidthLimitRule.yaml', 'api-ref/source/objectstorage/v1/storage-container-services.inc', 'api-ref/source/networking/v2-ext/updateQuota.yaml', 'api-ref/source/identity/v3/samples/admin/domain-group-roles-list-response.json', 'api-ref/source/orchestration/v1/stack_list.yaml', 'api-ref/source/networking/v2/subnets.inc', 'api-ref/source/orchestration/v1/samples/stack-preview-response.json', 'api-ref/source/identity/v3/samples/admin/user-create-response.json', 'api-ref/source/blockstorage/v2/createSnapshot.yaml', 'api-ref/source/database/v1/samples/db-update-config-grp-response-json-http.txt', 'api-ref/source/identity/v3/deleteConsumer.yaml', 'api-ref/source/identity/v3/listProjects.yaml', 'api-ref/source/data-processing/v1.1/samples/data-sources/data-source-register-swift-response.json', 'api-ref/source/data-processing/v1.1/samples/job-executions/job-ex-response.json', 'api-ref/source/networking/v2/samples/flavors/service-profile-create-request.json', 'api-ref/source/networking/v2-ext/updateFirewall.yaml', 'api-ref/source/clustering/v1/clustering-v1-nodes.inc', 'api-ref/source/data-processing/v1.1/listJobs.yaml', 'api-ref/source/database/v1/showVersionInfo-dbaas-v1.yaml', 'api-ref/source/networking/v2/samples/ports/port-show-response.json', 'api-ref/source/share/v1/samples/manila-share-server-show-details-response.json', 'api-ref/source/blockstorage/v2/samples/qos-specs/qos-list-response.xml', 'api-ref/source/clustering/v1/createProfile.yaml', 'api-ref/source/identity/v3/samples/OS-ENDPOINT-POLICY/policy-show-response.json', 'api-ref/source/database/v1/samples/db-create-config-grp-request.json', 'api-ref/source/networking/v2/samples/subnets/subnets-create-bulk-response.json', 'api-ref/source/clustering/v1/samples/cluster-show-response.json']",2205,d9948b7ad054512779f917f70a164eeb17731679,rst-api-ref,"{ ""cluster"": { ""created_at"": ""2015-02-11T15:13:20"", ""data"": {}, ""desired_capacity"": 0, ""domain"": null, ""id"": ""45edadcb-c73b-4920-87e1-518b2f29f54b"", ""init_at"": ""2015-02-10T14:26:10"", ""max_size"": -1, ""metadata"": {}, ""min_size"": 0, ""name"": ""test_cluster"", ""nodes"": [], ""policies"": [], ""profile_id"": ""edc63d0a-2ca4-48fa-9854-27926da76a4a"", ""profile_name"": ""mystack"", ""project"": ""6e18cc2bdbeb48a5b3cad2dc499f6804"", ""status"": ""ACTIVE"", ""status_reason"": ""Creation succeeded"", ""timeout"": 3600, ""updated_at"": null, ""user"": ""5e5bf8027826429c96af157f68dc9072"" } } ",,530170,0
openstack%2Fopenstack-ansible~master~Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,openstack/openstack-ansible,master,Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8,Add release note for paramiko issue workaround,MERGED,2016-05-03 11:19:42.000000000,2016-05-05 13:36:06.000000000,2016-05-04 20:32:50.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 15993}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-03 11:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/033f9ffec66c8bde90c5e8e9a9b1435c6a085abb', 'message': 'Add release note to workaround paramiko issue\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n'}, {'number': 2, 'created': '2016-05-03 11:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/60c4bef69e748e19dd74ce64eb7efdef100ace3c', 'message': 'Add release note for paramiko issue workaround\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n'}, {'number': 3, 'created': '2016-05-03 16:37:07.000000000', 'files': ['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81', 'message': 'Add release note for paramiko issue workaround\n\nChange Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve\nthe issue with the Paramkino 2.0 update, but did not include a release note to\nbe explicit that this is a known issue and to inform deployers how to work\naround it.\n\nThis patch adds a release note to do that.\n\nChange-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8\nCloses-Bug: #1577469\n'}]",2,312018,6bcb3d13d0b6ca23fba1b56f8d70ee5fdf612d81,19,5,3,6816,,,0,"Add release note for paramiko issue workaround

Change Ia7e0d64214cfd5412ec236ee4bdd6a076821d258 implemented the fix to resolve
the issue with the Paramkino 2.0 update, but did not include a release note to
be explicit that this is a known issue and to inform deployers how to work
around it.

This patch adds a release note to do that.

Change-Id: Iac3bca21fc336835ef1cad3a89d7cea0e4babaa8
Closes-Bug: #1577469
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/18/312018/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/paramiko-2-0-dependencies-9a7c7fe9aeb394e4.yaml'],1,033f9ffec66c8bde90c5e8e9a9b1435c6a085abb,bug/1577469,"--- issues: - With the update of Paramiko to version 2.0, the Python cryptography library is now used which requires additional system packages. For OpenStack-Ansible versions <12.0.12, <11.2.15, <13.0.2 the system packages must be installed on the deployment host manually by executing ``apt-get install -y build-essential libssl-dev libffi-dev``. ",,7,0
openstack%2Fopenstack-ansible-os_horizon~stable%2Fmitaka~I19c0f95e65bf7d57090398d92b11303589f0619c,openstack/openstack-ansible-os_horizon,stable/mitaka,I19c0f95e65bf7d57090398d92b11303589f0619c,Add dependencies for paramiko 2.0,MERGED,2016-05-03 13:58:13.000000000,2016-05-05 13:32:19.000000000,2016-05-05 13:32:19.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-03 13:58:13.000000000', 'files': ['run_tests.sh', 'other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/0ede87dc24a72a8b5d54ede47592028c05aa0b4d', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I19c0f95e65bf7d57090398d92b11303589f0619c\n(cherry picked from commit 30138c2850edf196639beacdc8418b36b441cd70)\n'}]",0,312080,0ede87dc24a72a8b5d54ede47592028c05aa0b4d,16,2,1,6816,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Change-Id: I19c0f95e65bf7d57090398d92b11303589f0619c
(cherry picked from commit 30138c2850edf196639beacdc8418b36b441cd70)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/80/312080/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,0ede87dc24a72a8b5d54ede47592028c05aa0b4d,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fglance~master~Ibace527bcacaf8a94871a1987166c93388510bba,openstack/glance,master,Ibace527bcacaf8a94871a1987166c93388510bba,Replace logging with oslo.log,ABANDONED,2016-04-25 07:53:50.000000000,2016-05-05 13:24:55.000000000,,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6676}, {'_account_id': 15054}, {'_account_id': 19919}]","[{'number': 1, 'created': '2016-04-25 07:53:50.000000000', 'files': ['glance/async/flows/introspect.py', 'glance/async/flows/ovf_process.py', 'glance/async/flows/convert.py', 'glance/common/config.py', 'glance/async/flows/base_import.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/fa533108c654d61fcf7f0c2e4b47ee9155f4717c', 'message': ""Replace logging with oslo.log\n\nIf we use logging lib to initialize a logger, the logger won't be applied\nthe oslo.log config options.\n\nChange-Id: Ibace527bcacaf8a94871a1987166c93388510bba\n""}]",0,309874,fa533108c654d61fcf7f0c2e4b47ee9155f4717c,9,6,1,8290,,,0,"Replace logging with oslo.log

If we use logging lib to initialize a logger, the logger won't be applied
the oslo.log config options.

Change-Id: Ibace527bcacaf8a94871a1987166c93388510bba
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/309874/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/async/flows/introspect.py', 'glance/async/flows/ovf_process.py', 'glance/async/flows/convert.py', 'glance/common/config.py', 'glance/async/flows/base_import.py']",5,fa533108c654d61fcf7f0c2e4b47ee9155f4717c,replace-logging,from oslo_log import logLOG = log.getLogger(__name__),import loggingLOG = logging.getLogger(__name__),11,13
openstack%2Ftripleo-ci~master~Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68,openstack/tripleo-ci,master,Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68,Tempest for tripleo CI,MERGED,2016-03-22 14:04:31.000000000,2016-05-05 13:17:17.000000000,2016-05-05 13:17:17.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 5196}, {'_account_id': 6796}, {'_account_id': 8652}, {'_account_id': 8997}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 14885}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-03-22 14:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1ff1bc74798eb4f27572f815e392b741b4b9c763', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 2, 'created': '2016-03-28 12:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1b8fd2f253be0ae82fd7bdccba653bdc54a770fd', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 3, 'created': '2016-03-28 16:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c25b4d0ea0f0be4512fa6f4c31251d709532b8ee', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 4, 'created': '2016-03-29 15:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/488104fa0a27f164db1255a841098a3fa873a525', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 5, 'created': '2016-03-30 11:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6909096ba86f89460e1706ccfad4d53c765eb36b', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 6, 'created': '2016-04-05 06:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e674e1aaa2807de9b33c297c9c5999ebf8c6dd45', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 7, 'created': '2016-04-05 06:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/13e91c475c3b039788cc9dd73eb4fb1b9211d59a', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 8, 'created': '2016-04-06 13:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e01c00ea69cef1de1dbe62232b61590b0934cf3e', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 9, 'created': '2016-04-06 13:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3d753f3650a3a9e6578d3f1b7a0c0302c9e69ff1', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 10, 'created': '2016-04-10 10:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/68acb30b115a358d35e5c005f092240b592b82e5', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, skip file,\ntests regex\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 11, 'created': '2016-04-13 08:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1986118723d3389b8f002b231f3096033e3581e', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 12, 'created': '2016-04-19 15:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65e298a376f6196cfe5a6c2e7d15e69841ee0332', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 13, 'created': '2016-04-19 15:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f8f6b32d45b2687581927e3eb4217f4b2ab5b688', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 14, 'created': '2016-04-19 15:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6faf924ddad5678eb3cd1b9f53e6de4402f48398', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 15, 'created': '2016-04-19 18:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d55bda5f15c71df98bdbc69d039d68b6ca568516', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 16, 'created': '2016-04-20 04:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3d678a5bccde93e448b6037a4ebb8a118306a566', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 17, 'created': '2016-04-24 08:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/192b7fafd40d2b86bf74de3c29c221997d2005ba', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}, {'number': 18, 'created': '2016-04-24 08:56:34.000000000', 'files': ['scripts/api_discovery.py', 'scripts/config_tempest.py', 'scripts/tripleo.sh', 'scripts/default-overrides.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c842bbacabbce371c90566b55c6beb9b91d2fca4', 'message': 'Tempest for tripleo CI\n\nAllow to run tempest tests with tripleo.sh\nSupport custom tempest configuration, tests regex.\n\nChange-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68\n'}]",21,295844,c842bbacabbce371c90566b55c6beb9b91d2fca4,139,14,18,10969,,,0,"Tempest for tripleo CI

Allow to run tempest tests with tripleo.sh
Support custom tempest configuration, tests regex.

Change-Id: Ib566968b5f0da5b5c3c9ef14a30b3d709bd6ba68
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/44/295844/18 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/skip_file', 'scripts/tripleo.sh']",2,1ff1bc74798eb4f27572f815e392b741b4b9c763,temprun," echo "" --tempest-run -- Run tempest tests."" -l,help,repo-setup,delorean-setup,delorean-build,undercloud,overcloud-images,register-nodes,introspect-nodes,overcloud-deploy,overcloud-update,overcloud-delete,use-containers,overcloud-pingtest,all,enable-check,tempest-run \TEMPEST_RUN=${TEMPEST_RUN:-""""} TEMPEST_ARGS=${TEMPEST_ARGS:-"".*smoke""} TEMPEST_ADD_CONFIG=${TEMPEST_ADD_CONFIG:-} TEMPEST_SKIP_FILE=${TEMPEST_SKIP_FILE:-$(readlink -f $(dirname ${BASH_SOURCE[0]:-$0}))/skip_file} --tempest-run) TEMPEST_RUN=""1""; shift 1;;function clean_tempest { neutron net-delete nova || echo ""Cleaning tempest: no networks were created"" rm -rf $HOME/tempest } function tempest_run { overcloudrc_check clean_tempest mkdir -p $HOME/tempest pushd $HOME/tempest CONFIGURE_TEMPEST_DIR=""$(ls /usr/share/openstack-tempest-*/tools/configure-tempest-directory)"" $CONFIGURE_TEMPEST_DIR export FLOATING_IP_CIDR=${FLOATING_IP_CIDR:-""192.0.2.0/24""}; export FLOATING_IP_START=${FLOATING_IP_START:-""192.0.2.50""}; export FLOATING_IP_END=${FLOATING_IP_END:-""192.0.2.64""}; export EXTERNAL_NETWORK_GATEWAY=${EXTERNAL_NETWORK_GATEWAY:-""192.0.2.1""}; neutron net-create nova --shared --router:external=True --provider:network_type flat --provider:physical_network datacentre; neutron subnet-create --name ext-subnet --allocation-pool start=$FLOATING_IP_START,end=$FLOATING_IP_END --disable-dhcp --gateway $EXTERNAL_NETWORK_GATEWAY nova $FLOATING_IP_CIDR; $HOME/tempest/tools/config_tempest.py --out etc/tempest.conf --debug --create \ identity.uri $OS_AUTH_URL \ compute.allow_tenant_isolation true \ object-storage.operator_role SwiftOperator \ identity.admin_password $OS_PASSWORD \ compute.build_timeout 500 \ compute.image_ssh_user cirros \ compute.ssh_user cirros \ network.build_timeout 500 \ volume.build_timeout 500 \ scenario.ssh_user cirros $TEMPEST_ADD_CONFIG touch $TEMPEST_SKIP_FILE $HOME/tempest/tools/run-tests.sh --skip-file $TEMPEST_SKIP_FILE --no-virtual-env $TEMPEST_ARGS 2>&1 | tee $HOME/tempest/tempest_console.log popd } if [ ""$TEMPEST_RUN"" = 1 ]; then tempest_run fi "," -l,help,repo-setup,delorean-setup,delorean-build,undercloud,overcloud-images,register-nodes,introspect-nodes,overcloud-deploy,overcloud-update,overcloud-delete,use-containers,overcloud-pingtest,all,enable-check \",47,1
openstack%2Ffuel-web~master~I7b5332c4c094b1f68ae8fc47da95d882770e6bf1,openstack/fuel-web,master,I7b5332c4c094b1f68ae8fc47da95d882770e6bf1,All attributes of node model are collected for fuel-stats,MERGED,2016-05-03 12:53:36.000000000,2016-05-05 13:13:43.000000000,2016-05-05 13:10:29.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 18205}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-05-03 12:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fd50512f60da42a6d608563b40ae2b452d19fb26', 'message': 'All attributes of node model are collected for fuel-stats\n\nWhite list added for Node model attributes.\nCollecting of node info for fuel-stats refactored for using\nnode attributes white list.\n\nChange-Id: I7b5332c4c094b1f68ae8fc47da95d882770e6bf1\nCloses-Bug: #1577759\n'}, {'number': 2, 'created': '2016-05-04 15:17:24.000000000', 'files': ['nailgun/nailgun/test/unit/fuel_statistics_tests/test_installation_info.py', 'nailgun/nailgun/statistics/fuel_statistics/installation_info.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/998b3dbdbb9d30c01c1873b0724664bc10ab893c', 'message': 'All attributes of node model are collected for fuel-stats\n\nWhite list added for Node model attributes.\nCollecting of node info for fuel-stats refactored for using\nnode attributes white list.\n\nCloses-Bug: #1577759\nChange-Id: I7b5332c4c094b1f68ae8fc47da95d882770e6bf1\n'}]",5,312047,998b3dbdbb9d30c01c1873b0724664bc10ab893c,45,9,2,10959,,,0,"All attributes of node model are collected for fuel-stats

White list added for Node model attributes.
Collecting of node info for fuel-stats refactored for using
node attributes white list.

Closes-Bug: #1577759
Change-Id: I7b5332c4c094b1f68ae8fc47da95d882770e6bf1
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/312047/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/fuel_statistics_tests/test_installation_info.py', 'nailgun/nailgun/statistics/fuel_statistics/installation_info.py']",2,fd50512f60da42a6d608563b40ae2b452d19fb26,bug/1577759," node_info_white_list = ( # ((path, to, property), 'map_to_name', transform_function) WhiteListRule(('id',), 'id', None), WhiteListRule(('group_id',), 'group_id', None), WhiteListRule(('cluster_id',), 'cluster_id', None), WhiteListRule(('name',), 'name', None), WhiteListRule(('labels',), 'labels', None), WhiteListRule(('roles',), 'roles', None), WhiteListRule(('primary_roles',), 'primary_roles', None), WhiteListRule(('os_platform',), 'os', None), WhiteListRule(('manufacturer',), 'manufacturer', None), WhiteListRule(('platform_name',), 'platform_name', None), WhiteListRule(('kernel_params',), 'kernel_params', None), WhiteListRule(('extensions',), 'extensions', None), WhiteListRule(('attributes',), 'attributes', None), WhiteListRule(('status',), 'status', None), WhiteListRule(('online',), 'online', None), WhiteListRule(('error_type',), 'error_type', None), WhiteListRule(('error_msg',), 'error_msg', None), WhiteListRule(('progress',), 'progress', None), WhiteListRule(('pending_addition',), 'pending_addition', None), WhiteListRule(('pending_deletion',), 'pending_deletion', None), WhiteListRule(('pending_roles',), 'pending_roles', None), WhiteListRule(('meta',), 'meta', None), WhiteListRule(('network_template',), 'network_template', None), WhiteListRule(('vms_conf',), 'vms_conf', None), ) node_info = self.get_attributes(node, self.node_info_white_list) node_info['meta'] = self.get_node_meta(node) node_info['nic_interfaces'] = self.get_node_intefaces_info( node.nic_interfaces, bond=False) node_info['bond_interfaces'] = self.get_node_intefaces_info( node.bond_interfaces, bond=True)"," node_info = { 'id': node.id, 'group_id': node.group_id, 'roles': node.roles, 'os': node.os_platform, 'status': node.status, 'error_type': node.error_type, 'online': node.online, 'manufacturer': node.manufacturer, 'platform_name': node.platform_name, 'meta': self.get_node_meta(node), 'pending_addition': node.pending_addition, 'pending_deletion': node.pending_deletion, 'pending_roles': node.pending_roles, 'nic_interfaces': self.get_node_intefaces_info(node.nic_interfaces, bond=False), 'bond_interfaces': self.get_node_intefaces_info(node.bond_interfaces, bond=True), }",100,47
openstack%2Ffuel-web~stable%2Fmitaka~I408fcadb9068154a4d355ee1ab206c42ecad7c64,openstack/fuel-web,stable/mitaka,I408fcadb9068154a4d355ee1ab206c42ecad7c64,Message in receiver requeued on deadlock,MERGED,2016-05-04 17:36:52.000000000,2016-05-05 13:13:28.000000000,2016-05-05 13:10:37.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 12559}, {'_account_id': 20384}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 17:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0c9dc97283882620390d2f9df1d6043f0b051a75', 'message': 'Message in receiver requeued on deadlock\n\nSeems, that we have regression in the Nailgun code that brings deadlocks.\nWhen deadlock occurs on message processing in the receiverd we mark message\nas acknowledged.\nAs partial fix we requeue message on deadlock in the receiverd.\n\nChange-Id: I408fcadb9068154a4d355ee1ab206c42ecad7c64\nPartial-Bug: #1578218\n(cherry picked from commit e42b6318be1ee6d7275fa91152dee64b54b06546)\n'}, {'number': 2, 'created': '2016-05-04 18:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4ac94f40f7ed89b0e43124f4fb48833b701944e6', 'message': 'Message in receiver requeued on deadlock\n\nSeems, that we have regression in the Nailgun code that brings deadlocks.\nWhen deadlock occurs on message processing in the receiverd we mark message\nas acknowledged.\nAs partial fix we requeue message on deadlock in the receiverd.\n\nChange-Id: I408fcadb9068154a4d355ee1ab206c42ecad7c64\nPartial-Bug: #1578218\n(cherry picked from commit e42b6318be1ee6d7275fa91152dee64b54b06546)\n'}, {'number': 3, 'created': '2016-05-05 10:00:18.000000000', 'files': ['nailgun/nailgun/test/unit/test_rpc_acknowledge.py', 'nailgun/nailgun/rpc/receiverd.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/622ac2be1bcc6a9cf8ab0d17abeebd53c30bd556', 'message': 'Message in receiver requeued on deadlock\n\nSeems, that we have regression in the Nailgun code that brings deadlocks.\nWhen deadlock occurs on message processing in the receiverd we mark message\nas acknowledged.\nAs partial fix we requeue message on deadlock in the receiverd.\n\nPartial-Bug: #1578218\nChange-Id: I408fcadb9068154a4d355ee1ab206c42ecad7c64\n(cherry picked from commit e42b6318be1ee6d7275fa91152dee64b54b06546)\n'}]",0,312654,622ac2be1bcc6a9cf8ab0d17abeebd53c30bd556,44,9,3,10959,,,0,"Message in receiver requeued on deadlock

Seems, that we have regression in the Nailgun code that brings deadlocks.
When deadlock occurs on message processing in the receiverd we mark message
as acknowledged.
As partial fix we requeue message on deadlock in the receiverd.

Partial-Bug: #1578218
Change-Id: I408fcadb9068154a4d355ee1ab206c42ecad7c64
(cherry picked from commit e42b6318be1ee6d7275fa91152dee64b54b06546)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/54/312654/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_rpc_acknowledge.py', 'nailgun/nailgun/rpc/receiverd.py']",2,0c9dc97283882620390d2f9df1d6043f0b051a75,bug/1578218,"import amqp.exceptions as amqp_exceptionsfrom psycopg2.extensions import TransactionRollbackError import six except TransactionRollbackError: logger.error(""Deadlock on message processing"") msg.requeue()",import six import amqp.exceptions as amqp_exceptions,15,5
openstack%2Fmanila~master~I03e767454a0f69fce9aebb10aa9866520acc1413,openstack/manila,master,I03e767454a0f69fce9aebb10aa9866520acc1413,cephfs_native: doc fixes,MERGED,2016-03-21 18:41:21.000000000,2016-05-05 12:59:54.000000000,2016-05-05 11:32:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7872}, {'_account_id': 8056}, {'_account_id': 8851}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 14624}, {'_account_id': 15100}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 17780}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18643}, {'_account_id': 18752}, {'_account_id': 19733}, {'_account_id': 20695}]","[{'number': 1, 'created': '2016-03-21 18:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a9fbfbfa011333710c93b583ffa070abac0195b9', 'message': 'Doc fixes for Ceph driver\n\nAdd more details about non-obvious driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 2, 'created': '2016-03-21 18:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a40caa1929500e19de574735e7e14a045eda7dc3', 'message': 'Doc fixes for CephFS native driver\n\nAdd more details about non-obvious driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 3, 'created': '2016-03-22 06:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dac8856fd8d32d1ef14c1162b46bb56db90ae357', 'message': 'Doc fixes for CephFS native driver\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 4, 'created': '2016-03-29 11:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7d5312e7d69111390ce4bbab9acfe9783ec0ca90', 'message': 'Doc fixes for CephFS native driver\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 5, 'created': '2016-03-29 12:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/12df61a12b626b286a54d24ef797bd5c4d3269a9', 'message': 'Doc fixes for CephFS native driver\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 6, 'created': '2016-04-20 20:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0c5c03b33e0360cbde448d64c587254c01f89291', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 7, 'created': '2016-04-21 07:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7089822cd5beecf65ed3b2cde7864d074d4c90f6', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 8, 'created': '2016-05-02 11:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a345d04f9f76fcf1019a0dda4202e76197f1c941', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 9, 'created': '2016-05-02 11:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f98bf19764c3d1a48bbef6e03792b4fba3ddce1c', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 10, 'created': '2016-05-02 14:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f6a815a18f3c2df55109788cc633061fa647a07d', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}, {'number': 11, 'created': '2016-05-05 06:03:57.000000000', 'files': ['doc/source/devref/cephfs_native_driver.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/affc78e711917cbcb6ba66066098d1b868f5cc04', 'message': 'cephfs_native: doc fixes\n\nAdd more details about driver specific concepts and usage.\nAlso, add known restrictions of the Mitaka version and license\ndetails.\n\nChange-Id: I03e767454a0f69fce9aebb10aa9866520acc1413\n'}]",80,295448,affc78e711917cbcb6ba66066098d1b868f5cc04,155,26,11,8056,,,0,"cephfs_native: doc fixes

Add more details about driver specific concepts and usage.
Also, add known restrictions of the Mitaka version and license
details.

Change-Id: I03e767454a0f69fce9aebb10aa9866520acc1413
",git fetch https://review.opendev.org/openstack/manila refs/changes/48/295448/8 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/cephfs_native_driver.rst'],1,a9fbfbfa011333710c93b583ffa070abac0195b9,cephfs-driver-doc,"Access is controlled via Ceph's cephx authentication system. When a user requests access to a share for an ID, Ceph creates a corresponding Ceph auth ID and a secret key, if they does not already exist, and authorizes the ID to access the share. The client can then mount the share using the ID and the secret key.Supported Operations -------------------- The following operations are supported with CephFS backend: - Create/delete CephFS share - Allow/deny CephFS share access * ``cephx`` access type is supported for CephFS protocol. * Read/write is supported. - Extend/shrink share - Create/delete snapshot - Create/delete consistency group (CG) - Create/delete CG snapshot servers running the :term:`manila-share` service. ``ceph-common`` package needs to be installed in the :term: `manila-share` servers. - Network connectivity between your Ceph cluster's public network and guests. - Jewel or later version of Ceph packages.on the server where the :term:`manila-share` service runs, and the paths to these configured in your manila.conf. cephfs_cluster_name = ceph cephfs_enable_snapshots = True Set ``cephfs_enable_snapshots`` to True in the section to let the driver perform snapshot related operations. Then edit ``enabled_share_backends`` to point to the driver's backend section using the section name. In this example we are also including another backend (""generic1""), you would include whatever other backends you have configured. The default share type may have ``driver_handles_share_servers`` set to True.Note the export location of the share: .. code-block:: console manila share-export-location-list cephshare1 The export location of the share contains the Ceph monitor (mon) addresses and ports, and the path to be mounted. It is of the form, ``{mon ip addr:port}[,{mon ip addr:port}]:{path to be mounted}`` Allowing access to shares -------------------------- Allow user ID ``alice`` access to the share using ``cephx`` access type. .. code-block:: console manila access-allow cephshare1 cephx alice Mounting shares using FUSE client --------------------------------- Using the secret key of the authorized ID ``alice`` create a keyring file, ``alice.keyring`` like: [client.alice].. note:: In Mitaka release, the Ceph admin needs to pass the secret key to the guest out of band of manila. You can refer the link below to see how the admin can obtain the secret key of an ID. http://docs.ceph.com/docs/jewel/rados/operations/user-management/#get-a-user Using the mon IP addresses from the share's export location, create a configuration file, ``ceph.conf`` like: mon host = 192.168.1.7:6789, 192.168.1.8:6789, 192.168.1.9:6789configuration files you just created, and substituting the path to be mounted from the share's export location: sudo ceph-fuse --id=alice --conf=./ceph.conf --keyring=./alice.keyring --client-mountpoint=/volumes/_nogroup/4c55ad20-9c55-4a5e-9233-8ac64566b98c ~/mnt Known restrictions ------------------ Mitaka release Consider the driver as a building block for supporting multi-tenant workloads in the future. However, it can be used in private cloud deployments. - The secret-key required to mount a share is not exposed by manila APIs. It needs to be shared with the guest by the Ceph admin out of band of manila. - The snapshot support of the driver is disabled by default. ``cephfs_enable_snapshots`` configuration option needs to be set to ``True`` to allow snapshot operations. - Snapshots are read-only and can be read from ``.snap/share-snapshot-{manila-snapshot-id}`` folder within the mounted share. Shares cannot be created from snapshots.","Access is controlled via Ceph's cephx authentication system. Each share has a distinct authentication key that must be passed to clients for them to use it. server running the :term:`manila-share` service. - Network connectivity between your Ceph cluster's public network and guestson the server where the :term:`manila-share` service runs, and the paths to these configured in your manila.conf. Then edit ``enabled_share_backends`` to point to it, using the same name that you used for the backend section. In this example we are also including another backend (""generic1""), you would include whatever other backends you have configured.The default share type may have driver_handles_share_servers set to True. Mounting a client with FUSE --------------------------- Using the key from your export location, and the share ID, create a keyring file like: [client.share-4c55ad20-9c55-4a5e-9233-8ac64566b98c]Using the mon IP addresses from your export location, create a ceph.conf file like: [mon.a] mon addr = 192.168.1.7:6789 [mon.b] mon addr = 192.168.1.8:6789 [mon.c] mon addr = 192.168.1.9:6789configuration files you just created: ceph-fuse --id=share-4c55ad20-9c55-4a5e-9233-8ac64566b98c -c ./client.conf --keyring=./client.keyring --client-mountpoint=/volumes/share-4c55ad20-9c55-4a5e-9233-8ac64566b98c ~/mnt",96,30
openstack%2Fcinder~master~I89e394fe6d0e0483c0816ae133f929616b340538,openstack/cinder,master,I89e394fe6d0e0483c0816ae133f929616b340538,Tests: lower case all fake uuid constants,MERGED,2016-05-03 17:36:56.000000000,2016-05-05 12:58:09.000000000,2016-05-03 18:26:05.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10379}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19933}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-05-03 17:36:56.000000000', 'files': ['cinder/tests/unit/api/v3/test_volumes.py', 'cinder/tests/unit/objects/test_base.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/tests/unit/test_backup_google.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/fakes.py', 'cinder/tests/unit/api/v2/test_types.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'cinder/tests/unit/fake_constants.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/api/v2/stubs.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/fake_consistencygroup.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/api/v1/test_types.py', 'cinder/tests/unit/test_pure.py', 'cinder/tests/unit/api/v2/test_snapshot_metadata.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/api/contrib/test_volume_tenant_attribute.py', 'cinder/tests/unit/api/v1/test_volumes.py', 'cinder/tests/unit/api/v3/stubs.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/tests/unit/api/v1/test_snapshots.py', 'cinder/tests/unit/fake_cgsnapshot.py', 'cinder/tests/unit/volume/drivers/emc/scaleio/test_consistencygroups.py', 'cinder/tests/unit/api/v1/stubs.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/tests/unit/test_volume.py', 'cinder/tests/unit/test_block_device.py', 'cinder/tests/unit/test_backup_swift.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/test_dellsc.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/api/v1/test_volume_metadata.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/test_sheepdog.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/tests/unit/api/fakes.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/tests/unit/fake_backup.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/backup/test_rpcapi.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8c3abfdfb06e7536d9397637f811dc21a29a8b14', 'message': 'Tests: lower case all fake uuid constants\n\nMidway through the valid uuid conversion project, we decided\nto use upper-case fake constant uuids.  For backwards compatibility,\nwe put both upper-case and lower-case versions of each constant\nin the fake_constants file, with the goal of returning and removing\nthe lower-case versions when their usages had been converted to\nupper-case.\n\nThis commit converts the lower-case usages of the constants to\nupper-case and removes the lower-case definitions from the\nconstants file.\n\nChange-Id: I89e394fe6d0e0483c0816ae133f929616b340538\n'}]",0,312182,8c3abfdfb06e7536d9397637f811dc21a29a8b14,37,28,1,9003,,,0,"Tests: lower case all fake uuid constants

Midway through the valid uuid conversion project, we decided
to use upper-case fake constant uuids.  For backwards compatibility,
we put both upper-case and lower-case versions of each constant
in the fake_constants file, with the goal of returning and removing
the lower-case versions when their usages had been converted to
upper-case.

This commit converts the lower-case usages of the constants to
upper-case and removes the lower-case definitions from the
constants file.

Change-Id: I89e394fe6d0e0483c0816ae133f929616b340538
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/312182/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/api/v3/test_volumes.py', 'cinder/tests/unit/objects/test_base.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/tests/unit/test_backup_google.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/fakes.py', 'cinder/tests/unit/api/v2/test_types.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'cinder/tests/unit/fake_constants.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/api/v2/stubs.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/fake_consistencygroup.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/api/v1/test_types.py', 'cinder/tests/unit/test_pure.py', 'cinder/tests/unit/api/v2/test_snapshot_metadata.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/api/contrib/test_volume_tenant_attribute.py', 'cinder/tests/unit/api/v1/test_volumes.py', 'cinder/tests/unit/api/v3/stubs.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/tests/unit/api/v1/test_snapshots.py', 'cinder/tests/unit/fake_cgsnapshot.py', 'cinder/tests/unit/volume/drivers/emc/scaleio/test_consistencygroups.py', 'cinder/tests/unit/api/v1/stubs.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/tests/unit/test_volume.py', 'cinder/tests/unit/test_block_device.py', 'cinder/tests/unit/test_backup_swift.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/test_dellsc.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/api/v1/test_volume_metadata.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/test_sheepdog.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/tests/unit/api/fakes.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/tests/unit/fake_backup.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/backup/test_rpcapi.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py']",57,8c3abfdfb06e7536d9397637f811dc21a29a8b14,uuid_warnings," fake.ATTACHMENT_ID) fake.ATTACHMENT_ID) fake.ATTACHMENT_ID), fake.ATTACHMENT_ID)])"," fake.attachment_id) fake.attachment_id) fake.attachment_id), fake.attachment_id)])",1171,1230
openstack%2Fironic-webclient~master~I9286403591cc29d13fae0dabc779aba1f3a28755,openstack/ironic-webclient,master,I9286403591cc29d13fae0dabc779aba1f3a28755,Added selection hover state to node list,MERGED,2016-04-05 13:53:25.000000000,2016-05-05 12:52:41.000000000,2016-05-05 12:52:41.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2016-04-05 13:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-webclient/commit/2de2f2402c67f655a5f8c9d02eb8d6009493f10a', 'message': 'Added selection hover state to node list\n\nSelected rows are now highlighted.\n\nChange-Id: I9286403591cc29d13fae0dabc779aba1f3a28755\n'}, {'number': 2, 'created': '2016-04-18 15:26:20.000000000', 'files': ['app/view/ironic/node_list.html'], 'web_link': 'https://opendev.org/openstack/ironic-webclient/commit/bbfa2a14d9486e1c1de58a896f57ed773e10e08f', 'message': 'Added selection hover state to node list\n\nSelected rows are now highlighted.\n\nChange-Id: I9286403591cc29d13fae0dabc779aba1f3a28755\n'}]",0,301681,bbfa2a14d9486e1c1de58a896f57ed773e10e08f,19,4,2,9717,,,0,"Added selection hover state to node list

Selected rows are now highlighted.

Change-Id: I9286403591cc29d13fae0dabc779aba1f3a28755
",git fetch https://review.opendev.org/openstack/ironic-webclient refs/changes/81/301681/2 && git format-patch -1 --stdout FETCH_HEAD,['app/view/ironic/node_list.html'],1,2de2f2402c67f655a5f8c9d02eb8d6009493f10a,ux," <table class=""table table-condensed table-striped table-bordered table-hover""> <tr ng-repeat=""node in nodeListCtrl.nodes"" ng-class=""{'info': nodeListCtrl.selectedNodes.indexOf(node.uuid) > -1}"">"," <table class=""table table-condensed table-striped table-bordered""> <tr ng-repeat=""node in nodeListCtrl.nodes"">",3,2
openstack%2Foslo.middleware~stable%2Fkilo~I4718ff996d18a3b924b99bd761b33c9cbc1b7135,openstack/oslo.middleware,stable/kilo,I4718ff996d18a3b924b99bd761b33c9cbc1b7135,Updated from global requirements,MERGED,2016-04-29 22:57:37.000000000,2016-05-05 12:44:47.000000000,2016-05-05 12:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-04-29 22:57:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/f0a1bb9598bc6e149661eb7f73cd529b1fd6979d', 'message': 'Updated from global requirements\n\nChange-Id: I4718ff996d18a3b924b99bd761b33c9cbc1b7135\n'}]",0,311437,f0a1bb9598bc6e149661eb7f73cd529b1fd6979d,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I4718ff996d18a3b924b99bd761b33c9cbc1b7135
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/37/311437/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f0a1bb9598bc6e149661eb7f73cd529b1fd6979d,openstack/requirements,"Babel!=2.3.0,!=2.3.1,!=2.3.2,!=2.3.3,>=1.3 # BSD",Babel>=1.3,1,1
openstack%2Fopenstack-ansible-os_horizon~stable%2Fmitaka~I8da8e341f988bf039efca7ead39626614da0806e,openstack/openstack-ansible-os_horizon,stable/mitaka,I8da8e341f988bf039efca7ead39626614da0806e,Fix test-requirements & releasenotes,MERGED,2016-05-05 11:45:16.000000000,2016-05-05 12:42:52.000000000,2016-05-05 12:42:52.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-05 11:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/69c9a4d5597c418edca84ddef5052bc688588b9e', 'message': 'Add reno to test-requirements\n\nChange-Id: I8da8e341f988bf039efca7ead39626614da0806e\n'}, {'number': 2, 'created': '2016-05-05 11:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/b5ebf8e8a4e075b02a3378b46b90a0488fb60097', 'message': 'Fix test-requirements\n\nChange-Id: I8da8e341f988bf039efca7ead39626614da0806e\n'}, {'number': 3, 'created': '2016-05-05 11:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/64522bbef7ef4dade2c18c207086d4e2a9ec5b60', 'message': 'Fix test-requirements\n\nSplit oslosphinx and reno onto separate lines.\n\nChange-Id: I8da8e341f988bf039efca7ead39626614da0806e\n'}, {'number': 4, 'created': '2016-05-05 12:08:12.000000000', 'files': ['test-requirements.txt', 'releasenotes/source/liberty.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/386af3557b6785483b5d8b6d8286502ff96a7efe', 'message': 'Fix test-requirements & releasenotes\n\n- Split oslosphinx and reno onto separate lines.\n- Remove liberty branch rst files as there is no liberty\n  branch for this repo.\n\nChange-Id: I8da8e341f988bf039efca7ead39626614da0806e\n'}]",0,312906,386af3557b6785483b5d8b6d8286502ff96a7efe,12,2,4,6816,,,0,"Fix test-requirements & releasenotes

- Split oslosphinx and reno onto separate lines.
- Remove liberty branch rst files as there is no liberty
  branch for this repo.

Change-Id: I8da8e341f988bf039efca7ead39626614da0806e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/06/312906/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,69c9a4d5597c418edca84ddef5052bc688588b9e,312906,oslosphinx>=2.5.0 # Apache-2.0 reno>=0.1.1 # Apache-2.0,oslosphinx>=2.5.0 # Apache-2.0reno>=0.1.1 # Apache-2.0,2,1
openstack%2Faodh~master~I9cc063891a6c52a9a568f864628bcbcb9106aa5b,openstack/aodh,master,I9cc063891a6c52a9a568f864628bcbcb9106aa5b,Trival fix bug in docs,MERGED,2016-05-04 09:05:15.000000000,2016-05-05 12:42:43.000000000,2016-05-05 12:42:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 8358}]","[{'number': 1, 'created': '2016-05-04 09:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/2db7085adb0f2d960a10b3d5b2007053dae83eab', 'message': 'Trival fix bug in docs\n\nThe current recommended Aodh storage backend is mysql\nintead of mongoDB\n\nChange-Id: I9cc063891a6c52a9a568f864628bcbcb9106aa5b\n'}, {'number': 2, 'created': '2016-05-04 09:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/7cabdd049d305d8c284d130413a2844c4260189a', 'message': 'Trival fix bug in docs\n\nThe current recommended Aodh storage backend is\nSQLAlchemy-supported DBs intead of mongoDB.\n\nChange-Id: I9cc063891a6c52a9a568f864628bcbcb9106aa5b\n'}, {'number': 3, 'created': '2016-05-05 01:23:56.000000000', 'files': ['doc/source/install/manual.rst'], 'web_link': 'https://opendev.org/openstack/aodh/commit/09ec847725347c00e0e089ac3789e0430826056a', 'message': 'Trival fix bug in docs\n\nThe current recommended Aodh storage backend is\nSQLAlchemy-supported DBs intead of mongoDB.\n\nChange-Id: I9cc063891a6c52a9a568f864628bcbcb9106aa5b\n'}]",2,312394,09ec847725347c00e0e089ac3789e0430826056a,13,5,3,15888,,,0,"Trival fix bug in docs

The current recommended Aodh storage backend is
SQLAlchemy-supported DBs intead of mongoDB.

Change-Id: I9cc063891a6c52a9a568f864628bcbcb9106aa5b
",git fetch https://review.opendev.org/openstack/aodh refs/changes/94/312394/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/manual.rst'],1,2db7085adb0f2d960a10b3d5b2007053dae83eab,trival_fix_doc,"SQLalchemy-supported DBs ------------------------ You may alternatively use `MySQL` (or any other SQLAlchemy-supported DB like `PostgreSQL`). The recommended Aodh storage backend is `MySQL`. In case of SQL-based database backends, you need to create a `aodh` database first and then initialise it by running:: aodh-dbsync To use MySQL as the storage backend, change the 'database' section in aodh.conf as follows:: [database] connection = mysql+pymysql://username:password@host/aodh?charset=utf8 Follow the instructions to install the MongoDB_ package for your operating system, then start the service. The required minimum version of MongoDB is 2.4."," The recommended Aodh storage backend is `MongoDB`. Follow the instructions to install the MongoDB_ package for your operating system, then start the service. The required minimum version of MongoDB is 2.4.SQLalchemy-supported DBs ------------------------ You may alternatively use `MySQL` (or any other SQLAlchemy-supported DB like `PostgreSQL`). In case of SQL-based database backends, you need to create a `aodh` database first and then initialise it by running:: aodh-dbsync To use MySQL as the storage backend, change the 'database' section in aodh.conf as follows:: [database] connection = mysql+pymysql://username:password@host/aodh?charset=utf8 ",20,20
openstack%2Fanchor~master~Ia22e2c2923c118321911c127bb4d46e50bca408b,openstack/anchor,master,Ia22e2c2923c118321911c127bb4d46e50bca408b,Modified config to bypass standards validation,MERGED,2016-05-05 12:07:34.000000000,2016-05-05 12:39:10.000000000,2016-05-05 12:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11716}]","[{'number': 1, 'created': '2016-05-05 12:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/651d5c3b4bf33138620dd664ae239f5fb05605f8', 'message': 'Modified config to bypass standards validation\n\nChange-Id: Ia22e2c2923c118321911c127bb4d46e50bca408b\n'}, {'number': 2, 'created': '2016-05-05 12:14:40.000000000', 'files': ['config.json'], 'web_link': 'https://opendev.org/openstack/anchor/commit/87d9da87b49c62a2ea4dfb76c4432b4d5c43eefd', 'message': 'Modified config to bypass standards validation\n\nStandards validation is failing using the examples in the readme,\nuntil this can be fixed and added to the tests, disabling\nstandards validation.\n\nChange-Id: Ia22e2c2923c118321911c127bb4d46e50bca408b\n'}]",0,312912,87d9da87b49c62a2ea4dfb76c4432b4d5c43eefd,9,3,2,11397,,,0,"Modified config to bypass standards validation

Standards validation is failing using the examples in the readme,
until this can be fixed and added to the tests, disabling
standards validation.

Change-Id: Ia22e2c2923c118321911c127bb4d46e50bca408b
",git fetch https://review.opendev.org/openstack/anchor refs/changes/12/312912/1 && git format-patch -1 --stdout FETCH_HEAD,['config.json'],1,651d5c3b4bf33138620dd664ae239f5fb05605f8,,," ""standards_compliance"": {},",0,1
openstack%2Fkeystone~master~I1f093dad0b9427027edf4dc1a9f563e99aedad0c,openstack/keystone,master,I1f093dad0b9427027edf4dc1a9f563e99aedad0c,Add conflict validation for idp update,MERGED,2016-03-17 17:38:55.000000000,2016-05-05 12:32:58.000000000,2016-05-05 06:35:37.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 18338}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-03-17 17:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c9193535ca2887a3a3eeb85a491c6440a15dec35', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n'}, {'number': 2, 'created': '2016-03-18 17:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1811647b3d7096b839d6fd2ce142402118637bea', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n'}, {'number': 3, 'created': '2016-03-21 20:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f88a59891ac418e6e42086e73a0942cf6b9d23bd', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n'}, {'number': 4, 'created': '2016-03-29 19:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/775c5c6e89cf5fc76ee28466a9490d42047ace5f', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n'}, {'number': 5, 'created': '2016-05-04 23:07:52.000000000', 'files': ['keystone/tests/unit/test_v3_federation.py', 'keystone/federation/backends/sql.py', 'keystone/federation/V8_backends/sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bfcbb3cd7679dd13d5ededd2f3b765d40e0bca7d', 'message': 'Add conflict validation for idp update\n\nRemote IDs conflicts can happen during an identity provider\nupdate (similar to what happens during create).\n\nThis patch adds the same conflict handling, so a 500 is not\nreturned by keystone.\n\nChange-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c\nCloses-Bug: 1558670\n'}]",37,294201,bfcbb3cd7679dd13d5ededd2f3b765d40e0bca7d,60,8,5,11022,,,0,"Add conflict validation for idp update

Remote IDs conflicts can happen during an identity provider
update (similar to what happens during create).

This patch adds the same conflict handling, so a 500 is not
returned by keystone.

Change-Id: I1f093dad0b9427027edf4dc1a9f563e99aedad0c
Closes-Bug: 1558670
",git fetch https://review.opendev.org/openstack/keystone refs/changes/01/294201/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_federation.py', 'keystone/federation/backends/sql.py']",2,c9193535ca2887a3a3eeb85a491c6440a15dec35,bug/1558670," try: with sql.session_for_write() as session: idp_ref = self._get_idp(session, idp_id) old_idp = idp_ref.to_dict() old_idp.update(idp) new_idp = IdentityProviderModel.from_dict(old_idp) for attr in IdentityProviderModel.mutable_attributes: setattr(idp_ref, attr, getattr(new_idp, attr)) return idp_ref.to_dict() except sql.DBDuplicateEntry as e: conflict_type = 'identity_provider' details = six.text_type(e) LOG.debug(self._CONFLICT_LOG_MSG, {'conflict_type': conflict_type, 'details': details}) if 'remote_id' in details: msg = _('Duplicate remote ID: %s') else: msg = _('Duplicate entry: %s') msg = msg % e.value raise exception.Conflict(type=conflict_type, details=msg)"," with sql.session_for_write() as session: idp_ref = self._get_idp(session, idp_id) old_idp = idp_ref.to_dict() old_idp.update(idp) new_idp = IdentityProviderModel.from_dict(old_idp) for attr in IdentityProviderModel.mutable_attributes: setattr(idp_ref, attr, getattr(new_idp, attr)) return idp_ref.to_dict()",51,8
openstack%2Ffuel-qa~master~Ia6c350b36be10b8172fca4927e709c95e9d9a5a3,openstack/fuel-qa,master,Ia6c350b36be10b8172fca4927e709c95e9d9a5a3,Test network bonding with DPDK,MERGED,2016-03-29 21:08:33.000000000,2016-05-05 12:31:09.000000000,2016-05-05 11:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11708}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14708}, {'_account_id': 15984}, {'_account_id': 19119}, {'_account_id': 20519}]","[{'number': 1, 'created': '2016-03-29 21:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/385782ffcdb1db0954a1a042406a0dd62e81117c', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 2, 'created': '2016-04-01 10:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/eacf9929c81d051629669292a4f54c90039fc1e9', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 3, 'created': '2016-04-03 10:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/741908b6f805d92139a7d7c0941283bd27a1ba60', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 4, 'created': '2016-04-04 09:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6b3ed2e7448e517af56d569e1106d8ff94784170', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 5, 'created': '2016-04-05 06:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/dc4bea2a84862a3768f596a9e882225e835a4b5a', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 6, 'created': '2016-04-06 14:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/4a63b9e713d6154294cb5fd16b3c40216ceb551b', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 7, 'created': '2016-04-27 10:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ede5fc8489ea8611282bd7ba8e91b7de97a47a8a', 'message': 'Test network bonding with DPDK\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 8, 'created': '2016-04-28 06:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/0b82147741b7aabe57ba19ca777ce0ac4903d46d', 'message': 'Test network bonding with DPDK\n\nTest enabling of DPDK for NICs bond which is used\nby private network.\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 9, 'created': '2016-04-28 07:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1768e32f52a7f55476fa2f19a2f72f880c1b0ae3', 'message': 'Test network bonding with DPDK\n\nTest enabling of DPDK for NICs bond which is used\nby private network.\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}, {'number': 10, 'created': '2016-04-28 07:20:58.000000000', 'files': ['fuelweb_test/tests/test_dpdk.py', 'fuelweb_test/tests/test_bonding_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c604e312c918e659e0721b05bc32f736ae2fa4da', 'message': 'Test network bonding with DPDK\n\nTest enabling of DPDK for NICs bond which is used\nby private network.\n\nChange-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3\nImplements: blueprint test-ovs-dpdk\n'}]",2,298982,c604e312c918e659e0721b05bc32f736ae2fa4da,59,13,10,11081,,,0,"Test network bonding with DPDK

Test enabling of DPDK for NICs bond which is used
by private network.

Change-Id: Ia6c350b36be10b8172fca4927e709c95e9d9a5a3
Implements: blueprint test-ovs-dpdk
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/82/298982/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_dpdk.py', 'fuelweb_test/tests/test_bonding_base.py']",2,385782ffcdb1db0954a1a042406a0dd62e81117c,bp/test-ovs-dpdk," 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, class BondingTestDPDK(BondingTest): def __init__(self): super(BondingTestDPDK, self).__init__() self.BOND_CONFIG = [ { 'mac': None, 'mode': 'active-backup', 'name': 'bond0', 'slaves': [ {'name': iface_alias('eth3')}, {'name': iface_alias('eth2')} ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, { 'mac': None, 'mode': 'active-backup', 'name': 'bond1', 'slaves': [ {'name': iface_alias('eth1')}, {'name': iface_alias('eth0')} ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, { 'mac': None, 'mode': 'active-backup', 'name': 'bond2', 'slaves': [ {'name': iface_alias('eth5')}, {'name': iface_alias('eth4')}, ], 'state': None, 'type': 'bond', 'assigned_networks': [], 'interface_properties': {'dpdk': {'available': True}}, 'bond_properties': {'mode': 'active-backup', 'type__': 'linux'}, }, ] self.INTERFACES = { 'bond0': [ 'public', 'management', 'storage', ], 'bond1': ['fuelweb_admin'], 'bond2': ['private'], }", 'assigned_networks': [] 'assigned_networks': [],179,6
openstack%2Fopenstack-ansible-os_ironic~stable%2Fmitaka~I81916b5bcf780922bfd4d6e4b938f00953832d21,openstack/openstack-ansible-os_ironic,stable/mitaka,I81916b5bcf780922bfd4d6e4b938f00953832d21,Add dependencies for paramiko 2.0,MERGED,2016-05-03 13:56:12.000000000,2016-05-05 12:20:15.000000000,2016-05-05 12:20:15.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-05-03 13:56:12.000000000', 'files': ['run_tests.sh', 'other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/b7de2575e007a85a4f97be343e71b364a986f50c', 'message': 'Add dependencies for paramiko 2.0\n\nParamiko version 2.0 has been released. It now uses the Python library\ncryptography. Installing this requires additional system packages. This\ncommit adds in the appropriate packages required by cryptography based\non its documentation [1].\n\nAn alternative approach would have been to constrain the version of\nParamiko however the project describes the 1.x versions as relying on\ninsecure dependencies [2].\n\n[1] https://cryptography.io/en/latest/installation/\n[2] http://www.paramiko.org/installing.html\n\nChange-Id: I81916b5bcf780922bfd4d6e4b938f00953832d21\n(cherry picked from commit c42d8847564dc5ca2967e92a33263368f6fe5d6d)\n'}]",0,312070,b7de2575e007a85a4f97be343e71b364a986f50c,16,2,1,6816,,,0,"Add dependencies for paramiko 2.0

Paramiko version 2.0 has been released. It now uses the Python library
cryptography. Installing this requires additional system packages. This
commit adds in the appropriate packages required by cryptography based
on its documentation [1].

An alternative approach would have been to constrain the version of
Paramiko however the project describes the 1.x versions as relying on
insecure dependencies [2].

[1] https://cryptography.io/en/latest/installation/
[2] http://www.paramiko.org/installing.html

Change-Id: I81916b5bcf780922bfd4d6e4b938f00953832d21
(cherry picked from commit c42d8847564dc5ca2967e92a33263368f6fe5d6d)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/70/312070/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'other-requirements.txt']",2,b7de2575e007a85a4f97be343e71b364a986f50c,paramiko-fix, # Requirements for Paramiko 2.0 libssl-dev libffi-dev,,5,1
openstack%2Fironic-ui~master~I4245b40757eed9d70c42729d3119dc518aea8f02,openstack/ironic-ui,master,I4245b40757eed9d70c42729d3119dc518aea8f02,Imported Translations from Zanata,MERGED,2016-05-01 06:16:10.000000000,2016-05-05 12:14:38.000000000,2016-05-05 12:14:38.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2016-05-01 06:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/ac5415cc82a6b0bf2ef8639fcd0ad74bc5a0f51d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4245b40757eed9d70c42729d3119dc518aea8f02\n'}, {'number': 2, 'created': '2016-05-02 06:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/ce4ba46a4b2a0ec73f337c6ffd117d6bc0eeff82', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4245b40757eed9d70c42729d3119dc518aea8f02\n'}, {'number': 3, 'created': '2016-05-03 06:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/7eb08b409fa74f4e08d5dfa27c973c6143d266e9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4245b40757eed9d70c42729d3119dc518aea8f02\n'}, {'number': 4, 'created': '2016-05-04 06:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/8cb24902fbc7957502cbf1c7aa38c50e76ea6f3f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4245b40757eed9d70c42729d3119dc518aea8f02\n'}, {'number': 5, 'created': '2016-05-05 06:41:20.000000000', 'files': ['ironic_ui/locale/django.pot', 'ironic_ui/locale/fr/LC_MESSAGES/django.po', 'ironic_ui/locale/djangojs.pot', 'ironic_ui/locale/fr/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/5a3dbeb083fbf5e8177ba27be9fa371192c656b3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4245b40757eed9d70c42729d3119dc518aea8f02\n'}]",0,311599,5a3dbeb083fbf5e8177ba27be9fa371192c656b3,17,3,5,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I4245b40757eed9d70c42729d3119dc518aea8f02
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/99/311599/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/locale/django.pot', 'ironic_ui/locale/fr/LC_MESSAGES/django.po', 'ironic_ui/locale/djangojs.pot', 'ironic_ui/locale/fr/LC_MESSAGES/djangojs.po']",4,ac5415cc82a6b0bf2ef8639fcd0ad74bc5a0f51d,zanata/translations,"# Gael Rehault <gael01@gmail.com>, 2015. #zanata # OpenStack Infra <zanata@openstack.org>, 2015. #zanata # Andreas Jaeger <jaegerandi@gmail.com>, 2016. #zanata # Martine Marin <mmarin@fr.ibm.com>, 2016. #zanata # Nicolas Fournier <nicolas.fournier3@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: PROJECT VERSION\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2016-04-12 19:37+0200\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-04-30 05:12+0000\n"" ""Last-Translator: Nicolas Fournier <nicolas.fournier3@gmail.com>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 3.7.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid ""Actions"" msgstr ""Actions"" msgid ""CPU Arch"" msgstr ""Architecture CPU"" msgid ""CPUs"" msgstr ""CPUs"" msgid ""Cancel"" msgstr ""Annuler"" msgid ""Capabilities"" msgstr ""Capacits"" msgid ""Chassis ID"" msgstr ""ID du chassis"" msgid ""Configuration"" msgstr ""Configuration"" msgid ""Console Enabled"" msgstr ""Console Active"" msgid ""Created At"" msgstr ""Cr le"" msgid ""Deploy Kernel"" msgstr ""Kernel de dploiement"" msgid ""Deploy Ramdisk"" msgstr ""Ramdisk de dploiement"" msgid ""Driver"" msgstr ""Driver"" msgid ""Driver Info"" msgstr ""Info du Driver"" msgid ""Extra"" msgstr ""Extra"" msgid ""General"" msgstr ""Gnral"" msgid ""Inspection Finished At"" msgstr ""Inspection termine "" msgid ""Inspection Started At"" msgstr ""Inspection dmarre "" msgid ""Instance ID"" msgstr ""ID de l'instance"" msgid ""Instance Info"" msgstr ""Infos de l'instance"" msgid ""Instance Name"" msgstr ""Nom de l'instance"" msgid ""Kernel"" msgstr ""Noyau"" msgid ""Last Error"" msgstr ""Dernire Erreur"" msgid ""Local GB"" msgstr ""GB locaux"" msgid ""Maintenance"" msgstr ""Maintenance"" msgid ""Maintenance Reason"" msgstr ""Raison de la maintenance"" msgid ""Maintenance off"" msgstr ""Maintenance dsactive"" msgid ""Maintenance on"" msgstr ""Maintenance active"" msgid ""Memory"" msgstr ""Mmoire"" msgid ""Name"" msgstr ""Nom"" msgid ""No Instance"" msgstr ""Pas d'instance"" msgid ""No maintenance reason given."" msgstr ""Aucune raison de maintenance fournie."" msgid ""Node ID"" msgstr ""ID du noeud"" msgid ""Node Name"" msgstr ""Nom du noeud"" msgid ""Node is already in maintenance mode."" msgstr ""Le noeud est dj en mode maintenance."" msgid ""Node is not in maintenance mode."" msgstr ""Le noeud n'est pas en mode maintenance."" msgid ""Node is not powered off."" msgstr ""Le noeud n'est pas teint."" msgid ""Node is not powered on."" msgstr ""Le noeud n'est pas allum."" msgid ""Overview"" msgstr ""Vue d'ensemble"" msgid ""Ports"" msgstr ""Ports"" msgid ""Power State"" msgstr ""tat de l'alimentation"" msgid ""Power off"" msgstr ""teindre"" msgid ""Power on"" msgstr ""Allumer"" msgid ""Properties"" msgstr ""Proprits"" msgid """" ""Provide a reason for why you are putting the selected node(s) into "" ""maintenance mode (optional)"" msgstr """" ""Fournir une raison pour avoir mis le(s) noeud(s) slectionn(s) en mode "" ""maintenance (optionnel)"" msgid ""Provision State"" msgstr ""tat de dploiement"" msgid ""Provisioning State"" msgstr ""tat de dploiement"" msgid ""Provisioning Status"" msgstr ""Statut de Dploiement"" msgid ""Put Node(s) Into Maintenance Mode"" msgstr ""Mettre le(s) noeud(s) en mode maintenance"" msgid ""Ramdisk"" msgstr ""Ramdisk"" msgid ""Refresh page to see updated power status"" msgstr ""Rafraichir la page pour voir les statuts d'alimentation  jour"" msgid ""Reservation"" msgstr ""Rservation"" msgid ""SSH Port"" msgstr ""Port SSH"" msgid ""SSH Username"" msgstr ""Utilisateur SSH"" msgid ""Target Power State"" msgstr ""tat de l'alimentation de la cible"" msgid ""Target Provision State"" msgstr ""tat de dploiement de la cible"" msgid ""UUID"" msgstr ""UUID"" msgid ""Unable to power off the node"" msgstr ""Impossible d'teindre le noeud"" msgid ""Unable to power on the node"" msgstr ""Impossible d'allumer le noeud"" msgid ""Unable to put the Ironic node in maintenance mode."" msgstr ""Impossible de mettre le noeud Ironic en mode maintenance."" msgid ""Unable to remove the Ironic node from maintenance mode."" msgstr ""Impossible de supprimer le noeud Ironic du mode maintenance"" msgid ""Unable to retrieve Ironic nodes."" msgstr ""Impossible de rcuprer les noeud Ironic."" msgid ""Unable to retrieve the Ironic node ports."" msgstr ""Impossible de rcuprer les ports du noeud Ironic."" msgid ""Unable to retrieve the Ironic node."" msgstr ""Impossible de rcuprer le noeud Ironic."" msgid ""Updated At"" msgstr ""Mis  jour "" ",,254,37
openstack%2Fironic-inspector~master~Ib3742ee1c1d4f2f96d29466626e1121694610dc3,openstack/ironic-inspector,master,Ib3742ee1c1d4f2f96d29466626e1121694610dc3,"Store ramdisk logs on all processing failures, not only reported by the ramdisk",MERGED,2016-03-31 14:48:34.000000000,2016-05-05 12:12:55.000000000,2016-05-05 12:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 7419}, {'_account_id': 13636}, {'_account_id': 18893}]","[{'number': 1, 'created': '2016-03-31 14:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/84c080f4c46644fc2068325ad9ea28486895777c', 'message': '[WIP] Store ramdisk logs on preprocessing failures as well\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if preprocessing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 2, 'created': '2016-04-04 13:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/295b0da0e647e2c3c08dba4791e91475949138e0', 'message': '[WIP] Store ramdisk logs on preprocessing failures as well\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if preprocessing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 3, 'created': '2016-04-08 13:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/3ffe11c8fad9f6e8a7b889e05ea8bb44e7e41f42', 'message': '[WIP] Store ramdisk logs on preprocessing failures as well\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if preprocessing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 4, 'created': '2016-04-11 15:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/0b122ccc6605c9d7917fee0168a691e9ebce3bbe', 'message': '[WIP] Store ramdisk logs on preprocessing failures as well\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if preprocessing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 5, 'created': '2016-04-12 11:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b6efeae7c467cac4e85057af1c153868e26e5ad5', 'message': 'Store ramdisk logs on preprocessing failures as well\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if preprocessing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 6, 'created': '2016-04-12 15:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/2a21392ab06c05505ab21be290dc7c629ce415f9', 'message': 'Store ramdisk logs on all processing failures, not only reported by the ramdisk\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if processing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code. As before, it can be disabled by setting ramdisk_logs_dir to\nan empty value.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 7, 'created': '2016-04-15 14:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/63b2d76ec1a8f5c4646651b468f60c0c100c0812', 'message': 'Store ramdisk logs on all processing failures, not only reported by the ramdisk\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if processing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code. As before, it can be disabled by setting ramdisk_logs_dir to\nan empty value.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}, {'number': 8, 'created': '2016-05-04 11:05:39.000000000', 'files': ['ironic_inspector/test/unit/test_plugins_standard.py', 'ironic_inspector/process.py', 'ironic_inspector/test/unit/test_process.py', 'releasenotes/notes/ramdisk-logs-on-all-failures-24da41edf3a98400.yaml', 'ironic_inspector/plugins/standard.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b65ab065ea41ab1ae3c0e7b4ccb16d2627bf9e22', 'message': 'Store ramdisk logs on all processing failures, not only reported by the ramdisk\n\nPreviously the ramdisk logs were only stored if the ramdisk reported an error.\nHowever, we are moving from ramdisk-side validation to server-side, so we need\nramdisk logs to be available if processing fails too.\n\nThis change moves storing ramdisk logs from a ramdisk_error plugin to core\nprocessing code. As before, it can be disabled by setting ramdisk_logs_dir to\nan empty value.\n\nChange-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3\nCloses-Bug: #1564448\n'}]",1,300011,b65ab065ea41ab1ae3c0e7b4ccb16d2627bf9e22,30,5,8,10239,,,0,"Store ramdisk logs on all processing failures, not only reported by the ramdisk

Previously the ramdisk logs were only stored if the ramdisk reported an error.
However, we are moving from ramdisk-side validation to server-side, so we need
ramdisk logs to be available if processing fails too.

This change moves storing ramdisk logs from a ramdisk_error plugin to core
processing code. As before, it can be disabled by setting ramdisk_logs_dir to
an empty value.

Change-Id: Ib3742ee1c1d4f2f96d29466626e1121694610dc3
Closes-Bug: #1564448
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/11/300011/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/process.py', 'ironic_inspector/plugins/standard.py']",2,84c080f4c46644fc2068325ad9ea28486895777c,bug/1564448,,"import base64 import datetime import os DATETIME_FORMAT = '%Y.%m.%d_%H.%M.%S_%f' logs = introspection_data.get('logs') if error or CONF.processing.always_store_ramdisk_logs: if logs: self._store_logs(logs, introspection_data) else: LOG.debug('No logs received from the ramdisk', data=introspection_data) def _store_logs(self, logs, introspection_data): if not CONF.processing.ramdisk_logs_dir: LOG.warning( _LW('Failed to store logs received from the ramdisk ' 'because ramdisk_logs_dir configuration option ' 'is not set'), data=introspection_data) return if not os.path.exists(CONF.processing.ramdisk_logs_dir): os.makedirs(CONF.processing.ramdisk_logs_dir) time_fmt = datetime.datetime.utcnow().strftime(self.DATETIME_FORMAT) bmc_address = introspection_data.get('ipmi_address', 'unknown') file_name = 'bmc_%s_%s' % (bmc_address, time_fmt) with open(os.path.join(CONF.processing.ramdisk_logs_dir, file_name), 'wb') as fp: fp.write(base64.b64decode(logs)) LOG.info(_LI('Ramdisk logs stored in file %s'), file_name, data=introspection_data)",30,36
openstack%2Ffuel-agent~master~I83116ccc9236053a93664c1cf40a3ef0c1a189b7,openstack/fuel-agent,master,I83116ccc9236053a93664c1cf40a3ef0c1a189b7,Switch from optimal alignment to minimum,MERGED,2016-02-10 16:21:46.000000000,2016-05-05 12:12:00.000000000,2016-04-08 15:01:16.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 9377}, {'_account_id': 14525}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-02-10 16:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/4282493c4af225e16d6a85807cc0a1768202c05c', 'message': ""Add 1M room to let parted align partitions\n\nfuel-agent always uses optimal alignment for partitions and\nthoroughly relies on parted to perform that aligning. (-a optimal)\n\nThe issue is that under certain circumstances due to that alignment,\nthe end of particular partition could cross 1M boundary. And due to\nactual partition' bounderies being rounded up, fuel-agent mistakenly\nassumes that partition couldn't fit within provided boundaries and\nraises errors.WrongPartitionSchemeError.\n\nAdding 1M gap between to the next beginning of partition resolves\ndescribed issue.\n\nChange-Id: I83116ccc9236053a93664c1cf40a3ef0c1a189b7\nCloses-Bug: #1543233\n""}, {'number': 2, 'created': '2016-04-04 17:43:36.000000000', 'files': ['fuel_agent/objects/partition/parted.py', 'fuel_agent/tests/test_partition.py', 'fuel_agent/tests/test_manager.py', 'fuel_agent/utils/partition.py', 'fuel_agent/tests/test_partition_utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/4c74eaa1875dd28d2e2c8256281d9088f83f25fb', 'message': ""Switch from optimal alignment to minimum\n\nfuel-agent always uses optimal alignment for partitions and\nthoroughly relies on parted to perform that aligning. (-a optimal)\n\nThe issue is that under certain circumstances due to that alignment,\nthe end of particular partition could cross 1M boundary. And due to\nactual partition' bounderies being rounded up, fuel-agent mistakenly\nassumes that partition couldn't fit within provided boundaries and\nraises errors.WrongPartitionSchemeError.\n\nHowever, some h/w data storages are well known for reporting\nrelatively huge optimal IO sizes (16M or even bigger), so the 1M room\ncan't be enough. Thus, optimal aligning is not an option. Therefore,\nparted has been switched to the minimum alignment.\n\nThe min value is the minimum aligment needed to align the partition\nproperly to physical blocks, which avoids performance degradation.\n\nChange-Id: I83116ccc9236053a93664c1cf40a3ef0c1a189b7\nCloses-Bug: #1543233\n""}]",0,278492,4c74eaa1875dd28d2e2c8256281d9088f83f25fb,25,7,2,8003,,,0,"Switch from optimal alignment to minimum

fuel-agent always uses optimal alignment for partitions and
thoroughly relies on parted to perform that aligning. (-a optimal)

The issue is that under certain circumstances due to that alignment,
the end of particular partition could cross 1M boundary. And due to
actual partition' bounderies being rounded up, fuel-agent mistakenly
assumes that partition couldn't fit within provided boundaries and
raises errors.WrongPartitionSchemeError.

However, some h/w data storages are well known for reporting
relatively huge optimal IO sizes (16M or even bigger), so the 1M room
can't be enough. Thus, optimal aligning is not an option. Therefore,
parted has been switched to the minimum alignment.

The min value is the minimum aligment needed to align the partition
properly to physical blocks, which avoids performance degradation.

Change-Id: I83116ccc9236053a93664c1cf40a3ef0c1a189b7
Closes-Bug: #1543233
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/92/278492/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/objects/partition/parted.py', 'fuel_agent/tests/test_partition.py', 'fuel_agent/tests/test_manager.py']",3,4282493c4af225e16d6a85807cc0a1768202c05c,bug/1543233," mock.call('/dev/sda', 26, 226, 'primary'), mock.call('/dev/sda', 227, 427, 'primary'), mock.call('/dev/sda', 428, 628, 'primary'), mock.call('/dev/sda', 629, 20067, 'primary'), mock.call('/dev/sda', 20068, 65665, 'primary'), mock.call('/dev/sda', 65666, 65686, 'primary'), mock.call('/dev/sdb', 26, 226, 'primary'), mock.call('/dev/sdb', 227, 65198, 'primary'), mock.call('/dev/sdc', 26, 226, 'primary'), mock.call('/dev/sdc', 227, 65198, 'primary')] "," mock.call('/dev/sda', 25, 225, 'primary'), mock.call('/dev/sda', 225, 425, 'primary'), mock.call('/dev/sda', 425, 625, 'primary'), mock.call('/dev/sda', 625, 20063, 'primary'), mock.call('/dev/sda', 20063, 65660, 'primary'), mock.call('/dev/sda', 65660, 65680, 'primary'), mock.call('/dev/sdb', 25, 225, 'primary'), mock.call('/dev/sdb', 225, 65196, 'primary'), mock.call('/dev/sdc', 25, 225, 'primary'), mock.call('/dev/sdc', 225, 65196, 'primary')]",17,16
openstack%2Fpython-glanceclient~master~I1924d8a8928f98d6e3170b068bb23994d200d1b9,openstack/python-glanceclient,master,I1924d8a8928f98d6e3170b068bb23994d200d1b9,WIP:Fix 'UnicodeEncodeError' for unicode values in url,ABANDONED,2016-05-05 12:08:25.000000000,2016-05-05 12:10:41.000000000,,[],"[{'number': 1, 'created': '2016-05-05 12:08:25.000000000', 'files': ['glanceclient/tests/unit/v2/test_metadefs_tags.py', 'glanceclient/v2/metadefs.py', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5769ed1ea8d0bb3428db8a4971179dbbd27c3eb9', 'message': 'WIP:Fix \'UnicodeEncodeError\' for unicode values in url\n\nUsed \'%\' instead of format() because ""%"" formatting operation\nreturns a unicode string if one of the values is a unicode string\neven when the format string is a non-unicode string.\n\nMade changes to print_err method to encode the text before\nit is printed on the console.\n\nNOTE:\nNot used u\'{0}.format(<str>) because in python 3 everything\nis unicode so no need to add explicit \'u\' to format string.\n\nCloses-Bug: #1570766\nChange-Id: I1924d8a8928f98d6e3170b068bb23994d200d1b9\n'}]",0,312915,5769ed1ea8d0bb3428db8a4971179dbbd27c3eb9,2,0,1,20182,,,0,"WIP:Fix 'UnicodeEncodeError' for unicode values in url

Used '%' instead of format() because ""%"" formatting operation
returns a unicode string if one of the values is a unicode string
even when the format string is a non-unicode string.

Made changes to print_err method to encode the text before
it is printed on the console.

NOTE:
Not used u'{0}.format(<str>) because in python 3 everything
is unicode so no need to add explicit 'u' to format string.

Closes-Bug: #1570766
Change-Id: I1924d8a8928f98d6e3170b068bb23994d200d1b9
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/15/312915/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/tests/unit/v2/test_metadefs_tags.py', 'glanceclient/v2/metadefs.py', 'glanceclient/common/utils.py']",3,5769ed1ea8d0bb3428db8a4971179dbbd27c3eb9,bug/1570766," print(encodeutils.safe_encode(msg), file=sys.stderr)"," print(encodeutils.safe_decode(msg), file=sys.stderr)",39,27
openstack%2Ffuel-web~master~If489879a3d4ca01ba2335dd279136c57e1bad171,openstack/fuel-web,master,If489879a3d4ca01ba2335dd279136c57e1bad171,Deployment graphs are deleted together with parent entity,MERGED,2016-04-08 18:36:57.000000000,2016-05-05 12:08:06.000000000,2016-05-05 12:06:23.000000000,"[{'_account_id': 3}, {'_account_id': 6571}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 14167}, {'_account_id': 14543}, {'_account_id': 16106}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 19158}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-04-08 18:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cda1973d3e0359f0e8eb8a6dfe365db3e4f5205f', 'message': 'Deployment graphs is deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs is deleting as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\n'}, {'number': 2, 'created': '2016-04-14 10:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9b18218dde43b2d4db6f675e37660e046f949dd', 'message': 'Deployment graphs is deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs is deleting as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\n'}, {'number': 3, 'created': '2016-04-15 14:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6aa865f1066d82ba4f2cb1e7efc4bbad7f8d78b3', 'message': 'Deployment graphs is deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs is deleting as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\n'}, {'number': 4, 'created': '2016-04-26 11:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/70ef9d1e4a81e1d8bce9a5721f2e19ccd717362e', 'message': 'Deployment graphs is deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs is deleting as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632'}, {'number': 5, 'created': '2016-04-26 11:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6cbfd444e5abf55293bee8fd3f28ecfe2ebdf12', 'message': 'Deployment graphs are deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}, {'number': 6, 'created': '2016-04-27 15:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3e646d41ecffa0d93c446a1310df7a51d26494ce', 'message': 'Deployment graphs are deleting together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}, {'number': 7, 'created': '2016-04-27 16:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2cc890f95daeaa52759d8151be0b9cc5895a0346', 'message': 'Deployment graphs are deleted together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}, {'number': 8, 'created': '2016-04-29 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/479aedca97cd918aa597701c10dda4e9225c35df', 'message': 'Deployment graphs are deleted together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}, {'number': 9, 'created': '2016-05-04 14:22:10.000000000', 'files': ['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun.xml', 'nailgun/nailgun/objects/deployment_graph.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py', 'nailgun/test_run/test.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/68a8e258d7d35caea6eed2d1643a4b5ea4b758ea', 'message': 'Deployment graphs are deleted together with parent entity\n\nWhen Release, Plugin or Cluster is deleted, related\ndeployment graphs are deleted as well.\n\nNote, that current DeploymentGraph deletion schema works if\nDeploymentGraph have only relation to parent\notherwise unwanted relations may be affected by graph cleanup.\n\nChange-Id: If489879a3d4ca01ba2335dd279136c57e1bad171\nCloses-Bug: #1567471\nCloses-Bug: #1557632\n'}]",23,303573,68a8e258d7d35caea6eed2d1643a4b5ea4b758ea,164,19,9,19158,,,0,"Deployment graphs are deleted together with parent entity

When Release, Plugin or Cluster is deleted, related
deployment graphs are deleted as well.

Note, that current DeploymentGraph deletion schema works if
DeploymentGraph have only relation to parent
otherwise unwanted relations may be affected by graph cleanup.

Change-Id: If489879a3d4ca01ba2335dd279136c57e1bad171
Closes-Bug: #1567471
Closes-Bug: #1557632
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/73/303573/5 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/test/integration/test_plugins_api.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/test/unit/test_release_handler.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/objects/plugin.py']",6,cda1973d3e0359f0e8eb8a6dfe365db3e4f5205f,bug/1567471," @classmethod def delete(cls, instance): """"""Delete plugin. :param instance: Release model instance :type instance: models.Release """""" for assoc in instance.deployment_graphs_assoc: db().delete(assoc.deployment_graph) super(Plugin, cls).delete(instance) ",,48,0
openstack%2Fopenstack-ansible~liberty~I6b122d749ad128a4ebc94029151c797867a3b872,openstack/openstack-ansible,liberty,I6b122d749ad128a4ebc94029151c797867a3b872,Cap paramiko to <2,MERGED,2016-05-04 15:11:37.000000000,2016-05-05 12:05:03.000000000,2016-05-05 12:05:03.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 10881}]","[{'number': 1, 'created': '2016-05-04 15:11:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/77b1c7c4efdbe5b00802569ebb1d0f5ba908184d', 'message': ""Cap paramiko to <2\n\nparamiko has been pinned to match global requirements and use a version\n<2. This change ensures we don't have runtime issues in nova.\n\nChange-Id: I6b122d749ad128a4ebc94029151c797867a3b872\nCloses-Bug: #1576755\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,312587,77b1c7c4efdbe5b00802569ebb1d0f5ba908184d,10,4,1,7353,,,0,"Cap paramiko to <2

paramiko has been pinned to match global requirements and use a version
<2. This change ensures we don't have runtime issues in nova.

Change-Id: I6b122d749ad128a4ebc94029151c797867a3b872
Closes-Bug: #1576755
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/87/312587/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,77b1c7c4efdbe5b00802569ebb1d0f5ba908184d,bug/1576755,"paramiko>=1.13.0,<2 # ansible",paramiko>=1.13.0 # ansible,1,1
openstack%2Fopenstack-ansible~kilo~I6b122d749ad128a4ebc94029151c797867a3b872,openstack/openstack-ansible,kilo,I6b122d749ad128a4ebc94029151c797867a3b872,Cap paramiko to <2,MERGED,2016-05-04 15:11:50.000000000,2016-05-05 12:04:56.000000000,2016-05-05 12:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 10881}, {'_account_id': 15993}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-05-04 15:11:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b230ae12ab5bf20c1420168b80a1c2cd327e7304', 'message': ""Cap paramiko to <2\n\nparamiko has been pinned to match global requirements and use a version\n<2. This change ensures we don't have runtime issues in nova.\n\nChange-Id: I6b122d749ad128a4ebc94029151c797867a3b872\nCloses-Bug: #1576755\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,312588,b230ae12ab5bf20c1420168b80a1c2cd327e7304,12,7,1,7353,,,0,"Cap paramiko to <2

paramiko has been pinned to match global requirements and use a version
<2. This change ensures we don't have runtime issues in nova.

Change-Id: I6b122d749ad128a4ebc94029151c797867a3b872
Closes-Bug: #1576755
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/88/312588/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b230ae12ab5bf20c1420168b80a1c2cd327e7304,bug/1576755,"paramiko>=1.13.0,<2 # ansible",paramiko>=1.13.0 # ansible,1,1
openstack%2Ffuel-agent~master~Ie2ab6fb6ee657b6eacbeebba05e90f2cd8aeaad5,openstack/fuel-agent,master,Ie2ab6fb6ee657b6eacbeebba05e90f2cd8aeaad5,DEB build depends on dh-python,MERGED,2016-04-26 16:07:13.000000000,2016-05-05 12:02:13.000000000,2016-05-05 12:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 12841}, {'_account_id': 14200}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-26 16:07:13.000000000', 'files': ['debian/changelog', 'debian/control'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/3dbcc68e7735710ea4d0af724e0888ed388fbda7', 'message': 'DEB build depends on dh-python\n\nChange-Id: Ie2ab6fb6ee657b6eacbeebba05e90f2cd8aeaad5\nCloses-Bug: #1574592\n'}]",0,310244,3dbcc68e7735710ea4d0af724e0888ed388fbda7,27,7,1,16574,,,0,"DEB build depends on dh-python

Change-Id: Ie2ab6fb6ee657b6eacbeebba05e90f2cd8aeaad5
Closes-Bug: #1574592
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/44/310244/1 && git format-patch -1 --stdout FETCH_HEAD,"['debian/changelog', 'debian/control']",2,3dbcc68e7735710ea4d0af724e0888ed388fbda7,bug/1574592," dh-python,",,7,0
openstack%2Ffuel-web~stable%2Fmitaka~I2288bc2bc34023c2ca705f1d3cc6ff48347bf549,openstack/fuel-web,stable/mitaka,I2288bc2bc34023c2ca705f1d3cc6ff48347bf549,Fix obtaining current state in ClusterTransaction,MERGED,2016-05-04 13:05:52.000000000,2016-05-05 11:55:36.000000000,2016-05-05 11:53:01.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 13:05:52.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/db/sqlalchemy/models/deployment_history.py', 'nailgun/nailgun/lcm/task_serializer.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0_1.py', 'nailgun/nailgun/objects/transaction.py', 'nailgun/nailgun/test/unit/test_objects.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0_1.py', 'nailgun/nailgun/lcm/context.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/835f188e016b9e7c246cc4955adde29503efaf81', 'message': 'Fix obtaining current state in ClusterTransaction\n\nNow we get deployment state from DeploymentHistory model. For every task\nwe get last success transaction and its state.\n\nChange-Id: I2288bc2bc34023c2ca705f1d3cc6ff48347bf549\nCloses-bug: #1572226\n(cherry picked from commit 364df8addd81ae653f203ebf3b17e537e181b162)\n'}]",0,312490,835f188e016b9e7c246cc4955adde29503efaf81,26,6,1,20384,,,0,"Fix obtaining current state in ClusterTransaction

Now we get deployment state from DeploymentHistory model. For every task
we get last success transaction and its state.

Change-Id: I2288bc2bc34023c2ca705f1d3cc6ff48347bf549
Closes-bug: #1572226
(cherry picked from commit 364df8addd81ae653f203ebf3b17e537e181b162)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/90/312490/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/db/sqlalchemy/models/deployment_history.py', 'nailgun/nailgun/lcm/task_serializer.py', 'nailgun/nailgun/test/integration/test_task_managers.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0_1.py', 'nailgun/nailgun/objects/transaction.py', 'nailgun/nailgun/test/unit/test_objects.py', 'nailgun/nailgun/lcm/context.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0_1.py']",9,835f188e016b9e7c246cc4955adde29503efaf81,bug/1572226,"# Copyright 2016 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import alembic from nailgun.db import dropdb from nailgun.db.migration import ALEMBIC_CONFIG from nailgun.test import base _prepare_revision = '11a9adc6d36a' _test_revision = '675105097a69' def setup_module(): dropdb() alembic.command.upgrade(ALEMBIC_CONFIG, _prepare_revision) prepare() alembic.command.upgrade(ALEMBIC_CONFIG, _test_revision) def prepare(): pass class TestDeploymentHistoryMigration(base.BaseAlembicMigrationTest): def test_history_has_task_name_status_idx_index(self): tbl = self.meta.tables['deployment_history'] self.assertIn('deployment_history_task_name_status_idx', [i.name for i in tbl.indexes]) ",,258,18
openstack%2Fvitrage~master~Ib632d457544576611a84fc728e1332f6dcca78ee,openstack/vitrage,master,Ib632d457544576611a84fc728e1332f6dcca78ee,split create_neighbors method to create_update_neighbors and create_snapshot_neighbors,MERGED,2016-05-05 11:41:30.000000000,2016-05-05 11:53:55.000000000,2016-05-05 11:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-05-05 11:41:30.000000000', 'files': ['vitrage/datasources/cinder/volume/transformer.py', 'vitrage/datasources/static_physical/transformer.py', 'vitrage/datasources/neutron/port/transformer.py', 'vitrage/datasources/nova/host/transformer.py', 'vitrage/datasources/nagios/transformer.py', 'vitrage/datasources/neutron/network/transformer.py', 'vitrage/evaluator/actions/evaluator_event_transformer.py', 'vitrage/datasources/nova/instance/transformer.py', 'vitrage/datasources/aodh/transformer.py', 'vitrage/datasources/nova/zone/transformer.py', 'vitrage/datasources/transformer_base.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/1bd410deeebf3b63910f669ac89614f4a2ffb980', 'message': 'split create_neighbors method to create_update_neighbors and create_snapshot_neighbors\n\nChange-Id: Ib632d457544576611a84fc728e1332f6dcca78ee\n'}]",0,312904,1bd410deeebf3b63910f669ac89614f4a2ffb980,6,2,1,19122,,,0,"split create_neighbors method to create_update_neighbors and create_snapshot_neighbors

Change-Id: Ib632d457544576611a84fc728e1332f6dcca78ee
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/04/312904/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/datasources/cinder/volume/transformer.py', 'vitrage/datasources/static_physical/transformer.py', 'vitrage/datasources/neutron/port/transformer.py', 'vitrage/datasources/nova/host/transformer.py', 'vitrage/datasources/nagios/transformer.py', 'vitrage/datasources/neutron/network/transformer.py', 'vitrage/evaluator/actions/evaluator_event_transformer.py', 'vitrage/datasources/nova/instance/transformer.py', 'vitrage/datasources/aodh/transformer.py', 'vitrage/datasources/nova/zone/transformer.py', 'vitrage/datasources/transformer_base.py']",11,1bd410deeebf3b63910f669ac89614f4a2ffb980,consisteny," if is_update_event(entity_event): return self._create_update_neighbors(entity_event) else: return self._create_snapshot_neighbors(entity_event) def _create_snapshot_neighbors(self, entity_event): return [] def _create_update_neighbors(self, entity_event): return [] ", @abc.abstractmethod,83,44
openstack%2Fopenstack-ansible~kilo~I96ff2fd7284924b8d8c7e9d0ac82e4a5075bbb5a,openstack/openstack-ansible,kilo,I96ff2fd7284924b8d8c7e9d0ac82e4a5075bbb5a,Remove XFS filesystem from the daily mlocate cron job,MERGED,2016-04-27 13:05:25.000000000,2016-05-05 11:50:43.000000000,2016-05-05 11:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14552}]","[{'number': 1, 'created': '2016-04-27 13:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/977e2eac7464b38048e1d834b14ef498b7326547', 'message': 'Remove XFS filesystem from the daily mlocate cron job\n\nThis fix removes the XFS filesystem from the daily cron job.\nIt will help to remove unnecessary disk IO due to updatedb/mlocate\nswift object indexing inside the /srv/node folders.\n\nThis fix is related to  https://review.openstack.org/#/c/308036/\n\nChange-Id: I96ff2fd7284924b8d8c7e9d0ac82e4a5075bbb5a\nCloses-Bug: #1572307\n'}, {'number': 2, 'created': '2016-04-28 20:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/eb86b56630a1a527c42b36f8ef1387e43c595cfc', 'message': 'Remove XFS filesystem from the daily mlocate cron job\n\nThis fix removes the XFS filesystem from the daily cron job.\nIt will help to remove unnecessary disk IO due to updatedb/mlocate\nswift object indexing inside the /srv/node folders.\n\nThis fix is related to  https://review.openstack.org/#/c/308036/\n\nChange-Id: I96ff2fd7284924b8d8c7e9d0ac82e4a5075bbb5a\nCloses-Bug: #1572307\n'}, {'number': 3, 'created': '2016-04-28 22:20:31.000000000', 'files': ['releasenotes/notes/swift-reconfigure-xfs-from-mlocate-e4844e6c0469afd6.yaml', 'playbooks/roles/os_swift/tasks/swift_pre_install.yml', 'playbooks/roles/os_swift/templates/mlocate-crond-daily.sh.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a93d3913a0a1bf541bdbc08fdc3f41aae8051520', 'message': 'Remove XFS filesystem from the daily mlocate cron job\n\nThis fix removes the XFS filesystem from the daily cron job.\nIt will help to remove unnecessary disk IO due to updatedb/mlocate\nswift object indexing inside the /srv/node folders.\n\nThis fix is related to  https://review.openstack.org/#/c/308036/\n\nChange-Id: I8bfa92003ce06ee4f065663e054cd2d04f458ec6\nCloses-Bug: #1572307\n'}]",0,310460,a93d3913a0a1bf541bdbc08fdc3f41aae8051520,16,5,3,14552,,,0,"Remove XFS filesystem from the daily mlocate cron job

This fix removes the XFS filesystem from the daily cron job.
It will help to remove unnecessary disk IO due to updatedb/mlocate
swift object indexing inside the /srv/node folders.

This fix is related to  https://review.openstack.org/#/c/308036/

Change-Id: I8bfa92003ce06ee4f065663e054cd2d04f458ec6
Closes-Bug: #1572307
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/60/310460/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_swift/tasks/swift_pre_install.yml'],1,977e2eac7464b38048e1d834b14ef498b7326547,bug/1572307," - name: Configure mlocate for cron.daily template: src: ""mlocate-crond-daily.sh.j2"" dest: ""/etc/cron.daily/mlocate"" mode: ""0755"" owner: ""root"" group: ""root"" tags: - swift-crond",,10,0
openstack%2Ffuel-library~master~I651b8c8ac701b32fd9b3465b0f947e30a41bb97f,openstack/fuel-library,master,I651b8c8ac701b32fd9b3465b0f947e30a41bb97f,Moving snapshots to /var/log/dump,ABANDONED,2016-04-27 12:49:22.000000000,2016-05-05 11:47:24.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 13344}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-04-27 12:49:22.000000000', 'files': ['deployment/puppet/fuel/manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ffa27aac9d3619f4dfb1f41021c063f527ea687c', 'message': 'Moving snapshots to /var/log/dump\n\nA partition used for /var is not big enough and, since snapshot contains\nmostly logs anyway, it makes sense to move it to /var/log\n\nChange-Id: I651b8c8ac701b32fd9b3465b0f947e30a41bb97f\nDepends-On: I2e1a60bd71955b2c607f46d2cde60daa49811be7\nCloses-Bug: #1543491\n'}]",0,310452,ffa27aac9d3619f4dfb1f41021c063f527ea687c,26,10,1,21013,,,0,"Moving snapshots to /var/log/dump

A partition used for /var is not big enough and, since snapshot contains
mostly logs anyway, it makes sense to move it to /var/log

Change-Id: I651b8c8ac701b32fd9b3465b0f947e30a41bb97f
Depends-On: I2e1a60bd71955b2c607f46d2cde60daa49811be7
Closes-Bug: #1543491
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/310452/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/fuel/manifests/params.pp'],1,ffa27aac9d3619f4dfb1f41021c063f527ea687c,bug/1543491, $logdumpdir = '/var/log/dump', $logdumpdir = '/var/dump',1,1
openstack%2Ftripleo-quickstart~master~I9c1894e8c0c1eb22b156bb13a85f749915e9cab0,openstack/tripleo-quickstart,master,I9c1894e8c0c1eb22b156bb13a85f749915e9cab0,Fix validate issue introduced in 5c676335,MERGED,2016-05-05 10:28:50.000000000,2016-05-05 11:44:20.000000000,2016-05-05 10:49:14.000000000,"[{'_account_id': 3}, {'_account_id': 12715}, {'_account_id': 18846}]","[{'number': 1, 'created': '2016-05-05 10:28:50.000000000', 'files': ['playbooks/roles/tripleo/overcloud/templates/overcloud-validate.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a896b5c142e4811750109eee5e3537cb6a60a1d4', 'message': 'Fix validate issue introduced in 5c676335\n\nChange-Id: I9c1894e8c0c1eb22b156bb13a85f749915e9cab0\n'}]",0,312889,a896b5c142e4811750109eee5e3537cb6a60a1d4,9,3,1,12715,,,0,"Fix validate issue introduced in 5c676335

Change-Id: I9c1894e8c0c1eb22b156bb13a85f749915e9cab0
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/89/312889/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/tripleo/overcloud/templates/overcloud-validate.sh.j2'],1,a896b5c142e4811750109eee5e3537cb6a60a1d4,whoops,# (trown) the new lines in between these are needed so that # after templating they variable assignments are on separate lines.,,4,0
openstack%2Fnova~master~Ie7189ddcb2b8bc103104045882055eb6b1fc8290,openstack/nova,master,Ie7189ddcb2b8bc103104045882055eb6b1fc8290,Remove legacy v2 API functional tests,MERGED,2016-05-04 10:05:12.000000000,2016-05-05 11:37:35.000000000,2016-05-05 11:37:33.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15524}]","[{'number': 1, 'created': '2016-05-04 10:05:12.000000000', 'files': ['nova/tests/functional/api_paste_fixture.py', 'nova/tests/functional/test_server_group.py', 'nova/tests/functional/test_extensions.py', 'nova/tests/functional/wsgi/test_flavor_manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e22983576b15c5378b02435802b5b0800bbf430b', 'message': 'Remove legacy v2 API functional tests\n\nThis patch removes the functional tests which against on the legacy V2 API.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Ie7189ddcb2b8bc103104045882055eb6b1fc8290\n'}]",5,312422,e22983576b15c5378b02435802b5b0800bbf430b,18,6,1,5754,,,0,"Remove legacy v2 API functional tests

This patch removes the functional tests which against on the legacy V2 API.

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: Ie7189ddcb2b8bc103104045882055eb6b1fc8290
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/312422/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_paste_fixture.py', 'nova/tests/functional/test_server_group.py', 'nova/tests/functional/test_extensions.py', 'nova/tests/functional/wsgi/test_flavor_manage.py']",4,e22983576b15c5378b02435802b5b0800bbf430b,bp/remove-legacy-v2-api-code,,"from nova.tests.functional import api_paste_fixture # test v2 with the v2 legacy code ('v2legacy', { 'api_major_version': 'v2', '_additional_fixtures': [ api_paste_fixture.ApiPasteLegacyV2Fixture]})",18,90
openstack%2Ffuel-main~master~Ie5b532ce18e6f2458e7e7dc425a03a3b5ffcb536,openstack/fuel-main,master,Ie5b532ce18e6f2458e7e7dc425a03a3b5ffcb536,Get rid of fuel-provisioning-scripts package,MERGED,2016-05-05 11:12:15.000000000,2016-05-05 11:35:13.000000000,2016-05-05 11:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 10288}, {'_account_id': 10836}, {'_account_id': 12817}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-05 11:12:15.000000000', 'files': ['requirements-fuel-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/edbff9a9a9f8d1b96bd7f2cd6da5535c784c55b3', 'message': 'Get rid of fuel-provisioning-scripts package\n\nIn Fuel 7.0 we dropped classical provisioning mode,\nfully switching to IBP. fuel-provisioning-scripts was removed in\npatch [1]. https://review.openstack.org/#/c/294087/\n\nChange-Id: Ie5b532ce18e6f2458e7e7dc425a03a3b5ffcb536\nPartial-bug: #1549346\n'}]",0,312898,edbff9a9a9f8d1b96bd7f2cd6da5535c784c55b3,15,8,1,12817,,,0,"Get rid of fuel-provisioning-scripts package

In Fuel 7.0 we dropped classical provisioning mode,
fully switching to IBP. fuel-provisioning-scripts was removed in
patch [1]. https://review.openstack.org/#/c/294087/

Change-Id: Ie5b532ce18e6f2458e7e7dc425a03a3b5ffcb536
Partial-bug: #1549346
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/98/312898/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-fuel-rpm.txt'],1,edbff9a9a9f8d1b96bd7f2cd6da5535c784c55b3,,,fuel-provisioning-scripts,0,1
openstack%2Fgnocchi~master~I6c28493f7ede4a9dc7390ad431fe05d1d1dc873d,openstack/gnocchi,master,I6c28493f7ede4a9dc7390ad431fe05d1d1dc873d,[alembic] delete a blank line from script.py.mako,MERGED,2016-05-05 09:59:39.000000000,2016-05-05 11:35:13.000000000,2016-05-05 11:35:13.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-05 09:59:39.000000000', 'files': ['gnocchi/indexer/alembic/script.py.mako'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a0d1e9ad9779f8c4fb69236f8d31e9e85c5c888f', 'message': '[alembic] delete a blank line from script.py.mako\n\nA new db version file always pep8 error which E303 too many blank lines.\nBeacause the line ${imports if imports else """"} often left a blank\nline in script.py.mako, this patch delete the below one line to avoid\npep8 error.\n\nreference:\nhttps://github.com/zzzeek/alembic/blob/master/alembic/templates/pylons/script.py.mako\n\nChange-Id: I6c28493f7ede4a9dc7390ad431fe05d1d1dc873d\n'}]",0,312880,a0d1e9ad9779f8c4fb69236f8d31e9e85c5c888f,7,3,1,8358,,,0,"[alembic] delete a blank line from script.py.mako

A new db version file always pep8 error which E303 too many blank lines.
Beacause the line ${imports if imports else """"} often left a blank
line in script.py.mako, this patch delete the below one line to avoid
pep8 error.

reference:
https://github.com/zzzeek/alembic/blob/master/alembic/templates/pylons/script.py.mako

Change-Id: I6c28493f7ede4a9dc7390ad431fe05d1d1dc873d
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/80/312880/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/alembic/script.py.mako'],1,a0d1e9ad9779f8c4fb69236f8d31e9e85c5c888f,alembic,,,0,1
openstack%2Fkolla-kubernetes~master~I5d5b5a2c7f9a39b59e8c9f14a8bd620c9d5cfea5,openstack/kolla-kubernetes,master,I5d5b5a2c7f9a39b59e8c9f14a8bd620c9d5cfea5,[WIP] testing jobs,ABANDONED,2016-05-05 11:25:34.000000000,2016-05-05 11:34:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-05-05 11:25:34.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/5ab5b491b61d4310d5e737a29280756ca337b118', 'message': '[WIP] testing jobs\n\nChange-Id: I5d5b5a2c7f9a39b59e8c9f14a8bd620c9d5cfea5\n'}]",0,312901,5ab5b491b61d4310d5e737a29280756ca337b118,3,1,1,5638,,,0,"[WIP] testing jobs

Change-Id: I5d5b5a2c7f9a39b59e8c9f14a8bd620c9d5cfea5
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/01/312901/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5ab5b491b61d4310d5e737a29280756ca337b118,,================================,==============================================================,2,2
openstack%2Fkuryr~master~I60cb57bc9f2fa850ed6ac7c83166fc330751979b,openstack/kuryr,master,I60cb57bc9f2fa850ed6ac7c83166fc330751979b,build: Split building libnetwork,ABANDONED,2016-05-04 12:09:38.000000000,2016-05-05 11:30:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 6598}, {'_account_id': 11343}, {'_account_id': 12069}, {'_account_id': 14352}]","[{'number': 1, 'created': '2016-05-04 12:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/76826ccef096571edc4cb87cc2ce213b05158a9e', 'message': 'build: Split building libnetwork\n\nAs we add more integrations into the repository, it will be good if\nwe are able to have different build scripts for each integration\nthat install all the necessary components. In this case, since I add\nthe libnetwork build script, I make it place the docker libnetwork\nspec file in the right location.\n\nAfter this patch, libnetwork specific parts should be moved to the\nkuryr/libnetwork path and leave the common parts in kuryr/\n\nChange-Id: I60cb57bc9f2fa850ed6ac7c83166fc330751979b\nSigned-off-by: Antoni Segura Puimedon <toni@midokura.com>\n'}, {'number': 2, 'created': '2016-05-04 12:33:15.000000000', 'files': ['README.rst', 'setup_libnetwork.cfg', 'setup.py', 'setup_libnetwork.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/4a2ffec008e1a3bd44cf94774241ef5f026cbd3f', 'message': 'build: Split building libnetwork\n\nAs we add more integrations into the repository, it will be good if\nwe are able to have different build scripts for each integration\nthat install all the necessary components. In this case, since I add\nthe libnetwork build script, I make it place the docker libnetwork\nspec file in the right location.\n\nAfter this patch, libnetwork specific parts should be moved to the\nkuryr/libnetwork path and leave the common parts in kuryr/\n\nChange-Id: I60cb57bc9f2fa850ed6ac7c83166fc330751979b\nSigned-off-by: Antoni Segura Puimedon <toni@midokura.com>\n'}]",0,312474,4a2ffec008e1a3bd44cf94774241ef5f026cbd3f,9,8,2,14352,,,0,"build: Split building libnetwork

As we add more integrations into the repository, it will be good if
we are able to have different build scripts for each integration
that install all the necessary components. In this case, since I add
the libnetwork build script, I make it place the docker libnetwork
spec file in the right location.

After this patch, libnetwork specific parts should be moved to the
kuryr/libnetwork path and leave the common parts in kuryr/

Change-Id: I60cb57bc9f2fa850ed6ac7c83166fc330751979b
Signed-off-by: Antoni Segura Puimedon <toni@midokura.com>
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/74/312474/2 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'setup_libnetwork.cfg', 'setup_libnetwork.py']",3,76826ccef096571edc4cb87cc2ce213b05158a9e,build_refactor,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT import setuptools # In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass from pbr import util setuptools.setup( **util.cfg_to_args(path='setup_libnetwork.cfg')) ",,101,0
openstack%2Fnova~master~Ibe165f00eb2e15a1a2d9466c1af48db2e6883916,openstack/nova,master,Ibe165f00eb2e15a1a2d9466c1af48db2e6883916,Fix unit tests for v2.1 API,MERGED,2016-05-04 03:39:22.000000000,2016-05-05 11:23:36.000000000,2016-05-05 11:23:34.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-04 03:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/010c15d3d524862dcf4f1296bc68cd6dd66334d5', 'message': 'Fix unit tests for v2.1 API\n\nVolumeApiTestV21 is a test class for v2.1 API as the name, but the\nclass tested v2.0 API because the module of v2.0 API was used.\nIn addition, the specified request bodies also were wrong because\nthe parameter ""size"" is required on JSON-Schema.\nThis patch fixes these problems.\n\nChange-Id: Ibe165f00eb2e15a1a2d9466c1af48db2e6883916\n'}, {'number': 2, 'created': '2016-05-04 17:30:52.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_volumes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/852c9df40b876aa9d3eb7176c8855d5d6fbdec16', 'message': 'Fix unit tests for v2.1 API\n\nVolumeApiTestV21 is a test class for v2.1 API as the name, but the\nclass tested v2.0 API because the module of v2.0 API was used.\nIn addition, the specified request bodies also were wrong because\nthe parameter ""size"" is required on JSON-Schema.\nThis patch fixes these problems.\n\nIn addition, this patch renames an internal method of the related\ntest because the method name was difficult to understand the purpose.\n\nChange-Id: Ibe165f00eb2e15a1a2d9466c1af48db2e6883916\n'}]",5,312320,852c9df40b876aa9d3eb7176c8855d5d6fbdec16,28,9,2,6167,,,0,"Fix unit tests for v2.1 API

VolumeApiTestV21 is a test class for v2.1 API as the name, but the
class tested v2.0 API because the module of v2.0 API was used.
In addition, the specified request bodies also were wrong because
the parameter ""size"" is required on JSON-Schema.
This patch fixes these problems.

In addition, this patch renames an internal method of the related
test because the method name was difficult to understand the purpose.

Change-Id: Ibe165f00eb2e15a1a2d9466c1af48db2e6883916
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/312320/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/test_volumes.py'],1,010c15d3d524862dcf4f1296bc68cd6dd66334d5,bp/remove-legacy-v2-api-code," vol = {""size"": '10', volumes_v21.VolumeController().create, req, body=body) vol = {""snapshot_id"": '1', ""size"": 10} volumes_v21.VolumeController().create, req, body=body)"," vol = {""size"": '#$?', volumes.VolumeController().create, req, body=body) vol = {""snapshot_id"": '1'} volumes.VolumeController().create, req, body=body)",6,4
openstack%2Ffuel-devops~master~Ief51fc0922f461c370916f11f506ef25dca0107b,openstack/fuel-devops,master,Ief51fc0922f461c370916f11f506ef25dca0107b,Allow create DB-independed libvirt networks,MERGED,2016-04-27 08:52:44.000000000,2016-05-05 11:18:52.000000000,2016-05-05 11:08:22.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 16106}, {'_account_id': 19011}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-04-27 08:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/acc2770735769797e680118a59c07d11c3a8e49d', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 2, 'created': '2016-04-27 14:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/c48cb0bddccf4160582e10e6540bb11ae2ba0305', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 3, 'created': '2016-04-27 14:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a996d5bcfd8778389e140f0f26a2b079e5639043', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 4, 'created': '2016-04-27 15:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/2dc5cb80dee3ea39cd50bafdbcad18c1cab64689', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 5, 'created': '2016-04-28 10:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/1c99161602678d3fe520ed84a02923303262794c', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 6, 'created': '2016-04-28 12:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/36a243d087656585bae099827bd530bc41063c37', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 7, 'created': '2016-04-28 13:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/eab47a652476ac27e5ff3e5c31760ee8f520972e', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}, {'number': 8, 'created': '2016-04-29 08:15:43.000000000', 'files': ['devops/driver/libvirt/libvirt_driver.py', 'devops/tests/driver/libvirt/test_xml_builder.py', 'devops/tests/driver/libvirt/base.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/tests/driver/libvirt/test_driver.py', 'devops/tests/driver/libvirt/test_l2_network_device.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/5e658acb646a2e66f1110b2e031b0056e582998e', 'message': 'Allow create DB-independed libvirt networks\n\n- added Driver.get_available_device_name to help\n  generate a valid names for libvirt networks and\n  node interfaces.\n- check existing devices using libvirt.\n- LibvirtXMLBuilder now takes full targed dev instead of id\n  of interface.\n- added unit tests for new code.\n\nChange-Id: Ief51fc0922f461c370916f11f506ef25dca0107b\nImplements: blueprint fuel-devops-multiple-databases\n'}]",6,310378,5e658acb646a2e66f1110b2e031b0056e582998e,50,9,8,19011,,,0,"Allow create DB-independed libvirt networks

- added Driver.get_available_device_name to help
  generate a valid names for libvirt networks and
  node interfaces.
- check existing devices using libvirt.
- LibvirtXMLBuilder now takes full targed dev instead of id
  of interface.
- added unit tests for new code.

Change-Id: Ief51fc0922f461c370916f11f506ef25dca0107b
Implements: blueprint fuel-devops-multiple-databases
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/78/310378/8 && git format-patch -1 --stdout FETCH_HEAD,"['devops/driver/libvirt/libvirt_driver.py', 'devops/tests/driver/libvirt/test_xml_builder.py', 'devops/tests/driver/libvirt/base.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/tests/driver/libvirt/test_driver.py', 'devops/tests/driver/libvirt/test_l2_network_device.py']",6,acc2770735769797e680118a59c07d11c3a8e49d,bp/fuel-devops-multiple-databases," assert self.l2_net_dev.bridge_name() == 'virbr0' "" <bridge name='virbr0' stp='on' delay='0'/>\n"""," assert self.l2_net_dev.bridge_name() == 'virbr1' "" <bridge name='virbr1' stp='on' delay='0'/>\n""",163,8
openstack%2Fnova~master~Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8,openstack/nova,master,Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8,Remove legacy v2 unit tests[a-e],MERGED,2016-05-02 03:49:28.000000000,2016-05-05 11:16:49.000000000,2016-05-05 11:16:48.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-05-02 03:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/027de675b7091f1697a40a9208c08a43d898574a', 'message': 'Remove legacy v2 unit tests[a-e]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\n used as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[a-e].\n\nNOTE: Two test modules test_extended_rescue_with_image and\n      test_extended_virtual_interfaces_net are just removed\n      because the corresponding modules exist on legacy v2\n      code only. These modules are merged into source modules\n      on v2.1 code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8\n'}, {'number': 2, 'created': '2016-05-02 04:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2c4882b875bea7d61631792c96d01970399ab22', 'message': 'Remove legacy v2 unit tests[a-e]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\n used as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[a-e].\n\nNOTE: Two test modules test_extended_rescue_with_image and\n      test_extended_virtual_interfaces_net are just removed\n      because the corresponding modules exist on legacy v2\n      code only. These modules are merged into source modules\n      on v2.1 code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8\n'}, {'number': 3, 'created': '2016-05-03 23:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/670cbe4b972f6656df5127b2dba251ecf4c86970', 'message': 'Remove legacy v2 unit tests[a-e]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\n used as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[a-e].\n\nNOTE: Two test modules test_extended_rescue_with_image and\n      test_extended_virtual_interfaces_net are just removed\n      because the corresponding modules exist on legacy v2\n      code only. These modules are merged into source modules\n      on v2.1 code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8\n'}, {'number': 4, 'created': '2016-05-04 03:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/015b6e342b5054f21cb22dc95c01683fe6c83c42', 'message': 'Remove legacy v2 unit tests[a-e]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\n used as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[a-e].\n\nNOTE: Two test modules test_extended_rescue_with_image and\n      test_extended_virtual_interfaces_net are just removed\n      because the corresponding modules exist on legacy v2\n      code only. These modules are merged into source modules\n      on v2.1 code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8\n'}, {'number': 5, 'created': '2016-05-04 17:30:52.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_console_auth_tokens.py', 'nova/tests/unit/api/openstack/compute/test_create_backup.py', 'nova/tests/unit/api/openstack/compute/test_extended_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_cells.py', 'nova/tests/unit/api/openstack/compute/test_extended_virtual_interfaces_net.py', 'nova/tests/unit/api/openstack/compute/test_block_device_mapping.py', 'nova/tests/unit/api/openstack/compute/test_access_ips.py', 'nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/tests/unit/api/openstack/compute/test_availability_zone.py', 'nova/tests/unit/api/openstack/compute/test_cloudpipe_update.py', 'nova/tests/unit/api/openstack/compute/test_admin_actions.py', 'nova/tests/unit/api/openstack/compute/test_extended_rescue_with_image.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_block_device_mapping_v1.py', 'nova/tests/unit/api/openstack/compute/test_deferred_delete.py', 'nova/tests/unit/api/openstack/compute/test_extended_ips_mac.py', 'nova/tests/unit/api/openstack/compute/test_baremetal_nodes.py', 'nova/tests/unit/api/openstack/compute/test_certificates.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/test_cloudpipe.py', 'nova/tests/unit/api/openstack/compute/test_config_drive.py', 'nova/tests/unit/api/openstack/compute/test_admin_password.py', 'nova/tests/unit/api/openstack/compute/test_agents.py', 'nova/tests/unit/api/openstack/compute/test_console_output.py', 'nova/tests/unit/api/openstack/compute/test_evacuate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b5ec25d6ab2cc878eacff5f6c1d2ec47294761f3', 'message': 'Remove legacy v2 unit tests[a-e]\n\nThere are two implementation code for similar API in Nova repository.\nOne is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been\n used as the default API since Liberty and legacy v2 API has been marked\nas deprecated. We have used and tested v2.1 API so well and now is nice\ntime to remove legacy API code based on the consensus of the design\nsummit of Austin.\n\nThis patch removes unit tests of legacy v2 API[a-e].\n\nNOTE: Two test modules test_extended_rescue_with_image and\n      test_extended_virtual_interfaces_net are just removed\n      because the corresponding modules exist on legacy v2\n      code only. These modules are merged into source modules\n      on v2.1 code.\n\nPartially implements blueprint remove-legacy-v2-api-code\n\nChange-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8\n'}]",0,311659,b5ec25d6ab2cc878eacff5f6c1d2ec47294761f3,43,11,5,6167,,,0,"Remove legacy v2 unit tests[a-e]

There are two implementation code for similar API in Nova repository.
One is newer: v2.1 API, another is legacy: v2 API. v2.1 API has been
 used as the default API since Liberty and legacy v2 API has been marked
as deprecated. We have used and tested v2.1 API so well and now is nice
time to remove legacy API code based on the consensus of the design
summit of Austin.

This patch removes unit tests of legacy v2 API[a-e].

NOTE: Two test modules test_extended_rescue_with_image and
      test_extended_virtual_interfaces_net are just removed
      because the corresponding modules exist on legacy v2
      code only. These modules are merged into source modules
      on v2.1 code.

Partially implements blueprint remove-legacy-v2-api-code

Change-Id: Icd57f5b1718faef3ab7afe4acd34e56d4d29a3a8
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/311659/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_console_auth_tokens.py', 'nova/tests/unit/api/openstack/compute/test_create_backup.py', 'nova/tests/unit/api/openstack/compute/test_extended_hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_cells.py', 'nova/tests/unit/api/openstack/compute/test_extended_virtual_interfaces_net.py', 'nova/tests/unit/api/openstack/compute/test_block_device_mapping.py', 'nova/tests/unit/api/openstack/compute/test_access_ips.py', 'nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/tests/unit/api/openstack/compute/test_availability_zone.py', 'nova/tests/unit/api/openstack/compute/test_cloudpipe_update.py', 'nova/tests/unit/api/openstack/compute/test_admin_actions.py', 'nova/tests/unit/api/openstack/compute/test_extended_rescue_with_image.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/unit/api/openstack/compute/test_block_device_mapping_v1.py', 'nova/tests/unit/api/openstack/compute/test_deferred_delete.py', 'nova/tests/unit/api/openstack/compute/test_extended_ips_mac.py', 'nova/tests/unit/api/openstack/compute/test_baremetal_nodes.py', 'nova/tests/unit/api/openstack/compute/test_certificates.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/test_cloudpipe.py', 'nova/tests/unit/api/openstack/compute/test_config_drive.py', 'nova/tests/unit/api/openstack/compute/test_admin_password.py', 'nova/tests/unit/api/openstack/compute/test_agents.py', 'nova/tests/unit/api/openstack/compute/test_console_output.py', 'nova/tests/unit/api/openstack/compute/test_evacuate.py']",25,027de675b7091f1697a40a9208c08a43d898574a,bp/remove-legacy-v2-api-code,,"from nova.api.openstack.compute.legacy_v2.contrib import evacuate \ as evacuate_v2class EvacuateTestV2(EvacuateTestV21): validation_error = webob.exc.HTTPBadRequest def _set_up_controller(self): ext_mgr = extensions.ExtensionManager() ext_mgr.extensions = {'os-extended-evacuate-find-host': 'fake'} self.controller = evacuate_v2.Controller(ext_mgr) ext_mgr_no_ext = extensions.ExtensionManager() ext_mgr_no_ext.extensions = {} self.controller_no_ext = evacuate_v2.Controller(ext_mgr_no_ext) def test_no_target_fails_if_extension_not_loaded(self): self._check_evacuate_failure(webob.exc.HTTPBadRequest, {'onSharedStorage': 'False', 'adminPass': 'MyNewPass'}, controller=self.controller_no_ext) def test_evacuate_instance_with_too_long_host(self): pass def test_evacuate_instance_with_invalid_characters_host(self): pass def test_evacuate_instance_with_invalid_on_shared_storage(self): pass def test_evacuate_disable_password_return(self): pass def test_evacuate_enable_password_return(self): pass def tet_evacuate_with_non_admin(self): self.assertRaises(exception.AdminRequired, self.controller.evacuate, self.req, fakes.FAKE_UUID, {}) ",0,763
openstack%2Ffuel-devops~master~I936b96e5bb1178266d3ec8446e307daee8e6d5cd,openstack/fuel-devops,master,I936b96e5bb1178266d3ec8446e307daee8e6d5cd,Split requirements for test and main for setup,MERGED,2016-04-27 15:51:38.000000000,2016-05-05 11:15:53.000000000,2016-05-05 11:08:16.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 19011}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-04-27 15:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f875d66b6b92992ba1e6fc8fdd347c10067dae8e', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}, {'number': 2, 'created': '2016-04-28 10:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/99e3131d07090082cea3e87c297021df2ed272e7', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}, {'number': 3, 'created': '2016-04-28 10:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/ce07d393da083e04c9cca31d0f5a2e7233f4c1f8', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\nRemove tests code, which is not used.\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}, {'number': 4, 'created': '2016-04-28 10:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/e8af40445fa6514fe3c89bf8c9ef9a25b3d4ccee', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\nRemove tests code, which is not used.\nClean-up docs\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}, {'number': 5, 'created': '2016-04-28 11:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f03841c2a99ee7efb2bf89136205c1353a0084fb', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\nRemove tests code, which is not used.\nClean-up docs\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}, {'number': 6, 'created': '2016-05-04 11:25:16.000000000', 'files': ['devops/tests/factories.py', 'test-requirements.txt', 'devops/tests/use_cases.py', 'devops/driver/ipmi/ipmi_driver.py', 'setup.py', 'devops/driver/ipmi/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f8bcdf24c12711c7ded94d246c65f6797c7a87f1', 'message': 'Split requirements for test and main for setup\n\nSplit requirements for test and main for setup\n(Do not install requirements, thisch is not needed for work)\nRemove tests code, which is not used.\nRemove unused IPMI driver\n\nChange-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd\n'}]",1,310526,f8bcdf24c12711c7ded94d246c65f6797c7a87f1,42,9,6,19119,,,0,"Split requirements for test and main for setup

Split requirements for test and main for setup
(Do not install requirements, thisch is not needed for work)
Remove tests code, which is not used.
Remove unused IPMI driver

Change-Id: I936b96e5bb1178266d3ec8446e307daee8e6d5cd
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/26/310526/2 && git format-patch -1 --stdout FETCH_HEAD,"['devops/tests/factories.py', 'setup.py']",2,f875d66b6b92992ba1e6fc8fdd347c10067dae8e,bug/1542275," 'six>=1.9.0', ], tests_require=[ ],"," 'sphinx>=1.4', 'six>=1.9.0', ]",5,3
openstack%2Fvitrage~master~I1e62807b7e8a106814c5bbb722ae045f288ca0b9,openstack/vitrage,master,I1e62807b7e8a106814c5bbb722ae045f288ca0b9,create a local.conf file with post-config,MERGED,2016-05-05 11:00:59.000000000,2016-05-05 11:14:13.000000000,2016-05-05 11:14:13.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-05-05 11:00:59.000000000', 'files': ['devstack/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/23e5baef40fbac2c03cd2538a809e17c6445c789', 'message': 'create a local.conf file with post-config\n\nChange-Id: I1e62807b7e8a106814c5bbb722ae045f288ca0b9\n'}]",0,312896,23e5baef40fbac2c03cd2538a809e17c6445c789,6,2,1,19134,,,0,"create a local.conf file with post-config

Change-Id: I1e62807b7e8a106814c5bbb722ae045f288ca0b9
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/96/312896/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/gate_hook.sh'],1,23e5baef40fbac2c03cd2538a809e17c6445c789,eyalb/tempest,"DEVSTACK_LOCAL_CONFIG+=$'\nenable_plugin vitrage-dashboard git://git.openstack.org/openstack/vitrage-dashboard' DEVSTACK_LOCAL_CONFIG+=$'\nenable_plugin ceilometer git://git.openstack.org/openstack/ceilometer' DEVSTACK_LOCAL_CONFIG+=$'\nenable_plugin aodh git://git.openstack.org/openstack/aodh' DEVSTACK_LOCAL_CONFIG+=$'\ndisable_service ceilometer-alarm-evaluator,ceilometer-alarm-notifier' DEVSTACK_LOCAL_CONFIG+=$'\ndisable_service n-net' GATE_DEST=$BASE/new DEVSTACK_PATH=$GATE_DEST/devstack cat > $DEVSTACK_PATH/local.conf <<EOF [[post-config|\$NOVA_CONF]] [DEFAULT] notification_topics = notifications,vitrage_notifications notification_driver = messagingv2 [[post-config|\$NEUTRON_CONF]] [DEFAULT] notification_topics = notifications,vitrage_notifications notification_driver = messagingv2 [[post-config|\$CINDER_CONF]] [DEFAULT] notification_topics = notifications,vitrage_notifications notification_driver = messagingv2 EOF $GATE_DEST/devstack-gate/devstack-vm-gate.sh","DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin vitrage-dashboard git://git.openstack.org/openstack/vitrage-dashboard"" DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin ceilometer git://git.openstack.org/openstack/ceilometer"" DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin aodh git://git.openstack.org/openstack/aodh"" DEVSTACK_LOCAL_CONFIG+=$'\n'""disable_service ceilometer-alarm-evaluator,ceilometer-alarm-notifier"" DEVSTACK_LOCAL_CONFIG+=$'\n'""disable_service n-net"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$NOVA_CONF]]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[DEFAULT]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_topics = notifications,vitrage_notifications"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_driver=messagingv2"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$NEUTRON_CONF]]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[DEFAULT]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_topics = notifications,vitrage_notifications"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_driver=messagingv2"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$CINDER_CONF]]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""[DEFAULT]"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_topics = notifications,vitrage_notifications"" DEVSTACK_LOCAL_CONFIG+=$'\n'""notification_driver=messagingv2""$BASE/new/devstack-gate/devstack-vm-gate.sh",27,18
openstack%2Ffuel-devops~master~I941af738fa4f7b510c565ec04dad50a32f7d4a1c,openstack/fuel-devops,master,I941af738fa4f7b510c565ec04dad50a32f7d4a1c,Add blocking traffic in network or interface,MERGED,2016-04-19 16:47:53.000000000,2016-05-05 11:13:02.000000000,2016-05-05 11:07:23.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19011}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-04-19 16:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/aec53868ca3159b8374ff52d31d0cc904dcaa71d', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}, {'number': 2, 'created': '2016-04-26 09:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f30d251f10e20701ea66bc2092e14dcfa92c8a86', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}, {'number': 3, 'created': '2016-04-27 14:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/8c5f43cc2afdb66941cc492d401e89abd7632071', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}, {'number': 4, 'created': '2016-04-28 12:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/2b97793ba2620cc6dfef7facd52f3f5dc215815c', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}, {'number': 5, 'created': '2016-04-28 13:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/08fed0ddbffd693f83b1e08d36dad12df309be0a', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}, {'number': 6, 'created': '2016-04-29 08:15:43.000000000', 'files': ['devops/driver/libvirt/libvirt_driver.py', 'devops/migrations/0001_initial.py', 'devops/driver/dummy/__init__.py', 'devops/models/network.py', 'devops/tests/driver/libvirt/test_xml_builder.py', 'devops/tests/driver/test_driver_imports.py', 'devops/tests/driver/libvirt/base.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/driver/libvirt/__init__.py', 'devops/models/node.py', 'devops/tests/driver/libvirt/test_node_snapshot.py', 'devops/tests/driver/libvirt/test_l2_network_device.py', 'devops/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/6ca8d71d1390b82251604599ac23b2fda5a0fd5f', 'message': 'Add blocking traffic in network or interface\n\nAdd method to Interface and L2NeworkDevice models for blocking traffic\n\nChange-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c\nRelated-bug: #1512773\n'}]",0,307918,6ca8d71d1390b82251604599ac23b2fda5a0fd5f,48,11,6,19011,,,0,"Add blocking traffic in network or interface

Add method to Interface and L2NeworkDevice models for blocking traffic

Change-Id: I941af738fa4f7b510c565ec04dad50a32f7d4a1c
Related-bug: #1512773
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/18/307918/6 && git format-patch -1 --stdout FETCH_HEAD,"['devops/driver/libvirt/libvirt_driver.py', 'devops/migrations/0003_refactoring.py', 'devops/models/network.py', 'devops/tests/driver/libvirt/test_xml_builder.py', 'devops/models/node.py', 'devops/tests/driver/libvirt/base.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/tests/driver/libvirt/test_node_snapshot.py', 'devops/tests/driver/libvirt/test_l2_network_device.py', 'devops/models/environment.py']",10,aec53868ca3159b8374ff52d31d0cc904dcaa71d,bp/fuel-devops-multiple-databases, for group in self.get_groups(): for l2netdev in group.get_l2_network_devices(): l2netdev.unblock() ,,336,31
openstack%2Ffuel-qa~master~I49a6f7736095a5e117a7e4a923ee989b9cd546ed,openstack/fuel-qa,master,I49a6f7736095a5e117a7e4a923ee989b9cd546ed,Fix test_gpg_signging tests,MERGED,2016-04-18 15:13:22.000000000,2016-05-05 10:56:32.000000000,2016-05-05 10:56:32.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 12817}, {'_account_id': 12867}, {'_account_id': 15984}, {'_account_id': 19119}, {'_account_id': 19120}, {'_account_id': 20519}]","[{'number': 1, 'created': '2016-04-18 15:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/5c4742f3b88a3d1149f39d0a08701237bd6c6a7a', 'message': 'Fix test_gpg_signging tests\n\n+Add fuel_release version to the repo path instead of hardcoded 8.0\n\nChange-Id: I49a6f7736095a5e117a7e4a923ee989b9cd546ed\nCloses-Bug: #1571570\n'}, {'number': 2, 'created': '2016-04-19 07:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/de9cf650f9f91a86d038f8b6cf1e27ab49a33a94', 'message': 'Fix test_gpg_signging tests\n\n+Add fuel_release version to the repo path instead of hardcoded 8.0\n\nChange-Id: I49a6f7736095a5e117a7e4a923ee989b9cd546ed\nCloses-Bug: #1571570\n'}, {'number': 3, 'created': '2016-04-26 13:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/86e19d1f086b2a81bc56e69fafffa27e1bb5495a', 'message': 'Fix test_gpg_signging tests\n\n+Add fuel_release version to the repo path instead of hardcoded 8.0\n\nChange-Id: I49a6f7736095a5e117a7e4a923ee989b9cd546ed\nCloses-Bug: #1571570\n'}, {'number': 4, 'created': '2016-04-27 08:03:45.000000000', 'files': ['fuelweb_test/tests/test_admin_node.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d37745c01055fda0c905d709ba0db9b742d1a117', 'message': 'Fix test_gpg_signging tests\n\n+Add fuel_release version to the repo path instead of hardcoded 8.0\n\nChange-Id: I49a6f7736095a5e117a7e4a923ee989b9cd546ed\nCloses-Bug: #1571570\n'}]",3,307316,d37745c01055fda0c905d709ba0db9b742d1a117,40,12,4,20519,,,0,"Fix test_gpg_signging tests

+Add fuel_release version to the repo path instead of hardcoded 8.0

Change-Id: I49a6f7736095a5e117a7e4a923ee989b9cd546ed
Closes-Bug: #1571570
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/16/307316/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_admin_node.py', 'fuelweb_test/settings.py']",3,5c4742f3b88a3d1149f39d0a08701237bd6c6a7a,bug/1571570,"CENTOS_REPO_PATH = os.environ.get( 'CENTOS_REPO_PATH', MOS_REPOS + 'centos/mos{release_version}-centos7-fuel/') UBUNTU_REPO_PATH = os.environ.get( 'UBUNTU_REPO_PATH', MOS_REPOS + 'ubuntu/{release_version}/') GPG_CENTOS_KEY_PATH = os.environ.get( 'GPG_CENTOS_KEY', CENTOS_REPO_PATH + 'os/RPM-GPG-KEY-mos{release_version}')","CENTOS_REPO_PATH = os.environ.get('CENTOS_REPO_PATH', MOS_REPOS + 'centos/mos8.0-centos7-fuel/') UBUNTU_REPO_PATH = os.environ.get('UBUNTU_REPO_PATH', MOS_REPOS + 'ubuntu/8.0/') GPG_CENTOS_KEY = os.environ.get('GPG_CENTOS_KEY', CENTOS_REPO_PATH + 'os/RPM-GPG-KEY-mos8.0')",44,25
openstack%2Ffuel-web~master~Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a,openstack/fuel-web,master,Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a,Add migration for 'cgroups' field,ABANDONED,2016-04-26 20:03:05.000000000,2016-05-05 10:35:55.000000000,,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12559}, {'_account_id': 19158}, {'_account_id': 20384}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-04-26 20:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1177a3827b89d09c428abc6fb860ca047731ddf1', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 2, 'created': '2016-04-26 20:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0f5bcf3539ca60d40eb80eda6d2fa8453ac68774', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 3, 'created': '2016-04-26 20:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c3cf51d933974264a0d1e245f28b153013ae8feb', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 4, 'created': '2016-04-27 16:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/819b247e1617f1405e1a184281387d72715d09e5', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 5, 'created': '2016-04-29 16:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e03020081c1e96ce93f090eae750a5fd67194fac', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 6, 'created': '2016-04-29 16:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e52ad8e0f3f13b682ea3e1131ff963743234ad86', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}, {'number': 7, 'created': '2016-04-29 16:22:48.000000000', 'files': ['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0_1.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0_1.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2fd53cb53224f2ec600f7ebf11f18cc93566c159', 'message': ""Add migration for 'cgroups' field\n\nChange-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a\nCloses-Bug: #1575263\n""}]",7,310294,2fd53cb53224f2ec600f7ebf11f18cc93566c159,121,13,7,12559,,,0,"Add migration for 'cgroups' field

Change-Id: Iad5de47b6942cb1935e13cd36dddb9000ffd3f0a
Closes-Bug: #1575263
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/94/310294/6 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0.py']",2,1177a3827b89d09c428abc6fb860ca047731ddf1,(detached,"class TestClusterAttributesMigration(base.BaseAlembicMigrationTest): def _get_clusters_attrs(self): clusters_editable_attrs = self.meta.tables['attributes'].c.editable for row in db.execute(sa.select([clusters_editable_attrs])).fetchall(): yield jsonutils.loads(row[0]) for cluster_attrs in self._get_clusters_attrs(): def test_cgroups_cluster_attrs(self): for cluster_attrs in self._get_clusters_attrs(): self.assertIn('cgroups', cluster_attrs)",class TestCephAttributesMigration(base.BaseAlembicMigrationTest): clusters_attributes = self.meta.tables['attributes'] results = db.execute( sa.select([clusters_attributes.c.editable]) ).fetchall() for cluster_attrs_row in results: cluster_attrs = jsonutils.loads(cluster_attrs_row[0]),50,7
openstack%2Fopenstack-ansible-openstack_hosts~stable%2Fmitaka~I891e99fd624589ee36d6ce4892c835fa5ece9671,openstack/openstack-ansible-openstack_hosts,stable/mitaka,I891e99fd624589ee36d6ce4892c835fa5ece9671,global_environment_variable is undefined while templating,MERGED,2016-05-05 00:12:13.000000000,2016-05-05 10:25:51.000000000,2016-05-05 10:25:51.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}]","[{'number': 1, 'created': '2016-05-05 00:12:13.000000000', 'files': ['templates/environment.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/a69986e3d5774982d0a76bd98b1b88ad91cebf05', 'message': 'global_environment_variable is undefined while templating\n\nopenstack_hosts role uses global_environment_variable for\ncreating its environment.j2. If the variable is not defined\nthe templating will fail.\n\nThis should fix it.\n\nChange-Id: I891e99fd624589ee36d6ce4892c835fa5ece9671\n(cherry picked from commit 848cb5529e80dc458de2be2dccb6d6660d58b15d)\n'}]",0,312793,a69986e3d5774982d0a76bd98b1b88ad91cebf05,7,3,1,14805,,,0,"global_environment_variable is undefined while templating

openstack_hosts role uses global_environment_variable for
creating its environment.j2. If the variable is not defined
the templating will fail.

This should fix it.

Change-Id: I891e99fd624589ee36d6ce4892c835fa5ece9671
(cherry picked from commit 848cb5529e80dc458de2be2dccb6d6660d58b15d)
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/93/312793/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/environment.j2'],1,a69986e3d5774982d0a76bd98b1b88ad91cebf05,fix_global_environment_variable,{% if global_environment_variables is defined %}{% endif %} ,{% if global_environment_variables %}{% endif %},2,2
openstack%2Fopenstack-ansible~master~Iac61518129536ce613e91ac894883440a8704998,openstack/openstack-ansible,master,Iac61518129536ce613e91ac894883440a8704998,Use slurp to collect the keystone ssh keys,MERGED,2016-01-13 11:20:26.000000000,2016-05-05 10:06:38.000000000,2016-01-26 04:22:50.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-01-13 11:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/66795d936a77eaddde2d17710bf65cf4aaef5e4c', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}, {'number': 2, 'created': '2016-01-13 12:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9c3dd4407875ef80bce0580dfa92d343ba7e0b8c', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}, {'number': 3, 'created': '2016-01-13 13:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/16c3817185ac10f686c3c0651b9fc5ea52630ce4', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}, {'number': 4, 'created': '2016-01-14 10:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1617caf0373348a79f6a3f29edb7e6952883f4b9', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}, {'number': 5, 'created': '2016-01-22 09:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8172c90c6cd9cbbfc5d8264adef2f1beefb54702', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}, {'number': 6, 'created': '2016-01-25 15:15:48.000000000', 'files': ['playbooks/roles/os_keystone/tasks/keystone_key_populate.yml', 'playbooks/roles/os_keystone/tasks/keystone_key_distribute.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b030d8e2d1cc53187d56fa9e03b2266ce6196eef', 'message': 'Use slurp to collect the keystone ssh keys\n\nExtracting the ssh public key using cat and storing the result in a\nfact has resulted in periodic failures in the collection of the key,\nand thereafter the failure to appropriately place that key into the\nauthorised_keys file.\n\nThis patch changes the collection method to use the Ansible slurp\nmodule which has been found to be more reliable.\n\nChange-Id: Iac61518129536ce613e91ac894883440a8704998\n'}]",0,266842,b030d8e2d1cc53187d56fa9e03b2266ce6196eef,33,6,6,6816,,,0,"Use slurp to collect the keystone ssh keys

Extracting the ssh public key using cat and storing the result in a
fact has resulted in periodic failures in the collection of the key,
and thereafter the failure to appropriately place that key into the
authorised_keys file.

This patch changes the collection method to use the Ansible slurp
module which has been found to be more reliable.

Change-Id: Iac61518129536ce613e91ac894883440a8704998
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/42/266842/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_keystone/tasks/keystone_key_populate.yml', 'playbooks/roles/os_keystone/tasks/keystone_key_distribute.yml']",2,66795d936a77eaddde2d17710bf65cf4aaef5e4c,," key: ""{{ hostvars[item]['keystone_pubkey'] | b64decode }}"""," key: ""{{ hostvars[item]['keystone_pubkey'] }}""",4,4
openstack%2Fdragonflow~master~I69ec4db6835235d33726c6683aeccc92f79a33f0,openstack/dragonflow,master,I69ec4db6835235d33726c6683aeccc92f79a33f0,Fix parameter name in DBClientNotFound to be ip,MERGED,2016-04-27 08:37:21.000000000,2016-05-05 10:03:12.000000000,2016-05-05 08:52:19.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 18811}]","[{'number': 1, 'created': '2016-04-27 08:37:21.000000000', 'files': ['dragonflow/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1bcdb381e5328bc5264b1dfaa9d8682eabd2614f', 'message': 'Fix parameter name in DBClientNotFound to be ip\n\nWhen this exception is invoked, in redis_db_driver.py, the passed\nparameter is ip. This parameter name seems more correct considering\nhow it is being used.\n\nChange-Id: I69ec4db6835235d33726c6683aeccc92f79a33f0\n'}]",0,310371,1bcdb381e5328bc5264b1dfaa9d8682eabd2614f,12,4,1,20229,,,0,"Fix parameter name in DBClientNotFound to be ip

When this exception is invoked, in redis_db_driver.py, the passed
parameter is ip. This parameter name seems more correct considering
how it is being used.

Change-Id: I69ec4db6835235d33726c6683aeccc92f79a33f0
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/71/310371/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/common/exceptions.py'],1,1bcdb381e5328bc5264b1dfaa9d8682eabd2614f,redis," message = _('DB client not found, ip=%(ip)s')"," message = _('DB client not found, ip=%(key)s')",1,1
openstack%2Ffuel-library~master~Iadc1a71197c7bf8a75b1636c3dcdd84f6147d15e,openstack/fuel-library,master,Iadc1a71197c7bf8a75b1636c3dcdd84f6147d15e,[WIP] change configuration_sumlynk condition,ABANDONED,2016-05-04 10:33:29.000000000,2016-05-05 10:01:11.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 10:33:29.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/astute/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0bccc4b703c63883d03b5c0b70e23ca925fb4855', 'message': '[WIP] change configuration_sumlynk condition\n\nChange-Id: Iadc1a71197c7bf8a75b1636c3dcdd84f6147d15e\n'}]",0,312435,0bccc4b703c63883d03b5c0b70e23ca925fb4855,13,3,1,12661,,,0,"[WIP] change configuration_sumlynk condition

Change-Id: Iadc1a71197c7bf8a75b1636c3dcdd84f6147d15e
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/35/312435/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/astute/tasks.yaml'],1,0bccc4b703c63883d03b5c0b70e23ca925fb4855,, yaql_exp: 'changed($)', yaql_exp: '$.uid in added($.network_metadata.nodes.values()).uid',1,1
openstack%2Ffuel-web~master~I8e1d8627da15ca6735dd1efd568d075447ec387c,openstack/fuel-web,master,I8e1d8627da15ca6735dd1efd568d075447ec387c,Move tests to network manager extension,MERGED,2016-04-13 22:26:25.000000000,2016-05-05 10:00:01.000000000,2016-05-05 09:57:05.000000000,"[{'_account_id': 3}, {'_account_id': 6571}, {'_account_id': 8392}, {'_account_id': 8829}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 19158}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-13 22:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/720c30b7023a288795f735d705ef21bd615130a6', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 2, 'created': '2016-04-14 18:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c628e30ad510a83711a4e3299610bb35ced61317', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 3, 'created': '2016-04-14 21:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c254cbe5db73ba322c5050f9b5343118145af7ba', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 4, 'created': '2016-04-15 16:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b7ed1789d7c65a83ed737d8bd5ab4c4136015a56', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 5, 'created': '2016-04-15 16:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/96b8292be2cea8b845128fb54b96d40cab9c9349', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 6, 'created': '2016-04-15 17:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9e98a865642294fb2a64096942a69270d8dae9e2', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 7, 'created': '2016-04-15 21:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bbca92ddbbeb84c1a17f554b9e23fef3a6a4c877', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 8, 'created': '2016-04-25 17:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8f2633422c974ce6ea01080f304a52c6348f839b', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 9, 'created': '2016-04-25 18:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/039b796f7cc8e287ff27ecc293c964c72efe754d', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 10, 'created': '2016-04-25 20:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/59f2552f599269fd769e730a99fa895b6f8ccb37', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 11, 'created': '2016-04-26 22:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6e3272be48aa6d577912dfc5dbe712c5de06e008', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 12, 'created': '2016-04-27 21:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/50efac43fe9d6ba07d8f1e9c31815796aa6e06d1', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 13, 'created': '2016-04-29 16:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cb58c3276a69ce58bb3a614142ebf7cd7b5046a7', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 14, 'created': '2016-04-29 16:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e4e574f435f9e4836452fb67c50bb19e3853b6f6', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}, {'number': 15, 'created': '2016-05-04 16:49:28.000000000', 'files': ['nailgun/nailgun/extensions/network_manager/tests/test_network_manager.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template_validator.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template.py', 'nailgun/nailgun/extensions/network_manager/tests/test_objects.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_handlers_w_bonding.py', 'nailgun/nailgun/extensions/network_manager/tests/__init__.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_check.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template_apply.py', 'nailgun/nailgun/extensions/network_manager/tests/test_ip_addrs_management.py', 'nailgun/nailgun/extensions/network_manager/tests/test_ip_addr_validator.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_assignment.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_validation.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_collection_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_configuration_validator.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_configuration.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_group_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_utils.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_models.py', 'nailgun/nailgun/extensions/network_manager/tests/test_checknetworkstask.py', 'nailgun/nailgun/extensions/network_manager/tests/test_verify_node_interface_update.py', 'nailgun/nailgun/test/unit/test_objects.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bf476343666e12674168f4ad9b7545024ed6cf48', 'message': 'Move tests to network manager extension\n\nTests that cover network-related API handlers, validators,\nNetworkManager classes or database models have been moved to\nthe network manager extension.\n\nChange-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c\nBlueprint: network-manager-extension\n'}]",9,305513,bf476343666e12674168f4ad9b7545024ed6cf48,203,13,15,8829,,,0,"Move tests to network manager extension

Tests that cover network-related API handlers, validators,
NetworkManager classes or database models have been moved to
the network manager extension.

Change-Id: I8e1d8627da15ca6735dd1efd568d075447ec387c
Blueprint: network-manager-extension
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/13/305513/7 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/extensions/network_manager/tests/test_network_manager.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_handlers_w_bonding.py', 'nailgun/nailgun/extensions/network_manager/tests/__init__.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_check.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template_apply.py', 'nailgun/nailgun/extensions/network_manager/tests/test_ip_addr_validator.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_assignment.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_validation.py', 'nailgun/nailgun/extensions/network_manager/tests/test_node_nic_collection_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_configuration.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_group_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_template_handler.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_utils.py', 'nailgun/nailgun/extensions/network_manager/tests/test_network_models.py', 'nailgun/nailgun/extensions/network_manager/tests/test_checknetworkstask.py']",17,720c30b7023a288795f735d705ef21bd615130a6,bp/network-manager-extension,,,0,0
openstack%2Fkolla~master~I9910b4fba5ef11c26e687af3273e4fccaf5f235f,openstack/kolla,master,I9910b4fba5ef11c26e687af3273e4fccaf5f235f,Add a CONTRIBUTING.rst for Kolla,MERGED,2016-04-13 16:58:11.000000000,2016-05-05 09:49:59.000000000,2016-05-05 09:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 11105}, {'_account_id': 13039}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 16233}, {'_account_id': 16237}, {'_account_id': 16620}, {'_account_id': 16993}]","[{'number': 1, 'created': '2016-04-13 16:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/65f9ad5ece68d3b49c11d68d4eeb8341ca73b799', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 2, 'created': '2016-04-13 16:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4bacac111ab1831b391ace65385293f93a2717fa', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 3, 'created': '2016-04-14 12:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/23d13abf0273ef2a09da6ffa4b0ad8be67ab54cb', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 4, 'created': '2016-05-03 16:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8e7ed8ca322a0cee5a71406942c72941c8accf3b', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 5, 'created': '2016-05-04 02:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/613579ac6fde4c396ce1abf7997b2055ee21d026', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 6, 'created': '2016-05-04 02:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6fdee836d8f35abed7086dca0ae88e26bc573780', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}, {'number': 7, 'created': '2016-05-04 12:10:47.000000000', 'files': ['doc/CONTRIBUTING.rst', 'doc/index.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6dfc1ef650ea6ed369f9c1939c78af47308b42e2', 'message': 'Add a CONTRIBUTING.rst for Kolla\n\nChange-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f\nCloses-Bug: #1570017\n'}]",22,305402,6dfc1ef650ea6ed369f9c1939c78af47308b42e2,35,10,7,16233,,,0,"Add a CONTRIBUTING.rst for Kolla

Change-Id: I9910b4fba5ef11c26e687af3273e4fccaf5f235f
Closes-Bug: #1570017
",git fetch https://review.opendev.org/openstack/kolla refs/changes/02/305402/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,65f9ad5ece68d3b49c11d68d4eeb8341ca73b799,,"================= How To Contribute ================= Basics ~~~~~~ * Our source code is hosted on `OpenStack GitHub`_, but please do not send pull requests there. * Please follow usual OpenStack `Gerrit Workflow`_ to submit a patch. * Note the branch you're proposing changes to. ``master`` is the current focus of development, use ``stable/VERSION`` for proposing an urgent fix, where ``VERSION`` is the current stable series. * Please file a launchpad_ blueprint for any significant code change and a bug for any significant bug fix or add a TrivialFix tag for simple changes. .. _OpenStack GitHub: https://github.com/openstack/kolla .. _Gerrit Workflow: http://docs.openstack.org/infra/manual/developers.html#development-workflow .. _launchpad: https://bugs.launchpad.net/kolla Development Environment ~~~~~~~~~~~~~~~~~~~~~~~ * Please follow our QuickStart `Kolla QuickStart`_ to deploy your environment .. _Kolla QuickStart: http://docs.openstack.org/developer/kolla/quickstart.html ",,29,0
openstack%2Fkolla~stable%2Fmitaka~Ieda226e652d67f5b5667112f4f2556f3171366d3,openstack/kolla,stable/mitaka,Ieda226e652d67f5b5667112f4f2556f3171366d3,Remove dependencies on kazoo and friends,MERGED,2016-05-04 22:54:14.000000000,2016-05-05 09:49:53.000000000,2016-05-05 09:49:52.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 14027}]","[{'number': 1, 'created': '2016-05-04 22:54:14.000000000', 'files': ['docker/base/set_configs.py', 'docker/base/Dockerfile.j2', 'tests/test_set_config.py', 'docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ece6638d268e81bdf119d29ca30b7d464876aacc', 'message': 'Remove dependencies on kazoo and friends\n\nSince kolla-mesos has been retired, there is no need in the code\nbase to keep the zookeeper implementation.  As a result, just remove\nit.  If we were to keep it we need virtualenvs for that part of the\ncode base which installs the python dependencies related to it\nfor from-binary installs.\n\nThis just simplifies the implementation tremendously and culls dead\ncode.\n\nCloses-Bug: #1577194\n(cherry picked from commit 025d57f82005a4ea92950f9b4d717c88f647d15f)\n\nConflicts:\n\tdocker/base/Dockerfile.j2\n\tdocker/kolla-toolbox/Dockerfile.j2\n\nChange-Id: Ieda226e652d67f5b5667112f4f2556f3171366d3\n'}]",0,312777,ece6638d268e81bdf119d29ca30b7d464876aacc,7,3,1,2834,,,0,"Remove dependencies on kazoo and friends

Since kolla-mesos has been retired, there is no need in the code
base to keep the zookeeper implementation.  As a result, just remove
it.  If we were to keep it we need virtualenvs for that part of the
code base which installs the python dependencies related to it
for from-binary installs.

This just simplifies the implementation tremendously and culls dead
code.

Closes-Bug: #1577194
(cherry picked from commit 025d57f82005a4ea92950f9b4d717c88f647d15f)

Conflicts:
	docker/base/Dockerfile.j2
	docker/kolla-toolbox/Dockerfile.j2

Change-Id: Ieda226e652d67f5b5667112f4f2556f3171366d3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/77/312777/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/set_configs.py', 'docker/base/Dockerfile.j2', 'tests/test_set_config.py', 'docker/kolla-toolbox/Dockerfile.j2']",4,ece6638d268e81bdf119d29ca30b7d464876aacc,bug/1577194, && yum clean all, && yum clean all \ && rpm -e --nodeps pytz python-babel,2,139
openstack%2Fkolla~master~I81c44c3d2cf5172e1b03928fe40c552e2a79f50a,openstack/kolla,master,I81c44c3d2cf5172e1b03928fe40c552e2a79f50a,Look for private interface's MAC address in vagrant-hostmanager,ABANDONED,2016-04-15 06:28:32.000000000,2016-05-05 09:49:47.000000000,,"[{'_account_id': 3}, {'_account_id': 14027}]","[{'number': 1, 'created': '2016-04-15 06:28:32.000000000', 'files': ['dev/vagrant/newest_dhcp_lease.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/19823cdc0d4331446b1c1fe16a1c9c009f9089c8', 'message': ""Look for private interface's MAC address in vagrant-hostmanager\n\nChange-Id: I81c44c3d2cf5172e1b03928fe40c552e2a79f50a\nCloses-Bug: 1570707\n""}]",0,306255,19823cdc0d4331446b1c1fe16a1c9c009f9089c8,4,2,1,14027,,,0,"Look for private interface's MAC address in vagrant-hostmanager

Change-Id: I81c44c3d2cf5172e1b03928fe40c552e2a79f50a
Closes-Bug: 1570707
",git fetch https://review.opendev.org/openstack/kolla refs/changes/55/306255/1 && git format-patch -1 --stdout FETCH_HEAD,['dev/vagrant/newest_dhcp_lease.py'],1,19823cdc0d4331446b1c1fe16a1c9c009f9089c8,bug/1570707,class NoPrivateInterfaceException(Exception): interfaces = devices.findall('interface') try: interface = interfaces[1] except KeyError: raise NoPrivateInterfaceException() mac_element = interface.find('mac') mac_address = mac_element.get('address') return mac_address,class NoPrivateDHCPInterfaceException(Exception): interfaces = devices.iterfind('interface') for interface in interfaces: source = interface.find('source') if source is None or source.get('network') != 'vagrant-private-dhcp': continue mac_element = interface.find('mac') mac_address = mac_element.get('address') return mac_address raise NoPrivateDHCPInterfaceException(),9,10
openstack%2Fkolla~master~I1797e32e32705182a763f53329eeb5c4a361abec,openstack/kolla,master,I1797e32e32705182a763f53329eeb5c4a361abec,Generate image dependencies on CLI,MERGED,2016-05-05 03:36:31.000000000,2016-05-05 09:48:41.000000000,2016-05-05 09:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 14027}, {'_account_id': 17731}]","[{'number': 1, 'created': '2016-05-05 03:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/17d321327cd849e4d77e8565e1f16a009d082e02', 'message': ""Generate image dependencies on CLI\n\nUsing the new --list-dependencies flag, one can query dependencies for a\ngiven filter. For example:\n\n./build.py --list-dependencies heat swift\n{'base': [{'openstack-base': [{'heat-base': ['heat-engine',\n                                             'heat-api-cfn',\n                                             'heat-api']},\n                              {'swift-base': ['swift-object',\n                                              'swift-proxy-server',\n                                              'swift-container',\n                                              'swift-rsyncd',\n                                              'swift-account']}]}]}\n\nAlso added --list-images to list all available images.\n\nChange-Id: I1797e32e32705182a763f53329eeb5c4a361abec\nImplements: blueprint images-dependency-tree-cli\n""}, {'number': 2, 'created': '2016-05-05 04:03:53.000000000', 'files': ['kolla/common/config.py', 'kolla/cmd/build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/696f0b9a06e415d8ef320bd8279c4911edbaca7f', 'message': ""Generate image dependencies on CLI\n\nUsing the new --list-dependencies flag, one can query dependencies for a\ngiven filter. For example:\n\n./build.py --list-dependencies heat swift\n{'base': [{'openstack-base': [{'heat-base': ['heat-engine',\n                                             'heat-api-cfn',\n                                             'heat-api']},\n                              {'swift-base': ['swift-object',\n                                              'swift-proxy-server',\n                                              'swift-container',\n                                              'swift-rsyncd',\n                                              'swift-account']}]}]}\n\nAlso added --list-images to list all available images.\n\nChange-Id: I1797e32e32705182a763f53329eeb5c4a361abec\nImplements: blueprint images-dependency-tree-cli\n""}]",0,312816,696f0b9a06e415d8ef320bd8279c4911edbaca7f,9,4,2,3098,,,0,"Generate image dependencies on CLI

Using the new --list-dependencies flag, one can query dependencies for a
given filter. For example:

./build.py --list-dependencies heat swift
{'base': [{'openstack-base': [{'heat-base': ['heat-engine',
                                             'heat-api-cfn',
                                             'heat-api']},
                              {'swift-base': ['swift-object',
                                              'swift-proxy-server',
                                              'swift-container',
                                              'swift-rsyncd',
                                              'swift-account']}]}]}

Also added --list-images to list all available images.

Change-Id: I1797e32e32705182a763f53329eeb5c4a361abec
Implements: blueprint images-dependency-tree-cli
",git fetch https://review.opendev.org/openstack/kolla refs/changes/16/312816/2 && git format-patch -1 --stdout FETCH_HEAD,"['kolla/common/config.py', 'kolla/cmd/build.py']",2,17d321327cd849e4d77e8565e1f16a009d082e02,bp/images-dependency-tree-cli,"from __future__ import print_functionimport pprint def list_images(self): for count, image in enumerate(self.images): print(count + 1, ':', image['name']) def list_dependencies(self): for image in self.images: if image['parent'] is None: base = image def list_children(images, ancestry): children = ancestry.values()[0] for item in images: if item['status'] not in ['matched']: continue if not item['children']: children.append(item['name']) else: newparent = {item['name']: []} children.append(newparent) list_children(item['children'], newparent) ancestry = {base['name']: []} list_children(base['children'], ancestry) pprint.pprint(ancestry) if conf.list_images: kolla.list_images() return if conf.list_dependencies: kolla.list_dependencies() return",,38,0
openstack%2Fswift-specs~master~I746ba547e0952d03ab9d949ea1a2e13d8b90c16a,openstack/swift-specs,master,I746ba547e0952d03ab9d949ea1a2e13d8b90c16a,Updateable Object Sysmeta,MERGED,2014-07-24 14:57:03.000000000,2016-05-05 09:47:15.000000000,2016-05-05 09:47:15.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-07-24 14:57:03.000000000', 'files': ['specs/swift/updateable-obj-sysmeta.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/ec7d869fe1411b03b63223bf7acd90f74c1360e3', 'message': ""Updateable Object Sysmeta\n\nThe goal of this work is to enable object\nsystem metadata to be persisted AND updated\nby 'fast-POST' requests. Unlike user metadata,\nit should be possible to update individual\nitems of system metadata independently when\nmaking a POST request to an object server.\n\nChange-Id: I746ba547e0952d03ab9d949ea1a2e13d8b90c16a\n""}]",0,109314,ec7d869fe1411b03b63223bf7acd90f74c1360e3,12,5,1,7847,,,0,"Updateable Object Sysmeta

The goal of this work is to enable object
system metadata to be persisted AND updated
by 'fast-POST' requests. Unlike user metadata,
it should be possible to update individual
items of system metadata independently when
making a POST request to an object server.

Change-Id: I746ba547e0952d03ab9d949ea1a2e13d8b90c16a
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/14/109314/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/swift/updateable-obj-sysmeta.rst'],1,ec7d869fe1411b03b63223bf7acd90f74c1360e3,p-updateable-obj-sysmeta,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: ""None"". For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ========================= Updateable Object Sysmeta ========================= The original system metadata patch ( https://review.openstack.org/#/c/51228/ ) supported only account and container system metadata. There are now patches in review that store middleware-generated metadata with objects, e.g.: * on demand migration https://review.openstack.org/#/c/64430/ * server side encryption https://review.openstack.org/#/c/76578/1 Object system metadata should not be stored in the x-object-meta- user metadata namespace because (a) there is a potential name conflict with arbitrarily named user metadata and (b) system metadata in the x-object-meta- namespace will be lost if a user sends a POST request to the object. A patch is under review ( https://review.openstack.org/#/c/79991/ ) that will persist system metadata that is included with an object PUT request, and ignore system metadata sent with POSTs. The goal of this work is to enable object system metadata to be persisted AND updated. Unlike user metadata, it should be possible to update individual items of system metadata independently when making a POST request to an object server. This work applies to fast-POST operation, not POST-as-copy operation. Problem Description =================== Item-by-item updates to metadata can be achieved by simple changes to the metadata read-modify-write cycle during a POST to the object server: read system metadata from existing data or meta file, merge new items, write to a new meta file. However, concurrent POSTs to a single server or inconsistent results between multiple servers can lead to multiple meta files containing divergent sets of system metadata. These must be preserved and eventually merged to achieve eventual consistency. Proposed Change =============== The proposed new behavior is to preserve multiple meta files in the obj_dir until their system metadata is known to have been read and merged into a newer meta file. When constructing a diskfile object, all existing meta files that are newer that the data file (usually just one) should be read for potential system metadata contributions. To enable a per-item most-recent-wins semantic when merging contributions from multiple meta files, system metadata should be stored in meta files as `key: (value, timestamp)` pairs. This is not necessary when system metadata is stored in a data file because the timestamp of those items is known to be that of the data file. When writing the diskfile during a POST, the merged set of system metadata should be written to the new meta file, after which the older meta files can be deleted. This requires a change to the diskfile cleanup code (`hash_cleanup_listdir`). After creating a new meta file, instead of deleting all older meta files, only those that were either older than the data file or read during construction of the new meta file are deleted. In most cases the result will be same, but if a second concurrent request has written a meta file that was not read by the first request handler then this meta file will be left in place. Similarly, a change is required in the async cleanup process (called by the replicator daemon). The cleanup process should merge any existing meta files into the most recent file before deleting older files. To reduce workload, this merge process could be conditional upon a threshold number of meta files being found. Replication considerations -------------------------- As a result of failures, object servers may have different existing meta files for an object when a POST is handled and a new (merged) metadata set is written to a new meta file. Consequently, object servers may end up with identically timestamped meta files having different system metadata content. rsync: To differentiate between these meta files it is proposed to include a hash of the metadata content in the name of the meta file. As a result, meta files with differing content will be replicated between object servers and their contents merged to achieve eventual consistency. The timestamp part of the meta filename is still required in order to (a) allow meta files older than a data or tombstone file to be deleted without being read and (b) to continue to record the modification time of user metadata. ssync - TBD Deleting system metadata ------------------------ An item of system metadata with key `x-object-sysmeta-x` should be deleted when a header `x-object-sysmeta-x:""""` is included with a POST request. This can be achieved by persisting the system metadata item in meta files with an empty value, i.e. `key : ("""", timestamp)`, to indicate to any future metadata merges that the item has been deleted. This guards against inclusion of obsolete values from older meta files at the expense of storing the empty value. The empty-valued system metadata may be finally removed during a subsequent merge when it is observed that some expiry time has passed since its timestamp (i.e. any older value that the empty value is overriding would have been replicated by this time, so it is safe to delete the empty value). Example ------- Consider the following scenario. Initially the object dir on each object server contains just the original data file:: obj_dir: t1.data: x-object-sysmeta-p: ('p1', t0) Two concurrent POSTs update the object on servers A and B, with timestamps t2 and t3, but fail on server C. One POST updates `x-object-sysmeta-p` and adds `x-object-sysmeta-y`. The other POST adds `x-object-sysmeta-z`. These POSTs result in two meta files being added to the object directory on A and B:: obj_dir: t1.data: x-object-sysmeta-p: ('p1', t0) t2.h2.meta: x-object-sysmeta-p: ('p2', t2) x-object-sysmeta-x: ('x1', t2) x-object-sysmeta-y: ('y1', t2) t3.h3.meta: x-object-sysmeta-p: ('p1', t0) x-object-sysmeta-x: ('x2', t3) x-object-sysmeta-z: ('z1', t3) (`hx` in filename represents hash of metadata) A response to a subsequent HEAD request would contain the composition of the two meta files' system metadata items:: x-object-sysmeta-p: 'p2' x-object-sysmeta-x: 'x2' x-object-sysmeta-y: 'y1' x-object-sysmeta-z: 'z1' A further POST request received at t4 deletes `x-object-sysmeta-p`. This causes the two meta files to be read, their contents merged and a new meta file to be written. This POST succeeds on all servers, so on servers A and B we have:: obj_dir: t1.data : x-object-sysmeta-p: ('p1', t0) t4.h4a.meta: x-object-sysmeta-p: ('', t4) x-object-sysmeta-x: ('x3', t3) x-object-sysmeta-z: ('z1', t3) x-object-sysmeta-y: ('y1', t2) whereas on server C we have:: obj_dir: t1.data : x-object-sysmeta-p: ('p1', t0) t4.h4b.meta: x-object-sysmeta-p: ('', t4) Eventually the meta files will be replicated between servers and merged, leaving all servers with:: obj_dir: t1.data : x-object-sysmeta-p: ('p1', t0) t4.h4a.meta: x-object-sysmeta-p: ('', t4) x-object-sysmeta-x: ('x3', t3) x-object-sysmeta-z: ('z1', t3) x-object-sysmeta-y: ('y1', t2) Alternatives ------------ One alternative approach would be to preserve all meta files that are newer than a data or tombstone file and never merge their contents. This removes the need to include a hash in the meta file name, but has the obvious disadvantage of accumulating an increasing number of files, each of which needs to be read when constructing a diskfile. Another alternative would store system metadata in separate `sysmeta` file. It may then be possible to discard the timestamp from the filename (if the `timestamp.hash` format is deemed too long). Implementation ============== Assignee(s) ----------- Primary assignee: Alistair Coles (acoles) Work Items ---------- TBD Repositories ------------ None Servers ------- None DNS Entries ----------- None Documentation ------------- No change to external API docs. Developer docs would be updated to make developers aware of the feature. Security -------- None Testing ------- Additional unit tests will be required for diskfile.py, object server. Probe tests will be useful to verify replication behavior. Dependencies ============ Patch for object system metadata on PUT only: https://review.openstack.org/#/c/79991/ Spec for updating containers on fast-POST: https://review.openstack.org/#/c/102592/ There is a mutual dependency between this spec and the spec to update containers on fast-POST: the latter requires content-type to be treated as an item of mutable system metadata, which this spec aims to enable. This spec assumes that fast-POST becomes usable, which requires consistent container updates to be enabled.",,270,0
openstack%2Fdragonflow~master~Idfa8495bd00d48f6dbe2471c206bbc3d5cf8f2f8,openstack/dragonflow,master,Idfa8495bd00d48f6dbe2471c206bbc3d5cf8f2f8,Enable tempest security group tests,MERGED,2016-05-04 06:58:49.000000000,2016-05-05 09:44:38.000000000,2016-05-05 09:44:38.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}]","[{'number': 1, 'created': '2016-05-04 06:58:49.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/41f8bf62a3565c1331e7a9a269d859b7f5ca0710', 'message': 'Enable tempest security group tests\n\nSecurity group application is merged, enable tempest tests\nfor security groups\n\nChange-Id: Idfa8495bd00d48f6dbe2471c206bbc3d5cf8f2f8\n'}]",0,312338,41f8bf62a3565c1331e7a9a269d859b7f5ca0710,10,3,1,11343,,,0,"Enable tempest security group tests

Security group application is merged, enable tempest tests
for security groups

Change-Id: Idfa8495bd00d48f6dbe2471c206bbc3d5cf8f2f8
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/38/312338/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,41f8bf62a3565c1331e7a9a269d859b7f5ca0710,,,"# skip tests that require security groups r=""$r|(?:tempest\.thirdparty\.boto\.test_ec2_instance_run\.InstanceRunTest\.test_compute_with_volumes.*)"" r=""$r|(?:tempest\.scenario\.test_security_groups.*)"" ",0,4
openstack%2Ffuel-library~stable%2Fmitaka~I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e,openstack/fuel-library,stable/mitaka,I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e,Fix half-hearted attempt to erase mnesia in OCF RA,MERGED,2016-04-12 15:38:30.000000000,2016-05-05 09:41:40.000000000,2016-05-05 09:38:05.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10489}, {'_account_id': 13344}, {'_account_id': 14985}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-04-12 15:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/175c6c65acc389118ea892a96b54b2ae4fb33156', 'message': 'Fix half-hearted attempt to erase mnesia in OCF RA\n\nocf_run does $(""$@""), so ""${MNESIA_FILES}/*"" wasn\'t expanded and mnesia\ndirectory wasn\'t actually cleaned up\n\nIt\'s safe to remove that directory completely - it will be re-created\nautomatically by mnesia.\n\nUpstream https://github.com/rabbitmq/rabbitmq-server/pull/724\n\nChange-Id: I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e\nCloses-Bug: 1565868\n'}, {'number': 2, 'created': '2016-04-13 14:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6d44b008e1c95772b4b407796aeba3e4169a63f7', 'message': 'Fix half-hearted attempt to erase mnesia in OCF RA\n\nCherry-picked from master (6e1d58557d54b0140f763733953f69a2c23396ac)\n\nocf_run does $(""$@""), so ""${MNESIA_FILES}/*"" wasn\'t expanded and mnesia\ndirectory wasn\'t actually cleaned up\n\nIt\'s safe to remove that directory completely - it will be re-created\nautomatically by mnesia.\n\nUpstream https://github.com/rabbitmq/rabbitmq-server/pull/724\n\nChange-Id: I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e\nCloses-Bug: 1565868\n'}, {'number': 3, 'created': '2016-05-04 11:39:43.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a2d9314432c5d7c31c18ffb981e9cf2c20898607', 'message': 'Fix half-hearted attempt to erase mnesia in OCF RA\n\nCherry-picked from master (6e1d58557d54b0140f763733953f69a2c23396ac)\n\nocf_run does $(""$@""), so ""${MNESIA_FILES}/*"" wasn\'t expanded and mnesia\ndirectory wasn\'t actually cleaned up\n\nIt\'s safe to remove that directory completely - it will be re-created\nautomatically by mnesia.\n\nUpstream https://github.com/rabbitmq/rabbitmq-server/pull/724\n\nChange-Id: I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e\nCloses-Bug: 1565868\n'}]",0,304711,a2d9314432c5d7c31c18ffb981e9cf2c20898607,48,8,3,18805,,,0,"Fix half-hearted attempt to erase mnesia in OCF RA

Cherry-picked from master (6e1d58557d54b0140f763733953f69a2c23396ac)

ocf_run does $(""$@""), so ""${MNESIA_FILES}/*"" wasn't expanded and mnesia
directory wasn't actually cleaned up

It's safe to remove that directory completely - it will be re-created
automatically by mnesia.

Upstream https://github.com/rabbitmq/rabbitmq-server/pull/724

Change-Id: I0aa47f61e03c99ee6ebb56b833463cdf4ccd243e
Closes-Bug: 1565868
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/11/304711/3 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,175c6c65acc389118ea892a96b54b2ae4fb33156,bug/1565868," ocf_run rm -rf ""${MNESIA_FILES}"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed from ${MNESIA_FILES}."""," ocf_run rm -rf ""${MNESIA_FILES}/*"" ocf_log warn ""${LH} Mnesia files appear corrupted and have been removed.""",2,2
openstack%2Foslo.messaging~master~If25edf500fa8d220d4233bb13d67121824e841c6,openstack/oslo.messaging,master,If25edf500fa8d220d4233bb13d67121824e841c6,[zmq] Redesign router proxy,MERGED,2016-04-20 22:08:33.000000000,2016-05-05 09:36:59.000000000,2016-05-05 09:36:58.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 13290}]","[{'number': 1, 'created': '2016-04-20 22:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6685c3bd7192bf4bc05817d1c59f4ac764ba6232', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 2, 'created': '2016-04-20 22:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/659475ecf6701d106a8be95b6b1663e237d7853a', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 3, 'created': '2016-04-21 12:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7fde69644f395bda5bd8d8f5e5bf96248b67ed00', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 4, 'created': '2016-04-26 03:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bd689ec2bd4a6703adb49543258c89e8514e2e08', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 5, 'created': '2016-04-26 03:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5708d3cddcc28407d148d9c9370acb2e10bd9885', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 6, 'created': '2016-04-26 04:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e76c6e8a62195439b7344a8c6f1ce689c55834a4', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 7, 'created': '2016-04-26 04:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b2724177a6b4bacd196659ecc2d81fa69e6f6cbf', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 8, 'created': '2016-04-28 05:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9f4386c1d20c5985d0e2b2e457c0ed40e1bae119', 'message': 'WIP: [zmq] Test mixed proxy\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\n'}, {'number': 9, 'created': '2016-04-28 08:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/53bf8b3796a1d8ff628d9e6f1bed7e3a532413da', 'message': '[zmq] Redesign router proxy into DEALER(cli)-ROUTER(proxy)-DEALER(srv)\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 10, 'created': '2016-04-28 08:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f611da176a61e51638c7a6189f953c5c9c94983a', 'message': '[zmq] Redesign router proxy into DEALER(cli)-ROUTER(proxy)-DEALER(srv)\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 11, 'created': '2016-04-28 09:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7bcca7a2f5e1a539edbabca6c9e3381e7d58b30b', 'message': '[zmq] Redesign router proxy into\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 12, 'created': '2016-04-28 09:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/32d1e48bf3999e59f1b6ef09e4dd18b4666a5565', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 13, 'created': '2016-04-28 11:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/21bce66ece9924f51cc23bf2dc0a37d540d2c63f', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 14, 'created': '2016-04-28 12:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/466194b2045e692bfe6c3742620b059f3eaaf38b', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 15, 'created': '2016-04-28 13:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3c8d1fa73c9d6198cb6accba56f2e1a0c16c34a9', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 16, 'created': '2016-04-28 13:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/66a5a281d3b7c8d07cb6d1eb38f6479f7eb4b130', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 17, 'created': '2016-04-28 13:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/20a16c6ade379a98afddce9da3bc6448a4f4193d', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 18, 'created': '2016-05-02 21:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7b8ba6e1d9f1eb2e26e72b07decf635495f17881', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 19, 'created': '2016-05-02 21:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2a25b14bf464a69e59574e72be40fc650c694e4d', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 20, 'created': '2016-05-03 14:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ae04eaa499bb0dedf9f95571143ce997df82a465', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 21, 'created': '2016-05-04 00:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/984e2fb0c5778abff4dbbeb0de286c83d538a8b7', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 22, 'created': '2016-05-04 10:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ed30226aa4263c11df073e7c12f0d719836e7143', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 23, 'created': '2016-05-04 11:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c9ec75b12d79a5d9562ce7c3e8911d3ff96419a1', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 24, 'created': '2016-05-04 12:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/92916e4be70e26ee3ea6adaa990c6d718089081c', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}, {'number': 25, 'created': '2016-05-04 12:12:22.000000000', 'files': ['oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_reply_waiter.py', 'oslo_messaging/_drivers/zmq_driver/broker/zmq_queue_proxy.py', 'oslo_messaging/_cmd/zmq_proxy.py', 'oslo_messaging/_drivers/zmq_driver/server/consumers/zmq_router_consumer.py', 'doc/source/zmq_driver.rst', 'oslo_messaging/_drivers/zmq_driver/server/zmq_server.py', 'oslo_messaging/_drivers/zmq_driver/server/consumers/zmq_sub_consumer.py', 'oslo_messaging/_drivers/zmq_driver/matchmaker/matchmaker_redis.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/zmq_publisher_base.py', 'oslo_messaging/_drivers/zmq_driver/client/zmq_client.py', 'oslo_messaging/_drivers/zmq_driver/client/zmq_envelope.py', 'oslo_messaging/_drivers/zmq_driver/client/zmq_request.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_dealer_publisher_proxy.py', 'oslo_messaging/_drivers/zmq_driver/server/consumers/zmq_dealer_consumer.py', 'oslo_messaging/_drivers/impl_zmq.py', 'oslo_messaging/_drivers/zmq_driver/server/consumers/zmq_pull_consumer.py', 'oslo_messaging/_drivers/zmq_driver/zmq_names.py', 'oslo_messaging/tests/drivers/zmq/matchmaker/test_impl_matchmaker.py', 'setup-test-env-zmq.sh', 'oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_dealer_publisher.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_dealer_call_publisher.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/zmq_pub_publisher.py', 'oslo_messaging/tests/functional/zmq/test_startup.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b5955b6ca938bfccfeefb37062bb5ff81c8895a4', 'message': '[zmq] Redesign router proxy\n\nIn this change router was redesigned in a way most\nappropriate for routing concept of zmq.ROUTER socket.\n\nDEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of\nDEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)\n\nThe main reason is to use zmq.DEALER identity in message\nrouting. For this reason DealerConsumer was introduced\nserver-side. RouterConsumer is left for peer-to-peer\nDEALER-ROUTER deployment option.\n\nAlso handled assertions in receive-methods in order\nto not stop server when received message with wrong format.\n\nChange-Id: If25edf500fa8d220d4233bb13d67121824e841c6\nCloses-Bug: #1558601\nRelated-Bug: #1555007\n'}]",0,308653,b5955b6ca938bfccfeefb37062bb5ff81c8895a4,58,3,25,13290,,,0,"[zmq] Redesign router proxy

In this change router was redesigned in a way most
appropriate for routing concept of zmq.ROUTER socket.

DEALER(cli)-ROUTER(proxy)-DEALER(srv) instead of
DEALER-ROUTER-DEALER-ROUTER (3 layers instead of 4)

The main reason is to use zmq.DEALER identity in message
routing. For this reason DealerConsumer was introduced
server-side. RouterConsumer is left for peer-to-peer
DEALER-ROUTER deployment option.

Also handled assertions in receive-methods in order
to not stop server when received message with wrong format.

Change-Id: If25edf500fa8d220d4233bb13d67121824e841c6
Closes-Bug: #1558601
Related-Bug: #1555007
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/53/308653/18 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/_drivers/impl_zmq.py', 'oslo_messaging/_drivers/zmq_driver/broker/zmq_queue_proxy.py', 'oslo_messaging/_cmd/zmq_proxy.py', 'setup-test-env-zmq.sh', 'oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_dealer_publisher.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/dealer/zmq_dealer_call_publisher.py', 'oslo_messaging/_drivers/zmq_driver/client/publishers/zmq_publisher_base.py', 'oslo_messaging/_drivers/zmq_driver/client/zmq_client.py']",8,6685c3bd7192bf4bc05817d1c59f4ac764ba6232,bug/1569530,"from oslo_messaging._drivers.zmq_driver.client.publishers \ import zmq_publisher_base self.sockets_manager = zmq_publisher_base.SocketsManager( conf, matchmaker, zmq.ROUTER, zmq.DEALER) publisher_to_proxy = zmq_dealer_publisher.DealerPublisherLight( conf, matchmaker, self.sockets_manager.get_socket_to_publishers()) cast_publisher = publisher_to_proxy if conf.use_router_proxy \ else zmq_dealer_publisher.DealerPublisherAsync( conf, matchmaker) fanout_publisher = publisher_to_proxy \ if conf.use_pub_sub else default_publisher conf, matchmaker, self.sockets_manager),"," cast_publisher = zmq_dealer_publisher.DealerPublisherAsync( conf, matchmaker) \ if zmq_async.is_eventlet_concurrency(conf) \ else default_publisher fanout_publisher = zmq_dealer_publisher.DealerPublisherLight( conf, matchmaker) if conf.use_pub_sub else default_publisher conf, matchmaker),",63,93
openstack%2Fceilometer~master~Ia1cfc87cfc1e72aab02900df11b5f4a0905ad247,openstack/ceilometer,master,Ia1cfc87cfc1e72aab02900df11b5f4a0905ad247,Clean the deprecated option database_connection,ABANDONED,2016-05-05 08:44:10.000000000,2016-05-05 09:35:20.000000000,,"[{'_account_id': 8290}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-05-05 08:44:10.000000000', 'files': ['ceilometer/opts.py', 'ceilometer/storage/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/878e29481ea2e606f9c092b07d7da4a6456d2412', 'message': 'Clean the deprecated option database_connection\n\nThis config option has been deprecated long ago, see patch:\nI582d4cb7d51d6ddecc27ae5fcdedcfd19dc898af\n\nChange-Id: Ia1cfc87cfc1e72aab02900df11b5f4a0905ad247\n'}]",0,312861,878e29481ea2e606f9c092b07d7da4a6456d2412,4,2,1,8290,,,0,"Clean the deprecated option database_connection

This config option has been deprecated long ago, see patch:
I582d4cb7d51d6ddecc27ae5fcdedcfd19dc898af

Change-Id: Ia1cfc87cfc1e72aab02900df11b5f4a0905ad247
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/312861/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/opts.py', 'ceilometer/storage/__init__.py']",2,878e29481ea2e606f9c092b07d7da4a6456d2412,rm-database_connection,,"OLD_OPTS = [ cfg.StrOpt('database_connection', secret=True, help='DEPRECATED - Database connection string.', ), ] cfg.CONF.register_opts(OLD_OPTS) if conf.database_connection: conf.set_override('connection', conf.database_connection, group='database')",0,14
openstack%2Fneutron~master~If08020152d335847969b5c5e374d442a560f889b,openstack/neutron,master,If08020152d335847969b5c5e374d442a560f889b,Add timestamp to neutron ext resources.,ABANDONED,2016-03-09 02:12:45.000000000,2016-05-05 09:24:20.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15309}, {'_account_id': 15752}, {'_account_id': 20066}]","[{'number': 1, 'created': '2016-03-09 02:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ef483b2d1f773d32b98f0ce075fa444ab91d305', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 2, 'created': '2016-03-09 03:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/73dda0e0345eb0d9a0ca50d62d3d95d70d06a58d', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 3, 'created': '2016-03-09 05:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/791a28acccf924a6ae0a4f706cf5549b20e29f8b', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 4, 'created': '2016-03-10 09:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c2721d53d8d2b3e33251356bb6c4f0ed2cd96ee', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 5, 'created': '2016-03-14 00:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5689c8773a58b3eb0584f4107d0dfd8dd0c8261', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 6, 'created': '2016-03-17 00:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4bc3093b520e14abac691033be2a0d75aa83f6d', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 7, 'created': '2016-03-17 01:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/472ee650870c2b105f1f7c7a7162f4f67ae9c24b', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}, {'number': 8, 'created': '2016-03-17 09:33:13.000000000', 'files': ['neutron/services/timestamp/timestamp_plugin.py', 'neutron/extensions/timestamp_core.py', 'neutron/tests/api/test_timestamp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cf0e7020c217d9a22963389d2887b712593fad8', 'message': ""Add timestamp to neutron ext resources.\n\nNow timestamp make timestamp field into db which resources'model inherit\nfrom HasStandardAttributes. But extenstion resource like router,\nfloatingip, security_group and security_group_rule cannot show to users.\n\nSo this patch make these extension resources can be showed, subscribe the\nextend_timestamp function and extend extention api map.\n\nCloses-Bug: #1554390\nChange-Id: If08020152d335847969b5c5e374d442a560f889b\n""}]",2,290234,3cf0e7020c217d9a22963389d2887b712593fad8,75,12,8,15309,,,0,"Add timestamp to neutron ext resources.

Now timestamp make timestamp field into db which resources'model inherit
from HasStandardAttributes. But extenstion resource like router,
floatingip, security_group and security_group_rule cannot show to users.

So this patch make these extension resources can be showed, subscribe the
extend_timestamp function and extend extention api map.

Closes-Bug: #1554390
Change-Id: If08020152d335847969b5c5e374d442a560f889b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/290234/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/timestamp/timestamp_plugin.py', 'neutron/extensions/timestamp_core.py', 'neutron/tests/api/test_timestamp.py']",3,5ef483b2d1f773d32b98f0ce075fa444ab91d305,bug/1554390,"from neutron.tests.api import base_routers from neutron.tests.api import base_security_groups from neutron.tests.tempest import config CONF = config.CONF class TestTimeStampWithExtResource(base_routers.BaseRouterTest, base_security_groups.BaseSecGroupTest): @classmethod def skip_checks(cls): super(TestTimeStampWithExtResource, cls).skip_checks() if not test.is_extension_enabled('timestamp_core', 'network'): raise cls.skipException(""timestamp_core extension not enabled"") @classmethod def resource_setup(cls): super(TestTimeStampWithExtResource, cls).resource_setup() cls.ext_net_id = CONF.network.public_network_id @test.idempotent_id('462be770-b310-4df9-9c42-773217e4c8b1') def test_create_router_with_timestamp(self): router = self.create_router(router_name='test') # Verifies body contains timestamp fields self.assertIsNotNone(router['created_at']) self.assertIsNotNone(router['updated_at']) @test.idempotent_id('4db5417a-e11c-474d-a361-af00ebef57c5') def test_update_router_with_timestamp(self): router = self.create_router(router_name='test') origin_updated_at = router['updated_at'] update_body = {'name': router['name'] + 'new'} body = self.admin_client.update_router(router['id'], **update_body) updated_router = body['router'] new_updated_at = updated_router['updated_at'] self.assertEqual(router['created_at'], updated_router['created_at']) # Verify that origin_updated_at is not same with new_updated_at self.assertIsNot(origin_updated_at, new_updated_at) @test.idempotent_id('2ac50ab2-7ebd-4e27-b3ce-a9e399faaea2') def test_show_router_attribute_with_timestamp(self): router = self.create_router(router_name='test') body = self.client.show_router(router['id']) show_router = body['router'] # verify the timestamp from creation and showed is same self.assertEqual(router['created_at'], show_router['created_at']) self.assertEqual(router['updated_at'], show_router['updated_at']) @test.idempotent_id('8ee55186-454f-4b97-9f9f-eb2772ee891c') def test_create_floatingip_with_timestamp(self): fip = self.create_floatingip(self.ext_net_id) # Verifies body contains timestamp fields self.assertIsNotNone(fip['created_at']) self.assertIsNotNone(fip['updated_at']) @test.idempotent_id('a490215a-6f4c-4af9-9a4c-57c41f1c4fa1') def test_update_floatingip_with_timestamp(self): fip = self.create_floatingip(self.ext_net_id) origin_updated_at = fip['updated_at'] update_body = {'description': 'new'} body = self.admin_client.update_floatingip(fip['id'], **update_body) updated_fip = body['floatingip'] new_updated_at = updated_fip['updated_at'] self.assertEqual(fip['created_at'], updated_fip['created_at']) # Verify that origin_updated_at is not same with new_updated_at self.assertIsNot(origin_updated_at, new_updated_at) @test.idempotent_id('1836a086-e7cf-4141-bf57-0cfe79e8051e') def test_show_floatingip_attribute_with_timestamp(self): fip = self.create_floatingip(self.ext_net_id) body = self.client.show_floatingip(fip['id']) show_fip = body['floatingip'] # verify the timestamp from creation and showed is same self.assertEqual(fip['created_at'], show_fip['created_at']) self.assertEqual(fip['updated_at'], show_fip['updated_at']) @test.idempotent_id('e2450a7b-d84f-4600-a093-45e78597bbac') def test_create_sg_with_timestamp(self): sg, _ = self._create_security_group() # Verifies body contains timestamp fields self.assertIsNotNone(sg['security_group']['created_at']) self.assertIsNotNone(sg['security_group']['updated_at']) @test.idempotent_id('4241e0d3-54b4-46ce-a9a7-093fc764161b') def test_update_sg_with_timestamp(self): sg, _ = self._create_security_group() origin_updated_at = sg['security_group']['updated_at'] update_body = {'name': sg['security_group']['name'] + 'new'} body = self.admin_client.update_security_group(sg['security_group']['id'], **update_body) updated_sg = body['security_group'] new_updated_at = updated_sg['updated_at'] self.assertEqual(sg['security_group']['created_at'], updated_sg['created_at']) # Verify that origin_updated_at is not same with new_updated_at self.assertIsNot(origin_updated_at, new_updated_at) @test.idempotent_id('584c6723-40b6-4f26-81dd-f508f9d9fb51') def test_show_sg_attribute_with_timestamp(self): sg, _ = self._create_security_group() body = self.client.show_security_group(sg['security_group']['id']) show_sg = body['security_group'] # verify the timestamp from creation and showed is same self.assertEqual(sg['security_group']['created_at'], show_sg['created_at']) self.assertEqual(sg['security_group']['updated_at'], show_sg['updated_at']) def _prepare_sgrule_test(self): sg, _ = self._create_security_group() sg_id = sg['security_group']['id'] direction = 'ingress' protocol = 'tcp' port_range_min = 77 port_range_max = 77 rule_create_body = self.client.create_security_group_rule( security_group_id=sg_id, direction=direction, ethertype=self.ethertype, protocol=protocol, port_range_min=port_range_min, port_range_max=port_range_max, remote_group_id=None, remote_ip_prefix=None ) return rule_create_body['security_group_rule'] @test.idempotent_id('87a8b196-4b90-44f0-b7f3-d2057d7d658e') def test_create_sgrule_with_timestamp(self): sgrule = self._prepare_sgrule_test() # Verifies body contains timestamp fields self.assertIsNotNone(sgrule['created_at']) self.assertIsNotNone(sgrule['updated_at']) @test.idempotent_id('1d3970e6-bcf7-46cd-b7d7-0807759c73b4') def test_show_sgrule_attribute_with_timestamp(self): sgrule = self._prepare_sgrule_test() body = self.client.show_security_group_rule(sgrule['id']) show_sgrule = body['security_group_rule'] # verify the timestamp from creation and showed is same self.assertEqual(sgrule['created_at'], show_sgrule['created_at']) self.assertEqual(sgrule['updated_at'], show_sgrule['updated_at'])",,161,2
openstack%2Fneutron~master~I5868dd8e3c2293be26fd7c99338f7c979f727533,openstack/neutron,master,I5868dd8e3c2293be26fd7c99338f7c979f727533,Move class properties to instances for dhcp tests,MERGED,2016-04-16 01:06:51.000000000,2016-05-05 09:18:58.000000000,2016-04-18 17:51:56.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9845}, {'_account_id': 11682}, {'_account_id': 14323}, {'_account_id': 14615}, {'_account_id': 16289}]","[{'number': 1, 'created': '2016-04-16 01:06:51.000000000', 'files': ['neutron/tests/unit/agent/linux/test_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e79137acc060db00c50fb8f0190768df0eb1296', 'message': 'Move class properties to instances for dhcp tests\n\nUsing class properties for tests always carries the risk of\nconflicting use between test cases when tests are run in parallel.\n\nRelated-Bug: #1569507\n\nChange-Id: I5868dd8e3c2293be26fd7c99338f7c979f727533\n'}]",0,306672,7e79137acc060db00c50fb8f0190768df0eb1296,20,10,1,6524,,,0,"Move class properties to instances for dhcp tests

Using class properties for tests always carries the risk of
conflicting use between test cases when tests are run in parallel.

Related-Bug: #1569507

Change-Id: I5868dd8e3c2293be26fd7c99338f7c979f727533
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/306672/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/agent/linux/test_dhcp.py'],1,7e79137acc060db00c50fb8f0190768df0eb1296,bug/1569507," def __init__(self): self.id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaa' self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_DHCP self.fixed_ips = [ FakeIPAllocation('192.168.0.1', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.mac_address = '00:00:80:aa:bb:ee' self.device_id = 'fake_dhcp_port' def __init__(self, id='reserved-aaaa-aaaa-aaaa-aaaaaaaaaaa'): self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_DHCP self.fixed_ips = [ FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.mac_address = '00:00:80:aa:bb:ee' self.device_id = constants.DEVICE_ID_RESERVED_DHCP_PORT def __init__(self, domain='openstacklocal'): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.admin_state_up = True self.device_owner = 'foo1' self.fixed_ips = [ FakeIPAllocation('192.168.0.2', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.mac_address = '00:00:80:aa:bb:cc' self.device_id = 'fake_port1' def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.admin_state_up = False self.device_owner = 'foo2' self.fixed_ips = [ FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.mac_address = '00:00:f3:aa:bb:cc' self.device_id = 'fake_port2' self.dns_assignment = [FakeDNSAssignment('192.168.0.3')] def __init__(self): self.id = '44444444-4444-4444-4444-444444444444' self.admin_state_up = True self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('192.168.0.4', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('192.168.1.2', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] self.dns_assignment = [FakeDNSAssignment('192.168.0.4'), FakeDNSAssignment('192.168.1.2')] self.mac_address = '00:00:0f:aa:bb:cc' self.device_id = 'fake_port3' def __init__(self): self.id = 'gggggggg-gggg-gggg-gggg-gggggggggggg' self.admin_state_up = False self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('192.168.0.4', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('ffda:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] self.dns_assignment = [ FakeDNSAssignment('192.168.0.4'), FakeDNSAssignment('ffda:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] self.mac_address = '00:16:3E:C2:77:1D' self.device_id = 'fake_port4' def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeee' self.admin_state_up = True self.device_owner = 'foo5' self.fixed_ips = [ FakeIPAllocation('192.168.0.5', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.dns_assignment = [FakeDNSAssignment('192.168.0.5')] self.mac_address = '00:00:0f:aa:bb:55' self.device_id = 'fake_port5' def __init__(self): self.id = 'ccccccccc-cccc-cccc-cccc-ccccccccc' self.admin_state_up = True self.device_owner = 'foo6' self.fixed_ips = [ FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.dns_assignment = [FakeDNSAssignment('192.168.0.6')] self.mac_address = '00:00:0f:aa:bb:66' self.device_id = 'fake_port6' def __init__(self, domain='openstacklocal'): self.id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' self.admin_state_up = True self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('fdca:3ba5:a17a:4ba3::2', 'ffffffff-ffff-ffff-ffff-ffffffffffff')] self.mac_address = '00:00:f3:aa:bb:cc' self.device_id = 'fake_port6' def __init__(self): self.id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' self.admin_state_up = True self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] self.dns_assignment = [ FakeDNSAssignment('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] self.mac_address = '00:16:3e:c2:77:1d' self.device_id = 'fake_port6' def __init__(self): self.id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' self.admin_state_up = True self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] self.dns_assignment = [ FakeDNSAssignment('192.168.0.3'), FakeDNSAssignment('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] self.mac_address = '00:16:3e:c2:77:1d' self.device_id = 'fake_port6' def __init__(self, domain='openstacklocal'): self.id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' self.admin_state_up = True self.device_owner = 'foo3' self.fixed_ips = [ FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('fdca:3ba5:a17a:4ba3::3', 'ffffffff-ffff-ffff-ffff-ffffffffffff')] self.mac_address = '00:00:0f:aa:bb:cc' self.device_id = 'fake_dual_port' self.id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_ROUTER_INTF self.mac_address = '00:00:0f:rr:rr:rr' self.device_id = 'fake_router_port' self.dns_assignment = [] def __init__(self): self.id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_ROUTER_INTF self.fixed_ips = [ FakeIPAllocation('192.168.1.1', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.dns_assignment = [FakeDNSAssignment('192.168.1.1')] self.mac_address = '00:00:0f:rr:rr:r2' self.device_id = 'fake_router_port2' def __init__(self): self.id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_DHCP self.fixed_ips = [ FakeIPAllocation('192.168.0.5', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.dns_assignment = [FakeDNSAssignment('192.168.0.5')] self.mac_address = '00:00:0f:dd:dd:dd' self.device_id = 'fake_multiple_agents_port' def __init__(self): self.id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' self.admin_state_up = True self.device_owner = constants.DEVICE_OWNER_DHCP self.fixed_ips = [ FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] self.dns_assignment = [FakeDNSAssignment('192.168.0.6')] self.mac_address = '00:00:0f:ee:ee:ee' self.device_id = 'fake_multiple_agents_port2' def __init__(self): self.destination = '20.0.0.1/24' self.nexthop = '20.0.0.1' def __init__(self): self.destination = constants.IPv4_ANY self.nexthop = '10.0.0.1' def __init__(self): self.destination = '2001:0200:feed:7ac0::/64' self.nexthop = '2001:0200:feed:7ac0::1' def __init__(self): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.ip_version = 4 self.cidr = '192.168.0.0/24' self.gateway_ip = '192.168.0.1' self.enable_dhcp = True self.host_routes = [FakeV4HostRoute()] self.dns_nameservers = ['8.8.8.8'] def __init__(self): super(FakeV4Subnet2, self).__init__() self.cidr = '192.168.1.0/24' self.gateway_ip = '192.168.1.1' self.host_routes = [] def __init__(self): super(FakeV4MetadataSubnet, self).__init__() self.cidr = '169.254.169.254/30' self.gateway_ip = '169.254.169.253' self.host_routes = [] self.dns_nameservers = [] def __init__(self): super(FakeV4SubnetGatewayRoute, self).__init__() self.host_routes = [FakeV4HostRouteGateway()] def __init__(self): super(FakeV4SubnetMultipleAgentsWithoutDnsProvided, self).__init__() self.dns_nameservers = [] self.host_routes = [] def __init__(self): super(FakeV4SubnetAgentWithManyDnsProvided, self).__init__() self.dns_nameservers = ['2.2.2.2', '9.9.9.9', '1.1.1.1', '3.3.3.3'] self.host_routes = [] def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.subnets = [FakeV4SubnetMultipleAgentsWithoutDnsProvided()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1(), FakePortMultipleAgents2()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.subnets = [FakeV4SubnetMultipleAgentsWithoutDnsProvided()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.subnets = [FakeV4SubnetAgentWithManyDnsProvided()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1()] self.namespace = 'qdhcp-ns' def __init__(self): super(FakeV4SubnetMultipleAgentsWithDnsProvided, self).__init__() self.host_routes = [] def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.subnets = [FakeV4SubnetMultipleAgentsWithDnsProvided()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1(), FakePortMultipleAgents2()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.ip_version = 6 self.cidr = 'fdca:3ba5:a17a:4ba3::/64' self.gateway_ip = 'fdca:3ba5:a17a:4ba3::1' self.enable_dhcp = True self.host_routes = [FakeV6HostRoute()] self.dns_nameservers = ['2001:0200:feed:7ac0::1'] self.ipv6_ra_mode = None self.ipv6_address_mode = None def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.ip_version = 4 self.cidr = '192.168.1.0/24' self.gateway_ip = '192.168.1.1' self.enable_dhcp = False self.host_routes = [] self.dns_nameservers = [] def __init__(self): self.id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' self.ip_version = 6 self.cidr = 'fdca:3ba5:a17a:4ba3::/64' self.gateway_ip = 'fdca:3ba5:a17a:4ba3::1' self.enable_dhcp = True self.host_routes = [FakeV6HostRoute()] self.dns_nameservers = ['2001:0200:feed:7ac0::1'] self.ipv6_ra_mode = None self.ipv6_address_mode = constants.DHCPV6_STATEFUL def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.ip_version = 6 self.cidr = 'ffda:3ba5:a17a:4ba3::/64' self.gateway_ip = 'ffda:3ba5:a17a:4ba3::1' self.enable_dhcp = True self.host_routes = [FakeV6HostRoute()] self.ipv6_address_mode = constants.IPV6_SLAAC self.ipv6_ra_mode = None def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.ip_version = 6 self.cidr = 'ffea:3ba5:a17a:4ba3::/64' self.gateway_ip = 'ffea:3ba5:a17a:4ba3::1' self.enable_dhcp = True self.dns_nameservers = [] self.host_routes = [] self.ipv6_address_mode = constants.DHCPV6_STATELESS self.ipv6_ra_mode = None def __init__(self): super(FakeV4SubnetNoGateway, self).__init__() self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.cidr = '192.168.1.0/24' self.gateway_ip = None self.enable_dhcp = True self.host_routes = [] self.dns_nameservers = [] def __init__(self): super(FakeV4SubnetNoRouter, self).__init__() self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.cidr = '192.168.1.0/24' self.gateway_ip = '192.168.1.1' self.host_routes = [] self.dns_nameservers = [] def __init__(self): self.id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakePort5(), FakePort6()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' self.subnets = [FakeV6Subnet()] self.ports = [FakePort2()] self.namespace = 'qdhcp-ns' def __init__(self, domain='openstacklocal'): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] self.ports = [FakePort1(), FakeV6Port(), FakeDualPort(), FakeRouterPort(), FakeReservedPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] self.ports = [FakePort1(), FakeV6Port(), FakeDualPort(), FakeRouterPort(), FakeReservedPort(), FakeReservedPort(id='reserved-2')] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakeDhcpPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4SubnetGatewayRoute(), FakeV6SubnetDHCPStateful()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV4SubnetNoDHCP()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV4Subnet2()] self.ports = [FakePort1(), FakeRouterPort(), FakeRouterPort2()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4SubnetNoGateway()] self.ports = [FakePort1()] def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4SubnetNoRouter()] self.ports = [FakePort1()] def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4MetadataSubnet()] self.ports = [FakeRouterPort(ip_address='169.254.169.253')] def __init__(self): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakeRouterPort( dev_owner=constants.DEVICE_OWNER_DVR_INTERFACE)] def __init__(self, port_detail=""portsSame""): self.id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' self.subnets = [FakeV4Subnet(), FakeV4SubnetNoDHCP()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self, port_detail=""portsSame""): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakePort2(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self, port_detail=""portsSame""): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.subnets = [FakeV6SubnetDHCPStateful()] self.ports = [FakeV6Port()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.subnets = [FakeV6SubnetDHCPStateful()] self.ports = [FakeV6Port()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.subnets = [FakeV4Subnet(), FakeV6SubnetSlaac()] self.ports = [FakePort1(), FakePort4(), FakeRouterPort()] def __init__(self): self.id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' self.subnets = [FakeV4Subnet(), FakeV6SubnetSlaac()] self.ports = [FakePort1(), FakePort4(), FakeRouterPort()] def __init__(self): self.id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' self.subnets = [FakeV4Subnet()] self.ports = [FakePort1(), FakeRouterPort()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' self.subnets = [FakeV6SubnetStateless()] self.ports = [FakeV6PortExtraOpt()] self.namespace = 'qdhcp-ns' def __init__(self): self.id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' self.subnets = [FakeV6SubnetStateless(), FakeV4Subnet()] self.ports = [FakeDualPortWithV6ExtraOpt(), FakeRouterPort()] self.namespace = 'qdhcp-ns' ipm_retval = {FakeV4SubnetNoGateway().id: '192.168.1.1'} ipm_retval = {FakeV4SubnetNoRouter().id: '192.168.1.2'} ipm_retval = {FakeV4Subnet().id: '192.168.0.1'} {FakeV4Subnet().id: '192.168.0.1'} dm = self._get_dnsmasq(FakeV4NetworkClientId()) dm = self._get_dnsmasq(FakeNetworkDhcpPort()) for alloc in FakeDhcpPort().fixed_ips]"," id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaa' admin_state_up = True device_owner = constants.DEVICE_OWNER_DHCP fixed_ips = [FakeIPAllocation('192.168.0.1', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] mac_address = '00:00:80:aa:bb:ee' device_id = 'fake_dhcp_port' def __init__(self): admin_state_up = True device_owner = constants.DEVICE_OWNER_DHCP fixed_ips = [FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] mac_address = '00:00:80:aa:bb:ee' device_id = constants.DEVICE_ID_RESERVED_DHCP_PORT def __init__(self, id='reserved-aaaa-aaaa-aaaa-aaaaaaaaaaa'): id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' admin_state_up = True device_owner = 'foo1' fixed_ips = [FakeIPAllocation('192.168.0.2', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] mac_address = '00:00:80:aa:bb:cc' device_id = 'fake_port1' def __init__(self, domain='openstacklocal'): id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' admin_state_up = False device_owner = 'foo2' fixed_ips = [FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] mac_address = '00:00:f3:aa:bb:cc' device_id = 'fake_port2' dns_assignment = [FakeDNSAssignment('192.168.0.3')] def __init__(self): id = '44444444-4444-4444-4444-444444444444' admin_state_up = True device_owner = 'foo3' fixed_ips = [FakeIPAllocation('192.168.0.4', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('192.168.1.2', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] dns_assignment = [FakeDNSAssignment('192.168.0.4'), FakeDNSAssignment('192.168.1.2')] mac_address = '00:00:0f:aa:bb:cc' device_id = 'fake_port3' def __init__(self): id = 'gggggggg-gggg-gggg-gggg-gggggggggggg' admin_state_up = False device_owner = 'foo3' fixed_ips = [FakeIPAllocation('192.168.0.4', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('ffda:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] dns_assignment = [ FakeDNSAssignment('192.168.0.4'), FakeDNSAssignment('ffda:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] mac_address = '00:16:3E:C2:77:1D' device_id = 'fake_port4' def __init__(self): id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeee' admin_state_up = True device_owner = 'foo5' fixed_ips = [FakeIPAllocation('192.168.0.5', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] dns_assignment = [FakeDNSAssignment('192.168.0.5')] mac_address = '00:00:0f:aa:bb:55' device_id = 'fake_port5' def __init__(self): id = 'ccccccccc-cccc-cccc-cccc-ccccccccc' admin_state_up = True device_owner = 'foo6' fixed_ips = [FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] dns_assignment = [FakeDNSAssignment('192.168.0.6')] mac_address = '00:00:0f:aa:bb:66' device_id = 'fake_port6' def __init__(self): id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' admin_state_up = True device_owner = 'foo3' fixed_ips = [FakeIPAllocation('fdca:3ba5:a17a:4ba3::2', 'ffffffff-ffff-ffff-ffff-ffffffffffff')] mac_address = '00:00:f3:aa:bb:cc' device_id = 'fake_port6' def __init__(self, domain='openstacklocal'): id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' admin_state_up = True device_owner = 'foo3' fixed_ips = [FakeIPAllocation('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] dns_assignment = [ FakeDNSAssignment('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] mac_address = '00:16:3e:c2:77:1d' device_id = 'fake_port6' def __init__(self): id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' admin_state_up = True device_owner = 'foo3' fixed_ips = [FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d', 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee')] dns_assignment = [ FakeDNSAssignment('192.168.0.3'), FakeDNSAssignment('ffea:3ba5:a17a:4ba3:0216:3eff:fec2:771d')] mac_address = '00:16:3e:c2:77:1d' device_id = 'fake_port6' def __init__(self): id = 'hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh' admin_state_up = True device_owner = 'foo3' fixed_ips = [FakeIPAllocation('192.168.0.3', 'dddddddd-dddd-dddd-dddd-dddddddddddd'), FakeIPAllocation('fdca:3ba5:a17a:4ba3::3', 'ffffffff-ffff-ffff-ffff-ffffffffffff')] mac_address = '00:00:0f:aa:bb:cc' device_id = 'fake_dual_port' def __init__(self, domain='openstacklocal'): id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' admin_state_up = True device_owner = constants.DEVICE_OWNER_ROUTER_INTF mac_address = '00:00:0f:rr:rr:rr' device_id = 'fake_router_port' dns_assignment = [] id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' admin_state_up = True device_owner = constants.DEVICE_OWNER_ROUTER_INTF fixed_ips = [FakeIPAllocation('192.168.1.1', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] dns_assignment = [FakeDNSAssignment('192.168.1.1')] mac_address = '00:00:0f:rr:rr:r2' device_id = 'fake_router_port2' def __init__(self): id = 'rrrrrrrr-rrrr-rrrr-rrrr-rrrrrrrrrrrr' admin_state_up = True device_owner = constants.DEVICE_OWNER_DHCP fixed_ips = [FakeIPAllocation('192.168.0.5', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] dns_assignment = [FakeDNSAssignment('192.168.0.5')] mac_address = '00:00:0f:dd:dd:dd' device_id = 'fake_multiple_agents_port' def __init__(self): id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' admin_state_up = True device_owner = constants.DEVICE_OWNER_DHCP fixed_ips = [FakeIPAllocation('192.168.0.6', 'dddddddd-dddd-dddd-dddd-dddddddddddd')] dns_assignment = [FakeDNSAssignment('192.168.0.6')] mac_address = '00:00:0f:ee:ee:ee' device_id = 'fake_multiple_agents_port2' def __init__(self): destination = '20.0.0.1/24' nexthop = '20.0.0.1' destination = constants.IPv4_ANY nexthop = '10.0.0.1' destination = '2001:0200:feed:7ac0::/64' nexthop = '2001:0200:feed:7ac0::1' id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' ip_version = 4 cidr = '192.168.0.0/24' gateway_ip = '192.168.0.1' enable_dhcp = True host_routes = [FakeV4HostRoute] dns_nameservers = ['8.8.8.8'] cidr = '192.168.1.0/24' gateway_ip = '192.168.1.1' host_routes = [] cidr = '169.254.169.254/30' gateway_ip = '169.254.169.253' host_routes = [] dns_nameservers = [] host_routes = [FakeV4HostRouteGateway] dns_nameservers = [] host_routes = [] dns_nameservers = ['2.2.2.2', '9.9.9.9', '1.1.1.1', '3.3.3.3'] host_routes = [] id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' subnets = [FakeV4SubnetMultipleAgentsWithoutDnsProvided()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1(), FakePortMultipleAgents2()] namespace = 'qdhcp-ns' id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' subnets = [FakeV4SubnetMultipleAgentsWithoutDnsProvided()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1()] namespace = 'qdhcp-ns' id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' subnets = [FakeV4SubnetAgentWithManyDnsProvided()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1()] namespace = 'qdhcp-ns' host_routes = [] id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' subnets = [FakeV4SubnetMultipleAgentsWithDnsProvided()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort(), FakePortMultipleAgents1(), FakePortMultipleAgents2()] namespace = 'qdhcp-ns' id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' ip_version = 6 cidr = 'fdca:3ba5:a17a:4ba3::/64' gateway_ip = 'fdca:3ba5:a17a:4ba3::1' enable_dhcp = True host_routes = [FakeV6HostRoute] dns_nameservers = ['2001:0200:feed:7ac0::1'] ipv6_ra_mode = None ipv6_address_mode = None id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' ip_version = 4 cidr = '192.168.1.0/24' gateway_ip = '192.168.1.1' enable_dhcp = False host_routes = [] dns_nameservers = [] id = 'ffffffff-ffff-ffff-ffff-ffffffffffff' ip_version = 6 cidr = 'fdca:3ba5:a17a:4ba3::/64' gateway_ip = 'fdca:3ba5:a17a:4ba3::1' enable_dhcp = True host_routes = [FakeV6HostRoute] dns_nameservers = ['2001:0200:feed:7ac0::1'] ipv6_ra_mode = None ipv6_address_mode = constants.DHCPV6_STATEFUL id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' ip_version = 6 cidr = 'ffda:3ba5:a17a:4ba3::/64' gateway_ip = 'ffda:3ba5:a17a:4ba3::1' enable_dhcp = True host_routes = [FakeV6HostRoute] ipv6_address_mode = constants.IPV6_SLAAC ipv6_ra_mode = None id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' ip_version = 6 cidr = 'ffea:3ba5:a17a:4ba3::/64' gateway_ip = 'ffea:3ba5:a17a:4ba3::1' enable_dhcp = True dns_nameservers = [] host_routes = [] ipv6_address_mode = constants.DHCPV6_STATELESS ipv6_ra_mode = None id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' cidr = '192.168.1.0/24' gateway_ip = None enable_dhcp = True host_routes = [] dns_nameservers = [] id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' cidr = '192.168.1.0/24' gateway_ip = '192.168.1.1' host_routes = [] dns_nameservers = [] id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' subnets = [FakeV4Subnet()] ports = [FakePort1()] namespace = 'qdhcp-ns' id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakePort5(), FakePort6()] namespace = 'qdhcp-ns' id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' subnets = [FakeV6Subnet()] ports = [FakePort2()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] # ports = [FakePort1(), FakeV6Port(), FakeDualPort(), FakeRouterPort()] namespace = 'qdhcp-ns' def __init__(self, domain='openstacklocal'): # Use instance rather than class attributes here, so that we get # an independent set of ports each time FakeDeviceManagerNetwork() # is used. id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] ports = [FakePort1(), FakeV6Port(), FakeDualPort(), FakeRouterPort(), FakeReservedPort()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV6SubnetDHCPStateful()] ports = [FakePort1(), FakeV6Port(), FakeDualPort(), FakeRouterPort(), FakeReservedPort(), FakeReservedPort(id='reserved-2')] namespace = 'qdhcp-ns' id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakeDhcpPort()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4SubnetGatewayRoute(), FakeV6SubnetDHCPStateful()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV4SubnetNoDHCP()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV4Subnet2()] ports = [FakePort1(), FakeRouterPort(), FakeRouterPort2()] namespace = 'qdhcp-ns' id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4SubnetNoGateway()] ports = [FakePort1()] id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4SubnetNoRouter()] ports = [FakePort1()] id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4MetadataSubnet()] ports = [FakeRouterPort(ip_address='169.254.169.253')] id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakeRouterPort(dev_owner=constants.DEVICE_OWNER_DVR_INTERFACE)] id = 'cccccccc-cccc-cccc-cccc-cccccccccccc' subnets = [FakeV4Subnet(), FakeV4SubnetNoDHCP()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] namespace = 'qdhcp-ns' def __init__(self, port_detail=""portsSame""): id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakePort2(), FakeRouterPort()] namespace = 'qdhcp-ns' def __init__(self, port_detail=""portsSame""): id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakePort2(), FakePort3(), FakeRouterPort()] namespace = 'qdhcp-ns' def __init__(self, port_detail=""portsSame""): id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' subnets = [FakeV6SubnetDHCPStateful()] ports = [FakeV6Port()] namespace = 'qdhcp-ns' def __init__(self): id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' subnets = [FakeV6SubnetDHCPStateful()] ports = [FakeV6Port()] namespace = 'qdhcp-ns' def __init__(self): id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' subnets = [FakeV4Subnet(), FakeV6SubnetSlaac()] ports = [FakePort1(), FakePort4(), FakeRouterPort()] id = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' subnets = [FakeV4Subnet(), FakeV6SubnetSlaac()] ports = [FakePort1(), FakePort4(), FakeRouterPort()] def __init__(self): id = 'dddddddd-dddd-dddd-dddd-dddddddddddd' subnets = [FakeV4Subnet()] ports = [FakePort1(), FakeRouterPort()] namespace = 'qdhcp-ns' def __init__(self): id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' subnets = [FakeV6SubnetStateless()] ports = [FakeV6PortExtraOpt()] namespace = 'qdhcp-ns' id = 'bbbbbbbb-bbbb-bbbb-bbbb-bbbbbbbbbbbb' subnets = [FakeV6SubnetStateless(), FakeV4Subnet()] ports = [FakeDualPortWithV6ExtraOpt(), FakeRouterPort()] namespace = 'qdhcp-ns' ipm_retval = {FakeV4SubnetNoGateway.id: '192.168.1.1'} ipm_retval = {FakeV4SubnetNoRouter.id: '192.168.1.2'} ipm_retval = {FakeV4Subnet.id: '192.168.0.1'} {FakeV4Subnet.id: '192.168.0.1'} dm = self._get_dnsmasq(FakeV4NetworkClientId) dm = self._get_dnsmasq(FakeNetworkDhcpPort) for alloc in FakeDhcpPort.fixed_ips]",394,366
openstack%2Fdragonflow~master~Iebc8d74bd0535729d72badbb4c1ffccae3370d0d,openstack/dragonflow,master,Iebc8d74bd0535729d72badbb4c1ffccae3370d0d,Make get_schema_helper accessible globally,MERGED,2016-04-24 08:06:51.000000000,2016-05-05 08:59:02.000000000,2016-05-05 08:59:02.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 13070}]","[{'number': 1, 'created': '2016-04-24 08:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/34c4533d761dea23717f738344826fdca9c8160a', 'message': 'Make get_schema_helper accessible globally\n\nget_schema_helper does not contain code that is specific to the\nOvsdbSwitchApi instance, and in fact is used to construct it.C\n\nMaking get_schema_helper accessible globally allows future OVSDB clients\nto use it, i.e. create IDL objects which report only specific tables.\n\nChange-Id: Iebc8d74bd0535729d72badbb4c1ffccae3370d0d\n'}, {'number': 2, 'created': '2016-04-24 13:09:23.000000000', 'files': ['dragonflow/db/drivers/ovsdb_vswitch_impl.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cb3e8d734a665cfedb4772db9d48408ffe9a9a21', 'message': 'Make get_schema_helper accessible globally\n\nget_schema_helper does not contain code that is specific to the\nOvsdbSwitchApi instance, and in fact is used to construct it.C\n\nMaking get_schema_helper accessible globally allows future OVSDB clients\nto use it, i.e. create IDL objects which report only specific tables.\n\nChange-Id: Iebc8d74bd0535729d72badbb4c1ffccae3370d0d\n'}]",0,309745,cb3e8d734a665cfedb4772db9d48408ffe9a9a21,9,4,2,20229,,,0,"Make get_schema_helper accessible globally

get_schema_helper does not contain code that is specific to the
OvsdbSwitchApi instance, and in fact is used to construct it.C

Making get_schema_helper accessible globally allows future OVSDB clients
to use it, i.e. create IDL objects which report only specific tables.

Change-Id: Iebc8d74bd0535729d72badbb4c1ffccae3370d0d
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/45/309745/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/drivers/ovsdb_vswitch_impl.py'],1,34c4533d761dea23717f738344826fdca9c8160a,df-meta,"def get_schema_helper(connection_string, db_name='Open_vSwitch', tables='all'): try: helper = idlutils.get_schema_helper(connection_string, db_name) except Exception: # We may have failed do to set-manager not being called helpers.enable_connection_uri(connection_string) # There is a small window for a race, so retry up to a second @retrying.retry(wait_exponential_multiplier=10, stop_max_delay=1000) def do_get_schema_helper(): return idlutils.get_schema_helper(connection_string, db_name) helper = do_get_schema_helper() if tables == 'all': helper.register_all() elif isinstance(tables, dict): for table_name, columns in six.iteritems(tables): if columns == 'all': helper.register_table(table_name) else: helper.register_columns(table_name, columns) return helper get_schema_helper( db_connection, tables=ovsdb_monitor_table_filter_default ),"," self.db_name = 'Open_vSwitch' def _get_schema_helper(self, tables='all'): db_connection = ('%s:%s:%s' % (self.protocol, self.ip, self.port)) try: helper = idlutils.get_schema_helper(db_connection, self.db_name) except Exception: # We may have failed do to set-manager not being called helpers.enable_connection_uri(db_connection) # There is a small window for a race, so retry up to a second @retrying.retry(wait_exponential_multiplier=10, stop_max_delay=1000) def do_get_schema_helper(): return idlutils.get_schema_helper(db_connection, self.db_name) helper = do_get_schema_helper() if tables == 'all': helper.register_all() elif isinstance(tables, dict): for table_name, columns in six.iteritems(tables): if columns == 'all': helper.register_table(table_name) else: helper.register_columns(table_name, columns) return helper self._get_schema_helper(ovsdb_monitor_table_filter_default),",30,28
openstack%2Fdragonflow~master~Ic9d5a191644ee7e334413295a07b59da15300681,openstack/dragonflow,master,Ic9d5a191644ee7e334413295a07b59da15300681,Have redis' get_all_keys return stripped key,MERGED,2016-04-27 08:35:50.000000000,2016-05-05 08:52:12.000000000,2016-05-05 08:52:12.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 18811}, {'_account_id': 18903}]","[{'number': 1, 'created': '2016-04-27 08:35:50.000000000', 'files': ['dragonflow/db/drivers/redis_db_driver.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f30dae23e905c6b389b0361039dc2186ba39cd68', 'message': ""Have redis' get_all_keys return stripped key\n\nThe driver's get_all_keys method should return only the objects' keys,\nwithout the table name and topic. This commit changes the redis driver\nto behave in that manner.\n\nChange-Id: Ic9d5a191644ee7e334413295a07b59da15300681\n""}]",0,310370,f30dae23e905c6b389b0361039dc2186ba39cd68,9,5,1,20229,,,0,"Have redis' get_all_keys return stripped key

The driver's get_all_keys method should return only the objects' keys,
without the table name and topic. This commit changes the redis driver
to behave in that manner.

Change-Id: Ic9d5a191644ee7e334413295a07b59da15300681
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/70/310370/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/drivers/redis_db_driver.py'],1,f30dae23e905c6b389b0361039dc2186ba39cd68,redis,"import re return [self._strip_table_name_from_key(key) for key in res] res = client.keys(local_key) return [self._strip_table_name_from_key(key) for key in res] def _strip_table_name_from_key(self, key): regex = '^{.*}\\.(.*)$' m = re.match(regex, key) return m.group(1) ", return res return client.keys(local_key),9,2
openstack%2Fvitrage~master~I20345b425077e1bcf4b2c696a13a2c6a8f8fb30c,openstack/vitrage,master,I20345b425077e1bcf4b2c696a13a2c6a8f8fb30c,escape the $ in the localrc file,MERGED,2016-05-05 08:38:38.000000000,2016-05-05 08:51:45.000000000,2016-05-05 08:51:44.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-05-05 08:38:38.000000000', 'files': ['devstack/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/bd3387f1d7bc1d8048079908cd825829f1ae6ddd', 'message': 'escape the $ in the localrc file\n\nChange-Id: I20345b425077e1bcf4b2c696a13a2c6a8f8fb30c\n'}]",0,312859,bd3387f1d7bc1d8048079908cd825829f1ae6ddd,6,2,1,19134,,,0,"escape the $ in the localrc file

Change-Id: I20345b425077e1bcf4b2c696a13a2c6a8f8fb30c
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/59/312859/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/gate_hook.sh'],1,bd3387f1d7bc1d8048079908cd825829f1ae6ddd,eyalb/tempest,"DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$NOVA_CONF]]""DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$NEUTRON_CONF]]""DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|\$CINDER_CONF]]""","DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|$NOVA_CONF]]""DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|$NEUTRON_CONF]]""DEVSTACK_LOCAL_CONFIG+=$'\n'""[[post-config|$CINDER_CONF]]""",3,3
openstack%2Fdragonflow~master~I59ff15225b213bf57b5c1eb3423c27543c1d42ab,openstack/dragonflow,master,I59ff15225b213bf57b5c1eb3423c27543c1d42ab,Ignore pep8 error: N530: Direct neutron imports not allowed,MERGED,2016-04-24 11:21:57.000000000,2016-05-05 08:51:19.000000000,2016-05-05 08:51:19.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-04-24 11:21:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9c85585550b51a440e0f996f9a1ebb9043535968', 'message': 'Ignore pep8 error: N530: Direct neutron imports not allowed\n\ntox is imposing test N530: Direct neutron imports not allowed. Added it\nto ignored list, pending solution of bug 1574230.\n\nChange-Id: I59ff15225b213bf57b5c1eb3423c27543c1d42ab\nRelated-Bug: 1574230\n'}]",0,309755,9c85585550b51a440e0f996f9a1ebb9043535968,10,5,1,20229,,,0,"Ignore pep8 error: N530: Direct neutron imports not allowed

tox is imposing test N530: Direct neutron imports not allowed. Added it
to ignored list, pending solution of bug 1574230.

Change-Id: I59ff15225b213bf57b5c1eb3423c27543c1d42ab
Related-Bug: 1574230
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/55/309755/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9c85585550b51a440e0f996f9a1ebb9043535968,bug/1574230,"# N530 Direct neutron imports not allowed ignore = E125,E126,E128,E129,E265,H301,H305,H307,H402,H404,H405,H904,H233,N530","ignore = E125,E126,E128,E129,E265,H301,H305,H307,H402,H404,H405,H904,H233",2,1
openstack%2Fneutron~master~Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a,openstack/neutron,master,Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a,DO NOT MERGE: Debug BGP extension loading issues in the gate,ABANDONED,2016-04-15 18:28:39.000000000,2016-05-05 08:44:24.000000000,,"[{'_account_id': 3}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 9845}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-04-15 18:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9d4491edb395a4ccbdef8bc068bb9a99831b143', 'message': 'DO NOT MERGE: Debug BGP extension loading issues in the gate\n\nChange-Id: Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a\n'}, {'number': 2, 'created': '2016-04-15 22:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5caaf1f9c852278192cbece2bf9fa175da97a538', 'message': 'DO NOT MERGE: Debug BGP extension loading issues in the gate\n\nChange-Id: Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a\n'}, {'number': 3, 'created': '2016-04-15 23:38:41.000000000', 'files': ['neutron/api/extensions.py', 'neutron/services/bgp/bgp_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3243c440c57ab8805a3ee5aa28dad88b7aa952f2', 'message': 'DO NOT MERGE: Debug BGP extension loading issues in the gate\n\nChange-Id: Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a\n'}]",2,306585,3243c440c57ab8805a3ee5aa28dad88b7aa952f2,27,9,3,4187,,,0,"DO NOT MERGE: Debug BGP extension loading issues in the gate

Change-Id: Id3cabb5296c3e4b583a0b31b9fafe3f9ce55630a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/306585/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/bgp/bgp_plugin.py'],1,a9d4491edb395a4ccbdef8bc068bb9a99831b143,," supported_extension_aliases = [""bgp"", ""bgp_dragent_scheduler""]","from neutron.extensions import bgp_dragentscheduler as dras_ext supported_extension_aliases = [bgp_ext.BGP_EXT_ALIAS, dras_ext.BGP_DRAGENT_SCHEDULER_EXT_ALIAS]",1,3
openstack%2Fsenlin~stable%2Fmitaka~I655bc73af07b84af424488c9333c039aae9262e3,openstack/senlin,stable/mitaka,I655bc73af07b84af424488c9333c039aae9262e3,Catch DBDuplicateEntry Error during cred_create,MERGED,2016-05-04 02:39:09.000000000,2016-05-05 08:43:25.000000000,2016-05-05 08:43:24.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-05-04 02:39:09.000000000', 'files': ['senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c2dbb2a4dbb32a9836a8e12c280c3701ddf6da38', 'message': 'Catch DBDuplicateEntry Error during cred_create\n\nThere might be some potential race condition for cred_create_update,\nthis patch catch DBDuplicateEntry error during cred_create and then\ndo cred_update.\nExisting unittest can cover this modification.\n\nCloses-Bug: #1567764\nChange-Id: I655bc73af07b84af424488c9333c039aae9262e3\n(cherry picked from commit 09ab723096cebbabdd1ab968ac976afcdbb257c5)\n'}]",0,312311,c2dbb2a4dbb32a9836a8e12c280c3701ddf6da38,11,4,1,7404,,,0,"Catch DBDuplicateEntry Error during cred_create

There might be some potential race condition for cred_create_update,
this patch catch DBDuplicateEntry error during cred_create and then
do cred_update.
Existing unittest can cover this modification.

Closes-Bug: #1567764
Change-Id: I655bc73af07b84af424488c9333c039aae9262e3
(cherry picked from commit 09ab723096cebbabdd1ab968ac976afcdbb257c5)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/11/312311/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/db/sqlalchemy/api.py'],1,c2dbb2a4dbb32a9836a8e12c280c3701ddf6da38,bug/1567764,from oslo_db import exception as db_exc try: except db_exc.DBDuplicateEntry:," cred = cred_get(context, values.get('user'), values.get('project')) if not cred: else:",3,3
openstack%2Fsenlin~stable%2Fmitaka~I7d27009ed9f7cec9f28c727d836a0efc1c75ef41,openstack/senlin,stable/mitaka,I7d27009ed9f7cec9f28c727d836a0efc1c75ef41,Remove concurrency constraint for functional tests,MERGED,2016-05-04 02:39:09.000000000,2016-05-05 08:40:58.000000000,2016-05-05 08:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-05-04 02:39:09.000000000', 'files': ['senlin/engine/service.py', 'senlin/api/middleware/trust.py', 'senlin/tests/functional/test_cluster_membership.py', 'senlin/db/api.py', 'senlin/tests/unit/db/test_cred_api.py', 'senlin/tests/unit/middleware/test_trust_middleware.py', 'tox.ini', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4a244a3b8e73d5e5d59dda7d6932e69e652e9157', 'message': 'Remove concurrency constraint for functional tests\n\nRemove concurrency constraint for functional tests, and fix\nthe issues found after enable concurrency.\n\nChange-Id: I7d27009ed9f7cec9f28c727d836a0efc1c75ef41\n(cherry picked from commit 5866a182ccd5c5f572acb4aa893c04176058fdd2)\n'}]",0,312310,4a244a3b8e73d5e5d59dda7d6932e69e652e9157,16,2,1,7404,,,0,"Remove concurrency constraint for functional tests

Remove concurrency constraint for functional tests, and fix
the issues found after enable concurrency.

Change-Id: I7d27009ed9f7cec9f28c727d836a0efc1c75ef41
(cherry picked from commit 5866a182ccd5c5f572acb4aa893c04176058fdd2)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/10/312310/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/api/middleware/trust.py', 'senlin/tests/functional/test_cluster_membership.py', 'senlin/db/api.py', 'senlin/tests/unit/db/test_cred_api.py', 'senlin/tests/unit/middleware/test_trust_middleware.py', 'tox.ini', 'senlin/db/sqlalchemy/api.py']",8,4a244a3b8e73d5e5d59dda7d6932e69e652e9157,bug/1567764,"def cred_create_update(context, values): cred = cred_get(context, values.get('user'), values.get('project')) if not cred: return cred_create(context, values) else: user = values.pop('user') project = values.pop('project') return cred_update(context, user, project, values) ",,44,12
openstack%2Fvitrage~master~I8c0277e95009faf19884b2bb14dcb9171f58a0be,openstack/vitrage,master,I8c0277e95009faf19884b2bb14dcb9171f58a0be,Replace deprecated LOG.warn with LOG.warning,MERGED,2016-05-05 08:24:00.000000000,2016-05-05 08:36:50.000000000,2016-05-05 08:36:50.000000000,"[{'_account_id': 3}, {'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 20066}, {'_account_id': 20863}]","[{'number': 1, 'created': '2016-05-05 08:24:00.000000000', 'files': ['vitrage/keystone_client.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/e1ed848b78f9bd9b4f549a4853089fdcba0a3d08', 'message': 'Replace deprecated LOG.warn with LOG.warning\n\nLOG.warn is deprecated. This patch updates it to use\nthe non-deprecated LOG.warning instead.\n\nChange-Id: I8c0277e95009faf19884b2bb14dcb9171f58a0be\nCloses-Bug: #1578506\n'}]",0,312857,e1ed848b78f9bd9b4f549a4853089fdcba0a3d08,9,5,1,19920,,,0,"Replace deprecated LOG.warn with LOG.warning

LOG.warn is deprecated. This patch updates it to use
the non-deprecated LOG.warning instead.

Change-Id: I8c0277e95009faf19884b2bb14dcb9171f58a0be
Closes-Bug: #1578506
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/57/312857/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/keystone_client.py'],1,e1ed848b78f9bd9b4f549a4853089fdcba0a3d08,bug/1578506," LOG.warning(""Value 'password-vitrage-legacy' for '[%s]/auth_type' "" ""is deprecated. And will be removed in Vitrage 2.0. "" ""Use 'password' instead."", CFG_GROUP)"," LOG.warn(""Value 'password-vitrage-legacy' for '[%s]/auth_type' "" ""is deprecated. And will be removed in Vitrage 2.0. "" ""Use 'password' instead."", CFG_GROUP)",4,4
openstack%2Ffuel-library~master~I55f487b1021e5971b60f34fa338b5fc87967495f,openstack/fuel-library,master,I55f487b1021e5971b60f34fa338b5fc87967495f,Ensure same node lists for possible masters search,MERGED,2016-05-04 16:15:44.000000000,2016-05-05 08:36:02.000000000,2016-05-05 08:32:12.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14200}, {'_account_id': 17730}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 16:15:44.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d9b44f11a6eb6b83eab8785a0e66e4bf85f5ca1a', 'message': ""Ensure same node lists for possible masters search\n\nThe 'crm_node --partition' returns nodes in different order\nfor different nodes. Ensure the same node lists to\nreach a consensus for the choosen master across all of the nodes\nin a partition.\n\nCloses-bug: #1578278\n\nChange-Id: I55f487b1021e5971b60f34fa338b5fc87967495f\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,312622,d9b44f11a6eb6b83eab8785a0e66e4bf85f5ca1a,28,8,1,6926,,,0,"Ensure same node lists for possible masters search

The 'crm_node --partition' returns nodes in different order
for different nodes. Ensure the same node lists to
reach a consensus for the choosen master across all of the nodes
in a partition.

Closes-bug: #1578278

Change-Id: I55f487b1021e5971b60f34fa338b5fc87967495f
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/22/312622/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,d9b44f11a6eb6b83eab8785a0e66e4bf85f5ca1a,bug/1578278," # Ensure the same nodes list to reach a consensus for the choosen master across all of the nodes NODES=$(printf -- '%s\n' ""${NODES}"" | sort -u)",,2,0
openstack%2Ffuel-qa~stable%2Fmitaka~I102ff02542ede7ebf7de86b22aa8964b50a9eb60,openstack/fuel-qa,stable/mitaka,I102ff02542ede7ebf7de86b22aa8964b50a9eb60,Add tests for tasks ensurability,MERGED,2016-05-04 13:45:13.000000000,2016-05-05 08:21:07.000000000,2016-05-05 08:21:07.000000000,"[{'_account_id': 3}, {'_account_id': 7935}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9588}, {'_account_id': 11969}, {'_account_id': 14708}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-05-04 13:45:13.000000000', 'files': ['fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/cluster_settings.yaml', 'doc/base_tests.rst', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/controller.yaml', 'fuelweb_test/tests/tests_lcm/test_idempotency.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/compute.yaml', 'fuelweb_test/tests/tests_lcm/test_ensurability.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ceph-osd.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/base_lcm_test.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cinder.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/cinder.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/mongo.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/ceph-osd.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/compute.yaml', 'fuelweb_test/models/nailgun_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/mongo.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/compute.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/dda97d5a2d2ad888852ee92d5402d265e04275aa', 'message': 'Add tests for tasks ensurability\n\nChange-Id: I102ff02542ede7ebf7de86b22aa8964b50a9eb60\nImplements: blueprint test-granular-task-ensurability\n(cherry picked from commit d82fee7e9e19b410edd13f8d9474fe5a85478e90)\nCloses-Bug: #1575807\n'}]",0,312505,dda97d5a2d2ad888852ee92d5402d265e04275aa,13,8,1,16819,,,0,"Add tests for tasks ensurability

Change-Id: I102ff02542ede7ebf7de86b22aa8964b50a9eb60
Implements: blueprint test-granular-task-ensurability
(cherry picked from commit d82fee7e9e19b410edd13f8d9474fe5a85478e90)
Closes-Bug: #1575807
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/05/312505/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/cluster_settings.yaml', 'doc/base_tests.rst', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/controller.yaml', 'fuelweb_test/tests/tests_lcm/test_idempotency.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/compute.yaml', 'fuelweb_test/tests/tests_lcm/test_ensurability.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ceph-osd.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/base_lcm_test.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cinder.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/cinder.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/mongo.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/ceph-osd.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/compute.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/compute.yaml', 'fuelweb_test/models/nailgun_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/nodes_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/mongo.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/compute.yaml']",30,dda97d5a2d2ad888852ee92d5402d265e04275aa,bp/test-granular-task-ensurability, type: skipped, type: shell - upload_provision_data: type: false,3600,65
openstack%2Ftripleo-heat-templates~master~I511052dc765788336ffd32dee2118d787fce725d,openstack/tripleo-heat-templates,master,I511052dc765788336ffd32dee2118d787fce725d,Leave start/stop/restart for Keystone and Glance in charge to the role,MERGED,2016-04-28 22:01:39.000000000,2016-05-05 08:17:04.000000000,2016-05-05 08:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6994}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2016-04-28 22:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/889dbe1b2e76589ece1502a7556eb94975410110', 'message': 'Leave start/stop/restart for Keystone and Glance in charge to the role\n\nChange-Id: I511052dc765788336ffd32dee2118d787fce725d\nDepends-On: I1d95746cb990292462106c191987147eba30ee61\n'}, {'number': 2, 'created': '2016-04-29 15:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f74eb438bd153978c883964332151038b44071e1', 'message': 'Leave start/stop/restart for Keystone and Glance in charge to the role\n\nChange-Id: I511052dc765788336ffd32dee2118d787fce725d\nDepends-On: I1d95746cb990292462106c191987147eba30ee61\n'}, {'number': 3, 'created': '2016-05-04 13:30:40.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/609b7ec3aa7b88bf05daeabd870360794498903c', 'message': 'Leave start/stop/restart for Keystone and Glance in charge to the role\n\nChange-Id: I511052dc765788336ffd32dee2118d787fce725d\n'}]",0,310936,609b7ec3aa7b88bf05daeabd870360794498903c,20,6,3,6796,,,0,"Leave start/stop/restart for Keystone and Glance in charge to the role

Change-Id: I511052dc765788336ffd32dee2118d787fce725d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/310936/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,889dbe1b2e76589ece1502a7556eb94975410110,bp/composable-services-within-roles,, tag == 'glance-service' or tag == 'keystone-service' or,0,2
openstack%2Fproject-config~master~Icc522448e46f9b7100ad117fbd339d5eed03f045,openstack/project-config,master,Icc522448e46f9b7100ad117fbd339d5eed03f045,Change service user domain for identity v3 only test,MERGED,2016-01-22 03:35:44.000000000,2016-05-05 08:15:05.000000000,2016-05-05 08:15:05.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6482}, {'_account_id': 6547}, {'_account_id': 12767}]","[{'number': 1, 'created': '2016-01-22 03:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bd8018333244ca8a6a23b2a5bcefdc2bd31ef205', 'message': 'Change service user domain for identity v3 only test\n\nThe V3 only test currently tries to ensure that everything works using\nv3 only authentication. To futher prove this lets put the service users\nin the non-default domain.\n\nChange-Id: Icc522448e46f9b7100ad117fbd339d5eed03f045\nDepends-On: I7e73df5dd1caabf355783da2bc0f3007ade92fba\n'}, {'number': 2, 'created': '2016-04-08 04:53:25.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fb0a58c0c058af71886ef6bd8138b350ec225391', 'message': 'Change service user domain for identity v3 only test\n\nThe V3 only test currently tries to ensure that everything works using\nv3 only authentication. To futher prove this lets put the service users\nin the non-default domain.\n\nChange-Id: Icc522448e46f9b7100ad117fbd339d5eed03f045\nDepends-On: I7e73df5dd1caabf355783da2bc0f3007ade92fba\n'}]",0,271127,fb0a58c0c058af71886ef6bd8138b350ec225391,16,5,2,7191,,,0,"Change service user domain for identity v3 only test

The V3 only test currently tries to ensure that everything works using
v3 only authentication. To futher prove this lets put the service users
in the non-default domain.

Change-Id: Icc522448e46f9b7100ad117fbd339d5eed03f045
Depends-On: I7e73df5dd1caabf355783da2bc0f3007ade92fba
",git fetch https://review.opendev.org/openstack/project-config refs/changes/27/271127/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,bd8018333244ca8a6a23b2a5bcefdc2bd31ef205,service-domain," export DEVSTACK_LOCAL_CONFIG+=$'\n'""SERVICE_DOMAIN=service""",,1,0
openstack%2Fproject-config~master~I8fa185fd96032c885ff8a0d3340b82c26023744f,openstack/project-config,master,I8fa185fd96032c885ff8a0d3340b82c26023744f,puppet/experimental: enable puppet4 jobs on xenial,MERGED,2016-05-04 21:18:06.000000000,2016-05-05 08:05:51.000000000,2016-05-05 08:05:51.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 21:18:06.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e7d010fbdb5d5407bc619d851c57eb659f33ea16', 'message': 'puppet/experimental: enable puppet4 jobs on xenial\n\nPuppetlabs packaged puppet4 on Xenial.\nThis patch adds the jobs in experimental queue so we can start testing\nPuppet OpenStack on Xenial with Puppet4.\n\nChange-Id: I8fa185fd96032c885ff8a0d3340b82c26023744f\n'}]",0,312754,e7d010fbdb5d5407bc619d851c57eb659f33ea16,7,3,1,3153,,,0,"puppet/experimental: enable puppet4 jobs on xenial

Puppetlabs packaged puppet4 on Xenial.
This patch adds the jobs in experimental queue so we can start testing
Puppet OpenStack on Xenial with Puppet4.

Change-Id: I8fa185fd96032c885ff8a0d3340b82c26023744f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/312754/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e7d010fbdb5d5407bc619d851c57eb659f33ea16,xenial/puppet4, - gate-puppet-openstack-integration-4-scenario001-tempest-ubuntu-xenial - gate-puppet-openstack-integration-4-scenario002-tempest-ubuntu-xenial - gate-puppet-openstack-integration-4-scenario003-tempest-ubuntu-xenial,,3,0
openstack%2Fproject-config~master~I4fa16005353c44cd914ef2b572a2f5cf810beaa9,openstack/project-config,master,I4fa16005353c44cd914ef2b572a2f5cf810beaa9,Normalize projects.yaml,MERGED,2016-05-05 06:04:37.000000000,2016-05-05 08:01:01.000000000,2016-05-05 08:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-05 06:04:37.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/023a68d7a8ec8c5bc63de1de8b8bffed79500d80', 'message': 'Normalize projects.yaml\n\nChange-Id: I4fa16005353c44cd914ef2b572a2f5cf810beaa9\n'}]",0,312832,023a68d7a8ec8c5bc63de1de8b8bffed79500d80,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I4fa16005353c44cd914ef2b572a2f5cf810beaa9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/32/312832/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,023a68d7a8ec8c5bc63de1de8b8bffed79500d80,project-yaml-normalization,, upstream: https://github.com/krotscheck/js-openstack-registry-hooks.git upstream: https://github.com/rthallisey/kolla-kubernetes.git,0,2
openstack%2Fproject-config~master~If67cd1c41e006a8505683a004c7cbce93064b3a1,openstack/project-config,master,If67cd1c41e006a8505683a004c7cbce93064b3a1,translations: Ignore version failures,MERGED,2016-05-04 22:00:41.000000000,2016-05-05 07:57:49.000000000,2016-05-05 07:57:49.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 22:00:41.000000000', 'files': ['jenkins/scripts/common_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/02528fc319985ad58b7d56fabd6f93ffdf8820d7', 'message': 'translations: Ignore version failures\n\npython setup.py --version fails on tacker repo since it has an extra\nsetup_hook. Instead of aborting the script, use ""unknown"" as version.\n\nChange-Id: If67cd1c41e006a8505683a004c7cbce93064b3a1\n'}]",0,312765,02528fc319985ad58b7d56fabd6f93ffdf8820d7,8,3,1,6547,,,0,"translations: Ignore version failures

python setup.py --version fails on tacker repo since it has an extra
setup_hook. Instead of aborting the script, use ""unknown"" as version.

Change-Id: If67cd1c41e006a8505683a004c7cbce93064b3a1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/65/312765/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/common_translation_update.sh'],1,02528fc319985ad58b7d56fabd6f93ffdf8820d7,tacker-version, # Note this might fail in some projects if the setup hook includes # additional hooks like in tacker repository. Use set +e set -e VERSION=${VERSION:-unknown},,5,0
openstack%2Fproject-config~master~I1f125c944c8fd23aafdce2fc0682454b4b2c264d,openstack/project-config,master,I1f125c944c8fd23aafdce2fc0682454b4b2c264d,Move image update cron back,MERGED,2016-05-02 23:26:17.000000000,2016-05-05 07:53:16.000000000,2016-05-05 07:53:16.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-02 23:26:17.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/536b52f2534ad642686a0d133f1468c797877518', 'message': 'Move image update cron back\n\nNow that we are almost completely dib image based the image update cron\nfirst builds all of the images which needs about 4 hours then proceeds\nto upload these images to the various cloud regions. Move the cron entry\nback 3 hours and 40 minutes so that image builds run then uploads happen\nroughly when we had previously expected these updates (~1400UTC).\n\nThis is not strictly required but should shift uploads back in the day\nallowing us to make more changes to nodepool later in our working hours\nwithout killing uploads.\n\nChange-Id: I1f125c944c8fd23aafdce2fc0682454b4b2c264d\n'}]",0,311890,536b52f2534ad642686a0d133f1468c797877518,8,4,1,4146,,,0,"Move image update cron back

Now that we are almost completely dib image based the image update cron
first builds all of the images which needs about 4 hours then proceeds
to upload these images to the various cloud regions. Move the cron entry
back 3 hours and 40 minutes so that image builds run then uploads happen
roughly when we had previously expected these updates (~1400UTC).

This is not strictly required but should shift uploads back in the day
allowing us to make more changes to nodepool later in our working hours
without killing uploads.

Change-Id: I1f125c944c8fd23aafdce2fc0682454b4b2c264d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/311890/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,536b52f2534ad642686a0d133f1468c797877518,move-image-cron-back, image-update: '10 34 * * *', image-update: '14 14 * * *',1,1
openstack%2Frally~master~I5e687f2ad5bee441724afebe9423f4bad0e3d5b2,openstack/rally,master,I5e687f2ad5bee441724afebe9423f4bad0e3d5b2,[CI] Fix jobs gate-rally-install-*,ABANDONED,2016-04-29 15:19:40.000000000,2016-05-05 07:52:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7428}, {'_account_id': 9234}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-04-29 15:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/51dd0db379d2aad652f2f9d693b056fa23c62938', 'message': '[CI] Fix gobs gate-rally-install-*\n\nThis changes install_rally.sh.\nThe problem is again in parsing URL to latest version of setuptools.\nList of URLs was obtained from https://pypi.python.org/simple/setuptools/\nin HTML format, which seems to be changed (again).\nNow we get URL via parsing pypi JSON API response - this seems\nto be a bit better.\n\nChange-Id: I5e687f2ad5bee441724afebe9423f4bad0e3d5b2\n'}, {'number': 2, 'created': '2016-04-29 15:40:50.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/adf134321907fd0c022645a946814e21650bf188', 'message': '[CI] Fix jobs gate-rally-install-*\n\nThis changes install_rally.sh.\nThe problem is in parsing URL to latest version of setuptools.\nList of URLs was obtained from https://pypi.python.org/simple/setuptools/\nin HTML format, which seems to be changed (again).\nNow we get URL via parsing pypi JSON API response - this seems\nto be a bit better.\n\nChange-Id: I5e687f2ad5bee441724afebe9423f4bad0e3d5b2\n'}]",11,311146,adf134321907fd0c022645a946814e21650bf188,21,8,2,10475,,,0,"[CI] Fix jobs gate-rally-install-*

This changes install_rally.sh.
The problem is in parsing URL to latest version of setuptools.
List of URLs was obtained from https://pypi.python.org/simple/setuptools/
in HTML format, which seems to be changed (again).
Now we get URL via parsing pypi JSON API response - this seems
to be a bit better.

Change-Id: I5e687f2ad5bee441724afebe9423f4bad0e3d5b2
",git fetch https://review.opendev.org/openstack/rally refs/changes/46/311146/2 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,51dd0db379d2aad652f2f9d693b056fa23c62938,fix-install-rally-sh,"download_from_pypi_latest () { # NOTE(amaretskiy): Download latest version of given package local pkg=${1} local pkg_json=$(download - ""http://pypi.python.org/pypi/${pkg}/json/"") local download_url=$(echo ""${pkg_json}""\ | grep url\"": | grep tar.gz | tail -1 | tr -d \""\ ,\ | cut -c 5-150) if [ -n ""${download_url}"" ]; then download $(basename ""${download_url}"") ""${download_url}"" die ${EX_PROTOCOL} ""Package '${pkg}' not found on PyPI!"" <<__EOF__ Unable to download package '${pkg}' from PyPI. (cd ""$DESTDIR"" && download_from_pypi_latest setuptools)","download_from_pypi () { local pkg=$1 # NOTE(amaretskiy): get packages list in HTML local packages=$(download - ""${BASE_PIP_URL}/${pkg}/"") # NOTE(amaretskiy): filter packages URLs packages=$(echo ${packages} | sed -En ""s/.*href=\""(.*${pkg}-.*\\.gz)\#.*/\1/p"") # NOTE(amaretskiy): sort packages URLs by their version part packages=$(echo ${packages} | sort -t / -k 7 -V) # NOTE(amaretskiy): finally, the URL is in the last line local url=$(echo ${packages} | tail -1) if [ -n ""$url"" ]; then download ""$(basename ""$url"")"" ""$BASE_PIP_URL""/""$pkg""/""$url"" die $EX_PROTOCOL ""Package '$pkg' not found on PyPI!"" <<__EOF__ Unable to download package '$pkg' from PyPI. (cd ""$DESTDIR"" && download_from_pypi setuptools)",11,20
openstack%2Fpuppet-murano~stable%2Fmitaka~Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0,openstack/puppet-murano,stable/mitaka,Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0,Prepare module for publication to the forge,MERGED,2016-05-03 22:04:00.000000000,2016-05-05 07:47:02.000000000,2016-05-04 22:51:20.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-05-03 22:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/28feb88628af5afebcfaa425ed2fccfd41a0119d', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0\n""}, {'number': 2, 'created': '2016-05-03 22:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/90601607dd253dabb822c9a68e50b334cee97aca', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent modules versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updating required open source puppet and\n  PE version, plus extends the operating system support list.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0\n""}, {'number': 3, 'created': '2016-05-04 18:28:15.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/c5b16dd5eae478301b5638554a9afd4dfeec0cba', 'message': ""Prepare module for publication to the forge\n\n  This commit validates the module's metadata.json by comparing\n  dependent module versions with those in the Puppetfile[1] found in\n  puppet-openstack-integration, updates required open source puppet and\n  PE versions, cleans up the supported operating system list so that we\n  only declare support for the OSes we know kilo runs on.\n\n  Obligatorily bumps the z version number.\n\n  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile\n\nChange-Id: Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0\n""}]",0,312268,c5b16dd5eae478301b5638554a9afd4dfeec0cba,16,4,3,7423,,,0,"Prepare module for publication to the forge

  This commit validates the module's metadata.json by comparing
  dependent module versions with those in the Puppetfile[1] found in
  puppet-openstack-integration, updates required open source puppet and
  PE versions, cleans up the supported operating system list so that we
  only declare support for the OSes we know kilo runs on.

  Obligatorily bumps the z version number.

  [1] https://github.com/openstack/puppet-openstack-integration/blob/stable/mitaka/Puppetfile

Change-Id: Ib0eee787afb3fa93a2b53cf34c8b0faa0fb135e0
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/68/312268/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,28feb88628af5afebcfaa425ed2fccfd41a0119d,prep_for_forge," ""version"": ""8.0.1"", { ""name"": ""pe"", ""version_requirement"": "">= 3.2.0 <= 2016.1.0"" }, { ""name"": ""puppet"", ""version_requirement"": "">= 3.0.0 < 5.0.0"" } ""operatingsystem"": ""Debian"", ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""21"", ""22"", ""23""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystemrelease"": [""6.5"", ""7""] }, { ""operatingsystem"": ""Ubuntu"", ""operatingsystemrelease"": [""12.04"", ""14.04""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.4.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.9.0 <5.0.0"" },"," ""version"": ""8.0.0"", { ""name"": ""pe"",""version_requirement"": ""3.x"" }, { ""name"": ""puppet"",""version_requirement"": ""3.x"" } ""operatingsystem"": ""Fedora"", ""operatingsystemrelease"": [""20""] }, { ""operatingsystem"": ""RedHat"", ""operatingsystem"": ""Debian"", ""operatingsystemrelease"": [""8""] { ""name"": ""puppetlabs/inifile"", ""version_requirement"": "">=1.0.0 <2.0.0"" }, { ""name"": ""puppetlabs/stdlib"", ""version_requirement"": "">=4.0.0 <5.0.0"" },",16,12
openstack%2Fopenstack-manuals~master~I59e30f73d13a41b7d298b499bb54211ed2fb0b88,openstack/openstack-manuals,master,I59e30f73d13a41b7d298b499bb54211ed2fb0b88,Imported Translations from Zanata,MERGED,2016-05-05 06:59:12.000000000,2016-05-05 07:34:39.000000000,2016-05-05 07:34:39.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-05-05 06:59:12.000000000', 'files': ['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/admin-guide/source/locale/admin-guide.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/99da0042b4719a0f11d57fdd8ab8e92652a24582', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I59e30f73d13a41b7d298b499bb54211ed2fb0b88\n'}]",0,312838,99da0042b4719a0f11d57fdd8ab8e92652a24582,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I59e30f73d13a41b7d298b499bb54211ed2fb0b88
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/312838/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/admin-guide/source/locale/admin-guide.pot']",3,99da0042b4719a0f11d57fdd8ab8e92652a24582,zanata/translations,"""POT-Creation-Date: 2016-05-05 06:57+0000\n""#: ../compute-flavors.rst:355 ../compute-flavors.rst:461 #: ../identity_service_api_protection.rst:19#: ../compute-flavors.rst:451#: ../compute-flavors.rst:454 msgid ""You can assign PCI devices to a guest by specifying them in the flavor."" msgstr """" #: ../compute-flavors.rst:463 msgid """" ""ALIAS: (string) The alias which correspond to a particular PCI device class "" ""as configured in the nova configuration file (see `nova.conf configuration "" ""options <http://docs.openstack.org/mitaka/config-reference/compute/config-"" ""options.html>`_)."" msgstr """" #: ../compute-flavors.rst:466 msgid """" ""COUNT: (integer) The amount of PCI devices of type ALIAS to be assigned to a "" ""guest."" msgstr """" #: ../compute-flavors.rst:466 msgid ""PCI passthrough"" msgstr """" ""To launch instances with the dashboard as an end user, see the `Launch and "" ""manage instances <http://docs.openstack.org/user-guide/"" ""dashboard_launch_instances.html>`__. in the OpenStack End User Guide.""","""POT-Creation-Date: 2016-05-04 06:21+0000\n""#: ../compute-flavors.rst:355 ../identity_service_api_protection.rst:19#: ../compute-flavors.rst:450""To launch instances with the dashboard, see the `OpenStack End User Guide "" ""<http://docs.openstack.org/user-guide/dashboard_launch_instances.html>`__.""",110,10
openstack%2Fheat~stable%2Fmitaka~I8567fa7565066476abf1fb62c4785ad523ca6c25,openstack/heat,stable/mitaka,I8567fa7565066476abf1fb62c4785ad523ca6c25,Imported Translations from Zanata,MERGED,2016-05-04 06:38:46.000000000,2016-05-05 07:12:33.000000000,2016-05-05 07:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 6577}]","[{'number': 1, 'created': '2016-05-04 06:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a18f7290a8a374db69391deafa0a500a90fedae0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8567fa7565066476abf1fb62c4785ad523ca6c25\n'}, {'number': 2, 'created': '2016-05-05 06:17:30.000000000', 'files': ['heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/79485642d9a9f84906fb2d04eef71193dd33e443', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8567fa7565066476abf1fb62c4785ad523ca6c25\n'}]",0,312333,79485642d9a9f84906fb2d04eef71193dd33e443,8,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I8567fa7565066476abf1fb62c4785ad523ca6c25
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/312333/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po']",2,a18f7290a8a374db69391deafa0a500a90fedae0,zanata/translations,"""Project-Id-Version: heat 6.0.1.dev9\n""""POT-Creation-Date: 2016-05-04 01:21+0000\n""""PO-Revision-Date: 2016-05-04 04:52+0000\n""msgstr ""El argumento \""%s\"" debe ser una cadena""msgstr ""El delimitador \""%s\"" debe ser una cadena""msgstr ""Los marcadores de parmetros \""%s\"" deben ser cadenas""msgstr ""Los parmetros \""%s\"" deben ser cadenas o nmeros""msgstr ""La plantilla \""%s\"" debe ser una cadena""msgstr ""%(name)s restriccin no vlida para %(utype)s""msgstr ""%(type)s no est en un formato vlido: %(error)s""msgstr ""El nombre de clave %s debe ser una cadena""msgstr ""El nombre de valor %s debe ser una cadena""""la que se genera la cadena aleatoria.""""partir de la cual se genera la cadena aleatoria.""""genera la cadena aleatoria.""""Una lista de secuencias de caracteres y sus restricciones a partir de la "" ""cual se genera la cadena aleatoria.""""Una lista de dimensiones (par arbitrario de nombre/valor) asociadas a la """"Una lista de polticas de cadena a aplicar. Valores predeterminados para "" ""anti-afinidad.""""recurso individual.""""Un URL firmado para crear ejecuciones de flujos de trabajo especificadas en "" ""el recurso Flujo de trabajo.""msgstr ""Una cadena especificada de servidores DNS para ser utilizados.""""Una cadena que especifica un nombre simblico para la red, que no necesita ""msgstr ""Una cadena que especifica la correlacin de red fsica para la red.""msgstr ""Una cadena que especifica el tipo de red de proveedor para la red.""msgstr ""Una cadena que especifica el id de segmentacin para la red.""msgstr ""La accin %s no esta permitida para el usuario""msgstr ""Accin que se debe realizar en el trfico coincidiendo con la regla.""msgstr ""Estado administrativo del direccionador.""msgstr ""El algoritmo debe ser uno de los siguientes: %s""""de larga duracin puedan completarse. Tenga en cuenta que esto vence a la "" ""caducidad de cualquier token de usuario proporcionado.""""independientemente de la opcin de arrendamiento especificada al iniciar la "" ""instancia.""msgstr ""AllowedPattern debe ser una cadena""""en el tamao de la RAM.""msgstr ""Una comprobacin de estado de la aplicacin para las instancias.""msgstr ""Se ha producido una excepcion desconocida""""cadena se serializarn en JSON (y la cadena serializada debe tener 255 ""msgstr ""El argumento en \""%s\"" debe ser una cadena""msgstr ""El argumento en \""%s\"" debe ser una cadena o una lista""msgstr ""El argumento para la funcin \""%s\"" debe ser una lista de cadenas""""[nombre_recurso] o [nombre_recurso, atributo, (va de acceso), ...]""msgstr ""Los argumentos de \""%s\"" deben tener el formato [ndice, coleccin]""""Los argumentos de \""%s\"" deben tener el formato [nombre_recurso, atributo]""msgstr ""Los argumentos de %s no se han resuelto completamente""msgstr ""Correlaciones de dispositivo de bloque a conectar a la instancia.""""Especificacin adicional booleana que se utiliza para filtrar programas de "" ""fondo segn su capacidad de crear instantneas de recursos compartidos.""msgstr ""No se ha podido encontrar el rol %s""msgstr ""No se puede comprobar %s, no se ha creado la pila""""No se ha podido obtener el token de usuario del dominio, no est configurado "" ""el id de dominio de la pila, por favor corriga su heat.conf""msgstr ""No se puede reanudar %s, no se ha establecido resource_id""msgstr ""Se ha encontrado una dependencia circular: %(cycle)s""""Se debe especificar el nombre del cliente y el nombre del getter del recurso.""""una cadena vaca si no se ha asignado nada en este momento. El resultado """"el error aadiendo --data-binary '{\""status\"": \""FAILURE\""}'.""""No se ha podido enlazar a %(bind_addr)s despus de intentarlo durante 30 ""msgstr ""ID o nombre del dominio DNS.""msgstr ""Serial del dominio DNS.""""informacin ms detallada, consulte la rfc 1035.""msgstr ""Los datos proporcionados no son vlidos: %(reason)s""""El valor predeterminado debe ser una cadena de lista delimitada por comas: %s""msgstr ""El delimitador para %s debe ser una cadena""msgstr ""El despliegue ha salido con un cdigo de estado distinto de cero: %s""msgstr ""No se ha encontrado el despliegue con el id %s""msgstr ""Descripcin de la alarma.""msgstr ""DisableRollback y OnFailure no se pueden usar a la vez""msgstr ""Direccin EIP a asociar con la instancia.""msgstr ""Falta Ebs; es obligatorio cuando se especifica BlockDeviceMappings.""""poltica predeterminada en Neutron restringe el uso de esta propiedad a "" ""usuarios administrativos solamente.""msgstr ""Error al autorizar la accin %s""""son especficos del hardware o de las extensiones instaladas.""""la alarma ha cambiado. De forma predeterminada, se llama a las acciones cada "" ""vez que se alcanza el umbral.""""Revisin de compilacin Heat. Si prefiere administrar su revisin de "" ""compilacin por separado, puede pasar esta seccin a un archivo distinto y """"Qu debe indicar el servidor a Heat con los valores de salida de despliegue.""msgstr ""ID de proyecto para autenticacin de la API""""IP u otra informacin de direccin sobre el invitado al que se ha permitido """"\""%(snapshot_id)s\"", sin embargo, las opciones especificadas actualmente ""msgstr ""Si se especifica, la copia de seguridad desde la que crear el volumen.""msgstr ""Si se especifica, la instantnea desde la que se crear el volumen.""""Si se especifica, el tipo de volumen a utilizar, correlacionndolo con un ""msgstr ""Los argumentos incorrectos de \""%(fn_name)s\"" deben ser: %(example)s""""ndice no correcto en \""%(fn_name)s\"", debera ser entre 0 y %(max_index)s""msgstr ""ndice no correcto en \""%(fn_name)s\"", debera ser: %(example)s""msgstr ""El ndice de \""%s\"" debe ser una cadena""msgstr ""El ndice de \""%s\"" debe ser un entero""msgstr ""Indique si el volumen se debe suprimir cuando la instancia se termine.""""poltica predeterminado en Neutron restringe el uso de esta propiedad a "" ""usuarios administrativos solamente. Esta propiedad no se puede utilizar "" ""junto al ID de agente L3.""""usuarios administrativos solamente. Y ahora Neutron no soporta ""msgstr """" ""ID de instancia a asociar con la EIP especificada por la propiedad EIP.""msgstr ""ID de instancia a asociar con la EIP.""msgstr ""ID de la instancia a reiniciar.""msgstr ""Esquema de URL no vlido %s""msgstr ""Version de UUID no vlida (%d)""msgstr ""Accin no vlida %s""msgstr ""Se ha especificado una accin no vlida: %s""msgstr ""Valor predeterminado no vlido %(default)s (%(exc)s)""msgstr ""Clave no vlida %s""""El nombre de pila no vlido \""%s\"" puede contener nicamente caracteres "" ""alfanumricos o los caracteres \""_-.\"" , debe empezar con alfa y debe tener "" ""255 caracteres o menos.""msgstr """" ""Estado no vlido %(state)s, se esperaba uno de los siguientes: %(expect)s""msgstr ""Tipo no vlido (%s)""""Los elementos a unir deben ser de tipo cadena, correlacin o lista. %s ha "" ""dado error en la serializacin con JSON""msgstr ""Clave secreta del par de claves.""msgstr ""Longitud de la cadena a generar.""""Lista de recursos a eliminar al realizar una actualizacin que requiera la ""msgstr """" ""Lista de identificadores de grupo de seguridad asociados a esta interfaz.""msgstr ""Lista de reglas de salida del grupo de seguridad.""msgstr ""Lista de reglas de acceso del grupo de seguridad.""msgstr ""Lista de cdigos asociados a esta interfaz.""msgstr ""Los elementos de la lista de miembros deben ser cadenas""msgstr ""Falta la credencial obligatoria:%(required)s ""msgstr ""Se han especificado mltiples acciones""msgstr ""Nombre para la poltica de cortafuegos.""""Espacio de nombres para agrupar esta configuracin de software cuando se ""msgstr ""ID de interfaz de red a asociar con la EIP.""msgstr ""Interfaces de red a asociar con la instancia.""msgstr ""No se ha especificado ninguna accin""msgstr ""No se ha encontrado ningn evento %s""msgstr ""No se han encontrado sucesos para el recurso %s""msgstr ""No se han encontrado datos de recursos""msgstr """" ""El recurso \""%s\"" debe tener obligatoriamente el tipo de recurso no vaco""msgstr ""Nmero de procesos del motor de Heat a bifurcar y ejecutar.""msgstr ""Nmero de minutos a esperar la creacin de esta pila.""msgstr ""'%(name)s' slo acepta un entero.""""Operador utilizado para comparar la estadstica especificada con el umbral.""""Heat URL opcional en un formato como http://0.0.0.0:8004/v1/%(tenant_id)s.""msgstr ""El nombre de parmetro en \""%s\"" debe ser una cadena""msgstr ""Contrasea para autenticacin de la API""msgstr ""Los componentes de va de acceso en \""%s\"" deben ser cadenas""msgstr ""Los componentes de va de acceso en los atributos deben ser cadenas""""Poltica a procesar al realizar una actualizacin que requiera la ""msgstr ""La creacin de la agrupacin ha fallado debido a la vip""msgstr ""cadena de clave precompartida para la conexin de sitio ipsec.""msgstr """" ""Las propiedades deber ser de tipo Properties (propiedades). Se ha encontrado "" ""%s.""""Propiedades que se tienen que pasar a cada recurso que se cree en la cadena.""msgstr ""El tipo del recurso \""%s\"" no es una cadena""msgstr ""Ya se ha solicitado la actualizacin de recurso""msgstr """" ""Esquema vlido nicamente para %(ltype)s o para %(mtype)s, no para %(utype)s""""Seleccine mtodo de autenticacin deferido, claves almacenadas o confianzas.""msgstr ""Secuencia de caracteres a partir de la cual crear la cadena aleatoria.""msgstr ""Nombre del recurso compartido.""msgstr ""Esquema nico vlido nicamente para %(ltype)s, no para %(utype)s""msgstr ""No se ha encontrado la instantnea con el id %s""""Falta SnapshotId; es obligatorio cuando se especifica BlockDeviceMappings.""msgstr ""No se ha encontrado la configuracin de software con el id %s""msgstr ""La pila est en un estado desconocido""msgstr ""La cadena a dividir debe ser cadena; se ha obtenido %s""msgstr ""ID de subred a asociar a esta interfaz.""msgstr ""ID de subred en el que iniciar la instancia.""msgstr ""Metadatos suministrados para los recursos del grupo.""msgstr ""Cdigos a adjuntar a la instancia.""msgstr ""No se ha proporcionado la versin de la plantilla""msgstr ""No se ha proporcionado TemplateBody ni TemplateUrl.""msgstr ""El nombre DNS del equilibrador de carga.""""El ID del nombre de la zona de host que est asociado al equilibrador de ""msgstr ""El ID del volumen a adjuntar.""msgstr ""El parmetro (%(key)s) no tiene atributos.""msgstr ""No se ha definido el parmetro (%(key)s) en la plantilla.""msgstr ""No se ha proporcionado el parmetro (%(key)s).""""El URL de una plantilla que especifica la pila que se debe crear como un ""msgstr ""El mtodo de agregacin a comparar con el umbral.""""de dentro de la instancia que se ejecutan en el interior de los servidores """"virtio-<VolumeId> en su lugar.""msgstr ""El tipo a utilizar.""msgstr ""La longitud debe ser al menos %(min)s.""msgstr ""La longitud no puede ser mayor que %(max)s.""""virtio-<VolumeId> en su lugar.""""cadena generada.""""El nmero mnimo de caracteres de esta secuencia que estarn en la cadena """"El nmero mnimo de recursos en servicio cuando se estn ejecutando """"El nombre de la zona de host que est asociada al equilibrador de carga.""""pasar la instancia a estado saludable.""""El nmero de segundos a esperar a que llegue el nmero correcto de seales.""""un rol administrativo y desea crear un RBAC para otro inquilino.""msgstr ""La cadena de clave precompartida de la conexin del sitio ipsec.""msgstr ""El perfil de certificado a utilizar.""""La cadena aleatoria generada por este recurso. Este valor tambin est """"La firma de solicitud que calculamos no coincide con la firma que ha """"El servidor no puede satisfacer la solicitud porque est mal formada o es "" ""incorrecta por algn otro motivo.""""El tamao del volumen en GB. Al actualizar, slo se admite el aumento de "" ""tamao.""""La subred para el puerto en el que se conectarn los miembros de la "" ""agrupacin.""msgstr ""La plantilla no es un objeto JSON ni una correlacin YAML.""msgstr ""La seccin de plantilla no es vlida: %(section)s""msgstr ""La versin de la plantilla no es vlida: %(explanation)s""msgstr ""El valor debe estar en el rango de %(min)s a %(max)s.""msgstr ""El valor no puede ser mayor que %(max)s.""msgstr ""El punto final del sitio web del grupo especificado.""""una conexin entrante est inactiva durante este nmero de segundos se "" ""cerrar. El valor '0' significa esperar permanentemente.""""signal_transport est definido como TOKEN_SIGNAL. Y hay None para todos los ""msgstr ""URL para la autenticacin de la API""""URL de TempURL donde el recurso sealar la terminacin y, opcionalmente, """"Identificador exclusivo de la poltica de cortafuegos a la que pertenece ""msgstr ""Utilizar la propiedad %s.""msgstr ""Usuario %s en dominio no vlido""msgstr ""Usuario %s en proyecto no vlido""msgstr ""El usuario no est autorizado para realizar esta accin""msgstr ""Nombre de usuario de autenticacin de la API""msgstr ""Al utilizar Cinder API V1, el acceso de tipo de volumen""""El valor '%(value)s' no es vlido para '%(name)s' que slo acepta un entero.""""El valor '%(value)s' no es vlido para '%(name)s' que slo acepta un entero "" ""no negativo.""msgstr ""El valor debe ser una cadena de lista delimitada por comas: %s""msgstr ""El valor debe ser una cadena""msgstr ""El valor debe coincidir con el patrn: %s""""desencadenar el recurso para sustituirlo por una cadena aleatoria nueva. El ""msgstr ""Volmenes a adjuntar a la instancia.""""vez que cambia la poltica de cortafuegos o las reglas de cortafuegos ""msgstr ""No est autorizado para completar esta accin.""msgstr ""el entorno tiene la seccin incorrecta \""%s\""""msgstr ""error en la vip""msgstr ""el lmite no puede ser menos de 4""msgstr ""no se han encontrado datos de recursos""msgstr ""no se han encontrado recursos para stack_id %s""msgstr ""no se han encontrado recursos""msgstr ""no se ha encontrado la plantilla plana con el id %s""msgstr ""no se ha encontrado el recurso con el id %s""msgstr ""source_path debe ser una lista no vaca con va de acceso.""msgstr ""source_path debera ser una lista con va de acceso en lugar de %s.""""La tarea %(task)s contiene la propiedad 'requires' en un flujo de trabajo ""","""Project-Id-Version: heat 6.0.1.dev8\n""""POT-Creation-Date: 2016-05-02 00:41+0000\n""""PO-Revision-Date: 2016-05-02 10:06+0000\n""msgstr ""El argumento \""%s\"" debe ser una serie""msgstr ""El delimitador \""%s\"" debe ser una serie""msgstr ""Los marcadores de parmetros \""%s\"" deben ser series""msgstr ""Los parmetros \""%s\"" deben ser series o nmeros""msgstr ""La plantilla \""%s\"" debe ser una serie""msgstr ""%(name)s restriccin invlida para %(utype)s""msgstr ""%(type)s no esta en un formato vlido: %(error)s""msgstr ""El nombre de clave %s debe ser una serie""msgstr ""El nombre de valor %s debe ser una serie""""la que se genera la serie aleatoria.""""partir de la que se genera la serie aleatoria.""""genera la serie aleatoria.""""Una lista de secuencias de caracteres y sus restricciones a partir de la que "" ""se genera la serie aleatoria.""""Una lista de dimensiones (par de nombre/valor arbitrario) asociado con la """"Una lista de polticas de serie a aplicar. Valores predeterminados para anti-"" ""afinidad.""""recursos.""""Un URL firmado para crear ejecuciones para flujos de trabajo especificados "" ""en el recurso Flujo de trabajo.""msgstr ""Una serie especificada de servidores DNS para ser utilizados.""""Una serie que especifica un nombre simblico para la red, que no necesita ""msgstr ""Una serie que especifica la correlacin de red fsica para la red.""msgstr ""Una serie que especifica el tipo de red de proveedor para la red.""msgstr ""Una serie que especifica el id de segmentacin para la red.""msgstr ""Accin %s no esta permitida por el usuario""msgstr ""Accin que se debe realizar en el trfico que coincide con la regla.""msgstr ""Estado administrativo de direccionador.""msgstr ""El algoritmo debe ser uno de %s""""that de larga duracin puedan completarse. Tenga en cuenta que esto vence a "" ""la caducidad de cualquier token de usuario proporcionado.""""independientemente de la opcin de arrendamiento especificada en el inicio "" ""de instancia.""msgstr ""AllowedPattern debe ser una serie""""en el tamao de ram.""msgstr ""Una comprobacin de estado de aplicacin para las instancias.""msgstr ""Una excepcion desconocida ha ocurrido""""serie se serializarn en JSON (y la serie serializada debe tener 255 ""msgstr ""El argumento en \""%s\"" debe ser una serie""msgstr ""El argumento en \""%s\"" debe ser una serie o lista""msgstr ""El argumento para la funcin \""%s\"" debe ser una lista de series""""[nombre_recurso] o [nombre_recurso, atributo, (ruta), ...]""msgstr ""Los argumentos en \""%s\"" deben tener el formato [ndice, coleccin]""""Los argumentos en \""%s\"" deben tener el formato [nombre_recurso, atributo]""msgstr ""Los argumentos en %s no se han resuelto por completo""msgstr ""Correlaciones de dispositivo de bloque que se conectan a la instancia.""""Especificacin adicional booleana que se utiliza para el filtrado de "" ""programas de fondo por su capacidad de crear instantneas de recursos "" ""compartidos.""msgstr ""No se ha podido encontrar rol %s""msgstr ""No se puede comprobar %s, pila no creada""""No se ha podido obtener token de usuario del dominio, no est configurado el "" ""id de dominio de la pila, por favor corriga su heat.conf""msgstr ""No se puede reanudar %s, no se estableci resource_id""msgstr ""Dependencia Circular Encontrada: %(cycle)s""""Se debe especificar el nombre del cliente y el nombre del detter del recurso.""""una serie vaca si no se ha asignado nada en este momento. El resultado """"sealar el error aadiendo --data-binary '{\""status\"": \""FAILURE\""}'.""""No se ha podido enlazar a %(bind_addr)s despus de intentar durante 30 ""msgstr ""ID o nombre de dominio DNS.""msgstr ""Serial de dominio DNS.""""informacin ms detallada, consulte rfc 1035.""msgstr ""Datos proporcionados no son vlidos: %(reason)s""""El valor predeterminado debe ser una serie de lista delimitada por comas: %s""msgstr ""El delimitador para %s debe ser una serie""msgstr ""El despliegue ha saldo con un cdigo de estado distinto de cero: %s""msgstr ""Despliegue con id %s no encontrado""msgstr ""Descripcin para la alarma.""msgstr ""DisableRollback y OnFailure no se pueden usar juntas""msgstr ""Direccin EIP a asociar con instancia.""msgstr ""Falta Ebs; es necesario cuando se especifica BlockDeviceMappings.""""poltica predeterminada en Neutron restringe el uso de esta propiedad slo a "" ""los usuarios administrativos.""msgstr ""Error autorizando la accin %s""""son especficos del hardware o de las extensiones instalados.""""la alarma ha cambiado. De forma predeterminada, se llaman a las acciones "" ""cada vez que se alcanza el umbral.""""Revisin de compilacin Heat. Si prefieres administrar su revisin de "" ""compilacin por separado, puedes pasar esta seccin a un archivo distinto y """"Cmo debe el servidor sealar en Heat con los valores de salida de "" ""despliegue.""msgstr ""ID de proyecto para autenticacin de API""""IP u otra informacin de direccin sobre el invitado que le han permitido """"\""%(snapshot_id)s\"", sin embargo,las opciones especificadas actualmente ""msgstr """" ""Si se especifica, la copia de seguridad desde la que se debe crear el "" ""volumen.""msgstr """" ""Si se especifica, la instantnea desde la que se debe crear el volumen.""""Si se especifica, el tipo de volumen a utilizar, correlacionndose a un ""msgstr ""Argumentos incorrectos en \""%(fn_name)s\"" deben ser: %(example)s""""ndice no correcto a \""%(fn_name)s\"" debera ser entre 0 y %(max_index)s""msgstr ""ndice no correcto a \""%(fn_name)s\"" debera ser: %(example)s""msgstr ""El ndice en \""%s\"" debe ser una serie""msgstr ""El ndice en \""%s\"" debe ser un entero""msgstr ""Indique si el volumen se debe suprimir cuando la instancia se termina.""""poltica predeterminado en Neutron restringe el uso de esta propiedad slo a "" ""usuarios administrativos. Esta propiedad no se puede utilizar junto al ID de "" ""agente L3.""""usuarios administrativos nicamente. Y ahora Neutron no soporta ""msgstr ""ID de instancia a asociar con EIP especificado por la propiedad EIP.""msgstr ""ID de instancia a asociar con EIP.""msgstr ""ID de instancia que se debe reiniciar.""msgstr ""Esquema de URL invlida %s""msgstr ""Version UUID invlida (%d)""msgstr ""Accin invlida %s""msgstr ""Accin invlida %s especificada""msgstr ""Predeterminada invlida %(default)s (%(exc)s)""msgstr ""Clave invlida %s""""El nombre de pila no vlido %s debe contener solo caracteres alfanumricos o "" ""los caracteres \""_-.\"" , debe empezar con alfa y debe tener 255 caracteres o "" ""menos.""msgstr ""Estado invlido %(state)s, esperando uno de %(expect)s""msgstr ""Tipo invlido (%s)""""Los elementos a unir deben de tipo cadena, correlacin o lista. %s ha dado "" ""error en la serializacin con JSON""msgstr ""Clave secreta de par de claves.""msgstr ""Longitud de la serie a generar.""""Lista de recursos a eliminar al realizar una actualizacin que requiere la ""msgstr ""Lista de ID de grupo de seguridad asociados con esta interfaz.""msgstr ""Lista de reglas de salida de grupo de seguridad.""msgstr ""Lista de reglas de acceso de grupo de seguridad.""msgstr ""Lista de cdigos asociados con esta interfaz.""msgstr ""Los elementos de lista de miembros deben ser series""msgstr ""Falta la credencial necesaria :%(required)s ""msgstr ""Mltiples accines especificadas""msgstr ""Nombre para la poltica de firewall.""""Espacio de nombre para agrupar esta configuracin de software cuando se ""msgstr ""ID de interfaz de red a asociar con EIP.""msgstr ""Interfaces de red a asociar con instancia.""msgstr ""Ninguna accin especificada""msgstr ""Ningn evento %s se ha encontrado""msgstr ""No se ha encontrado eventos para el recurso %s""msgstr ""Datos de recursos no se han encontrado""msgstr ""Tipo de Recurso no vaco es obligatorio para el recurso \""%s\""""msgstr ""Nmero de procesos del motor de Heat que bifurcar y ejecutar.""msgstr ""Nmero de minutos a esperar en la creacin de esta pila.""msgstr ""'%(name)s' slo acepta el entero.""""Operador utilizado para comparar la estadstica especificada con umbral.""""Heat URL opcional en un formato parecido a http://0.0.0.0:8004/v1/"" ""%(tenant_id)s.""msgstr ""El nombre de parmetro en \""%s\"" debe ser una serie""msgstr ""Contrasea para autenticacin de API""msgstr ""Los componentes de va de acceso en \""%s\"" deben ser series""msgstr ""Los componentes de va de acceso en los atributos deben ser series""""Poltica a procesar al realizar una actualizacin que requiere la ""msgstr ""La creacin de la agrupacin ha fallado debido a vip""msgstr ""Serie de clave precompartida para la conexin de sitio ipsec.""msgstr ""Las propiedades deber ser de tipo Propiedad. Se ha encontrado %s.""""Propiedades que se tienen qu pasar a cada recurso que se cree en la cadena.""msgstr ""El tipo \""%s\"" de recurso no es una serie""msgstr ""La actualizacin de recurso ya se ha solicitado""msgstr ""Esquema slo vlido para %(ltype)s o %(mtype)s, no %(utype)s""""Seleccina mtodo de autenticacin deferido, claves almacenadas, o "" ""confianzas.""msgstr ""Secuencia de caracteres desde la que crear la una serie aleatoria.""msgstr ""Nombre de recurso compartido.""msgstr ""Esquema nico slo vlido para %(ltype)s, no %(utype)s""msgstr ""Instantnea con id %s no encontrado""""Falta SnapshotId; es necesario cuando se especifica BlockDeviceMappings.""msgstr ""No se ha encontrado configuracin de software con el id %s""msgstr ""Estado desconocido de la pila""msgstr ""La serie a dividir debe ser string; se ha obtenido %s""msgstr ""ID de subred a asociar con esta interfaz.""msgstr ""ID de subred en el que iniciar instancia.""msgstr ""Metadoas suministrados para los recursos del grupo.""msgstr ""Cdigos a adjuntar a instancia.""msgstr ""No se ha proporcionado la versin de plantilla""msgstr ""TemplateBody or TemplateUrl no han sido proporcionadas.""msgstr ""El nombre DNS para el equilibrador de carga.""""El ID del nombre de zona de host que est asociado con el equilibrador de ""msgstr ""El ID del volumen que se debe adjuntar.""msgstr ""El Parametro (%(key)s) no tiene atributos.""msgstr ""El Parametro (%(key)s) no estaba definido en la plantilla.""msgstr ""El Parametro (%(key)s) no estaba proporcionado.""""El URL de una plantilla que especifica la pila que se debe crear como una ""msgstr ""El mtodo de agregacin para comparar con el umbral.""""dentro de la instancia que se ejecutan en el interior de los servidores """"virtio-<IdVolumen> en su lugar.""msgstr ""El sabor a utilizar.""msgstr ""La longitud debe estar al menos %(min)s.""msgstr ""La longitud no debe ser mayor que %(max)s.""""virtio-<IdVolumen> en su lugar.""""serie generada.""""El nmero mnimo de caracteres de esta secuencia que estarn en la serie """"El nmero mnimo de recursos en servicio cuando estn ejecutando """"El nombre de la zona de host que est asociada con el equilibrador de carga.""""mover la instancia al estado saludable.""""El nmero de segundo a esperar a que llegue el nmero correcto de seales.""""un rol administrativo y dese crear un RBAC para otro inquilino.""msgstr ""La serie de clave precompartida de la conexin del sitio ipsec.""msgstr ""El perfil del certificado a utilizar.""""La serie aleatoria generada por este recurso. Este valor tambin est """"La firma de solicitud que calculmos no coincide con la firma que has """"El servidor no puede satisfacer la solicitud ya que tiene un formato "" ""incorrecto o es incorrecta por otro motivo.""""El tamao del volumen en GB. Al actualizar, slo el aumento de tamao est "" ""soportado.""""La subred para el puerto en el que los miembros de la agrupacin se "" ""conectarn.""msgstr ""La plantilla no es un objeto JSON ni correlacin YAML.""msgstr ""La seccin de plantillas es invlida: %(section)s""msgstr ""La version de la plantilla es invlida: %(explanation)s""msgstr ""El valor debe estar en el rango %(min)s a %(max)s.""msgstr ""El valor no debe ser mayor que %(max)s.""msgstr ""El punto final de sitio web para el grupo especificado.""""una conexin entrante est inactiva para este nmero de segundos se cerrar. "" ""Un valor de '0' significa esperar permanentemente.""""signal_transport est definido como TOKEN_SIGNAL. Y hay None en todos los ""msgstr ""URL para autenticacin de API""""URL de TempURL donde el recurso sealar la terminacin y opcionalmente """"Identificador exclusivo de la poltica de cortafuegos a la que se pertenece ""msgstr ""Utilizar propiedad %s.""msgstr ""Usuario %s en dominio invlido""msgstr ""Usuario %s en proyecto invlido""msgstr ""Usuario no est autorizado a realizar la accin""msgstr ""Nombre de usuario de autenticacin de API""msgstr ""Utilizando Cinder API V1, el acceso de tipo de volumen""""El valor '%(value)s' no es vlido para '%(name)s' que slo acepta entero.""""El valor '%(value)s' no es vlido para '%(name)s' que slo acepta enterono "" ""negativo.""msgstr ""El valor debe ser una serie de lista delimitada por comas: %s""msgstr ""El valor debe ser una serie""msgstr ""Valor debe coincidir la forma: %s""""desencadenar el recurso para sustituirlo por una serie aleatoria nueva. El ""msgstr ""Volmenes a adjuntar a instancia.""""vez que cambian la poltica de cortafuegos o las reglas de cortafuegos ""msgstr ""No est autorizado a completar esta accin.""msgstr ""entorno tiene seccin incorrecta \""%s\""""msgstr ""error en vip""msgstr ""lmite no puede ser menos de 4""msgstr ""datos de recursos no se han encontrado""msgstr ""recursos para stack_id %s no se han encontrado""msgstr ""recursos no se han encontrado""msgstr ""plantilla plana con id %s no encontrada""msgstr ""recurso con el id %s no encontrado""msgstr ""source_path debe ser una lista no vaca con ruta.""msgstr ""source_path debera ser una lista con ruta en lugar de %s.""""La tarea %(task)s contine la propiedad 'requires' en un flujo de trabajo """,652,648
openstack%2Fpython-openstackclient~master~I7f29578d0e14884f21183bfb82228d2fe7b7a029,openstack/python-openstackclient,master,I7f29578d0e14884f21183bfb82228d2fe7b7a029,Add functional tests for commands of floating ip,MERGED,2016-04-25 03:24:15.000000000,2016-05-05 07:11:59.000000000,2016-05-05 07:11:58.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 14937}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-04-25 03:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/880f9985fd272349dd7f42d5d29299e405925f8c', 'message': 'Add functional tests for commands of floating ip\n\nThis patch add functinal tests for commands of floating ip\n\nChange-Id: I7f29578d0e14884f21183bfb82228d2fe7b7a029\n'}, {'number': 2, 'created': '2016-04-28 07:20:09.000000000', 'files': ['functional/tests/network/v2/test_floating_ip.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9dba843bdeede54eab30e7f3b537c75965748110', 'message': 'Add functional tests for commands of floating ip\n\nThis patch add functinal tests for commands of floating ip\n\nChange-Id: I7f29578d0e14884f21183bfb82228d2fe7b7a029\n'}]",1,309834,9dba843bdeede54eab30e7f3b537c75965748110,31,5,2,21514,,,0,"Add functional tests for commands of floating ip

This patch add functinal tests for commands of floating ip

Change-Id: I7f29578d0e14884f21183bfb82228d2fe7b7a029
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/34/309834/2 && git format-patch -1 --stdout FETCH_HEAD,"['functional/tests/network/v2/test_floating_ip.py', 'releasenotes/notes/add-floating-ip-functional-test-905fb62b090dfece.yaml']",2,880f9985fd272349dd7f42d5d29299e405925f8c,add-floating-ip-functional-test,--- features: - | Add functional tests for commands of floating ip ,,62,0
openstack%2Fpython-keystoneclient~master~I8b9777a5d81f050fce80e02a72b75809c2307f65,openstack/python-keystoneclient,master,I8b9777a5d81f050fce80e02a72b75809c2307f65,Updated from global requirements,MERGED,2016-04-30 18:08:22.000000000,2016-05-05 06:55:39.000000000,2016-05-05 06:55:38.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6676}]","[{'number': 1, 'created': '2016-04-30 18:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/73235f02b186095f6bf301e185c6473bda4d5055', 'message': 'Updated from global requirements\n\nChange-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65\n'}, {'number': 2, 'created': '2016-05-03 03:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c401816071c5f7a1ae07832333900301f8a099c3', 'message': 'Updated from global requirements\n\nDepends-On: Iffbaf505ef50a6c6d97c5340645acb2f6fda7e0e\n\nChange-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65\n'}, {'number': 3, 'created': '2016-05-03 16:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/24f201b4e61566bbbf7acae17481df4f207cd7bb', 'message': 'Updated from global requirements\n\nChange-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65\n'}, {'number': 4, 'created': '2016-05-04 07:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1e38805b03f65b3176f84efcd8c2b2c391140637', 'message': 'Updated from global requirements\n\nDepends-On: Iffbaf505ef50a6c6d97c5340645acb2f6fda7e0e\n\nChange-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65\n'}, {'number': 5, 'created': '2016-05-04 22:12:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8f8ea68646490f8e334a395f50a9751786069703', 'message': 'Updated from global requirements\n\nChange-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65\n'}]",0,311548,8f8ea68646490f8e334a395f50a9751786069703,22,3,5,11131,,,0,"Updated from global requirements

Change-Id: I8b9777a5d81f050fce80e02a72b75809c2307f65
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/48/311548/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,73235f02b186095f6bf301e185c6473bda4d5055,openstack/requirements,iso8601>=0.1.11 # MIT,iso8601>=0.1.9 # MIT,1,1
openstack%2Fneutron~master~Id002775e31eaa07d6f3f7778fb349813b2be5134,openstack/neutron,master,Id002775e31eaa07d6f3f7778fb349813b2be5134,Bump to neutron-lib 0.1.0,ABANDONED,2016-02-26 17:09:29.000000000,2016-05-05 06:54:15.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 11307}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-26 17:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ebe94902523fc6474977f343c7508d30a0734f9', 'message': 'Bump to neutron-lib 0.0.2\n\nChange-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134\n'}, {'number': 2, 'created': '2016-02-26 20:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e1160f98db320c26406d92b95faec9e8c46ecee', 'message': 'Bump to neutron-lib 0.0.2\n\nChange-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134\n'}, {'number': 3, 'created': '2016-02-26 20:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/970595eada4d5e15a7b2569f107ca9ef74c1fab8', 'message': 'Bump to neutron-lib 0.0.2\n\nChange-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134\n'}, {'number': 4, 'created': '2016-04-15 20:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/17f9fa64b515190b8b77cfd07af441e578746120', 'message': 'Bump to neutron-lib 0.1.0\n\nChange-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134\n'}, {'number': 5, 'created': '2016-04-15 23:12:48.000000000', 'files': ['neutron/common/_deprecate.py', 'requirements.txt', 'neutron/api/v2/attributes.py', 'neutron/common/config.py', 'neutron/hacking/checks.py', 'neutron/tests/unit/api/v2/test_attributes.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/77d12c20f4fce57ae7e29537246fcbaa5fa38639', 'message': 'Bump to neutron-lib 0.1.0\n\nChange-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134\n'}]",2,285441,77d12c20f4fce57ae7e29537246fcbaa5fa38639,49,17,5,10980,,,0,"Bump to neutron-lib 0.1.0

Change-Id: Id002775e31eaa07d6f3f7778fb349813b2be5134
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/285441/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/_deprecate.py', 'requirements.txt', 'neutron/api/v2/attributes.py', 'neutron/common/config.py', 'neutron/hacking/checks.py']",5,3ebe94902523fc6474977f343c7508d30a0734f9,nl-010,import neutron_lib.hacking.checks neutron_lib.hacking.checks.factory(register),"mutable_default_args = re.compile(r""^\s*def .+\((.+=\{\}|.+=\[\])"")oslo_namespace_imports_dot = re.compile(r""import[\s]+oslo[.][^\s]+"") oslo_namespace_imports_from_dot = re.compile(r""from[\s]+oslo[.]"") oslo_namespace_imports_from_root = re.compile(r""from[\s]+oslo[\s]+import[\s]+"") contextlib_nested = re.compile(r""^with (contextlib\.)?nested\("") def use_jsonutils(logical_line, filename): msg = ""N321: jsonutils.%(fun)s must be used instead of json.%(fun)s"" # Some files in the tree are not meant to be run from inside Neutron # itself, so we should not complain about them not using jsonutils json_check_skipped_patterns = [ ""neutron/plugins/ml2/drivers/openvswitch/agent/xenapi/etc/xapi.d/"" ""plugins/netwrap"", ] for pattern in json_check_skipped_patterns: if pattern in filename: return if ""json."" in logical_line: json_funcs = ['dumps(', 'dump(', 'loads(', 'load('] for f in json_funcs: pos = logical_line.find('json.%s' % f) if pos != -1: yield (pos, msg % {'fun': f[:-1]}) def check_oslo_namespace_imports(logical_line): if re.match(oslo_namespace_imports_from_dot, logical_line): msg = (""N323: '%s' must be used instead of '%s'."") % ( logical_line.replace('oslo.', 'oslo_'), logical_line) yield(0, msg) elif re.match(oslo_namespace_imports_from_root, logical_line): msg = (""N323: '%s' must be used instead of '%s'."") % ( logical_line.replace('from oslo import ', 'import oslo_'), logical_line) yield(0, msg) elif re.match(oslo_namespace_imports_dot, logical_line): msg = (""N323: '%s' must be used instead of '%s'."") % ( logical_line.replace('import', 'from').replace('.', ' import '), logical_line) yield(0, msg) def check_no_contextlib_nested(logical_line, filename): msg = (""N324: contextlib.nested is deprecated. With Python 2.7 and later "" ""the with-statement supports multiple nested objects. See https://"" ""docs.python.org/2/library/contextlib.html#contextlib.nested for "" ""more information."") if contextlib_nested.match(logical_line): yield(0, msg) def check_python3_xrange(logical_line): if re.search(r""\bxrange\s*\("", logical_line): yield(0, ""N325: Do not use xrange. Use range, or six.moves.range for "" ""large loops."") def check_no_basestring(logical_line): if re.search(r""\bbasestring\b"", logical_line): msg = (""N326: basestring is not Python3-compatible, use "" ""six.string_types instead."") yield(0, msg) def check_python3_no_iteritems(logical_line): if re.search(r"".*\.iteritems\(\)"", logical_line): msg = (""N327: Use six.iteritems() instead of dict.iteritems()."") yield(0, msg) def no_mutable_default_args(logical_line): msg = ""N329: Method's default argument shouldn't be mutable!"" if mutable_default_args.match(logical_line): yield (0, msg) register(use_jsonutils) register(check_oslo_namespace_imports) register(check_no_contextlib_nested) register(check_python3_xrange) register(check_no_basestring) register(check_python3_no_iteritems) register(no_mutable_default_args)",81,198
openstack%2Fpuppet-tripleo~master~Id065a9180f1f1a41ab225ec5f755498ec7d9a827,openstack/puppet-tripleo,master,Id065a9180f1f1a41ab225ec5f755498ec7d9a827,Create dbs in step 3 for the roles,MERGED,2016-05-04 13:20:03.000000000,2016-05-05 06:47:12.000000000,2016-05-05 06:47:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-05-04 13:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/14ab465b4043fd96892c27d68b6ad6974203e28f', 'message': ""Create dbs in step 3 for the roles\n\nBefore the roles we could make the create db operation depend on a\n'galera-ready' resource [1]. We can't do it anymore from the role so\nwe need to do create in step 3, when we do sync as well.\n\n1. https://github.com/openstack/tripleo-heat-templates/blob/master/puppet/manifests/overcloud_controller_pacemaker.pp#L382\n # Please enter the commit message for your changes. Lines starting\n\nChange-Id: Id065a9180f1f1a41ab225ec5f755498ec7d9a827\n""}, {'number': 2, 'created': '2016-05-04 13:20:56.000000000', 'files': ['manifests/profile/base/keystone.pp', 'manifests/profile/base/glance/registry.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/172412c0638107db538f1a491513de0836fdc311', 'message': ""Create dbs in step 3 for the roles\n\nBefore the roles we could make the create db operation depend on a\n'galera-ready' resource [1]. We can't do it anymore from the role so\nwe need to do create in step 3, when we do sync as well.\n\n1. https://github.com/openstack/tripleo-heat-templates/blob/master/puppet/manifests/overcloud_controller_pacemaker.pp#L382\n\nChange-Id: Id065a9180f1f1a41ab225ec5f755498ec7d9a827\n""}]",0,312496,172412c0638107db538f1a491513de0836fdc311,9,3,2,6796,,,0,"Create dbs in step 3 for the roles

Before the roles we could make the create db operation depend on a
'galera-ready' resource [1]. We can't do it anymore from the role so
we need to do create in step 3, when we do sync as well.

1. https://github.com/openstack/tripleo-heat-templates/blob/master/puppet/manifests/overcloud_controller_pacemaker.pp#L382

Change-Id: Id065a9180f1f1a41ab225ec5f755498ec7d9a827
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/96/312496/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/keystone.pp', 'manifests/profile/base/glance/registry.pp']",2,14ab465b4043fd96892c27d68b6ad6974203e28f,sync_db_without_require, if $step >= 3 and $sync_db {, if $step >= 2 and $sync_db {,2,2
openstack%2Fdiskimage-builder~master~I285c5cc680dd9fbd9bd3f667ef102be14e248114,openstack/diskimage-builder,master,I285c5cc680dd9fbd9bd3f667ef102be14e248114,Add documentation for dib-lint,MERGED,2016-05-02 06:29:25.000000000,2016-05-05 06:43:21.000000000,2016-05-05 06:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 10035}, {'_account_id': 10873}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-05-02 06:29:25.000000000', 'files': ['doc/source/developer/index.rst', 'doc/source/developer/dib_lint.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c6b6f269cc6fc5d77dae8e167ec0037e4c13c024', 'message': 'Add documentation for dib-lint\n\nPrior to this, no user documentation of dib-lint existed, which\nmeant users had to read the dib-lint code itself to figure out\nhow it worked.  This changes adds documentation on using dib-lint\nand the checks it currently supports.\n\nChange-Id: I285c5cc680dd9fbd9bd3f667ef102be14e248114\n'}]",0,311671,c6b6f269cc6fc5d77dae8e167ec0037e4c13c024,10,4,1,6928,,,0,"Add documentation for dib-lint

Prior to this, no user documentation of dib-lint existed, which
meant users had to read the dib-lint code itself to figure out
how it worked.  This changes adds documentation on using dib-lint
and the checks it currently supports.

Change-Id: I285c5cc680dd9fbd9bd3f667ef102be14e248114
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/71/311671/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer/index.rst', 'doc/source/developer/dib_lint.rst']",2,c6b6f269cc6fc5d77dae8e167ec0037e4c13c024,dib-lint-docs,"dib-lint ======== dib-lint provides a way to check for common errors in diskimage-builder elements. To use it, simply run the ``dib-lint`` script in a directory containing an ``elements`` directory. The checks will be run against every file found under ``elements``. The following is a list of what is currently caught by dib-lint: * executable: Ensure any files that begin with #! are executable * indent: Ensure that all source code is using an indent of four spaces * element-deps ordering: Ensure all element-deps files are alphabetized * /bin/bash: Ensure all scripts are using bash explicitly * sete: Ensure all scripts are set -e * setu: Ensure all scripts are set -u * setpipefail: Ensure all scripts are set -o pipefail * dibdebugtrace: Ensure all scripts respect the DIB_DEBUG_TRACE variable * tabindent: Ensure no tabs are used for indentation * newline: Ensure that every file ends with a newline * mddocs: Ensure that only markdown-formatted documentation is used * yaml validation: Ensure that any yaml files in the repo have valid syntax Some of the checks can be omitted, either for an entire project or for an individual file. Project exclusions go in tox.ini, using the following section format:: [dib-lint] ignore=sete setpipefail This will cause the set -e and set -o pipefail checks to be ignored. File-specific exclusions are specified as a comment in the relevant file, using the following format:: # dib-lint: disable=sete setpipefail This will exclude the same tests, but only for the file in which the comment appears. Only some of the checks can be disabled. The ones available for exclusion are: * executable * indent * sete * setu * setpipefail * dibdebugtrace * tabindent * newline * mddocs ",,52,0
openstack%2Finstack-undercloud~master~Iaa522a888806fd9a58eafa30a3cf7d5aac01a45e,openstack/instack-undercloud,master,Iaa522a888806fd9a58eafa30a3cf7d5aac01a45e,Add dib-lint to pep8 tox job,MERGED,2016-04-15 15:55:44.000000000,2016-05-05 06:39:21.000000000,2016-05-05 06:39:21.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-04-15 15:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/ec71b1ad1eca67fe4025404340168af39b726ec5', 'message': ""Add dib-lint to pep8 tox job\n\ndib-lint can catch some common errors in elements, so it would be\ngood to run it on instack-undercloud.  For the moment I'm just\nignoring failures that would require invasive changes to the\nexisting code, but it might be good to actually fix those at some\npoint.\n\nChange-Id: Iaa522a888806fd9a58eafa30a3cf7d5aac01a45e\nDepends-On: Id4b167ed220dd55852b6587b884fabe7bc8554eb\n""}, {'number': 2, 'created': '2016-05-04 16:00:32.000000000', 'files': ['elements/instack-vm/element-deps', 'elements/undercloud-stack-config/os-refresh-config/configure.d/30-reload-keepalived', 'elements/puppet-stack-config/install.d/02-puppet-stack-config', 'elements/undercloud-post-config/os-refresh-config/post-configure.d/98-undercloud-setup', 'elements/undercloud-stack-config/install.d/02-undercloud-stack-heat-metadata', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/0be2088102044b170c32c6e0befda50796f6f9f1', 'message': ""Add dib-lint to pep8 tox job\n\ndib-lint can catch some common errors in elements, so it would be\ngood to run it on instack-undercloud.  For the moment I'm just\nignoring failures that would require invasive changes to the\nexisting code, but it might be good to actually fix those at some\npoint.\n\nChange-Id: Iaa522a888806fd9a58eafa30a3cf7d5aac01a45e\nDepends-On: Id4b167ed220dd55852b6587b884fabe7bc8554eb\n""}]",0,306521,0be2088102044b170c32c6e0befda50796f6f9f1,15,4,2,6928,,,0,"Add dib-lint to pep8 tox job

dib-lint can catch some common errors in elements, so it would be
good to run it on instack-undercloud.  For the moment I'm just
ignoring failures that would require invasive changes to the
existing code, but it might be good to actually fix those at some
point.

Change-Id: Iaa522a888806fd9a58eafa30a3cf7d5aac01a45e
Depends-On: Id4b167ed220dd55852b6587b884fabe7bc8554eb
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/21/306521/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/instack-vm/element-deps', 'elements/puppet-stack-config/install.d/02-puppet-stack-config', 'elements/undercloud-stack-config/install.d/02-undercloud-stack-heat-metadata', 'tox.ini']",4,ec71b1ad1eca67fe4025404340168af39b726ec5,dib-lint," diskimage-builder dib-lint# puppet-stack-config horribly violates E501 (line length), but I'm not # bothered enough to spend the time to fix it. exclude = .tox,dist,doc,*.egg,build,elements/puppet-stack-config/install.d/02-puppet-stack-config [dib-lint] # NOTE(bnemec): I mostly want the executable check from dib-lint, so at least # for the moment I'm ignoring any failures that would require more than simple # reformatting of files. ignore = dibdebugtrace sete setu setpipefail mddocs","exclude = .tox,dist,doc,*.egg,build",22,8
openstack%2Ffuel-library~master~I86fb5433d100d2ea675b259a963a0e84268fa095,openstack/fuel-library,master,I86fb5433d100d2ea675b259a963a0e84268fa095,"For OCF status, match mysqld by process id",MERGED,2016-05-04 12:06:46.000000000,2016-05-05 06:29:11.000000000,2016-05-05 06:25:33.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-04 12:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/22d96091c53d408dc4ee59e3a1b7f0d25689ff6a', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well\n\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2016-05-04 13:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/64e257f14790de63a9f1536bb28070e59993a49d', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well\n\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2016-05-04 13:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9a0fb8bcaa142779a8839dbb45f6b75ab94add29', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well\n\nCo-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2016-05-04 16:35:47.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/590a3f13f3fee83ae971e4c5d69d33a6487196d1', 'message': 'For OCF status, match mysqld by process id\n\nWhen started and doing SST, pidfile is not created immediately.\nFix race conditions by making action status to search by\nthe pid as well. Add a dummy_test to status check, which does\nselect 1.\n\nCo-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\nCloses-bug: #1574999\n\nChange-Id: I86fb5433d100d2ea675b259a963a0e84268fa095\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,312471,590a3f13f3fee83ae971e4c5d69d33a6487196d1,64,6,4,6926,,,0,"For OCF status, match mysqld by process id

When started and doing SST, pidfile is not created immediately.
Fix race conditions by making action status to search by
the pid as well. Add a dummy_test to status check, which does
select 1.

Co-authored-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
Closes-bug: #1574999

Change-Id: I86fb5433d100d2ea675b259a963a0e84268fa095
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/71/312471/2 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,22d96091c53d408dc4ee59e3a1b7f0d25689ff6a,bug/1574999," # Match a mysqld pid by the datadir, exclude position recovery pid=$(ps -C mysqld -o pid= -o args= | grep ""datadir=${OCF_RESKEY_datadir}"" | awk ""!/wsrep-recover/ {print $1}"") if [ ""${pid}"" ] ; then ocf_log info ""${LH} MySQL process ${pid} found"" return $OCF_SUCCESS fi ",,7,0
openstack%2Fproject-config~master~I93f33a29c7e699b5eb635e46292943041e5ba98a,openstack/project-config,master,I93f33a29c7e699b5eb635e46292943041e5ba98a,Add pep8 job to stacklight-integration-tests,MERGED,2016-05-04 15:12:18.000000000,2016-05-05 06:09:19.000000000,2016-05-05 06:09:19.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 19267}]","[{'number': 1, 'created': '2016-05-04 15:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/48ca3b34ab62212853522b9d91a952744955e5d5', 'message': 'Add pep8 job to stacklight-integration-tests\n\nstacklight-integration-tests has a bunch of python code in it,\nso we want to run pep8 against it.\n\nChange-Id: I93f33a29c7e699b5eb635e46292943041e5ba98a\n'}, {'number': 2, 'created': '2016-05-04 15:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d72f27333337b7f8247dabbe8eb29c47c9d85e99', 'message': 'Add pep8 job to stacklight-integration-tests\n\nstacklight-integration-tests has a bunch of python code in it,\nso we want to run pep8 against it.\n\nChange-Id: I93f33a29c7e699b5eb635e46292943041e5ba98a\n'}, {'number': 3, 'created': '2016-05-04 15:38:59.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f3f1ab6b2963fdcbdb188ed591bdb94720200c96', 'message': 'Add pep8 job to stacklight-integration-tests\n\nstacklight-integration-tests has a bunch of python code in it,\nso we want to run pep8 against it.\n\nChange-Id: I93f33a29c7e699b5eb635e46292943041e5ba98a\n'}]",0,312590,f3f1ab6b2963fdcbdb188ed591bdb94720200c96,11,7,3,14691,,,0,"Add pep8 job to stacklight-integration-tests

stacklight-integration-tests has a bunch of python code in it,
so we want to run pep8 against it.

Change-Id: I93f33a29c7e699b5eb635e46292943041e5ba98a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/312590/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,48ca3b34ab62212853522b9d91a952744955e5d5,stacklight-integration-tests, check: - gate-stacklight-integration-tests-pep8 gate: - gate-stacklight-integration-tests-pep8, - name: noop-jobs,11,1
openstack%2Fproject-config~master~I181dbc0aa21863fa35268a823d5b9f20d4baa8e4,openstack/project-config,master,I181dbc0aa21863fa35268a823d5b9f20d4baa8e4,Add publish-to-pypi job for tripleo-puppet-elements,MERGED,2016-05-04 17:10:52.000000000,2016-05-05 06:09:12.000000000,2016-05-05 06:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6928}]","[{'number': 1, 'created': '2016-05-04 17:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cad70451e0fd37d7cef1fcfe340a3276033f5cdd', 'message': 'Add publish-to-pypi job for tripleo-puppet-elements\n\nWe need this in order to release the project under the new\nmechanism.\n\nChange-Id: I181dbc0aa21863fa35268a823d5b9f20d4baa8e4\n'}, {'number': 2, 'created': '2016-05-04 17:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad7f9e6e70888be904e3576429a6c8c400c189a1', 'message': 'Add publish-to-pypi job for tripleo-puppet-elements\n\nWe need this in order to release the project under the new\nmechanism.\n\nChange-Id: I181dbc0aa21863fa35268a823d5b9f20d4baa8e4\n'}, {'number': 3, 'created': '2016-05-04 19:01:59.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8f9bba3cb8771295607c330324e82632724f19a6', 'message': 'Add publish-to-pypi job for tripleo-puppet-elements\n\nWe need this in order to release the project under the new\nmechanism.\n\nChange-Id: I181dbc0aa21863fa35268a823d5b9f20d4baa8e4\n'}]",2,312642,8f9bba3cb8771295607c330324e82632724f19a6,13,4,3,6928,,,0,"Add publish-to-pypi job for tripleo-puppet-elements

We need this in order to release the project under the new
mechanism.

Change-Id: I181dbc0aa21863fa35268a823d5b9f20d4baa8e4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/312642/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,cad70451e0fd37d7cef1fcfe340a3276033f5cdd,publish-tpe, - name: publish-to-pypi post: - tripleo-puppet-elements-branch-tarball,,3,0
openstack%2Fproject-config~master~I7fa9b810ae7f56fecc3b676e8d161e1ec814cb99,openstack/project-config,master,I7fa9b810ae7f56fecc3b676e8d161e1ec814cb99,Vitrage - Jenkins,MERGED,2016-05-03 13:14:46.000000000,2016-05-05 06:09:04.000000000,2016-05-05 06:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-03 13:14:46.000000000', 'files': ['jenkins/jobs/vitrage.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3b5fdaf88dbbd5e9e18ef1e2410a26f4580f8bfb', 'message': 'Vitrage - Jenkins\n\nVitrage.yaml - Added the AODH project to $PROJECTS variable for job\n\nChange-Id: I7fa9b810ae7f56fecc3b676e8d161e1ec814cb99\n'}]",0,312053,3b5fdaf88dbbd5e9e18ef1e2410a26f4580f8bfb,9,3,1,20667,,,0,"Vitrage - Jenkins

Vitrage.yaml - Added the AODH project to $PROJECTS variable for job

Change-Id: I7fa9b810ae7f56fecc3b676e8d161e1ec814cb99
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/312053/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/vitrage.yaml'],1,3b5fdaf88dbbd5e9e18ef1e2410a26f4580f8bfb,Add-AodhProject-to-job," export PROJECTS=""openstack/aodh $PROJECTS""",,1,0
openstack%2Fproject-config~master~I97f012eee4b23bf8deed765a7db73caaa1dc326d,openstack/project-config,master,I97f012eee4b23bf8deed765a7db73caaa1dc326d,Disable App Catalog periodic job,MERGED,2016-05-02 17:12:28.000000000,2016-05-05 06:08:57.000000000,2016-05-05 06:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-02 17:12:28.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a484082221f5f9918bb93d8f42004c90dd23c65', 'message': 'Disable App Catalog periodic job\n\nThis commit disables the periodic job that checks for dead links and\nsubmits a proposal with an update if any dead links are found. The job\nis having trouble following some links that have redirects which\nresults in live links being flagged as dead. We will also adjust this\nin the near future to take direct action rather than proposing a\nchange via gerrit.\n\nChange-Id: I97f012eee4b23bf8deed765a7db73caaa1dc326d\n'}]",0,311790,4a484082221f5f9918bb93d8f42004c90dd23c65,9,3,1,9788,,,0,"Disable App Catalog periodic job

This commit disables the periodic job that checks for dead links and
submits a proposal with an update if any dead links are found. The job
is having trouble following some links that have redirects which
results in live links being flagged as dead. We will also adjust this
in the near future to take direct action rather than proposing a
change via gerrit.

Change-Id: I97f012eee4b23bf8deed765a7db73caaa1dc326d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/311790/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,4a484082221f5f9918bb93d8f42004c90dd23c65,disable-app-cat-update,, periodic: - propose-app-catalog-update,0,2
openstack%2Fcinder~master~Icf91ca7c9e3d3962277c4c4f70e783f80bbe2f77,openstack/cinder,master,Icf91ca7c9e3d3962277c4c4f70e783f80bbe2f77,Huawei: Do not do split if replication pair abnormal,MERGED,2016-03-31 07:07:07.000000000,2016-05-05 06:08:40.000000000,2016-05-05 05:14:05.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13203}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16595}, {'_account_id': 16708}, {'_account_id': 16793}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 21193}]","[{'number': 1, 'created': '2016-03-31 07:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c2d9d2b380954dd6f0d6c09f2cee0df9d452e37e', 'message': 'Huawei: Do not do split if replication pair abnormal\n\nIn Huawei cinder volume driver, replication feature will failed to\nfailover when primary array error. The Implemented failover steps:\n  1. Split replication pair;\n  2. Make the second pair readable & writable.\n\nWhen primary and secondary array are normal, the split will success.\nBut when primary array is error, the split command sent to secondary\nwill fail, so failover will fail.\n\nWhen error occurred on primary or secondary array, the running status\nof replication pair will be abnormal (ERRUPTED). If the status is in\nthis case we should not do split.\n\nChange-Id: Icf91ca7c9e3d3962277c4c4f70e783f80bbe2f77\nCloses-Bug: #1564199\n'}, {'number': 2, 'created': '2016-04-02 11:57:48.000000000', 'files': ['cinder/volume/drivers/huawei/constants.py', 'cinder/tests/unit/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/replication.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/11805628279cc49c8172f0296fd8048fd96b977b', 'message': 'Huawei: Do not do split if replication pair abnormal\n\nIn Huawei cinder volume driver, replication feature will fail to\nfailover when there is a primary array error. The Implemented failover\nsteps:\n  1. Split replication pair;\n  2. Make the second pair readable & writable.\n\nWhen primary and secondary array are normal, the split will succeed.\nBut when primary array is error, the split command sent to secondary\nwill fail, so failover will fail.\n\nWhen error occurred on primary or secondary array, the running status\nof replication pair will be abnormal (ERRUPTED). If the status is in\nthis case we should not do split.\n\nChange-Id: Icf91ca7c9e3d3962277c4c4f70e783f80bbe2f77\nCloses-Bug: #1564199\n'}]",6,299780,11805628279cc49c8172f0296fd8048fd96b977b,84,36,2,16793,,,0,"Huawei: Do not do split if replication pair abnormal

In Huawei cinder volume driver, replication feature will fail to
failover when there is a primary array error. The Implemented failover
steps:
  1. Split replication pair;
  2. Make the second pair readable & writable.

When primary and secondary array are normal, the split will succeed.
But when primary array is error, the split command sent to secondary
will fail, so failover will fail.

When error occurred on primary or secondary array, the running status
of replication pair will be abnormal (ERRUPTED). If the status is in
this case we should not do split.

Change-Id: Icf91ca7c9e3d3962277c4c4f70e783f80bbe2f77
Closes-Bug: #1564199
",git fetch https://review.opendev.org/openstack/cinder refs/changes/80/299780/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/huawei/constants.py', 'cinder/tests/unit/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/replication.py']",3,c2d9d2b380954dd6f0d6c09f2cee0df9d452e37e,bug/1564199," constants.REPLICA_RUNNING_STATUS_INVALID, constants.REPLICA_RUNNING_STATUS_ERRUPTED)", constants.REPLICA_RUNNING_STATUS_INVALID),20,1
openstack%2Fmurano~stable%2Fmitaka~Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95,openstack/murano,stable/mitaka,Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95,Increase status report messages time resolution,ABANDONED,2016-04-29 07:34:09.000000000,2016-05-05 06:04:28.000000000,,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 8127}]","[{'number': 1, 'created': '2016-04-29 07:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f9d756903b2de7ed9617c261f52cf6ac4db4dd11', 'message': 'Increase status report messages time resolution\n\nWe use DATETIME SQL type for created/updated columns\neverywhere through the database. In SQL standard\nDATETIME defaults to DATETIME(6) which is 6 digit\nfraction second part. However MySQL defaults it\nto DATETIME(0) for backward compatibility. In result\nstatus messages timestamps get rounded to the\nsecond boundary and if there are several status\nmessages were generated within a second\nafter table sort they might be shown in a different\norder.\n\nThis commit adds MySQL migration that increases\nresolution for the status table and adds subseconds\nto the generated status repor timestamps.\n\nChange-Id: Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95\nRelated-Bug: #Related-Bug: #\n'}, {'number': 2, 'created': '2016-05-02 17:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1fe86910bd7267b9cee14e73c89897a7817f75d2', 'message': 'Increase status report messages time resolution\n\nWe use DATETIME SQL type for created/updated columns\neverywhere through the database. In SQL standard\nDATETIME defaults to DATETIME(6) which is 6 digit\nfraction second part. However MySQL defaults it\nto DATETIME(0) for backward compatibility. In result\nstatus messages timestamps get rounded to the\nsecond boundary and if there are several status\nmessages were generated within a second\nafter table sort they might be shown in a different\norder.\n\nThis commit adds MySQL migration that increases\nresolution for the status table and adds subseconds\nto the generated status repor timestamps.\n\nChange-Id: Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95\nRelated-Bug: #Related-Bug: #\n'}, {'number': 3, 'created': '2016-05-02 17:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/adffdf8f0afd6a146f61786321d3dc3d8aa73417', 'message': 'Increase status report messages time resolution\n\nWe use DATETIME SQL type for created/updated columns\neverywhere through the database. In SQL standard\nDATETIME defaults to DATETIME(6) which is 6 digit\nfraction second part. However MySQL defaults it\nto DATETIME(0) for backward compatibility. In result\nstatus messages timestamps get rounded to the\nsecond boundary and if there are several status\nmessages were generated within a second\nafter table sort they might be shown in a different\norder.\n\nThis commit adds MySQL migration that increases\nresolution for the status table and adds subseconds\nto the generated status repor timestamps.\n\nChange-Id: Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95\nRelated-Bug: #1462270\n'}, {'number': 4, 'created': '2016-05-04 17:24:44.000000000', 'files': ['murano/engine/system/status_reporter.py', 'murano/db/migration/alembic_migrations/versions/014_incrrease_status_time_resolution.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/4746b334e1cdf0a6e672ce8c8c707fec596349f6', 'message': 'Increase status report messages time resolution\n\nWe use DATETIME SQL type for created/updated columns\neverywhere through the database. In SQL standard\nDATETIME defaults to DATETIME(6) which is 6 digit\nfraction second part. However MySQL defaults it\nto DATETIME(0) for backward compatibility. In result\nstatus messages timestamps get rounded to the\nsecond boundary and if there are several status\nmessages were generated within a second\nafter table sort they might be shown in a different\norder.\n\nThis commit adds MySQL migration that increases\nresolution for the status table and adds subseconds\nto the generated status repor timestamps.\n\nChange-Id: Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95\nRelated-Bug: #1462270\n'}]",0,311046,4746b334e1cdf0a6e672ce8c8c707fec596349f6,17,4,4,7226,,,0,"Increase status report messages time resolution

We use DATETIME SQL type for created/updated columns
everywhere through the database. In SQL standard
DATETIME defaults to DATETIME(6) which is 6 digit
fraction second part. However MySQL defaults it
to DATETIME(0) for backward compatibility. In result
status messages timestamps get rounded to the
second boundary and if there are several status
messages were generated within a second
after table sort they might be shown in a different
order.

This commit adds MySQL migration that increases
resolution for the status table and adds subseconds
to the generated status repor timestamps.

Change-Id: Ice8c2d82c6a320c7f73c27f4c60c87bef55b8d95
Related-Bug: #1462270
",git fetch https://review.opendev.org/openstack/murano refs/changes/46/311046/4 && git format-patch -1 --stdout FETCH_HEAD,"['murano/engine/system/status_reporter.py', 'murano/db/migration/alembic_migrations/versions/014_incrrease_status_time_resolution.py']",2,f9d756903b2de7ed9617c261f52cf6ac4db4dd11,status-timestamp-resolution,"# Copyright 2016 OpenStack Foundation. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Increase time resolution for status reports Revision ID: 014 Create Date: 2016-04-28 """""" # revision identifiers, used by Alembic. revision = '014' down_revision = '013' from alembic import op import sqlalchemy.dialects.mysql as sa_mysql MYSQL_ENGINE = 'InnoDB' MYSQL_CHARSET = 'utf8' def upgrade(): engine = op.get_bind() if engine.dialect.dialect_description.startswith('mysql'): with op.batch_alter_table('status') as batch_op: batch_op.alter_column('created', type_=sa_mysql.DATETIME(fsp=6)) batch_op.alter_column('updated', type_=sa_mysql.DATETIME(fsp=6)) def downgrade(): engine = op.get_bind() if engine.dialect.dialect_description.startswith('mysql'): with op.batch_alter_table('status') as batch_op: batch_op.alter_column('created', type_=sa_mysql.DATETIME()) batch_op.alter_column('updated', type_=sa_mysql.DATETIME()) ",,48,1
openstack%2Fsenlin~master~Ib67d7c3a5457bdac338e786bdd193946b71aa4b5,openstack/senlin,master,Ib67d7c3a5457bdac338e786bdd193946b71aa4b5,replace logging with oslo.log,MERGED,2016-04-25 12:12:56.000000000,2016-05-05 06:01:57.000000000,2016-05-05 06:01:57.000000000,"[{'_account_id': 3}, {'_account_id': 6676}, {'_account_id': 7404}, {'_account_id': 8358}, {'_account_id': 11034}, {'_account_id': 19902}]","[{'number': 1, 'created': '2016-04-25 12:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/cd822559330089f698a5d034c472577f8731a747', 'message': 'replace logging with oslo.log\n\noslo.log provides more features and is a fundamental recommended\nlibrary to use.\n\nAlso the library oslo.log provides compatibility for log levels,\nlogging namespace is not needed.\n\nChange-Id: Ib67d7c3a5457bdac338e786bdd193946b71aa4b5\n'}, {'number': 2, 'created': '2016-04-28 22:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/452bf9d3786971637027d03406715bcc875e1ece', 'message': 'replace logging with oslo.log\n\noslo.log provides more features and is a fundamental recommended\nlibrary to use.\n\nAlso the library oslo.log provides compatibility for log levels,\nlogging namespace is not needed.\n\nChange-Id: Ib67d7c3a5457bdac338e786bdd193946b71aa4b5\n'}, {'number': 3, 'created': '2016-05-03 03:14:39.000000000', 'files': ['senlin/tests/unit/common/base.py', 'senlin/tests/unit/engine/test_event.py', 'senlin/engine/event.py', 'senlin/tests/unit/db/test_event_api.py', 'senlin/tests/unit/test_common_utils.py', 'senlin/common/consts.py', 'senlin/api/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2e0cb2e33c8b3e5c1aa9cdbef86aae39d917ada8', 'message': 'replace logging with oslo.log\n\noslo.log provides more features and is a fundamental recommended\nlibrary to use.\n\nAlso the library oslo.log provides compatibility for log levels,\nlogging namespace is not needed.\n\nChange-Id: Ib67d7c3a5457bdac338e786bdd193946b71aa4b5\n'}]",8,309950,2e0cb2e33c8b3e5c1aa9cdbef86aae39d917ada8,20,6,3,6676,,,0,"replace logging with oslo.log

oslo.log provides more features and is a fundamental recommended
library to use.

Also the library oslo.log provides compatibility for log levels,
logging namespace is not needed.

Change-Id: Ib67d7c3a5457bdac338e786bdd193946b71aa4b5
",git fetch https://review.opendev.org/openstack/senlin refs/changes/50/309950/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/common/base.py', 'senlin/tests/unit/engine/test_event.py', 'senlin/engine/event.py', 'senlin/tests/unit/db/test_event_api.py', 'senlin/tests/unit/test_common_utils.py', 'senlin/api/common/wsgi.py', 'senlin/common/consts.py']",7,cd822559330089f698a5d034c472577f8731a747,use-oslo.log,"from oslo_log import log 'CRITICAL': log.CRITICAL, 'ERROR': log.ERROR, 'WARNING': log.WARNING, 'INFO': log.INFO, 'DEBUG': log.DEBUG,","import logging 'CRITICAL': logging.CRITICAL, 'ERROR': logging.ERROR, 'WARNING': logging.WARNING, 'INFO': logging.INFO, 'DEBUG': logging.DEBUG,",36,42
openstack%2Fxstatic-jsencrypt~master~I9779b3294847c21925643c15cbbf5ae1afe0d525,openstack/xstatic-jsencrypt,master,I9779b3294847c21925643c15cbbf5ae1afe0d525,Update JSEncrypt to 2.1.0 from 2.0.0,ABANDONED,2016-01-05 23:32:00.000000000,2016-05-05 05:56:48.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7179}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-01-05 23:32:00.000000000', 'files': ['xstatic/pkg/jsencrypt/data/jsencrypt.js', 'xstatic/pkg/jsencrypt/__init__.py'], 'web_link': 'https://opendev.org/openstack/xstatic-jsencrypt/commit/905e1cccd109332a0021bffe68270677d5c3d23a', 'message': 'Update JSEncrypt to 2.1.0 from 2.0.0\n\nChange-Id: I9779b3294847c21925643c15cbbf5ae1afe0d525\nCloses-Bug: #1531337\n'}]",0,263947,905e1cccd109332a0021bffe68270677d5c3d23a,8,7,1,17013,,,0,"Update JSEncrypt to 2.1.0 from 2.0.0

Change-Id: I9779b3294847c21925643c15cbbf5ae1afe0d525
Closes-Bug: #1531337
",git fetch https://review.opendev.org/openstack/xstatic-jsencrypt refs/changes/47/263947/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/jsencrypt/data/jsencrypt.js', 'xstatic/pkg/jsencrypt/__init__.py']",2,905e1cccd109332a0021bffe68270677d5c3d23a,bug/1531337,"VERSION = '2.1.0' # version of the packaged files, please use the upstreamBUILD = '0' # our package build number, so we can release new builds","VERSION = '2.0.0' # version of the packaged files, please use the upstreamBUILD = '2' # our package build number, so we can release new builds",236,219
openstack%2Fproject-config~master~Ia80c55690c065514f076b4db3ae235a3f00521c0,openstack/project-config,master,Ia80c55690c065514f076b4db3ae235a3f00521c0,Kolla-kubernetes,MERGED,2016-05-04 15:14:58.000000000,2016-05-05 05:55:30.000000000,2016-05-05 05:55:30.000000000,"[{'_account_id': 3}, {'_account_id': 2468}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-05-04 15:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b8997cb3597916f3aedc7fa2c3d874691b0d481f', 'message': 'Kolla-kubernetes\n\nCreate the kolla-kubernetes repo.\n\nChange-Id: Ia80c55690c065514f076b4db3ae235a3f00521c0\n'}, {'number': 2, 'created': '2016-05-04 15:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bb764b4cb0d0d8d907a7d436b8f737c73011aff5', 'message': 'Kolla-kubernetes\n\nCreate the kolla-kubernetes repo.\n\nChange-Id: Ia80c55690c065514f076b4db3ae235a3f00521c0\n'}, {'number': 3, 'created': '2016-05-04 19:20:04.000000000', 'files': ['gerrit/acls/openstack/kolla-kubernetes.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ffc14863fb549cabb001a5b03e889b385d0d542a', 'message': 'Kolla-kubernetes\n\nCreate the kolla-kubernetes repo.\n\nNeeded-By: Iefefcd460ec7db3071a5f182793649f1e8da5609\nChange-Id: Ia80c55690c065514f076b4db3ae235a3f00521c0\n'}]",0,312592,ffc14863fb549cabb001a5b03e889b385d0d542a,19,7,3,10419,,,0,"Kolla-kubernetes

Create the kolla-kubernetes repo.

Needed-By: Iefefcd460ec7db3071a5f182793649f1e8da5609
Change-Id: Ia80c55690c065514f076b4db3ae235a3f00521c0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/312592/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/kolla-kubernetes.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,b8997cb3597916f3aedc7fa2c3d874691b0d481f,new-project, - name: openstack/kolla-kubernetes template: - name: merge-check - name: python-jobs - name: python3-jobs - name: check-requirements - name: openstack-server-publish-jobs - name: publish-to-pypi - name: release-notes-jobs ,,41,0
openstack%2Fmanila~master~I5aa4c128cd0e25fb12316de21eed262cca810e08,openstack/manila,master,I5aa4c128cd0e25fb12316de21eed262cca810e08,Added docs for commit message tags,MERGED,2016-04-25 16:06:00.000000000,2016-05-05 05:54:54.000000000,2016-05-05 05:23:15.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 6938}, {'_account_id': 7102}, {'_account_id': 7872}, {'_account_id': 8932}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 14624}, {'_account_id': 14643}, {'_account_id': 15100}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 17097}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 17780}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 20079}, {'_account_id': 20581}, {'_account_id': 20695}, {'_account_id': 21111}, {'_account_id': 21242}]","[{'number': 1, 'created': '2016-04-25 16:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dc8eca418dd96be168ba86e24bda08a186769b80', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 2, 'created': '2016-04-25 16:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4de895929dadfe887027de76c472bd7f6d087704', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 3, 'created': '2016-04-25 16:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4a949c761afb1e05cb5ce949677a0aa351abf925', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 4, 'created': '2016-04-25 22:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c96816b8a531243d8a9884f3c86937b38d1580e1', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 5, 'created': '2016-04-26 15:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3ffb39b7cc144bbab7e71a08f3550481a57c3b4f', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 6, 'created': '2016-04-26 17:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a0c9e5b1ea910f573502e403d6defee1dfbe51aa', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 7, 'created': '2016-04-27 15:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4447317637dba4ee5f780b5de9cd8eafb4c80e1f', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 8, 'created': '2016-04-27 17:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/97b72b148f81f42e65601c0c4aa72438c43fad43', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 9, 'created': '2016-05-03 14:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cf2d5955843edad4e599f7b7e3a8f0cce62f7d2b', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 10, 'created': '2016-05-03 18:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0dad036b04da143e360af519a1bb0be51124e09e', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}, {'number': 11, 'created': '2016-05-04 17:42:45.000000000', 'files': ['doc/source/devref/index.rst', 'doc/source/devref/commit_message_tags.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/fef3c1e7db33140287a6c091c181f5622168417f', 'message': 'Added docs for commit message tags\n\nAdded some documentation for how and when to use commit message tags\nin git commit messages. Also added a link to the new article in the\nindex for the dev ref.\n\nChange-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08\n'}]",52,310009,fef3c1e7db33140287a6c091c181f5622168417f,169,29,11,17780,,,0,"Added docs for commit message tags

Added some documentation for how and when to use commit message tags
in git commit messages. Also added a link to the new article in the
index for the dev ref.

Change-Id: I5aa4c128cd0e25fb12316de21eed262cca810e08
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/310009/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/index.rst', 'doc/source/devref/commit_message_tags.rst']",2,dc8eca418dd96be168ba86e24bda08a186769b80,commit_tags_in_docs,"Using Commit Message Tags in Manila =================================== When writing git commit messages for code submissions into Manila, it can be useful to provide tags in the message for both human consumption as well as linking to other external resources, such as Launchpad. The tags are placed on a line on their own and each subsequent tag must be on its own line The following tags are used in Manila. - **APIImpact** - Use this tag when the code change modifies a public HTTP API interface. This tag indicates that the patch creates, changes, or deletes a public API interface. - **Change-id** - This tag is automatically generated by a Gerrit hook and is a unique hash that describes the change. This hash should not be changed when rebasing as it is used by Gerrit to keep track of the change. - **Closes-Bug:** *<#launchpad_bug_id>* - This tag is used when the change closes the bug referenced by the Launchpad bug ID given. - **DocImpact** *<reason>* - Use this tag when the code change requires changes or additions to documentation in order to be understood. This tag can also be used if the documentation is provided along with the patch itself. While not required, it is recommended to provide a short description of the documentation changes needed or provided for or with the patch. This will also generate a bug in the openstack-manuals project for triaging and tracking. - **Implements:** *blueprint <name_of_blueprint>* - Use this tag when a change implements the given blueprint in Launchpad. This will automatically generate a link to the blueprint in Gerrit for easy access for reviewers. - **Partial-Fix:** *<#launchpad_bug_id>* - This tag is used when the change partially fixes the issue referenced by the Launchpad bug ID given. Use this tag when more work is needed to close the bug. - **Related-Bug:** *<#launchpad_bug_id>* - This tag is used when a reference to another bug is needed but is not impacted by the current change. - **Trivial-Fix:** - This tag is used when a change provides a simple for an issue such that having a Launchpad bug does not need to be created. Make sure that the **Closes-Bug**, **Partial-Fix**, **Related-Bug**, **blueprint**, and **Change-id** tags are at the very end of the commit message. The Gerrit hooks will automatically put the hash at the end of the commit message. For more information on tags and some examples of good commit messages, refer to GitCommitMessages_ documentation. .. _GitCommitMessages: https://wiki.openstack.org/wiki/GitCommitMessages#Including_external_references ",,42,0
openstack%2Fneutron~master~I2451f9a2c6a64ce27a607b193900caa05742273d,openstack/neutron,master,I2451f9a2c6a64ce27a607b193900caa05742273d,Optimize get_ports query by filtering on subnet,MERGED,2016-04-06 07:13:29.000000000,2016-05-05 05:43:20.000000000,2016-04-21 13:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10267}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 14615}, {'_account_id': 15752}, {'_account_id': 20257}]","[{'number': 1, 'created': '2016-04-06 07:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/351ca63d764f6d5e2908007deb120830c0417f6a', 'message': 'Optimize get_ports query by filtering on subnet\n\nCurrent code gets all ports from DB and then for each port it checks\nif it has a PD subnet. With this, we get ports which are not needed\nand again we need to check for subnet in these ports.\n\nWe can optimize this by querying the DB by filtering on subnet.\n\nCloses-bug: #1566676\nChange-Id: I2451f9a2c6a64ce27a607b193900caa05742273d\n'}, {'number': 2, 'created': '2016-04-07 09:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad199a479c8a23664b9798753d1c8929ae9513f6', 'message': 'Optimize get_ports query by filtering on subnet\n\nCurrent code gets all ports from DB and then for each port it checks\nif it has a PD subnet. With this, we get ports which are not needed\nand again we need to check for subnet in these ports.\n\nWe can optimize this by querying the DB by filtering on subnet.\n\nCloses-bug: #1566676\nChange-Id: I2451f9a2c6a64ce27a607b193900caa05742273d\n'}, {'number': 3, 'created': '2016-04-13 13:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04a92875f78c09fe2997c4b9bf939c4ef5814f81', 'message': 'Optimize get_ports query by filtering on subnet\n\nCurrent code gets all ports from DB and then for each port it checks\nif it has a PD subnet. With this, we get ports which are not needed\nand again we need to check for subnet in these ports.\n\nWe can optimize this by querying the DB by filtering on subnet.\n\nCloses-bug: #1566676\nChange-Id: I2451f9a2c6a64ce27a607b193900caa05742273d\n'}, {'number': 4, 'created': '2016-04-15 22:55:15.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8693d21ef34f4b3a4273862894838d47e924b63f', 'message': 'Optimize get_ports query by filtering on subnet\n\nCurrent code gets all ports from DB and then for each port it checks\nif it has a PD subnet. With this, we get ports which are not needed\nand again we need to check for subnet in these ports.\n\nWe can optimize this by querying the DB by filtering on subnet.\n\nCloses-bug: #1566676\nChange-Id: I2451f9a2c6a64ce27a607b193900caa05742273d\n'}]",4,302062,8693d21ef34f4b3a4273862894838d47e924b63f,81,20,4,10267,,,0,"Optimize get_ports query by filtering on subnet

Current code gets all ports from DB and then for each port it checks
if it has a PD subnet. With this, we get ports which are not needed
and again we need to check for subnet in these ports.

We can optimize this by querying the DB by filtering on subnet.

Closes-bug: #1566676
Change-Id: I2451f9a2c6a64ce27a607b193900caa05742273d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/302062/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,351ca63d764f6d5e2908007deb120830c0417f6a,bug_1566676," filters = {'fixed_ips': {'subnet_id': [s['id']]}} ports = self.get_ports(context, filters=filters) new_port = {'port': port} new_port['port']['fixed_ips'] = fixed_ips self.update_port(context, port['id'], new_port)"," ports = self.get_ports(context) new_port = {'port': port} if fixed_ips: new_port['port']['fixed_ips'] = fixed_ips self.update_port(context, port['id'], new_port)",5,5
openstack%2Fproject-config~master~Idd0e42dbf0a0f6e830e7ec7e4b614187f5c216cb,openstack/project-config,master,Idd0e42dbf0a0f6e830e7ec7e4b614187f5c216cb,Correct image name for generated magnum image,MERGED,2016-05-04 18:00:55.000000000,2016-05-05 05:37:49.000000000,2016-05-05 05:37:46.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 18:00:55.000000000', 'files': ['jenkins/jobs/magnum.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cb88b954f874454381f9cd0f30f3e9ab66358eb6', 'message': 'Correct image name for generated magnum image\n\nWe use the image without -latest suffix in our jobs,\nso publish to the right name.\n\nChange-Id: Idd0e42dbf0a0f6e830e7ec7e4b614187f5c216cb\n'}]",0,312667,cb88b954f874454381f9cd0f30f3e9ab66358eb6,7,3,1,6133,,,0,"Correct image name for generated magnum image

We use the image without -latest suffix in our jobs,
so publish to the right name.

Change-Id: Idd0e42dbf0a0f6e830e7ec7e4b614187f5c216cb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/312667/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/magnum.yaml'],1,cb88b954f874454381f9cd0f30f3e9ab66358eb6,, cp $WORKSPACE/${IMAGE_NAME}.qcow2 $WORKSPACE/fedora-atomic-f23-dib.qcow2, cp $WORKSPACE/${IMAGE_NAME}.qcow2 $WORKSPACE/fedora-atomic-f23-dib-latest.qcow2,1,1
openstack%2Frally~master~I4b43dd6941a6356082c7e63b958351f48e3faaa8,openstack/rally,master,I4b43dd6941a6356082c7e63b958351f48e3faaa8,Updated from global requirements,ABANDONED,2016-04-30 18:09:06.000000000,2016-05-05 05:31:39.000000000,,"[{'_account_id': 3}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-04-30 18:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6d966a83ae9ba6e30fc131bd96a7bc20694a76bf', 'message': 'Updated from global requirements\n\nChange-Id: I4b43dd6941a6356082c7e63b958351f48e3faaa8\n'}, {'number': 2, 'created': '2016-05-03 16:03:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/b1e5feb059d7abf6561cf43d76c3b32cbc8949d1', 'message': 'Updated from global requirements\n\nChange-Id: I4b43dd6941a6356082c7e63b958351f48e3faaa8\n'}]",0,311556,b1e5feb059d7abf6561cf43d76c3b32cbc8949d1,11,4,2,11131,,,0,"Updated from global requirements

Change-Id: I4b43dd6941a6356082c7e63b958351f48e3faaa8
",git fetch https://review.opendev.org/openstack/rally refs/changes/56/311556/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6d966a83ae9ba6e30fc131bd96a7bc20694a76bf,openstack/requirements,iso8601>=0.1.11 # MIT,iso8601>=0.1.9 # MIT,1,1
openstack%2Foslo.middleware~master~Ia5ead0fe27a0e5e6a0eaec532bd267276b003794,openstack/oslo.middleware,master,Ia5ead0fe27a0e5e6a0eaec532bd267276b003794,Added PATCH method to default config,MERGED,2016-03-17 10:24:18.000000000,2016-05-05 05:31:15.000000000,2016-05-05 05:31:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-03-17 10:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/71b64d1e4bbdd7161cc6ab7f4c9d038db4e508a2', 'message': 'Added PATCH method to default config\n\nThis patch adds the PATCH method (rfc5789) to the default permitted\nHTTP Methods in this middleware.\n\nChange-Id: Ia5ead0fe27a0e5e6a0eaec532bd267276b003794\n'}, {'number': 2, 'created': '2016-04-05 13:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/0cb16365baba3c3674f8897625bb9abdce4b8473', 'message': 'Added PATCH method to default config\n\nThis patch adds the PATCH method (rfc5789) to the default permitted\nHTTP Methods in this middleware.\n\nChange-Id: Ia5ead0fe27a0e5e6a0eaec532bd267276b003794\n'}, {'number': 3, 'created': '2016-05-04 13:53:16.000000000', 'files': ['oslo_middleware/cors.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/9673e634966df3792d4103e5fd7ac156cd9ba677', 'message': 'Added PATCH method to default config\n\nThis patch adds the PATCH method (rfc5789) to the default permitted\nHTTP Methods in this middleware.\n\nChange-Id: Ia5ead0fe27a0e5e6a0eaec532bd267276b003794\n'}]",0,293930,9673e634966df3792d4103e5fd7ac156cd9ba677,15,5,3,9717,,,0,"Added PATCH method to default config

This patch adds the PATCH method (rfc5789) to the default permitted
HTTP Methods in this middleware.

Change-Id: Ia5ead0fe27a0e5e6a0eaec532bd267276b003794
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/30/293930/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_middleware/cors.py'],1,71b64d1e4bbdd7161cc6ab7f4c9d038db4e508a2,cors," 'TRACE', 'PATCH'], # RFC 2616, RFC 5789"," 'TRACE'], # RFC 2616",1,1
openstack%2Fmanila-ui~master~Icc9d550427113c972996116e1416601ca97644b4,openstack/manila-ui,master,Icc9d550427113c972996116e1416601ca97644b4,Updated from global requirements,MERGED,2016-04-30 18:04:22.000000000,2016-05-05 05:20:52.000000000,2016-05-05 05:20:52.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 14567}, {'_account_id': 15100}]","[{'number': 1, 'created': '2016-04-30 18:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/eccccdee23029aaee88bf69381178cdfd1c55aea', 'message': 'Updated from global requirements\n\nChange-Id: Icc9d550427113c972996116e1416601ca97644b4\n'}, {'number': 2, 'created': '2016-05-04 22:08:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/144d73702d9a6fa1e82b53718b3bb9980752101c', 'message': 'Updated from global requirements\n\nChange-Id: Icc9d550427113c972996116e1416601ca97644b4\n'}]",0,311539,144d73702d9a6fa1e82b53718b3bb9980752101c,10,4,2,11131,,,0,"Updated from global requirements

Change-Id: Icc9d550427113c972996116e1416601ca97644b4
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/39/311539/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,eccccdee23029aaee88bf69381178cdfd1c55aea,openstack/requirements,iso8601>=0.1.11 # MIT,iso8601>=0.1.9 # MIT,1,1
openstack%2Fopenstack-ansible-lxc_hosts~master~I851f29d8feebc41e9bcbc1866bba1782c6727d6a,openstack/openstack-ansible-lxc_hosts,master,I851f29d8feebc41e9bcbc1866bba1782c6727d6a,Fix generation of LXC hostnames,MERGED,2016-05-04 21:15:40.000000000,2016-05-05 05:14:25.000000000,2016-05-05 05:14:25.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 15993}]","[{'number': 1, 'created': '2016-05-04 21:15:40.000000000', 'files': ['handlers/main.yml', 'tasks/lxc_cache.yml', 'tasks/lxc_cache_create.yml', 'tasks/lxc_cache_preparation.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6c12d17fedf285155fe8d54672099b75ddde815f', 'message': ""Fix generation of LXC hostnames\n\nThe LXC download template sets hostnames within containers by an\nin-place string replacement of 'LXC_NAME' in /etc/hosts and\n/etc/hostnames with the given container name.\n\nCreate the base cache container image with the name 'LXC_NAME' so that\nthis this in-place text replacement happens and containers are created\nwith the expected hostnames.\n\nChange-Id: I851f29d8feebc41e9bcbc1866bba1782c6727d6a\n""}]",0,312752,6c12d17fedf285155fe8d54672099b75ddde815f,12,4,1,14805,,,0,"Fix generation of LXC hostnames

The LXC download template sets hostnames within containers by an
in-place string replacement of 'LXC_NAME' in /etc/hosts and
/etc/hostnames with the given container name.

Create the base cache container image with the name 'LXC_NAME' so that
this this in-place text replacement happens and containers are created
with the expected hostnames.

Change-Id: I851f29d8feebc41e9bcbc1866bba1782c6727d6a
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/52/312752/1 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'tasks/lxc_cache.yml', 'tasks/lxc_cache_create.yml', 'tasks/lxc_cache_preparation.yml']",4,6c12d17fedf285155fe8d54672099b75ddde815f,lxc_hostnames," dest: ""/var/lib/lxc/LXC_NAME/rootfs{{ item.dest }}"" dest: ""/var/lib/lxc/LXC_NAME/rootfs/usr/local/bin/cache-prep-commands.sh"" command: ""chroot /var/lib/lxc/LXC_NAME/rootfs /usr/local/bin/cache-prep-commands.sh"" dest: ""/var/lib/lxc/LXC_NAME/rootfs{{ item.key }}"" dest: ""/var/lib/lxc/LXC_NAME/rootfs/usr/local/bin/cache-package-prep-commands.sh"" command: ""chroot /var/lib/lxc/LXC_NAME/rootfs /usr/local/bin/cache-package-prep-commands.sh"" dest: ""/var/lib/lxc/LXC_NAME/rootfs/usr/local/bin/cache-post-prep-commands.sh"" command: ""chroot /var/lib/lxc/LXC_NAME/rootfs /usr/local/bin/cache-post-prep-commands.sh"" dest: ""/var/lib/lxc/LXC_NAME/rootfs/etc/ssh/sshd_config"" dest: ""/var/lib/lxc/LXC_NAME/rootfs/root/.ssh/authorized_keys"""," dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs{{ item.dest }}"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs/usr/local/bin/cache-prep-commands.sh"" command: ""chroot /var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs /usr/local/bin/cache-prep-commands.sh"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs{{ item.key }}"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs/usr/local/bin/cache-package-prep-commands.sh"" command: ""chroot /var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs /usr/local/bin/cache-package-prep-commands.sh"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs/usr/local/bin/cache-post-prep-commands.sh"" command: ""chroot /var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs /usr/local/bin/cache-post-prep-commands.sh"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs/etc/ssh/sshd_config"" dest: ""/var/lib/lxc/cache-{{ lxc_cache_map.distro }}/rootfs/root/.ssh/authorized_keys""",14,14
openstack%2Fglance~stable%2Fmitaka~I80f04f8b6a23c208f9553b398c8f5db05190bebb,openstack/glance,stable/mitaka,I80f04f8b6a23c208f9553b398c8f5db05190bebb,"Increase max wait time, avoid racy failure in gate",MERGED,2016-04-13 23:11:51.000000000,2016-05-05 04:43:17.000000000,2016-05-05 04:43:17.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}]","[{'number': 1, 'created': '2016-04-13 23:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fdfe0776265b602a428cbbc75dfe98bb351d7617', 'message': ""Increase max wait time, avoid racy failure in gate\n\nThe test_task_api fails intermittently in gate.\n\nExample:\nhttp://logs.openstack.org/15/293415/2/check/gate-glance-python27/6a96731/testr_results.html.gz\n\nThe reason behind this is that the recent addition of flows to tasks\ntake extra time. When this test was written it considered execution time\nfor limited script length. Some of the nodes in the gate might be slower\nthan others resulting into these intermittent failures.\n\nUntil we come up with better way to control the flows that run by\ndefault on tasks, we don't have a good way to run smaller script. The\nincrease of timeout doesn't hurt as much as the sleep interval is 0.05\nseconds so, only the slower runs in the gate/dev box will be affected.\n\nCo-Authored-By: Nikhil Komawar<nik.komawar@gmail.com>\n\nChange-Id: I80f04f8b6a23c208f9553b398c8f5db05190bebb\n(cherry picked from commit 143df036fa2aa1416a6b44e26db48b8eb9ed2f3b)\n""}, {'number': 2, 'created': '2016-04-14 09:31:52.000000000', 'files': ['glance/tests/integration/v2/test_tasks_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/aa2d1a2fdd4976ed172e9705a5ecb4ce1463fa4c', 'message': ""Increase max wait time, avoid racy failure in gate\n\nThe test_task_api fails intermittently in gate.\n\nExample:\nhttp://logs.openstack.org/15/293415/2/check/gate-glance-python27/6a96731/testr_results.html.gz\n\nThe reason behind this is that the recent addition of flows to tasks\ntake extra time. When this test was written it considered execution time\nfor limited script length. Some of the nodes in the gate might be slower\nthan others resulting into these intermittent failures.\n\nUntil we come up with better way to control the flows that run by\ndefault on tasks, we don't have a good way to run smaller script. The\nincrease of timeout doesn't hurt as much as the sleep interval is 0.05\nseconds so, only the slower runs in the gate/dev box will be affected.\n\nCloses-Bug: #1552404\n\nCo-Authored-By: Nikhil Komawar<nik.komawar@gmail.com>\n\nChange-Id: I80f04f8b6a23c208f9553b398c8f5db05190bebb\n(cherry picked from commit 143df036fa2aa1416a6b44e26db48b8eb9ed2f3b)\n""}]",0,305520,aa2d1a2fdd4976ed172e9705a5ecb4ce1463fa4c,12,3,2,6484,,,0,"Increase max wait time, avoid racy failure in gate

The test_task_api fails intermittently in gate.

Example:
http://logs.openstack.org/15/293415/2/check/gate-glance-python27/6a96731/testr_results.html.gz

The reason behind this is that the recent addition of flows to tasks
take extra time. When this test was written it considered execution time
for limited script length. Some of the nodes in the gate might be slower
than others resulting into these intermittent failures.

Until we come up with better way to control the flows that run by
default on tasks, we don't have a good way to run smaller script. The
increase of timeout doesn't hurt as much as the sleep interval is 0.05
seconds so, only the slower runs in the gate/dev box will be affected.

Closes-Bug: #1552404

Co-Authored-By: Nikhil Komawar<nik.komawar@gmail.com>

Change-Id: I80f04f8b6a23c208f9553b398c8f5db05190bebb
(cherry picked from commit 143df036fa2aa1416a6b44e26db48b8eb9ed2f3b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/20/305520/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/integration/v2/test_tasks_api.py'],1,fdfe0776265b602a428cbbc75dfe98bb351d7617,bug/1552404," def _wait_on_task_execution(self, max_wait=5): # wait for maximum of seconds defined by max_wait while timeutils.delta_seconds(start, timeutils.utcnow()) < max_wait: self._wait_on_task_execution(max_wait=10)"," def _wait_on_task_execution(self): # wait for maximum of 5 seconds while timeutils.delta_seconds(start, timeutils.utcnow()) < 5: self._wait_on_task_execution()",4,4
openstack%2Fmanila~stable%2Fmitaka~Ie4724ebaaf73faf9503073f8b2e1152e7562e942,openstack/manila,stable/mitaka,Ie4724ebaaf73faf9503073f8b2e1152e7562e942,Fix manage tempest test validation,MERGED,2016-04-15 13:13:33.000000000,2016-05-05 04:29:40.000000000,2016-05-04 18:52:51.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11865}, {'_account_id': 13144}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 21059}]","[{'number': 1, 'created': '2016-04-15 13:13:33.000000000', 'files': ['manila_tempest_tests/tests/api/admin/test_share_manage.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/1e23ad1a93cef7848f3df8c3272389830f1398c2', 'message': ""Fix manage tempest test validation\n\nBackporting this change to complement previous backport commit.\nOriginal description below:\n\nTempest test test_manage_with_type_invalid always passes\nbecause if scheduler mistakenly accept the share type and\nhost combination, manage operation will fail in the backend\nand test would assume it failed for the correct reason.\n\nPart of the fix is ensuring share being managed exists, so\nstatus becomes 'available' if scheduler accepts the share.\nSince this test, which is originally a negative test, requires\nthe resource in the backend to exist and be cleaned up, share needs\nto properly be managed again to be deleted. This is exactly what\nanother separate test does. Originally both test cases were merged\nin a single tempest test, possibly for this purpose, so this change\naddresses the bug by merging them back.\n\n(cherry-picked from commit a909f233b6bb8b48457ce952a1e17c8274feeeb5)\nCloses-bug: #1564505\n\nChange-Id: Ie4724ebaaf73faf9503073f8b2e1152e7562e942\n""}]",0,306414,1e23ad1a93cef7848f3df8c3272389830f1398c2,21,9,1,14567,,,0,"Fix manage tempest test validation

Backporting this change to complement previous backport commit.
Original description below:

Tempest test test_manage_with_type_invalid always passes
because if scheduler mistakenly accept the share type and
host combination, manage operation will fail in the backend
and test would assume it failed for the correct reason.

Part of the fix is ensuring share being managed exists, so
status becomes 'available' if scheduler accepts the share.
Since this test, which is originally a negative test, requires
the resource in the backend to exist and be cleaned up, share needs
to properly be managed again to be deleted. This is exactly what
another separate test does. Originally both test cases were merged
in a single tempest test, possibly for this purpose, so this change
addresses the bug by merging them back.

(cherry-picked from commit a909f233b6bb8b48457ce952a1e17c8274feeeb5)
Closes-bug: #1564505

Change-Id: Ie4724ebaaf73faf9503073f8b2e1152e7562e942
",git fetch https://review.opendev.org/openstack/manila refs/changes/14/306414/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/admin/test_share_manage.py'],1,1e23ad1a93cef7848f3df8c3272389830f1398c2,backport/manila/mitaka," def test_manage_invalid(self): # Try to manage share with invalid parameters, it should not succeed # because the scheduler will reject it. If it succeeds, then this test # case failed. Then, in order to remove the resource from backend, we # need to manage it again, properly, so we can delete it. Consequently # the second part of this test also tests that manage operation with a # proper share type works. def _delete_share(share_id): self.shares_v2_client.reset_state(share_id) self.shares_v2_client.delete_share(share_id) self.shares_v2_client.wait_for_resource_deletion(share_id=share_id) self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share, share_id) self.addCleanup(_delete_share, share['id']) self.shares_v2_client.wait_for_share_status( share['id'], 'manage_error') # Delete resource from backend. We need to manage the share properly # so it can be removed. self.addCleanup(_delete_share, share['id']) self.shares_v2_client.wait_for_share_status( share['id'], 'available')"," def test_manage_with_type_invalid(self): # Manage share with invalid type # Wait for failure self.shares_v2_client.wait_for_share_status(share['id'], 'manage_error') # Delete share self.shares_v2_client.reset_state(share['id']) self.shares_v2_client.delete_share(share['id']) self.shares_v2_client.wait_for_resource_deletion(share_id=share['id']) self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share, share['id']) @test.attr(type=[""gate"", ""smoke"", ]) def test_manage_with_type(self): # Manage share with type # Wait for success self.shares_v2_client.wait_for_share_status(share['id'], 'available') # Delete share self.shares_v2_client.delete_share(share['id']) self.shares_v2_client.wait_for_resource_deletion(share_id=share['id']) self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share, share['id'])",23,24
openstack%2Fmanila~stable%2Fmitaka~If9960d22a63c3db30179c7a4ce5b805cef983b73,openstack/manila,stable/mitaka,If9960d22a63c3db30179c7a4ce5b805cef983b73,Fix Manage API synchronous call,MERGED,2016-04-15 13:13:33.000000000,2016-05-05 04:02:44.000000000,2016-05-04 18:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 11865}, {'_account_id': 13144}, {'_account_id': 16643}, {'_account_id': 21059}]","[{'number': 1, 'created': '2016-04-15 13:13:33.000000000', 'files': ['manila/tests/api/v1/test_share_manage.py', 'manila/db/api.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/tests/scheduler/test_rpcapi.py', 'manila/api/v1/share_manage.py', 'manila/scheduler/rpcapi.py', 'manila_tempest_tests/tests/api/admin/test_share_manage.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/3eaf9bf23b1aaaadba4ea36b3f26cf1f8ec7b19f', 'message': 'Fix Manage API synchronous call\n\nBackporting this to stable/mitaka to fix improper behavior\nof manage API.\n\nOriginal description below:\n\nRPCAPI call to Scheduler to perform share_type and host\nvalidation should be asynchronous so share can be\ncreated in DB with status ""manage_error"" if validation\nis not successful.\n\nThis change also addresses incorrect exception type in API\nand DB popping fields from supplied parameter.\n\nAPIImpact\n\n(cherry-picked from commit 165b03e02102e7ab760ccb7f9bb24ff771d4b408)\nCloses-bug: #1561139\nChange-Id: If9960d22a63c3db30179c7a4ce5b805cef983b73\n'}]",0,306413,3eaf9bf23b1aaaadba4ea36b3f26cf1f8ec7b19f,20,7,1,14567,,,0,"Fix Manage API synchronous call

Backporting this to stable/mitaka to fix improper behavior
of manage API.

Original description below:

RPCAPI call to Scheduler to perform share_type and host
validation should be asynchronous so share can be
created in DB with status ""manage_error"" if validation
is not successful.

This change also addresses incorrect exception type in API
and DB popping fields from supplied parameter.

APIImpact

(cherry-picked from commit 165b03e02102e7ab760ccb7f9bb24ff771d4b408)
Closes-bug: #1561139
Change-Id: If9960d22a63c3db30179c7a4ce5b805cef983b73
",git fetch https://review.opendev.org/openstack/manila refs/changes/13/306413/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/api/v1/test_share_manage.py', 'manila/db/api.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/tests/scheduler/test_rpcapi.py', 'manila/api/v1/share_manage.py', 'manila/scheduler/rpcapi.py', 'manila_tempest_tests/tests/api/admin/test_share_manage.py']",10,3eaf9bf23b1aaaadba4ea36b3f26cf1f8ec7b19f,backport/manila/mitaka," @test.attr(type=[""gate"", ""smoke"", ""negative"", ]) def test_manage_with_type_invalid(self): # Manage share with invalid type share = self.shares_v2_client.manage_share( # Wait for failure self.shares_v2_client.wait_for_share_status(share['id'], 'manage_error') # Delete share self.shares_v2_client.reset_state(share['id']) self.shares_v2_client.delete_share(share['id']) self.shares_v2_client.wait_for_resource_deletion(share_id=share['id']) self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share, share['id']) @test.attr(type=[""gate"", ""smoke"", ]) def test_manage_with_type(self): # Manage share with type # Wait for success self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share,"," @test.attr(type=[""gate"", ""smoke""]) def test_manage_retry(self): # Manage share with invalid parameters self.assertRaises( lib_exc.Conflict, self.shares_v2_client.manage_share, self.assertRaises(lib_exc.NotFound, self.shares_v2_client.get_share,",99,85
openstack%2Fswift-specs~master~I8ce40b4466bfa1ffa5cf525c21b97f35c10691a3,openstack/swift-specs,master,I8ce40b4466bfa1ffa5cf525c21b97f35c10691a3,because spelng is hard,MERGED,2016-05-05 03:57:43.000000000,2016-05-05 04:02:02.000000000,2016-05-05 04:02:02.000000000,"[{'_account_id': 3}, {'_account_id': 330}]","[{'number': 1, 'created': '2016-05-05 03:57:43.000000000', 'files': ['doc/source/index.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/c01a9b684e3d8bec85349d843a1c049f4c6da2e4', 'message': 'because spelng is hard\n\nChange-Id: I8ce40b4466bfa1ffa5cf525c21b97f35c10691a3\n'}]",0,312819,c01a9b684e3d8bec85349d843a1c049f4c6da2e4,6,2,1,330,,,0,"because spelng is hard

Change-Id: I8ce40b4466bfa1ffa5cf525c21b97f35c10691a3
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/19/312819/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'README.rst']",2,c01a9b684e3d8bec85349d843a1c049f4c6da2e4,,"necessarily a formal design for a feature, nor are they docs for a","necissarily a formal design for a feature, nor are they docs for a",2,2
openstack%2Fswift-specs~master~Ief1e07441dabb1b8c9b57d8b5e55e38ea8d8cefd,openstack/swift-specs,master,Ief1e07441dabb1b8c9b57d8b5e55e38ea8d8cefd,Killing specs,MERGED,2016-05-04 23:01:49.000000000,2016-05-05 03:55:48.000000000,2016-05-05 03:55:48.000000000,"[{'_account_id': 3}, {'_account_id': 330}]","[{'number': 1, 'created': '2016-05-04 23:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/9af92153954afe8d67a445390f3bf9707e0ac60b', 'message': 'Killing specs\n\nFuture ideas should be referenced on\nhttps://wiki.openstack.org/wiki/Swift/ideas\n\nChange-Id: Ief1e07441dabb1b8c9b57d8b5e55e38ea8d8cefd\n'}, {'number': 2, 'created': '2016-05-05 03:49:30.000000000', 'files': ['doc/source/index.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/fc4a8b24dc2d32cfdf274871d434abb4c2a60af8', 'message': 'Killing specs\n\nFuture ideas should be referenced on\nhttps://wiki.openstack.org/wiki/Swift/ideas\n\nChange-Id: Ief1e07441dabb1b8c9b57d8b5e55e38ea8d8cefd\n'}]",0,312778,fc4a8b24dc2d32cfdf274871d434abb4c2a60af8,9,2,2,330,,,0,"Killing specs

Future ideas should be referenced on
https://wiki.openstack.org/wiki/Swift/ideas

Change-Id: Ief1e07441dabb1b8c9b57d8b5e55e38ea8d8cefd
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/78/312778/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'README.rst']",2,9af92153954afe8d67a445390f3bf9707e0ac60b,hes_dead_jim,This archive is no longer active. Content is kept for historic purposes. ======================================================================== ,,7,0
openstack%2Fxstatic-d3~master~If5ec57706d257fd5bf65d2d66c69d5e48934694f,openstack/xstatic-d3,master,If5ec57706d257fd5bf65d2d66c69d5e48934694f,Update XStatic-D3 to 3.5.16,MERGED,2016-04-20 18:44:30.000000000,2016-05-05 03:55:21.000000000,2016-05-05 03:55:21.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7665}, {'_account_id': 11778}]","[{'number': 1, 'created': '2016-04-20 18:44:30.000000000', 'files': ['xstatic/pkg/d3/__init__.py', 'xstatic/pkg/d3/data/d3.js'], 'web_link': 'https://opendev.org/openstack/xstatic-d3/commit/2e19ec3d42cf49a5973f5157422184f1a34fad90', 'message': 'Update XStatic-D3 to 3.5.16\n\nChange-Id: If5ec57706d257fd5bf65d2d66c69d5e48934694f\n'}]",0,308523,2e19ec3d42cf49a5973f5157422184f1a34fad90,8,4,1,12826,,,0,"Update XStatic-D3 to 3.5.16

Change-Id: If5ec57706d257fd5bf65d2d66c69d5e48934694f
",git fetch https://review.opendev.org/openstack/xstatic-d3 refs/changes/23/308523/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/d3/__init__.py', 'xstatic/pkg/d3/data/d3.js']",2,2e19ec3d42cf49a5973f5157422184f1a34fad90,update-to-v3.5.16,"!function() { var d3 = { version: ""3.5.16"" var d3_arraySlice = [].slice, d3_array = function(list) { return d3_arraySlice.call(list); }; var d3_document = this.document; function d3_documentElement(node) { return node && (node.ownerDocument || node.document || node).documentElement; } function d3_window(node) { return node && (node.ownerDocument && node.ownerDocument.defaultView || node.document && node || node.defaultView); } if (d3_document) { try { d3_array(d3_document.documentElement.childNodes)[0].nodeType; } catch (e) { d3_array = function(list) { var i = list.length, array = new Array(i); while (i--) array[i] = list[i]; return array; }; } } if (d3_document) { try { d3_document.createElement(""DIV"").style.setProperty(""opacity"", 0, """"); } catch (error) { var d3_element_prototype = this.Element.prototype, d3_element_setAttribute = d3_element_prototype.setAttribute, d3_element_setAttributeNS = d3_element_prototype.setAttributeNS, d3_style_prototype = this.CSSStyleDeclaration.prototype, d3_style_setProperty = d3_style_prototype.setProperty; d3_element_prototype.setAttribute = function(name, value) { d3_element_setAttribute.call(this, name, value + """"); }; d3_element_prototype.setAttributeNS = function(space, local, value) { d3_element_setAttributeNS.call(this, space, local, value + """"); }; d3_style_prototype.setProperty = function(name, value, priority) { d3_style_setProperty.call(this, name, value + """", priority); }; } } d3.ascending = d3_ascending; function d3_ascending(a, b) { } while (++i < n) if ((b = array[i]) != null && b >= b) { a = b; break; } while (++i < n) if ((b = f.call(array, array[i], i)) != null && b >= b) { a = b; break; } while (++i < n) if ((b = array[i]) != null && b >= b) { a = b; break; } while (++i < n) if ((b = f.call(array, array[i], i)) != null && b >= b) { a = b; break; } while (++i < n) if ((b = array[i]) != null && b >= b) { a = c = b; break; } while (++i < n) if ((b = f.call(array, array[i], i)) != null && b >= b) { a = c = b; break; } function d3_number(x) { return x === null ? NaN : +x; } function d3_numeric(x) { return !isNaN(x); } while (++i < n) if (d3_numeric(a = +array[i])) s += a; } else { while (++i < n) if (d3_numeric(a = +f.call(array, array[i], i))) s += a; d3.mean = function(array, f) { var s = 0, n = array.length, a, i = -1, j = n; if (arguments.length === 1) { while (++i < n) if (d3_numeric(a = d3_number(array[i]))) s += a; else --j; } else { while (++i < n) if (d3_numeric(a = d3_number(f.call(array, array[i], i)))) s += a; else --j; } if (j) return s / j; var numbers = [], n = array.length, a, i = -1; if (arguments.length === 1) { while (++i < n) if (d3_numeric(a = d3_number(array[i]))) numbers.push(a); } else { while (++i < n) if (d3_numeric(a = d3_number(f.call(array, array[i], i)))) numbers.push(a); } if (numbers.length) return d3.quantile(numbers.sort(d3_ascending), .5); d3.variance = function(array, f) { var n = array.length, m = 0, a, d, s = 0, i = -1, j = 0; if (arguments.length === 1) { while (++i < n) { if (d3_numeric(a = d3_number(array[i]))) { d = a - m; m += d / ++j; s += d * (a - m); } } } else { while (++i < n) { if (d3_numeric(a = d3_number(f.call(array, array[i], i)))) { d = a - m; m += d / ++j; s += d * (a - m); } } } if (j > 1) return s / (j - 1); }; d3.deviation = function() { var v = d3.variance.apply(this, arguments); return v ? Math.sqrt(v) : v; }; function d3_bisector(compare) { if (compare(a[mid], x) < 0) lo = mid + 1; else hi = mid; if (compare(a[mid], x) > 0) hi = mid; else lo = mid + 1; } var d3_bisect = d3_bisector(d3_ascending); d3.bisectLeft = d3_bisect.left; d3.bisect = d3.bisectRight = d3_bisect.right; d3.bisector = function(f) { return d3_bisector(f.length === 1 ? function(d, x) { return d3_ascending(f(d), x); } : f); d3.shuffle = function(array, i0, i1) { if ((m = arguments.length) < 3) { i1 = array.length; if (m < 2) i0 = 0; } var m = i1 - i0, t, i; t = array[m + i0], array[m + i0] = array[i + i0], array[i + i0] = t; var i = indexes.length, permutes = new Array(i); while (i--) permutes[i] = array[indexes[i]]; d3.pairs = function(array) { var i = 0, n = array.length - 1, p0, p1 = array[0], pairs = new Array(n < 0 ? 0 : n); while (i < n) pairs[i] = [ p0 = p1, p1 = array[++i] ]; return pairs; }; d3.transpose = function(matrix) { if (!(n = matrix.length)) return []; for (var i = -1, m = d3.min(matrix, d3_transposeLength), transpose = new Array(m); ++i < m; ) { for (var j = -1, n, row = transpose[i] = new Array(n); ++j < n; ) { row[j] = matrix[j][i]; } } return transpose; function d3_transposeLength(d) { d3.zip = function() { return d3.transpose(arguments); var n = arrays.length, m, i = -1, j = 0, merged, array; while (++i < n) j += arrays[i].length; merged = new Array(j); while (--n >= 0) { array = arrays[n]; m = array.length; while (--m >= 0) { merged[--j] = array[m]; } } return merged; var abs = Math.abs; var range = [], k = d3_range_integerScale(abs(step)), i = -1, j; for (var key in properties) { Object.defineProperty(ctor.prototype, key, { value: properties[key], enumerable: false }); } } d3.map = function(object, f) { if (object instanceof d3_Map) { object.forEach(function(key, value) { map.set(key, value); }); } else if (Array.isArray(object)) { var i = -1, n = object.length, o; if (arguments.length === 1) while (++i < n) map.set(i, object[i]); else while (++i < n) map.set(f.call(object, o = object[i], i), o); } else { for (var key in object) map.set(key, object[key]); } function d3_Map() { this._ = Object.create(null); } var d3_map_proto = ""__proto__"", d3_map_zero = ""\x00""; d3_class(d3_Map, { has: d3_map_has, get: function(key) { return this._[d3_map_escape(key)]; return this._[d3_map_escape(key)] = value; remove: d3_map_remove, keys: d3_map_keys, for (var key in this._) values.push(this._[key]); for (var key in this._) entries.push({ key: d3_map_unescape(key), value: this._[key] size: d3_map_size, empty: d3_map_empty, forEach: function(f) { for (var key in this._) f.call(this, d3_map_unescape(key), this._[key]); function d3_map_escape(key) { return (key += """") === d3_map_proto || key[0] === d3_map_zero ? d3_map_zero + key : key; } function d3_map_unescape(key) { return (key += """")[0] === d3_map_zero ? key.slice(1) : key; } function d3_map_has(key) { return d3_map_escape(key) in this._; } function d3_map_remove(key) { return (key = d3_map_escape(key)) in this._ && delete this._[key]; } function d3_map_keys() { var keys = []; for (var key in this._) keys.push(d3_map_unescape(key)); return keys; } function d3_map_size() { var size = 0; for (var key in this._) ++size; return size; } function d3_map_empty() { for (var key in this._) return false; return true; } if (array) for (var i = 0, n = array.length; i < n; ++i) set.add(array[i]); function d3_Set() { this._ = Object.create(null); } d3_class(d3_Set, { has: d3_map_has, add: function(key) { this._[d3_map_escape(key += """")] = true; return key; remove: d3_map_remove, values: d3_map_keys, size: d3_map_size, empty: d3_map_empty, forEach: function(f) { for (var key in this._) f.call(this, d3_map_unescape(key)); function d3_identity(d) { return d; } function d3_vendorSymbol(object, name) { if (name in object) return name; name = name.charAt(0).toUpperCase() + name.slice(1); for (var i = 0, n = d3_vendorPrefixes.length; i < n; ++i) { var prefixName = d3_vendorPrefixes[i] + name; if (prefixName in object) return prefixName; } } var d3_vendorPrefixes = [ ""webkit"", ""ms"", ""moz"", ""Moz"", ""o"", ""O"" ]; function d3_noop() {} name = type.slice(i + 1); type = type.slice(0, i); function d3_eventPreventDefault() { d3.requote = function(s) { return s.replace(d3_requote_re, ""\\$&""); var d3_requote_re = /[\\\^\$\*\+\?\|\[\]\(\)\.\{\}]/g; var d3_subclass = {}.__proto__ ? function(object, prototype) { object.__proto__ = prototype; } : function(object, prototype) { for (var property in prototype) object[property] = prototype[property]; d3_subclass(groups, d3_selectionPrototype); }, d3_selectMatches = function(n, s) { var d3_selectMatcher = n.matches || n[d3_vendorSymbol(n, ""matchesSelector"")]; d3_selectMatches = function(n, s) { return d3_selectMatcher.call(n, s); }; return d3_selectMatches(n, s); d3_selectAll = Sizzle; return d3.select(d3_document.documentElement); selector = d3_selection_selector(selector); subgroup.push(subnode = selector.call(node, node.__data__, i, j)); return typeof selector === ""function"" ? selector : function() { selector = d3_selection_selectorAll(selector); subgroups.push(subgroup = d3_array(selector.call(node, node.__data__, i, j))); return typeof selector === ""function"" ? selector : function() { var d3_nsXhtml = ""http://www.w3.org/1999/xhtml""; xhtml: d3_nsXhtml, if (i >= 0 && (prefix = name.slice(0, i)) !== ""xmlns"") name = name.slice(i + 1); var node = this.node(), n = (name = d3_selection_classes(name)).length, i = -1; function d3_selection_classes(name) { return (name + """").trim().split(/^|\s+/); } function d3_selection_classed(name, value) { name = d3_selection_classes(name).map(d3_selection_classedName); if (n < 2) { var node = this.node(); return d3_window(node).getComputedStyle(node, null).getPropertyValue(name); } name = d3_selection_creator(name); return this.select(function() { return this.appendChild(name.apply(this, arguments)); function d3_selection_creator(name) { function create() { var document = this.ownerDocument, namespace = this.namespaceURI; return namespace === d3_nsXhtml && document.documentElement.namespaceURI === d3_nsXhtml ? document.createElement(name) : document.createElementNS(namespace, name); } function createNS() { return this.ownerDocument.createElementNS(name.space, name.local); } return typeof name === ""function"" ? name : (name = d3.ns.qualify(name)).local ? createNS : create; } d3_selectionPrototype.insert = function(name, before) { name = d3_selection_creator(name); before = d3_selection_selector(before); return this.select(function() { return this.insertBefore(name.apply(this, arguments), before.apply(this, arguments) || null); }); }; d3_selectionPrototype.remove = function() { return this.each(d3_selectionRemove); }; function d3_selectionRemove() { var parent = this.parentNode; if (parent) parent.removeChild(this); } var nodeByKeyValue = new d3_Map(), keyValues = new Array(n), keyValue; for (i = -1; ++i < n; ) { if (node = group[i]) { if (nodeByKeyValue.has(keyValue = key.call(node, node.__data__, i))) { exitNodes[i] = node; } else { nodeByKeyValue.set(keyValue, node); } keyValues[i] = keyValue; } if (!(node = nodeByKeyValue.get(keyValue = key.call(groupData, nodeData = groupData[i], i)))) { enterNodes[i] = d3_selection_dataNode(nodeData); } else if (node !== true) { } nodeByKeyValue.set(keyValue, true); if (i in keyValues && nodeByKeyValue.get(keyValues[i]) !== true) { if ((node = group[i]) && filter.call(node, node.__data__, i, j)) { if (!arguments.length) comparator = d3_ascending; return function(a, b) { return a && b ? comparator(a.__data__, b.__data__) : !a - !b; d3_selectionPrototype.size = function() { var n = 0; d3_selection_each(this, function() { ++n; }); return n; }; function d3_selection_enter(selection) { d3_subclass(selection, d3_selection_enterPrototype); d3_selection_enterPrototype.call = d3_selectionPrototype.call; d3_selection_enterPrototype.size = d3_selectionPrototype.size; subgroup.push(upgroup[i] = subnode = selector.call(group.parentNode, node.__data__, i, j)); d3_selection_enterPrototype.insert = function(name, before) { if (arguments.length < 2) before = d3_selection_enterInsertBefore(this); return d3_selectionPrototype.insert.call(this, name, before); function d3_selection_enterInsertBefore(enter) { var i0, j0; return function(d, i, j) { var group = enter[j].update, n = group.length, node; if (j != j0) j0 = j, i0 = 0; if (i >= i0) i0 = i + 1; while (!(node = group[i0]) && ++i0 < n) ; return node; }; } d3.select = function(node) { var group; if (typeof node === ""string"") { group = [ d3_select(node, d3_document) ]; group.parentNode = d3_document.documentElement; } else { group = [ node ]; group.parentNode = d3_documentElement(node); } var group; if (typeof nodes === ""string"") { group = d3_array(d3_selectAll(nodes, d3_document)); group.parentNode = d3_document.documentElement; } else { group = d3_array(nodes); group.parentNode = null; } d3_selectionPrototype.on = function(type, listener, capture) { var n = arguments.length; if (n < 3) { if (typeof type !== ""string"") { if (n < 2) listener = false; for (capture in type) this.each(d3_selection_on(capture, type[capture], listener)); return this; } if (n < 2) return (n = this.node()[""__on"" + type]) && n._; capture = false; } return this.each(d3_selection_on(type, listener, capture)); }; function d3_selection_on(type, listener, capture) { var name = ""__on"" + type, i = type.indexOf("".""), wrap = d3_selection_onListener; if (i > 0) type = type.slice(0, i); var filter = d3_selection_onFilters.get(type); if (filter) type = filter, wrap = d3_selection_onFilter; function onRemove() { var l = this[name]; if (l) { this.removeEventListener(type, l, l.$); delete this[name]; } } function onAdd() { var l = wrap(listener, d3_array(arguments)); onRemove.call(this); this.addEventListener(type, this[name] = l, l.$ = capture); l._ = listener; } function removeAll() { var re = new RegExp(""^__on([^.]+)"" + d3.requote(type) + ""$""), match; for (var name in this) { if (match = name.match(re)) { var l = this[name]; this.removeEventListener(match[1], l, l.$); delete this[name]; } } } return i ? listener ? onAdd : onRemove : listener ? d3_noop : removeAll; } var d3_selection_onFilters = d3.map({ mouseenter: ""mouseover"", mouseleave: ""mouseout"" }); if (d3_document) { d3_selection_onFilters.forEach(function(k) { if (""on"" + k in d3_document) d3_selection_onFilters.remove(k); }); } function d3_selection_onListener(listener, argumentz) { return function(e) { var o = d3.event; d3.event = e; argumentz[0] = this.__data__; try { listener.apply(this, argumentz); } finally { d3.event = o; } }; } function d3_selection_onFilter(listener, argumentz) { var l = d3_selection_onListener(listener, argumentz); return function(e) { var target = this, related = e.relatedTarget; if (!related || related !== target && !(related.compareDocumentPosition(target) & 8)) { l.call(target, e); } }; } var d3_event_dragSelect, d3_event_dragId = 0; function d3_event_dragSuppress(node) { var name = "".dragsuppress-"" + ++d3_event_dragId, click = ""click"" + name, w = d3.select(d3_window(node)).on(""touchmove"" + name, d3_eventPreventDefault).on(""dragstart"" + name, d3_eventPreventDefault).on(""selectstart"" + name, d3_eventPreventDefault); if (d3_event_dragSelect == null) { d3_event_dragSelect = ""onselectstart"" in node ? false : d3_vendorSymbol(node.style, ""userSelect""); } if (d3_event_dragSelect) { var style = d3_documentElement(node).style, select = style[d3_event_dragSelect]; style[d3_event_dragSelect] = ""none""; } return function(suppressClick) { w.on(name, null); if (d3_event_dragSelect) style[d3_event_dragSelect] = select; if (suppressClick) { var off = function() { w.on(click, null); }; w.on(click, function() { d3_eventPreventDefault(); off(); }, true); setTimeout(off, 0); } }; } d3.mouse = function(container) { return d3_mousePoint(container, d3_eventSource()); }; var d3_mouse_bug44083 = this.navigator && /WebKit/.test(this.navigator.userAgent) ? -1 : 0; function d3_mousePoint(container, e) { if (e.changedTouches) e = e.changedTouches[0]; var svg = container.ownerSVGElement || container; if (svg.createSVGPoint) { var point = svg.createSVGPoint(); if (d3_mouse_bug44083 < 0) { var window = d3_window(container); if (window.scrollX || window.scrollY) { svg = d3.select(""body"").append(""svg"").style({ position: ""absolute"", top: 0, left: 0, margin: 0, padding: 0, border: ""none"" }, ""important""); var ctm = svg[0][0].getScreenCTM(); d3_mouse_bug44083 = !(ctm.f || ctm.e); svg.remove(); } } if (d3_mouse_bug44083) point.x = e.pageX, point.y = e.pageY; else point.x = e.clientX, point.y = e.clientY; point = point.matrixTransform(container.getScreenCTM().inverse()); return [ point.x, point.y ]; } var rect = container.getBoundingClientRect(); return [ e.clientX - rect.left - container.clientLeft, e.clientY - rect.top - container.clientTop ]; } d3.touch = function(container, touches, identifier) { if (arguments.length < 3) identifier = touches, touches = d3_eventSource().changedTouches; if (touches) for (var i = 0, n = touches.length, touch; i < n; ++i) { if ((touch = touches[i]).identifier === identifier) { return d3_mousePoint(container, touch); } } }; d3.behavior.drag = function() { var event = d3_eventDispatch(drag, ""drag"", ""dragstart"", ""dragend""), origin = null, mousedown = dragstart(d3_noop, d3.mouse, d3_window, ""mousemove"", ""mouseup""), touchstart = dragstart(d3_behavior_dragTouchId, d3.touch, d3_identity, ""touchmove"", ""touchend""); function drag() { this.on(""mousedown.drag"", mousedown).on(""touchstart.drag"", touchstart); } function dragstart(id, position, subject, move, end) { return function() { var that = this, target = d3.event.target.correspondingElement || d3.event.target, parent = that.parentNode, dispatch = event.of(that, arguments), dragged = 0, dragId = id(), dragName = "".drag"" + (dragId == null ? """" : ""-"" + dragId), dragOffset, dragSubject = d3.select(subject(target)).on(move + dragName, moved).on(end + dragName, ended), dragRestore = d3_event_dragSuppress(target), position0 = position(parent, dragId); if (origin) { dragOffset = origin.apply(that, arguments); dragOffset = [ dragOffset.x - position0[0], dragOffset.y - position0[1] ]; } else { dragOffset = [ 0, 0 ]; } dispatch({ type: ""dragstart"" }); function moved() { var position1 = position(parent, dragId), dx, dy; if (!position1) return; dx = position1[0] - position0[0]; dy = position1[1] - position0[1]; dragged |= dx | dy; position0 = position1; dispatch({ type: ""drag"", x: position1[0] + dragOffset[0], y: position1[1] + dragOffset[1], dx: dx, dy: dy }); } function ended() { if (!position(parent, dragId)) return; dragSubject.on(move + dragName, null).on(end + dragName, null); dragRestore(dragged); dispatch({ type: ""dragend"" }); } }; } drag.origin = function(x) { if (!arguments.length) return origin; origin = x; return drag; }; return d3.rebind(drag, event, ""on""); }; function d3_behavior_dragTouchId() { return d3.event.changedTouches[0].identifier; } d3.touches = function(container, touches) { if (arguments.length < 2) touches = d3_eventSource().touches; return touches ? d3_array(touches).map(function(touch) { var point = d3_mousePoint(container, touch); point.identifier = touch.identifier; return point; }) : []; }; var  = 1e-6, 2 =  * ,  = Math.PI,  = 2 * ,  =  - , half =  / 2, d3_radians =  / 180, d3_degrees = 180 / ; function d3_sgn(x) { return x > 0 ? 1 : x < 0 ? -1 : 0; } function d3_cross2d(a, b, c) { return (b[0] - a[0]) * (c[1] - a[1]) - (b[1] - a[1]) * (c[0] - a[0]); } function d3_acos(x) { return x > 1 ? 0 : x < -1 ?  : Math.acos(x); } function d3_asin(x) { return x > 1 ? half : x < -1 ? -half : Math.asin(x); } function d3_sinh(x) { return ((x = Math.exp(x)) - 1 / x) / 2; } function d3_cosh(x) { return ((x = Math.exp(x)) + 1 / x) / 2; } function d3_tanh(x) { return ((x = Math.exp(2 * x)) - 1) / (x + 1); } function d3_haversin(x) { return (x = Math.sin(x / 2)) * x; } var  = Math.SQRT2, 2 = 2, 4 = 4; d3.interpolateZoom = function(p0, p1) { var ux0 = p0[0], uy0 = p0[1], w0 = p0[2], ux1 = p1[0], uy1 = p1[1], w1 = p1[2], dx = ux1 - ux0, dy = uy1 - uy0, d2 = dx * dx + dy * dy, i, S; if (d2 < 2) { S = Math.log(w1 / w0) / ; i = function(t) { return [ ux0 + t * dx, uy0 + t * dy, w0 * Math.exp( * t * S) ]; }; } else { var d1 = Math.sqrt(d2), b0 = (w1 * w1 - w0 * w0 + 4 * d2) / (2 * w0 * 2 * d1), b1 = (w1 * w1 - w0 * w0 - 4 * d2) / (2 * w1 * 2 * d1), r0 = Math.log(Math.sqrt(b0 * b0 + 1) - b0), r1 = Math.log(Math.sqrt(b1 * b1 + 1) - b1); S = (r1 - r0) / ; i = function(t) { var s = t * S, coshr0 = d3_cosh(r0), u = w0 / (2 * d1) * (coshr0 * d3_tanh( * s + r0) - d3_sinh(r0)); return [ ux0 + u * dx, uy0 + u * dy, w0 * coshr0 / d3_cosh( * s + r0) ]; }; } i.duration = S * 1e3; return i; }; d3.behavior.zoom = function() { var view = { x: 0, y: 0, k: 1 }, translate0, center0, center, size = [ 960, 500 ], scaleExtent = d3_behavior_zoomInfinity, duration = 250, zooming = 0, mousedown = ""mousedown.zoom"", mousemove = ""mousemove.zoom"", mouseup = ""mouseup.zoom"", mousewheelTimer, touchstart = ""touchstart.zoom"", touchtime, event = d3_eventDispatch(zoom, ""zoomstart"", ""zoom"", ""zoomend""), x0, x1, y0, y1; if (!d3_behavior_zoomWheel) { d3_behavior_zoomWheel = ""onwheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return -d3.event.deltaY * (d3.event.deltaMode ? 120 : 1); }, ""wheel"") : ""onmousewheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return d3.event.wheelDelta; }, ""mousewheel"") : (d3_behavior_zoomDelta = function() { return -d3.event.detail; }, ""MozMousePixelScroll""); } function zoom(g) { g.on(mousedown, mousedowned).on(d3_behavior_zoomWheel + "".zoom"", mousewheeled).on(""dblclick.zoom"", dblclicked).on(touchstart, touchstarted); } zoom.event = function(g) { g.each(function() { var dispatch = event.of(this, arguments), view1 = view; if (d3_transitionInheritId) { d3.select(this).transition().each(""start.zoom"", function() { view = this.__chart__ || { x: 0, y: 0, k: 1 }; zoomstarted(dispatch); }).tween(""zoom:zoom"", function() { var dx = size[0], dy = size[1], cx = center0 ? center0[0] : dx / 2, cy = center0 ? center0[1] : dy / 2, i = d3.interpolateZoom([ (cx - view.x) / view.k, (cy - view.y) / view.k, dx / view.k ], [ (cx - view1.x) / view1.k, (cy - view1.y) / view1.k, dx / view1.k ]); return function(t) { var l = i(t), k = dx / l[2]; this.__chart__ = view = { x: cx - l[0] * k, y: cy - l[1] * k, k: k }; zoomed(dispatch); }; }).each(""interrupt.zoom"", function() { zoomended(dispatch); }).each(""end.zoom"", function() { zoomended(dispatch); }); } else { this.__chart__ = view; zoomstarted(dispatch); zoomed(dispatch); zoomended(dispatch); } }); }; zoom.translate = function(_) { if (!arguments.length) return [ view.x, view.y ]; view = { x: +_[0], y: +_[1], k: view.k }; zoom.scale = function(_) { if (!arguments.length) return view.k; view = { x: view.x, y: view.y, k: null }; scaleTo(+_); zoom.scaleExtent = function(_) { scaleExtent = _ == null ? d3_behavior_zoomInfinity : [ +_[0], +_[1] ]; return zoom; }; zoom.center = function(_) { if (!arguments.length) return center; center = _ && [ +_[0], +_[1] ]; return zoom; }; zoom.size = function(_) { if (!arguments.length) return size; size = _ && [ +_[0], +_[1] ]; return zoom; }; zoom.duration = function(_) { if (!arguments.length) return duration; duration = +_; view = { x: 0, y: 0, k: 1 }; view = { x: 0, y: 0, k: 1 }; return [ (p[0] - view.x) / view.k, (p[1] - view.y) / view.k ]; return [ l[0] * view.k + view.x, l[1] * view.k + view.y ]; view.k = Math.max(scaleExtent[0], Math.min(scaleExtent[1], s)); view.x += p[0] - l[0]; view.y += p[1] - l[1]; } function zoomTo(that, p, l, k) { that.__chart__ = { x: view.x, y: view.y, k: view.k }; scaleTo(Math.pow(2, k)); translateTo(center0 = p, l); that = d3.select(that); if (duration > 0) that = that.transition().duration(duration); that.call(zoom.event); return (x - view.x) / view.k; return (y - view.y) / view.k; function zoomstarted(dispatch) { if (!zooming++) dispatch({ type: ""zoomstart"" }); } function zoomed(dispatch) { dispatch({ scale: view.k, translate: [ view.x, view.y ] function zoomended(dispatch) { if (!--zooming) dispatch({ type: ""zoomend"" }), center0 = null; } function mousedowned() { var that = this, dispatch = event.of(that, arguments), dragged = 0, subject = d3.select(d3_window(that)).on(mousemove, moved).on(mouseup, ended), location0 = location(d3.mouse(that)), dragRestore = d3_event_dragSuppress(that); d3_selection_interrupt.call(that); zoomstarted(dispatch); function moved() { dragged = 1; translateTo(d3.mouse(that), location0); zoomed(dispatch); } function ended() { subject.on(mousemove, null).on(mouseup, null); dragRestore(dragged); zoomended(dispatch); } } function touchstarted() { var that = this, dispatch = event.of(that, arguments), locations0 = {}, distance0 = 0, scale0, zoomName = "".zoom-"" + d3.event.changedTouches[0].identifier, touchmove = ""touchmove"" + zoomName, touchend = ""touchend"" + zoomName, targets = [], subject = d3.select(that), dragRestore = d3_event_dragSuppress(that); started(); zoomstarted(dispatch); subject.on(mousedown, null).on(touchstart, started); function relocate() { var touches = d3.touches(that); scale0 = view.k; touches.forEach(function(t) { if (t.identifier in locations0) locations0[t.identifier] = location(t); }); return touches; } function started() { var target = d3.event.target; d3.select(target).on(touchmove, moved).on(touchend, ended); targets.push(target); var changed = d3.event.changedTouches; for (var i = 0, n = changed.length; i < n; ++i) { locations0[changed[i].identifier] = null; } var touches = relocate(), now = Date.now(); if (touches.length === 1) { if (now - touchtime < 500) { var p = touches[0]; zoomTo(that, p, locations0[p.identifier], Math.floor(Math.log(view.k) / Math.LN2) + 1); d3_eventPreventDefault(); } touchtime = now; } else if (touches.length > 1) { var p = touches[0], q = touches[1], dx = p[0] - q[0], dy = p[1] - q[1]; distance0 = dx * dx + dy * dy; } } function moved() { var touches = d3.touches(that), p0, l0, p1, l1; d3_selection_interrupt.call(that); for (var i = 0, n = touches.length; i < n; ++i, l1 = null) { p1 = touches[i]; if (l1 = locations0[p1.identifier]) { if (l0) break; p0 = p1, l0 = l1; } } if (l1) { var distance1 = (distance1 = p1[0] - p0[0]) * distance1 + (distance1 = p1[1] - p0[1]) * distance1, scale1 = distance0 && Math.sqrt(distance1 / distance0); p0 = [ (p0[0] + p1[0]) / 2, (p0[1] + p1[1]) / 2 ]; l0 = [ (l0[0] + l1[0]) / 2, (l0[1] + l1[1]) / 2 ]; scaleTo(scale1 * scale0); } touchtime = null; translateTo(p0, l0); zoomed(dispatch); } function ended() { if (d3.event.touches.length) { var changed = d3.event.changedTouches; for (var i = 0, n = changed.length; i < n; ++i) { delete locations0[changed[i].identifier]; } for (var identifier in locations0) { return void relocate(); } } d3.selectAll(targets).on(zoomName, null); subject.on(mousedown, mousedowned).on(touchstart, touchstarted); dragRestore(); zoomended(dispatch); } } function mousewheeled() { var dispatch = event.of(this, arguments); if (mousewheelTimer) clearTimeout(mousewheelTimer); else d3_selection_interrupt.call(this), translate0 = location(center0 = center || d3.mouse(this)), zoomstarted(dispatch); mousewheelTimer = setTimeout(function() { mousewheelTimer = null; zoomended(dispatch); }, 50); d3_eventPreventDefault(); scaleTo(Math.pow(2, d3_behavior_zoomDelta() * .002) * view.k); translateTo(center0, translate0); zoomed(dispatch); } function dblclicked() { var p = d3.mouse(this), k = Math.log(view.k) / Math.LN2; zoomTo(this, p, location(p), d3.event.shiftKey ? Math.ceil(k) - 1 : Math.floor(k) + 1); var d3_behavior_zoomInfinity = [ 0, Infinity ], d3_behavior_zoomDelta, d3_behavior_zoomWheel; d3.color = d3_color; function d3_color() {} d3_color.prototype.toString = function() { d3.hsl = d3_hsl; function d3_hsl(h, s, l) { return this instanceof d3_hsl ? void (this.h = +h, this.s = +s, this.l = +l) : arguments.length < 2 ? h instanceof d3_hsl ? new d3_hsl(h.h, h.s, h.l) : d3_rgb_parse("""" + h, d3_rgb_hsl, d3_hsl) : new d3_hsl(h, s, l); } var d3_hslPrototype = d3_hsl.prototype = new d3_color(); return new d3_hsl(this.h, this.s, this.l / k); return new d3_hsl(this.h, this.s, k * this.l); return new d3_rgb(vv(h + 120), vv(h), vv(h - 120)); } d3.hcl = d3_hcl; function d3_hcl(h, c, l) { return this instanceof d3_hcl ? void (this.h = +h, this.c = +c, this.l = +l) : arguments.length < 2 ? h instanceof d3_hcl ? new d3_hcl(h.h, h.c, h.l) : h instanceof d3_lab ? d3_lab_hcl(h.l, h.a, h.b) : d3_lab_hcl((h = d3_rgb_lab((h = d3.rgb(h)).r, h.g, h.b)).l, h.a, h.b) : new d3_hcl(h, c, l); } var d3_hclPrototype = d3_hcl.prototype = new d3_color(); d3_hclPrototype.brighter = function(k) { return new d3_hcl(this.h, this.c, Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1))); return new d3_hcl(this.h, this.c, Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1))); return new d3_lab(l, Math.cos(h *= d3_radians) * c, Math.sin(h) * c); } d3.lab = d3_lab; function d3_lab(l, a, b) { return this instanceof d3_lab ? void (this.l = +l, this.a = +a, this.b = +b) : arguments.length < 2 ? l instanceof d3_lab ? new d3_lab(l.l, l.a, l.b) : l instanceof d3_hcl ? d3_hcl_lab(l.h, l.c, l.l) : d3_rgb_lab((l = d3_rgb(l)).r, l.g, l.b) : new d3_lab(l, a, b); var d3_labPrototype = d3_lab.prototype = new d3_color(); d3_labPrototype.brighter = function(k) { return new d3_lab(Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); return new d3_lab(Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); return new d3_rgb(d3_xyz_rgb(3.2404542 * x - 1.5371385 * y - .4985314 * z), d3_xyz_rgb(-.969266 * x + 1.8760108 * y + .041556 * z), d3_xyz_rgb(.0556434 * x - .2040259 * y + 1.0572252 * z)); return l > 0 ? new d3_hcl(Math.atan2(b, a) * d3_degrees, Math.sqrt(a * a + b * b), l) : new d3_hcl(NaN, NaN, l); d3.rgb = d3_rgb; function d3_rgb(r, g, b) { return this instanceof d3_rgb ? void (this.r = ~~r, this.g = ~~g, this.b = ~~b) : arguments.length < 2 ? r instanceof d3_rgb ? new d3_rgb(r.r, r.g, r.b) : d3_rgb_parse("""" + r, d3_rgb, d3_hsl_rgb) : new d3_rgb(r, g, b); } function d3_rgbNumber(value) { return new d3_rgb(value >> 16, value >> 8 & 255, value & 255); } function d3_rgbString(value) { return d3_rgbNumber(value) + """"; } var d3_rgbPrototype = d3_rgb.prototype = new d3_color(); if (!r && !g && !b) return new d3_rgb(i, i, i); return new d3_rgb(Math.min(255, r / k), Math.min(255, g / k), Math.min(255, b / k)); return new d3_rgb(k * this.r, k * this.g, k * this.b); var r = 0, g = 0, b = 0, m1, m2, color; m1 = /([a-z]+)\((.*)\)/.exec(format = format.toLowerCase()); if (color = d3_rgb_names.get(format)) { return rgb(color.r, color.g, color.b); } if (format != null && format.charAt(0) === ""#"" && !isNaN(color = parseInt(format.slice(1), 16))) { if (format.length === 4) { r = (color & 3840) >> 4; r = r >> 4 | r; g = color & 240; g = g >> 4 | g; b = color & 15; b = b << 4 | b; } else if (format.length === 7) { r = (color & 16711680) >> 16; g = (color & 65280) >> 8; b = color & 255; } return new d3_hsl(h, s, l); aliceblue: 15792383, antiquewhite: 16444375, aqua: 65535, aquamarine: 8388564, azure: 15794175, beige: 16119260, bisque: 16770244, black: 0, blanchedalmond: 16772045, blue: 255, blueviolet: 9055202, brown: 10824234, burlywood: 14596231, cadetblue: 6266528, chartreuse: 8388352, chocolate: 13789470, coral: 16744272, cornflowerblue: 6591981, cornsilk: 16775388, crimson: 14423100, cyan: 65535, darkblue: 139, darkcyan: 35723, darkgoldenrod: 12092939, darkgray: 11119017, darkgreen: 25600, darkgrey: 11119017, darkkhaki: 12433259, darkmagenta: 9109643, darkolivegreen: 5597999, darkorange: 16747520, darkorchid: 10040012, darkred: 9109504, darksalmon: 15308410, darkseagreen: 9419919, darkslateblue: 4734347, darkslategray: 3100495, darkslategrey: 3100495, darkturquoise: 52945, darkviolet: 9699539, deeppink: 16716947, deepskyblue: 49151, dimgray: 6908265, dimgrey: 6908265, dodgerblue: 2003199, firebrick: 11674146, floralwhite: 16775920, forestgreen: 2263842, fuchsia: 16711935, gainsboro: 14474460, ghostwhite: 16316671, gold: 16766720, goldenrod: 14329120, gray: 8421504, green: 32768, greenyellow: 11403055, grey: 8421504, honeydew: 15794160, hotpink: 16738740, indianred: 13458524, indigo: 4915330, ivory: 16777200, khaki: 15787660, lavender: 15132410, lavenderblush: 16773365, lawngreen: 8190976, lemonchiffon: 16775885, lightblue: 11393254, lightcoral: 15761536, lightcyan: 14745599, lightgoldenrodyellow: 16448210, lightgray: 13882323, lightgreen: 9498256, lightgrey: 13882323, lightpink: 16758465, lightsalmon: 16752762, lightseagreen: 2142890, lightskyblue: 8900346, lightslategray: 7833753, lightslategrey: 7833753, lightsteelblue: 11584734, lightyellow: 16777184, lime: 65280, limegreen: 3329330, linen: 16445670, magenta: 16711935, maroon: 8388608, mediumaquamarine: 6737322, mediumblue: 205, mediumorchid: 12211667, mediumpurple: 9662683, mediumseagreen: 3978097, mediumslateblue: 8087790, mediumspringgreen: 64154, mediumturquoise: 4772300, mediumvioletred: 13047173, midnightblue: 1644912, mintcream: 16121850, mistyrose: 16770273, moccasin: 16770229, navajowhite: 16768685, navy: 128, oldlace: 16643558, olive: 8421376, olivedrab: 7048739, orange: 16753920, orangered: 16729344, orchid: 14315734, palegoldenrod: 15657130, palegreen: 10025880, paleturquoise: 11529966, palevioletred: 14381203, papayawhip: 16773077, peachpuff: 16767673, peru: 13468991, pink: 16761035, plum: 14524637, powderblue: 11591910, purple: 8388736, rebeccapurple: 6697881, red: 16711680, rosybrown: 12357519, royalblue: 4286945, saddlebrown: 9127187, salmon: 16416882, sandybrown: 16032864, seagreen: 3050327, seashell: 16774638, sienna: 10506797, silver: 12632256, skyblue: 8900331, slateblue: 6970061, slategray: 7372944, slategrey: 7372944, snow: 16775930, springgreen: 65407, steelblue: 4620980, tan: 13808780, teal: 32896, thistle: 14204888, tomato: 16737095, turquoise: 4251856, violet: 15631086, wheat: 16113331, white: 16777215, whitesmoke: 16119285, yellow: 16776960, yellowgreen: 10145074 d3_rgb_names.set(key, d3_rgbNumber(value)); d3.xhr = d3_xhrType(d3_identity); function d3_xhrType(response) { return function(url, mimeType, callback) { if (arguments.length === 2 && typeof mimeType === ""function"") callback = mimeType, mimeType = null; return d3_xhr(url, mimeType, response, callback); }; } function d3_xhr(url, mimeType, response, callback) { var xhr = {}, dispatch = d3.dispatch(""beforesend"", ""progress"", ""load"", ""error""), headers = {}, request = new XMLHttpRequest(), responseType = null; if (this.XDomainRequest && !(""withCredentials"" in request) && /^(http(s)?:)?\/\//.test(url)) request = new XDomainRequest(); var status = request.status, result; if (!status && d3_xhrHasResponse(request) || status >= 200 && status < 300 || status === 304) { try { result = response.call(xhr, request); } catch (e) { dispatch.error.call(xhr, e); return; } dispatch.load.call(xhr, result); } else { dispatch.error.call(xhr, request); } xhr.responseType = function(value) { if (!arguments.length) return responseType; responseType = value; return xhr; }; if (responseType != null) request.responseType = responseType; dispatch.beforesend.call(xhr, request); } function d3_xhrHasResponse(request) { var type = request.responseType; return type && type !== ""text"" ? request.response : request.responseText; } d3.dsv = function(delimiter, mimeType) { var xhr = d3_xhr(url, mimeType, row == null ? response : typedResponse(row), callback); return xhr; return text.slice(j + 1, i).replace(/""""/g, '""'); return text.slice(j, I - k); } return text.slice(j); if (f && (a = f(a, n++)) == null) continue; }; d3.csv = d3.dsv("","", ""text/csv""); d3.tsv = d3.dsv("" "", ""text/tab-separated-values""); var d3_timer_queueHead, d3_timer_queueTail, d3_timer_interval, d3_timer_timeout, d3_timer_frame = this[d3_vendorSymbol(this, ""requestAnimationFrame"")] || function(callback) { setTimeout(callback, 17); }; d3.timer = function() { d3_timer.apply(this, arguments); }; function d3_timer(callback, delay, then) { var n = arguments.length; if (n < 2) delay = 0; if (n < 3) then = Date.now(); var time = then + delay, timer = { c: callback, t: time, n: null if (d3_timer_queueTail) d3_timer_queueTail.n = timer; else d3_timer_queueHead = timer; d3_timer_queueTail = timer; return timer; } function d3_timer_step() { var now = d3_timer_mark(), delay = d3_timer_sweep() - now; d3_timer_mark(); d3_timer_sweep(); function d3_timer_mark() { var now = Date.now(), timer = d3_timer_queueHead; while (timer) { if (now >= timer.t && timer.c(now - timer.t)) timer.c = null; timer = timer.n; } return now; } function d3_timer_sweep() { var t0, t1 = d3_timer_queueHead, time = Infinity; while (t1) { if (t1.c) { if (t1.t < time) time = t1.t; t1 = (t0 = t1).n; } else { t1 = t0 ? t0.n = t1.n : d3_timer_queueHead = t1.n; } } d3_timer_queueTail = t0; return time; } function d3_format_precision(x, p) { return p - (x ? Math.ceil(Math.log(x) / Math.LN10) : 1); } d3.round = function(x, n) { return n ? Math.round(x * (n = Math.pow(10, n))) / n : Math.round(x); if (value = +value) { i = Math.max(-24, Math.min(24, Math.floor((i - 1) / 3) * 3)); var k = Math.pow(10, abs(8 - i) * 3); function d3_locale_numberFormat(locale) { var locale_decimal = locale.decimal, locale_thousands = locale.thousands, locale_grouping = locale.grouping, locale_currency = locale.currency, formatGroup = locale_grouping && locale_thousands ? function(value, width) { var i = value.length, t = [], j = 0, g = locale_grouping[0], length = 0; while (i > 0 && g > 0) { if (length + g + 1 > width) g = Math.max(1, width - length); t.push(value.substring(i -= g, i + g)); if ((length += g + 1) > width) break; g = locale_grouping[j = (j + 1) % locale_grouping.length]; } return t.reverse().join(locale_thousands); } : d3_identity; return function(specifier) { var match = d3_format_re.exec(specifier), fill = match[1] || "" "", align = match[2] || "">"", sign = match[3] || ""-"", symbol = match[4] || """", zfill = match[5], width = +match[6], comma = match[7], precision = match[8], type = match[9], scale = 1, prefix = """", suffix = """", integer = false, exponent = true; if (precision) precision = +precision.substring(1); if (zfill || fill === ""0"" && align === ""="") { zfill = fill = ""0""; align = ""=""; } switch (type) { case ""n"": comma = true; type = ""g""; break; case ""%"": scale = 100; suffix = ""%""; type = ""f""; break; case ""p"": scale = 100; suffix = ""%""; type = ""r""; break; case ""b"": case ""o"": case ""x"": case ""X"": if (symbol === ""#"") prefix = ""0"" + type.toLowerCase(); case ""c"": exponent = false; case ""d"": integer = true; precision = 0; break; case ""s"": scale = -1; type = ""r""; break; } if (symbol === ""$"") prefix = locale_currency[0], suffix = locale_currency[1]; if (type == ""r"" && !precision) type = ""g""; if (precision != null) { if (type == ""g"") precision = Math.max(1, Math.min(21, precision)); else if (type == ""e"" || type == ""f"") precision = Math.max(0, Math.min(20, precision)); } type = d3_format_types.get(type) || d3_format_typeDefault; var zcomma = zfill && comma; return function(value) { var fullSuffix = suffix; if (integer && value % 1) return """"; var negative = value < 0 || value === 0 && 1 / value < 0 ? (value = -value, ""-"") : sign === ""-"" ? """" : sign; if (scale < 0) { var unit = d3.formatPrefix(value, precision); value = unit.scale(value); fullSuffix = unit.symbol + suffix; } else { value *= scale; } value = type(value, precision); var i = value.lastIndexOf("".""), before, after; if (i < 0) { var j = exponent ? value.lastIndexOf(""e"") : -1; if (j < 0) before = value, after = """"; else before = value.substring(0, j), after = value.substring(j); } else { before = value.substring(0, i); after = locale_decimal + value.substring(i + 1); } if (!zfill && comma) before = formatGroup(before, Infinity); var length = prefix.length + before.length + after.length + (zcomma ? 0 : negative.length), padding = length < width ? new Array(length = width - length + 1).join(fill) : """"; if (zcomma) before = formatGroup(padding + before, padding.length ? width - after.length : Infinity); negative += prefix; value = before + after; return (align === ""<"" ? negative + value + padding : align === "">"" ? padding + negative + value : align === ""^"" ? padding.substring(0, length >>= 1) + negative + value + padding.substring(length) : negative + (zcomma ? value : padding + value)) + fullSuffix; }; } var d3_format_re = /(?:([^{])?([<>=^]))?([+\- ])?([$#])?(0)?(\d+)?(,)?(\.-?\d+)?([a-z%])?/i; var d3_time = d3.time = {}, d3_date = Date; function d3_date_utc() { this._ = new Date(arguments.length > 1 ? Date.UTC.apply(this, arguments) : arguments[0]); } d3_date_utc.prototype = { getDate: function() { return this._.getUTCDate(); }, getDay: function() { return this._.getUTCDay(); }, getFullYear: function() { return this._.getUTCFullYear(); }, getHours: function() { return this._.getUTCHours(); }, getMilliseconds: function() { return this._.getUTCMilliseconds(); }, getMinutes: function() { return this._.getUTCMinutes(); }, getMonth: function() { return this._.getUTCMonth(); }, getSeconds: function() { return this._.getUTCSeconds(); }, getTime: function() { return this._.getTime(); }, getTimezoneOffset: function() { return 0; }, valueOf: function() { return this._.valueOf(); }, setDate: function() { d3_time_prototype.setUTCDate.apply(this._, arguments); }, setDay: function() { d3_time_prototype.setUTCDay.apply(this._, arguments); }, setFullYear: function() { d3_time_prototype.setUTCFullYear.apply(this._, arguments); }, setHours: function() { d3_time_prototype.setUTCHours.apply(this._, arguments); }, setMilliseconds: function() { d3_time_prototype.setUTCMilliseconds.apply(this._, arguments); }, setMinutes: function() { d3_time_prototype.setUTCMinutes.apply(this._, arguments); }, setMonth: function() { d3_time_prototype.setUTCMonth.apply(this._, arguments); }, setSeconds: function() { d3_time_prototype.setUTCSeconds.apply(this._, arguments); }, setTime: function() { d3_time_prototype.setTime.apply(this._, arguments); } }; var d3_time_prototype = Date.prototype; function d3_time_interval(local, step, number) { function round(date) { var d0 = local(date), d1 = offset(d0, 1); return date - d0 < d1 - date ? d0 : d1; } function ceil(date) { step(date = local(new d3_date(date - 1)), 1); return date; } function offset(date, k) { step(date = new d3_date(+date), k); return date; } function range(t0, t1, dt) { var time = ceil(t0), times = []; if (dt > 1) { while (time < t1) { if (!(number(time) % dt)) times.push(new Date(+time)); step(time, 1); } } else { while (time < t1) times.push(new Date(+time)), step(time, 1); } return times; } function range_utc(t0, t1, dt) { try { d3_date = d3_date_utc; var utc = new d3_date_utc(); utc._ = t0; return range(utc, t1, dt); } finally { d3_date = Date; } } local.floor = local; local.round = round; local.ceil = ceil; local.offset = offset; local.range = range; var utc = local.utc = d3_time_interval_utc(local); utc.floor = utc; utc.round = d3_time_interval_utc(round); utc.ceil = d3_time_interval_utc(ceil); utc.offset = d3_time_interval_utc(offset); utc.range = range_utc; return local; } function d3_time_interval_utc(method) { return function(date, k) { try { d3_date = d3_date_utc; var utc = new d3_date_utc(); utc._ = date; return method(utc, k)._; } finally { d3_date = Date; } d3_time.year = d3_time_interval(function(date) { date = d3_time.day(date); date.setMonth(0, 1); return date; }, function(date, offset) { date.setFullYear(date.getFullYear() + offset); }, function(date) { return date.getFullYear(); }); d3_time.years = d3_time.year.range; d3_time.years.utc = d3_time.year.utc.range; d3_time.day = d3_time_interval(function(date) { var day = new d3_date(2e3, 0); day.setFullYear(date.getFullYear(), date.getMonth(), date.getDate()); return day; }, function(date, offset) { date.setDate(date.getDate() + offset); }, function(date) { return date.getDate() - 1; }); d3_time.days = d3_time.day.range; d3_time.days.utc = d3_time.day.utc.range; d3_time.dayOfYear = function(date) { var year = d3_time.year(date); return Math.floor((date - year - (date.getTimezoneOffset() - year.getTimezoneOffset()) * 6e4) / 864e5); }; [ ""sunday"", ""monday"", ""tuesday"", ""wednesday"", ""thursday"", ""friday"", ""saturday"" ].forEach(function(day, i) { i = 7 - i; var interval = d3_time[day] = d3_time_interval(function(date) { (date = d3_time.day(date)).setDate(date.getDate() - (date.getDay() + i) % 7); return date; }, function(date, offset) { date.setDate(date.getDate() + Math.floor(offset) * 7); }, function(date) { var day = d3_time.year(date).getDay(); return Math.floor((d3_time.dayOfYear(date) + (day + i) % 7) / 7) - (day !== i); }); d3_time[day + ""s""] = interval.range; d3_time[day + ""s""].utc = interval.utc.range; d3_time[day + ""OfYear""] = function(date) { var day = d3_time.year(date).getDay(); return Math.floor((d3_time.dayOfYear(date) + (day + i) % 7) / 7); }; }); d3_time.week = d3_time.sunday; d3_time.weeks = d3_time.sunday.range; d3_time.weeks.utc = d3_time.sunday.utc.range; d3_time.weekOfYear = d3_time.sundayOfYear; function d3_locale_timeFormat(locale) { var locale_dateTime = locale.dateTime, locale_date = locale.date, locale_time = locale.time, locale_periods = locale.periods, locale_days = locale.days, locale_shortDays = locale.shortDays, locale_months = locale.months, locale_shortMonths = locale.shortMonths; function d3_time_format(template) { var n = template.length; function format(date) { var string = [], i = -1, j = 0, c, p, f; while (++i < n) { if (template.charCodeAt(i) === 37) { string.push(template.slice(j, i)); if ((p = d3_time_formatPads[c = template.charAt(++i)]) != null) c = template.charAt(++i); if (f = d3_time_formats[c]) c = f(date, p == null ? c === ""e"" ? "" "" : ""0"" : p); string.push(c); j = i + 1; } } string.push(template.slice(j, i)); return string.join(""""); } format.parse = function(string) { var d = { y: 1900, m: 0, d: 1, H: 0, M: 0, S: 0, L: 0, Z: null }, i = d3_time_parse(d, template, string, 0); if (i != string.length) return null; if (""p"" in d) d.H = d.H % 12 + d.p * 12; var localZ = d.Z != null && d3_date !== d3_date_utc, date = new (localZ ? d3_date_utc : d3_date)(); if (""j"" in d) date.setFullYear(d.y, 0, d.j); else if (""W"" in d || ""U"" in d) { if (!(""w"" in d)) d.w = ""W"" in d ? 1 : 0; date.setFullYear(d.y, 0, 1); date.setFullYear(d.y, 0, ""W"" in d ? (d.w + 6) % 7 + d.W * 7 - (date.getDay() + 5) % 7 : d.w + d.U * 7 - (date.getDay() + 6) % 7); } else date.setFullYear(d.y, d.m, d.d); date.setHours(d.H + (d.Z / 100 | 0), d.M + d.Z % 100, d.S, d.L); return localZ ? date._ : date; }; format.toString = function() { return template; }; return format; } function d3_time_parse(date, template, string, j) { var c, p, t, i = 0, n = template.length, m = string.length; while (i < n) { if (j >= m) return -1; c = template.charCodeAt(i++); if (c === 37) { t = template.charAt(i++); p = d3_time_parsers[t in d3_time_formatPads ? template.charAt(i++) : t]; if (!p || (j = p(date, string, j)) < 0) return -1; } else if (c != string.charCodeAt(j++)) { return -1; } } return j; } d3_time_format.utc = function(template) { var local = d3_time_format(template); function format(date) { try { d3_date = d3_date_utc; var utc = new d3_date(); utc._ = date; return local(utc); } finally { d3_date = Date; } } format.parse = function(string) { try { d3_date = d3_date_utc; var date = local.parse(string); return date && date._; } finally { d3_date = Date; } }; format.toString = local.toString; return format; }; d3_time_format.multi = d3_time_format.utc.multi = d3_time_formatMulti; var d3_time_periodLookup = d3.map(), d3_time_dayRe = d3_time_formatRe(locale_days), d3_time_dayLookup = d3_time_formatLookup(locale_days), d3_time_dayAbbrevRe = d3_time_formatRe(locale_shortDays), d3_time_dayAbbrevLookup = d3_time_formatLookup(locale_shortDays), d3_time_monthRe = d3_time_formatRe(locale_months), d3_time_monthLookup = d3_time_formatLookup(locale_months), d3_time_monthAbbrevRe = d3_time_formatRe(locale_shortMonths), d3_time_monthAbbrevLookup = d3_time_formatLookup(locale_shortMonths); locale_periods.forEach(function(p, i) { d3_time_periodLookup.set(p.toLowerCase(), i); }); var d3_time_formats = { a: function(d) { return locale_shortDays[d.getDay()]; }, A: function(d) { return locale_days[d.getDay()]; }, b: function(d) { return locale_shortMonths[d.getMonth()]; }, B: function(d) { return locale_months[d.getMonth()]; }, c: d3_time_format(locale_dateTime), d: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, e: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, H: function(d, p) { return d3_time_formatPad(d.getHours(), p, 2); }, I: function(d, p) { return d3_time_formatPad(d.getHours() % 12 || 12, p, 2); }, j: function(d, p) { return d3_time_formatPad(1 + d3_time.dayOfYear(d), p, 3); }, L: function(d, p) { return d3_time_formatPad(d.getMilliseconds(), p, 3); }, m: function(d, p) { return d3_time_formatPad(d.getMonth() + 1, p, 2); }, M: function(d, p) { return d3_time_formatPad(d.getMinutes(), p, 2); }, p: function(d) { return locale_periods[+(d.getHours() >= 12)]; }, S: function(d, p) { return d3_time_formatPad(d.getSeconds(), p, 2); }, U: function(d, p) { return d3_time_formatPad(d3_time.sundayOfYear(d), p, 2); }, w: function(d) { return d.getDay(); }, W: function(d, p) { return d3_time_formatPad(d3_time.mondayOfYear(d), p, 2); }, x: d3_time_format(locale_date), X: d3_time_format(locale_time), y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 100, p, 2); }, Y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 1e4, p, 4); }, Z: d3_time_zone, ""%"": function() { return ""%""; } }; var d3_time_parsers = { a: d3_time_parseWeekdayAbbrev, A: d3_time_parseWeekday, b: d3_time_parseMonthAbbrev, B: d3_time_parseMonth, c: d3_time_parseLocaleFull, d: d3_time_parseDay, e: d3_time_parseDay, H: d3_time_parseHour24, I: d3_time_parseHour24, j: d3_time_parseDayOfYear, L: d3_time_parseMilliseconds, m: d3_time_parseMonthNumber, M: d3_time_parseMinutes, p: d3_time_parseAmPm, S: d3_time_parseSeconds, U: d3_time_parseWeekNumberSunday, w: d3_time_parseWeekdayNumber, W: d3_time_parseWeekNumberMonday, x: d3_time_parseLocaleDate, X: d3_time_parseLocaleTime, y: d3_time_parseYear, Y: d3_time_parseFullYear, Z: d3_time_parseZone, ""%"": d3_time_parseLiteralPercent }; function d3_time_parseWeekdayAbbrev(date, string, i) { d3_time_dayAbbrevRe.lastIndex = 0; var n = d3_time_dayAbbrevRe.exec(string.slice(i)); return n ? (date.w = d3_time_dayAbbrevLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseWeekday(date, string, i) { d3_time_dayRe.lastIndex = 0; var n = d3_time_dayRe.exec(string.slice(i)); return n ? (date.w = d3_time_dayLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseMonthAbbrev(date, string, i) { d3_time_monthAbbrevRe.lastIndex = 0; var n = d3_time_monthAbbrevRe.exec(string.slice(i)); return n ? (date.m = d3_time_monthAbbrevLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseMonth(date, string, i) { d3_time_monthRe.lastIndex = 0; var n = d3_time_monthRe.exec(string.slice(i)); return n ? (date.m = d3_time_monthLookup.get(n[0].toLowerCase()), i + n[0].length) : -1; } function d3_time_parseLocaleFull(date, string, i) { return d3_time_parse(date, d3_time_formats.c.toString(), string, i); } function d3_time_parseLocaleDate(date, string, i) { return d3_time_parse(date, d3_time_formats.x.toString(), string, i); } function d3_time_parseLocaleTime(date, string, i) { return d3_time_parse(date, d3_time_formats.X.toString(), string, i); } function d3_time_parseAmPm(date, string, i) { var n = d3_time_periodLookup.get(string.slice(i, i += 2).toLowerCase()); return n == null ? -1 : (date.p = n, i); } return d3_time_format; } var d3_time_formatPads = { ""-"": """", _: "" "", ""0"": ""0"" }, d3_time_numberRe = /^\s*\d+/, d3_time_percentRe = /^%/; function d3_time_formatPad(value, fill, width) { var sign = value < 0 ? ""-"" : """", string = (sign ? -value : value) + """", length = string.length; return sign + (length < width ? new Array(width - length + 1).join(fill) + string : string); } function d3_time_formatRe(names) { return new RegExp(""^(?:"" + names.map(d3.requote).join(""|"") + "")"", ""i""); } function d3_time_formatLookup(names) { var map = new d3_Map(), i = -1, n = names.length; while (++i < n) map.set(names[i].toLowerCase(), i); return map; } function d3_time_parseWeekdayNumber(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 1)); return n ? (date.w = +n[0], i + n[0].length) : -1; } function d3_time_parseWeekNumberSunday(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i)); return n ? (date.U = +n[0], i + n[0].length) : -1; } function d3_time_parseWeekNumberMonday(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i)); return n ? (date.W = +n[0], i + n[0].length) : -1; } function d3_time_parseFullYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 4)); return n ? (date.y = +n[0], i + n[0].length) : -1; } function d3_time_parseYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.y = d3_time_expandYear(+n[0]), i + n[0].length) : -1; } function d3_time_parseZone(date, string, i) { return /^[+-]\d{4}$/.test(string = string.slice(i, i + 5)) ? (date.Z = -string, i + 5) : -1; } function d3_time_expandYear(d) { return d + (d > 68 ? 1900 : 2e3); } function d3_time_parseMonthNumber(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.m = n[0] - 1, i + n[0].length) : -1; } function d3_time_parseDay(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.d = +n[0], i + n[0].length) : -1; } function d3_time_parseDayOfYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 3)); return n ? (date.j = +n[0], i + n[0].length) : -1; } function d3_time_parseHour24(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.H = +n[0], i + n[0].length) : -1; } function d3_time_parseMinutes(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.M = +n[0], i + n[0].length) : -1; } function d3_time_parseSeconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 2)); return n ? (date.S = +n[0], i + n[0].length) : -1; } function d3_time_parseMilliseconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.slice(i, i + 3)); return n ? (date.L = +n[0], i + n[0].length) : -1; } function d3_time_zone(d) { var z = d.getTimezoneOffset(), zs = z > 0 ? ""-"" : ""+"", zh = abs(z) / 60 | 0, zm = abs(z) % 60; return zs + d3_time_formatPad(zh, ""0"", 2) + d3_time_formatPad(zm, ""0"", 2); } function d3_time_parseLiteralPercent(date, string, i) { d3_time_percentRe.lastIndex = 0; var n = d3_time_percentRe.exec(string.slice(i, i + 1)); return n ? i + n[0].length : -1; } function d3_time_formatMulti(formats) { var n = formats.length, i = -1; while (++i < n) formats[i][0] = this(formats[i][0]); return function(date) { var i = 0, f = formats[i]; while (!f[1](date)) f = formats[++i]; return f[0](date); }; } d3.locale = function(locale) { return { numberFormat: d3_locale_numberFormat(locale), timeFormat: d3_locale_timeFormat(locale) }; }; var d3_locale_enUS = d3.locale({ decimal: ""."", thousands: "","", grouping: [ 3 ], currency: [ ""$"", """" ], dateTime: ""%a %b %e %X %Y"", date: ""%m/%d/%Y"", time: ""%H:%M:%S"", periods: [ ""AM"", ""PM"" ], days: [ ""Sunday"", ""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"" ], shortDays: [ ""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"" ], months: [ ""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December"" ], shortMonths: [ ""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"" ] }); d3.format = d3_locale_enUS.numberFormat; function d3_adder() {} d3_adder.prototype = { s: 0, t: 0, add: function(y) { d3_adderSum(y, this.t, d3_adderTemp); d3_adderSum(d3_adderTemp.s, this.s, this); if (this.s) this.t += d3_adderTemp.t; else this.s = d3_adderTemp.t; }, reset: function() { this.s = this.t = 0; }, valueOf: function() { return this.s; } }; var d3_adderTemp = new d3_adder(); function d3_adderSum(a, b, o) { var x = o.s = a + b, bv = x - a, av = x - bv; o.t = a - av + (b - bv); } object = object.coordinates; listener.point(object[0], object[1], object[2]); var coordinates = object.coordinates, i = -1, n = coordinates.length; while (++i < n) object = coordinates[i], listener.point(object[0], object[1], object[2]); while (++i < n) coordinate = coordinates[i], listener.point(coordinate[0], coordinate[1], coordinate[2]); var d3_geo_areaSum, d3_geo_areaRingSum = new d3_adder(); d3_geo_areaRingSum.reset(); var area = 2 * d3_geo_areaRingSum; var d =  - 0, sd = d >= 0 ? 1 : -1, ad = sd * d, cos = Math.cos(), sin = Math.sin(), k = sin0 * sin, u = cos0 * cos + k * Math.cos(ad), v = k * sd * Math.sin(ad); d3_geo_areaRingSum.add(Math.atan2(v, u)); function d3_geo_spherical(cartesian) { return [ Math.atan2(cartesian[1], cartesian[0]), d3_asin(cartesian[2]) ]; } function d3_geo_sphericalEqual(a, b) { return abs(a[0] - b[0]) <  && abs(a[1] - b[1]) < ; } d3.geo.bounds = function() { var 0, 0, 1, 1, _, __, __, p0, dSum, ranges, range; var bound = { point: point, lineStart: lineStart, lineEnd: lineEnd, polygonStart: function() { bound.point = ringPoint; bound.lineStart = ringStart; bound.lineEnd = ringEnd; dSum = 0; d3_geo_area.polygonStart(); }, polygonEnd: function() { d3_geo_area.polygonEnd(); bound.point = point; bound.lineStart = lineStart; bound.lineEnd = lineEnd; if (d3_geo_areaRingSum < 0) 0 = -(1 = 180), 0 = -(1 = 90); else if (dSum > ) 1 = 90; else if (dSum < -) 0 = -90; range[0] = 0, range[1] = 1; } }; function point(, ) { ranges.push(range = [ 0 = , 1 =  ]); if ( < 0) 0 = ; if ( > 1) 1 = ; } function linePoint(, ) { var p = d3_geo_cartesian([  * d3_radians,  * d3_radians ]); if (p0) { var normal = d3_geo_cartesianCross(p0, p), equatorial = [ normal[1], -normal[0], 0 ], inflection = d3_geo_cartesianCross(equatorial, normal); d3_geo_cartesianNormalize(inflection); inflection = d3_geo_spherical(inflection); var d =  - _, s = d > 0 ? 1 : -1, i = inflection[0] * d3_degrees * s, antimeridian = abs(d) > 180; if (antimeridian ^ (s * _ < i && i < s * )) { var i = inflection[1] * d3_degrees; if (i > 1) 1 = i; } else if (i = (i + 360) % 360 - 180, antimeridian ^ (s * _ < i && i < s * )) { var i = -inflection[1] * d3_degrees; if (i < 0) 0 = i; } else { if ( < 0) 0 = ; if ( > 1) 1 = ; } if (antimeridian) { if ( < _) { if (angle(0, ) > angle(0, 1)) 1 = ; } else { if (angle(, 1) > angle(0, 1)) 0 = ; } } else { if (1 >= 0) { if ( < 0) 0 = ; if ( > 1) 1 = ; } else { if ( > _) { if (angle(0, ) > angle(0, 1)) 1 = ; } else { if (angle(, 1) > angle(0, 1)) 0 = ; } } } } else { point(, ); } p0 = p, _ = ; } function lineStart() { bound.point = linePoint; } function lineEnd() { range[0] = 0, range[1] = 1; bound.point = point; p0 = null; } function ringPoint(, ) { if (p0) { var d =  - _; dSum += abs(d) > 180 ? d + (d > 0 ? 360 : -360) : d; } else __ = , __ = ; d3_geo_area.point(, ); linePoint(, ); } function ringStart() { d3_geo_area.lineStart(); } function ringEnd() { ringPoint(__, __); d3_geo_area.lineEnd(); if (abs(dSum) > ) 0 = -(1 = 180); range[0] = 0, range[1] = 1; p0 = null; } function angle(0, 1) { return (1 -= 0) < 0 ? 1 + 360 : 1; } function compareRanges(a, b) { return a[0] - b[0]; } function withinRange(x, range) { return range[0] <= range[1] ? range[0] <= x && x <= range[1] : x < range[0] || range[1] < x; } return function(feature) { 1 = 1 = -(0 = 0 = Infinity); ranges = []; d3.geo.stream(feature, bound); var n = ranges.length; if (n) { ranges.sort(compareRanges); for (var i = 1, a = ranges[0], b, merged = [ a ]; i < n; ++i) { b = ranges[i]; if (withinRange(b[0], a) || withinRange(b[1], a)) { if (angle(a[0], b[1]) > angle(a[0], a[1])) a[1] = b[1]; if (angle(b[0], a[1]) > angle(a[0], a[1])) a[0] = b[0]; } else { merged.push(a = b); } } var best = -Infinity, d; for (var n = merged.length - 1, i = 0, a = merged[n], b; i <= n; a = b, ++i) { b = merged[i]; if ((d = angle(a[1], b[0])) > best) best = d, 0 = b[0], 1 = a[1]; } } ranges = range = null; return 0 === Infinity || 0 === Infinity ? [ [ NaN, NaN ], [ NaN, NaN ] ] : [ [ 0, 0 ], [ 1, 1 ] ]; }; }(); d3.geo.centroid = function(object) { d3_geo_centroidW0 = d3_geo_centroidW1 = d3_geo_centroidX0 = d3_geo_centroidY0 = d3_geo_centroidZ0 = d3_geo_centroidX1 = d3_geo_centroidY1 = d3_geo_centroidZ1 = d3_geo_centroidX2 = d3_geo_centroidY2 = d3_geo_centroidZ2 = 0; d3.geo.stream(object, d3_geo_centroid); var x = d3_geo_centroidX2, y = d3_geo_centroidY2, z = d3_geo_centroidZ2, m = x * x + y * y + z * z; if (m < 2) { x = d3_geo_centroidX1, y = d3_geo_centroidY1, z = d3_geo_centroidZ1; if (d3_geo_centroidW1 < ) x = d3_geo_centroidX0, y = d3_geo_centroidY0, z = d3_geo_centroidZ0; m = x * x + y * y + z * z; if (m < 2) return [ NaN, NaN ]; } return [ Math.atan2(y, x) * d3_degrees, d3_asin(z / Math.sqrt(m)) * d3_degrees ]; }; var d3_geo_centroidW0, d3_geo_centroidW1, d3_geo_centroidX0, d3_geo_centroidY0, d3_geo_centroidZ0, d3_geo_centroidX1, d3_geo_centroidY1, d3_geo_centroidZ1, d3_geo_centroidX2, d3_geo_centroidY2, d3_geo_centroidZ2; var d3_geo_centroid = { sphere: d3_noop, point: d3_geo_centroidPoint, lineStart: d3_geo_centroidLineStart, lineEnd: d3_geo_centroidLineEnd, polygonStart: function() { d3_geo_centroid.lineStart = d3_geo_centroidRingStart; }, polygonEnd: function() { d3_geo_centroid.lineStart = d3_geo_centroidLineStart; } }; function d3_geo_centroidPoint(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians); d3_geo_centroidPointXYZ(cos * Math.cos(), cos * Math.sin(), Math.sin()); } function d3_geo_centroidPointXYZ(x, y, z) { ++d3_geo_centroidW0; d3_geo_centroidX0 += (x - d3_geo_centroidX0) / d3_geo_centroidW0; d3_geo_centroidY0 += (y - d3_geo_centroidY0) / d3_geo_centroidW0; d3_geo_centroidZ0 += (z - d3_geo_centroidZ0) / d3_geo_centroidW0; } function d3_geo_centroidLineStart() { var x0, y0, z0; d3_geo_centroid.point = function(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians); x0 = cos * Math.cos(); y0 = cos * Math.sin(); z0 = Math.sin(); d3_geo_centroid.point = nextPoint; d3_geo_centroidPointXYZ(x0, y0, z0); }; function nextPoint(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians), x = cos * Math.cos(), y = cos * Math.sin(), z = Math.sin(), w = Math.atan2(Math.sqrt((w = y0 * z - z0 * y) * w + (w = z0 * x - x0 * z) * w + (w = x0 * y - y0 * x) * w), x0 * x + y0 * y + z0 * z); d3_geo_centroidW1 += w; d3_geo_centroidX1 += w * (x0 + (x0 = x)); d3_geo_centroidY1 += w * (y0 + (y0 = y)); d3_geo_centroidZ1 += w * (z0 + (z0 = z)); d3_geo_centroidPointXYZ(x0, y0, z0); } } function d3_geo_centroidLineEnd() { d3_geo_centroid.point = d3_geo_centroidPoint; } function d3_geo_centroidRingStart() { var 00, 00, x0, y0, z0; d3_geo_centroid.point = function(, ) { 00 = , 00 = ; d3_geo_centroid.point = nextPoint;  *= d3_radians; var cos = Math.cos( *= d3_radians); x0 = cos * Math.cos(); y0 = cos * Math.sin(); z0 = Math.sin(); d3_geo_centroidPointXYZ(x0, y0, z0); }; d3_geo_centroid.lineEnd = function() { nextPoint(00, 00); d3_geo_centroid.lineEnd = d3_geo_centroidLineEnd; d3_geo_centroid.point = d3_geo_centroidPoint; }; function nextPoint(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians), x = cos * Math.cos(), y = cos * Math.sin(), z = Math.sin(), cx = y0 * z - z0 * y, cy = z0 * x - x0 * z, cz = x0 * y - y0 * x, m = Math.sqrt(cx * cx + cy * cy + cz * cz), u = x0 * x + y0 * y + z0 * z, v = m && -d3_acos(u) / m, w = Math.atan2(m, u); d3_geo_centroidX2 += v * cx; d3_geo_centroidY2 += v * cy; d3_geo_centroidZ2 += v * cz; d3_geo_centroidW1 += w; d3_geo_centroidX1 += w * (x0 + (x0 = x)); d3_geo_centroidY1 += w * (y0 + (y0 = y)); d3_geo_centroidZ1 += w * (z0 + (z0 = z)); d3_geo_centroidPointXYZ(x0, y0, z0); } } function d3_geo_compose(a, b) { function compose(x, y) { return x = a(x, y), b(x[0], x[1]); } if (a.invert && b.invert) compose.invert = function(x, y) { return x = b.invert(x, y), x && a.invert(x[0], x[1]); }; return compose; } function d3_geo_clipPolygon(segments, compare, clipStartInside, interpolate, listener) { var a = new d3_geo_clipPolygonIntersection(p0, segment, null, true), b = new d3_geo_clipPolygonIntersection(p0, null, a, false); a.o = b; a = new d3_geo_clipPolygonIntersection(p1, segment, null, false); b = new d3_geo_clipPolygonIntersection(p1, null, a, true); a.o = b; for (var i = 0, entry = clipStartInside, n = clip.length; i < n; ++i) { clip[i].e = entry = !entry; } var start = subject[0], points, point; while (1) { var current = start, isSubject = true; while (current.v) if ((current = current.n) === start) return; points = current.z; current.v = current.o.v = true; if (current.e) { if (isSubject) { for (var i = 0, n = points.length; i < n; ++i) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.x, current.n.x, 1, listener); } current = current.n; } else { if (isSubject) { points = current.p.z; for (var i = points.length - 1; i >= 0; --i) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.x, current.p.x, -1, listener); } current = current.p; } current = current.o; points = current.z; isSubject = !isSubject; } while (!current.v); a.n = b = array[i]; b.p = a; a.n = b = array[0]; b.p = a; } function d3_geo_clipPolygonIntersection(point, points, other, entry) { this.x = point; this.z = points; this.o = other; this.e = entry; this.v = false; this.n = this.p = null; } function d3_geo_clip(pointVisible, clipLine, interpolate, clipStart) { return function(rotate, listener) { var line = clipLine(listener), rotatedClipStart = rotate.invert(clipStart[0], clipStart[1]); polygon = []; var clipStartInside = d3_geo_pointInPolygon(rotatedClipStart, polygon); if (segments.length) { if (!polygonStarted) listener.polygonStart(), polygonStarted = true; d3_geo_clipPolygon(segments, d3_geo_clipSort, clipStartInside, interpolate, listener); } else if (clipStartInside) { if (!polygonStarted) listener.polygonStart(), polygonStarted = true; if (polygonStarted) listener.polygonEnd(), polygonStarted = false; segments = polygon = null; var point = rotate(, ); if (pointVisible( = point[0],  = point[1])) listener.point(, ); var point = rotate(, ); line.point(point[0], point[1]); var segments; var buffer = d3_geo_clipBufferListener(), ringListener = clipLine(buffer), polygonStarted = false, polygon, ring; function pointRing(, ) { var point = rotate(, ); ringListener.point(point[0], point[1]); ring.pop(); polygon.push(ring); if (!n) return; if (n > 0) { if (!polygonStarted) listener.polygonStart(), polygonStarted = true; listener.lineStart(); while (++i < n) listener.point((point = segment[i])[0], point[1]); listener.lineEnd(); } function d3_geo_clipSort(a, b) { return ((a = a.x)[0] < 0 ? a[1] - half -  : half - a[1]) - ((b = b.x)[0] < 0 ? b[1] - half -  : half - b[1]); } var d3_geo_clipAntimeridian = d3_geo_clip(d3_true, d3_geo_clipAntimeridianLine, d3_geo_clipAntimeridianInterpolate, [ -, - / 2 ]); var s1 = 1 > 0 ?  : -, d = abs(1 - 0); if (abs(d - ) < ) { listener.point(0, 0 = (0 + 1) / 2 > 0 ? half : -half); if (abs(0 - s0) < ) 0 -= s0 * ; if (abs(1 - s1) < ) 1 -= s1 * ; return abs(sin0_1) >  ? Math.atan((Math.sin(0) * (cos1 = Math.cos(1)) * Math.sin(1) - Math.sin(1) * (cos0 = Math.cos(0)) * Math.sin(0)) / (cos0 * cos1 * sin0_1)) : (0 + 1) / 2;  = direction * half; } else if (abs(from[0] - to[0]) > ) { var s = from[0] < to[0] ?  : -; function d3_geo_pointInPolygon(point, polygon) { var meridian = point[0], parallel = point[1], meridianNormal = [ Math.sin(meridian), -Math.cos(meridian), 0 ], polarAngle = 0, winding = 0; d3_geo_areaRingSum.reset(); for (var i = 0, n = polygon.length; i < n; ++i) { var ring = polygon[i], m = ring.length; if (!m) continue; var point0 = ring[0], 0 = point0[0], 0 = point0[1] / 2 +  / 4, sin0 = Math.sin(0), cos0 = Math.cos(0), j = 1; while (true) { if (j === m) j = 0; point = ring[j]; var  = point[0],  = point[1] / 2 +  / 4, sin = Math.sin(), cos = Math.cos(), d =  - 0, sd = d >= 0 ? 1 : -1, ad = sd * d, antimeridian = ad > , k = sin0 * sin; d3_geo_areaRingSum.add(Math.atan2(k * sd * Math.sin(ad), cos0 * cos + k * Math.cos(ad))); polarAngle += antimeridian ? d + sd *  : d; if (antimeridian ^ 0 >= meridian ^  >= meridian) { var arc = d3_geo_cartesianCross(d3_geo_cartesian(point0), d3_geo_cartesian(point)); d3_geo_cartesianNormalize(arc); var intersection = d3_geo_cartesianCross(meridianNormal, arc); d3_geo_cartesianNormalize(intersection); var arc = (antimeridian ^ d >= 0 ? -1 : 1) * d3_asin(intersection[2]); if (parallel > arc || parallel === arc && (arc[0] || arc[1])) { winding += antimeridian ^ d >= 0 ? 1 : -1; } } if (!j++) break; 0 = , sin0 = sin, cos0 = cos, point0 = point; } } return (polarAngle < - || polarAngle <  && d3_geo_areaRingSum < 0) ^ winding & 1; } function d3_geo_clipCircle(radius) { var cr = Math.cos(radius), smallRadius = cr > 0, notHemisphere = abs(cr) > , interpolate = d3_geo_circleInterpolate(radius, 6 * d3_radians); return d3_geo_clip(visible, clipLine, interpolate, smallRadius ? [ 0, -radius ] : [ -, radius -  ]); var  = 1 - 0, polar = abs( - ) < , meridian = polar ||  < ; if (meridian ? polar ? 0 + 1 > 0 ^ q[1] < (abs(q[0] - 0) <  ? 0 : 1) : 0 <= q[1] && q[1] <= 1 :  >  ^ (0 <= q[0] && q[0] <= 1)) { function d3_geom_clipLine(x0, y0, x1, y1) { return function(line) { var a = line.a, b = line.b, ax = a.x, ay = a.y, bx = b.x, by = b.y, t0 = 0, t1 = 1, dx = bx - ax, dy = by - ay, r; r = x0 - ax; if (!dx && r > 0) return; r /= dx; if (dx < 0) { if (r < t0) return; if (r < t1) t1 = r; } else if (dx > 0) { if (r > t1) return; if (r > t0) t0 = r; } r = x1 - ax; if (!dx && r < 0) return; r /= dx; if (dx < 0) { if (r > t1) return; if (r > t0) t0 = r; } else if (dx > 0) { if (r < t0) return; if (r < t1) t1 = r; } r = y0 - ay; if (!dy && r > 0) return; r /= dy; if (dy < 0) { if (r < t0) return; if (r < t1) t1 = r; } else if (dy > 0) { if (r > t1) return; if (r > t0) t0 = r; } r = y1 - ay; if (!dy && r < 0) return; r /= dy; if (dy < 0) { if (r > t1) return; if (r > t0) t0 = r; } else if (dy > 0) { if (r < t0) return; if (r < t1) t1 = r; } if (t0 > 0) line.a = { x: ax + t0 * dx, y: ay + t0 * dy }; if (t1 < 1) line.b = { x: ax + t1 * dx, y: ay + t1 * dy }; return line; }; } var d3_geo_clipExtentMAX = 1e9; d3.geo.clipExtent = function() { var x0, y0, x1, y1, stream, clip, clipExtent = { stream: function(output) { if (stream) stream.valid = false; stream = clip(output); stream.valid = true; return stream; }, extent: function(_) { if (!arguments.length) return [ [ x0, y0 ], [ x1, y1 ] ]; clip = d3_geo_clipExtent(x0 = +_[0][0], y0 = +_[0][1], x1 = +_[1][0], y1 = +_[1][1]); if (stream) stream.valid = false, stream = null; return clipExtent; } }; return clipExtent.extent([ [ 0, 0 ], [ 960, 500 ] ]); }; function d3_geo_clipExtent(x0, y0, x1, y1) { return function(listener) { var listener_ = listener, bufferListener = d3_geo_clipBufferListener(), clipLine = d3_geom_clipLine(x0, y0, x1, y1), segments, polygon, ring; clean = true; segments = d3.merge(segments); var clipStartInside = insidePolygon([ x0, y1 ]), inside = clean && clipStartInside, visible = segments.length; if (inside || visible) { if (inside) { listener.lineStart(); interpolate(null, null, 1, listener); listener.lineEnd(); } if (visible) { d3_geo_clipPolygon(segments, compare, clipStartInside, interpolate, listener); } for (var j = 1, v = polygon[i], m = v.length, a = v[0], b; j < m; ++j) { if (b[1] > y && d3_cross2d(a, b, p) > 0) ++wn; } else { if (b[1] <= y && d3_cross2d(a, b, p) < 0) --wn; function pointVisible(x, y) { if (pointVisible(x, y)) listener.point(x, y); } var x__, y__, v__, x_, y_, v_, first, clean; x = Math.max(-d3_geo_clipExtentMAX, Math.min(d3_geo_clipExtentMAX, x)); y = Math.max(-d3_geo_clipExtentMAX, Math.min(d3_geo_clipExtentMAX, y)); var v = pointVisible(x, y); var l = { a: { x: x_, y: y_ }, b: { x: x, y: y } }; if (clipLine(l)) { listener.point(l.a.x, l.a.y); } listener.point(l.b.x, l.b.y); clean = false; } else if (v) { clean = false; return abs(p[0] - x0) <  ? direction > 0 ? 0 : 3 : abs(p[0] - x1) <  ? direction > 0 ? 2 : 1 : abs(p[1] - y0) <  ? direction > 0 ? 1 : 0 : direction > 0 ? 3 : 2; return comparePoints(a.x, b.x); } function d3_geo_conic(projectAt) { var 0 = 0, 1 =  / 3, m = d3_geo_projectionMutator(projectAt), p = m(0, 1); p.parallels = function(_) { if (!arguments.length) return [ 0 /  * 180, 1 /  * 180 ]; return m(0 = _[0] *  / 180, 1 = _[1] *  / 180); return p; } function d3_geo_conicEqualArea(0, 1) { var sin0 = Math.sin(0), n = (sin0 + Math.sin(1)) / 2, C = 1 + sin0 * (2 * n - sin0), 0 = Math.sqrt(C) / n; function forward(, ) { var  = Math.sqrt(C - 2 * n * Math.sin()) / n; return [  * Math.sin( *= n), 0 -  * Math.cos() ]; } forward.invert = function(x, y) { var 0_y = 0 - y; return [ Math.atan2(x, 0_y) / n, d3_asin((C - (x * x + 0_y * 0_y) * n * n) / (2 * n)) ]; }; return forward; } (d3.geo.conicEqualArea = function() { return d3_geo_conic(d3_geo_conicEqualArea); }).raw = d3_geo_conicEqualArea; d3.geo.albers = function() { return d3.geo.conicEqualArea().rotate([ 96, 0 ]).center([ -.6, 38.7 ]).parallels([ 29.5, 45.5 ]).scale(1070); }; d3.geo.albersUsa = function() { var lower48 = d3.geo.albers(); var alaska = d3.geo.conicEqualArea().rotate([ 154, 0 ]).center([ -2, 58.5 ]).parallels([ 55, 65 ]); var hawaii = d3.geo.conicEqualArea().rotate([ 157, 0 ]).center([ -3, 19.9 ]).parallels([ 8, 18 ]); var point, pointStream = { point: function(x, y) { point = [ x, y ]; } }, lower48Point, alaskaPoint, hawaiiPoint; function albersUsa(coordinates) { var x = coordinates[0], y = coordinates[1]; point = null; (lower48Point(x, y), point) || (alaskaPoint(x, y), point) || hawaiiPoint(x, y); return point; } albersUsa.invert = function(coordinates) { var k = lower48.scale(), t = lower48.translate(), x = (coordinates[0] - t[0]) / k, y = (coordinates[1] - t[1]) / k; return (y >= .12 && y < .234 && x >= -.425 && x < -.214 ? alaska : y >= .166 && y < .234 && x >= -.214 && x < -.115 ? hawaii : lower48).invert(coordinates); }; albersUsa.stream = function(stream) { var lower48Stream = lower48.stream(stream), alaskaStream = alaska.stream(stream), hawaiiStream = hawaii.stream(stream); return { point: function(x, y) { lower48Stream.point(x, y); alaskaStream.point(x, y); hawaiiStream.point(x, y); }, sphere: function() { lower48Stream.sphere(); alaskaStream.sphere(); hawaiiStream.sphere(); }, lineStart: function() { lower48Stream.lineStart(); alaskaStream.lineStart(); hawaiiStream.lineStart(); }, lineEnd: function() { lower48Stream.lineEnd(); alaskaStream.lineEnd(); hawaiiStream.lineEnd(); }, polygonStart: function() { lower48Stream.polygonStart(); alaskaStream.polygonStart(); hawaiiStream.polygonStart(); }, polygonEnd: function() { lower48Stream.polygonEnd(); alaskaStream.polygonEnd(); hawaiiStream.polygonEnd(); } }; }; albersUsa.precision = function(_) { if (!arguments.length) return lower48.precision(); lower48.precision(_); alaska.precision(_); hawaii.precision(_); return albersUsa; }; albersUsa.scale = function(_) { if (!arguments.length) return lower48.scale(); lower48.scale(_); alaska.scale(_ * .35); hawaii.scale(_); return albersUsa.translate(lower48.translate()); }; albersUsa.translate = function(_) { if (!arguments.length) return lower48.translate(); var k = lower48.scale(), x = +_[0], y = +_[1]; lower48Point = lower48.translate(_).clipExtent([ [ x - .455 * k, y - .238 * k ], [ x + .455 * k, y + .238 * k ] ]).stream(pointStream).point; alaskaPoint = alaska.translate([ x - .307 * k, y + .201 * k ]).clipExtent([ [ x - .425 * k + , y + .12 * k +  ], [ x - .214 * k - , y + .234 * k -  ] ]).stream(pointStream).point; hawaiiPoint = hawaii.translate([ x - .205 * k, y + .212 * k ]).clipExtent([ [ x - .214 * k + , y + .166 * k +  ], [ x - .115 * k - , y + .234 * k -  ] ]).stream(pointStream).point; return albersUsa; }; return albersUsa.scale(1070); }; var d3_geo_pathAreaSum, d3_geo_pathAreaPolygon, d3_geo_pathArea = { point: d3_noop, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: function() { d3_geo_pathAreaPolygon = 0; d3_geo_pathArea.lineStart = d3_geo_pathAreaRingStart; }, polygonEnd: function() { d3_geo_pathArea.lineStart = d3_geo_pathArea.lineEnd = d3_geo_pathArea.point = d3_noop; d3_geo_pathAreaSum += abs(d3_geo_pathAreaPolygon / 2); } }; function d3_geo_pathAreaRingStart() { var x00, y00, x0, y0; d3_geo_pathArea.point = function(x, y) { d3_geo_pathArea.point = nextPoint; x00 = x0 = x, y00 = y0 = y; }; function nextPoint(x, y) { d3_geo_pathAreaPolygon += y0 * x - x0 * y; x0 = x, y0 = y; } d3_geo_pathArea.lineEnd = function() { nextPoint(x00, y00); }; } var d3_geo_pathBoundsX0, d3_geo_pathBoundsY0, d3_geo_pathBoundsX1, d3_geo_pathBoundsY1; var d3_geo_pathBounds = { point: d3_geo_pathBoundsPoint, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: d3_noop, polygonEnd: d3_noop }; function d3_geo_pathBoundsPoint(x, y) { if (x < d3_geo_pathBoundsX0) d3_geo_pathBoundsX0 = x; if (x > d3_geo_pathBoundsX1) d3_geo_pathBoundsX1 = x; if (y < d3_geo_pathBoundsY0) d3_geo_pathBoundsY0 = y; if (y > d3_geo_pathBoundsY1) d3_geo_pathBoundsY1 = y; } function d3_geo_pathBuffer() { var pointCircle = d3_geo_pathBufferCircle(4.5), buffer = []; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointCircle = d3_geo_pathBufferCircle(_); return stream; }, result: function() { if (buffer.length) { var result = buffer.join(""""); buffer = []; return result; } } }; function point(x, y) { buffer.push(""M"", x, "","", y, pointCircle); } function pointLineStart(x, y) { buffer.push(""M"", x, "","", y); stream.point = pointLine; } function pointLine(x, y) { buffer.push(""L"", x, "","", y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { buffer.push(""Z""); } return stream; } function d3_geo_pathBufferCircle(radius) { return ""m0,"" + radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + -2 * radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + 2 * radius + ""z""; } var d3_geo_pathCentroid = { point: d3_geo_pathCentroidPoint, lineStart: d3_geo_pathCentroidLineStart, lineEnd: d3_geo_pathCentroidLineEnd, polygonStart: function() { d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidRingStart; }, polygonEnd: function() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidLineStart; d3_geo_pathCentroid.lineEnd = d3_geo_pathCentroidLineEnd; } }; function d3_geo_pathCentroidPoint(x, y) { d3_geo_centroidX0 += x; d3_geo_centroidY0 += y; ++d3_geo_centroidZ0; } function d3_geo_pathCentroidLineStart() { var x0, y0; d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; d3_geo_pathCentroidPoint(x0 = x, y0 = y); }; function nextPoint(x, y) { var dx = x - x0, dy = y - y0, z = Math.sqrt(dx * dx + dy * dy); d3_geo_centroidX1 += z * (x0 + x) / 2; d3_geo_centroidY1 += z * (y0 + y) / 2; d3_geo_centroidZ1 += z; d3_geo_pathCentroidPoint(x0 = x, y0 = y); } } function d3_geo_pathCentroidLineEnd() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; } function d3_geo_pathCentroidRingStart() { var x00, y00, x0, y0; d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; d3_geo_pathCentroidPoint(x00 = x0 = x, y00 = y0 = y); }; function nextPoint(x, y) { var dx = x - x0, dy = y - y0, z = Math.sqrt(dx * dx + dy * dy); d3_geo_centroidX1 += z * (x0 + x) / 2; d3_geo_centroidY1 += z * (y0 + y) / 2; d3_geo_centroidZ1 += z; z = y0 * x - x0 * y; d3_geo_centroidX2 += z * (x0 + x); d3_geo_centroidY2 += z * (y0 + y); d3_geo_centroidZ2 += z * 3; d3_geo_pathCentroidPoint(x0 = x, y0 = y); } d3_geo_pathCentroid.lineEnd = function() { nextPoint(x00, y00); }; } function d3_geo_pathContext(context) { var pointRadius = 4.5; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointRadius = _; return stream; }, result: d3_noop }; function point(x, y) { context.moveTo(x + pointRadius, y); context.arc(x, y, pointRadius, 0, ); } function pointLineStart(x, y) { context.moveTo(x, y); stream.point = pointLine; } function pointLine(x, y) { context.lineTo(x, y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { context.closePath(); } return stream; var 2 = .5, cosMinDistance = Math.cos(30 * d3_radians), maxDepth = 16; function resample(stream) { return (maxDepth ? resampleRecursive : resampleNone)(stream); } function resampleNone(stream) { return d3_geo_transformPoint(stream, function(x, y) { x = project(x, y); stream.point(x[0], x[1]); }); } function resampleRecursive(stream) { var 00, 00, x00, y00, a00, b00, c00, 0, x0, y0, a0, b0, c0; resample.lineStart = ringStart; function ringStart() { resample.point = ringPoint; resample.lineEnd = ringEnd; } function ringPoint(, ) { linePoint(00 = , 00 = ), x00 = x0, y00 = y0, a00 = a0, b00 = b0, c00 = c0; resample.point = linePoint; } function ringEnd() { resampleLineTo(x0, y0, 0, a0, b0, c0, x00, y00, 00, a00, b00, c00, maxDepth, stream); resample.lineEnd = lineEnd; lineEnd(); var a = a0 + a1, b = b0 + b1, c = c0 + c1, m = Math.sqrt(a * a + b * b + c * c), 2 = Math.asin(c /= m), 2 = abs(abs(c) - 1) <  || abs(0 - 1) <  ? (0 + 1) / 2 : Math.atan2(b, a), p = project(2, 2), x2 = p[0], y2 = p[1], dx2 = x2 - x0, dy2 = y2 - y0, dz = dy * dx2 - dx * dy2; if (dz * dz / d2 > 2 || abs((dx * dx2 + dy * dy2) / d2 - .5) > .3 || a0 * a1 + b0 * b1 + c0 * c1 < cosMinDistance) { d3.geo.path = function() { var pointRadius = 4.5, projection, context, projectStream, contextStream, cacheStream; function path(object) { if (object) { if (typeof pointRadius === ""function"") contextStream.pointRadius(+pointRadius.apply(this, arguments)); if (!cacheStream || !cacheStream.valid) cacheStream = projectStream(contextStream); d3.geo.stream(object, cacheStream); } return contextStream.result(); } path.area = function(object) { d3_geo_pathAreaSum = 0; d3.geo.stream(object, projectStream(d3_geo_pathArea)); return d3_geo_pathAreaSum; }; path.centroid = function(object) { d3_geo_centroidX0 = d3_geo_centroidY0 = d3_geo_centroidZ0 = d3_geo_centroidX1 = d3_geo_centroidY1 = d3_geo_centroidZ1 = d3_geo_centroidX2 = d3_geo_centroidY2 = d3_geo_centroidZ2 = 0; d3.geo.stream(object, projectStream(d3_geo_pathCentroid)); return d3_geo_centroidZ2 ? [ d3_geo_centroidX2 / d3_geo_centroidZ2, d3_geo_centroidY2 / d3_geo_centroidZ2 ] : d3_geo_centroidZ1 ? [ d3_geo_centroidX1 / d3_geo_centroidZ1, d3_geo_centroidY1 / d3_geo_centroidZ1 ] : d3_geo_centroidZ0 ? [ d3_geo_centroidX0 / d3_geo_centroidZ0, d3_geo_centroidY0 / d3_geo_centroidZ0 ] : [ NaN, NaN ]; }; path.bounds = function(object) { d3_geo_pathBoundsX1 = d3_geo_pathBoundsY1 = -(d3_geo_pathBoundsX0 = d3_geo_pathBoundsY0 = Infinity); d3.geo.stream(object, projectStream(d3_geo_pathBounds)); return [ [ d3_geo_pathBoundsX0, d3_geo_pathBoundsY0 ], [ d3_geo_pathBoundsX1, d3_geo_pathBoundsY1 ] ]; }; path.projection = function(_) { if (!arguments.length) return projection; projectStream = (projection = _) ? _.stream || d3_geo_pathProjectStream(_) : d3_identity; return reset(); }; path.context = function(_) { if (!arguments.length) return context; contextStream = (context = _) == null ? new d3_geo_pathBuffer() : new d3_geo_pathContext(_); if (typeof pointRadius !== ""function"") contextStream.pointRadius(pointRadius); return reset(); }; path.pointRadius = function(_) { if (!arguments.length) return pointRadius; pointRadius = typeof _ === ""function"" ? _ : (contextStream.pointRadius(+_), +_); return path; }; function reset() { cacheStream = null; return path; } return path.projection(d3.geo.albersUsa()).context(null); }; function d3_geo_pathProjectStream(project) { var resample = d3_geo_resample(function(x, y) { return project([ x * d3_degrees, y * d3_degrees ]); }); return function(stream) { return d3_geo_projectionRadians(resample(stream)); }; } d3.geo.transform = function(methods) { return { stream: function(stream) { var transform = new d3_geo_transform(stream); for (var k in methods) transform[k] = methods[k]; return transform; } }; }; function d3_geo_transform(stream) { this.stream = stream; } d3_geo_transform.prototype = { point: function(x, y) { this.stream.point(x, y); }, sphere: function() { this.stream.sphere(); }, lineStart: function() { this.stream.lineStart(); }, lineEnd: function() { this.stream.lineEnd(); }, polygonStart: function() { this.stream.polygonStart(); }, polygonEnd: function() { this.stream.polygonEnd(); } }; function d3_geo_transformPoint(stream, point) { return { point: point, sphere: function() { stream.sphere(); }, lineStart: function() { stream.lineStart(); }, lineEnd: function() { stream.lineEnd(); }, polygonStart: function() { stream.polygonStart(); }, polygonEnd: function() { stream.polygonEnd(); } }; } }), k = 150, x = 480, y = 250,  = 0,  = 0,  = 0,  = 0,  = 0, x, y, preclip = d3_geo_clipAntimeridian, postclip = d3_identity, clipAngle = null, clipExtent = null, stream; projection.stream = function(output) { if (stream) stream.valid = false; stream = d3_geo_projectionRadians(preclip(rotate, projectResample(postclip(output)))); stream.valid = true; return stream; return invalidate(); postclip = _ ? d3_geo_clipExtent(_[0][0], _[0][1], _[1][0], _[1][1]) : d3_identity; return invalidate(); return invalidate(); } function invalidate() { if (stream) stream.valid = false, stream = null; function d3_geo_projectionRadians(stream) { return d3_geo_transformPoint(stream, function(x, y) { stream.point(x * d3_radians, y * d3_radians); }); function d3_geo_identityRotation(, ) { return [  >  ?  -  :  < - ?  +  : ,  ]; } d3_geo_identityRotation.invert = d3_geo_equirectangular; function d3_geo_rotation(, , ) { return  ?  ||  ? d3_geo_compose(d3_geo_rotation(), d3_geo_rotation(, )) : d3_geo_rotation() :  ||  ? d3_geo_rotation(, ) : d3_geo_identityRotation; return  += , [  >  ?  -  :  < - ?  +  : ,  ]; return [ Math.atan2(y * cos - k * sin, x * cos - z * sin), d3_asin(k * cos + y * sin) ]; return [ Math.atan2(y * cos + z * sin, x * cos + k * sin), d3_asin(k * cos - x * sin) ]; var step = direction * precision; if (direction > 0 ? from < to : from > to) from += direction * ; } else { from = radius + direction * ; to = radius - .5 * step; } for (var point, t = from; direction > 0 ? t > to : t < to; t -= step) { return abs(x % DX) > ; }).map(x)).concat(d3.range(Math.ceil(y0 / dy) * dy, y1, dy).filter(function(y) { return abs(y % DY) > ; var sin = Math.sin( *= d3_radians), cos = Math.cos(), t = abs(( *= d3_radians) - 0), cos = Math.cos(t); if (F > 0) { if ( < -half + )  = -half + ; } else { if ( > half - )  = half - ; } var  = F / Math.pow(t(), n); return [ Math.atan2(x, 0_y) / n, 2 * Math.atan(Math.pow(F / , 1 / n)) - half ]; if (abs(n) < ) return d3_geo_equirectangular; return [ x, 2 * Math.atan(Math.exp(y)) - half ]; return [ Math.log(Math.tan( / 4 +  / 2)), - ]; return [ -y, 2 * Math.atan(Math.exp(x)) - half ]; var projection = d3_geo_mercatorProjection(d3_geo_transverseMercator), center = projection.center, rotate = projection.rotate; projection.center = function(_) { return _ ? center([ -_[1], _[0] ]) : (_ = center(), [ _[1], -_[0] ]); }; projection.rotate = function(_) { return _ ? rotate([ _[0], _[1], _.length > 2 ? _[2] + 90 : 90 ]) : (_ = rotate(), [ _[0], _[1], _[2] - 90 ]); }; return rotate([ 0, 0, 90 ]); function d3_geom_pointX(d) { function d3_geom_pointY(d) { d3.geom.hull = function(vertices) { var x = d3_geom_pointX, y = d3_geom_pointY; var fx = d3_functor(x), fy = d3_functor(y), i, n = data.length, points = [], flippedPoints = []; for (i = 0; i < n; i++) { points.push([ +fx.call(this, data[i], i), +fy.call(this, data[i], i), i ]); } points.sort(d3_geom_hullOrder); for (i = 0; i < n; i++) flippedPoints.push([ points[i][0], -points[i][1] ]); var upper = d3_geom_hullUpper(points), lower = d3_geom_hullUpper(flippedPoints); var skipLeft = lower[0] === upper[0], skipRight = lower[lower.length - 1] === upper[upper.length - 1], polygon = []; for (i = upper.length - 1; i >= 0; --i) polygon.push(data[points[upper[i]][2]]); for (i = +skipLeft; i < lower.length - skipRight; ++i) polygon.push(data[points[lower[i]][2]]); return polygon; function d3_geom_hullUpper(points) { var n = points.length, hull = [ 0, 1 ], hs = 2; for (var i = 2; i < n; i++) { while (hs > 1 && d3_cross2d(points[hull[hs - 2]], points[hull[hs - 1]], points[i]) <= 0) --hs; hull[hs++] = i; } return hull.slice(0, hs); } function d3_geom_hullOrder(a, b) { return a[0] - b[0] || a[1] - b[1]; d3_subclass(coordinates, d3_geom_polygonPrototype); return coordinates; }; var d3_geom_polygonPrototype = d3.geom.polygon.prototype = []; d3_geom_polygonPrototype.area = function() { var i = -1, n = this.length, a, b = this[n - 1], area = 0; while (++i < n) { a = b; b = this[i]; area += a[1] * b[0] - a[0] * b[1]; } return area * .5; }; d3_geom_polygonPrototype.centroid = function(k) { var i = -1, n = this.length, x = 0, y = 0, a, b = this[n - 1], c; if (!arguments.length) k = -1 / (6 * this.area()); while (++i < n) { a = b; b = this[i]; c = a[0] * b[1] - b[0] * a[1]; x += (a[0] + b[0]) * c; y += (a[1] + b[1]) * c; } return [ x * k, y * k ]; }; d3_geom_polygonPrototype.clip = function(subject) { var input, closed = d3_geom_polygonClosed(subject), i = -1, n = this.length - d3_geom_polygonClosed(this), j, m, a = this[n - 1], b, c, d; while (++i < n) { input = subject.slice(); subject.length = 0; b = this[i]; c = input[(m = input.length - closed) - 1]; j = -1; while (++j < m) { d = input[j]; if (d3_geom_polygonInside(d, a, b)) { if (!d3_geom_polygonInside(c, a, b)) { subject.push(d); } else if (d3_geom_polygonInside(c, a, b)) { subject.push(d3_geom_polygonIntersect(c, d, a, b)); } c = d; } if (closed) subject.push(subject[0]); a = b; } return subject; function d3_geom_polygonClosed(coordinates) { var a = coordinates[0], b = coordinates[coordinates.length - 1]; return !(a[0] - b[0] || a[1] - b[1]); } var d3_geom_voronoiEdges, d3_geom_voronoiCells, d3_geom_voronoiBeaches, d3_geom_voronoiBeachPool = [], d3_geom_voronoiFirstCircle, d3_geom_voronoiCircles, d3_geom_voronoiCirclePool = []; function d3_geom_voronoiBeach() { d3_geom_voronoiRedBlackNode(this); this.edge = this.site = this.circle = null; } function d3_geom_voronoiCreateBeach(site) { var beach = d3_geom_voronoiBeachPool.pop() || new d3_geom_voronoiBeach(); beach.site = site; return beach; } function d3_geom_voronoiDetachBeach(beach) { d3_geom_voronoiDetachCircle(beach); d3_geom_voronoiBeaches.remove(beach); d3_geom_voronoiBeachPool.push(beach); d3_geom_voronoiRedBlackNode(beach); } function d3_geom_voronoiRemoveBeach(beach) { var circle = beach.circle, x = circle.x, y = circle.cy, vertex = { x: x, y: y }, previous = beach.P, next = beach.N, disappearing = [ beach ]; d3_geom_voronoiDetachBeach(beach); var lArc = previous; while (lArc.circle && abs(x - lArc.circle.x) <  && abs(y - lArc.circle.cy) < ) { previous = lArc.P; disappearing.unshift(lArc); d3_geom_voronoiDetachBeach(lArc); lArc = previous; } disappearing.unshift(lArc); d3_geom_voronoiDetachCircle(lArc); var rArc = next; while (rArc.circle && abs(x - rArc.circle.x) <  && abs(y - rArc.circle.cy) < ) { next = rArc.N; disappearing.push(rArc); d3_geom_voronoiDetachBeach(rArc); rArc = next; } disappearing.push(rArc); d3_geom_voronoiDetachCircle(rArc); var nArcs = disappearing.length, iArc; for (iArc = 1; iArc < nArcs; ++iArc) { rArc = disappearing[iArc]; lArc = disappearing[iArc - 1]; d3_geom_voronoiSetEdgeEnd(rArc.edge, lArc.site, rArc.site, vertex); } lArc = disappearing[0]; rArc = disappearing[nArcs - 1]; rArc.edge = d3_geom_voronoiCreateEdge(lArc.site, rArc.site, null, vertex); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); } function d3_geom_voronoiAddBeach(site) { var x = site.x, directrix = site.y, lArc, rArc, dxl, dxr, node = d3_geom_voronoiBeaches._; while (node) { dxl = d3_geom_voronoiLeftBreakPoint(node, directrix) - x; if (dxl > ) node = node.L; else { dxr = x - d3_geom_voronoiRightBreakPoint(node, directrix); if (dxr > ) { if (!node.R) { lArc = node; break; } node = node.R; } else { if (dxl > -) { lArc = node.P; rArc = node; } else if (dxr > -) { lArc = node; rArc = node.N; } else { lArc = rArc = node; } break; } } } var newArc = d3_geom_voronoiCreateBeach(site); d3_geom_voronoiBeaches.insert(lArc, newArc); if (!lArc && !rArc) return; if (lArc === rArc) { d3_geom_voronoiDetachCircle(lArc); rArc = d3_geom_voronoiCreateBeach(lArc.site); d3_geom_voronoiBeaches.insert(newArc, rArc); newArc.edge = rArc.edge = d3_geom_voronoiCreateEdge(lArc.site, newArc.site); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); return; } if (!rArc) { newArc.edge = d3_geom_voronoiCreateEdge(lArc.site, newArc.site); return; } d3_geom_voronoiDetachCircle(lArc); d3_geom_voronoiDetachCircle(rArc); var lSite = lArc.site, ax = lSite.x, ay = lSite.y, bx = site.x - ax, by = site.y - ay, rSite = rArc.site, cx = rSite.x - ax, cy = rSite.y - ay, d = 2 * (bx * cy - by * cx), hb = bx * bx + by * by, hc = cx * cx + cy * cy, vertex = { x: (cy * hb - by * hc) / d + ax, y: (bx * hc - cx * hb) / d + ay d3_geom_voronoiSetEdgeEnd(rArc.edge, lSite, rSite, vertex); newArc.edge = d3_geom_voronoiCreateEdge(lSite, site, null, vertex); rArc.edge = d3_geom_voronoiCreateEdge(site, rSite, null, vertex); d3_geom_voronoiAttachCircle(lArc); d3_geom_voronoiAttachCircle(rArc); } function d3_geom_voronoiLeftBreakPoint(arc, directrix) { var site = arc.site, rfocx = site.x, rfocy = site.y, pby2 = rfocy - directrix; if (!pby2) return rfocx; var lArc = arc.P; if (!lArc) return -Infinity; site = lArc.site; var lfocx = site.x, lfocy = site.y, plby2 = lfocy - directrix; if (!plby2) return lfocx; var hl = lfocx - rfocx, aby2 = 1 / pby2 - 1 / plby2, b = hl / plby2; if (aby2) return (-b + Math.sqrt(b * b - 2 * aby2 * (hl * hl / (-2 * plby2) - lfocy + plby2 / 2 + rfocy - pby2 / 2))) / aby2 + rfocx; return (rfocx + lfocx) / 2; } function d3_geom_voronoiRightBreakPoint(arc, directrix) { var rArc = arc.N; if (rArc) return d3_geom_voronoiLeftBreakPoint(rArc, directrix); var site = arc.site; return site.y === directrix ? site.x : Infinity; } function d3_geom_voronoiCell(site) { this.site = site; this.edges = []; } d3_geom_voronoiCell.prototype.prepare = function() { var halfEdges = this.edges, iHalfEdge = halfEdges.length, edge; while (iHalfEdge--) { edge = halfEdges[iHalfEdge].edge; if (!edge.b || !edge.a) halfEdges.splice(iHalfEdge, 1); } halfEdges.sort(d3_geom_voronoiHalfEdgeOrder); return halfEdges.length; }; function d3_geom_voronoiCloseCells(extent) { var x0 = extent[0][0], x1 = extent[1][0], y0 = extent[0][1], y1 = extent[1][1], x2, y2, x3, y3, cells = d3_geom_voronoiCells, iCell = cells.length, cell, iHalfEdge, halfEdges, nHalfEdges, start, end; while (iCell--) { cell = cells[iCell]; if (!cell || !cell.prepare()) continue; halfEdges = cell.edges; nHalfEdges = halfEdges.length; iHalfEdge = 0; while (iHalfEdge < nHalfEdges) { end = halfEdges[iHalfEdge].end(), x3 = end.x, y3 = end.y; start = halfEdges[++iHalfEdge % nHalfEdges].start(), x2 = start.x, y2 = start.y; if (abs(x3 - x2) >  || abs(y3 - y2) > ) { halfEdges.splice(iHalfEdge, 0, new d3_geom_voronoiHalfEdge(d3_geom_voronoiCreateBorderEdge(cell.site, end, abs(x3 - x0) <  && y1 - y3 >  ? { x: x0, y: abs(x2 - x0) <  ? y2 : y1 } : abs(y3 - y1) <  && x1 - x3 >  ? { x: abs(y2 - y1) <  ? x2 : x1, y: y1 } : abs(x3 - x1) <  && y3 - y0 >  ? { x: x1, y: abs(x2 - x1) <  ? y2 : y0 } : abs(y3 - y0) <  && x3 - x0 >  ? { x: abs(y2 - y0) <  ? x2 : x0, y: y0 } : null), cell.site, null)); ++nHalfEdges; } } } } function d3_geom_voronoiHalfEdgeOrder(a, b) { return b.angle - a.angle; } function d3_geom_voronoiCircle() { d3_geom_voronoiRedBlackNode(this); this.x = this.y = this.arc = this.site = this.cy = null; } function d3_geom_voronoiAttachCircle(arc) { var lArc = arc.P, rArc = arc.N; if (!lArc || !rArc) return; var lSite = lArc.site, cSite = arc.site, rSite = rArc.site; if (lSite === rSite) return; var bx = cSite.x, by = cSite.y, ax = lSite.x - bx, ay = lSite.y - by, cx = rSite.x - bx, cy = rSite.y - by; var d = 2 * (ax * cy - ay * cx); if (d >= -2) return; var ha = ax * ax + ay * ay, hc = cx * cx + cy * cy, x = (cy * ha - ay * hc) / d, y = (ax * hc - cx * ha) / d, cy = y + by; var circle = d3_geom_voronoiCirclePool.pop() || new d3_geom_voronoiCircle(); circle.arc = arc; circle.site = cSite; circle.x = x + bx; circle.y = cy + Math.sqrt(x * x + y * y); circle.cy = cy; arc.circle = circle; var before = null, node = d3_geom_voronoiCircles._; while (node) { if (circle.y < node.y || circle.y === node.y && circle.x <= node.x) { if (node.L) node = node.L; else { before = node.P; break; } } else { if (node.R) node = node.R; else { before = node; break; } } } d3_geom_voronoiCircles.insert(before, circle); if (!before) d3_geom_voronoiFirstCircle = circle; } function d3_geom_voronoiDetachCircle(arc) { var circle = arc.circle; if (circle) { if (!circle.P) d3_geom_voronoiFirstCircle = circle.N; d3_geom_voronoiCircles.remove(circle); d3_geom_voronoiCirclePool.push(circle); d3_geom_voronoiRedBlackNode(circle); arc.circle = null; } } function d3_geom_voronoiClipEdges(extent) { var edges = d3_geom_voronoiEdges, clip = d3_geom_clipLine(extent[0][0], extent[0][1], extent[1][0], extent[1][1]), i = edges.length, e; while (i--) { e = edges[i]; if (!d3_geom_voronoiConnectEdge(e, extent) || !clip(e) || abs(e.a.x - e.b.x) <  && abs(e.a.y - e.b.y) < ) { e.a = e.b = null; edges.splice(i, 1); } } } function d3_geom_voronoiConnectEdge(edge, extent) { var vb = edge.b; if (vb) return true; var va = edge.a, x0 = extent[0][0], x1 = extent[1][0], y0 = extent[0][1], y1 = extent[1][1], lSite = edge.l, rSite = edge.r, lx = lSite.x, ly = lSite.y, rx = rSite.x, ry = rSite.y, fx = (lx + rx) / 2, fy = (ly + ry) / 2, fm, fb; if (ry === ly) { if (fx < x0 || fx >= x1) return; if (lx > rx) { if (!va) va = { x: fx, y: y0 }; else if (va.y >= y1) return; vb = { x: fx, y: y1 }; } else { if (!va) va = { x: fx, y: y1 }; else if (va.y < y0) return; vb = { x: fx, y: y0 }; } } else { fm = (lx - rx) / (ry - ly); fb = fy - fm * fx; if (fm < -1 || fm > 1) { if (lx > rx) { if (!va) va = { x: (y0 - fb) / fm, y: y0 }; else if (va.y >= y1) return; vb = { x: (y1 - fb) / fm, y: y1 }; } else { if (!va) va = { x: (y1 - fb) / fm, y: y1 }; else if (va.y < y0) return; vb = { x: (y0 - fb) / fm, y: y0 }; } } else { if (ly < ry) { if (!va) va = { x: x0, y: fm * x0 + fb }; else if (va.x >= x1) return; vb = { x: x1, y: fm * x1 + fb }; } else { if (!va) va = { x: x1, y: fm * x1 + fb }; else if (va.x < x0) return; vb = { x: x0, y: fm * x0 + fb }; } } } edge.a = va; edge.b = vb; return true; } function d3_geom_voronoiEdge(lSite, rSite) { this.l = lSite; this.r = rSite; this.a = this.b = null; } function d3_geom_voronoiCreateEdge(lSite, rSite, va, vb) { var edge = new d3_geom_voronoiEdge(lSite, rSite); d3_geom_voronoiEdges.push(edge); if (va) d3_geom_voronoiSetEdgeEnd(edge, lSite, rSite, va); if (vb) d3_geom_voronoiSetEdgeEnd(edge, rSite, lSite, vb); d3_geom_voronoiCells[lSite.i].edges.push(new d3_geom_voronoiHalfEdge(edge, lSite, rSite)); d3_geom_voronoiCells[rSite.i].edges.push(new d3_geom_voronoiHalfEdge(edge, rSite, lSite)); return edge; } function d3_geom_voronoiCreateBorderEdge(lSite, va, vb) { var edge = new d3_geom_voronoiEdge(lSite, null); edge.a = va; edge.b = vb; d3_geom_voronoiEdges.push(edge); return edge; } function d3_geom_voronoiSetEdgeEnd(edge, lSite, rSite, vertex) { if (!edge.a && !edge.b) { edge.a = vertex; edge.l = lSite; edge.r = rSite; } else if (edge.l === rSite) { edge.b = vertex; } else { edge.a = vertex; } } function d3_geom_voronoiHalfEdge(edge, lSite, rSite) { var va = edge.a, vb = edge.b; this.edge = edge; this.site = lSite; this.angle = rSite ? Math.atan2(rSite.y - lSite.y, rSite.x - lSite.x) : edge.l === lSite ? Math.atan2(vb.x - va.x, va.y - vb.y) : Math.atan2(va.x - vb.x, vb.y - va.y); } d3_geom_voronoiHalfEdge.prototype = { start: function() { return this.edge.l === this.site ? this.edge.a : this.edge.b; }, end: function() { return this.edge.l === this.site ? this.edge.b : this.edge.a; } function d3_geom_voronoiRedBlackTree() { this._ = null; } function d3_geom_voronoiRedBlackNode(node) { node.U = node.C = node.L = node.R = node.P = node.N = null; } d3_geom_voronoiRedBlackTree.prototype = { insert: function(after, node) { var parent, grandpa, uncle; if (after) { node.P = after; node.N = after.N; if (after.N) after.N.P = node; after.N = node; if (after.R) { after = after.R; while (after.L) after = after.L; after.L = node; } else { after.R = node; } parent = after; } else if (this._) { after = d3_geom_voronoiRedBlackFirst(this._); node.P = null; node.N = after; after.P = after.L = node; parent = after; } else { node.P = node.N = null; this._ = node; parent = null; } node.L = node.R = null; node.U = parent; node.C = true; after = node; while (parent && parent.C) { grandpa = parent.U; if (parent === grandpa.L) { uncle = grandpa.R; if (uncle && uncle.C) { parent.C = uncle.C = false; grandpa.C = true; after = grandpa; } else { if (after === parent.R) { d3_geom_voronoiRedBlackRotateLeft(this, parent); after = parent; parent = after.U; } parent.C = false; grandpa.C = true; d3_geom_voronoiRedBlackRotateRight(this, grandpa); uncle = grandpa.L; if (uncle && uncle.C) { parent.C = uncle.C = false; grandpa.C = true; after = grandpa; } else { if (after === parent.L) { d3_geom_voronoiRedBlackRotateRight(this, parent); after = parent; parent = after.U; } parent.C = false; grandpa.C = true; d3_geom_voronoiRedBlackRotateLeft(this, grandpa); } } parent = after.U; } this._.C = false; }, remove: function(node) { if (node.N) node.N.P = node.P; if (node.P) node.P.N = node.N; node.N = node.P = null; var parent = node.U, sibling, left = node.L, right = node.R, next, red; if (!left) next = right; else if (!right) next = left; else next = d3_geom_voronoiRedBlackFirst(right); if (parent) { if (parent.L === node) parent.L = next; else parent.R = next; } else { this._ = next; } if (left && right) { red = next.C; next.C = node.C; next.L = left; left.U = next; if (next !== right) { parent = next.U; next.U = node.U; node = next.R; parent.L = node; next.R = right; right.U = next; } else { next.U = parent; parent = next; node = next.R; } } else { red = node.C; node = next; } if (node) node.U = parent; if (red) return; if (node && node.C) { node.C = false; return; } do { if (node === this._) break; if (node === parent.L) { sibling = parent.R; if (sibling.C) { sibling.C = false; parent.C = true; d3_geom_voronoiRedBlackRotateLeft(this, parent); sibling = parent.R; } if (sibling.L && sibling.L.C || sibling.R && sibling.R.C) { if (!sibling.R || !sibling.R.C) { sibling.L.C = false; sibling.C = true; d3_geom_voronoiRedBlackRotateRight(this, sibling); sibling = parent.R; } sibling.C = parent.C; parent.C = sibling.R.C = false; d3_geom_voronoiRedBlackRotateLeft(this, parent); node = this._; break; } } else { sibling = parent.L; if (sibling.C) { sibling.C = false; parent.C = true; d3_geom_voronoiRedBlackRotateRight(this, parent); sibling = parent.L; } if (sibling.L && sibling.L.C || sibling.R && sibling.R.C) { if (!sibling.L || !sibling.L.C) { sibling.R.C = false; sibling.C = true; d3_geom_voronoiRedBlackRotateLeft(this, sibling); sibling = parent.L; } sibling.C = parent.C; parent.C = sibling.L.C = false; d3_geom_voronoiRedBlackRotateRight(this, parent); node = this._; sibling.C = true; node = parent; parent = parent.U; } while (!node.C); if (node) node.C = false; } }; function d3_geom_voronoiRedBlackRotateLeft(tree, node) { var p = node, q = node.R, parent = p.U; if (parent) { if (parent.L === p) parent.L = q; else parent.R = q; } else { tree._ = q; } q.U = parent; p.U = q; p.R = q.L; if (p.R) p.R.U = p; q.L = p; } function d3_geom_voronoiRedBlackRotateRight(tree, node) { var p = node, q = node.L, parent = p.U; if (parent) { if (parent.L === p) parent.L = q; else parent.R = q; } else { tree._ = q; } q.U = parent; p.U = q; p.L = q.R; if (p.L) p.L.U = p; q.R = p; } function d3_geom_voronoiRedBlackFirst(node) { while (node.L) node = node.L; return node; } function d3_geom_voronoi(sites, bbox) { var site = sites.sort(d3_geom_voronoiVertexOrder).pop(), x0, y0, circle; d3_geom_voronoiEdges = []; d3_geom_voronoiCells = new Array(sites.length); d3_geom_voronoiBeaches = new d3_geom_voronoiRedBlackTree(); d3_geom_voronoiCircles = new d3_geom_voronoiRedBlackTree(); while (true) { circle = d3_geom_voronoiFirstCircle; if (site && (!circle || site.y < circle.y || site.y === circle.y && site.x < circle.x)) { if (site.x !== x0 || site.y !== y0) { d3_geom_voronoiCells[site.i] = new d3_geom_voronoiCell(site); d3_geom_voronoiAddBeach(site); x0 = site.x, y0 = site.y; } site = sites.pop(); } else if (circle) { d3_geom_voronoiRemoveBeach(circle.arc); if (bbox) d3_geom_voronoiClipEdges(bbox), d3_geom_voronoiCloseCells(bbox); var diagram = { cells: d3_geom_voronoiCells, edges: d3_geom_voronoiEdges }; d3_geom_voronoiBeaches = d3_geom_voronoiCircles = d3_geom_voronoiEdges = d3_geom_voronoiCells = null; return diagram; } function d3_geom_voronoiVertexOrder(a, b) { return b.y - a.y || b.x - a.x; } d3.geom.voronoi = function(points) { var x = d3_geom_pointX, y = d3_geom_pointY, fx = x, fy = y, clipExtent = d3_geom_voronoiClipExtent; if (points) return voronoi(points); function voronoi(data) { var polygons = new Array(data.length), x0 = clipExtent[0][0], y0 = clipExtent[0][1], x1 = clipExtent[1][0], y1 = clipExtent[1][1]; d3_geom_voronoi(sites(data), clipExtent).cells.forEach(function(cell, i) { var edges = cell.edges, site = cell.site, polygon = polygons[i] = edges.length ? edges.map(function(e) { var s = e.start(); return [ s.x, s.y ]; }) : site.x >= x0 && site.x <= x1 && site.y >= y0 && site.y <= y1 ? [ [ x0, y1 ], [ x1, y1 ], [ x1, y0 ], [ x0, y0 ] ] : []; polygon.point = data[i]; }); return polygons; } function sites(data) { return data.map(function(d, i) { return { x: Math.round(fx(d, i) / ) * , y: Math.round(fy(d, i) / ) * , i: i }; }); } voronoi.links = function(data) { return d3_geom_voronoi(sites(data)).edges.filter(function(edge) { return edge.l && edge.r; }).map(function(edge) { return { source: data[edge.l.i], target: data[edge.r.i] }; }); }; voronoi.triangles = function(data) { var triangles = []; d3_geom_voronoi(sites(data)).cells.forEach(function(cell, i) { var site = cell.site, edges = cell.edges.sort(d3_geom_voronoiHalfEdgeOrder), j = -1, m = edges.length, e0, s0, e1 = edges[m - 1].edge, s1 = e1.l === site ? e1.r : e1.l; while (++j < m) { e0 = e1; s0 = s1; e1 = edges[j].edge; s1 = e1.l === site ? e1.r : e1.l; if (i < s0.i && i < s1.i && d3_geom_voronoiTriangleArea(site, s0, s1) < 0) { triangles.push([ data[i], data[s0.i], data[s1.i] ]); } } }); return triangles; }; voronoi.x = function(_) { return arguments.length ? (fx = d3_functor(x = _), voronoi) : x; }; voronoi.y = function(_) { return arguments.length ? (fy = d3_functor(y = _), voronoi) : y; }; voronoi.clipExtent = function(_) { if (!arguments.length) return clipExtent === d3_geom_voronoiClipExtent ? null : clipExtent; clipExtent = _ == null ? d3_geom_voronoiClipExtent : _; return voronoi; }; voronoi.size = function(_) { if (!arguments.length) return clipExtent === d3_geom_voronoiClipExtent ? null : clipExtent && clipExtent[1]; return voronoi.clipExtent(_ && [ [ 0, 0 ], _ ]); }; return voronoi; }; var d3_geom_voronoiClipExtent = [ [ -1e6, -1e6 ], [ 1e6, 1e6 ] ]; function d3_geom_voronoiTriangleArea(a, b, c) { return (a.x - c.x) * (b.y - a.y) - (a.x - b.x) * (c.y - a.y); } d3.geom.delaunay = function(vertices) { return d3.geom.voronoi().triangles(vertices); }; d3.geom.quadtree = function(points, x1, y1, x2, y2) { var x = d3_geom_pointX, y = d3_geom_pointY, compat; if (abs(nx - x) + abs(ny - y) < .01) { var xm = (x1 + x2) * .5, ym = (y1 + y2) * .5, right = x >= xm, below = y >= ym, i = below << 1 | right; if (right) x1 = xm; else x2 = xm; if (below) y1 = ym; else y2 = ym; root.find = function(point) { return d3_geom_quadtreeFind(root, point[0], point[1], x1_, y1_, x2_, y2_); }; quadtree.extent = function(_) { if (!arguments.length) return x1 == null ? null : [ [ x1, y1 ], [ x2, y2 ] ]; if (_ == null) x1 = y1 = x2 = y2 = null; else x1 = +_[0][0], y1 = +_[0][1], x2 = +_[1][0], y2 = +_[1][1]; return quadtree; }; quadtree.size = function(_) { if (!arguments.length) return x1 == null ? null : [ x2 - x1, y2 - y1 ]; if (_ == null) x1 = y1 = x2 = y2 = null; else x1 = y1 = 0, x2 = +_[0], y2 = +_[1]; function d3_geom_quadtreeFind(root, x, y, x0, y0, x3, y3) { var minDistance2 = Infinity, closestPoint; (function find(node, x1, y1, x2, y2) { if (x1 > x3 || y1 > y3 || x2 < x0 || y2 < y0) return; if (point = node.point) { var point, dx = x - node.x, dy = y - node.y, distance2 = dx * dx + dy * dy; if (distance2 < minDistance2) { var distance = Math.sqrt(minDistance2 = distance2); x0 = x - distance, y0 = y - distance; x3 = x + distance, y3 = y + distance; closestPoint = point; } } var children = node.nodes, xm = (x1 + x2) * .5, ym = (y1 + y2) * .5, right = x >= xm, below = y >= ym; for (var i = below << 1 | right, j = i + 4; i < j; ++i) { if (node = children[i & 3]) switch (i & 3) { case 0: find(node, x1, y1, xm, ym); break; case 1: find(node, xm, y1, x2, ym); break; case 2: find(node, x1, ym, xm, y2); break; case 3: find(node, xm, ym, x2, y2); break; } } })(root, x0, y0, x3, y3); return closestPoint; } i[k] = d3_interpolate(a[k], b[k]); d3.interpolateNumber = d3_interpolateNumber; function d3_interpolateNumber(a, b) { a = +a, b = +b; return function(t) { return a * (1 - t) + b * t; d3.interpolateString = d3_interpolateString; function d3_interpolateString(a, b) { var bi = d3_interpolate_numberA.lastIndex = d3_interpolate_numberB.lastIndex = 0, am, bm, bs, i = -1, s = [], q = []; a = a + """", b = b + """"; while ((am = d3_interpolate_numberA.exec(a)) && (bm = d3_interpolate_numberB.exec(b))) { if ((bs = bm.index) > bi) { bs = b.slice(bi, bs); if (s[i]) s[i] += bs; else s[++i] = bs; } if ((am = am[0]) === (bm = bm[0])) { if (s[i]) s[i] += bm; else s[++i] = bm; } else { s[++i] = null; q.push({ i: i, x: d3_interpolateNumber(am, bm) }); } bi = d3_interpolate_numberB.lastIndex; } if (bi < b.length) { bs = b.slice(bi); if (s[i]) s[i] += bs; else s[++i] = bs; } return s.length < 2 ? q[0] ? (b = q[0].x, function(t) { return b(t) + """"; }) : function() { return b; } : (b = q.length, function(t) { for (var i = 0, o; i < b; ++i) s[(o = q[i]).i] = o.x(t); return s.join(""""); }); } var d3_interpolate_numberA = /[-+]?(?:\d+\.?\d*|\.?\d+)(?:[eE][-+]?\d+)?/g, d3_interpolate_numberB = new RegExp(d3_interpolate_numberA.source, ""g""); return (t === ""string"" ? d3_rgb_names.has(b.toLowerCase()) || /^(#|rgb\(|hsl\()/i.test(b) ? d3_interpolateRgb : d3_interpolateString : b instanceof d3_color ? d3_interpolateRgb : Array.isArray(b) ? d3_interpolateArray : t === ""object"" && isNaN(b) ? d3_interpolateObject : d3_interpolateNumber)(a, b); var i = name.indexOf(""-""), t = i >= 0 ? name.slice(0, i) : name, m = i >= 0 ? name.slice(i + 1) : ""in""; return d3_ease_clamp(m(t.apply(null, d3_arraySlice.call(arguments, 1)))); return 1 - Math.cos(t * half); if (arguments.length) s = p /  * Math.asin(1 / a); else a = 1, s = p / 4; return function(t) { return 1 + a * Math.pow(2, -10 * t) * Math.sin((t - s) *  / p); d3.transform = function(string) { var g = d3_document.createElementNS(d3.ns.prefix.svg, ""g""); return (d3.transform = function(string) { if (string != null) { g.setAttribute(""transform"", string); var t = g.transform.baseVal.consolidate(); } return new d3_transform(t ? t.matrix : d3_transformIdentity); })(string); }; function d3_transform(m) { var r0 = [ m.a, m.b ], r1 = [ m.c, m.d ], kx = d3_transformNormalize(r0), kz = d3_transformDot(r0, r1), ky = d3_transformNormalize(d3_transformCombine(r1, r0, -kz)) || 0; if (r0[0] * r1[1] < r1[0] * r0[1]) { r0[0] *= -1; r0[1] *= -1; kx *= -1; kz *= -1; } this.rotate = (kx ? Math.atan2(r0[1], r0[0]) : Math.atan2(-r1[0], r1[1])) * d3_degrees; this.translate = [ m.e, m.f ]; this.scale = [ kx, ky ]; this.skew = ky ? Math.atan2(kz, ky) * d3_degrees : 0; } d3_transform.prototype.toString = function() { return ""translate("" + this.translate + "")rotate("" + this.rotate + "")skewX("" + this.skew + "")scale("" + this.scale + "")""; }; function d3_transformDot(a, b) { return a[0] * b[0] + a[1] * b[1]; } function d3_transformNormalize(a) { var k = Math.sqrt(d3_transformDot(a, a)); if (k) { a[0] /= k; a[1] /= k; } return k; } function d3_transformCombine(a, b, k) { a[0] += k * b[0]; a[1] += k * b[1]; return a; } var d3_transformIdentity = { a: 1, b: 0, c: 0, d: 1, e: 0, f: 0 }; d3.interpolateTransform = d3_interpolateTransform; function d3_interpolateTransformPop(s) { return s.length ? s.pop() + "","" : """"; } function d3_interpolateTranslate(ta, tb, s, q) { if (ta[0] !== tb[0] || ta[1] !== tb[1]) { var i = s.push(""translate("", null, "","", null, "")""); q.push({ i: i - 4, x: d3_interpolateNumber(ta[0], tb[0]) }, { i: i - 2, x: d3_interpolateNumber(ta[1], tb[1]) }); } else if (tb[0] || tb[1]) { s.push(""translate("" + tb + "")""); } } function d3_interpolateRotate(ra, rb, s, q) { if (ra !== rb) { if (ra - rb > 180) rb += 360; else if (rb - ra > 180) ra += 360; q.push({ i: s.push(d3_interpolateTransformPop(s) + ""rotate("", null, "")"") - 2, x: d3_interpolateNumber(ra, rb) }); } else if (rb) { s.push(d3_interpolateTransformPop(s) + ""rotate("" + rb + "")""); } } function d3_interpolateSkew(wa, wb, s, q) { if (wa !== wb) { q.push({ i: s.push(d3_interpolateTransformPop(s) + ""skewX("", null, "")"") - 2, x: d3_interpolateNumber(wa, wb) }); } else if (wb) { s.push(d3_interpolateTransformPop(s) + ""skewX("" + wb + "")""); } } function d3_interpolateScale(ka, kb, s, q) { if (ka[0] !== kb[0] || ka[1] !== kb[1]) { var i = s.push(d3_interpolateTransformPop(s) + ""scale("", null, "","", null, "")""); q.push({ i: i - 4, x: d3_interpolateNumber(ka[0], kb[0]) }, { i: i - 2, x: d3_interpolateNumber(ka[1], kb[1]) }); } else if (kb[0] !== 1 || kb[1] !== 1) { s.push(d3_interpolateTransformPop(s) + ""scale("" + kb + "")""); } } function d3_interpolateTransform(a, b) { var s = [], q = []; a = d3.transform(a), b = d3.transform(b); d3_interpolateTranslate(a.translate, b.translate, s, q); d3_interpolateRotate(a.rotate, b.rotate, s, q); d3_interpolateSkew(a.skew, b.skew, s, q); d3_interpolateScale(a.scale, b.scale, s, q); a = b = null; return function(t) { var i = -1, n = q.length, o; while (++i < n) s[(o = q[i]).i] = o.x(t); return s.join(""""); }; } function d3_uninterpolateNumber(a, b) { b = (b -= a = +a) || 1 / b; return function(x) { return (x - a) / b; b = (b -= a = +a) || 1 / b; return function(x) { return Math.max(0, Math.min(1, (x - a) / b)); k = ( - padding * n) / k; value: groupSums[di] var force = {}, event = d3.dispatch(""start"", ""tick"", ""end""), timer, size = [ 1, 1 ], drag, alpha, friction = .9, linkDistance = d3_layout_forceLinkDistance, linkStrength = d3_layout_forceLinkStrength, charge = -30, chargeDistance2 = d3_layout_forceChargeDistance2, gravity = .1, theta2 = .64, nodes = [], links = [], distances, strengths, charges; var dx = quad.cx - node.x, dy = quad.cy - node.y, dw = x2 - x1, dn = dx * dx + dy * dy; if (dw * dw / theta2 < dn) { if (dn < chargeDistance2) { var k = quad.charge / dn; node.px -= dx * k; node.py -= dy * k; } if (quad.point && dn && dn < chargeDistance2) { var k = quad.pointCharge / dn; timer = null; t.x -= x * (k = s.weight + t.weight ? s.weight / (s.weight + t.weight) : .5); force.chargeDistance = function(x) { if (!arguments.length) return Math.sqrt(chargeDistance2); chargeDistance2 = x * x; return force; }; if (!arguments.length) return Math.sqrt(theta2); theta2 = x * x; if (x > 0) { alpha = x; } else { timer.c = null, timer.t = NaN, timer = null; event.end({ type: ""end"", alpha: alpha = 0 }); } timer = d3_timer(force.tick); var i, n = nodes.length, m = links.length, w = size[0], h = size[1], neighbors, o; if (!neighbors) { neighbors = new Array(n); var candidates = neighbors[i], j = -1, l = candidates.length, x; while (++j < l) if (!isNaN(x = candidates[j][dimension])) return x; return Math.random() * size; var d3_layout_forceLinkDistance = 20, d3_layout_forceLinkStrength = 1, d3_layout_forceChargeDistance2 = Infinity; function hierarchy(root) { var stack = [ root ], nodes = [], node; root.depth = 0; while ((node = stack.pop()) != null) { nodes.push(node); if ((childs = children.call(hierarchy, node, node.depth)) && (n = childs.length)) { var n, childs, child; while (--n >= 0) { stack.push(child = childs[n]); child.parent = node; child.depth = node.depth + 1; } if (value) node.value = 0; node.children = childs; } else { if (value) node.value = +value.call(hierarchy, node, node.depth) || 0; delete node.children; } } d3_layout_hierarchyVisitAfter(root, function(node) { var childs, parent; if (sort && (childs = node.children)) childs.sort(sort); if (value && (parent = node.parent)) parent.value += node.value; }); if (value) { d3_layout_hierarchyVisitBefore(root, function(node) { if (node.children) node.value = 0; }); d3_layout_hierarchyVisitAfter(root, function(node) { var parent; if (!node.children) node.value = +value.call(hierarchy, node, node.depth) || 0; if (parent = node.parent) parent.value += node.value; }); } function d3_layout_hierarchyVisitBefore(node, callback) { var nodes = [ node ]; while ((node = nodes.pop()) != null) { callback(node); if ((children = node.children) && (n = children.length)) { var n, children; while (--n >= 0) nodes.push(children[n]); } } } function d3_layout_hierarchyVisitAfter(node, callback) { var nodes = [ node ], nodes2 = []; while ((node = nodes.pop()) != null) { nodes2.push(node); if ((children = node.children) && (n = children.length)) { var i = -1, n, children; while (++i < n) nodes.push(children[i]); } } while ((node = nodes2.pop()) != null) { callback(node); } } var value = Number, sort = d3_layout_pieSortByValue, startAngle = 0, endAngle = , padAngle = 0; function pie(data) { var n = data.length, values = data.map(function(d, i) { }), a = +(typeof startAngle === ""function"" ? startAngle.apply(this, arguments) : startAngle), da = (typeof endAngle === ""function"" ? endAngle.apply(this, arguments) : endAngle) - a, p = Math.min(Math.abs(da) / n, +(typeof padAngle === ""function"" ? padAngle.apply(this, arguments) : padAngle)), pa = p * (da < 0 ? -1 : 1), sum = d3.sum(values), k = sum ? (da - n * pa) / sum : 0, index = d3.range(n), arcs = [], v; index.forEach(function(i) { value: v = values[i], endAngle: a += v * k + pa, padAngle: p pie.value = function(_) { value = _; pie.sort = function(_) { sort = _; pie.startAngle = function(_) { startAngle = _; pie.endAngle = function(_) { endAngle = _; return pie; }; pie.padAngle = function(_) { if (!arguments.length) return padAngle; padAngle = _; if (!(n = data.length)) return data; var m = series[0].length, n, i, j, o; d3.layout.pack = function() { var hierarchy = d3.layout.hierarchy().sort(d3_layout_packSort), padding = 0, size = [ 1, 1 ], radius; function pack(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0], w = size[0], h = size[1], r = radius == null ? Math.sqrt : typeof radius === ""function"" ? radius : function() { return radius; }; root.x = root.y = 0; d3_layout_hierarchyVisitAfter(root, function(d) { d.r = +r(d.value); d3_layout_hierarchyVisitAfter(root, d3_layout_packSiblings); if (padding) { var dr = padding * (radius ? 1 : Math.max(2 * root.r / w, 2 * root.r / h)) / 2; d3_layout_hierarchyVisitAfter(root, function(d) { d3_layout_hierarchyVisitAfter(root, d3_layout_packSiblings); d3_layout_hierarchyVisitAfter(root, function(d) { } d3_layout_packTransform(root, w / 2, h / 2, radius ? 1 : 1 / Math.max(2 * root.r / w, 2 * root.r / h)); pack.size = function(_) { size = _; return pack; }; pack.radius = function(_) { if (!arguments.length) return radius; radius = _ == null || typeof _ === ""function"" ? _ : +_; return .999 * dr * dr > dx * dx + dy * dy; d3.layout.tree = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ], nodeSize = null; function tree(d, i) { var nodes = hierarchy.call(this, d, i), root0 = nodes[0], root1 = wrapTree(root0); d3_layout_hierarchyVisitAfter(root1, firstWalk), root1.parent.m = -root1.z; d3_layout_hierarchyVisitBefore(root1, secondWalk); if (nodeSize) d3_layout_hierarchyVisitBefore(root0, sizeNode); else { var left = root0, right = root0, bottom = root0; d3_layout_hierarchyVisitBefore(root0, function(node) { if (node.x < left.x) left = node; if (node.x > right.x) right = node; if (node.depth > bottom.depth) bottom = node; }); var tx = separation(left, right) / 2 - left.x, kx = size[0] / (right.x + separation(right, left) / 2 + tx), ky = size[1] / (bottom.depth || 1); d3_layout_hierarchyVisitBefore(root0, function(node) { node.x = (node.x + tx) * kx; node.y = node.depth * ky; }); } return nodes; } function wrapTree(root0) { var root1 = { A: null, children: [ root0 ] }, queue = [ root1 ], node1; while ((node1 = queue.pop()) != null) { for (var children = node1.children, child, i = 0, n = children.length; i < n; ++i) { queue.push((children[i] = child = { _: children[i], parent: node1, children: (child = children[i].children) && child.slice() || [], A: null, a: null, z: 0, m: 0, c: 0, s: 0, t: null, i: i }).a = child); } } return root1.children[0]; } function firstWalk(v) { var children = v.children, siblings = v.parent.children, w = v.i ? siblings[v.i - 1] : null; if (children.length) { d3_layout_treeShift(v); var midpoint = (children[0].z + children[children.length - 1].z) / 2; if (w) { v.z = w.z + separation(v._, w._); v.m = v.z - midpoint; } else { v.z = midpoint; } } else if (w) { v.z = w.z + separation(v._, w._); } v.parent.A = apportion(v, w, v.parent.A || siblings[0]); } function secondWalk(v) { v._.x = v.z + v.parent.m; v.m += v.parent.m; } function apportion(v, w, ancestor) { if (w) { var vip = v, vop = v, vim = w, vom = vip.parent.children[0], sip = vip.m, sop = vop.m, sim = vim.m, som = vom.m, shift; while (vim = d3_layout_treeRight(vim), vip = d3_layout_treeLeft(vip), vim && vip) { vom = d3_layout_treeLeft(vom); vop = d3_layout_treeRight(vop); vop.a = v; shift = vim.z + sim - vip.z - sip + separation(vim._, vip._); if (shift > 0) { d3_layout_treeMove(d3_layout_treeAncestor(vim, v, ancestor), v, shift); sip += shift; sop += shift; } sim += vim.m; sip += vip.m; som += vom.m; sop += vop.m; } if (vim && !d3_layout_treeRight(vop)) { vop.t = vim; vop.m += sim - sop; } if (vip && !d3_layout_treeLeft(vom)) { vom.t = vip; vom.m += sip - som; ancestor = v; } } return ancestor; } function sizeNode(node) { node.x *= size[0]; node.y = node.depth * size[1]; } tree.separation = function(x) { if (!arguments.length) return separation; separation = x; return tree; }; tree.size = function(x) { if (!arguments.length) return nodeSize ? null : size; nodeSize = (size = x) == null ? sizeNode : null; return tree; }; tree.nodeSize = function(x) { if (!arguments.length) return nodeSize ? size : null; nodeSize = (size = x) == null ? null : sizeNode; return tree; }; return d3_layout_hierarchyRebind(tree, hierarchy); }; function d3_layout_treeSeparation(a, b) { return a.parent == b.parent ? 1 : 2; } function d3_layout_treeLeft(v) { var children = v.children; return children.length ? children[0] : v.t; } function d3_layout_treeRight(v) { var children = v.children, n; return (n = children.length) ? children[n - 1] : v.t; } function d3_layout_treeMove(wm, wp, shift) { var change = shift / (wp.i - wm.i); wp.c -= change; wp.s += shift; wm.c += change; wp.z += shift; wp.m += shift; } function d3_layout_treeShift(v) { var shift = 0, change = 0, children = v.children, i = children.length, w; while (--i >= 0) { w = children[i]; w.z += shift; w.m += shift; shift += w.s + (change += w.c); } } function d3_layout_treeAncestor(vim, v, ancestor) { return vim.a.parent === v.parent ? vim.a : ancestor; } d3.layout.cluster = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ], nodeSize = false; d3_layout_hierarchyVisitAfter(root, function(node) { d3_layout_hierarchyVisitAfter(root, nodeSize ? function(node) { node.x = (node.x - root.x) * size[0]; node.y = (root.y - node.y) * size[1]; } : function(node) { if (!arguments.length) return nodeSize ? null : size; nodeSize = (size = x) == null; return cluster; }; cluster.nodeSize = function(x) { if (!arguments.length) return nodeSize ? size : null; nodeSize = (size = x) != null; root.x = root.y = 0; if (root.value) root.dx = size[0], root.dy = size[1]; else root.dx = root.dy = 0; bates: function(m) { var random = d3.random.irwinHall(m); return function() { return random() / m; }; }, return s; domain[i0] = nice.floor(x0); domain[i1] = nice.ceil(x1); function d3_scale_niceStep(step) { return step ? { floor: function(x) { return Math.floor(x / step) * step; }, ceil: function(x) { return Math.ceil(x / step) * step; } } : d3_scale_niceIdentity; } var d3_scale_niceIdentity = { floor: d3_identity, ceil: d3_identity }; scale.nice = function(m) { d3_scale_linearNice(domain, m); function d3_scale_linearNice(domain, m) { d3_scale_nice(domain, d3_scale_niceStep(d3_scale_linearTickRange(domain, m)[2])); d3_scale_nice(domain, d3_scale_niceStep(d3_scale_linearTickRange(domain, m)[2])); return domain; if (m == null) m = 10; var range = d3_scale_linearTickRange(domain, m); if (format) { var match = d3_format_re.exec(format); match.shift(); if (match[8] === ""s"") { var prefix = d3.formatPrefix(Math.max(abs(range[0]), abs(range[1]))); if (!match[7]) match[7] = ""."" + d3_scale_linearPrecision(prefix.scale(range[2])); match[8] = ""f""; format = d3.format(match.join("""")); return function(d) { return format(prefix.scale(d)) + prefix.symbol; }; } if (!match[7]) match[7] = ""."" + d3_scale_linearFormatPrecision(match[8], range); format = match.join(""""); } else { format = "",."" + d3_scale_linearPrecision(range[2]) + ""f""; } return d3.format(format); } var d3_scale_linearFormatSignificant = { s: 1, g: 1, p: 1, r: 1, e: 1 }; function d3_scale_linearPrecision(value) { return -Math.floor(Math.log(value) / Math.LN10 + .01); } function d3_scale_linearFormatPrecision(type, range) { var p = d3_scale_linearPrecision(range[2]); return type in d3_scale_linearFormatSignificant ? Math.abs(p - d3_scale_linearPrecision(Math.max(abs(range[0]), abs(range[1])))) + +(type !== ""e"") : p - (type === ""%"") * 2; return d3_scale_log(d3.scale.linear().domain([ 0, 1 ]), 10, true, [ 1, 10 ]); function d3_scale_log(linear, base, positive, domain) { function log(x) { return (positive ? Math.log(x < 0 ? 0 : x) : -Math.log(x > 0 ? 0 : -x)) / Math.log(base); } function pow(x) { return positive ? Math.pow(base, x) : -Math.pow(base, -x); } if (!arguments.length) return domain; positive = x[0] >= 0; linear.domain((domain = x.map(Number)).map(log)); linear.domain(domain.map(log)); var niced = d3_scale_nice(domain.map(log), positive ? Math : d3_scale_logNiceNegative); linear.domain(niced); domain = niced.map(pow); var extent = d3_scaleExtent(domain), ticks = [], u = extent[0], v = extent[1], i = Math.floor(log(u)), j = Math.ceil(log(v)), n = base % 1 ? 2 : base; if (isFinite(j - i)) { if (positive) { for (;i < j; i++) for (var k = 1; k < n; k++) ticks.push(pow(i) * k); ticks.push(pow(i)); } else { ticks.push(pow(i)); for (;i++ < j; ) for (var k = n - 1; k > 0; k--) ticks.push(pow(i) * k); if (!arguments.length) return d3_scale_logFormat; if (arguments.length < 2) format = d3_scale_logFormat; else if (typeof format !== ""function"") format = d3.format(format); var k = Math.max(1, base * n / scale.ticks().length); return function(d) { var i = d / pow(Math.round(log(d))); if (i * base < base - .5) i *= base; return i <= k ? format(d) : """"; return d3_scale_log(linear.copy(), base, positive, domain); var d3_scale_logFormat = d3.format("".0e""), d3_scale_logNiceNegative = { floor: function(x) { return -Math.ceil(-x); }, ceil: function(x) { return -Math.floor(-x); } d3.scale.pow = function() { return d3_scale_pow(d3.scale.linear(), 1, [ 0, 1 ]); }; function d3_scale_pow(linear, exponent, domain) { if (!arguments.length) return domain; linear.domain((domain = x.map(Number)).map(powp)); return d3_scale_linearTicks(domain, m); return d3_scale_linearTickFormat(domain, m, format); scale.nice = function(m) { return scale.domain(d3_scale_linearNice(domain, m)); linear.domain(domain.map(powp)); return scale; return d3_scale_pow(linear.copy(), exponent, domain); return range[((index.get(x) || (ranger.t === ""range"" ? index.set(x, domain.push(x)) : NaN)) - 1) % range.length]; var start = x[0], stop = x[1], step = domain.length < 2 ? (start = (start + stop) / 2, 0) : (stop - start) / (domain.length - 1 + padding); range = steps(start + step * padding / 2, step); scale.rangeRoundPoints = function(x, padding) { if (arguments.length < 2) padding = 0; var start = x[0], stop = x[1], step = domain.length < 2 ? (start = stop = Math.round((start + stop) / 2), 0) : (stop - start) / (domain.length - 1 + padding) | 0; range = steps(start + Math.round(step * padding / 2 + (stop - start - (domain.length - 1 + padding) * step) / 2), step); rangeBand = 0; ranger = { t: ""rangeRoundPoints"", a: arguments }; return scale; }; var reverse = x[1] < x[0], start = x[reverse - 0], stop = x[1 - reverse], step = Math.floor((stop - start) / (domain.length - padding + 2 * outerPadding)); range = steps(start + Math.round((stop - start - (domain.length - padding) * step) / 2), step); var d3_category10 = [ 2062260, 16744206, 2924588, 14034728, 9725885, 9197131, 14907330, 8355711, 12369186, 1556175 ].map(d3_rgbString); var d3_category20 = [ 2062260, 11454440, 16744206, 16759672, 2924588, 10018698, 14034728, 16750742, 9725885, 12955861, 9197131, 12885140, 14907330, 16234194, 8355711, 13092807, 12369186, 14408589, 1556175, 10410725 ].map(d3_rgbString); var d3_category20b = [ 3750777, 5395619, 7040719, 10264286, 6519097, 9216594, 11915115, 13556636, 9202993, 12426809, 15186514, 15190932, 8666169, 11356490, 14049643, 15177372, 8077683, 10834324, 13528509, 14589654 ].map(d3_rgbString); var d3_category20c = [ 3244733, 7057110, 10406625, 13032431, 15095053, 16616764, 16625259, 16634018, 3253076, 7652470, 10607003, 13101504, 7695281, 10394312, 12369372, 14342891, 6513507, 9868950, 12434877, 14277081 ].map(d3_rgbString); if (!isNaN(x = +x)) return range[d3.bisect(thresholds, x)]; domain = x.map(d3_number).filter(d3_numeric).sort(d3_ascending); scale.invertExtent = function(y) { y = range.indexOf(y); return y < 0 ? [ NaN, NaN ] : [ y > 0 ? thresholds[y - 1] : domain[0], y < thresholds.length ? thresholds[y] : domain[domain.length - 1] ]; }; scale.invertExtent = function(y) { y = range.indexOf(y); y = y < 0 ? NaN : y / kx + x0; return [ y, y + 1 / kx ]; }; if (x <= x) return range[d3.bisect(domain, x)]; scale.invertExtent = function(y) { y = range.indexOf(y); return [ domain[y - 1], domain[y] ]; }; d3.svg = {}; function d3_zero() { return 0; } d3.svg.arc = function() { var innerRadius = d3_svg_arcInnerRadius, outerRadius = d3_svg_arcOuterRadius, cornerRadius = d3_zero, padRadius = d3_svg_arcAuto, startAngle = d3_svg_arcStartAngle, endAngle = d3_svg_arcEndAngle, padAngle = d3_svg_arcPadAngle; function arc() { var r0 = Math.max(0, +innerRadius.apply(this, arguments)), r1 = Math.max(0, +outerRadius.apply(this, arguments)), a0 = startAngle.apply(this, arguments) - half, a1 = endAngle.apply(this, arguments) - half, da = Math.abs(a1 - a0), cw = a0 > a1 ? 0 : 1; if (r1 < r0) rc = r1, r1 = r0, r0 = rc; if (da >= ) return circleSegment(r1, cw) + (r0 ? circleSegment(r0, 1 - cw) : """") + ""Z""; var rc, cr, rp, ap, p0 = 0, p1 = 0, x0, y0, x1, y1, x2, y2, x3, y3, path = []; if (ap = (+padAngle.apply(this, arguments) || 0) / 2) { rp = padRadius === d3_svg_arcAuto ? Math.sqrt(r0 * r0 + r1 * r1) : +padRadius.apply(this, arguments); if (!cw) p1 *= -1; if (r1) p1 = d3_asin(rp / r1 * Math.sin(ap)); if (r0) p0 = d3_asin(rp / r0 * Math.sin(ap)); } if (r1) { x0 = r1 * Math.cos(a0 + p1); y0 = r1 * Math.sin(a0 + p1); x1 = r1 * Math.cos(a1 - p1); y1 = r1 * Math.sin(a1 - p1); var l1 = Math.abs(a1 - a0 - 2 * p1) <=  ? 0 : 1; if (p1 && d3_svg_arcSweep(x0, y0, x1, y1) === cw ^ l1) { var h1 = (a0 + a1) / 2; x0 = r1 * Math.cos(h1); y0 = r1 * Math.sin(h1); x1 = y1 = null; } } else { x0 = y0 = 0; } if (r0) { x2 = r0 * Math.cos(a1 - p0); y2 = r0 * Math.sin(a1 - p0); x3 = r0 * Math.cos(a0 + p0); y3 = r0 * Math.sin(a0 + p0); var l0 = Math.abs(a0 - a1 + 2 * p0) <=  ? 0 : 1; if (p0 && d3_svg_arcSweep(x2, y2, x3, y3) === 1 - cw ^ l0) { var h0 = (a0 + a1) / 2; x2 = r0 * Math.cos(h0); y2 = r0 * Math.sin(h0); x3 = y3 = null; } } else { x2 = y2 = 0; } if (da >  && (rc = Math.min(Math.abs(r1 - r0) / 2, +cornerRadius.apply(this, arguments))) > .001) { cr = r0 < r1 ^ cw ? 0 : 1; var rc1 = rc, rc0 = rc; if (da < ) { var oc = x3 == null ? [ x2, y2 ] : x1 == null ? [ x0, y0 ] : d3_geom_polygonIntersect([ x0, y0 ], [ x3, y3 ], [ x1, y1 ], [ x2, y2 ]), ax = x0 - oc[0], ay = y0 - oc[1], bx = x1 - oc[0], by = y1 - oc[1], kc = 1 / Math.sin(Math.acos((ax * bx + ay * by) / (Math.sqrt(ax * ax + ay * ay) * Math.sqrt(bx * bx + by * by))) / 2), lc = Math.sqrt(oc[0] * oc[0] + oc[1] * oc[1]); rc0 = Math.min(rc, (r0 - lc) / (kc - 1)); rc1 = Math.min(rc, (r1 - lc) / (kc + 1)); } if (x1 != null) { var t30 = d3_svg_arcCornerTangents(x3 == null ? [ x2, y2 ] : [ x3, y3 ], [ x0, y0 ], r1, rc1, cw), t12 = d3_svg_arcCornerTangents([ x1, y1 ], [ x2, y2 ], r1, rc1, cw); if (rc === rc1) { path.push(""M"", t30[0], ""A"", rc1, "","", rc1, "" 0 0,"", cr, "" "", t30[1], ""A"", r1, "","", r1, "" 0 "", 1 - cw ^ d3_svg_arcSweep(t30[1][0], t30[1][1], t12[1][0], t12[1][1]), "","", cw, "" "", t12[1], ""A"", rc1, "","", rc1, "" 0 0,"", cr, "" "", t12[0]); } else { path.push(""M"", t30[0], ""A"", rc1, "","", rc1, "" 0 1,"", cr, "" "", t12[0]); } } else { path.push(""M"", x0, "","", y0); } if (x3 != null) { var t03 = d3_svg_arcCornerTangents([ x0, y0 ], [ x3, y3 ], r0, -rc0, cw), t21 = d3_svg_arcCornerTangents([ x2, y2 ], x1 == null ? [ x0, y0 ] : [ x1, y1 ], r0, -rc0, cw); if (rc === rc0) { path.push(""L"", t21[0], ""A"", rc0, "","", rc0, "" 0 0,"", cr, "" "", t21[1], ""A"", r0, "","", r0, "" 0 "", cw ^ d3_svg_arcSweep(t21[1][0], t21[1][1], t03[1][0], t03[1][1]), "","", 1 - cw, "" "", t03[1], ""A"", rc0, "","", rc0, "" 0 0,"", cr, "" "", t03[0]); } else { path.push(""L"", t21[0], ""A"", rc0, "","", rc0, "" 0 0,"", cr, "" "", t03[0]); } } else { path.push(""L"", x2, "","", y2); } } else { path.push(""M"", x0, "","", y0); if (x1 != null) path.push(""A"", r1, "","", r1, "" 0 "", l1, "","", cw, "" "", x1, "","", y1); path.push(""L"", x2, "","", y2); if (x3 != null) path.push(""A"", r0, "","", r0, "" 0 "", l0, "","", 1 - cw, "" "", x3, "","", y3); } path.push(""Z""); return path.join(""""); } function circleSegment(r1, cw) { return ""M0,"" + r1 + ""A"" + r1 + "","" + r1 + "" 0 1,"" + cw + "" 0,"" + -r1 + ""A"" + r1 + "","" + r1 + "" 0 1,"" + cw + "" 0,"" + r1; arc.cornerRadius = function(v) { if (!arguments.length) return cornerRadius; cornerRadius = d3_functor(v); return arc; }; arc.padRadius = function(v) { if (!arguments.length) return padRadius; padRadius = v == d3_svg_arcAuto ? d3_svg_arcAuto : d3_functor(v); return arc; }; arc.padAngle = function(v) { if (!arguments.length) return padAngle; padAngle = d3_functor(v); return arc; }; arc.centroid = function() { var r = (+innerRadius.apply(this, arguments) + +outerRadius.apply(this, arguments)) / 2, a = (+startAngle.apply(this, arguments) + +endAngle.apply(this, arguments)) / 2 - half; var d3_svg_arcAuto = ""auto""; function d3_svg_arcPadAngle(d) { return d && d.padAngle; } function d3_svg_arcSweep(x0, y0, x1, y1) { return (x0 - x1) * y0 - (y0 - y1) * x0 > 0 ? 0 : 1; } function d3_svg_arcCornerTangents(p0, p1, r1, rc, cw) { var x01 = p0[0] - p1[0], y01 = p0[1] - p1[1], lo = (cw ? rc : -rc) / Math.sqrt(x01 * x01 + y01 * y01), ox = lo * y01, oy = -lo * x01, x1 = p0[0] + ox, y1 = p0[1] + oy, x2 = p1[0] + ox, y2 = p1[1] + oy, x3 = (x1 + x2) / 2, y3 = (y1 + y2) / 2, dx = x2 - x1, dy = y2 - y1, d2 = dx * dx + dy * dy, r = r1 - rc, D = x1 * y2 - x2 * y1, d = (dy < 0 ? -1 : 1) * Math.sqrt(Math.max(0, r * r * d2 - D * D)), cx0 = (D * dy - dx * d) / d2, cy0 = (-D * dx - dy * d) / d2, cx1 = (D * dy + dx * d) / d2, cy1 = (-D * dx + dy * d) / d2, dx0 = cx0 - x3, dy0 = cy0 - y3, dx1 = cx1 - x3, dy1 = cy1 - y3; if (dx0 * dx0 + dy0 * dy0 > dx1 * dx1 + dy1 * dy1) cx0 = cx1, cy0 = cy1; return [ [ cx0 - ox, cy0 - oy ], [ cx0 * r1 / r, cy0 * r1 / r ] ]; } function d3_svg_line(projection) { var x = d3_geom_pointX, y = d3_geom_pointY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, tension = .7; function line(data) { var segments = [], points = [], i = -1, n = data.length, d, fx = d3_functor(x), fy = d3_functor(y); function segment() { segments.push(""M"", interpolate(projection(points), tension)); } while (++i < n) { if (defined.call(this, d = data[i], i)) { points.push([ +fx.call(this, d, i), +fy.call(this, d, i) ]); } else if (points.length) { segment(); points = []; } } if (points.length) segment(); return segments.length ? segments.join("""") : null; } line.x = function(_) { if (!arguments.length) return x; x = _; return line; }; line.y = function(_) { if (!arguments.length) return y; y = _; return line; }; line.defined = function(_) { if (!arguments.length) return defined; defined = _; return line; }; line.interpolate = function(_) { if (!arguments.length) return interpolateKey; if (typeof _ === ""function"") interpolateKey = interpolate = _; else interpolateKey = (interpolate = d3_svg_lineInterpolators.get(_) || d3_svg_lineLinear).key; return line; }; line.tension = function(_) { if (!arguments.length) return tension; tension = _; return line; }; return line; } d3.svg.line = function() { return d3_svg_line(d3_identity); }; var d3_svg_lineInterpolators = d3.map({ linear: d3_svg_lineLinear, ""linear-closed"": d3_svg_lineLinearClosed, step: d3_svg_lineStep, ""step-before"": d3_svg_lineStepBefore, ""step-after"": d3_svg_lineStepAfter, basis: d3_svg_lineBasis, ""basis-open"": d3_svg_lineBasisOpen, ""basis-closed"": d3_svg_lineBasisClosed, bundle: d3_svg_lineBundle, cardinal: d3_svg_lineCardinal, ""cardinal-open"": d3_svg_lineCardinalOpen, ""cardinal-closed"": d3_svg_lineCardinalClosed, monotone: d3_svg_lineMonotone }); d3_svg_lineInterpolators.forEach(function(key, value) { value.key = key; value.closed = /-closed$/.test(key); }); function d3_svg_lineLinear(points) { return points.length > 1 ? points.join(""L"") : points + ""Z""; } function d3_svg_lineLinearClosed(points) { return points.join(""L"") + ""Z""; } function d3_svg_lineStep(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""H"", (p[0] + (p = points[i])[0]) / 2, ""V"", p[1]); if (n > 1) path.push(""H"", p[0]); return path.join(""""); } function d3_svg_lineStepBefore(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""V"", (p = points[i])[1], ""H"", p[0]); return path.join(""""); } function d3_svg_lineStepAfter(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""H"", (p = points[i])[0], ""V"", p[1]); return path.join(""""); } function d3_svg_lineCardinalOpen(points, tension) { return points.length < 4 ? d3_svg_lineLinear(points) : points[1] + d3_svg_lineHermite(points.slice(1, -1), d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineCardinalClosed(points, tension) { return points.length < 3 ? d3_svg_lineLinearClosed(points) : points[0] + d3_svg_lineHermite((points.push(points[0]), points), d3_svg_lineCardinalTangents([ points[points.length - 2] ].concat(points, [ points[1] ]), tension)); } function d3_svg_lineCardinal(points, tension) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineHermite(points, tangents) { if (tangents.length < 1 || points.length != tangents.length && points.length != tangents.length + 2) { return d3_svg_lineLinear(points); } var quad = points.length != tangents.length, path = """", p0 = points[0], p = points[1], t0 = tangents[0], t = t0, pi = 1; if (quad) { path += ""Q"" + (p[0] - t0[0] * 2 / 3) + "","" + (p[1] - t0[1] * 2 / 3) + "","" + p[0] + "","" + p[1]; p0 = points[1]; pi = 2; } if (tangents.length > 1) { t = tangents[1]; p = points[pi]; pi++; path += ""C"" + (p0[0] + t0[0]) + "","" + (p0[1] + t0[1]) + "","" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; for (var i = 2; i < tangents.length; i++, pi++) { p = points[pi]; t = tangents[i]; path += ""S"" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; } } if (quad) { var lp = points[pi]; path += ""Q"" + (p[0] + t[0] * 2 / 3) + "","" + (p[1] + t[1] * 2 / 3) + "","" + lp[0] + "","" + lp[1]; } return path; } function d3_svg_lineCardinalTangents(points, tension) { var tangents = [], a = (1 - tension) / 2, p0, p1 = points[0], p2 = points[1], i = 1, n = points.length; while (++i < n) { p0 = p1; p1 = p2; p2 = points[i]; tangents.push([ a * (p2[0] - p0[0]), a * (p2[1] - p0[1]) ]); } return tangents; } function d3_svg_lineBasis(points) { if (points.length < 3) return d3_svg_lineLinear(points); var i = 1, n = points.length, pi = points[0], x0 = pi[0], y0 = pi[1], px = [ x0, x0, x0, (pi = points[1])[0] ], py = [ y0, y0, y0, pi[1] ], path = [ x0, "","", y0, ""L"", d3_svg_lineDot4(d3_svg_lineBasisBezier3, px), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, py) ]; points.push(points[n - 1]); while (++i <= n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } points.pop(); path.push(""L"", pi); return path.join(""""); } function d3_svg_lineBasisOpen(points) { if (points.length < 4) return d3_svg_lineLinear(points); var path = [], i = -1, n = points.length, pi, px = [ 0 ], py = [ 0 ]; while (++i < 3) { pi = points[i]; px.push(pi[0]); py.push(pi[1]); } path.push(d3_svg_lineDot4(d3_svg_lineBasisBezier3, px) + "","" + d3_svg_lineDot4(d3_svg_lineBasisBezier3, py)); --i; while (++i < n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBasisClosed(points) { var path, i = -1, n = points.length, m = n + 4, pi, px = [], py = []; while (++i < 4) { pi = points[i % n]; px.push(pi[0]); py.push(pi[1]); } path = [ d3_svg_lineDot4(d3_svg_lineBasisBezier3, px), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, py) ]; --i; while (++i < m) { pi = points[i % n]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBundle(points, tension) { var n = points.length - 1; if (n) { var x0 = points[0][0], y0 = points[0][1], dx = points[n][0] - x0, dy = points[n][1] - y0, i = -1, p, t; while (++i <= n) { p = points[i]; t = i / n; p[0] = tension * p[0] + (1 - tension) * (x0 + t * dx); p[1] = tension * p[1] + (1 - tension) * (y0 + t * dy); } } return d3_svg_lineBasis(points); } function d3_svg_lineDot4(a, b) { return a[0] * b[0] + a[1] * b[1] + a[2] * b[2] + a[3] * b[3]; } var d3_svg_lineBasisBezier1 = [ 0, 2 / 3, 1 / 3, 0 ], d3_svg_lineBasisBezier2 = [ 0, 1 / 3, 2 / 3, 0 ], d3_svg_lineBasisBezier3 = [ 0, 1 / 6, 2 / 3, 1 / 6 ]; function d3_svg_lineBasisBezier(path, x, y) { path.push(""C"", d3_svg_lineDot4(d3_svg_lineBasisBezier1, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier1, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, y)); } function d3_svg_lineSlope(p0, p1) { return (p1[1] - p0[1]) / (p1[0] - p0[0]); } function d3_svg_lineFiniteDifferences(points) { var i = 0, j = points.length - 1, m = [], p0 = points[0], p1 = points[1], d = m[0] = d3_svg_lineSlope(p0, p1); while (++i < j) { m[i] = (d + (d = d3_svg_lineSlope(p0 = p1, p1 = points[i + 1]))) / 2; } m[i] = d; return m; } function d3_svg_lineMonotoneTangents(points) { var tangents = [], d, a, b, s, m = d3_svg_lineFiniteDifferences(points), i = -1, j = points.length - 1; while (++i < j) { d = d3_svg_lineSlope(points[i], points[i + 1]); if (abs(d) < ) { m[i] = m[i + 1] = 0; } else { a = m[i] / d; b = m[i + 1] / d; s = a * a + b * b; if (s > 9) { s = d * 3 / Math.sqrt(s); m[i] = s * a; m[i + 1] = s * b; } } } i = -1; while (++i <= j) { s = (points[Math.min(j, i + 1)][0] - points[Math.max(0, i - 1)][0]) / (6 * (1 + m[i] * m[i])); tangents.push([ s || 0, m[i] * s || 0 ]); } return tangents; } function d3_svg_lineMonotone(points) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineMonotoneTangents(points)); } a = point[1] - half; var x0 = d3_geom_pointX, x1 = d3_geom_pointX, y0 = 0, y1 = d3_geom_pointY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, interpolateReverse = interpolate, L = ""L"", tension = .7; var subgroup = f.call(self, d, i), r = radius.call(self, subgroup, i), a0 = startAngle.call(self, subgroup, i) - half, a1 = endAngle.call(self, subgroup, i) - half; var d = projection.apply(this, arguments), r = d[0], a = d[1] - half; d3_selectionPrototype.transition = function(name) { var id = d3_transitionInheritId || ++d3_transitionId, ns = d3_transitionNamespace(name), subgroups = [], subgroup, node, transition = d3_transitionInherit || { time: Date.now(), ease: d3_ease_cubicInOut, delay: 0, duration: 250 }; if (node = group[i]) d3_transitionNode(node, i, ns, id, transition); subgroup.push(node); } } return d3_transition(subgroups, ns, id); }; d3_selectionPrototype.interrupt = function(name) { return this.each(name == null ? d3_selection_interrupt : d3_selection_interruptNS(d3_transitionNamespace(name))); }; var d3_selection_interrupt = d3_selection_interruptNS(d3_transitionNamespace()); function d3_selection_interruptNS(ns) { return function() { var lock, activeId, active; if ((lock = this[ns]) && (active = lock[activeId = lock.active])) { active.timer.c = null; active.timer.t = NaN; if (--lock.count) delete lock[activeId]; else delete this[ns]; lock.active += .5; active.event && active.event.interrupt.call(this, this.__data__, active.index); } }; } function d3_transition(groups, ns, id) { d3_subclass(groups, d3_transitionPrototype); groups.namespace = ns; groups.id = id; return groups; } var d3_transitionPrototype = [], d3_transitionId = 0, d3_transitionInheritId, d3_transitionInherit; d3_transitionPrototype.call = d3_selectionPrototype.call; d3_transitionPrototype.empty = d3_selectionPrototype.empty; d3_transitionPrototype.node = d3_selectionPrototype.node; d3_transitionPrototype.size = d3_selectionPrototype.size; d3.transition = function(selection, name) { return selection && selection.transition ? d3_transitionInheritId ? selection.transition(name) : selection : d3.selection().transition(selection); }; d3.transition.prototype = d3_transitionPrototype; d3_transitionPrototype.select = function(selector) { var id = this.id, ns = this.namespace, subgroups = [], subgroup, subnode, node; selector = d3_selection_selector(selector); for (var j = -1, m = this.length; ++j < m; ) { subgroups.push(subgroup = []); for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if ((node = group[i]) && (subnode = selector.call(node, node.__data__, i, j))) { d3_transitionNode(subnode, i, ns, id, node[ns][id]); return d3_transition(subgroups, ns, id); var id = this.id, ns = this.namespace, subgroups = [], subgroup, subnodes, node, subnode, transition; selector = d3_selection_selectorAll(selector); transition = node[ns][id]; subnodes = selector.call(node, node.__data__, i, j); if (subnode = subnodes[k]) d3_transitionNode(subnode, k, ns, id, transition); return d3_transition(subgroups, ns, id); if ((node = group[i]) && filter.call(node, node.__data__, i, j)) { return d3_transition(subgroups, this.namespace, this.id); var id = this.id, ns = this.namespace; if (arguments.length < 2) return this.node()[ns][id].tween.get(name); return d3_selection_each(this, tween == null ? function(node) { node[ns][id].tween.remove(name); } : function(node) { node[ns][id].tween.set(name, tween); var id = groups.id, ns = groups.namespace; return d3_selection_each(groups, typeof value === ""function"" ? function(node, i, j) { node[ns][id].tween.set(name, tween(value.call(node, node.__data__, i, j))); } : (value = tween(value), function(node) { node[ns][id].tween.set(name, value); var interpolate = nameNS == ""transform"" ? d3_interpolateTransform : d3_interpolate, name = d3.ns.qualify(nameNS); var a = d3_window(this).getComputedStyle(this, null).getPropertyValue(name), i; return a !== b && (i = d3_interpolate(a, b), function(t) { var f = tween.call(this, d, i, d3_window(this).getComputedStyle(this, null).getPropertyValue(name)); var ns = this.namespace; if (this[ns].count < 2 && (p = this.parentNode)) p.removeChild(this); var id = this.id, ns = this.namespace; if (arguments.length < 1) return this.node()[ns][id].ease; node[ns][id].ease = value; var id = this.id, ns = this.namespace; if (arguments.length < 1) return this.node()[ns][id].delay; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node[ns][id].delay = +value.call(node, node.__data__, i, j); } : (value = +value, function(node) { node[ns][id].delay = value; var id = this.id, ns = this.namespace; if (arguments.length < 1) return this.node()[ns][id].duration; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node[ns][id].duration = Math.max(1, value.call(node, node.__data__, i, j)); } : (value = Math.max(1, value), function(node) { node[ns][id].duration = value; var id = this.id, ns = this.namespace; try { d3_transitionInheritId = id; d3_selection_each(this, function(node, i, j) { d3_transitionInherit = node[ns][id]; type.call(node, node.__data__, i, j); }); } finally { d3_transitionInherit = inherit; d3_transitionInheritId = inheritId; } var transition = node[ns][id]; (transition.event || (transition.event = d3.dispatch(""start"", ""end"", ""interrupt""))).on(type, listener); var id0 = this.id, id1 = ++d3_transitionId, ns = this.namespace, subgroups = [], subgroup, group, node, transition; transition = node[ns][id0]; d3_transitionNode(node, i, ns, id1, { time: transition.time, ease: transition.ease, delay: transition.delay + transition.duration, duration: transition.duration }); return d3_transition(subgroups, ns, id1); function d3_transitionNamespace(name) { return name == null ? ""__transition__"" : ""__transition_"" + name + ""__""; } function d3_transitionNode(node, i, ns, id, inherit) { var lock = node[ns] || (node[ns] = { }), transition = lock[id], time, timer, duration, ease, tweens; function schedule(elapsed) { var delay = transition.delay; timer.t = delay + time; if (delay <= elapsed) return start(elapsed - delay); timer.c = start; } function start(elapsed) { var activeId = lock.active, active = lock[activeId]; if (active) { active.timer.c = null; active.timer.t = NaN; --lock.count; delete lock[activeId]; active.event && active.event.interrupt.call(node, node.__data__, active.index); } for (var cancelId in lock) { if (+cancelId < id) { var cancel = lock[cancelId]; cancel.timer.c = null; cancel.timer.t = NaN; --lock.count; delete lock[cancelId]; } } timer.c = tick; d3_timer(function() { if (timer.c && tick(elapsed || 1)) { timer.c = null; timer.t = NaN; } return 1; }, 0, time); lock.active = id; transition.event && transition.event.start.call(node, node.__data__, i); tweens = []; transition.tween.forEach(function(key, value) { if (value = value.call(node, node.__data__, i)) { tweens.push(value); } }); ease = transition.ease; duration = transition.duration; } function tick(elapsed) { var t = elapsed / duration, e = ease(t), n = tweens.length; while (n > 0) { tweens[--n].call(node, e); } if (t >= 1) { transition.event && transition.event.end.call(node, node.__data__, i); if (--lock.count) delete lock[id]; else delete node[ns]; return 1; } } if (!transition) { time = inherit.time; timer = d3_timer(schedule, 0, time); timer: timer, duration: inherit.duration, ease: inherit.ease, index: i inherit = null; var scale = d3.scale.linear(), orient = d3_svg_axisDefaultOrient, innerTickSize = 6, outerTickSize = 6, tickPadding = 3, tickArguments_ = [ 10 ], tickValues = null, tickFormat_; var scale0 = this.__chart__ || scale, scale1 = this.__chart__ = scale.copy(); var ticks = tickValues == null ? scale1.ticks ? scale1.ticks.apply(scale1, tickArguments_) : scale1.domain() : tickValues, tickFormat = tickFormat_ == null ? scale1.tickFormat ? scale1.tickFormat.apply(scale1, tickArguments_) : d3_identity : tickFormat_, tick = g.selectAll("".tick"").data(ticks, scale1), tickEnter = tick.enter().insert(""g"", "".domain"").attr(""class"", ""tick"").style(""opacity"", ), tickExit = d3.transition(tick.exit()).style(""opacity"", ).remove(), tickUpdate = d3.transition(tick.order()).style(""opacity"", 1), tickSpacing = Math.max(innerTickSize, 0) + tickPadding, tickTransform; var range = d3_scaleRange(scale1), path = g.selectAll("".domain"").data([ 0 ]), pathUpdate = (path.enter().append(""path"").attr(""class"", ""domain""), var lineEnter = tickEnter.select(""line""), lineUpdate = tickUpdate.select(""line""), text = tick.select(""text"").text(tickFormat), textEnter = tickEnter.select(""text""), textUpdate = tickUpdate.select(""text""), sign = orient === ""top"" || orient === ""left"" ? -1 : 1, x1, x2, y1, y2; if (orient === ""bottom"" || orient === ""top"") { tickTransform = d3_svg_axisX, x1 = ""x"", y1 = ""y"", x2 = ""x2"", y2 = ""y2""; text.attr(""dy"", sign < 0 ? ""0em"" : "".71em"").style(""text-anchor"", ""middle""); pathUpdate.attr(""d"", ""M"" + range[0] + "","" + sign * outerTickSize + ""V0H"" + range[1] + ""V"" + sign * outerTickSize); } else { tickTransform = d3_svg_axisY, x1 = ""y"", y1 = ""x"", x2 = ""y2"", y2 = ""x2""; text.attr(""dy"", "".32em"").style(""text-anchor"", sign < 0 ? ""end"" : ""start""); pathUpdate.attr(""d"", ""M"" + sign * outerTickSize + "","" + range[0] + ""H0V"" + range[1] + ""H"" + sign * outerTickSize); } lineEnter.attr(y2, sign * innerTickSize); textEnter.attr(y1, sign * tickSpacing); lineUpdate.attr(x2, 0).attr(y2, sign * innerTickSize); textUpdate.attr(x1, 0).attr(y1, sign * tickSpacing); if (scale1.rangeBand) { var x = scale1, dx = x.rangeBand() / 2; scale0 = scale1 = function(d) { return x(d) + dx; }; } else if (scale0.rangeBand) { scale0 = scale1; } else { tickExit.call(tickTransform, scale1, scale0); } tickEnter.call(tickTransform, scale0, scale1); tickUpdate.call(tickTransform, scale1, scale1); tickArguments_ = d3_array(arguments); axis.tickSize = function(x) { var n = arguments.length; if (!n) return innerTickSize; innerTickSize = +x; outerTickSize = +arguments[n - 1]; return axis; }; axis.innerTickSize = function(x) { if (!arguments.length) return innerTickSize; innerTickSize = +x; return axis; }; axis.outerTickSize = function(x) { if (!arguments.length) return outerTickSize; outerTickSize = +x; axis.tickSubdivide = function() { return arguments.length && axis; function d3_svg_axisX(selection, x0, x1) { selection.attr(""transform"", function(d) { var v0 = x0(d); return ""translate("" + (isFinite(v0) ? v0 : x1(d)) + "",0)""; function d3_svg_axisY(selection, y0, y1) { selection.attr(""transform"", function(d) { var v0 = y0(d); return ""translate(0,"" + (isFinite(v0) ? v0 : y1(d)) + "")""; d3.svg.brush = function() { var event = d3_eventDispatch(brush, ""brushstart"", ""brush"", ""brushend""), x = null, y = null, xExtent = [ 0, 0 ], yExtent = [ 0, 0 ], xExtentDomain, yExtentDomain, xClamp = true, yClamp = true, resizes = d3_svg_brushResizes[0]; var g = d3.select(this).style(""pointer-events"", ""all"").style(""-webkit-tap-highlight-color"", ""rgba(0,0,0,0)"").on(""mousedown.brush"", brushstart).on(""touchstart.brush"", brushstart); var background = g.selectAll("".background"").data([ 0 ]); background.enter().append(""rect"").attr(""class"", ""background"").style(""visibility"", ""hidden"").style(""cursor"", ""crosshair""); g.selectAll("".extent"").data([ 0 ]).enter().append(""rect"").attr(""class"", ""extent"").style(""cursor"", ""move""); var resize = g.selectAll("".resize"").data(resizes, d3_identity); resize.exit().remove(); resize.enter().append(""g"").attr(""class"", function(d) { resize.style(""display"", brush.empty() ? ""none"" : null); var gUpdate = d3.transition(g), backgroundUpdate = d3.transition(background), range; if (x) { range = d3_scaleRange(x); backgroundUpdate.attr(""x"", range[0]).attr(""width"", range[1] - range[0]); redrawX(gUpdate); range = d3_scaleRange(y); backgroundUpdate.attr(""y"", range[0]).attr(""height"", range[1] - range[0]); redrawY(gUpdate); } redraw(gUpdate); brush.event = function(g) { g.each(function() { var event_ = event.of(this, arguments), extent1 = { x: xExtent, y: yExtent, i: xExtentDomain, j: yExtentDomain }, extent0 = this.__chart__ || extent1; this.__chart__ = extent1; if (d3_transitionInheritId) { d3.select(this).transition().each(""start.brush"", function() { xExtentDomain = extent0.i; yExtentDomain = extent0.j; xExtent = extent0.x; yExtent = extent0.y; event_({ type: ""brushstart"" }); }).tween(""brush:brush"", function() { var xi = d3_interpolateArray(xExtent, extent1.x), yi = d3_interpolateArray(yExtent, extent1.y); xExtentDomain = yExtentDomain = null; return function(t) { xExtent = extent1.x = xi(t); yExtent = extent1.y = yi(t); event_({ type: ""brush"", mode: ""resize"" }); }; }).each(""end.brush"", function() { xExtentDomain = extent1.i; yExtentDomain = extent1.j; event_({ type: ""brush"", mode: ""resize"" }); event_({ type: ""brushend"" }); }); } else { event_({ type: ""brushstart"" }); event_({ type: ""brush"", mode: ""resize"" }); event_({ type: ""brushend"" }); } }); }; return ""translate("" + xExtent[+/e$/.test(d)] + "","" + yExtent[+/^s/.test(d)] + "")""; g.select("".extent"").attr(""x"", xExtent[0]); g.selectAll("".extent,.n>rect,.s>rect"").attr(""width"", xExtent[1] - xExtent[0]); g.select("".extent"").attr(""y"", yExtent[0]); g.selectAll("".extent,.e>rect,.w>rect"").attr(""height"", yExtent[1] - yExtent[0]); var target = this, eventTarget = d3.select(d3.event.target), event_ = event.of(target, arguments), g = d3.select(target), resizing = eventTarget.datum(), resizingX = !/^(n|s)$/.test(resizing) && x, resizingY = !/^(e|w)$/.test(resizing) && y, dragging = eventTarget.classed(""extent""), dragRestore = d3_event_dragSuppress(target), center, origin = d3.mouse(target), offset; var w = d3.select(d3_window(target)).on(""keydown.brush"", keydown).on(""keyup.brush"", keyup); if (d3.event.changedTouches) { w.on(""touchmove.brush"", brushmove).on(""touchend.brush"", brushend); } else { w.on(""mousemove.brush"", brushmove).on(""mouseup.brush"", brushend); } g.interrupt().selectAll(""*"").interrupt(); if (dragging) { origin[0] = xExtent[0] - origin[0]; origin[1] = yExtent[0] - origin[1]; offset = [ xExtent[1 - ex] - origin[0], yExtent[1 - ey] - origin[1] ]; origin[0] = xExtent[ex]; origin[1] = yExtent[ey]; origin[0] -= xExtent[1]; origin[1] -= yExtent[1]; d3_eventPreventDefault(); origin[0] += xExtent[1]; origin[1] += yExtent[1]; d3_eventPreventDefault(); var point = d3.mouse(target), moved = false; if (!center) center = [ (xExtent[0] + xExtent[1]) / 2, (yExtent[0] + yExtent[1]) / 2 ]; origin[0] = xExtent[+(point[0] < center[0])]; origin[1] = yExtent[+(point[1] < center[1])]; var range = d3_scaleRange(scale), r0 = range[0], r1 = range[1], position = origin[i], extent = i ? yExtent : xExtent, size = extent[1] - extent[0], min, max; min = (i ? yClamp : xClamp) ? Math.max(r0, Math.min(r1, point[i])) : point[i]; if (extent[0] != min || extent[1] != max) { if (i) yExtentDomain = null; else xExtentDomain = null; extent[0] = min; extent[1] = max; dragRestore(); brush.clamp = function(z) { if (!arguments.length) return x && y ? [ xClamp, yClamp ] : x ? xClamp : y ? yClamp : null; if (x && y) xClamp = !!z[0], yClamp = !!z[1]; else if (x) xClamp = !!z; else if (y) yClamp = !!z; return brush; }; if (x) { if (xExtentDomain) { x0 = xExtentDomain[0], x1 = xExtentDomain[1]; } else { x0 = xExtent[0], x1 = xExtent[1]; if (yExtentDomain) { y0 = yExtentDomain[0], y1 = yExtentDomain[1]; } else { y0 = yExtent[0], y1 = yExtent[1]; xExtentDomain = [ x0, x1 ]; if (x0 != xExtent[0] || x1 != xExtent[1]) xExtent = [ x0, x1 ]; yExtentDomain = [ y0, y1 ]; if (y0 != yExtent[0] || y1 != yExtent[1]) yExtent = [ y0, y1 ]; if (!brush.empty()) { xExtent = [ 0, 0 ], yExtent = [ 0, 0 ]; xExtentDomain = yExtentDomain = null; } return !!x && xExtent[0] == xExtent[1] || !!y && yExtent[0] == yExtent[1]; var d3_time_format = d3_time.format = d3_locale_enUS.timeFormat; var d3_time_formatUtc = d3_time_format.utc; var d3_time_formatIso = d3_time_formatUtc(""%Y-%m-%dT%H:%M:%S.%LZ""); d3_time_format.iso = Date.prototype.toISOString && +new Date(""2000-01-01T00:00:00.000Z"") ? d3_time_formatIsoNative : d3_time_formatIso; d3_time.second = d3_time_interval(function(date) { return new d3_date(Math.floor(date / 1e3) * 1e3); d3_time.seconds = d3_time.second.range; d3_time.seconds.utc = d3_time.second.utc.range; d3_time.minute = d3_time_interval(function(date) { return new d3_date(Math.floor(date / 6e4) * 6e4); d3_time.minutes = d3_time.minute.range; d3_time.minutes.utc = d3_time.minute.utc.range; d3_time.hour = d3_time_interval(function(date) { return new d3_date((Math.floor(date / 36e5 - timezone) + timezone) * 36e5); d3_time.hours = d3_time.hour.range; d3_time.hours.utc = d3_time.hour.utc.range; d3_time.month = d3_time_interval(function(date) { date = d3_time.day(date); d3_time.months = d3_time.month.range; d3_time.months.utc = d3_time.month.utc.range; function tickMethod(extent, count) { var span = extent[1] - extent[0], target = span / count, i = d3.bisect(d3_time_scaleSteps, target); return i == d3_time_scaleSteps.length ? [ methods.year, d3_scale_linearTickRange(extent.map(function(d) { return d / 31536e6; }), count)[2] ] : !i ? [ d3_time_scaleMilliseconds, d3_scale_linearTickRange(extent, count)[2] ] : methods[target / d3_time_scaleSteps[i - 1] < d3_time_scaleSteps[i] / target ? i - 1 : i]; } scale.nice = function(interval, skip) { var domain = scale.domain(), extent = d3_scaleExtent(domain), method = interval == null ? tickMethod(extent, 10) : typeof interval === ""number"" && tickMethod(extent, interval); if (method) interval = method[0], skip = method[1]; function skipped(date) { return !isNaN(date) && !interval.range(date, d3_time_scaleDate(+date + 1), skip).length; } return scale.domain(d3_scale_nice(domain, skip > 1 ? { floor: function(date) { while (skipped(date = interval.floor(date))) date = d3_time_scaleDate(date - 1); return date; }, ceil: function(date) { while (skipped(date = interval.ceil(date))) date = d3_time_scaleDate(+date + 1); return date; } } : interval)); }; scale.ticks = function(interval, skip) { var extent = d3_scaleExtent(scale.domain()), method = interval == null ? tickMethod(extent, 10) : typeof interval === ""number"" ? tickMethod(extent, interval) : !interval.range && [ { range: interval }, skip ]; if (method) interval = method[0], skip = method[1]; return interval.range(extent[0], d3_time_scaleDate(+extent[1] + 1), skip < 1 ? 1 : skip); var d3_time_scaleLocalMethods = [ [ d3_time.second, 1 ], [ d3_time.second, 5 ], [ d3_time.second, 15 ], [ d3_time.second, 30 ], [ d3_time.minute, 1 ], [ d3_time.minute, 5 ], [ d3_time.minute, 15 ], [ d3_time.minute, 30 ], [ d3_time.hour, 1 ], [ d3_time.hour, 3 ], [ d3_time.hour, 6 ], [ d3_time.hour, 12 ], [ d3_time.day, 1 ], [ d3_time.day, 2 ], [ d3_time.week, 1 ], [ d3_time.month, 1 ], [ d3_time.month, 3 ], [ d3_time.year, 1 ] ]; var d3_time_scaleLocalFormat = d3_time_format.multi([ [ "".%L"", function(d) { } ], [ "":%S"", function(d) { return d.getSeconds(); } ], [ ""%I:%M"", function(d) { return d.getMinutes(); } ], [ ""%I %p"", function(d) { return d.getHours(); } ], [ ""%a %d"", function(d) { return d.getDay() && d.getDate() != 1; } ], [ ""%b %d"", function(d) { return d.getDate() != 1; } ], [ ""%B"", function(d) { return d.getMonth(); } ], [ ""%Y"", d3_true ] ]); var d3_time_scaleMilliseconds = { range: function(start, stop, step) { return d3.range(Math.ceil(start / step) * step, +stop, step).map(d3_time_scaleDate); }, floor: d3_identity, ceil: d3_identity d3_time_scaleLocalMethods.year = d3_time.year; d3_time.scale = function() { var d3_time_scaleUtcMethods = d3_time_scaleLocalMethods.map(function(m) { var d3_time_scaleUtcFormat = d3_time_formatUtc.multi([ [ "".%L"", function(d) { } ], [ "":%S"", function(d) { return d.getUTCSeconds(); } ], [ ""%I:%M"", function(d) { return d.getUTCMinutes(); } ], [ ""%I %p"", function(d) { return d.getUTCHours(); } ], [ ""%a %d"", function(d) { return d.getUTCDay() && d.getUTCDate() != 1; } ], [ ""%b %d"", function(d) { return d.getUTCDate() != 1; } ], [ ""%B"", function(d) { return d.getUTCMonth(); } ], [ ""%Y"", d3_true ] ]); d3_time_scaleUtcMethods.year = d3_time.year.utc; d3_time.scale.utc = function() { return d3_time_scale(d3.scale.linear(), d3_time_scaleUtcMethods, d3_time_scaleUtcFormat); d3.text = d3_xhrType(function(request) { }); d3.json = function(url, callback) { return d3_xhr(url, ""application/json"", d3_json, callback); return d3_xhr(url, ""text/html"", d3_html, callback); d3.xml = d3_xhrType(function(request) { }); if (typeof define === ""function"" && define.amd) this.d3 = d3, define(d3); else if (typeof module === ""object"" && module.exports) module.exports = d3; else this.d3 = d3;","d3 = function() { var d3 = { version: ""3.1.6"" var d3_document = document, d3_window = window; try { d3_document.createElement(""div"").style.setProperty(""opacity"", 0, """"); } catch (error) { var d3_style_prototype = d3_window.CSSStyleDeclaration.prototype, d3_style_setProperty = d3_style_prototype.setProperty; d3_style_prototype.setProperty = function(name, value, priority) { d3_style_setProperty.call(this, name, value + """", priority); }; } d3.ascending = function(a, b) { }; while (++i < n && ((a = array[i]) == null || a != a)) a = undefined; while (++i < n && ((a = f.call(array, array[i], i)) == null || a != a)) a = undefined; while (++i < n && ((a = array[i]) == null || a != a)) a = undefined; while (++i < n && ((a = f.call(array, array[i], i)) == null || a != a)) a = undefined; while (++i < n && ((a = c = array[i]) == null || a != a)) a = c = undefined; while (++i < n && ((a = c = f.call(array, array[i], i)) == null || a != a)) a = undefined; while (++i < n) if (!isNaN(a = +array[i])) s += a; } else { while (++i < n) if (!isNaN(a = +f.call(array, array[i], i))) s += a; function d3_number(x) { return x != null && !isNaN(x); } d3.mean = function(array, f) { var n = array.length, a, m = 0, i = -1, j = 0; if (arguments.length === 1) { while (++i < n) if (d3_number(a = array[i])) m += (a - m) / ++j; } else { while (++i < n) if (d3_number(a = f.call(array, array[i], i))) m += (a - m) / ++j; } return j ? m : undefined; if (arguments.length > 1) array = array.map(f); array = array.filter(d3_number); return array.length ? d3.quantile(array.sort(d3.ascending), .5) : undefined; d3.bisector = function(f) { if (f.call(a, a[mid], mid) < x) lo = mid + 1; else hi = mid; if (x < f.call(a, a[mid], mid)) hi = mid; else lo = mid + 1; var d3_bisector = d3.bisector(function(d) { return d; }); d3.bisectLeft = d3_bisector.left; d3.bisect = d3.bisectRight = d3_bisector.right; d3.shuffle = function(array) { var m = array.length, t, i; t = array[m], array[m] = array[i], array[i] = t; var permutes = [], i = -1, n = indexes.length; while (++i < n) permutes[i] = array[indexes[i]]; d3.zip = function() { if (!(n = arguments.length)) return []; for (var i = -1, m = d3.min(arguments, d3_zipLength), zips = new Array(m); ++i < m; ) { for (var j = -1, n, zip = zips[i] = new Array(n); ++j < n; ) { zip[j] = arguments[j][i]; } } return zips; function d3_zipLength(d) { d3.transpose = function(matrix) { return d3.zip.apply(d3, matrix); return Array.prototype.concat.apply([], arrays); var range = [], k = d3_range_integerScale(Math.abs(step)), i = -1, j; try { for (var key in properties) { Object.defineProperty(ctor.prototype, key, { value: properties[key], enumerable: false }); } } catch (e) { ctor.prototype = properties; } } d3.map = function(object) { for (var key in object) map.set(key, object[key]); function d3_Map() {} d3_class(d3_Map, { has: function(key) { return d3_map_prefix + key in this; }, get: function(key) { return this[d3_map_prefix + key]; return this[d3_map_prefix + key] = value; remove: function(key) { key = d3_map_prefix + key; return key in this && delete this[key]; }, keys: function() { var keys = []; this.forEach(function(key) { keys.push(key); }); return keys; }, this.forEach(function(key, value) { values.push(value); }); this.forEach(function(key, value) { entries.push({ key: key, value: value }); forEach: function(f) { for (var key in this) { if (key.charCodeAt(0) === d3_map_prefixCode) { f.call(this, key.substring(1), this[key]); } } var d3_map_prefix = ""\0"", d3_map_prefixCode = d3_map_prefix.charCodeAt(0); if (array) for (var i = 0; i < array.length; i++) set.add(array[i]); function d3_Set() {} d3_class(d3_Set, { has: function(value) { return d3_map_prefix + value in this; add: function(value) { this[d3_map_prefix + value] = true; return value; }, remove: function(value) { value = d3_map_prefix + value; return value in this && delete this[value]; }, values: function() { var values = []; this.forEach(function(value) { values.push(value); }); return values; }, forEach: function(f) { for (var value in this) { if (value.charCodeAt(0) === d3_map_prefixCode) { f.call(this, value.substring(1)); } } name = type.substring(i + 1); type = type.substring(0, i); function d3_eventCancel() { d3.event.stopPropagation(); function d3_eventSuppress(target, type) { function off() { target.on(type, null); } target.on(type, function() { d3_eventCancel(); off(); }, true); setTimeout(off, 0); } d3.mouse = function(container) { return d3_mousePoint(container, d3_eventSource()); var d3_mouse_bug44083 = /WebKit/.test(d3_window.navigator.userAgent) ? -1 : 0; function d3_mousePoint(container, e) { var svg = container.ownerSVGElement || container; if (svg.createSVGPoint) { var point = svg.createSVGPoint(); if (d3_mouse_bug44083 < 0 && (d3_window.scrollX || d3_window.scrollY)) { svg = d3.select(d3_document.body).append(""svg"").style(""position"", ""absolute"").style(""top"", 0).style(""left"", 0); var ctm = svg[0][0].getScreenCTM(); d3_mouse_bug44083 = !(ctm.f || ctm.e); svg.remove(); } if (d3_mouse_bug44083) { point.x = e.pageX; point.y = e.pageY; } else { point.x = e.clientX; point.y = e.clientY; } point = point.matrixTransform(container.getScreenCTM().inverse()); return [ point.x, point.y ]; } var rect = container.getBoundingClientRect(); return [ e.clientX - rect.left - container.clientLeft, e.clientY - rect.top - container.clientTop ]; } var d3_array = d3_arraySlice; function d3_arrayCopy(pseudoarray) { var i = -1, n = pseudoarray.length, array = []; while (++i < n) array.push(pseudoarray[i]); return array; } function d3_arraySlice(pseudoarray) { return Array.prototype.slice.call(pseudoarray); } try { d3_array(d3_document.documentElement.childNodes)[0].nodeType; } catch (e) { d3_array = d3_arrayCopy; } var d3_arraySubclass = [].__proto__ ? function(array, prototype) { array.__proto__ = prototype; } : function(array, prototype) { for (var property in prototype) array[property] = prototype[property]; }; d3.touches = function(container, touches) { if (arguments.length < 2) touches = d3_eventSource().touches; return touches ? d3_array(touches).map(function(touch) { var point = d3_mousePoint(container, touch); point.identifier = touch.identifier; return point; }) : []; }; d3.behavior.drag = function() { var event = d3_eventDispatch(drag, ""drag"", ""dragstart"", ""dragend""), origin = null; function drag() { this.on(""mousedown.drag"", mousedown).on(""touchstart.drag"", mousedown); } function mousedown() { var target = this, event_ = event.of(target, arguments), eventTarget = d3.event.target, touchId = d3.event.touches ? d3.event.changedTouches[0].identifier : null, offset, origin_ = point(), moved = 0; var w = d3.select(d3_window).on(touchId != null ? ""touchmove.drag-"" + touchId : ""mousemove.drag"", dragmove).on(touchId != null ? ""touchend.drag-"" + touchId : ""mouseup.drag"", dragend, true); if (origin) { offset = origin.apply(target, arguments); offset = [ offset.x - origin_[0], offset.y - origin_[1] ]; } else { offset = [ 0, 0 ]; } if (touchId == null) d3_eventCancel(); event_({ type: ""dragstart"" }); function point() { var p = target.parentNode; return touchId != null ? d3.touches(p).filter(function(p) { return p.identifier === touchId; })[0] : d3.mouse(p); } function dragmove() { if (!target.parentNode) return dragend(); var p = point(), dx = p[0] - origin_[0], dy = p[1] - origin_[1]; moved |= dx | dy; origin_ = p; d3_eventCancel(); event_({ type: ""drag"", x: p[0] + offset[0], y: p[1] + offset[1], dx: dx, dy: dy }); } function dragend() { event_({ type: ""dragend"" }); if (moved) { d3_eventCancel(); if (d3.event.target === eventTarget) d3_eventSuppress(w, ""click""); } w.on(touchId != null ? ""touchmove.drag-"" + touchId : ""mousemove.drag"", null).on(touchId != null ? ""touchend.drag-"" + touchId : ""mouseup.drag"", null); } } drag.origin = function(x) { if (!arguments.length) return origin; origin = x; return drag; }; return d3.rebind(drag, event, ""on""); d3_arraySubclass(groups, d3_selectionPrototype); }, d3_selectRoot = d3_document.documentElement, d3_selectMatcher = d3_selectRoot.matchesSelector || d3_selectRoot.webkitMatchesSelector || d3_selectRoot.mozMatchesSelector || d3_selectRoot.msMatchesSelector || d3_selectRoot.oMatchesSelector, d3_selectMatches = function(n, s) { return d3_selectMatcher.call(n, s); d3_selectAll = function(s, n) { return Sizzle.uniqueSort(Sizzle(s, n)); }; return d3_selectionRoot; if (typeof selector !== ""function"") selector = d3_selection_selector(selector); subgroup.push(subnode = selector.call(node, node.__data__, i)); return function() { if (typeof selector !== ""function"") selector = d3_selection_selectorAll(selector); subgroups.push(subgroup = d3_array(selector.call(node, node.__data__, i))); return function() { xhtml: ""http://www.w3.org/1999/xhtml"", if (i >= 0) { prefix = name.substring(0, i); name = name.substring(i + 1); } d3.requote = function(s) { return s.replace(d3_requote_re, ""\\$&""); }; var d3_requote_re = /[\\\^\$\*\+\?\|\[\]\(\)\.\{\}]/g; var node = this.node(), n = (name = name.trim().split(/^|\s+/g)).length, i = -1; function d3_selection_classed(name, value) { name = name.trim().split(/\s+/).map(d3_selection_classedName); if (n < 2) return d3_window.getComputedStyle(this.node(), null).getPropertyValue(name); name = d3.ns.qualify(name); function append() { return this.appendChild(d3_document.createElementNS(this.namespaceURI, name)); } function appendNS() { return this.appendChild(d3_document.createElementNS(name.space, name.local)); } return this.select(name.local ? appendNS : append); }; d3_selectionPrototype.insert = function(name, before) { name = d3.ns.qualify(name); if (typeof before !== ""function"") before = d3_selection_selector(before); function insert(d, i) { return this.insertBefore(d3_document.createElementNS(this.namespaceURI, name), before.call(this, d, i)); } function insertNS(d, i) { return this.insertBefore(d3_document.createElementNS(name.space, name.local), before.call(this, d, i)); } return this.select(name.local ? insertNS : insert); }; d3_selectionPrototype.remove = function() { return this.each(function() { var parent = this.parentNode; if (parent) parent.removeChild(this); var nodeByKeyValue = new d3_Map(), dataByKeyValue = new d3_Map(), keyValues = [], keyValue; for (i = -1; ++i < n; ) { keyValue = key.call(node = group[i], node.__data__, i); if (nodeByKeyValue.has(keyValue)) { exitNodes[i] = node; } else { nodeByKeyValue.set(keyValue, node); } keyValues.push(keyValue); keyValue = key.call(groupData, nodeData = groupData[i], i); if (node = nodeByKeyValue.get(keyValue)) { } else if (!dataByKeyValue.has(keyValue)) { enterNodes[i] = d3_selection_dataNode(nodeData); } dataByKeyValue.set(keyValue, nodeData); nodeByKeyValue.remove(keyValue); if (nodeByKeyValue.has(keyValues[i])) { if ((node = group[i]) && filter.call(node, node.__data__, i)) { if (!arguments.length) comparator = d3.ascending; return function(a, b) { return !a - !b || comparator(a.__data__, b.__data__); }; } function d3_noop() {} d3_selectionPrototype.on = function(type, listener, capture) { var n = arguments.length; if (n < 3) { if (typeof type !== ""string"") { if (n < 2) listener = false; for (capture in type) this.each(d3_selection_on(capture, type[capture], listener)); return this; } if (n < 2) return (n = this.node()[""__on"" + type]) && n._; capture = false; } return this.each(d3_selection_on(type, listener, capture)); }; function d3_selection_on(type, listener, capture) { var name = ""__on"" + type, i = type.indexOf("".""), wrap = d3_selection_onListener; if (i > 0) type = type.substring(0, i); var filter = d3_selection_onFilters.get(type); if (filter) type = filter, wrap = d3_selection_onFilter; function onRemove() { var l = this[name]; if (l) { this.removeEventListener(type, l, l.$); delete this[name]; } } function onAdd() { var l = wrap(listener, d3_array(arguments)); onRemove.call(this); this.addEventListener(type, this[name] = l, l.$ = capture); l._ = listener; } function removeAll() { var re = new RegExp(""^__on([^.]+)"" + d3.requote(type) + ""$""), match; for (var name in this) { if (match = name.match(re)) { var l = this[name]; this.removeEventListener(match[1], l, l.$); delete this[name]; } } } return i ? listener ? onAdd : onRemove : listener ? d3_noop : removeAll; } var d3_selection_onFilters = d3.map({ mouseenter: ""mouseover"", mouseleave: ""mouseout"" }); d3_selection_onFilters.forEach(function(k) { if (""on"" + k in d3_document) d3_selection_onFilters.remove(k); }); function d3_selection_onListener(listener, argumentz) { return function(e) { var o = d3.event; d3.event = e; argumentz[0] = this.__data__; try { listener.apply(this, argumentz); } finally { d3.event = o; } }; } function d3_selection_onFilter(listener, argumentz) { var l = d3_selection_onListener(listener, argumentz); return function(e) { var target = this, related = e.relatedTarget; if (!related || related !== target && !(related.compareDocumentPosition(target) & 8)) { l.call(target, e); } function d3_selection_enter(selection) { d3_arraySubclass(selection, d3_selection_enterPrototype); d3_selection_enterPrototype.insert = d3_selectionPrototype.insert; subgroup.push(upgroup[i] = subnode = selector.call(group.parentNode, node.__data__, i)); d3_selectionPrototype.transition = function() { var id = d3_transitionInheritId || ++d3_transitionId, subgroups = [], subgroup, node, transition = Object.create(d3_transitionInherit); transition.time = Date.now(); for (var j = -1, m = this.length; ++j < m; ) { subgroups.push(subgroup = []); for (var group = this[j], i = -1, n = group.length; ++i < n; ) { if (node = group[i]) d3_transitionNode(node, i, id, transition); subgroup.push(node); } } return d3_transition(subgroups, id); d3.select = function(node) { var group = [ typeof node === ""string"" ? d3_select(node, d3_document) : node ]; group.parentNode = d3_selectRoot; var group = d3_array(typeof nodes === ""string"" ? d3_selectAll(nodes, d3_document) : nodes); group.parentNode = d3_selectRoot; var d3_selectionRoot = d3.select(d3_selectRoot); d3.behavior.zoom = function() { var translate = [ 0, 0 ], translate0, scale = 1, scale0, scaleExtent = d3_behavior_zoomInfinity, event = d3_eventDispatch(zoom, ""zoom""), x0, x1, y0, y1, touchtime; function zoom() { this.on(""mousedown.zoom"", mousedown).on(""mousemove.zoom"", mousemove).on(d3_behavior_zoomWheel + "".zoom"", mousewheel).on(""dblclick.zoom"", dblclick).on(""touchstart.zoom"", touchstart).on(""touchmove.zoom"", touchmove).on(""touchend.zoom"", touchstart); } zoom.translate = function(x) { if (!arguments.length) return translate; translate = x.map(Number); zoom.scale = function(x) { if (!arguments.length) return scale; scale = +x; zoom.scaleExtent = function(x) { scaleExtent = x == null ? d3_behavior_zoomInfinity : x.map(Number); translate = [ 0, 0 ]; scale = 1; translate = [ 0, 0 ]; scale = 1; return [ (p[0] - translate[0]) / scale, (p[1] - translate[1]) / scale ]; return [ l[0] * scale + translate[0], l[1] * scale + translate[1] ]; scale = Math.max(scaleExtent[0], Math.min(scaleExtent[1], s)); translate[0] += p[0] - l[0]; translate[1] += p[1] - l[1]; return (x - translate[0]) / scale; return (y - translate[1]) / scale; function dispatch(event) { d3.event.preventDefault(); event({ scale: scale, translate: translate function mousedown() { var target = this, event_ = event.of(target, arguments), eventTarget = d3.event.target, moved = 0, w = d3.select(d3_window).on(""mousemove.zoom"", mousemove).on(""mouseup.zoom"", mouseup), l = location(d3.mouse(target)); d3_window.focus(); d3_eventCancel(); function mousemove() { moved = 1; translateTo(d3.mouse(target), l); dispatch(event_); } function mouseup() { if (moved) d3_eventCancel(); w.on(""mousemove.zoom"", null).on(""mouseup.zoom"", null); if (moved && d3.event.target === eventTarget) d3_eventSuppress(w, ""click.zoom""); } } function mousewheel() { if (!translate0) translate0 = location(d3.mouse(this)); scaleTo(Math.pow(2, d3_behavior_zoomDelta() * .002) * scale); translateTo(d3.mouse(this), translate0); dispatch(event.of(this, arguments)); } function mousemove() { translate0 = null; } function dblclick() { var p = d3.mouse(this), l = location(p), k = Math.log(scale) / Math.LN2; scaleTo(Math.pow(2, d3.event.shiftKey ? Math.ceil(k) - 1 : Math.floor(k) + 1)); translateTo(p, l); dispatch(event.of(this, arguments)); } function touchstart() { var touches = d3.touches(this), now = Date.now(); scale0 = scale; translate0 = {}; touches.forEach(function(t) { translate0[t.identifier] = location(t); }); d3_eventCancel(); if (touches.length === 1) { if (now - touchtime < 500) { var p = touches[0], l = location(touches[0]); scaleTo(scale * 2); translateTo(p, l); dispatch(event.of(this, arguments)); } touchtime = now; } } function touchmove() { var touches = d3.touches(this), p0 = touches[0], l0 = translate0[p0.identifier]; if (p1 = touches[1]) { var p1, l1 = translate0[p1.identifier]; p0 = [ (p0[0] + p1[0]) / 2, (p0[1] + p1[1]) / 2 ]; l0 = [ (l0[0] + l1[0]) / 2, (l0[1] + l1[1]) / 2 ]; scaleTo(d3.event.scale * scale0); } translateTo(p0, l0); touchtime = null; dispatch(event.of(this, arguments)); var d3_behavior_zoomInfinity = [ 0, Infinity ]; var d3_behavior_zoomDelta, d3_behavior_zoomWheel = ""onwheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return -d3.event.deltaY * (d3.event.deltaMode ? 120 : 1); }, ""wheel"") : ""onmousewheel"" in d3_document ? (d3_behavior_zoomDelta = function() { return d3.event.wheelDelta; }, ""mousewheel"") : (d3_behavior_zoomDelta = function() { return -d3.event.detail; }, ""MozMousePixelScroll""); function d3_Color() {} d3_Color.prototype.toString = function() { d3.hsl = function(h, s, l) { return arguments.length === 1 ? h instanceof d3_Hsl ? d3_hsl(h.h, h.s, h.l) : d3_rgb_parse("""" + h, d3_rgb_hsl, d3_hsl) : d3_hsl(+h, +s, +l); }; function d3_hsl(h, s, l) { return new d3_Hsl(h, s, l); } function d3_Hsl(h, s, l) { this.h = h; this.s = s; this.l = l; } var d3_hslPrototype = d3_Hsl.prototype = new d3_Color(); return d3_hsl(this.h, this.s, this.l / k); return d3_hsl(this.h, this.s, k * this.l); return d3_rgb(vv(h + 120), vv(h), vv(h - 120)); } var  = Math.PI,  = 1e-6, d3_radians =  / 180, d3_degrees = 180 / ; function d3_sgn(x) { return x > 0 ? 1 : x < 0 ? -1 : 0; } function d3_acos(x) { return Math.acos(Math.max(-1, Math.min(1, x))); } function d3_asin(x) { return x > 1 ?  / 2 : x < -1 ? - / 2 : Math.asin(x); } function d3_sinh(x) { return (Math.exp(x) - Math.exp(-x)) / 2; } function d3_cosh(x) { return (Math.exp(x) + Math.exp(-x)) / 2; } function d3_haversin(x) { return (x = Math.sin(x / 2)) * x; } d3.hcl = function(h, c, l) { return arguments.length === 1 ? h instanceof d3_Hcl ? d3_hcl(h.h, h.c, h.l) : h instanceof d3_Lab ? d3_lab_hcl(h.l, h.a, h.b) : d3_lab_hcl((h = d3_rgb_lab((h = d3.rgb(h)).r, h.g, h.b)).l, h.a, h.b) : d3_hcl(+h, +c, +l); }; function d3_hcl(h, c, l) { return new d3_Hcl(h, c, l); } function d3_Hcl(h, c, l) { this.h = h; this.c = c; this.l = l; } var d3_hclPrototype = d3_Hcl.prototype = new d3_Color(); d3_hclPrototype.brighter = function(k) { return d3_hcl(this.h, this.c, Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1))); return d3_hcl(this.h, this.c, Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1))); return d3_lab(l, Math.cos(h *= d3_radians) * c, Math.sin(h) * c); } d3.lab = function(l, a, b) { return arguments.length === 1 ? l instanceof d3_Lab ? d3_lab(l.l, l.a, l.b) : l instanceof d3_Hcl ? d3_hcl_lab(l.l, l.c, l.h) : d3_rgb_lab((l = d3.rgb(l)).r, l.g, l.b) : d3_lab(+l, +a, +b); }; function d3_lab(l, a, b) { return new d3_Lab(l, a, b); } function d3_Lab(l, a, b) { this.l = l; this.a = a; this.b = b; var d3_labPrototype = d3_Lab.prototype = new d3_Color(); d3_labPrototype.brighter = function(k) { return d3_lab(Math.min(100, this.l + d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); return d3_lab(Math.max(0, this.l - d3_lab_K * (arguments.length ? k : 1)), this.a, this.b); return d3_rgb(d3_xyz_rgb(3.2404542 * x - 1.5371385 * y - .4985314 * z), d3_xyz_rgb(-.969266 * x + 1.8760108 * y + .041556 * z), d3_xyz_rgb(.0556434 * x - .2040259 * y + 1.0572252 * z)); return l > 0 ? d3_hcl(Math.atan2(b, a) * d3_degrees, Math.sqrt(a * a + b * b), l) : d3_hcl(NaN, NaN, l); d3.rgb = function(r, g, b) { return arguments.length === 1 ? r instanceof d3_Rgb ? d3_rgb(r.r, r.g, r.b) : d3_rgb_parse("""" + r, d3_rgb, d3_hsl_rgb) : d3_rgb(~~r, ~~g, ~~b); }; function d3_rgb(r, g, b) { return new d3_Rgb(r, g, b); } function d3_Rgb(r, g, b) { this.r = r; this.g = g; this.b = b; } var d3_rgbPrototype = d3_Rgb.prototype = new d3_Color(); if (!r && !g && !b) return d3_rgb(i, i, i); return d3_rgb(Math.min(255, Math.floor(r / k)), Math.min(255, Math.floor(g / k)), Math.min(255, Math.floor(b / k))); return d3_rgb(Math.floor(k * this.r), Math.floor(k * this.g), Math.floor(k * this.b)); var r = 0, g = 0, b = 0, m1, m2, name; m1 = /([a-z]+)\((.*)\)/i.exec(format); if (name = d3_rgb_names.get(format)) return rgb(name.r, name.g, name.b); if (format != null && format.charAt(0) === ""#"") { if (format.length === 4) { r = format.charAt(1); r += r; g = format.charAt(2); g += g; b = format.charAt(3); b += b; } else if (format.length === 7) { r = format.substring(1, 3); g = format.substring(3, 5); b = format.substring(5, 7); } r = parseInt(r, 16); g = parseInt(g, 16); b = parseInt(b, 16); return d3_hsl(h, s, l); aliceblue: ""#f0f8ff"", antiquewhite: ""#faebd7"", aqua: ""#00ffff"", aquamarine: ""#7fffd4"", azure: ""#f0ffff"", beige: ""#f5f5dc"", bisque: ""#ffe4c4"", black: ""#000000"", blanchedalmond: ""#ffebcd"", blue: ""#0000ff"", blueviolet: ""#8a2be2"", brown: ""#a52a2a"", burlywood: ""#deb887"", cadetblue: ""#5f9ea0"", chartreuse: ""#7fff00"", chocolate: ""#d2691e"", coral: ""#ff7f50"", cornflowerblue: ""#6495ed"", cornsilk: ""#fff8dc"", crimson: ""#dc143c"", cyan: ""#00ffff"", darkblue: ""#00008b"", darkcyan: ""#008b8b"", darkgoldenrod: ""#b8860b"", darkgray: ""#a9a9a9"", darkgreen: ""#006400"", darkgrey: ""#a9a9a9"", darkkhaki: ""#bdb76b"", darkmagenta: ""#8b008b"", darkolivegreen: ""#556b2f"", darkorange: ""#ff8c00"", darkorchid: ""#9932cc"", darkred: ""#8b0000"", darksalmon: ""#e9967a"", darkseagreen: ""#8fbc8f"", darkslateblue: ""#483d8b"", darkslategray: ""#2f4f4f"", darkslategrey: ""#2f4f4f"", darkturquoise: ""#00ced1"", darkviolet: ""#9400d3"", deeppink: ""#ff1493"", deepskyblue: ""#00bfff"", dimgray: ""#696969"", dimgrey: ""#696969"", dodgerblue: ""#1e90ff"", firebrick: ""#b22222"", floralwhite: ""#fffaf0"", forestgreen: ""#228b22"", fuchsia: ""#ff00ff"", gainsboro: ""#dcdcdc"", ghostwhite: ""#f8f8ff"", gold: ""#ffd700"", goldenrod: ""#daa520"", gray: ""#808080"", green: ""#008000"", greenyellow: ""#adff2f"", grey: ""#808080"", honeydew: ""#f0fff0"", hotpink: ""#ff69b4"", indianred: ""#cd5c5c"", indigo: ""#4b0082"", ivory: ""#fffff0"", khaki: ""#f0e68c"", lavender: ""#e6e6fa"", lavenderblush: ""#fff0f5"", lawngreen: ""#7cfc00"", lemonchiffon: ""#fffacd"", lightblue: ""#add8e6"", lightcoral: ""#f08080"", lightcyan: ""#e0ffff"", lightgoldenrodyellow: ""#fafad2"", lightgray: ""#d3d3d3"", lightgreen: ""#90ee90"", lightgrey: ""#d3d3d3"", lightpink: ""#ffb6c1"", lightsalmon: ""#ffa07a"", lightseagreen: ""#20b2aa"", lightskyblue: ""#87cefa"", lightslategray: ""#778899"", lightslategrey: ""#778899"", lightsteelblue: ""#b0c4de"", lightyellow: ""#ffffe0"", lime: ""#00ff00"", limegreen: ""#32cd32"", linen: ""#faf0e6"", magenta: ""#ff00ff"", maroon: ""#800000"", mediumaquamarine: ""#66cdaa"", mediumblue: ""#0000cd"", mediumorchid: ""#ba55d3"", mediumpurple: ""#9370db"", mediumseagreen: ""#3cb371"", mediumslateblue: ""#7b68ee"", mediumspringgreen: ""#00fa9a"", mediumturquoise: ""#48d1cc"", mediumvioletred: ""#c71585"", midnightblue: ""#191970"", mintcream: ""#f5fffa"", mistyrose: ""#ffe4e1"", moccasin: ""#ffe4b5"", navajowhite: ""#ffdead"", navy: ""#000080"", oldlace: ""#fdf5e6"", olive: ""#808000"", olivedrab: ""#6b8e23"", orange: ""#ffa500"", orangered: ""#ff4500"", orchid: ""#da70d6"", palegoldenrod: ""#eee8aa"", palegreen: ""#98fb98"", paleturquoise: ""#afeeee"", palevioletred: ""#db7093"", papayawhip: ""#ffefd5"", peachpuff: ""#ffdab9"", peru: ""#cd853f"", pink: ""#ffc0cb"", plum: ""#dda0dd"", powderblue: ""#b0e0e6"", purple: ""#800080"", red: ""#ff0000"", rosybrown: ""#bc8f8f"", royalblue: ""#4169e1"", saddlebrown: ""#8b4513"", salmon: ""#fa8072"", sandybrown: ""#f4a460"", seagreen: ""#2e8b57"", seashell: ""#fff5ee"", sienna: ""#a0522d"", silver: ""#c0c0c0"", skyblue: ""#87ceeb"", slateblue: ""#6a5acd"", slategray: ""#708090"", slategrey: ""#708090"", snow: ""#fffafa"", springgreen: ""#00ff7f"", steelblue: ""#4682b4"", tan: ""#d2b48c"", teal: ""#008080"", thistle: ""#d8bfd8"", tomato: ""#ff6347"", turquoise: ""#40e0d0"", violet: ""#ee82ee"", wheat: ""#f5deb3"", white: ""#ffffff"", whitesmoke: ""#f5f5f5"", yellow: ""#ffff00"", yellowgreen: ""#9acd32"" d3_rgb_names.set(key, d3_rgb_parse(value, d3_rgb, d3_hsl_rgb)); function d3_identity(d) { return d; } d3.xhr = function(url, mimeType, callback) { var xhr = {}, dispatch = d3.dispatch(""progress"", ""load"", ""error""), headers = {}, response = d3_identity, request = new (d3_window.XDomainRequest && /^(http(s)?:)?\/\//.test(url) ? XDomainRequest : XMLHttpRequest)(); var s = request.status; !s && request.responseText || s >= 200 && s < 300 || s === 304 ? dispatch.load.call(xhr, response.call(xhr, request)) : dispatch.error.call(xhr, request); if (arguments.length === 2 && typeof mimeType === ""function"") callback = mimeType, mimeType = null; }; function d3_dsv(delimiter, mimeType) { var xhr = d3.xhr(url, mimeType, callback); return xhr.row(row); return text.substring(j + 1, i).replace(/""""/g, '""'); return text.substring(j, I - k); } return text.substring(j); if (f && !(a = f(a, n++))) continue; } d3.csv = d3_dsv("","", ""text/csv""); d3.tsv = d3_dsv("" "", ""text/tab-separated-values""); var d3_timer_id = 0, d3_timer_byId = {}, d3_timer_queue = null, d3_timer_interval, d3_timer_timeout; d3.timer = function(callback, delay, then) { if (arguments.length < 3) { if (arguments.length < 2) delay = 0; else if (!isFinite(delay)) return; then = Date.now(); } var timer = d3_timer_byId[callback.id]; if (timer && timer.callback === callback) { timer.then = then; timer.delay = delay; } else d3_timer_byId[callback.id = ++d3_timer_id] = d3_timer_queue = { callback: callback, then: then, delay: delay, next: d3_timer_queue }; function d3_timer_step() { var elapsed, now = Date.now(), t1 = d3_timer_queue; while (t1) { elapsed = now - t1.then; if (elapsed >= t1.delay) t1.flush = t1.callback(elapsed); t1 = t1.next; } var delay = d3_timer_flush() - now; var elapsed, now = Date.now(), t1 = d3_timer_queue; while (t1) { elapsed = now - t1.then; if (!t1.delay) t1.flush = t1.callback(elapsed); t1 = t1.next; } d3_timer_flush(); function d3_timer_flush() { var t0 = null, t1 = d3_timer_queue, then = Infinity; while (t1) { if (t1.flush) { delete d3_timer_byId[t1.callback.id]; t1 = t0 ? t0.next = t1.next : d3_timer_queue = t1.next; } else { then = Math.min(then, t1.then + t1.delay); t1 = (t0 = t1).next; } } return then; } var d3_timer_frame = d3_window.requestAnimationFrame || d3_window.webkitRequestAnimationFrame || d3_window.mozRequestAnimationFrame || d3_window.oRequestAnimationFrame || d3_window.msRequestAnimationFrame || function(callback) { setTimeout(callback, 17); var d3_format_decimalPoint = ""."", d3_format_thousandsSeparator = "","", d3_format_grouping = [ 3, 3 ]; if (value) { i = Math.max(-24, Math.min(24, Math.floor((i <= 0 ? i + 1 : i - 1) / 3) * 3)); var k = Math.pow(10, Math.abs(8 - i) * 3); d3.round = function(x, n) { return n ? Math.round(x * (n = Math.pow(10, n))) / n : Math.round(x); }; d3.format = function(specifier) { var match = d3_format_re.exec(specifier), fill = match[1] || "" "", align = match[2] || "">"", sign = match[3] || """", basePrefix = match[4] || """", zfill = match[5], width = +match[6], comma = match[7], precision = match[8], type = match[9], scale = 1, suffix = """", integer = false; if (precision) precision = +precision.substring(1); if (zfill || fill === ""0"" && align === ""="") { zfill = fill = ""0""; align = ""=""; if (comma) width -= Math.floor((width - 1) / 4); } switch (type) { case ""n"": comma = true; type = ""g""; break; case ""%"": scale = 100; suffix = ""%""; type = ""f""; break; case ""p"": scale = 100; suffix = ""%""; type = ""r""; break; case ""b"": case ""o"": case ""x"": case ""X"": if (basePrefix) basePrefix = ""0"" + type.toLowerCase(); case ""c"": case ""d"": integer = true; precision = 0; break; case ""s"": scale = -1; type = ""r""; break; } if (basePrefix === ""#"") basePrefix = """"; if (type == ""r"" && !precision) type = ""g""; if (precision != null) { if (type == ""g"") precision = Math.max(1, Math.min(21, precision)); else if (type == ""e"" || type == ""f"") precision = Math.max(0, Math.min(20, precision)); } type = d3_format_types.get(type) || d3_format_typeDefault; var zcomma = zfill && comma; return function(value) { if (integer && value % 1) return """"; var negative = value < 0 || value === 0 && 1 / value < 0 ? (value = -value, ""-"") : sign; if (scale < 0) { var prefix = d3.formatPrefix(value, precision); value = prefix.scale(value); suffix = prefix.symbol; } else { value *= scale; } value = type(value, precision); if (!zfill && comma) value = d3_format_group(value); var length = basePrefix.length + value.length + (zcomma ? 0 : negative.length), padding = length < width ? new Array(length = width - length + 1).join(fill) : """"; if (zcomma) value = d3_format_group(padding + value); if (d3_format_decimalPoint) value.replace(""."", d3_format_decimalPoint); negative += basePrefix; return (align === ""<"" ? negative + value + padding : align === "">"" ? padding + negative + value : align === ""^"" ? padding.substring(0, length >>= 1) + negative + value + padding.substring(length) : negative + (zcomma ? value : padding + value)) + suffix; }; var d3_format_re = /(?:([^{])?([<>=^]))?([+\- ])?(#)?(0)?(\d+)?(,)?(\.-?\d+)?([a-z%])?/i; function d3_format_precision(x, p) { return p - (x ? Math.ceil(Math.log(x) / Math.LN10) : 1); } var d3_format_group = d3_identity; if (d3_format_grouping) { var d3_format_groupingLength = d3_format_grouping.length; d3_format_group = function(value) { var i = value.lastIndexOf("".""), f = i >= 0 ? ""."" + value.substring(i + 1) : (i = value.length, """"), t = [], j = 0, g = d3_format_grouping[0]; while (i > 0 && g > 0) { t.push(value.substring(i -= g, i + g)); g = d3_format_grouping[j = (j + 1) % d3_format_groupingLength]; } return t.reverse().join(d3_format_thousandsSeparator || """") + f; var coordinate = object.coordinates; listener.point(coordinate[0], coordinate[1]); var coordinates = object.coordinates, i = -1, n = coordinates.length, coordinate; while (++i < n) coordinate = coordinates[i], listener.point(coordinate[0], coordinate[1]); while (++i < n) coordinate = coordinates[i], listener.point(coordinate[0], coordinate[1]); var d3_geo_areaSum, d3_geo_areaRingU, d3_geo_areaRingV; d3_geo_areaRingU = 1, d3_geo_areaRingV = 0; var area = 2 * Math.atan2(d3_geo_areaRingV, d3_geo_areaRingU); var d =  - 0, cos = Math.cos(), sin = Math.sin(), k = sin0 * sin, u0 = d3_geo_areaRingU, v0 = d3_geo_areaRingV, u = cos0 * cos + k * Math.cos(d), v = k * Math.sin(d); d3_geo_areaRingU = u0 * u - v0 * v; d3_geo_areaRingV = v0 * u + u0 * v; d3.geo.bounds = d3_geo_bounds(d3_identity); function d3_geo_bounds(projectStream) { var x0, y0, x1, y1; var bound = { point: boundPoint, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: function() { bound.lineEnd = boundPolygonLineEnd; }, polygonEnd: function() { bound.point = boundPoint; } }; function boundPoint(x, y) { if (x < x0) x0 = x; if (x > x1) x1 = x; if (y < y0) y0 = y; if (y > y1) y1 = y; } function boundPolygonLineEnd() { bound.point = bound.lineEnd = d3_noop; } return function(feature) { y1 = x1 = -(x0 = y0 = Infinity); d3.geo.stream(feature, projectStream(bound)); return [ [ x0, y0 ], [ x1, y1 ] ]; }; } d3.geo.centroid = function(object) { d3_geo_centroidDimension = d3_geo_centroidW = d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; d3.geo.stream(object, d3_geo_centroid); var m; if (d3_geo_centroidW && Math.abs(m = Math.sqrt(d3_geo_centroidX * d3_geo_centroidX + d3_geo_centroidY * d3_geo_centroidY + d3_geo_centroidZ * d3_geo_centroidZ)) > ) { return [ Math.atan2(d3_geo_centroidY, d3_geo_centroidX) * d3_degrees, Math.asin(Math.max(-1, Math.min(1, d3_geo_centroidZ / m))) * d3_degrees ]; } }; var d3_geo_centroidDimension, d3_geo_centroidW, d3_geo_centroidX, d3_geo_centroidY, d3_geo_centroidZ; var d3_geo_centroid = { sphere: function() { if (d3_geo_centroidDimension < 2) { d3_geo_centroidDimension = 2; d3_geo_centroidW = d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; } }, point: d3_geo_centroidPoint, lineStart: d3_geo_centroidLineStart, lineEnd: d3_geo_centroidLineEnd, polygonStart: function() { if (d3_geo_centroidDimension < 2) { d3_geo_centroidDimension = 2; d3_geo_centroidW = d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; } d3_geo_centroid.lineStart = d3_geo_centroidRingStart; }, polygonEnd: function() { d3_geo_centroid.lineStart = d3_geo_centroidLineStart; } }; function d3_geo_centroidPoint(, ) { if (d3_geo_centroidDimension) return; ++d3_geo_centroidW;  *= d3_radians; var cos = Math.cos( *= d3_radians); d3_geo_centroidX += (cos * Math.cos() - d3_geo_centroidX) / d3_geo_centroidW; d3_geo_centroidY += (cos * Math.sin() - d3_geo_centroidY) / d3_geo_centroidW; d3_geo_centroidZ += (Math.sin() - d3_geo_centroidZ) / d3_geo_centroidW; } function d3_geo_centroidRingStart() { var 00, 00; d3_geo_centroidDimension = 1; d3_geo_centroidLineStart(); d3_geo_centroidDimension = 2; var linePoint = d3_geo_centroid.point; d3_geo_centroid.point = function(, ) { linePoint(00 = , 00 = ); }; d3_geo_centroid.lineEnd = function() { d3_geo_centroid.point(00, 00); d3_geo_centroidLineEnd(); d3_geo_centroid.lineEnd = d3_geo_centroidLineEnd; }; } function d3_geo_centroidLineStart() { var x0, y0, z0; if (d3_geo_centroidDimension > 1) return; if (d3_geo_centroidDimension < 1) { d3_geo_centroidDimension = 1; d3_geo_centroidW = d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; } d3_geo_centroid.point = function(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians); x0 = cos * Math.cos(); y0 = cos * Math.sin(); z0 = Math.sin(); d3_geo_centroid.point = nextPoint; }; function nextPoint(, ) {  *= d3_radians; var cos = Math.cos( *= d3_radians), x = cos * Math.cos(), y = cos * Math.sin(), z = Math.sin(), w = Math.atan2(Math.sqrt((w = y0 * z - z0 * y) * w + (w = z0 * x - x0 * z) * w + (w = x0 * y - y0 * x) * w), x0 * x + y0 * y + z0 * z); d3_geo_centroidW += w; d3_geo_centroidX += w * (x0 + (x0 = x)); d3_geo_centroidY += w * (y0 + (y0 = y)); d3_geo_centroidZ += w * (z0 + (z0 = z)); } } function d3_geo_centroidLineEnd() { d3_geo_centroid.point = d3_geo_centroidPoint; } function d3_geo_spherical(cartesian) { return [ Math.atan2(cartesian[1], cartesian[0]), Math.asin(Math.max(-1, Math.min(1, cartesian[2]))) ]; } function d3_geo_sphericalEqual(a, b) { return Math.abs(a[0] - b[0]) <  && Math.abs(a[1] - b[1]) < ; } function d3_geo_clipPolygon(segments, compare, inside, interpolate, listener) { var a = { point: p0, points: segment, other: null, visited: false, entry: true, subject: true }, b = { point: p0, points: [ p0 ], other: a, visited: false, entry: false, subject: false }; a.other = b; a = { point: p1, points: [ p1 ], other: null, visited: false, entry: false, subject: true }; b = { point: p1, points: [ p1 ], other: a, visited: false, entry: true, subject: false }; a.other = b; if (inside) for (var i = 1, e = !inside(clip[0].point), n = clip.length; i < n; ++i) { clip[i].entry = e = !e; } var start = subject[0], current, points, point; while (1) { current = start; while (current.visited) if ((current = current.next) === start) return; points = current.points; current.visited = current.other.visited = true; if (current.entry) { if (current.subject) { for (var i = 0; i < points.length; i++) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.point, current.next.point, 1, listener); } current = current.next; } else { if (current.subject) { points = current.prev.points; for (var i = points.length; --i >= 0; ) listener.point((point = points[i])[0], point[1]); } else { interpolate(current.point, current.prev.point, -1, listener); } current = current.prev; } current = current.other; points = current.points; } while (!current.visited); a.next = b = array[i]; b.prev = a; a.next = b = array[0]; b.prev = a; } function d3_geo_clip(pointVisible, clipLine, interpolate) { return function(listener) { var line = clipLine(listener); invisible = false; invisibleArea = visibleArea = 0; listener.polygonStart(); if (segments.length) { d3_geo_clipPolygon(segments, d3_geo_clipSort, null, interpolate, listener); } else if (visibleArea < - || invisible && invisibleArea < -) { listener.polygonEnd(); segments = null; if (pointVisible(, )) listener.point(, ); line.point(, ); var segments, visibleArea, invisibleArea, invisible; var buffer = d3_geo_clipBufferListener(), ringListener = clipLine(buffer), ring; function pointRing(, ) { ringListener.point(, ); if (!n) { invisible = true; invisibleArea += d3_geo_clipAreaRing(ring, -1); ring = null; return; } visibleArea += d3_geo_clipAreaRing(segment, 1); listener.lineStart(); while (++i < n) listener.point((point = segment[i])[0], point[1]); listener.lineEnd(); function d3_geo_clipAreaRing(ring, invisible) { if (!(n = ring.length)) return 0; var n, i = 0, area = 0, p = ring[0],  = p[0],  = p[1], cos = Math.cos(), x0 = Math.atan2(invisible * Math.sin() * cos, Math.sin()), y0 = 1 - invisible * Math.cos() * cos, x1 = x0, x, y; while (++i < n) { p = ring[i]; cos = Math.cos( = p[1]); x = Math.atan2(invisible * Math.sin( = p[0]) * cos, Math.sin()); y = 1 - invisible * Math.cos() * cos; if (Math.abs(y0 - 2) <  && Math.abs(y - 2) < ) continue; if (Math.abs(y) <  || Math.abs(y0) < ) {} else if (Math.abs(Math.abs(x - x0) - ) < ) { if (y + y0 > 2) area += 4 * (x - x0); } else if (Math.abs(y0 - 2) < ) area += 4 * (x - x1); else area += ((3 *  + x - x0) % (2 * ) - ) * (y0 + y); x1 = x0, x0 = x, y0 = y; } return area; } function d3_geo_clipSort(a, b) { return ((a = a.point)[0] < 0 ? a[1] -  / 2 -  :  / 2 - a[1]) - ((b = b.point)[0] < 0 ? b[1] -  / 2 -  :  / 2 - b[1]); } var d3_geo_clipAntimeridian = d3_geo_clip(d3_true, d3_geo_clipAntimeridianLine, d3_geo_clipAntimeridianInterpolate); var s1 = 1 > 0 ?  : -, d = Math.abs(1 - 0); if (Math.abs(d - ) < ) { listener.point(0, 0 = (0 + 1) / 2 > 0 ?  / 2 : - / 2); if (Math.abs(0 - s0) < ) 0 -= s0 * ; if (Math.abs(1 - s1) < ) 1 -= s1 * ; return Math.abs(sin0_1) >  ? Math.atan((Math.sin(0) * (cos1 = Math.cos(1)) * Math.sin(1) - Math.sin(1) * (cos0 = Math.cos(0)) * Math.sin(0)) / (cos0 * cos1 * sin0_1)) : (0 + 1) / 2;  = direction *  / 2; } else if (Math.abs(from[0] - to[0]) > ) { var s = (from[0] < to[0] ? 1 : -1) * ; function d3_geo_clipCircle(radius) { var cr = Math.cos(radius), smallRadius = cr > 0, notHemisphere = Math.abs(cr) > , interpolate = d3_geo_circleInterpolate(radius, 6 * d3_radians); return d3_geo_clip(visible, clipLine, interpolate); var  = 1 - 0, polar = Math.abs( - ) < , meridian = polar ||  < ; if (meridian ? polar ? 0 + 1 > 0 ^ q[1] < (Math.abs(q[0] - 0) <  ? 0 : 1) : 0 <= q[1] && q[1] <= 1 :  >  ^ (0 <= q[0] && q[0] <= 1)) { var d3_geo_clipViewMAX = 1e9; function d3_geo_clipView(x0, y0, x1, y1) { return function(listener) { var listener_ = listener, bufferListener = d3_geo_clipBufferListener(), segments, polygon, ring; if ((segments = d3.merge(segments)).length) { d3_geo_clipPolygon(segments, compare, inside, interpolate, listener); } else if (insidePolygon([ x0, y0 ])) { listener.polygonStart(), listener.lineStart(); interpolate(null, null, 1, listener); listener.lineEnd(), listener.polygonEnd(); function inside(point) { var a = corner(point, -1), i = insidePolygon([ a === 0 || a === 3 ? x0 : x1, a > 1 ? y1 : y0 ]); return i; } for (var j = 1, v = polygon[i], m = v.length, a = v[0]; j < m; ++j) { if (b[1] > y && isLeft(a, b, p) > 0) ++wn; } else { if (b[1] <= y && isLeft(a, b, p) < 0) --wn; function isLeft(a, b, c) { return (b[0] - a[0]) * (c[1] - a[1]) - (c[0] - a[0]) * (b[1] - a[1]); } function visible(x, y) { if (visible(x, y)) listener.point(x, y); } var x__, y__, v__, x_, y_, v_, first; x = Math.max(-d3_geo_clipViewMAX, Math.min(d3_geo_clipViewMAX, x)); y = Math.max(-d3_geo_clipViewMAX, Math.min(d3_geo_clipViewMAX, y)); var v = visible(x, y); var a = [ x_, y_ ], b = [ x, y ]; if (clipLine(a, b)) { listener.point(a[0], a[1]); } listener.point(b[0], b[1]); } else { return Math.abs(p[0] - x0) <  ? direction > 0 ? 0 : 3 : Math.abs(p[0] - x1) <  ? direction > 0 ? 2 : 1 : Math.abs(p[1] - y0) <  ? direction > 0 ? 1 : 0 : direction > 0 ? 3 : 2; return comparePoints(a.point, b.point); function clipLine(a, b) { var dx = b[0] - a[0], dy = b[1] - a[1], t = [ 0, 1 ]; if (Math.abs(dx) <  && Math.abs(dy) < ) return x0 <= a[0] && a[0] <= x1 && y0 <= a[1] && a[1] <= y1; if (d3_geo_clipViewT(x0 - a[0], dx, t) && d3_geo_clipViewT(a[0] - x1, -dx, t) && d3_geo_clipViewT(y0 - a[1], dy, t) && d3_geo_clipViewT(a[1] - y1, -dy, t)) { if (t[1] < 1) { b[0] = a[0] + t[1] * dx; b[1] = a[1] + t[1] * dy; } if (t[0] > 0) { a[0] += t[0] * dx; a[1] += t[0] * dy; } return true; } return false; } } function d3_geo_clipViewT(num, denominator, t) { if (Math.abs(denominator) < ) return num <= 0; var u = num / denominator; if (denominator > 0) { if (u > t[1]) return false; if (u > t[0]) t[0] = u; } else { if (u < t[0]) return false; if (u < t[1]) t[1] = u; } return true; } function d3_geo_compose(a, b) { function compose(x, y) { return x = a(x, y), b(x[0], x[1]); } if (a.invert && b.invert) compose.invert = function(x, y) { return x = b.invert(x, y), x && a.invert(x[0], x[1]); return compose; var 2 = .5, maxDepth = 16; function resample(stream) { var 0, x0, y0, a0, b0, c0; resample.lineStart = polygonLineStart; function polygonLineStart() { var 00, 00, x00, y00, a00, b00, c00; resample.point = function(, ) { linePoint(00 = , 00 = ), x00 = x0, y00 = y0, a00 = a0, b00 = b0, c00 = c0; resample.point = linePoint; }; resample.lineEnd = function() { resampleLineTo(x0, y0, 0, a0, b0, c0, x00, y00, 00, a00, b00, c00, maxDepth, stream); resample.lineEnd = lineEnd; lineEnd(); }; var a = a0 + a1, b = b0 + b1, c = c0 + c1, m = Math.sqrt(a * a + b * b + c * c), 2 = Math.asin(c /= m), 2 = Math.abs(Math.abs(c) - 1) <  ? (0 + 1) / 2 : Math.atan2(b, a), p = project(2, 2), x2 = p[0], y2 = p[1], dx2 = x2 - x0, dy2 = y2 - y0, dz = dy * dx2 - dx * dy2; if (dz * dz / d2 > 2 || Math.abs((dx * dx2 + dy * dy2) / d2 - .5) > .3) { }), k = 150, x = 480, y = 250,  = 0,  = 0,  = 0,  = 0,  = 0, x, y, preclip = d3_geo_clipAntimeridian, postclip = d3_identity, clipAngle = null, clipExtent = null; projection.stream = function(stream) { return d3_geo_projectionRadiansRotate(rotate, preclip(projectResample(postclip(stream)))); return projection; postclip = _ == null ? d3_identity : d3_geo_clipView(_[0][0], _[0][1], _[1][0], _[1][1]); return projection; function d3_geo_projectionRadiansRotate(rotate, stream) { return { point: function(x, y) { y = rotate(x * d3_radians, y * d3_radians), x = y[0]; stream.point(x >  ? x - 2 *  : x < - ? x + 2 *  : x, y[1]); }, sphere: function() { stream.sphere(); }, lineStart: function() { stream.lineStart(); }, lineEnd: function() { stream.lineEnd(); }, polygonStart: function() { stream.polygonStart(); }, polygonEnd: function() { stream.polygonEnd(); } }; function d3_geo_rotation(, , ) { return  ?  ||  ? d3_geo_compose(d3_geo_rotation(), d3_geo_rotation(, )) : d3_geo_rotation() :  ||  ? d3_geo_rotation(, ) : d3_geo_equirectangular; return  += , [  >  ?  - 2 *  :  < - ?  + 2 *  : ,  ]; return [ Math.atan2(y * cos - k * sin, x * cos - z * sin), Math.asin(Math.max(-1, Math.min(1, k * cos + y * sin))) ]; return [ Math.atan2(y * cos + z * sin, x * cos + k * sin), Math.asin(Math.max(-1, Math.min(1, k * cos - x * sin))) ]; if (direction > 0 ? from < to : from > to) from += direction * 2 * ; } else { from = radius + direction * 2 * ; to = radius; } var point; for (var step = direction * precision, t = from; direction > 0 ? t > to : t < to; t -= step) { return Math.abs(x % DX) > ; }).map(x)).concat(d3.range(Math.ceil(y0 / dy) * dy, y1, dy).filter(function(y) { return Math.abs(y % DY) > ; var sin = Math.sin( *= d3_radians), cos = Math.cos(), t = Math.abs(( *= d3_radians) - 0), cos = Math.cos(t); function d3_geo_conic(projectAt) { var 0 = 0, 1 =  / 3, m = d3_geo_projectionMutator(projectAt), p = m(0, 1); p.parallels = function(_) { if (!arguments.length) return [ 0 /  * 180, 1 /  * 180 ]; return m(0 = _[0] *  / 180, 1 = _[1] *  / 180); }; return p; } function d3_geo_conicEqualArea(0, 1) { var sin0 = Math.sin(0), n = (sin0 + Math.sin(1)) / 2, C = 1 + sin0 * (2 * n - sin0), 0 = Math.sqrt(C) / n; function forward(, ) { var  = Math.sqrt(C - 2 * n * Math.sin()) / n; return [  * Math.sin( *= n), 0 -  * Math.cos() ]; } forward.invert = function(x, y) { var 0_y = 0 - y; return [ Math.atan2(x, 0_y) / n, Math.asin((C - (x * x + 0_y * 0_y) * n * n) / (2 * n)) ]; }; return forward; } (d3.geo.conicEqualArea = function() { return d3_geo_conic(d3_geo_conicEqualArea); }).raw = d3_geo_conicEqualArea; d3.geo.albersUsa = function() { var lower48 = d3.geo.conicEqualArea().rotate([ 98, 0 ]).center([ 0, 38 ]).parallels([ 29.5, 45.5 ]); var alaska = d3.geo.conicEqualArea().rotate([ 160, 0 ]).center([ 0, 60 ]).parallels([ 55, 65 ]); var hawaii = d3.geo.conicEqualArea().rotate([ 160, 0 ]).center([ 0, 20 ]).parallels([ 8, 18 ]); var puertoRico = d3.geo.conicEqualArea().rotate([ 60, 0 ]).center([ 0, 10 ]).parallels([ 8, 18 ]); var alaskaInvert, hawaiiInvert, puertoRicoInvert; function albersUsa(coordinates) { return projection(coordinates)(coordinates); } function projection(point) { var lon = point[0], lat = point[1]; return lat > 50 ? alaska : lon < -140 ? hawaii : lat < 21 ? puertoRico : lower48; } albersUsa.invert = function(coordinates) { return alaskaInvert(coordinates) || hawaiiInvert(coordinates) || puertoRicoInvert(coordinates) || lower48.invert(coordinates); }; albersUsa.scale = function(x) { if (!arguments.length) return lower48.scale(); lower48.scale(x); alaska.scale(x * .6); hawaii.scale(x); puertoRico.scale(x * 1.5); return albersUsa.translate(lower48.translate()); }; albersUsa.translate = function(x) { if (!arguments.length) return lower48.translate(); var dz = lower48.scale(), dx = x[0], dy = x[1]; lower48.translate(x); alaska.translate([ dx - .4 * dz, dy + .17 * dz ]); hawaii.translate([ dx - .19 * dz, dy + .2 * dz ]); puertoRico.translate([ dx + .58 * dz, dy + .43 * dz ]); alaskaInvert = d3_geo_albersUsaInvert(alaska, [ [ -180, 50 ], [ -130, 72 ] ]); hawaiiInvert = d3_geo_albersUsaInvert(hawaii, [ [ -164, 18 ], [ -154, 24 ] ]); puertoRicoInvert = d3_geo_albersUsaInvert(puertoRico, [ [ -67.5, 17.5 ], [ -65, 19 ] ]); return albersUsa; }; return albersUsa.scale(1e3); }; function d3_geo_albersUsaInvert(projection, extent) { var a = projection(extent[0]), b = projection([ .5 * (extent[0][0] + extent[1][0]), extent[0][1] ]), c = projection([ extent[1][0], extent[0][1] ]), d = projection(extent[1]); var dya = b[1] - a[1], dxa = b[0] - a[0], dyb = c[1] - b[1], dxb = c[0] - b[0]; var ma = dya / dxa, mb = dyb / dxb; var cx = .5 * (ma * mb * (a[1] - c[1]) + mb * (a[0] + b[0]) - ma * (b[0] + c[0])) / (mb - ma), cy = (.5 * (a[0] + b[0]) - cx) / ma + .5 * (a[1] + b[1]); var dx0 = d[0] - cx, dy0 = d[1] - cy, dx1 = a[0] - cx, dy1 = a[1] - cy, r0 = dx0 * dx0 + dy0 * dy0, r1 = dx1 * dx1 + dy1 * dy1; var a0 = Math.atan2(dy0, dx0), a1 = Math.atan2(dy1, dx1); return function(coordinates) { var dx = coordinates[0] - cx, dy = coordinates[1] - cy, r = dx * dx + dy * dy, a = Math.atan2(dy, dx); if (r0 < r && r < r1 && a0 < a && a < a1) return projection.invert(coordinates); }; } var d3_geo_pathAreaSum, d3_geo_pathAreaPolygon, d3_geo_pathArea = { point: d3_noop, lineStart: d3_noop, lineEnd: d3_noop, polygonStart: function() { d3_geo_pathAreaPolygon = 0; d3_geo_pathArea.lineStart = d3_geo_pathAreaRingStart; }, polygonEnd: function() { d3_geo_pathArea.lineStart = d3_geo_pathArea.lineEnd = d3_geo_pathArea.point = d3_noop; d3_geo_pathAreaSum += Math.abs(d3_geo_pathAreaPolygon / 2); } }; function d3_geo_pathAreaRingStart() { var x00, y00, x0, y0; d3_geo_pathArea.point = function(x, y) { d3_geo_pathArea.point = nextPoint; x00 = x0 = x, y00 = y0 = y; }; function nextPoint(x, y) { d3_geo_pathAreaPolygon += y0 * x - x0 * y; x0 = x, y0 = y; } d3_geo_pathArea.lineEnd = function() { nextPoint(x00, y00); }; } function d3_geo_pathBuffer() { var pointCircle = d3_geo_pathCircle(4.5), buffer = []; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointCircle = d3_geo_pathCircle(_); return stream; }, result: function() { if (buffer.length) { var result = buffer.join(""""); buffer = []; return result; } } }; function point(x, y) { buffer.push(""M"", x, "","", y, pointCircle); } function pointLineStart(x, y) { buffer.push(""M"", x, "","", y); stream.point = pointLine; } function pointLine(x, y) { buffer.push(""L"", x, "","", y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { buffer.push(""Z""); } return stream; } var d3_geo_pathCentroid = { point: d3_geo_pathCentroidPoint, lineStart: d3_geo_pathCentroidLineStart, lineEnd: d3_geo_pathCentroidLineEnd, polygonStart: function() { d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidRingStart; }, polygonEnd: function() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; d3_geo_pathCentroid.lineStart = d3_geo_pathCentroidLineStart; d3_geo_pathCentroid.lineEnd = d3_geo_pathCentroidLineEnd; } }; function d3_geo_pathCentroidPoint(x, y) { if (d3_geo_centroidDimension) return; d3_geo_centroidX += x; d3_geo_centroidY += y; ++d3_geo_centroidZ; } function d3_geo_pathCentroidLineStart() { var x0, y0; if (d3_geo_centroidDimension !== 1) { if (d3_geo_centroidDimension < 1) { d3_geo_centroidDimension = 1; d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; } else return; } d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; x0 = x, y0 = y; }; function nextPoint(x, y) { var dx = x - x0, dy = y - y0, z = Math.sqrt(dx * dx + dy * dy); d3_geo_centroidX += z * (x0 + x) / 2; d3_geo_centroidY += z * (y0 + y) / 2; d3_geo_centroidZ += z; x0 = x, y0 = y; } } function d3_geo_pathCentroidLineEnd() { d3_geo_pathCentroid.point = d3_geo_pathCentroidPoint; } function d3_geo_pathCentroidRingStart() { var x00, y00, x0, y0; if (d3_geo_centroidDimension < 2) { d3_geo_centroidDimension = 2; d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; } d3_geo_pathCentroid.point = function(x, y) { d3_geo_pathCentroid.point = nextPoint; x00 = x0 = x, y00 = y0 = y; }; function nextPoint(x, y) { var z = y0 * x - x0 * y; d3_geo_centroidX += z * (x0 + x); d3_geo_centroidY += z * (y0 + y); d3_geo_centroidZ += z * 3; x0 = x, y0 = y; } d3_geo_pathCentroid.lineEnd = function() { nextPoint(x00, y00); }; } function d3_geo_pathContext(context) { var pointRadius = 4.5; var stream = { point: point, lineStart: function() { stream.point = pointLineStart; }, lineEnd: lineEnd, polygonStart: function() { stream.lineEnd = lineEndPolygon; }, polygonEnd: function() { stream.lineEnd = lineEnd; stream.point = point; }, pointRadius: function(_) { pointRadius = _; return stream; }, result: d3_noop }; function point(x, y) { context.moveTo(x, y); context.arc(x, y, pointRadius, 0, 2 * ); } function pointLineStart(x, y) { context.moveTo(x, y); stream.point = pointLine; } function pointLine(x, y) { context.lineTo(x, y); } function lineEnd() { stream.point = point; } function lineEndPolygon() { context.closePath(); } return stream; } d3.geo.path = function() { var pointRadius = 4.5, projection, context, projectStream, contextStream; function path(object) { if (object) d3.geo.stream(object, projectStream(contextStream.pointRadius(typeof pointRadius === ""function"" ? +pointRadius.apply(this, arguments) : pointRadius))); return contextStream.result(); } path.area = function(object) { d3_geo_pathAreaSum = 0; d3.geo.stream(object, projectStream(d3_geo_pathArea)); return d3_geo_pathAreaSum; }; path.centroid = function(object) { d3_geo_centroidDimension = d3_geo_centroidX = d3_geo_centroidY = d3_geo_centroidZ = 0; d3.geo.stream(object, projectStream(d3_geo_pathCentroid)); return d3_geo_centroidZ ? [ d3_geo_centroidX / d3_geo_centroidZ, d3_geo_centroidY / d3_geo_centroidZ ] : undefined; }; path.bounds = function(object) { return d3_geo_bounds(projectStream)(object); }; path.projection = function(_) { if (!arguments.length) return projection; projectStream = (projection = _) ? _.stream || d3_geo_pathProjectStream(_) : d3_identity; return path; }; path.context = function(_) { if (!arguments.length) return context; contextStream = (context = _) == null ? new d3_geo_pathBuffer() : new d3_geo_pathContext(_); return path; }; path.pointRadius = function(_) { if (!arguments.length) return pointRadius; pointRadius = typeof _ === ""function"" ? _ : +_; return path; }; return path.projection(d3.geo.albersUsa()).context(null); }; function d3_geo_pathCircle(radius) { return ""m0,"" + radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + -2 * radius + ""a"" + radius + "","" + radius + "" 0 1,1 0,"" + +2 * radius + ""z""; } function d3_geo_pathProjectStream(project) { var resample = d3_geo_resample(function(, ) { return project([  * d3_degrees,  * d3_degrees ]); }); return function(stream) { stream = resample(stream); return { point: function(, ) { stream.point( * d3_radians,  * d3_radians); }, sphere: function() { stream.sphere(); }, lineStart: function() { stream.lineStart(); }, lineEnd: function() { stream.lineEnd(); }, polygonStart: function() { stream.polygonStart(); }, polygonEnd: function() { stream.polygonEnd(); } }; }; } d3.geo.albers = function() { return d3.geo.conicEqualArea().parallels([ 29.5, 45.5 ]).rotate([ 98, 0 ]).center([ 0, 38 ]).scale(1e3); }; var  = Math.abs(Math.abs() -  / 2) <  ? 0 : F / Math.pow(t(), n); return [ Math.atan2(x, 0_y) / n, 2 * Math.atan(Math.pow(F / , 1 / n)) -  / 2 ]; if (Math.abs(n) < ) return d3_geo_equirectangular; return [ x, 2 * Math.atan(Math.exp(y)) -  / 2 ]; var B = Math.cos() * Math.sin(); return [ Math.log((1 + B) / (1 - B)) / 2, Math.atan2(Math.tan(), Math.cos()) ]; return [ Math.atan2(d3_sinh(x), Math.cos(y)), d3_asin(Math.sin(y) / d3_cosh(x)) ]; return d3_geo_mercatorProjection(d3_geo_transverseMercator); d3.svg = {}; function d3_svg_line(projection) { var x = d3_svg_lineX, y = d3_svg_lineY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, tension = .7; function line(data) { var segments = [], points = [], i = -1, n = data.length, d, fx = d3_functor(x), fy = d3_functor(y); function segment() { segments.push(""M"", interpolate(projection(points), tension)); } while (++i < n) { if (defined.call(this, d = data[i], i)) { points.push([ +fx.call(this, d, i), +fy.call(this, d, i) ]); } else if (points.length) { segment(); points = []; } } if (points.length) segment(); return segments.length ? segments.join("""") : null; } line.x = function(_) { if (!arguments.length) return x; x = _; return line; }; line.y = function(_) { if (!arguments.length) return y; y = _; return line; }; line.defined = function(_) { if (!arguments.length) return defined; defined = _; return line; }; line.interpolate = function(_) { if (!arguments.length) return interpolateKey; if (typeof _ === ""function"") interpolateKey = interpolate = _; else interpolateKey = (interpolate = d3_svg_lineInterpolators.get(_) || d3_svg_lineLinear).key; return line; }; line.tension = function(_) { if (!arguments.length) return tension; tension = _; return line; }; return line; } d3.svg.line = function() { return d3_svg_line(d3_identity); }; function d3_svg_lineX(d) { function d3_svg_lineY(d) { var d3_svg_lineInterpolators = d3.map({ linear: d3_svg_lineLinear, ""linear-closed"": d3_svg_lineLinearClosed, ""step-before"": d3_svg_lineStepBefore, ""step-after"": d3_svg_lineStepAfter, basis: d3_svg_lineBasis, ""basis-open"": d3_svg_lineBasisOpen, ""basis-closed"": d3_svg_lineBasisClosed, bundle: d3_svg_lineBundle, cardinal: d3_svg_lineCardinal, ""cardinal-open"": d3_svg_lineCardinalOpen, ""cardinal-closed"": d3_svg_lineCardinalClosed, monotone: d3_svg_lineMonotone }); d3_svg_lineInterpolators.forEach(function(key, value) { value.key = key; value.closed = /-closed$/.test(key); }); function d3_svg_lineLinear(points) { return points.join(""L""); } function d3_svg_lineLinearClosed(points) { return d3_svg_lineLinear(points) + ""Z""; } function d3_svg_lineStepBefore(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""V"", (p = points[i])[1], ""H"", p[0]); return path.join(""""); } function d3_svg_lineStepAfter(points) { var i = 0, n = points.length, p = points[0], path = [ p[0], "","", p[1] ]; while (++i < n) path.push(""H"", (p = points[i])[0], ""V"", p[1]); return path.join(""""); } function d3_svg_lineCardinalOpen(points, tension) { return points.length < 4 ? d3_svg_lineLinear(points) : points[1] + d3_svg_lineHermite(points.slice(1, points.length - 1), d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineCardinalClosed(points, tension) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite((points.push(points[0]), points), d3_svg_lineCardinalTangents([ points[points.length - 2] ].concat(points, [ points[1] ]), tension)); } function d3_svg_lineCardinal(points, tension) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineCardinalTangents(points, tension)); } function d3_svg_lineHermite(points, tangents) { if (tangents.length < 1 || points.length != tangents.length && points.length != tangents.length + 2) { return d3_svg_lineLinear(points); } var quad = points.length != tangents.length, path = """", p0 = points[0], p = points[1], t0 = tangents[0], t = t0, pi = 1; if (quad) { path += ""Q"" + (p[0] - t0[0] * 2 / 3) + "","" + (p[1] - t0[1] * 2 / 3) + "","" + p[0] + "","" + p[1]; p0 = points[1]; pi = 2; } if (tangents.length > 1) { t = tangents[1]; p = points[pi]; pi++; path += ""C"" + (p0[0] + t0[0]) + "","" + (p0[1] + t0[1]) + "","" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; for (var i = 2; i < tangents.length; i++, pi++) { p = points[pi]; t = tangents[i]; path += ""S"" + (p[0] - t[0]) + "","" + (p[1] - t[1]) + "","" + p[0] + "","" + p[1]; } } if (quad) { var lp = points[pi]; path += ""Q"" + (p[0] + t[0] * 2 / 3) + "","" + (p[1] + t[1] * 2 / 3) + "","" + lp[0] + "","" + lp[1]; } return path; } function d3_svg_lineCardinalTangents(points, tension) { var tangents = [], a = (1 - tension) / 2, p0, p1 = points[0], p2 = points[1], i = 1, n = points.length; while (++i < n) { p0 = p1; p1 = p2; p2 = points[i]; tangents.push([ a * (p2[0] - p0[0]), a * (p2[1] - p0[1]) ]); } return tangents; } function d3_svg_lineBasis(points) { if (points.length < 3) return d3_svg_lineLinear(points); var i = 1, n = points.length, pi = points[0], x0 = pi[0], y0 = pi[1], px = [ x0, x0, x0, (pi = points[1])[0] ], py = [ y0, y0, y0, pi[1] ], path = [ x0, "","", y0 ]; d3_svg_lineBasisBezier(path, px, py); while (++i < n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } i = -1; while (++i < 2) { px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBasisOpen(points) { if (points.length < 4) return d3_svg_lineLinear(points); var path = [], i = -1, n = points.length, pi, px = [ 0 ], py = [ 0 ]; while (++i < 3) { pi = points[i]; px.push(pi[0]); py.push(pi[1]); } path.push(d3_svg_lineDot4(d3_svg_lineBasisBezier3, px) + "","" + d3_svg_lineDot4(d3_svg_lineBasisBezier3, py)); --i; while (++i < n) { pi = points[i]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBasisClosed(points) { var path, i = -1, n = points.length, m = n + 4, pi, px = [], py = []; while (++i < 4) { pi = points[i % n]; px.push(pi[0]); py.push(pi[1]); } path = [ d3_svg_lineDot4(d3_svg_lineBasisBezier3, px), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, py) ]; --i; while (++i < m) { pi = points[i % n]; px.shift(); px.push(pi[0]); py.shift(); py.push(pi[1]); d3_svg_lineBasisBezier(path, px, py); } return path.join(""""); } function d3_svg_lineBundle(points, tension) { var n = points.length - 1; if (n) { var x0 = points[0][0], y0 = points[0][1], dx = points[n][0] - x0, dy = points[n][1] - y0, i = -1, p, t; while (++i <= n) { p = points[i]; t = i / n; p[0] = tension * p[0] + (1 - tension) * (x0 + t * dx); p[1] = tension * p[1] + (1 - tension) * (y0 + t * dy); } } return d3_svg_lineBasis(points); } function d3_svg_lineDot4(a, b) { return a[0] * b[0] + a[1] * b[1] + a[2] * b[2] + a[3] * b[3]; } var d3_svg_lineBasisBezier1 = [ 0, 2 / 3, 1 / 3, 0 ], d3_svg_lineBasisBezier2 = [ 0, 1 / 3, 2 / 3, 0 ], d3_svg_lineBasisBezier3 = [ 0, 1 / 6, 2 / 3, 1 / 6 ]; function d3_svg_lineBasisBezier(path, x, y) { path.push(""C"", d3_svg_lineDot4(d3_svg_lineBasisBezier1, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier1, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier2, y), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, x), "","", d3_svg_lineDot4(d3_svg_lineBasisBezier3, y)); } function d3_svg_lineSlope(p0, p1) { return (p1[1] - p0[1]) / (p1[0] - p0[0]); } function d3_svg_lineFiniteDifferences(points) { var i = 0, j = points.length - 1, m = [], p0 = points[0], p1 = points[1], d = m[0] = d3_svg_lineSlope(p0, p1); while (++i < j) { m[i] = (d + (d = d3_svg_lineSlope(p0 = p1, p1 = points[i + 1]))) / 2; } m[i] = d; return m; } function d3_svg_lineMonotoneTangents(points) { var tangents = [], d, a, b, s, m = d3_svg_lineFiniteDifferences(points), i = -1, j = points.length - 1; while (++i < j) { d = d3_svg_lineSlope(points[i], points[i + 1]); if (Math.abs(d) < 1e-6) { m[i] = m[i + 1] = 0; } else { a = m[i] / d; b = m[i + 1] / d; s = a * a + b * b; if (s > 9) { s = d * 3 / Math.sqrt(s); m[i] = s * a; m[i + 1] = s * b; } } } i = -1; while (++i <= j) { s = (points[Math.min(j, i + 1)][0] - points[Math.max(0, i - 1)][0]) / (6 * (1 + m[i] * m[i])); tangents.push([ s || 0, m[i] * s || 0 ]); } return tangents; } function d3_svg_lineMonotone(points) { return points.length < 3 ? d3_svg_lineLinear(points) : points[0] + d3_svg_lineHermite(points, d3_svg_lineMonotoneTangents(points)); } d3.geom.hull = function(vertices) { var x = d3_svg_lineX, y = d3_svg_lineY; var fx = d3_functor(x), fy = d3_functor(y), n = data.length, vertices, plen = n - 1, points = [], stack = [], d, i, j, h = 0, x1, y1, x2, y2, u, v, a, sp; if (fx === d3_svg_lineX && y === d3_svg_lineY) vertices = data; else for (i = 0, vertices = []; i < n; ++i) { vertices.push([ +fx.call(this, d = data[i], i), +fy.call(this, d, i) ]); } for (i = 1; i < n; ++i) { if (vertices[i][1] < vertices[h][1] || vertices[i][1] == vertices[h][1] && vertices[i][0] < vertices[h][0]) h = i; } for (i = 0; i < n; ++i) { if (i === h) continue; y1 = vertices[i][1] - vertices[h][1]; x1 = vertices[i][0] - vertices[h][0]; points.push({ angle: Math.atan2(y1, x1), index: i }); } points.sort(function(a, b) { return a.angle - b.angle; }); a = points[0].angle; v = points[0].index; u = 0; for (i = 1; i < plen; ++i) { j = points[i].index; if (a == points[i].angle) { x1 = vertices[v][0] - vertices[h][0]; y1 = vertices[v][1] - vertices[h][1]; x2 = vertices[j][0] - vertices[h][0]; y2 = vertices[j][1] - vertices[h][1]; if (x1 * x1 + y1 * y1 >= x2 * x2 + y2 * y2) { points[i].index = -1; continue; } else { points[u].index = -1; } } a = points[i].angle; u = i; v = j; } stack.push(h); for (i = 0, j = 0; i < 2; ++j) { if (points[j].index > -1) { stack.push(points[j].index); i++; } } sp = stack.length; for (;j < plen; ++j) { if (points[j].index < 0) continue; while (!d3_geom_hullCCW(stack[sp - 2], stack[sp - 1], points[j].index, vertices)) { --sp; } stack[sp++] = points[j].index; } var poly = []; for (i = sp - 1; i >= 0; --i) poly.push(data[stack[i]]); return poly; function d3_geom_hullCCW(i1, i2, i3, v) { var t, a, b, c, d, e, f; t = v[i1]; a = t[0]; b = t[1]; t = v[i2]; c = t[0]; d = t[1]; t = v[i3]; e = t[0]; f = t[1]; return (f - b) * (c - a) - (d - b) * (e - a) > 0; coordinates.area = function() { var i = 0, n = coordinates.length, area = coordinates[n - 1][1] * coordinates[0][0] - coordinates[n - 1][0] * coordinates[0][1]; while (++i < n) { area += coordinates[i - 1][1] * coordinates[i][0] - coordinates[i - 1][0] * coordinates[i][1]; } return area * .5; }; coordinates.centroid = function(k) { var i = -1, n = coordinates.length, x = 0, y = 0, a, b = coordinates[n - 1], c; if (!arguments.length) k = -1 / (6 * coordinates.area()); while (++i < n) { a = b; b = coordinates[i]; c = a[0] * b[1] - b[0] * a[1]; x += (a[0] + b[0]) * c; y += (a[1] + b[1]) * c; } return [ x * k, y * k ]; }; coordinates.clip = function(subject) { var input, i = -1, n = coordinates.length, j, m, a = coordinates[n - 1], b, c, d; while (++i < n) { input = subject.slice(); subject.length = 0; b = coordinates[i]; c = input[(m = input.length) - 1]; j = -1; while (++j < m) { d = input[j]; if (d3_geom_polygonInside(d, a, b)) { if (!d3_geom_polygonInside(c, a, b)) { subject.push(d3_geom_polygonIntersect(c, d, a, b)); } subject.push(d); } else if (d3_geom_polygonInside(c, a, b)) { c = d; } a = b; } return subject; }; return coordinates; d3.geom.delaunay = function(vertices) { var edges = vertices.map(function() { return []; }), triangles = []; d3_geom_voronoiTessellate(vertices, function(e) { edges[e.region.l.index].push(vertices[e.region.r.index]); }); edges.forEach(function(edge, i) { var v = vertices[i], cx = v[0], cy = v[1]; edge.forEach(function(v) { v.angle = Math.atan2(v[0] - cx, v[1] - cy); }); edge.sort(function(a, b) { return a.angle - b.angle; }); for (var j = 0, m = edge.length - 1; j < m; j++) { triangles.push([ v, edge[j], edge[j + 1] ]); } }); return triangles; }; d3.geom.voronoi = function(points) { var size = null, x = d3_svg_lineX, y = d3_svg_lineY, clip; if (arguments.length) return voronoi(points); function voronoi(data) { var points, polygons = data.map(function() { return []; }), fx = d3_functor(x), fy = d3_functor(y), d, i, n = data.length, Z = 1e6; if (fx === d3_svg_lineX && fy === d3_svg_lineY) points = data; else for (points = [], i = 0; i < n; ++i) { points.push([ +fx.call(this, d = data[i], i), +fy.call(this, d, i) ]); } d3_geom_voronoiTessellate(points, function(e) { var s1, s2, x1, x2, y1, y2; if (e.a === 1 && e.b >= 0) { s1 = e.ep.r; s2 = e.ep.l; } else { s1 = e.ep.l; s2 = e.ep.r; } if (e.a === 1) { y1 = s1 ? s1.y : -Z; x1 = e.c - e.b * y1; y2 = s2 ? s2.y : Z; x2 = e.c - e.b * y2; } else { x1 = s1 ? s1.x : -Z; y1 = e.c - e.a * x1; x2 = s2 ? s2.x : Z; y2 = e.c - e.a * x2; } var v1 = [ x1, y1 ], v2 = [ x2, y2 ]; polygons[e.region.l.index].push(v1, v2); polygons[e.region.r.index].push(v1, v2); }); polygons = polygons.map(function(polygon, i) { var cx = points[i][0], cy = points[i][1], angle = polygon.map(function(v) { return Math.atan2(v[0] - cx, v[1] - cy); }), order = d3.range(polygon.length).sort(function(a, b) { return angle[a] - angle[b]; }); return order.filter(function(d, i) { return !i || angle[d] - angle[order[i - 1]] > ; }).map(function(d) { return polygon[d]; }); }); polygons.forEach(function(polygon, i) { var n = polygon.length; if (!n) return polygon.push([ -Z, -Z ], [ -Z, Z ], [ Z, Z ], [ Z, -Z ]); if (n > 2) return; var p0 = points[i], p1 = polygon[0], p2 = polygon[1], x0 = p0[0], y0 = p0[1], x1 = p1[0], y1 = p1[1], x2 = p2[0], y2 = p2[1], dx = Math.abs(x2 - x1), dy = y2 - y1; if (Math.abs(dy) < ) { var y = y0 < y1 ? -Z : Z; polygon.push([ -Z, y ], [ Z, y ]); } else if (dx < ) { var x = x0 < x1 ? -Z : Z; polygon.push([ x, -Z ], [ x, Z ]); } else { var y = (x2 - x1) * (y1 - y0) < (x1 - x0) * (y2 - y1) ? Z : -Z, z = Math.abs(dy) - dx; if (Math.abs(z) < ) { polygon.push([ dy < 0 ? y : -y, y ]); } else { if (z > 0) y *= -1; polygon.push([ -Z, y ], [ Z, y ]); } } }); if (clip) for (i = 0; i < n; ++i) clip(polygons[i]); for (i = 0; i < n; ++i) polygons[i].point = data[i]; return polygons; } voronoi.x = function(_) { return arguments.length ? (x = _, voronoi) : x; voronoi.y = function(_) { return arguments.length ? (y = _, voronoi) : y; }; voronoi.size = function(_) { if (!arguments.length) return size; if (_ == null) { clip = null; } else { size = [ +_[0], +_[1] ]; clip = d3.geom.polygon([ [ 0, 0 ], [ 0, size[1] ], size, [ size[0], 0 ] ]).clip; } return voronoi; }; voronoi.links = function(data) { var points, graph = data.map(function() { return []; }), links = [], fx = d3_functor(x), fy = d3_functor(y), d, i, n = data.length; if (fx === d3_svg_lineX && fy === d3_svg_lineY) points = data; else for (i = 0; i < n; ++i) { points.push([ +fx.call(this, d = data[i], i), +fy.call(this, d, i) ]); } d3_geom_voronoiTessellate(points, function(e) { var l = e.region.l.index, r = e.region.r.index; if (graph[l][r]) return; graph[l][r] = graph[r][l] = true; links.push({ source: data[l], target: data[r] }); }); return links; }; voronoi.triangles = function(data) { if (x === d3_svg_lineX && y === d3_svg_lineY) return d3.geom.delaunay(data); var points, point, fx = d3_functor(x), fy = d3_functor(y), d, i, n; for (i = 0, points = [], n = data.length; i < n; ++i) { point = [ +fx.call(this, d = data[i], i), +fy.call(this, d, i) ]; point.data = d; points.push(point); } return d3.geom.delaunay(points).map(function(triangle) { return triangle.map(function(point) { return point.data; }); }); }; return voronoi; var d3_geom_voronoiOpposite = { l: ""r"", r: ""l"" }; function d3_geom_voronoiTessellate(points, callback) { var Sites = { list: points.map(function(v, i) { return { index: i, x: v[0], y: v[1] }; }).sort(function(a, b) { return a.y < b.y ? -1 : a.y > b.y ? 1 : a.x < b.x ? -1 : a.x > b.x ? 1 : 0; }), bottomSite: null }; var EdgeList = { list: [], leftEnd: null, rightEnd: null, init: function() { EdgeList.leftEnd = EdgeList.createHalfEdge(null, ""l""); EdgeList.rightEnd = EdgeList.createHalfEdge(null, ""l""); EdgeList.leftEnd.r = EdgeList.rightEnd; EdgeList.rightEnd.l = EdgeList.leftEnd; EdgeList.list.unshift(EdgeList.leftEnd, EdgeList.rightEnd); }, createHalfEdge: function(edge, side) { return { edge: edge, side: side, vertex: null, l: null, r: null }; }, insert: function(lb, he) { he.l = lb; he.r = lb.r; lb.r.l = he; lb.r = he; }, leftBound: function(p) { var he = EdgeList.leftEnd; do { he = he.r; } while (he != EdgeList.rightEnd && Geom.rightOf(he, p)); he = he.l; return he; }, del: function(he) { he.l.r = he.r; he.r.l = he.l; he.edge = null; }, right: function(he) { return he.r; }, left: function(he) { return he.l; }, leftRegion: function(he) { return he.edge == null ? Sites.bottomSite : he.edge.region[he.side]; }, rightRegion: function(he) { return he.edge == null ? Sites.bottomSite : he.edge.region[d3_geom_voronoiOpposite[he.side]]; } }; var Geom = { bisect: function(s1, s2) { var newEdge = { region: { l: s1, r: s2 }, ep: { l: null, r: null } }; var dx = s2.x - s1.x, dy = s2.y - s1.y, adx = dx > 0 ? dx : -dx, ady = dy > 0 ? dy : -dy; newEdge.c = s1.x * dx + s1.y * dy + (dx * dx + dy * dy) * .5; if (adx > ady) { newEdge.a = 1; newEdge.b = dy / dx; newEdge.c /= dx; } else { newEdge.b = 1; newEdge.a = dx / dy; newEdge.c /= dy; } return newEdge; }, intersect: function(el1, el2) { var e1 = el1.edge, e2 = el2.edge; if (!e1 || !e2 || e1.region.r == e2.region.r) { return null; } var d = e1.a * e2.b - e1.b * e2.a; if (Math.abs(d) < 1e-10) { return null; } var xint = (e1.c * e2.b - e2.c * e1.b) / d, yint = (e2.c * e1.a - e1.c * e2.a) / d, e1r = e1.region.r, e2r = e2.region.r, el, e; if (e1r.y < e2r.y || e1r.y == e2r.y && e1r.x < e2r.x) { el = el1; e = e1; } else { el = el2; e = e2; } var rightOfSite = xint >= e.region.r.x; if (rightOfSite && el.side === ""l"" || !rightOfSite && el.side === ""r"") { return null; } return { x: xint, y: yint }; }, rightOf: function(he, p) { var e = he.edge, topsite = e.region.r, rightOfSite = p.x > topsite.x; if (rightOfSite && he.side === ""l"") { return 1; } if (!rightOfSite && he.side === ""r"") { return 0; } if (e.a === 1) { var dyp = p.y - topsite.y, dxp = p.x - topsite.x, fast = 0, above = 0; if (!rightOfSite && e.b < 0 || rightOfSite && e.b >= 0) { above = fast = dyp >= e.b * dxp; } else { above = p.x + p.y * e.b > e.c; if (e.b < 0) { above = !above; } if (!above) { fast = 1; } } if (!fast) { var dxs = topsite.x - e.region.l.x; above = e.b * (dxp * dxp - dyp * dyp) < dxs * dyp * (1 + 2 * dxp / dxs + e.b * e.b); if (e.b < 0) { above = !above; } var yl = e.c - e.a * p.x, t1 = p.y - yl, t2 = p.x - topsite.x, t3 = yl - topsite.y; above = t1 * t1 > t2 * t2 + t3 * t3; } return he.side === ""l"" ? above : !above; }, endPoint: function(edge, side, site) { edge.ep[side] = site; if (!edge.ep[d3_geom_voronoiOpposite[side]]) return; callback(edge); }, distance: function(s, t) { var dx = s.x - t.x, dy = s.y - t.y; return Math.sqrt(dx * dx + dy * dy); } }; var EventQueue = { list: [], insert: function(he, site, offset) { he.vertex = site; he.ystar = site.y + offset; for (var i = 0, list = EventQueue.list, l = list.length; i < l; i++) { var next = list[i]; if (he.ystar > next.ystar || he.ystar == next.ystar && site.x > next.vertex.x) { continue; } else { list.splice(i, 0, he); }, del: function(he) { for (var i = 0, ls = EventQueue.list, l = ls.length; i < l && ls[i] != he; ++i) {} ls.splice(i, 1); }, empty: function() { return EventQueue.list.length === 0; }, nextEvent: function(he) { for (var i = 0, ls = EventQueue.list, l = ls.length; i < l; ++i) { if (ls[i] == he) return ls[i + 1]; } return null; }, min: function() { var elem = EventQueue.list[0]; return { x: elem.vertex.x, y: elem.ystar }; }, extractMin: function() { return EventQueue.list.shift(); } }; EdgeList.init(); Sites.bottomSite = Sites.list.shift(); var newSite = Sites.list.shift(), newIntStar; var lbnd, rbnd, llbnd, rrbnd, bisector; var bot, top, temp, p, v; var e, pm; while (true) { if (!EventQueue.empty()) { newIntStar = EventQueue.min(); } if (newSite && (EventQueue.empty() || newSite.y < newIntStar.y || newSite.y == newIntStar.y && newSite.x < newIntStar.x)) { lbnd = EdgeList.leftBound(newSite); rbnd = EdgeList.right(lbnd); bot = EdgeList.rightRegion(lbnd); e = Geom.bisect(bot, newSite); bisector = EdgeList.createHalfEdge(e, ""l""); EdgeList.insert(lbnd, bisector); p = Geom.intersect(lbnd, bisector); if (p) { EventQueue.del(lbnd); EventQueue.insert(lbnd, p, Geom.distance(p, newSite)); } lbnd = bisector; bisector = EdgeList.createHalfEdge(e, ""r""); EdgeList.insert(lbnd, bisector); p = Geom.intersect(bisector, rbnd); if (p) { EventQueue.insert(bisector, p, Geom.distance(p, newSite)); } newSite = Sites.list.shift(); } else if (!EventQueue.empty()) { lbnd = EventQueue.extractMin(); llbnd = EdgeList.left(lbnd); rbnd = EdgeList.right(lbnd); rrbnd = EdgeList.right(rbnd); bot = EdgeList.leftRegion(lbnd); top = EdgeList.rightRegion(rbnd); v = lbnd.vertex; Geom.endPoint(lbnd.edge, lbnd.side, v); Geom.endPoint(rbnd.edge, rbnd.side, v); EdgeList.del(lbnd); EventQueue.del(rbnd); EdgeList.del(rbnd); pm = ""l""; if (bot.y > top.y) { temp = bot; bot = top; top = temp; pm = ""r""; } e = Geom.bisect(bot, top); bisector = EdgeList.createHalfEdge(e, pm); EdgeList.insert(llbnd, bisector); Geom.endPoint(e, d3_geom_voronoiOpposite[pm], v); p = Geom.intersect(llbnd, bisector); if (p) { EventQueue.del(llbnd); EventQueue.insert(llbnd, p, Geom.distance(p, bot)); } p = Geom.intersect(bisector, rrbnd); if (p) { EventQueue.insert(bisector, p, Geom.distance(p, bot)); } for (lbnd = EdgeList.right(EdgeList.leftEnd); lbnd != EdgeList.rightEnd; lbnd = EdgeList.right(lbnd)) { callback(lbnd.edge); } } d3.geom.quadtree = function(points, x1, y1, x2, y2) { var x = d3_svg_lineX, y = d3_svg_lineY, compat; if (Math.abs(nx - x) + Math.abs(ny - y) < .01) { var sx = (x1 + x2) * .5, sy = (y1 + y2) * .5, right = x >= sx, bottom = y >= sy, i = (bottom << 1) + right; if (right) x1 = sx; else x2 = sx; if (bottom) y1 = sy; else y2 = sy; quadtree.size = function(_) { if (!arguments.length) return x1 == null ? null : [ x2, y2 ]; if (_ == null) { x1 = y1 = x2 = y2 = null; } else { x1 = y1 = 0; x2 = +_[0], y2 = +_[1]; } d3.transform = function(string) { var g = d3_document.createElementNS(d3.ns.prefix.svg, ""g""); return (d3.transform = function(string) { g.setAttribute(""transform"", string); var t = g.transform.baseVal.consolidate(); return new d3_transform(t ? t.matrix : d3_transformIdentity); })(string); }; function d3_transform(m) { var r0 = [ m.a, m.b ], r1 = [ m.c, m.d ], kx = d3_transformNormalize(r0), kz = d3_transformDot(r0, r1), ky = d3_transformNormalize(d3_transformCombine(r1, r0, -kz)) || 0; if (r0[0] * r1[1] < r1[0] * r0[1]) { r0[0] *= -1; r0[1] *= -1; kx *= -1; kz *= -1; } this.rotate = (kx ? Math.atan2(r0[1], r0[0]) : Math.atan2(-r1[0], r1[1])) * d3_degrees; this.translate = [ m.e, m.f ]; this.scale = [ kx, ky ]; this.skew = ky ? Math.atan2(kz, ky) * d3_degrees : 0; } d3_transform.prototype.toString = function() { return ""translate("" + this.translate + "")rotate("" + this.rotate + "")skewX("" + this.skew + "")scale("" + this.scale + "")""; }; function d3_transformDot(a, b) { return a[0] * b[0] + a[1] * b[1]; } function d3_transformNormalize(a) { var k = Math.sqrt(d3_transformDot(a, a)); if (k) { a[0] /= k; a[1] /= k; } return k; } function d3_transformCombine(a, b, k) { a[0] += k * b[0]; a[1] += k * b[1]; return a; } var d3_transformIdentity = { a: 1, b: 0, c: 0, d: 1, e: 0, f: 0 }; d3.interpolateNumber = d3_interpolateNumber; function d3_interpolateNumber(a, b) { b -= a = +a; return function(t) { return a + b * t; }; } d3.interpolateTransform = d3_interpolateTransform; function d3_interpolateTransform(a, b) { var s = [], q = [], n, A = d3.transform(a), B = d3.transform(b), ta = A.translate, tb = B.translate, ra = A.rotate, rb = B.rotate, wa = A.skew, wb = B.skew, ka = A.scale, kb = B.scale; if (ta[0] != tb[0] || ta[1] != tb[1]) { s.push(""translate("", null, "","", null, "")""); q.push({ i: 1, x: d3_interpolateNumber(ta[0], tb[0]) }, { i: 3, x: d3_interpolateNumber(ta[1], tb[1]) }); } else if (tb[0] || tb[1]) { s.push(""translate("" + tb + "")""); } else { s.push(""""); } if (ra != rb) { if (ra - rb > 180) rb += 360; else if (rb - ra > 180) ra += 360; q.push({ i: s.push(s.pop() + ""rotate("", null, "")"") - 2, x: d3_interpolateNumber(ra, rb) }); } else if (rb) { s.push(s.pop() + ""rotate("" + rb + "")""); } if (wa != wb) { q.push({ i: s.push(s.pop() + ""skewX("", null, "")"") - 2, x: d3_interpolateNumber(wa, wb) }); } else if (wb) { s.push(s.pop() + ""skewX("" + wb + "")""); } if (ka[0] != kb[0] || ka[1] != kb[1]) { n = s.push(s.pop() + ""scale("", null, "","", null, "")""); q.push({ i: n - 4, x: d3_interpolateNumber(ka[0], kb[0]) }, { i: n - 2, x: d3_interpolateNumber(ka[1], kb[1]) }); } else if (kb[0] != 1 || kb[1] != 1) { s.push(s.pop() + ""scale("" + kb + "")""); } n = q.length; return function(t) { var i = -1, o; while (++i < n) s[(o = q[i]).i] = o.x(t); return s.join(""""); }; } i[k] = d3_interpolateByName(k)(a[k], b[k]); d3.interpolateString = d3_interpolateString; function d3_interpolateString(a, b) { var m, i, j, s0 = 0, s1 = 0, s = [], q = [], n, o; a = a + """", b = b + """"; d3_interpolate_number.lastIndex = 0; for (i = 0; m = d3_interpolate_number.exec(b); ++i) { if (m.index) s.push(b.substring(s0, s1 = m.index)); q.push({ i: s.length, x: m[0] }); s.push(null); s0 = d3_interpolate_number.lastIndex; } if (s0 < b.length) s.push(b.substring(s0)); for (i = 0, n = q.length; (m = d3_interpolate_number.exec(a)) && i < n; ++i) { o = q[i]; if (o.x == m[0]) { if (o.i) { if (s[o.i + 1] == null) { s[o.i - 1] += o.x; s.splice(o.i, 1); for (j = i + 1; j < n; ++j) q[j].i--; } else { s[o.i - 1] += o.x + s[o.i + 1]; s.splice(o.i, 2); for (j = i + 1; j < n; ++j) q[j].i -= 2; } } else { if (s[o.i + 1] == null) { s[o.i] = o.x; } else { s[o.i] = o.x + s[o.i + 1]; s.splice(o.i + 1, 1); for (j = i + 1; j < n; ++j) q[j].i--; } } q.splice(i, 1); n--; i--; } else { o.x = d3_interpolateNumber(parseFloat(m[0]), parseFloat(o.x)); } } while (i < n) { o = q.pop(); if (s[o.i + 1] == null) { s[o.i] = o.x; } else { s[o.i] = o.x + s[o.i + 1]; s.splice(o.i + 1, 1); } n--; } if (s.length === 1) { return s[0] == null ? q[0].x : function() { return b; }; } return function(t) { for (i = 0; i < n; ++i) s[(o = q[i]).i] = o.x(t); return s.join(""""); var d3_interpolate_number = /[-+]?(?:\d+\.?\d*|\.?\d+)(?:[eE][-+]?\d+)?/g; function d3_interpolateByName(name) { return name == ""transform"" ? d3_interpolateTransform : d3_interpolate; } return (t === ""string"" || t !== typeof a ? d3_rgb_names.has(b) || /^(#|rgb\(|hsl\()/.test(b) ? d3_interpolateRgb : d3_interpolateString : b instanceof d3_Color ? d3_interpolateRgb : t === ""object"" ? Array.isArray(b) ? d3_interpolateArray : d3_interpolateObject : d3_interpolateNumber)(a, b); var i = name.indexOf(""-""), t = i >= 0 ? name.substring(0, i) : name, m = i >= 0 ? name.substring(i + 1) : ""in""; return d3_ease_clamp(m(t.apply(null, Array.prototype.slice.call(arguments, 1)))); return 1 - Math.cos(t *  / 2); if (arguments.length) s = p / (2 * ) * Math.asin(1 / a); else a = 1, s = p / 4; return function(t) { return 1 + a * Math.pow(2, 10 * -t) * Math.sin((t - s) * 2 *  / p); function d3_uninterpolateNumber(a, b) { b = b - (a = +a) ? 1 / (b - a) : 0; return function(x) { return (x - a) * b; b = b - (a = +a) ? 1 / (b - a) : 0; return function(x) { return Math.max(0, Math.min(1, (x - a) * b)); k = (2 *  - padding * n) / k; value: (x - x0) / k var force = {}, event = d3.dispatch(""start"", ""tick"", ""end""), size = [ 1, 1 ], drag, alpha, friction = .9, linkDistance = d3_layout_forceLinkDistance, linkStrength = d3_layout_forceLinkStrength, charge = -30, gravity = .1, theta = .8, nodes = [], links = [], distances, strengths, charges; var dx = quad.cx - node.x, dy = quad.cy - node.y, dn = 1 / Math.sqrt(dx * dx + dy * dy); if ((x2 - x1) * dn < theta) { var k = quad.charge * dn * dn; node.px -= dx * k; node.py -= dy * k; if (quad.point && isFinite(dn)) { var k = quad.pointCharge * dn * dn; t.x -= x * (k = s.weight / (t.weight + s.weight)); if (!arguments.length) return theta; theta = +x; if (x > 0) alpha = x; else alpha = 0; d3.timer(force.tick); var i, j, n = nodes.length, m = links.length, w = size[0], h = size[1], neighbors, o; var neighbors = neighbor(i), j = -1, m = neighbors.length, x; while (++j < m) if (!isNaN(x = neighbors[j][dimension])) return x; return Math.random() * size; } function neighbor() { if (!neighbors) { neighbors = []; return neighbors[i]; var d3_layout_forceLinkDistance = 20, d3_layout_forceLinkStrength = 1; function recurse(node, depth, nodes) { var childs = children.call(hierarchy, node, depth); node.depth = depth; nodes.push(node); if (childs && (n = childs.length)) { var i = -1, n, c = node.children = [], v = 0, j = depth + 1, d; while (++i < n) { d = recurse(childs[i], j, nodes); d.parent = node; c.push(d); v += d.value; } if (sort) c.sort(sort); if (value) node.value = v; } else if (value) { node.value = +value.call(hierarchy, node, depth) || 0; } return node; } function revalue(node, depth) { var children = node.children, v = 0; if (children && (n = children.length)) { var i = -1, n, j = depth + 1; while (++i < n) v += revalue(children[i], j); } else if (value) { v = +value.call(hierarchy, node, depth) || 0; } if (value) node.value = v; return v; } function hierarchy(d) { var nodes = []; recurse(d, 0, nodes); revalue(root, 0); var value = Number, sort = d3_layout_pieSortByValue, startAngle = 0, endAngle = 2 * ; function pie(data) { var values = data.map(function(d, i) { }); var a = +(typeof startAngle === ""function"" ? startAngle.apply(this, arguments) : startAngle); var k = ((typeof endAngle === ""function"" ? endAngle.apply(this, arguments) : endAngle) - a) / d3.sum(values); var index = d3.range(data.length); var arcs = []; index.forEach(function(i) { var d; value: d = values[i], endAngle: a += d * k pie.value = function(x) { value = x; pie.sort = function(x) { sort = x; pie.startAngle = function(x) { startAngle = x; pie.endAngle = function(x) { endAngle = x; var n = series.length, m = series[0].length, i, j, o; d3.layout.tree = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ]; function tree(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0]; function firstWalk(node, previousSibling) { var children = node.children, layout = node._tree; if (children && (n = children.length)) { var n, firstChild = children[0], previousChild, ancestor = firstChild, child, i = -1; while (++i < n) { child = children[i]; firstWalk(child, previousChild); ancestor = apportion(child, previousChild, ancestor); previousChild = child; } d3_layout_treeShift(node); var midpoint = .5 * (firstChild._tree.prelim + child._tree.prelim); if (previousSibling) { layout.prelim = previousSibling._tree.prelim + separation(node, previousSibling); layout.mod = layout.prelim - midpoint; } else { layout.prelim = midpoint; } } else { if (previousSibling) { layout.prelim = previousSibling._tree.prelim + separation(node, previousSibling); } } } function secondWalk(node, x) { node.x = node._tree.prelim + x; var children = node.children; if (children && (n = children.length)) { var i = -1, n; x += node._tree.mod; while (++i < n) { secondWalk(children[i], x); } } } function apportion(node, previousSibling, ancestor) { if (previousSibling) { var vip = node, vop = node, vim = previousSibling, vom = node.parent.children[0], sip = vip._tree.mod, sop = vop._tree.mod, sim = vim._tree.mod, som = vom._tree.mod, shift; while (vim = d3_layout_treeRight(vim), vip = d3_layout_treeLeft(vip), vim && vip) { vom = d3_layout_treeLeft(vom); vop = d3_layout_treeRight(vop); vop._tree.ancestor = node; shift = vim._tree.prelim + sim - vip._tree.prelim - sip + separation(vim, vip); if (shift > 0) { d3_layout_treeMove(d3_layout_treeAncestor(vim, node, ancestor), node, shift); sip += shift; sop += shift; } sim += vim._tree.mod; sip += vip._tree.mod; som += vom._tree.mod; sop += vop._tree.mod; } if (vim && !d3_layout_treeRight(vop)) { vop._tree.thread = vim; vop._tree.mod += sim - sop; } if (vip && !d3_layout_treeLeft(vom)) { vom._tree.thread = vip; vom._tree.mod += sip - som; ancestor = node; } } return ancestor; } d3_layout_treeVisitAfter(root, function(node, previousSibling) { node._tree = { ancestor: node, prelim: 0, mod: 0, change: 0, shift: 0, number: previousSibling ? previousSibling._tree.number + 1 : 0 }; }); firstWalk(root); secondWalk(root, -root._tree.prelim); var left = d3_layout_treeSearch(root, d3_layout_treeLeftmost), right = d3_layout_treeSearch(root, d3_layout_treeRightmost), deep = d3_layout_treeSearch(root, d3_layout_treeDeepest), x0 = left.x - separation(left, right) / 2, x1 = right.x + separation(right, left) / 2, y1 = deep.depth || 1; d3_layout_treeVisitAfter(root, function(node) { node.x = (node.x - x0) / (x1 - x0) * size[0]; node.y = node.depth / y1 * size[1]; delete node._tree; }); return nodes; } tree.separation = function(x) { if (!arguments.length) return separation; separation = x; return tree; }; tree.size = function(x) { if (!arguments.length) return size; size = x; return tree; }; return d3_layout_hierarchyRebind(tree, hierarchy); }; function d3_layout_treeSeparation(a, b) { return a.parent == b.parent ? 1 : 2; } function d3_layout_treeLeft(node) { var children = node.children; return children && children.length ? children[0] : node._tree.thread; } function d3_layout_treeRight(node) { var children = node.children, n; return children && (n = children.length) ? children[n - 1] : node._tree.thread; } function d3_layout_treeSearch(node, compare) { var children = node.children; if (children && (n = children.length)) { var child, n, i = -1; while (++i < n) { if (compare(child = d3_layout_treeSearch(children[i], compare), node) > 0) { node = child; } } } return node; } function d3_layout_treeRightmost(a, b) { return a.x - b.x; } function d3_layout_treeLeftmost(a, b) { return b.x - a.x; } function d3_layout_treeDeepest(a, b) { return a.depth - b.depth; } function d3_layout_treeVisitAfter(node, callback) { function visit(node, previousSibling) { var children = node.children; if (children && (n = children.length)) { var child, previousChild = null, i = -1, n; while (++i < n) { child = children[i]; visit(child, previousChild); previousChild = child; } } callback(node, previousSibling); } visit(node, null); } function d3_layout_treeShift(node) { var shift = 0, change = 0, children = node.children, i = children.length, child; while (--i >= 0) { child = children[i]._tree; child.prelim += shift; child.mod += shift; shift += child.shift + (change += child.change); } } function d3_layout_treeMove(ancestor, node, shift) { ancestor = ancestor._tree; node = node._tree; var change = shift / (node.number - ancestor.number); ancestor.change += change; node.change -= change; node.shift += shift; node.prelim += shift; node.mod += shift; } function d3_layout_treeAncestor(vim, node, ancestor) { return vim._tree.ancestor.parent == node.parent ? vim._tree.ancestor : ancestor; } d3.layout.pack = function() { var hierarchy = d3.layout.hierarchy().sort(d3_layout_packSort), padding = 0, size = [ 1, 1 ]; function pack(d, i) { var nodes = hierarchy.call(this, d, i), root = nodes[0]; root.x = 0; root.y = 0; d3_layout_treeVisitAfter(root, function(d) { d.r = Math.sqrt(d.value); d3_layout_treeVisitAfter(root, d3_layout_packSiblings); var w = size[0], h = size[1], k = Math.max(2 * root.r / w, 2 * root.r / h); if (padding > 0) { var dr = padding * k / 2; d3_layout_treeVisitAfter(root, function(d) { d3_layout_treeVisitAfter(root, d3_layout_packSiblings); d3_layout_treeVisitAfter(root, function(d) { k = Math.max(2 * root.r / w, 2 * root.r / h); } d3_layout_packTransform(root, w / 2, h / 2, 1 / k); pack.size = function(x) { size = x; return dr * dr - dx * dx - dy * dy > .001; d3.layout.cluster = function() { var hierarchy = d3.layout.hierarchy().sort(null).value(null), separation = d3_layout_treeSeparation, size = [ 1, 1 ]; d3_layout_treeVisitAfter(root, function(node) { d3_layout_treeVisitAfter(root, function(node) { if (!arguments.length) return size; size = x; root.x = 0; root.y = 0; root.dx = size[0]; root.dy = size[1]; return s / m; if (nice = nice(x1 - x0)) { domain[i0] = nice.floor(x0); domain[i1] = nice.ceil(x1); } scale.nice = function() { d3_scale_nice(domain, d3_scale_linearNice); function d3_scale_linearNice(dx) { dx = Math.pow(10, Math.round(Math.log(dx) / Math.LN10) - 1); return dx && { floor: function(x) { return Math.floor(x / dx) * dx; }, ceil: function(x) { return Math.ceil(x / dx) * dx; } }; var precision = -Math.floor(Math.log(d3_scale_linearTickRange(domain, m)[2]) / Math.LN10 + .01); return d3.format(format ? format.replace(d3_format_re, function(a, b, c, d, e, f, g, h, i, j) { return [ b, c, d, e, f, g, h, i || ""."" + (precision - (j === ""%"") * 2), j ].join(""""); }) : "",."" + precision + ""f""); return d3_scale_log(d3.scale.linear().domain([ 0, Math.LN10 ]), 10, d3_scale_logp, d3_scale_powp); function d3_scale_log(linear, base, log, pow) { if (!arguments.length) return linear.domain().map(pow); if (x[0] < 0) log = d3_scale_logn, pow = d3_scale_pown; else log = d3_scale_logp, pow = d3_scale_powp; linear.domain(x.map(log)); linear.domain(d3_scale_nice(linear.domain(), d3_scale_logNice(base))); var extent = d3_scaleExtent(linear.domain()), ticks = []; if (extent.every(isFinite)) { var b = Math.log(base), i = Math.floor(extent[0] / b), j = Math.ceil(extent[1] / b), u = pow(extent[0]), v = pow(extent[1]), n = base % 1 ? 2 : base; if (log === d3_scale_logn) { ticks.push(-Math.pow(base, -i)); for (;i++ < j; ) for (var k = n - 1; k > 0; k--) ticks.push(-Math.pow(base, -i) * k); } else { for (;i < j; i++) for (var k = 1; k < n; k++) ticks.push(Math.pow(base, i) * k); ticks.push(Math.pow(base, i)); if (arguments.length < 2) format = d3_scale_logFormat; if (!arguments.length) return format; var b = Math.log(base), k = Math.max(.1, n / scale.ticks().length), f = log === d3_scale_logn ? (e = -1e-12, Math.floor) : (e = 1e-12, Math.ceil), e; return function(d) { return d / pow(b * f(log(d) / b + e)) <= k ? format(d) : """"; return d3_scale_log(linear.copy(), base, log, pow); var d3_scale_logFormat = d3.format("".0e""); function d3_scale_logp(x) { return Math.log(x < 0 ? 0 : x); } function d3_scale_powp(x) { return Math.exp(x); } function d3_scale_logn(x) { return -Math.log(x > 0 ? 0 : -x); } function d3_scale_pown(x) { return -Math.exp(-x); } function d3_scale_logNice(base) { base = Math.log(base); var nice = { floor: function(x) { return Math.floor(x / base) * base; }, ceil: function(x) { return Math.ceil(x / base) * base; } }; return function() { return nice; }; } d3.scale.pow = function() { return d3_scale_pow(d3.scale.linear(), 1); function d3_scale_pow(linear, exponent) { if (!arguments.length) return linear.domain().map(powb); linear.domain(x.map(powp)); return d3_scale_linearTicks(scale.domain(), m); return d3_scale_linearTickFormat(scale.domain(), m, format); scale.nice = function() { return scale.domain(d3_scale_nice(scale.domain(), d3_scale_linearNice)); var domain = scale.domain(); return scale.domain(domain); return d3_scale_pow(linear.copy(), exponent); return range[((index.get(x) || index.set(x, domain.push(x))) - 1) % range.length]; var start = x[0], stop = x[1], step = (stop - start) / (Math.max(1, domain.length - 1) + padding); range = steps(domain.length < 2 ? (start + stop) / 2 : start + step * padding / 2, step); var reverse = x[1] < x[0], start = x[reverse - 0], stop = x[1 - reverse], step = Math.floor((stop - start) / (domain.length - padding + 2 * outerPadding)), error = stop - start - (domain.length - padding) * step; range = steps(start + Math.round(error / 2), step); var d3_category10 = [ ""#1f77b4"", ""#ff7f0e"", ""#2ca02c"", ""#d62728"", ""#9467bd"", ""#8c564b"", ""#e377c2"", ""#7f7f7f"", ""#bcbd22"", ""#17becf"" ]; var d3_category20 = [ ""#1f77b4"", ""#aec7e8"", ""#ff7f0e"", ""#ffbb78"", ""#2ca02c"", ""#98df8a"", ""#d62728"", ""#ff9896"", ""#9467bd"", ""#c5b0d5"", ""#8c564b"", ""#c49c94"", ""#e377c2"", ""#f7b6d2"", ""#7f7f7f"", ""#c7c7c7"", ""#bcbd22"", ""#dbdb8d"", ""#17becf"", ""#9edae5"" ]; var d3_category20b = [ ""#393b79"", ""#5254a3"", ""#6b6ecf"", ""#9c9ede"", ""#637939"", ""#8ca252"", ""#b5cf6b"", ""#cedb9c"", ""#8c6d31"", ""#bd9e39"", ""#e7ba52"", ""#e7cb94"", ""#843c39"", ""#ad494a"", ""#d6616b"", ""#e7969c"", ""#7b4173"", ""#a55194"", ""#ce6dbd"", ""#de9ed6"" ]; var d3_category20c = [ ""#3182bd"", ""#6baed6"", ""#9ecae1"", ""#c6dbef"", ""#e6550d"", ""#fd8d3c"", ""#fdae6b"", ""#fdd0a2"", ""#31a354"", ""#74c476"", ""#a1d99b"", ""#c7e9c0"", ""#756bb1"", ""#9e9ac8"", ""#bcbddc"", ""#dadaeb"", ""#636363"", ""#969696"", ""#bdbdbd"", ""#d9d9d9"" ]; if (isNaN(x = +x)) return NaN; return range[d3.bisect(thresholds, x)]; domain = x.filter(function(d) { return !isNaN(d); }).sort(d3.ascending); return range[d3.bisect(domain, x)]; d3.svg.arc = function() { var innerRadius = d3_svg_arcInnerRadius, outerRadius = d3_svg_arcOuterRadius, startAngle = d3_svg_arcStartAngle, endAngle = d3_svg_arcEndAngle; function arc() { var r0 = innerRadius.apply(this, arguments), r1 = outerRadius.apply(this, arguments), a0 = startAngle.apply(this, arguments) + d3_svg_arcOffset, a1 = endAngle.apply(this, arguments) + d3_svg_arcOffset, da = (a1 < a0 && (da = a0, a0 = a1, a1 = da), a1 - a0), df = da <  ? ""0"" : ""1"", c0 = Math.cos(a0), s0 = Math.sin(a0), c1 = Math.cos(a1), s1 = Math.sin(a1); return da >= d3_svg_arcMax ? r0 ? ""M0,"" + r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + -r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + r1 + ""M0,"" + r0 + ""A"" + r0 + "","" + r0 + "" 0 1,0 0,"" + -r0 + ""A"" + r0 + "","" + r0 + "" 0 1,0 0,"" + r0 + ""Z"" : ""M0,"" + r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + -r1 + ""A"" + r1 + "","" + r1 + "" 0 1,1 0,"" + r1 + ""Z"" : r0 ? ""M"" + r1 * c0 + "","" + r1 * s0 + ""A"" + r1 + "","" + r1 + "" 0 "" + df + "",1 "" + r1 * c1 + "","" + r1 * s1 + ""L"" + r0 * c1 + "","" + r0 * s1 + ""A"" + r0 + "","" + r0 + "" 0 "" + df + "",0 "" + r0 * c0 + "","" + r0 * s0 + ""Z"" : ""M"" + r1 * c0 + "","" + r1 * s0 + ""A"" + r1 + "","" + r1 + "" 0 "" + df + "",1 "" + r1 * c1 + "","" + r1 * s1 + ""L0,0"" + ""Z""; arc.centroid = function() { var r = (innerRadius.apply(this, arguments) + outerRadius.apply(this, arguments)) / 2, a = (startAngle.apply(this, arguments) + endAngle.apply(this, arguments)) / 2 + d3_svg_arcOffset; var d3_svg_arcOffset = - / 2, d3_svg_arcMax = 2 *  - 1e-6; a = point[1] + d3_svg_arcOffset; var x0 = d3_svg_lineX, x1 = d3_svg_lineX, y0 = 0, y1 = d3_svg_lineY, defined = d3_true, interpolate = d3_svg_lineLinear, interpolateKey = interpolate.key, interpolateReverse = interpolate, L = ""L"", tension = .7; var subgroup = f.call(self, d, i), r = radius.call(self, subgroup, i), a0 = startAngle.call(self, subgroup, i) + d3_svg_arcOffset, a1 = endAngle.call(self, subgroup, i) + d3_svg_arcOffset; var d = projection.apply(this, arguments), r = d[0], a = d[1] + d3_svg_arcOffset; function d3_transition(groups, id) { d3_arraySubclass(groups, d3_transitionPrototype); groups.id = id; return groups; } var d3_transitionPrototype = [], d3_transitionId = 0, d3_transitionInheritId, d3_transitionInherit = { ease: d3_ease_cubicInOut, delay: 0, duration: 250 }; d3_transitionPrototype.call = d3_selectionPrototype.call; d3_transitionPrototype.empty = d3_selectionPrototype.empty; d3_transitionPrototype.node = d3_selectionPrototype.node; d3.transition = function(selection) { return arguments.length ? d3_transitionInheritId ? selection.transition() : selection : d3_selectionRoot.transition(); }; d3.transition.prototype = d3_transitionPrototype; d3_transitionPrototype.select = function(selector) { var id = this.id, subgroups = [], subgroup, subnode, node; if (typeof selector !== ""function"") selector = d3_selection_selector(selector); if ((node = group[i]) && (subnode = selector.call(node, node.__data__, i))) { d3_transitionNode(subnode, i, id, node.__transition__[id]); return d3_transition(subgroups, id); var id = this.id, subgroups = [], subgroup, subnodes, node, subnode, transition; if (typeof selector !== ""function"") selector = d3_selection_selectorAll(selector); transition = node.__transition__[id]; subnodes = selector.call(node, node.__data__, i); d3_transitionNode(subnode = subnodes[k], k, id, transition); return d3_transition(subgroups, id); if ((node = group[i]) && filter.call(node, node.__data__, i)) { return d3_transition(subgroups, this.id, this.time).ease(this.ease()); var id = this.id; if (arguments.length < 2) return this.node().__transition__[id].tween.get(name); return d3_selection_each(this, tween == null ? function(node) { node.__transition__[id].tween.remove(name); } : function(node) { node.__transition__[id].tween.set(name, tween); var id = groups.id; return d3_selection_each(groups, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].tween.set(name, tween(value.call(node, node.__data__, i, j))); } : (value = tween(value), function(node) { node.__transition__[id].tween.set(name, value); var interpolate = d3_interpolateByName(nameNS), name = d3.ns.qualify(nameNS); var interpolate = d3_interpolateByName(name); var a = d3_window.getComputedStyle(this, null).getPropertyValue(name), i; return a !== b && (i = interpolate(a, b), function(t) { var f = tween.call(this, d, i, d3_window.getComputedStyle(this, null).getPropertyValue(name)); if (!this.__transition__ && (p = this.parentNode)) p.removeChild(this); var id = this.id; if (arguments.length < 1) return this.node().__transition__[id].ease; node.__transition__[id].ease = value; var id = this.id; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].delay = value.call(node, node.__data__, i, j) | 0; } : (value |= 0, function(node) { node.__transition__[id].delay = value; var id = this.id; return d3_selection_each(this, typeof value === ""function"" ? function(node, i, j) { node.__transition__[id].duration = Math.max(1, value.call(node, node.__data__, i, j) | 0); } : (value = Math.max(1, value | 0), function(node) { node.__transition__[id].duration = value; var id = this.id; d3_transitionInheritId = id; d3_selection_each(this, function(node, i, j) { d3_transitionInherit = node.__transition__[id]; type.call(node, node.__data__, i, j); }); d3_transitionInherit = inherit; d3_transitionInheritId = inheritId; node.__transition__[id].event.on(type, listener); var id0 = this.id, id1 = ++d3_transitionId, subgroups = [], subgroup, group, node, transition; transition = Object.create(node.__transition__[id0]); transition.delay += transition.duration; d3_transitionNode(node, i, id1, transition); return d3_transition(subgroups, id1); function d3_transitionNode(node, i, id, inherit) { var lock = node.__transition__ || (node.__transition__ = { }), transition = lock[id]; if (!transition) { var time = inherit.time; event: d3.dispatch(""start"", ""end""), ease: inherit.ease, duration: inherit.duration d3.timer(function(elapsed) { var d = node.__data__, ease = transition.ease, event = transition.event, delay = transition.delay, duration = transition.duration, tweened = []; return delay <= elapsed ? start(elapsed) : d3.timer(start, delay, time), 1; function start(elapsed) { if (lock.active > id) return stop(); lock.active = id; event.start.call(node, d, i); transition.tween.forEach(function(key, value) { if (value = value.call(node, d, i)) { tweened.push(value); } }); if (!tick(elapsed)) d3.timer(tick, 0, time); return 1; } function tick(elapsed) { if (lock.active !== id) return stop(); var t = (elapsed - delay) / duration, e = ease(t), n = tweened.length; while (n > 0) { tweened[--n].call(node, e); } if (t >= 1) { stop(); event.end.call(node, d, i); return 1; } } function stop() { if (--lock.count) delete lock[id]; else delete node.__transition__; return 1; } }, 0, time); return transition; var scale = d3.scale.linear(), orient = d3_svg_axisDefaultOrient, tickMajorSize = 6, tickMinorSize = 6, tickEndSize = 6, tickPadding = 3, tickArguments_ = [ 10 ], tickValues = null, tickFormat_, tickSubdivide = 0; var ticks = tickValues == null ? scale.ticks ? scale.ticks.apply(scale, tickArguments_) : scale.domain() : tickValues, tickFormat = tickFormat_ == null ? scale.tickFormat ? scale.tickFormat.apply(scale, tickArguments_) : String : tickFormat_; var subticks = d3_svg_axisSubdivide(scale, ticks, tickSubdivide), subtick = g.selectAll("".tick.minor"").data(subticks, String), subtickEnter = subtick.enter().insert(""line"", "".tick"").attr(""class"", ""tick minor"").style(""opacity"", 1e-6), subtickExit = d3.transition(subtick.exit()).style(""opacity"", 1e-6).remove(), subtickUpdate = d3.transition(subtick).style(""opacity"", 1); var tick = g.selectAll("".tick.major"").data(ticks, String), tickEnter = tick.enter().insert(""g"", ""path"").attr(""class"", ""tick major"").style(""opacity"", 1e-6), tickExit = d3.transition(tick.exit()).style(""opacity"", 1e-6).remove(), tickUpdate = d3.transition(tick).style(""opacity"", 1), tickTransform; var range = d3_scaleRange(scale), path = g.selectAll("".domain"").data([ 0 ]), pathUpdate = (path.enter().append(""path"").attr(""class"", ""domain""), var scale1 = scale.copy(), scale0 = this.__chart__ || scale1; this.__chart__ = scale1; var lineEnter = tickEnter.select(""line""), lineUpdate = tickUpdate.select(""line""), text = tick.select(""text"").text(tickFormat), textEnter = tickEnter.select(""text""), textUpdate = tickUpdate.select(""text""); switch (orient) { case ""bottom"": { tickTransform = d3_svg_axisX; subtickEnter.attr(""y2"", tickMinorSize); subtickUpdate.attr(""x2"", 0).attr(""y2"", tickMinorSize); lineEnter.attr(""y2"", tickMajorSize); textEnter.attr(""y"", Math.max(tickMajorSize, 0) + tickPadding); lineUpdate.attr(""x2"", 0).attr(""y2"", tickMajorSize); textUpdate.attr(""x"", 0).attr(""y"", Math.max(tickMajorSize, 0) + tickPadding); text.attr(""dy"", "".71em"").style(""text-anchor"", ""middle""); pathUpdate.attr(""d"", ""M"" + range[0] + "","" + tickEndSize + ""V0H"" + range[1] + ""V"" + tickEndSize); break; } case ""top"": { tickTransform = d3_svg_axisX; subtickEnter.attr(""y2"", -tickMinorSize); subtickUpdate.attr(""x2"", 0).attr(""y2"", -tickMinorSize); lineEnter.attr(""y2"", -tickMajorSize); textEnter.attr(""y"", -(Math.max(tickMajorSize, 0) + tickPadding)); lineUpdate.attr(""x2"", 0).attr(""y2"", -tickMajorSize); textUpdate.attr(""x"", 0).attr(""y"", -(Math.max(tickMajorSize, 0) + tickPadding)); text.attr(""dy"", ""0em"").style(""text-anchor"", ""middle""); pathUpdate.attr(""d"", ""M"" + range[0] + "","" + -tickEndSize + ""V0H"" + range[1] + ""V"" + -tickEndSize); break; } case ""left"": { tickTransform = d3_svg_axisY; subtickEnter.attr(""x2"", -tickMinorSize); subtickUpdate.attr(""x2"", -tickMinorSize).attr(""y2"", 0); lineEnter.attr(""x2"", -tickMajorSize); textEnter.attr(""x"", -(Math.max(tickMajorSize, 0) + tickPadding)); lineUpdate.attr(""x2"", -tickMajorSize).attr(""y2"", 0); textUpdate.attr(""x"", -(Math.max(tickMajorSize, 0) + tickPadding)).attr(""y"", 0); text.attr(""dy"", "".32em"").style(""text-anchor"", ""end""); pathUpdate.attr(""d"", ""M"" + -tickEndSize + "","" + range[0] + ""H0V"" + range[1] + ""H"" + -tickEndSize); break; } case ""right"": { tickTransform = d3_svg_axisY; subtickEnter.attr(""x2"", tickMinorSize); subtickUpdate.attr(""x2"", tickMinorSize).attr(""y2"", 0); lineEnter.attr(""x2"", tickMajorSize); textEnter.attr(""x"", Math.max(tickMajorSize, 0) + tickPadding); lineUpdate.attr(""x2"", tickMajorSize).attr(""y2"", 0); textUpdate.attr(""x"", Math.max(tickMajorSize, 0) + tickPadding).attr(""y"", 0); text.attr(""dy"", "".32em"").style(""text-anchor"", ""start""); pathUpdate.attr(""d"", ""M"" + tickEndSize + "","" + range[0] + ""H0V"" + range[1] + ""H"" + tickEndSize); break; } } if (scale.ticks) { tickEnter.call(tickTransform, scale0); tickUpdate.call(tickTransform, scale1); tickExit.call(tickTransform, scale1); subtickEnter.call(tickTransform, scale0); subtickUpdate.call(tickTransform, scale1); subtickExit.call(tickTransform, scale1); } else { var dx = scale1.rangeBand() / 2, x = function(d) { return scale1(d) + dx; }; tickEnter.call(tickTransform, x); tickUpdate.call(tickTransform, x); } tickArguments_ = arguments; axis.tickSize = function(x, y) { if (!arguments.length) return tickMajorSize; var n = arguments.length - 1; tickMajorSize = +x; tickMinorSize = n > 1 ? +y : tickMajorSize; tickEndSize = n > 0 ? +arguments[n] : tickMajorSize; axis.tickSubdivide = function(x) { if (!arguments.length) return tickSubdivide; tickSubdivide = +x; return axis; function d3_svg_axisX(selection, x) { selection.attr(""transform"", function(d) { return ""translate("" + x(d) + "",0)""; function d3_svg_axisY(selection, y) { selection.attr(""transform"", function(d) { return ""translate(0,"" + y(d) + "")""; function d3_svg_axisSubdivide(scale, ticks, m) { subticks = []; if (m && ticks.length > 1) { var extent = d3_scaleExtent(scale.domain()), subticks, i = -1, n = ticks.length, d = (ticks[1] - ticks[0]) / ++m, j, v; while (++i < n) { for (j = m; --j > 0; ) { if ((v = +ticks[i] - j * d) >= extent[0]) { subticks.push(v); } } } for (--i, j = 0; ++j < m && (v = +ticks[i] + j * d) < extent[1]; ) { subticks.push(v); } } return subticks; } d3.svg.brush = function() { var event = d3_eventDispatch(brush, ""brushstart"", ""brush"", ""brushend""), x = null, y = null, resizes = d3_svg_brushResizes[0], extent = [ [ 0, 0 ], [ 0, 0 ] ], extentDomain; var g = d3.select(this), bg = g.selectAll("".background"").data([ 0 ]), fg = g.selectAll("".extent"").data([ 0 ]), tz = g.selectAll("".resize"").data(resizes, String), e; g.style(""pointer-events"", ""all"").on(""mousedown.brush"", brushstart).on(""touchstart.brush"", brushstart); bg.enter().append(""rect"").attr(""class"", ""background"").style(""visibility"", ""hidden"").style(""cursor"", ""crosshair""); fg.enter().append(""rect"").attr(""class"", ""extent"").style(""cursor"", ""move""); tz.enter().append(""g"").attr(""class"", function(d) { tz.style(""display"", brush.empty() ? ""none"" : null); tz.exit().remove(); if (x) { e = d3_scaleRange(x); bg.attr(""x"", e[0]).attr(""width"", e[1] - e[0]); redrawX(g); e = d3_scaleRange(y); bg.attr(""y"", e[0]).attr(""height"", e[1] - e[0]); redrawY(g); } redraw(g); return ""translate("" + extent[+/e$/.test(d)][0] + "","" + extent[+/^s/.test(d)][1] + "")""; g.select("".extent"").attr(""x"", extent[0][0]); g.selectAll("".extent,.n>rect,.s>rect"").attr(""width"", extent[1][0] - extent[0][0]); g.select("".extent"").attr(""y"", extent[0][1]); g.selectAll("".extent,.e>rect,.w>rect"").attr(""height"", extent[1][1] - extent[0][1]); var target = this, eventTarget = d3.select(d3.event.target), event_ = event.of(target, arguments), g = d3.select(target), resizing = eventTarget.datum(), resizingX = !/^(n|s)$/.test(resizing) && x, resizingY = !/^(e|w)$/.test(resizing) && y, dragging = eventTarget.classed(""extent""), center, origin = mouse(), offset; var w = d3.select(d3_window).on(""mousemove.brush"", brushmove).on(""mouseup.brush"", brushend).on(""touchmove.brush"", brushmove).on(""touchend.brush"", brushend).on(""keydown.brush"", keydown).on(""keyup.brush"", keyup); if (dragging) { origin[0] = extent[0][0] - origin[0]; origin[1] = extent[0][1] - origin[1]; offset = [ extent[1 - ex][0] - origin[0], extent[1 - ey][1] - origin[1] ]; origin[0] = extent[ex][0]; origin[1] = extent[ey][1]; d3_eventCancel(); function mouse() { var touches = d3.event.changedTouches; return touches ? d3.touches(target, touches)[0] : d3.mouse(target); } origin[0] -= extent[1][0]; origin[1] -= extent[1][1]; d3_eventCancel(); origin[0] += extent[1][0]; origin[1] += extent[1][1]; d3_eventCancel(); var point = mouse(), moved = false; if (!center) center = [ (extent[0][0] + extent[1][0]) / 2, (extent[0][1] + extent[1][1]) / 2 ]; origin[0] = extent[+(point[0] < center[0])][0]; origin[1] = extent[+(point[1] < center[1])][1]; var range = d3_scaleRange(scale), r0 = range[0], r1 = range[1], position = origin[i], size = extent[1][i] - extent[0][i], min, max; min = Math.max(r0, Math.min(r1, point[i])); if (extent[0][i] !== min || extent[1][i] !== max) { extentDomain = null; extent[0][i] = min; extent[1][i] = max; d3_eventCancel(); z = extentDomain || extent; if (x) { x0 = z[0][0], x1 = z[1][0]; if (!extentDomain) { x0 = extent[0][0], x1 = extent[1][0]; y0 = z[0][1], y1 = z[1][1]; if (!extentDomain) { y0 = extent[0][1], y1 = extent[1][1]; extentDomain = [ [ 0, 0 ], [ 0, 0 ] ]; extentDomain[0][0] = x0, extentDomain[1][0] = x1; extent[0][0] = x0 | 0, extent[1][0] = x1 | 0; extentDomain[0][1] = y0, extentDomain[1][1] = y1; extent[0][1] = y0 | 0, extent[1][1] = y1 | 0; extentDomain = null; extent[0][0] = extent[0][1] = extent[1][0] = extent[1][1] = 0; return x && extent[0][0] === extent[1][0] || y && extent[0][1] === extent[1][1]; d3.time = {}; var d3_time = Date, d3_time_daySymbols = [ ""Sunday"", ""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"" ]; function d3_time_utc() { this._ = new Date(arguments.length > 1 ? Date.UTC.apply(this, arguments) : arguments[0]); } d3_time_utc.prototype = { getDate: function() { return this._.getUTCDate(); }, getDay: function() { return this._.getUTCDay(); }, getFullYear: function() { return this._.getUTCFullYear(); }, getHours: function() { return this._.getUTCHours(); }, getMilliseconds: function() { return this._.getUTCMilliseconds(); }, getMinutes: function() { return this._.getUTCMinutes(); }, getMonth: function() { return this._.getUTCMonth(); }, getSeconds: function() { return this._.getUTCSeconds(); }, getTime: function() { return this._.getTime(); }, getTimezoneOffset: function() { return 0; }, valueOf: function() { return this._.valueOf(); }, setDate: function() { d3_time_prototype.setUTCDate.apply(this._, arguments); }, setDay: function() { d3_time_prototype.setUTCDay.apply(this._, arguments); }, setFullYear: function() { d3_time_prototype.setUTCFullYear.apply(this._, arguments); }, setHours: function() { d3_time_prototype.setUTCHours.apply(this._, arguments); }, setMilliseconds: function() { d3_time_prototype.setUTCMilliseconds.apply(this._, arguments); }, setMinutes: function() { d3_time_prototype.setUTCMinutes.apply(this._, arguments); }, setMonth: function() { d3_time_prototype.setUTCMonth.apply(this._, arguments); }, setSeconds: function() { d3_time_prototype.setUTCSeconds.apply(this._, arguments); }, setTime: function() { d3_time_prototype.setTime.apply(this._, arguments); } }; var d3_time_prototype = Date.prototype; var d3_time_formatDateTime = ""%a %b %e %X %Y"", d3_time_formatDate = ""%m/%d/%Y"", d3_time_formatTime = ""%H:%M:%S""; var d3_time_days = [ ""Sunday"", ""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday"" ], d3_time_dayAbbreviations = [ ""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"" ], d3_time_months = [ ""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December"" ], d3_time_monthAbbreviations = [ ""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"" ]; function d3_time_interval(local, step, number) { function round(date) { var d0 = local(date), d1 = offset(d0, 1); return date - d0 < d1 - date ? d0 : d1; } function ceil(date) { step(date = local(new d3_time(date - 1)), 1); return date; } function offset(date, k) { step(date = new d3_time(+date), k); return date; } function range(t0, t1, dt) { var time = ceil(t0), times = []; if (dt > 1) { while (time < t1) { if (!(number(time) % dt)) times.push(new Date(+time)); step(time, 1); } } else { while (time < t1) times.push(new Date(+time)), step(time, 1); } return times; } function range_utc(t0, t1, dt) { try { d3_time = d3_time_utc; var utc = new d3_time_utc(); utc._ = t0; return range(utc, t1, dt); } finally { d3_time = Date; } } local.floor = local; local.round = round; local.ceil = ceil; local.offset = offset; local.range = range; var utc = local.utc = d3_time_interval_utc(local); utc.floor = utc; utc.round = d3_time_interval_utc(round); utc.ceil = d3_time_interval_utc(ceil); utc.offset = d3_time_interval_utc(offset); utc.range = range_utc; return local; } function d3_time_interval_utc(method) { return function(date, k) { try { d3_time = d3_time_utc; var utc = new d3_time_utc(); utc._ = date; return method(utc, k)._; } finally { d3_time = Date; } }; } d3.time.year = d3_time_interval(function(date) { date = d3.time.day(date); date.setMonth(0, 1); return date; }, function(date, offset) { date.setFullYear(date.getFullYear() + offset); }, function(date) { return date.getFullYear(); }); d3.time.years = d3.time.year.range; d3.time.years.utc = d3.time.year.utc.range; d3.time.day = d3_time_interval(function(date) { var day = new d3_time(1970, 0); day.setFullYear(date.getFullYear(), date.getMonth(), date.getDate()); return day; }, function(date, offset) { date.setDate(date.getDate() + offset); }, function(date) { return date.getDate() - 1; }); d3.time.days = d3.time.day.range; d3.time.days.utc = d3.time.day.utc.range; d3.time.dayOfYear = function(date) { var year = d3.time.year(date); return Math.floor((date - year - (date.getTimezoneOffset() - year.getTimezoneOffset()) * 6e4) / 864e5); }; d3_time_daySymbols.forEach(function(day, i) { day = day.toLowerCase(); i = 7 - i; var interval = d3.time[day] = d3_time_interval(function(date) { (date = d3.time.day(date)).setDate(date.getDate() - (date.getDay() + i) % 7); return date; }, function(date, offset) { date.setDate(date.getDate() + Math.floor(offset) * 7); }, function(date) { var day = d3.time.year(date).getDay(); return Math.floor((d3.time.dayOfYear(date) + (day + i) % 7) / 7) - (day !== i); }); d3.time[day + ""s""] = interval.range; d3.time[day + ""s""].utc = interval.utc.range; d3.time[day + ""OfYear""] = function(date) { var day = d3.time.year(date).getDay(); return Math.floor((d3.time.dayOfYear(date) + (day + i) % 7) / 7); }; }); d3.time.week = d3.time.sunday; d3.time.weeks = d3.time.sunday.range; d3.time.weeks.utc = d3.time.sunday.utc.range; d3.time.weekOfYear = d3.time.sundayOfYear; d3.time.format = function(template) { var n = template.length; function format(date) { var string = [], i = -1, j = 0, c, p, f; while (++i < n) { if (template.charCodeAt(i) === 37) { string.push(template.substring(j, i)); if ((p = d3_time_formatPads[c = template.charAt(++i)]) != null) c = template.charAt(++i); if (f = d3_time_formats[c]) c = f(date, p == null ? c === ""e"" ? "" "" : ""0"" : p); string.push(c); j = i + 1; } } string.push(template.substring(j, i)); return string.join(""""); } format.parse = function(string) { var d = { y: 1900, m: 0, d: 1, H: 0, M: 0, S: 0, L: 0 }, i = d3_time_parse(d, template, string, 0); if (i != string.length) return null; if (""p"" in d) d.H = d.H % 12 + d.p * 12; var date = new d3_time(); date.setFullYear(d.y, d.m, d.d); date.setHours(d.H, d.M, d.S, d.L); return date; }; format.toString = function() { return template; }; return format; }; function d3_time_parse(date, template, string, j) { var c, p, i = 0, n = template.length, m = string.length; while (i < n) { if (j >= m) return -1; c = template.charCodeAt(i++); if (c === 37) { p = d3_time_parsers[template.charAt(i++)]; if (!p || (j = p(date, string, j)) < 0) return -1; } else if (c != string.charCodeAt(j++)) { return -1; } } return j; } function d3_time_formatRe(names) { return new RegExp(""^(?:"" + names.map(d3.requote).join(""|"") + "")"", ""i""); } function d3_time_formatLookup(names) { var map = new d3_Map(), i = -1, n = names.length; while (++i < n) map.set(names[i].toLowerCase(), i); return map; } function d3_time_formatPad(value, fill, width) { value += """"; var length = value.length; return length < width ? new Array(width - length + 1).join(fill) + value : value; } var d3_time_dayRe = d3_time_formatRe(d3_time_days), d3_time_dayAbbrevRe = d3_time_formatRe(d3_time_dayAbbreviations), d3_time_monthRe = d3_time_formatRe(d3_time_months), d3_time_monthLookup = d3_time_formatLookup(d3_time_months), d3_time_monthAbbrevRe = d3_time_formatRe(d3_time_monthAbbreviations), d3_time_monthAbbrevLookup = d3_time_formatLookup(d3_time_monthAbbreviations); var d3_time_formatPads = { ""-"": """", _: "" "", ""0"": ""0"" }; var d3_time_formats = { a: function(d) { return d3_time_dayAbbreviations[d.getDay()]; }, A: function(d) { return d3_time_days[d.getDay()]; }, b: function(d) { return d3_time_monthAbbreviations[d.getMonth()]; }, B: function(d) { return d3_time_months[d.getMonth()]; }, c: d3.time.format(d3_time_formatDateTime), d: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, e: function(d, p) { return d3_time_formatPad(d.getDate(), p, 2); }, H: function(d, p) { return d3_time_formatPad(d.getHours(), p, 2); }, I: function(d, p) { return d3_time_formatPad(d.getHours() % 12 || 12, p, 2); }, j: function(d, p) { return d3_time_formatPad(1 + d3.time.dayOfYear(d), p, 3); }, L: function(d, p) { return d3_time_formatPad(d.getMilliseconds(), p, 3); }, m: function(d, p) { return d3_time_formatPad(d.getMonth() + 1, p, 2); }, M: function(d, p) { return d3_time_formatPad(d.getMinutes(), p, 2); }, p: function(d) { return d.getHours() >= 12 ? ""PM"" : ""AM""; }, S: function(d, p) { return d3_time_formatPad(d.getSeconds(), p, 2); }, U: function(d, p) { return d3_time_formatPad(d3.time.sundayOfYear(d), p, 2); }, w: function(d) { return d.getDay(); }, W: function(d, p) { return d3_time_formatPad(d3.time.mondayOfYear(d), p, 2); }, x: d3.time.format(d3_time_formatDate), X: d3.time.format(d3_time_formatTime), y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 100, p, 2); }, Y: function(d, p) { return d3_time_formatPad(d.getFullYear() % 1e4, p, 4); }, Z: d3_time_zone, ""%"": function() { return ""%""; } }; var d3_time_parsers = { a: d3_time_parseWeekdayAbbrev, A: d3_time_parseWeekday, b: d3_time_parseMonthAbbrev, B: d3_time_parseMonth, c: d3_time_parseLocaleFull, d: d3_time_parseDay, e: d3_time_parseDay, H: d3_time_parseHour24, I: d3_time_parseHour24, L: d3_time_parseMilliseconds, m: d3_time_parseMonthNumber, M: d3_time_parseMinutes, p: d3_time_parseAmPm, S: d3_time_parseSeconds, x: d3_time_parseLocaleDate, X: d3_time_parseLocaleTime, y: d3_time_parseYear, Y: d3_time_parseFullYear }; function d3_time_parseWeekdayAbbrev(date, string, i) { d3_time_dayAbbrevRe.lastIndex = 0; var n = d3_time_dayAbbrevRe.exec(string.substring(i)); return n ? i += n[0].length : -1; } function d3_time_parseWeekday(date, string, i) { d3_time_dayRe.lastIndex = 0; var n = d3_time_dayRe.exec(string.substring(i)); return n ? i += n[0].length : -1; } function d3_time_parseMonthAbbrev(date, string, i) { d3_time_monthAbbrevRe.lastIndex = 0; var n = d3_time_monthAbbrevRe.exec(string.substring(i)); return n ? (date.m = d3_time_monthAbbrevLookup.get(n[0].toLowerCase()), i += n[0].length) : -1; } function d3_time_parseMonth(date, string, i) { d3_time_monthRe.lastIndex = 0; var n = d3_time_monthRe.exec(string.substring(i)); return n ? (date.m = d3_time_monthLookup.get(n[0].toLowerCase()), i += n[0].length) : -1; } function d3_time_parseLocaleFull(date, string, i) { return d3_time_parse(date, d3_time_formats.c.toString(), string, i); } function d3_time_parseLocaleDate(date, string, i) { return d3_time_parse(date, d3_time_formats.x.toString(), string, i); } function d3_time_parseLocaleTime(date, string, i) { return d3_time_parse(date, d3_time_formats.X.toString(), string, i); } function d3_time_parseFullYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 4)); return n ? (date.y = +n[0], i += n[0].length) : -1; } function d3_time_parseYear(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.y = d3_time_expandYear(+n[0]), i += n[0].length) : -1; } function d3_time_expandYear(d) { return d + (d > 68 ? 1900 : 2e3); } function d3_time_parseMonthNumber(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.m = n[0] - 1, i += n[0].length) : -1; } function d3_time_parseDay(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.d = +n[0], i += n[0].length) : -1; } function d3_time_parseHour24(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.H = +n[0], i += n[0].length) : -1; } function d3_time_parseMinutes(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.M = +n[0], i += n[0].length) : -1; } function d3_time_parseSeconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 2)); return n ? (date.S = +n[0], i += n[0].length) : -1; } function d3_time_parseMilliseconds(date, string, i) { d3_time_numberRe.lastIndex = 0; var n = d3_time_numberRe.exec(string.substring(i, i + 3)); return n ? (date.L = +n[0], i += n[0].length) : -1; } var d3_time_numberRe = /^\s*\d+/; function d3_time_parseAmPm(date, string, i) { var n = d3_time_amPmLookup.get(string.substring(i, i += 2).toLowerCase()); return n == null ? -1 : (date.p = n, i); } var d3_time_amPmLookup = d3.map({ am: 0, pm: 1 }); function d3_time_zone(d) { var z = d.getTimezoneOffset(), zs = z > 0 ? ""-"" : ""+"", zh = ~~(Math.abs(z) / 60), zm = Math.abs(z) % 60; return zs + d3_time_formatPad(zh, ""0"", 2) + d3_time_formatPad(zm, ""0"", 2); } d3.time.format.utc = function(template) { var local = d3.time.format(template); function format(date) { try { d3_time = d3_time_utc; var utc = new d3_time(); utc._ = date; return local(utc); } finally { d3_time = Date; } } format.parse = function(string) { try { d3_time = d3_time_utc; var date = local.parse(string); return date && date._; } finally { d3_time = Date; } }; format.toString = local.toString; return format; }; var d3_time_formatIso = d3.time.format.utc(""%Y-%m-%dT%H:%M:%S.%LZ""); d3.time.format.iso = Date.prototype.toISOString && +new Date(""2000-01-01T00:00:00.000Z"") ? d3_time_formatIsoNative : d3_time_formatIso; d3.time.second = d3_time_interval(function(date) { return new d3_time(Math.floor(date / 1e3) * 1e3); d3.time.seconds = d3.time.second.range; d3.time.seconds.utc = d3.time.second.utc.range; d3.time.minute = d3_time_interval(function(date) { return new d3_time(Math.floor(date / 6e4) * 6e4); d3.time.minutes = d3.time.minute.range; d3.time.minutes.utc = d3.time.minute.utc.range; d3.time.hour = d3_time_interval(function(date) { return new d3_time((Math.floor(date / 36e5 - timezone) + timezone) * 36e5); d3.time.hours = d3.time.hour.range; d3.time.hours.utc = d3.time.hour.utc.range; d3.time.month = d3_time_interval(function(date) { date = d3.time.day(date); d3.time.months = d3.time.month.range; d3.time.months.utc = d3.time.month.utc.range; scale.nice = function(m) { return scale.domain(d3_scale_nice(scale.domain(), function() { return m; })); }; scale.ticks = function(m, k) { var extent = d3_scaleExtent(scale.domain()); if (typeof m !== ""function"") { var span = extent[1] - extent[0], target = span / m, i = d3.bisect(d3_time_scaleSteps, target); if (i == d3_time_scaleSteps.length) return methods.year(extent, m); if (!i) return linear.ticks(m).map(d3_time_scaleDate); if (Math.log(target / d3_time_scaleSteps[i - 1]) < Math.log(d3_time_scaleSteps[i] / target)) --i; m = methods[i]; k = m[1]; m = m[0].range; } return m(extent[0], new Date(+extent[1] + 1), k); function d3_time_scaleFormat(formats) { return function(date) { var i = formats.length - 1, f = formats[i]; while (!f[1](date)) f = formats[--i]; return f[0](date); }; } function d3_time_scaleSetYear(y) { var d = new Date(y, 0, 1); d.setFullYear(y); return d; } function d3_time_scaleGetYear(d) { var y = d.getFullYear(), d0 = d3_time_scaleSetYear(y), d1 = d3_time_scaleSetYear(y + 1); return y + (d - d0) / (d1 - d0); } var d3_time_scaleLocalMethods = [ [ d3.time.second, 1 ], [ d3.time.second, 5 ], [ d3.time.second, 15 ], [ d3.time.second, 30 ], [ d3.time.minute, 1 ], [ d3.time.minute, 5 ], [ d3.time.minute, 15 ], [ d3.time.minute, 30 ], [ d3.time.hour, 1 ], [ d3.time.hour, 3 ], [ d3.time.hour, 6 ], [ d3.time.hour, 12 ], [ d3.time.day, 1 ], [ d3.time.day, 2 ], [ d3.time.week, 1 ], [ d3.time.month, 1 ], [ d3.time.month, 3 ], [ d3.time.year, 1 ] ]; var d3_time_scaleLocalFormats = [ [ d3.time.format(""%Y""), d3_true ], [ d3.time.format(""%B""), function(d) { return d.getMonth(); } ], [ d3.time.format(""%b %d""), function(d) { return d.getDate() != 1; } ], [ d3.time.format(""%a %d""), function(d) { return d.getDay() && d.getDate() != 1; } ], [ d3.time.format(""%I %p""), function(d) { return d.getHours(); } ], [ d3.time.format(""%I:%M""), function(d) { return d.getMinutes(); } ], [ d3.time.format("":%S""), function(d) { return d.getSeconds(); } ], [ d3.time.format("".%L""), function(d) { } ] ]; var d3_time_scaleLinear = d3.scale.linear(), d3_time_scaleLocalFormat = d3_time_scaleFormat(d3_time_scaleLocalFormats); d3_time_scaleLocalMethods.year = function(extent, m) { return d3_time_scaleLinear.domain(extent.map(d3_time_scaleGetYear)).ticks(m).map(d3_time_scaleSetYear); d3.time.scale = function() { var d3_time_scaleUTCMethods = d3_time_scaleLocalMethods.map(function(m) { var d3_time_scaleUTCFormats = [ [ d3.time.format.utc(""%Y""), d3_true ], [ d3.time.format.utc(""%B""), function(d) { return d.getUTCMonth(); } ], [ d3.time.format.utc(""%b %d""), function(d) { return d.getUTCDate() != 1; } ], [ d3.time.format.utc(""%a %d""), function(d) { return d.getUTCDay() && d.getUTCDate() != 1; } ], [ d3.time.format.utc(""%I %p""), function(d) { return d.getUTCHours(); } ], [ d3.time.format.utc(""%I:%M""), function(d) { return d.getUTCMinutes(); } ], [ d3.time.format.utc("":%S""), function(d) { return d.getUTCSeconds(); } ], [ d3.time.format.utc("".%L""), function(d) { } ] ]; var d3_time_scaleUTCFormat = d3_time_scaleFormat(d3_time_scaleUTCFormats); function d3_time_scaleUTCSetYear(y) { var d = new Date(Date.UTC(y, 0, 1)); d.setUTCFullYear(y); return d; } function d3_time_scaleUTCGetYear(d) { var y = d.getUTCFullYear(), d0 = d3_time_scaleUTCSetYear(y), d1 = d3_time_scaleUTCSetYear(y + 1); return y + (d - d0) / (d1 - d0); } d3_time_scaleUTCMethods.year = function(extent, m) { return d3_time_scaleLinear.domain(extent.map(d3_time_scaleUTCGetYear)).ticks(m).map(d3_time_scaleUTCSetYear); d3.time.scale.utc = function() { return d3_time_scale(d3.scale.linear(), d3_time_scaleUTCMethods, d3_time_scaleUTCFormat); }; d3.text = function() { return d3.xhr.apply(d3, arguments).response(d3_text); }; function d3_text(request) { } d3.json = function(url, callback) { return d3.xhr(url, ""application/json"", callback).response(d3_json); return d3.xhr(url, ""text/html"", callback).response(d3_html); d3.xml = function() { return d3.xhr.apply(d3, arguments).response(d3_xml); }; function d3_xml(request) { } return d3;",4855,3733
openstack%2Fxstatic-jsencrypt~master~I2000c1aa6d85e2dace544e79727dd4e504fa30cd,openstack/xstatic-jsencrypt,master,I2000c1aa6d85e2dace544e79727dd4e504fa30cd,Update JSEncrypt to v2.3.0,MERGED,2016-04-21 15:16:53.000000000,2016-05-05 03:55:09.000000000,2016-05-05 03:55:09.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7179}, {'_account_id': 7665}, {'_account_id': 11778}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-04-21 15:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-jsencrypt/commit/a50e24ef7a07b23842d40d021a770a948b92b5d0', 'message': 'Update JSEncrypt to v2.3.0\n\nChange-Id: I2000c1aa6d85e2dace544e79727dd4e504fa30cd\n'}, {'number': 2, 'created': '2016-04-21 15:19:17.000000000', 'files': ['xstatic/pkg/jsencrypt/data/jsencrypt.js', 'xstatic/pkg/jsencrypt/__init__.py'], 'web_link': 'https://opendev.org/openstack/xstatic-jsencrypt/commit/5a62fc037e1a0a2264d4470789229fa01dbe4483', 'message': 'Update JSEncrypt to v2.3.0\n\nChange-Id: I2000c1aa6d85e2dace544e79727dd4e504fa30cd\n'}]",1,309062,5a62fc037e1a0a2264d4470789229fa01dbe4483,13,6,2,12826,,,0,"Update JSEncrypt to v2.3.0

Change-Id: I2000c1aa6d85e2dace544e79727dd4e504fa30cd
",git fetch https://review.opendev.org/openstack/xstatic-jsencrypt refs/changes/62/309062/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/jsencrypt/jsencrypt.js', 'xstatic/pkg/jsencrypt/__init__.py']",2,a50e24ef7a07b23842d40d021a770a948b92b5d0,update-to-v2.3.0,"VERSION = '2.3.0' # version of the packaged files, please use the upstreamBUILD = '0' # our package build number, so we can release new builds","VERSION = '2.0.0' # version of the packaged files, please use the upstreamBUILD = '2' # our package build number, so we can release new builds",502,2
openstack%2Fxstatic-angular~master~Ie61a6282f792a8721674014dc11f2e2a2ec1245b,openstack/xstatic-angular,master,Ie61a6282f792a8721674014dc11f2e2a2ec1245b,Update XStatic-Angular to 1.4.10,MERGED,2016-04-20 10:27:38.000000000,2016-05-05 03:54:08.000000000,2016-05-05 03:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 11778}]","[{'number': 1, 'created': '2016-04-20 10:27:38.000000000', 'files': ['xstatic/pkg/angular/data/version.json', 'xstatic/pkg/angular/__init__.py', 'xstatic/pkg/angular/data/angular-csp.css', 'xstatic/pkg/angular/data/angular-loader.js', 'xstatic/pkg/angular/data/version.txt', 'xstatic/pkg/angular/data/angular-messages.js', 'xstatic/pkg/angular/data/angular-route.js', 'xstatic/pkg/angular/data/angular-aria.js', 'xstatic/pkg/angular/data/angular.js', 'xstatic/pkg/angular/data/errors.json', 'xstatic/pkg/angular/data/angular-mocks.js', 'xstatic/pkg/angular/data/angular-sanitize.js', 'xstatic/pkg/angular/data/angular-animate.js', 'xstatic/pkg/angular/data/angular-cookies.js', 'xstatic/pkg/angular/data/angular-message-format.js', 'xstatic/pkg/angular/data/angular-touch.js'], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/65cde9c21257795353c9d111c232596de1bcb995', 'message': 'Update XStatic-Angular to 1.4.10\n\nChange-Id: Ie61a6282f792a8721674014dc11f2e2a2ec1245b\n'}]",0,308251,65cde9c21257795353c9d111c232596de1bcb995,11,3,1,12826,,,0,"Update XStatic-Angular to 1.4.10

Change-Id: Ie61a6282f792a8721674014dc11f2e2a2ec1245b
",git fetch https://review.opendev.org/openstack/xstatic-angular refs/changes/51/308251/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/angular/data/version.json', 'xstatic/pkg/angular/__init__.py', 'xstatic/pkg/angular/data/angular-csp.css', 'xstatic/pkg/angular/data/angular-loader.js', 'xstatic/pkg/angular/data/version.txt', 'xstatic/pkg/angular/data/angular-messages.js', 'xstatic/pkg/angular/data/angular-route.js', 'xstatic/pkg/angular/data/angular-aria.js', 'xstatic/pkg/angular/data/angular.js', 'xstatic/pkg/angular/data/errors.json', 'xstatic/pkg/angular/data/angular-mocks.js', 'xstatic/pkg/angular/data/angular-sanitize.js', 'xstatic/pkg/angular/data/angular-animate.js', 'xstatic/pkg/angular/data/angular-cookies.js', 'xstatic/pkg/angular/data/angular-message-format.js', 'xstatic/pkg/angular/data/angular-touch.js']",16,65cde9c21257795353c9d111c232596de1bcb995,update-to-v1.4.10," * @license AngularJS v1.4.10 * (c) 2010-2015 Google, Inc. http://angularjs.org * `$swipe` is used by the `ngSwipeLeft` and `ngSwipeRight` directives in `ngTouch`. * receive as a parameter a coordinates object of the form `{ x: 150, y: 310 }` and the raw * `event`. `cancel` receives the raw `event` as its single parameter. // So we detect touchstart, touchcancel and touchend ourselves and determine when // (- touchcancel ends the touch, no click follows)"," * @license AngularJS v1.3.18 * (c) 2010-2014 Google, Inc. http://angularjs.org * `$swipe` is used by the `ngSwipeLeft` and `ngSwipeRight` directives in `ngTouch`, and by * `ngCarousel` in a separate component. * receive as a parameter a coordinates object of the form `{ x: 150, y: 310 }`. // So we detect touchstart, touchmove, touchcancel and touchend ourselves and determine when // (- touchmove or touchcancel ends the touch, no click follows) element.on('touchmove', function(event) { resetState(); }); ",12818,5987
openstack%2Fswift-specs~master~I21766423a07a5b6195656b06db4e590598bf3d41,openstack/swift-specs,master,I21766423a07a5b6195656b06db4e590598bf3d41,Large containers (Sharding) - Pivot Ranges.,MERGED,2015-08-31 06:12:24.000000000,2016-05-05 03:49:34.000000000,2016-05-05 03:49:34.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 11317}, {'_account_id': 13104}, {'_account_id': 13390}, {'_account_id': 13997}, {'_account_id': 16206}]","[{'number': 1, 'created': '2015-08-31 06:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/07fecc4d3de447e152fb74b9f0cb3022ecb362e5', 'message': ""Large containers (Sharding) - Pivot/Split Tree\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin, plus some initial work I have\nalready put together to see how it would work.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all nodes in a pivot tree, so can\nshort circuit requests as it knows all data will be in the tree's\nleaves.\n\nThere is a idea to do an intermediate step which is to use the pivot\npoints to split the container's DB, and leave additional SQLite dbs\nwith the broker. This would have the advantage of only having to\nmodify the container backend to deal with more then 1 database. I\nhaven't worked through this option yet.\n\nMore work and thought needs to go into parts of this POC, but this\nis how it currently stands. If I missed anything from Austin please\nlet me know.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 2, 'created': '2015-09-01 01:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/5fea277cdd31016d26e2435165d45efffc2ff0d8', 'message': ""Large containers (Sharding) - Pivot/Split Tree\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin, plus some initial work I have\nalready put together to see how it would work.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all nodes in a pivot tree, so can\nshort circuit requests as it knows all data will be in the tree's\nleaves.\n\nThere is a idea to do an intermediate step which is to use the pivot\npoints to split the container's DB, and leave additional SQLite dbs\nwith the broker. This would have the advantage of only having to\nmodify the container backend to deal with more then 1 database. I\nhaven't worked through this option yet.\n\nMore work and thought needs to go into parts of this POC, but this\nis how it currently stands. If I missed anything from Austin please\nlet me know.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 3, 'created': '2015-09-01 01:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/dc35f427c5ab172dcfd5a6f62026b4d0886aa2fd', 'message': ""Large containers (Sharding) - Pivot/Split Tree\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin, plus some initial work I have\nalready put together to see how it would work.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all nodes in a pivot tree, so can\nshort circuit requests as it knows all data will be in the tree's\nleaves.\n\nThere is a idea to do an intermediate step which is to use the pivot\npoints to split the container's DB, and leave additional SQLite dbs\nwith the broker. This would have the advantage of only having to\nmodify the container backend to deal with more then 1 database. I\nhaven't worked through this option yet.\n\nMore work and thought needs to go into parts of this POC, but this\nis how it currently stands. If I missed anything from Austin please\nlet me know.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 4, 'created': '2015-10-08 00:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/cd15a3729068a2e77c52adbf65635a3bed03cf1f', 'message': ""Large containers (Sharding) - Pivot/Split Tree\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin, plus some initial work I have\nalready put together to see how it would work.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all nodes in a pivot tree, so can\nshort circuit requests as it knows all data will be in the tree's\nleaves.\n\nThere is a idea to do an intermediate step which is to use the pivot\npoints to split the container's DB, and leave additional SQLite dbs\nwith the broker. This would have the advantage of only having to\nmodify the container backend to deal with more then 1 database. I\nhaven't worked through this option yet.\n\nMore work and thought needs to go into parts of this POC, but this\nis how it currently stands. If I missed anything from Austin please\nlet me know.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 5, 'created': '2015-10-26 22:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/3c57dac84596b62cbe6531a40c8b403fa96a5d58', 'message': ""Large containers (Sharding) - Pivot/Split Tree\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin, plus some initial work I have\nalready put together to see how it would work.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all nodes in a pivot tree, so can\nshort circuit requests as it knows all data will be in the tree's\nleaves.\n\nThere is a idea to do an intermediate step which is to use the pivot\npoints to split the container's DB, and leave additional SQLite dbs\nwith the broker. This would have the advantage of only having to\nmodify the container backend to deal with more then 1 database. I\nhaven't worked through this option yet.\n\nMore work and thought needs to go into parts of this POC, but this\nis how it currently stands. If I missed anything from Austin please\nlet me know.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 6, 'created': '2016-04-23 05:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/3a7881dc71b9a47119a8fb34be9a0d2657b34748', 'message': ""Large containers (Sharding) - Pivot Ranges.\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin and the Tokyo design summit,\nplus some initial work I have already put together to see how it would\nwork.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all the new containers and their range,\nso it can short circuit requests as it knows all data will be in the tree's\nleaves.\n\nThis current version isn't totally complete, I need to write a bunch\nmore on the shrinking algorithm and delete problem. But wanted to get\nsomething up before I got on the plane to come to Austin. I'll polish it\nup and hopefully finish it off while flying.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 7, 'created': '2016-04-24 16:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/d1d3750a3ea70d5d46f33c1302c6550f657a43d7', 'message': ""Large containers (Sharding) - Pivot Ranges.\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin and the Tokyo design summit,\nplus some initial work I have already put together to see how it would\nwork.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all the new containers and their range,\nso it can short circuit requests as it knows all data will be in the tree's\nleaves.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}, {'number': 8, 'created': '2016-04-26 14:20:12.000000000', 'files': ['specs/in_progress/images/PivotPoints.png', 'specs/in_progress/images/PivotRanges.png', 'specs/in_progress/container_sharding.rst', 'specs/in_progress/images/seq_obj_put_delete.png'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/74f085594bf282ab224ae621077d131ea7bb5224', 'message': ""Large containers (Sharding) - Pivot Ranges.\n\nHere is an initial version of the next sharding POC, it is based off\ndiscussions at the hackathon in Austin and the Tokyo design summit,\nplus some initial work I have already put together to see how it would\nwork.\n\nThis approach is similar, but simpler then in the last distributed\nprefix tree POC. It will simply split the table at a pivot point,\ncreating two new containers that hold all the objects. The root\ncontainer holds a reference to all the new containers and their range,\nso it can short circuit requests as it knows all data will be in the tree's\nleaves.\n\nChange-Id: I21766423a07a5b6195656b06db4e590598bf3d41\n""}]",61,218738,74f085594bf282ab224ae621077d131ea7bb5224,28,8,8,7233,,,0,"Large containers (Sharding) - Pivot Ranges.

Here is an initial version of the next sharding POC, it is based off
discussions at the hackathon in Austin and the Tokyo design summit,
plus some initial work I have already put together to see how it would
work.

This approach is similar, but simpler then in the last distributed
prefix tree POC. It will simply split the table at a pivot point,
creating two new containers that hold all the objects. The root
container holds a reference to all the new containers and their range,
so it can short circuit requests as it knows all data will be in the tree's
leaves.

Change-Id: I21766423a07a5b6195656b06db4e590598bf3d41
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/38/218738/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/in_progress/images/PivotPoints.png', 'specs/in_progress/container_sharding.rst', 'specs/in_progress/images/seq_obj_put_delete.png']",3,07fecc4d3de447e152fb74b9f0cb3022ecb362e5,container-sharding,,,169,436
openstack%2Fswift-specs~master~I95afabc3587fb4701e08ebec9f646727ae18a46d,openstack/swift-specs,master,I95afabc3587fb4701e08ebec9f646727ae18a46d,PACO single-process spec.,MERGED,2015-08-06 20:50:13.000000000,2016-05-05 03:47:35.000000000,2016-05-05 03:47:35.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 4608}, {'_account_id': 6968}]","[{'number': 1, 'created': '2015-08-06 20:50:13.000000000', 'files': ['specs/in_progress/single_process.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/f8548ced79424b8efb9243bbfceee5d893a4ed5d', 'message': 'PACO single-process spec.\n\nThis spec describes the idea behing patch:\nhttps://review.openstack.org/#/c/159285/\n\nChange-Id: I95afabc3587fb4701e08ebec9f646727ae18a46d\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",6,210117,f8548ced79424b8efb9243bbfceee5d893a4ed5d,9,4,1,9625,,,0,"PACO single-process spec.

This spec describes the idea behing patch:
https://review.openstack.org/#/c/159285/

Change-Id: I95afabc3587fb4701e08ebec9f646727ae18a46d
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/17/210117/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/single_process.rst'],1,f8548ced79424b8efb9243bbfceee5d893a4ed5d,single_process_spec,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== PACO Single Process deployments =============================== Since the release of the DiskFile API, there's been a number of different implementations providing the ability of storing Swift objects in the third-party storage systems. Commonly these systems provide the durability and availability of the objects (e.g., GlusterFS, GPFS), thus requiring the object ring to be created with only one replica. A typical deployment style for this configuration is a ""PACO"" deployment, where the proxy, account, container and object services are running on the same node. The object ring is built in a such a way that the proxy server always send requests to the local object server. The object server (with it's third-party DiskFile) is then responsible for writing the data to the underlying storage system which will then distribute the data according to its own policies. Problem description =================== In a typical swift deployment, proxy nodes send data to object servers running on different nodes and the object servers write the data directly to disk. In the case of third-party storage systems, the object server typically makes another network connection to send the object to that storage system, adding some latency to the data path. Even when the proxy and object servers are on the same node, latency is still introduced due to RPC communication over local network. Proposed change =============== For the scenario of single replica - PACO deployments, the proxy server would be sending data directly to the third-party storage systems. To accomplish this we would like to call the object wsgi application directly from the proxy process instead of making the additional network connection. This proposed solution focuses on reducing the proxy to object server latency Proxy to account and/or container communications would stay the same for now and be addressed on later patch. Assignee(s) ----------- Primary assignee: thiago@redhat.com Work Items ---------- A WiP patch has been submitted: https://review.openstack.org/#/c/159285/. The work that has been done recently to the Object Controllers in the proxy servers provides the ability for a very nice separation of the code. TODOs and where further investigation is needed: * How to load the object WSGI application instance in the proxy process? * How to add support for multiple storage policies? Prototype --------- To test patch `159285 <https://review.openstack.org/#/c/159285/>`_ follow these steps: #. Create new single replica storage system. Update swift.conf and create new ring. The port provided during ring creation will not be used for anything. #. Create an object-server config file: ``/etc/swift/single-process.conf``. This configuration file can look like any other object-server configuration file, just make sure it specifies the correct device the object server should be writing to. For example, in the case of `Swift-on-File <https://github.com/stackforge/swiftonfile>`_ object server, the device is the mountpoint of the shared filesystem (i.e., Gluster, GPFS). #. Start the proxy. ",,81,0
openstack%2Fswift-specs~master~I4237f141022382131977ff16760f5645d0391ea5,openstack/swift-specs,master,I4237f141022382131977ff16760f5645d0391ea5,formpost should allow subprefix-based signature,MERGED,2015-09-18 08:34:11.000000000,2016-05-05 03:47:33.000000000,2016-05-05 03:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 17245}]","[{'number': 1, 'created': '2015-09-18 08:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/4b34c3b39dcfc55881d065adf8617a102112cfd6', 'message': 'formpost should allow subprefix-based signature\n\nformpost currently requires that the signature used to validate a file\nupload contains the same object_prefix as the object_prefix specified\nin the action url of the form.\nWe propose that the middleware should also accept signatures calculated\nwith a subprefix of the object_prefix in the action url. Thus, formpost\nwould accept all uploads to pseudofolders which contain a common\nsubprefix.\nWith this, sharing of data with external people is made much easier via\nwebbased applications, because only one signature is needed in order to\ncreate forms for every pseudofolder in a container.\n\nChange-Id: I4237f141022382131977ff16760f5645d0391ea5\n'}, {'number': 2, 'created': '2015-09-18 11:38:29.000000000', 'files': ['specs/in_progress/formpost_subprefix_signature.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/2525ca1c07d95ea817f8d6938377f393efd0f1c3', 'message': 'formpost should allow subprefix-based signature\n\nformpost currently requires that the signature used to validate a file\nupload contains the same object_prefix as the object_prefix specified\nin the action url of the form.\nWe propose that the middleware should also accept signatures calculated\nwith a subprefix of the object_prefix in the action url. Thus, formpost\nwould accept all uploads to pseudofolders which contain a common\nsubprefix.\nWith this, sharing of data with external people is made much easier via\nwebbased applications, because only one signature is needed in order to\ncreate forms for every pseudofolder in a container.\n\nChange-Id: I4237f141022382131977ff16760f5645d0391ea5\n'}]",2,225059,2525ca1c07d95ea817f8d6938377f393efd0f1c3,15,5,2,17245,,,0,"formpost should allow subprefix-based signature

formpost currently requires that the signature used to validate a file
upload contains the same object_prefix as the object_prefix specified
in the action url of the form.
We propose that the middleware should also accept signatures calculated
with a subprefix of the object_prefix in the action url. Thus, formpost
would accept all uploads to pseudofolders which contain a common
subprefix.
With this, sharing of data with external people is made much easier via
webbased applications, because only one signature is needed in order to
create forms for every pseudofolder in a container.

Change-Id: I4237f141022382131977ff16760f5645d0391ea5
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/59/225059/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/formpost_subprefix_signature.rst'],1,4b34c3b39dcfc55881d065adf8617a102112cfd6,,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ================================================ formpost should allow subprefix-based signatures ================================================ The signature used by formpost to validate a file upload should also be considered valid, if the object_prefix, which is used to calculate the signature, is a real subprefix of the object_prefix used in the action url of the form. With this, sharing of data with external people is made much easier via webbased applications, because just one signature is needed to create forms for every pseudofolder in a container. Problem Description =================== At the moment, if one wants to use a form to upload data, the signature of the form must be calculated using the same object_prefix as the object_prefix in the url of the action attribute of the form. We propose to allow dynamically created forms, which are valid for all object_prefixes which contain a common prefix. With this, one could generate one signature, which is valid for all pseudofolders in a container. This signature could be used in a webapplication, to share every possible pseudofolder of a container with external people. The user who wants to share his container would not be obliged to generate a signature for every pseudofolder. Proposed Change =============== The formpost middleware should be changed. The code change would be really small. If a subprefix-based signature is desired, a form with a hidden field and name ""subprefix"" must be used. Formpost would use the value of this field to calculate a hash based on that value. Furthermore, the middleware would check if the object path really contains this prefix. Lets have one example: A user wants to share the pseudofolder ""folder"" with external users in a web-based fashion. He (or a webapplication) calcluates the signature with the path ""/v1/my_account/container/folder"": :: import hmac from hashlib import sha1 from time import time path = '/v1/my_account/container/folder' redirect = 'https://myserver.com/some-page' max_file_size = 104857600 max_file_count = 10 expires = int(time() + 600) key = 'MYKEY' hmac_body = '%s\n%s\n%s\n%s\n%s' % (path, redirect, max_file_size, max_file_count, expires) signature = hmac.new(key, hmac_body, sha1).hexdigest() If an external user is willing to post to the subfolder folder/subfolder/, a form which contains the above calculated signature and the hidden field subprefix would be used: :: <![CDATA[ <form action=""https://myswift/v1/my_account_container/folder/subfolder/"" method=""POST"" enctype=""multipart/form-data""> <input type=""hidden"" name=""redirect"" value=""REDIRECT_URL""/> <input type=""hidden"" name=""max_file_size"" value=""BYTES""/> <input type=""hidden"" name=""max_file_count"" value=""COUNT""/> <input type=""hidden"" name=""expires"" value=""UNIX_TIMESTAMP""/> <input type=""hidden"" name=""signature"" value=""HMAC""/> <input type=""hidden"" name=""subprefix"" value=""folder"" <input type=""file"" name=""FILE_NAME""/> <br/> <input type=""submit""/> </form> ]]> Implementation ============== Assignee(s) ----------- Primary assignee: bartz Work Items ---------- Add modifications to formpost and respective test module. Repositories ------------ None Servers ------- None DNS Entries ----------- None Documentation ------------- Modify documentation for formpost middleware. Security -------- None Testing ------- Tests should be added to the existing test module. Dependencies ============ None ",,131,0
openstack%2Fswift-specs~master~Ie7d88b170bcd0172f093d94a30c75281ccdeed62,openstack/swift-specs,master,Ie7d88b170bcd0172f093d94a30c75281ccdeed62,Add questions section into global_ec_cluster,MERGED,2015-09-17 06:05:26.000000000,2016-05-05 03:47:04.000000000,2016-05-05 03:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 330}]","[{'number': 1, 'created': '2015-09-17 06:05:26.000000000', 'files': ['specs/in_progress/global_ec_cluster.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/cdfa7b2ec504f7336c970c7d06ac8f750cb9e147', 'message': 'Add questions section into global_ec_cluster\n\nChange-Id: Ie7d88b170bcd0172f093d94a30c75281ccdeed62\n'}]",2,224439,cdfa7b2ec504f7336c970c7d06ac8f750cb9e147,8,2,1,4608,,,0,"Add questions section into global_ec_cluster

Change-Id: Ie7d88b170bcd0172f093d94a30c75281ccdeed62
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/39/224439/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/global_ec_cluster.rst'],1,cdfa7b2ec504f7336c970c7d06ac8f750cb9e147,global-ec-cluster-questions,Questions and Answers ===================== - TBD,,4,0
openstack%2Fswift-specs~master~Id9b39b5b856da9c37cc37e6882fef814af81f540,openstack/swift-specs,master,Id9b39b5b856da9c37cc37e6882fef814af81f540,Swift tiering specification,MERGED,2015-01-29 18:14:46.000000000,2016-05-05 03:46:40.000000000,2016-05-05 03:46:40.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7479}, {'_account_id': 10068}, {'_account_id': 12193}, {'_account_id': 14737}, {'_account_id': 14967}, {'_account_id': 16550}]","[{'number': 1, 'created': '2015-01-29 18:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/1540090d51cb336801e811f7375da05eee16cd7e', 'message': 'Swift tiering specification\n\nChange-Id: Id9b39b5b856da9c37cc37e6882fef814af81f540\n'}, {'number': 2, 'created': '2015-02-10 16:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/5f5ab7cf18340523dca413c3fe82a4dde319d7ac', 'message': 'Swift tiering specification\n\nChange-Id: Id9b39b5b856da9c37cc37e6882fef814af81f540\n'}, {'number': 3, 'created': '2015-08-04 19:19:18.000000000', 'files': ['specs/in_progress/images/tiering_overview.png', 'specs/in_progress/tiering.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/08226f79b6e089259d4650f022f1e087f43b2348', 'message': 'Swift tiering specification\n\nChange-Id: Id9b39b5b856da9c37cc37e6882fef814af81f540\n'}]",5,151335,08226f79b6e089259d4650f022f1e087f43b2348,35,10,3,14737,,,0,"Swift tiering specification

Change-Id: Id9b39b5b856da9c37cc37e6882fef814af81f540
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/35/151335/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/tiering.rst'],1,1540090d51cb336801e811f7375da05eee16cd7e,tiering,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ************************* Automated Tiering Support ************************* 1. Summary ========== Automated tiering is a feature provided by storage systems that include multiple media types like SSD, HDD, and Tape. It enables seamless movement of active data to high-performance storage media and inactive data to low-cost, high capacity storage media. Effective utilization of these tiers results in an overall total cost of ownership (TCO) reduction for the customers. Tiering is typically automated by declaring a policy based on age, object attributes, etc. The system then, in the background, identifies candidate objects and moves them between the tiers. 2. Motivation ============= This initial spec proposes to add automated tiering as a native feature in Swift. The motivation to do so stems from (but not limited to) the following observations: (a) In some customer environments, Swift may not be the final tier in an object's lifecycle. Some examples of archival-class stores lower in cost than Swift include specialized tape-based systems, public cloud solutions such as Glacier, etc. Analogous to what we are proposing, Amazon S3 already has the in-built support to tier objects between S3 and Glacier after a certain scheduled time. (b) Similar to primary storage systems, data hosted by a Swift cluster goes through its own information lifecycle. As data ages, it becomes more and more unlikely to be accessed by the user. Swift can leverage the change in data properties to move objects from one of its supported backends to another that fits more closely the objects business needs ($/GB, performance, availability) transparent to users. Note that with the introduction of Storage policies feature, Swift 2.0 now has the ability to manage multiple disparate backends spanning a spectrum of high-performance to low-performance storage media. (c) Support for multiple storage policies also enables logical tiering/transformation of data. For example, as Swift data gets cold, it can be seamlessly moved from a low-density, low access cost (e.g. replication) to high-density, high access-cost (erasure coding) configuration. 3. Proposed Implementation ========================== As part of this initial spec, we present some rough/initial thoughts towards one possible implementation of data tiering in Swift. If the proposal to add tiering as a Swift feature is approved, this spec will evolve into a more complete design document with collective input from community members. 3.1 Stub-based Mechanism ------------------------ (a) We propose to add a new background process to Swift say, object-migrator. Its main function would be to walk through resident objects in Swift and identify candidates to be moved to a different tier. The destination tier could be an external storage system or a different storage backend in a Swift cluster. (b) The criterion for de-staging objects from Swift is likely to be based on age, but other rules can apply. Swift inherently maintains the creation time in the objects internal name. When an object is stored on the default XFS filesystem, it gets the filename <objectname>.<timestamp>. For more advanced criteria (say, popularity), Swift might need to support auxiliary data structures to capture/sort (i) object access counts (ii) last time object was touched, etc. (c) After the object is moved, the background process leaves a stub/reference object in its place. The stub object is akin to a symbolic link in a POSIX file system. It only holds sufficient information to locate the real object stored in the destination tier. In Swift, a stub object could be identified with a special system metadata key/value pair. (e) Replacing de-staged objects with stub/reference objects keeps the tiering implementation transparent to the user. No changes to the objects external namespace as seen by the client are required. Also, no changes to Swifts internal ring-based lookup mechanisms would be required. Further, no changes to container/account servers or their operations are expected. (f) When a GET request attempts to read a de-staged object from Swift, a custom handler is invoked upon encountering the stub. The handler routine could fetch-on-demand the object from the destination tier and serve it to the client. Alternatively, for very slow destination tiers like Glacier that take a long time to retrieve data, Swift can respond to the client with an appropriate retry later message while the stubbed object is being restored in the background. The handler could be written as a pluggable module specific to the backend tier device. For example, it can be inserted as a middleware in the object server pipeline. (g) We would need to handle new issues arising out of maintaining stub objects. For example, consider the garbage collection problem such as when a moved object is overwritten in Swift by a client PUT. Either on ingest operation of the PUT or later as part of the background process, the old object in the destination tier must be deleted. 3.2 Tiering Policies -------------------- Specification of tiering rules (e.g. move all objects older than 6 months to tape) can be de-coupled from the exact implementation mechanism. Some options to specify rules are (a) Tiering rules can be specified separately in a configuration section for the object-migrator daemon. This would be similar to how configuration options are defined for object-auditor, object-replicator, etc. (b) Tiering rules can be incorporated as core property of the storage backend in Swift from which objects are periodically de-staged to lower tier. For example, they can be specified within the storage policy configuration section for the backend. (c) Tiering rules can also be specified to pre-migrate (planned move from lower tier to higher tier) if access patterns are planned. Given the wide needs of customers here we are hoping to hear from operators on this forum to help identify a pragmatic set of policies. 3.3 Possible Optimizations -------------------------- Based on some feedback received during the brainstorming session in Paris summit, the following optimizations can be considered to alleviate tiering overheads. (a) Client DELETE requests for de-staged objects should be completed asynchronously by background process to avoid increased latencies for foreground API requests. (b) The tiering process should attempt to minimize the number of I/O connections to the lower tier. This requirement becomes important when communicating across WAN to remote DCs. (c) The tiering process should include capability to coalesce candidate objects and perform de-staging operations by packing/unpacking as compound objects before/after moving objects between tiers. This requirement caters to tiering small objects to bottom tiers such as Tape that are more suited for large I/O streaming workloads. 4. Related Spec =============== The stub-based mechanism introduced in this spec is similar to whats proposed in a separate spec on hybrid containers. In both the specs, stub is the underlying technique used to cross-link between multiple storage backends. As discussed in the specs, the ability to place a stub in one backend that points to another object location facilitates seamless data migration without any client involvement. ",,155,0
openstack%2Fswift-specs~master~Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d,openstack/swift-specs,master,Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d,Changing Policies spec,MERGED,2015-03-30 02:09:29.000000000,2016-05-05 03:45:45.000000000,2016-05-05 03:45:45.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 12193}]","[{'number': 1, 'created': '2015-03-30 02:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/59f161bc6877f50a7e688fb051ad213c451c8360', 'message': 'Changing Policies spec\n\nThis is the proposal to give swift users power to change storage policies\nof containers after creating them.\n\nImplements: blueprint changing-policies\n\nChange-Id: Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d\n'}, {'number': 2, 'created': '2015-05-07 07:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/53ba9814d941d9406be1bb275a6430284f6ebc74', 'message': 'Changing Policies spec\n\nThis is the proposal to give swift users power to change storage policies\nof containers after creating them.\n\nImplements: blueprint changing-policies\n\nChange-Id: Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d\n'}, {'number': 3, 'created': '2015-11-16 09:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/eebd254b431f313f6ce4a39d948ba80226b778cc', 'message': 'Changing Policies spec\n\nThis is the proposal to give swift users power to change storage policies\nof containers after creating them.\n\nImplements: blueprint changing-policies\n\nChange-Id: Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d\n'}, {'number': 4, 'created': '2015-11-17 05:26:32.000000000', 'files': ['specs/in_progress/changing_policies.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/0d00d362b7e4911823786876703b7536d7fbc599', 'message': 'Changing Policies spec\n\nThis is the proposal to give swift users power to change storage policies\nof containers after creating them.\n\nImplements: blueprint changing-policies\n\nChange-Id: Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d\n'}]",0,168761,0d00d362b7e4911823786876703b7536d7fbc599,15,5,4,8859,,,0,"Changing Policies spec

This is the proposal to give swift users power to change storage policies
of containers after creating them.

Implements: blueprint changing-policies

Change-Id: Ia4b3f8471e9b8347439dc2f6c41df15c5d84db8d
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/61/168761/3 && git format-patch -1 --stdout FETCH_HEAD,"['specs/in_progress/changing_policies.rst', 'specs/in_progress/images/policy_changing_fig1.png', 'specs/in_progress/images/policy_changing_fig2.png']",3,59f161bc6877f50a7e688fb051ad213c451c8360,bp/changing-policies,,,285,0
openstack%2Fswift-specs~master~I20db8dcc7c6b661e35c00e1dab6e8770ff216a27,openstack/swift-specs,master,I20db8dcc7c6b661e35c00e1dab6e8770ff216a27,Updating spec to reflect a few changes.,MERGED,2015-11-18 21:28:43.000000000,2016-05-05 03:45:42.000000000,2016-05-05 03:45:42.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 12193}]","[{'number': 1, 'created': '2015-11-18 21:28:43.000000000', 'files': ['specs/in_progress/expiring_objects_rework.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/89fbfdf4b97794ee7ee80ed134a3d45e9dc95696', 'message': 'Updating spec to reflect a few changes.\n\nChange-Id: I20db8dcc7c6b661e35c00e1dab6e8770ff216a27\n'}]",0,247185,89fbfdf4b97794ee7ee80ed134a3d45e9dc95696,7,3,1,13297,,,0,"Updating spec to reflect a few changes.

Change-Id: I20db8dcc7c6b661e35c00e1dab6e8770ff216a27
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/85/247185/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/expiring_objects_rework.rst'],1,89fbfdf4b97794ee7ee80ed134a3d45e9dc95696,expiring_objects_spec_update,"There are multiple parts to the implementation. The updating of the container database to remove the expired objects and the removal of the object from disk. Step 1: A expired table will be added to the container database. There will be a 'obj_row_id' and 'expired_at' column on the table. The 'obj_row_id' column will correlate to the row_id for an object in the objects table. The 'expired_at' column will be an integer timestamp of when the object expires. The container replicator will remove the object rows from objects table when their corresponding 'expire_at' time in the expired table is before the start time of the pass. There will be a trigger to delete row(s) in the 'expired' table after the deletion of row(s) out of the 'objects' table. Once, the removal of the expired objects are complete the container database will be replicated. Step 2:"," The object table, in the container database, will have a 'expire_at'column added. The expire_at column will be a timestamp that reflect when/if an object should expire. When a container listing request is made objects whos 'expire_at' times are before the request time will not be returned. The container replicator will remove the object rows from the container databases when the expire_at and reclaim age have passed. Once the container updater runs and updates that stats for the containers the objects that are expired will no longer be considered in the bytes_used or the object counts in the account database. ",14,11
openstack%2Fswift-specs~master~Ibb5e7118933ceff02c4325734ab29917239602a5,openstack/swift-specs,master,Ibb5e7118933ceff02c4325734ab29917239602a5,tempurls with a prefix-based scope,MERGED,2015-07-08 15:12:22.000000000,2016-05-05 03:44:49.000000000,2016-05-05 03:44:49.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 860}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 5600}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 9216}, {'_account_id': 17245}]","[{'number': 1, 'created': '2015-07-08 15:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/a55fd28f66015c0a7002e28206a5cfe131ac2c69', 'message': 'See blueprint: https://blueprints.launchpad.net/swift/+spec/tempurl-container-signature\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 2, 'created': '2015-07-08 15:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/cdc0d058b4cafc0ab6e4064c11495b3261f7839a', 'message': 'tempurls with a container-level scope\n\nSee blueprint: https://blueprints.launchpad.net/swift/+spec/tempurl-container-signature\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 3, 'created': '2015-07-08 15:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/82c3b44ea3f89945ea513254d763866de02de25a', 'message': 'tempurls with a container-level scope\n\nThe tempurl middleware should be allowed to use signatures with a container-level scope in order to access all objects inside a container.\nThis avoids the creation of a large amount of temporary urls. Beyond that, the tempurl middleware should also operate on containers and not only objects.\nA use-case could be a container listing.\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 4, 'created': '2015-07-08 16:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/7a8bd28c6fea9f01254e982c84f08f667e9a9144', 'message': 'tempurls with a container-level scope\n\nThe tempurl middleware should be allowed to use signatures with a\ncontainer-level scope in order to access all objects inside a container.\nThis avoids the creation of a large amount of temporary urls.\nBeyond that, the tempurl middleware should also operate on containers and not only objects.\nA use-case could be a container listing.\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 5, 'created': '2015-07-09 10:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/60df1d47da5ead4e5faabc4bef23e7d5992090fd', 'message': 'tempurls with a container-level scope\n\nThe tempurl middleware should be allowed to use signatures with a\ncontainer-level scope in order to access all objects inside a container.\nThis avoids the creation of a large amount of temporary urls. The signature could\nalso be based on a prefix, to support the sharing of pseudofolders.\nBeyond that, the tempurl middleware should also operate on containers and not only objects.\nA use-case could be a container listing.\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 6, 'created': '2015-08-10 09:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/40c462e18b70d552038c9e30c0150da8829f8ea4', 'message': 'tempurls with a container-level scope\n\nThe tempurl middleware should be allowed to use signatures with a\ncontainer-level scope in order to access all objects inside a container.\nThis avoids the creation of a large amount of temporary urls. The signature could\nalso be based on a prefix, to support the sharing of pseudofolders.\nBeyond that, the tempurl middleware should also operate on containers and not only objects.\nA use-case could be a container listing.\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}, {'number': 7, 'created': '2016-01-28 10:55:15.000000000', 'files': ['specs/in_progress/prefix_based_tempurl.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/2d41f397df695587652143b824ae0bbd0a66fb6a', 'message': 'tempurls with a prefix-based scope\n\nThe tempurl middleware should be allowed to use signatures with a\nprefix-based scope in order to access all objects which share the same prefix.\nThis avoids the creation of a large amount of temporary urls, when\na whole container or pseudofolder is shared.\n\nChange-Id: Ibb5e7118933ceff02c4325734ab29917239602a5\n'}]",33,199607,2d41f397df695587652143b824ae0bbd0a66fb6a,43,10,7,17245,,,0,"tempurls with a prefix-based scope

The tempurl middleware should be allowed to use signatures with a
prefix-based scope in order to access all objects which share the same prefix.
This avoids the creation of a large amount of temporary urls, when
a whole container or pseudofolder is shared.

Change-Id: Ibb5e7118933ceff02c4325734ab29917239602a5
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/07/199607/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/container_tempurl.rst'],1,a55fd28f66015c0a7002e28206a5cfe131ac2c69,bp/https,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: ""None"". For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html =============================== tempurl should also allow container based signatures =============================== The tempurl middleware should be allowed to use a container-based signature for all objects inside the container. See blueprint: https://blueprints.launchpad.net/swift/+spec/tempurl-container-signature Problem Description =================== At the moment, if one wants to share a large amount of objects inside a container with external people, one has to create temporary urls for each object. In the case of PUT, often, the name of the data which has to be put is not known in advance, but the temporary urls must already contain the name. It would be better to have one signature which allow access for all objects inside the whole container. Beyond that, the temporary urls should also allow access to the container itself and not only objects within a container. It could be useful for example to list the objects of a container. Proposed Change =============== The temporary url middleware should be changed. The code must only be rewritten on some places. If the client desires to use a container based signature, he can append an URL parameter ""container_based"", and the middleware would only use the container-path for calculating the signature. Beyond that, the middleware should be changed to allow operations on the container itself. It appears that only some lines have to be changed. Alternatives ------------ A new middleware could be introduced. But it seems that this would only lead to a lot of code-copying, as the changes are really small in comparison to the original middleware. Implementation ============== Assignee(s) ----------- Primary assignee: bartz Work Items ---------- Add modifications to tempurl and respective test module. Repositories ------------ None Servers ------- None DNS Entries ----------- None Documentation ------------- Modify documentation for tempurl middleware. Security -------- None Testing ------- Tests should be added to the existing test module. Dependencies ============ None ",,96,0
openstack%2Fswift-specs~master~Ib42f7218d51b77d7976b50245b23b794cd93422a,openstack/swift-specs,master,Ib42f7218d51b77d7976b50245b23b794cd93422a,Swift Request tagging for detailed logging/tracing,MERGED,2016-03-03 15:38:47.000000000,2016-05-05 03:44:44.000000000,2016-05-05 03:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}]","[{'number': 1, 'created': '2016-03-03 15:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/2c64442dfc45f2a611007af9d9d1ca6c18374a7e', 'message': ""Swift Request tagging for detailed logging/tracing\n\nAdding/enhancing Swift-Inspector middleware for OpenStack Swift to\ntag a particular request/every 'x' requests which would undergo\nmore detailed logging.\nA Swift user is having problems which we cannot recreate but tag this request\nfor more logging. Also an internal user(admin/op) could use additional logs\nto investigate a cluster for bottlenecks/problems.\n\nChange-Id: Ib42f7218d51b77d7976b50245b23b794cd93422a\n""}, {'number': 2, 'created': '2016-03-03 15:45:06.000000000', 'files': ['specs/in_progress/request_tagging_logging.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/1a9e9315a31e7c8bdf05ee338227bd0b11d2d9b3', 'message': ""Swift Request tagging for detailed logging/tracing\n\nAdding/enhancing Swift-Inspector middleware for OpenStack Swift to\ntag a particular request/every 'x' requests which would undergo\nmore detailed logging.\nA Swift user is having problems which we cannot recreate but tag this\nrequest for more logging. Also an internal user(admin/op) could use\nadditional logs to investigate a cluster for bottlenecks/problems.\n\nChange-Id: Ib42f7218d51b77d7976b50245b23b794cd93422a\n""}]",4,287922,1a9e9315a31e7c8bdf05ee338227bd0b11d2d9b3,8,3,2,17361,,,0,"Swift Request tagging for detailed logging/tracing

Adding/enhancing Swift-Inspector middleware for OpenStack Swift to
tag a particular request/every 'x' requests which would undergo
more detailed logging.
A Swift user is having problems which we cannot recreate but tag this
request for more logging. Also an internal user(admin/op) could use
additional logs to investigate a cluster for bottlenecks/problems.

Change-Id: Ib42f7218d51b77d7976b50245b23b794cd93422a
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/22/287922/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/request_tagging_logging.rst'],1,2c64442dfc45f2a611007af9d9d1ca6c18374a7e,swift-request-tagging,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: ""None"". For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================================== Swift Request Tagging for detailed logging/tracing ================================================== URL of your blueprint: None. To tag a particular request/every 'x' requests, which would undergo more detailed logging. Problem Description =================== Reasons for detailed logging: - A Swift user is having problems, which we cannot recreate but could tag this user request for more logging. - In order to better investigate a cluster for bottlenecks/problems - Internal user (admin/op) wants additional info on some situations where the client is getting inconsistent container listings. With the Swift-inspector, we can tell what node is not returning the correct listings. Proposed Change =============== Existing: Swift-Inspector (https://github.com/hurricanerix/swift-inspector ) currently provides middleware in Proxy and Object servers. Relays info about a request back to the client with the assumption that the client is actively making a decision to tag a request to trigger some action that would not otherwise occur. Current Inspectors: - Timing -Inspector-Timing: gives the amount of time it took for the proxy-server to process the request - Handlers  Inspector-Handlers: not implemented (meant to return the account/container/object servers that were contacted in the request) Inspector-Handlers-Proxy: returns the proxy that handled the request - Nodes - Inspector-Nodes: returns what account/container/object servers the path resides on Inspector-More-Nodes: returns extra nodes for handoff. Changes: - Add logging inspector to the above inspectors , which would enable detailed logging for tagged requests. - Add the capability to let the system decide (instead of the client) to tag a request and nice to add rules to trigger actions like extra logging etc. Possible Tagging criteria: Tagging - every 'x' requests/ a % of all requests. - based on something in the request/response headers (e.g.if the HTTP method is DELETE, or the response is sending a specific status code back) - based on a specific account/container/object/feature. Alternatives ------------ - Logging: log collector/log aggregator like logstash. Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~shashirekha-j-gundur Work Items ---------- - To add an Inspector Logging to existing inspectors , to enable the logs. - Add rules to tag decide which requests to be tagged - Trigger actions like logging. - Restrict the access of nodes/inventory list displayed to admins/ops only. - Figure out hmac_key access (Inspector-Sig) and Logging work together? Repositories ------------ Will any new git repositories need to be created? Yes. Servers ------- Will any new servers need to be created? No. What existing servers will be affected? Proxy and Object servers. DNS Entries ----------- Will any other DNS entries need to be created or updated? No. Documentation ------------- Will this require a documentation change? Yes , Swift-inspector docs. Will it impact developer workflow? No. Will additional communication need to be made? No. Security -------- None. Testing ------- Unit tests. Dependencies ============ - Swift-Inspector https://github.com/hurricanerix/swift-inspector - Does it require a new puppet module? No. ",,123,0
openstack%2Fswift-specs~master~Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac,openstack/swift-specs,master,Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac,Add containeralias spec,MERGED,2015-02-12 23:13:48.000000000,2016-05-05 03:44:12.000000000,2016-05-05 03:44:12.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 18838}]","[{'number': 1, 'created': '2015-02-12 23:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/d09c5abf2d2234d2fc2443a5d24ea26239094de2', 'message': 'Add containeralias spec\n\nChange-Id: Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac\n'}, {'number': 2, 'created': '2015-02-12 23:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/d2d96a63b75455245f51f266e176499ea60406dd', 'message': 'Add containeralias spec\n\nChange-Id: Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac\n'}, {'number': 3, 'created': '2015-02-14 00:32:07.000000000', 'files': ['specs/in_progress/containeralias.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/6f082fbb00e0cc4517807c8104262cfa2d03757c', 'message': 'Add containeralias spec\n\nChange-Id: Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac\n'}]",3,155524,6f082fbb00e0cc4517807c8104262cfa2d03757c,12,5,3,6968,,,0,"Add containeralias spec

Change-Id: Ib9fdc5ef70ab303b6ead4eac89b281368bc466ac
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/24/155524/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/containeralias.rst'],1,d09c5abf2d2234d2fc2443a5d24ea26239094de2,containeralias,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ================= Container aliases ================= A container alias makes it possible to link to other containers, even to containers in different accounts. Problem Description =================== Currently it is quite quite complicated to access containers in other accounts, because you need to use a different storage URL that might be even unknown to a client. Even if the storage URL is known these containers are not listed when doing a GET request on the users account, thus they are not discoverable by a regular client application. Alias container could simplify this task. A user can set an alias onto a container, and this alias points to a second container, even in a different account. This makes it much more simple to access these containers with existing clients for different reasons. 1. A GET request on the account level would list these containers 2. Requests to an alias container are forwarded to the target container, making it possible to access that container without using a different storage URL in the client. However, setting the alias still requires the storage URL (see below for an alternative to this). Caveats ======= Setting an alias should be impossible if there are objects in the source container. These would become inaccessible, but still require storage space. There is a possible race condition if a container is created and objects are stored within while at the same time (plus a few milliseconds?) an alias is set. A reconciler mechanism (similar to the one used in storage policies) might solve this, as well as ensuring that the alias can be only set during container creation. Unsetting alias should be denied, instead the alias container is to be deleted. Bonus ===== Cross-account container sharing might be even more simplified, leading to a better user experience. Let's assume there are two users in different accounts: test:tester and test2:tester2. If test:tester puts an ACL onto an container /AUTH_test/container to allow access for test2:tester2, the middleware could create an alias container /AUTH_test2/test_container linking to /AUTH_test/container. This would make it possible to discover shared containers to other users/accounts. However, there are two challenges: 1. Name conflicts: there might be an existing container ""/AUTH_test2/test_container"" 2. A lookup would require to resolve an account name into the account ID Proposed Change =============== Most of the required changes can be put into a separate middleware. There is an existing patch: https://review.openstack.org/#/c/62494 An update to the container-reconciler is required to move objects in an alias container to the target container. Assignee(s) ----------- Primary assignee: cschwede <christian.schwede@enovance.com Work Items ---------- Update container reconciler. Documentation ------------- Update the documentation and document the behavior. Security -------- Test and verify what happens if requests are not yet authenticated; make sure ACLs are respected and unauthorized requests to containers in other accounts is impossible. ",,102,0
openstack%2Foslo.utils~master~I1a039792748facab4a09cfe11d8d9b935192517c,openstack/oslo.utils,master,I1a039792748facab4a09cfe11d8d9b935192517c,Imported Translations from Zanata,MERGED,2016-05-03 06:47:06.000000000,2016-05-05 03:28:00.000000000,2016-05-05 03:28:00.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6676}]","[{'number': 1, 'created': '2016-05-03 06:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/ff13d2e840f794c6eddfb9e3f21f604fd8222a40', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1a039792748facab4a09cfe11d8d9b935192517c\n'}, {'number': 2, 'created': '2016-05-04 06:33:52.000000000', 'files': ['oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/oslo_utils-log-info.pot', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/oslo_utils-log-error.pot', 'oslo_utils/locale/oslo_utils.pot', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/oslo_utils-log-warning.pot', 'oslo_utils/locale/es/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/pt_BR/LC_MESSAGES/oslo_utils-log-error.po'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/406c753a72c900884e07cd47ee5bc62d739f5e6a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1a039792748facab4a09cfe11d8d9b935192517c\n'}]",0,311936,406c753a72c900884e07cd47ee5bc62d739f5e6a,9,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1a039792748facab4a09cfe11d8d9b935192517c
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/36/311936/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/oslo_utils-log-info.pot', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/oslo_utils-log-error.pot', 'oslo_utils/locale/oslo_utils.pot', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-info.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/fr/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/en_GB/LC_MESSAGES/oslo_utils.po', 'oslo_utils/locale/oslo_utils-log-warning.pot', 'oslo_utils/locale/es/LC_MESSAGES/oslo_utils-log-error.po', 'oslo_utils/locale/de/LC_MESSAGES/oslo_utils-log-warning.po', 'oslo_utils/locale/pt_BR/LC_MESSAGES/oslo_utils-log-error.po']",17,ff13d2e840f794c6eddfb9e3f21f604fd8222a40,zanata/translations,"""Project-Id-Version: oslo.utils 3.7.1.dev13\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2016-05-02 20:03+0000\n""","""Project-Id-Version: oslo.utils 3.7.1.dev10\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2016-04-12 20:23+0200\n""",77,77
openstack%2Foslo.messaging~master~I507c021d851254d4d84e8922de687931f8545864,openstack/oslo.messaging,master,I507c021d851254d4d84e8922de687931f8545864,Simulator: align stats to whole seconds,MERGED,2016-03-22 08:45:58.000000000,2016-05-05 03:22:06.000000000,2016-05-05 03:22:05.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-22 08:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f5c1f9e338c9b3a032d2af9fa594e34fffca1045', 'message': 'Simulator: align stats to whole seconds\n\nAligning stats collection to whole seconds allows to merge data\nfrom client and server - useful for visualization of message flow.\n\nChange-Id: I507c021d851254d4d84e8922de687931f8545864\n'}, {'number': 2, 'created': '2016-03-22 10:39:09.000000000', 'files': ['tools/simulator.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/782ab770cf55d9856a9917ace5924c9d2732af99', 'message': 'Simulator: align stats to whole seconds\n\nAligning message sending and stats collection to whole seconds.\nThis allows to merge data from client and server - useful\nfor visualization of message flow.\n\nChange-Id: I507c021d851254d4d84e8922de687931f8545864\n'}]",0,295673,782ab770cf55d9856a9917ace5924c9d2732af99,9,2,2,5950,,,0,"Simulator: align stats to whole seconds

Aligning message sending and stats collection to whole seconds.
This allows to merge data from client and server - useful
for visualization of message flow.

Change-Id: I507c021d851254d4d84e8922de687931f8545864
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/73/295673/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/simulator.py'],1,f5c1f9e338c9b3a032d2af9fa594e34fffca1045,sim-align-time," now = time.time() diff = int(now) - now + 1 # align start to whole seconds threading.Timer(diff, self.monitor).start() # schedule in a second"," threading.Timer(1.0, self.monitor).start() # schedule in a second",4,1
openstack%2Fhorizon~master~I56b2c300ae91875fda3b804a1c8728319e234363,openstack/horizon,master,I56b2c300ae91875fda3b804a1c8728319e234363,Updated from global requirements,MERGED,2016-05-03 15:58:09.000000000,2016-05-05 03:16:18.000000000,2016-05-05 03:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2016-05-03 15:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/72aa0f8a51c2e17f97a7840de4ed333efadb22bd', 'message': 'Updated from global requirements\n\nChange-Id: I56b2c300ae91875fda3b804a1c8728319e234363\n'}, {'number': 2, 'created': '2016-05-04 22:07:50.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/86cf509f7df05682da1cc3b18e1f05786a71d7cd', 'message': 'Updated from global requirements\n\nChange-Id: I56b2c300ae91875fda3b804a1c8728319e234363\n'}]",0,312136,86cf509f7df05682da1cc3b18e1f05786a71d7cd,12,4,2,11131,,,0,"Updated from global requirements

Change-Id: I56b2c300ae91875fda3b804a1c8728319e234363
",git fetch https://review.opendev.org/openstack/horizon refs/changes/36/312136/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,72aa0f8a51c2e17f97a7840de4ed333efadb22bd,openstack/requirements,"requests!=2.9.0,>=2.8.1 # Apache-2.0","requests>=2.8.1,!=2.9.0 # Apache-2.0",1,1
openstack%2Fnova~master~Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44,openstack/nova,master,Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44,Make compute rpcapi 'live_migration' backward compatible,MERGED,2016-04-28 08:07:06.000000000,2016-05-05 02:33:58.000000000,2016-05-05 02:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-04-28 08:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32404aba997bb711f3389bb123e5999e224cf07e', 'message': 'Make compute rpcapi \'live_migration\' backward compatible\n\nThis commit[1] added compute rpcapi version 4.2 which introduced a new\nargument \'migration\' when calling \'live_migration\' method, but the code\ndid not ensure the backward compatibility with older version compute node.\nWhen calling \'live_migration\' method with \'migration\' argument on older\nversion(like Kilo) of nova compute node, a ""TypeError: live_migration()\ngot an unexpected keyword argument \'migration\'"" will be threw up.\n\n[1]https://github.com/openstack/nova/commit/2f4e64a7cf81de4a22fe2fc4210b1f795b1a3db4\n\nChange-Id: Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44\nCloses-Bug: #1576048\n'}, {'number': 2, 'created': '2016-04-28 08:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/740e12e04fe30beeb20bfd914f3924382e8471b4', 'message': 'Make compute rpcapi \'live_migration\' backward compatible\n\nThis commit[1] added compute rpcapi version 4.2 which introduced a new\nargument \'migration\' when calling \'live_migration\' method, but the code\ndid not ensure the backward compatibility with older version compute\nnode.\n\nWhen calling \'live_migration\' method with \'migration\' argument on older\nversion(like Kilo) of nova compute node, a ""TypeError: live_migration()\ngot an unexpected keyword argument \'migration\'"" will be threw up.\n\n[1]https://github.com/openstack/nova/commit/2f4e64a7cf81de4a22fe2fc4210b1f795b1a3db4\n\nChange-Id: Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44\nCloses-Bug: #1576048\n'}, {'number': 3, 'created': '2016-04-28 10:37:43.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/34b8336a41e2896f0639c402f64a05247f475fea', 'message': 'Make compute rpcapi \'live_migration\' backward compatible\n\nThis commit[1] added compute rpcapi version 4.2 which introduced a new\nargument \'migration\' when calling \'live_migration\' method, but the code\ndid not ensure the backward compatibility with older version compute\nnode.\n\nWhen calling \'live_migration\' method with \'migration\' argument on older\nversion(like Kilo) of nova compute node, a ""TypeError: live_migration()\ngot an unexpected keyword argument \'migration\'"" will be threw up.\n\n[1]https://github.com/openstack/nova/commit/2f4e64a7cf81de4a22fe2fc4210b1f795b1a3db4\n\nChange-Id: Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44\nCloses-Bug: #1576048\n'}]",0,310691,34b8336a41e2896f0639c402f64a05247f475fea,30,12,3,13248,,,0,"Make compute rpcapi 'live_migration' backward compatible

This commit[1] added compute rpcapi version 4.2 which introduced a new
argument 'migration' when calling 'live_migration' method, but the code
did not ensure the backward compatibility with older version compute
node.

When calling 'live_migration' method with 'migration' argument on older
version(like Kilo) of nova compute node, a ""TypeError: live_migration()
got an unexpected keyword argument 'migration'"" will be threw up.

[1]https://github.com/openstack/nova/commit/2f4e64a7cf81de4a22fe2fc4210b1f795b1a3db4

Change-Id: Ie5c498d34e7c4c6573d611abd592c25f1bcb4f44
Closes-Bug: #1576048
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/310691/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/rpcapi.py'],1,32404aba997bb711f3389bb123e5999e224cf07e,bug/1576048, args = {},,1,0
openstack%2Ftripleo-ci~master~I0ad97df8a05646ac48be937cdc5b97ae77c7aa71,openstack/tripleo-ci,master,I0ad97df8a05646ac48be937cdc5b97ae77c7aa71,Enable undercloud ssl on nonha job,MERGED,2016-01-28 20:34:26.000000000,2016-05-05 02:33:28.000000000,2016-05-05 02:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-28 20:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/994930153f1423d1003b66841c1c2e5629524ac7', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 2, 'created': '2016-01-29 17:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c079c6f0188def4cc6aba0d777d452b17b96fd69', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 3, 'created': '2016-02-15 15:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/04843b91236891dbf6b9b3c359c9ac14ac934693', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 4, 'created': '2016-02-26 23:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f6479c9e1a91d43a77a3034491a8a0dc80fab0c', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 5, 'created': '2016-03-01 16:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fc1fc56b5c3f3a92bb074952371b4379f0ae5c20', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 6, 'created': '2016-03-04 18:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5f25f6d6895216fc21f9eacf35c82a6d633be2ba', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 7, 'created': '2016-03-08 22:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/20f4b2cb9e2397865bd3105ab4cca10af4c59e90', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 8, 'created': '2016-03-24 15:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bf78184840be041f9b9d48e86b008252ae9ef3f8', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}, {'number': 9, 'created': '2016-05-04 21:21:32.000000000', 'files': ['toci_instack.sh', 'scripts/deploy.sh', 'toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/50a9e1a2212932554653f83dc894601f1baad509', 'message': 'Enable undercloud ssl on nonha job\n\nMake use of the automatic certificate generation in the dependent\npatch to test that installing the undercloud with ssl endpoints\nworks.\n\nChange-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71\nDepends-On: I7616b82913d16f2ba837298309d836c4811c2a44\n'}]",0,273743,50a9e1a2212932554653f83dc894601f1baad509,61,4,9,6928,,,0,"Enable undercloud ssl on nonha job

Make use of the automatic certificate generation in the dependent
patch to test that installing the undercloud with ssl endpoints
works.

Change-Id: I0ad97df8a05646ac48be937cdc5b97ae77c7aa71
Depends-On: I7616b82913d16f2ba837298309d836c4811c2a44
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/43/273743/8 && git format-patch -1 --stdout FETCH_HEAD,"['toci_instack.sh', 'toci_gate_test.sh']",2,994930153f1423d1003b66841c1c2e5629524ac7,ssl-undercloud,export UNDERCLOUD_SSL=0 UNDERCLOUD_SSL=1,,6,0
openstack%2Ftricircle~master~I96013e2a3c871640b530611e36fa0a219c5e0516,openstack/tricircle,master,I96013e2a3c871640b530611e36fa0a219c5e0516,Pass tempest list_server_filters test,MERGED,2016-04-22 11:57:48.000000000,2016-05-05 02:22:41.000000000,2016-05-05 02:22:41.000000000,"[{'_account_id': 3}, {'_account_id': 11819}, {'_account_id': 12076}, {'_account_id': 13305}, {'_account_id': 17448}, {'_account_id': 18452}, {'_account_id': 19060}, {'_account_id': 19960}, {'_account_id': 21023}, {'_account_id': 21306}]","[{'number': 1, 'created': '2016-04-22 11:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/ca5f41c4deefe1e7e615bff7a51c8236dc3ab0ee', 'message': 'Pass tempest list_server_filters test\n\nChange the following to pass tempest list_server_filters test:\n\n(1) Change response body of Nova API gateway image controller\n(2) Add network controller\n(3) Add server list filters support\n(4) Change response body of server list\n\nChange-Id: I96013e2a3c871640b530611e36fa0a219c5e0516\n'}, {'number': 2, 'created': '2016-04-22 12:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/772b634bf22f4e3258ec7fedecdfaaebf57f3988', 'message': 'Pass tempest list_server_filters test\n\nChange the following to pass tempest list_server_filters test:\n\n(1) Change response body of Nova API gateway image controller\n(2) Add network controller\n(3) Add server list filters support\n(4) Change response body of server list\n\nChange-Id: I96013e2a3c871640b530611e36fa0a219c5e0516\n'}, {'number': 3, 'created': '2016-04-23 02:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/f75221da232c3d79cb8835959986619e13d5e3c2', 'message': 'Pass tempest list_server_filters test\n\nChange the following to pass tempest list_server_filters test:\n\n(1) Change response body of Nova API gateway image controller\n(2) Add network controller\n(3) Add server list filters support\n(4) Change response body of server list\n\nChange-Id: I96013e2a3c871640b530611e36fa0a219c5e0516\n'}, {'number': 4, 'created': '2016-04-28 03:11:27.000000000', 'files': ['tricircle/common/lock_handle.py', 'tricircle/common/utils.py', 'tricircle/tests/unit/nova_apigw/controllers/test_server.py', 'tricircle/nova_apigw/controllers/image.py', 'tricircle/nova_apigw/controllers/network.py', 'tricircle/nova_apigw/controllers/root.py', 'tricircle/nova_apigw/controllers/server.py', 'tricircle/network/plugin.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/e43c4bc656872a4ea297357ccc9e4f545811859a', 'message': 'Pass tempest list_server_filters test\n\nChange the following to pass tempest list_server_filters test:\n\n(1) Change response body of Nova API gateway image controller\n(2) Add network controller\n(3) Add server list filters support\n(4) Change response body of server list\n\nChange-Id: I96013e2a3c871640b530611e36fa0a219c5e0516\n'}]",0,309374,e43c4bc656872a4ea297357ccc9e4f545811859a,15,10,4,12076,,,0,"Pass tempest list_server_filters test

Change the following to pass tempest list_server_filters test:

(1) Change response body of Nova API gateway image controller
(2) Add network controller
(3) Add server list filters support
(4) Change response body of server list

Change-Id: I96013e2a3c871640b530611e36fa0a219c5e0516
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/74/309374/4 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/common/lock_handle.py', 'tricircle/common/utils.py', 'tricircle/tests/unit/nova_apigw/controllers/test_server.py', 'tricircle/nova_apigw/controllers/image.py', 'tricircle/tests/unit/network/test_plugin.py', 'tricircle/nova_apigw/controllers/network.py', 'tricircle/nova_apigw/controllers/root.py', 'tricircle/network/plugin.py', 'tricircle/nova_apigw/controllers/server.py']",9,ca5f41c4deefe1e7e615bff7a51c8236dc3ab0ee,ngw-tempest-basic," def _get_all(self, context, params): filters = [{'key': key, 'comparator': 'eq', 'value': value} for key, value in params.iteritems()] servers = client.list_servers(context, filters=filters) @staticmethod def _construct_brief_server_entry(server): return {'id': server['id'], 'name': server.get('name'), 'links': server.get('links')} @staticmethod def _transform_network_name(server): if 'addresses' not in server: return if not server['addresses']: return key = server['addresses'].keys()[0] value = server['addresses'].pop(key) key = key.split('#')[1] server['addresses'][key] = value return server def get_one(self, _id, **kwargs): return {'servers': [self._transform_network_name( server) for server in self._get_all(context, kwargs)]} self._transform_network_name(server) def get_all(self, **kwargs): return {'servers': [self._construct_brief_server_entry( server) for server in self._get_all(context, kwargs)]} pecan.response.status = 202 def list_resources(t_ctx, q_ctx, pod_, ele, _type_): 'value': ele['id']}]) self.project_id, pod, {'id': _id}, _type, list_resources) 'name': utils.get_bottom_network_name(network), def list_resources(t_ctx, q_ctx, pod_, ele_, _type_): if _type_ == constants.RT_NETWORK: value = utils.get_bottom_network_name(ele_) else: value = ele_['id'] return client.list_resources( _type_, t_ctx, [{'key': 'name', 'comparator': 'eq', 'value': value}])"," def _get_all(self, context): servers = client.list_servers(context) def get_one(self, _id): return {'servers': self._get_all(context)} def get_all(self): return {'servers': self._get_all(context)} def list_resources(t_ctx, q_ctx, pod_, _id_, _type_): 'value': _id_}]) self.project_id, pod, _id, _type, list_resources) 'name': network['id'], def list_resources(t_ctx, q_ctx, pod_, _id_, _type_): return client.list_resources(_type_, t_ctx, [{'key': 'name', 'comparator': 'eq', 'value': _id_}])",409,43
openstack%2Fnova~master~I16eafee7bd24febf58201d984cdcbfdef8b97ef3,openstack/nova,master,I16eafee7bd24febf58201d984cdcbfdef8b97ef3,Add ppc64le architecture to some libvirt unit tests,MERGED,2016-01-26 15:49:01.000000000,2016-05-05 02:13:34.000000000,2016-05-05 02:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 7979}, {'_account_id': 8175}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-01-26 15:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f783653603634ff7a3f075dd91db585545046afa', 'message': 'Add ppc64le architecture to some libvirt unit tests\n\nSome unit tests are failing when running on ppc64le.\nIt is necessary to add the option ppc64le inside the\narchitecture check for some test_blockinfo and test_driver unit tests.\n\nChange-Id: I16eafee7bd24febf58201d984cdcbfdef8b97ef3\n'}, {'number': 2, 'created': '2016-01-26 16:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80f12cc5f56830c533280ead04d6ff0912b4f1af', 'message': 'Add ppc64le architecture to some libvirt unit tests\n\nSome unit tests are failing when running on ppc64le.\nIt is necessary to add the option ppc64le inside the\narchitecture check for some test_blockinfo and test_driver unit tests.\n\nCloses-Bug: #1523734\n\nChange-Id: I16eafee7bd24febf58201d984cdcbfdef8b97ef3\n'}, {'number': 3, 'created': '2016-01-26 21:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bcc6d0d6a20618e25f50eb3ed9ff52af914c27e', 'message': 'Add ppc64le architecture to some libvirt unit tests\n\nSome unit tests are failing when running on ppc64le.\nIt is necessary to add the option ppc64le inside the\narchitecture check for some test_blockinfo and test_driver unit tests.\n\nCloses-Bug: #1523734\n\nChange-Id: I16eafee7bd24febf58201d984cdcbfdef8b97ef3\n'}, {'number': 4, 'created': '2016-03-08 19:44:03.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/83574aa27364e538dc4b96a9c90adae75b14ecf3', 'message': 'Add ppc64le architecture to some libvirt unit tests\n\nSome unit tests are failing when running on ppc64le.\nIt is necessary to add the option ppc64le inside the\narchitecture check for some test_blockinfo and test_driver unit tests.\n\nCloses-Bug: #1523734\n\nChange-Id: I16eafee7bd24febf58201d984cdcbfdef8b97ef3\n'}]",2,272603,83574aa27364e538dc4b96a9c90adae75b14ecf3,34,11,4,10577,,,0,"Add ppc64le architecture to some libvirt unit tests

Some unit tests are failing when running on ppc64le.
It is necessary to add the option ppc64le inside the
architecture check for some test_blockinfo and test_driver unit tests.

Closes-Bug: #1523734

Change-Id: I16eafee7bd24febf58201d984cdcbfdef8b97ef3
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/272603/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,f783653603634ff7a3f075dd91db585545046afa,," expect = {""ppc"": ""sdz"", ""ppc64"": ""sdz"", ""ppc64le"": ""sdz""} arch.PPC64: (""cdrom"", ""scsi"", ""sda""), arch.PPC64LE: (""cdrom"", ""scsi"", ""sda"")} arch.PPC64: (""cdrom"", ""scsi"", ""sda""), arch.PPC64LE: (""cdrom"", ""scsi"", ""sda"")}"," expect = {""ppc"": ""sdz"", ""ppc64"": ""sdz""} arch.PPC64: (""cdrom"", ""scsi"", ""sda"")} arch.PPC64: (""cdrom"", ""scsi"", ""sda"")}",7,5
openstack%2Fsearchlight~master~I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d,openstack/searchlight,master,I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d,Add cleanup in functional tests,MERGED,2016-03-21 09:22:52.000000000,2016-05-05 02:04:15.000000000,2016-05-05 02:04:15.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 10063}, {'_account_id': 16150}]","[{'number': 1, 'created': '2016-03-21 09:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/1b0e8b944e056f558b62616aa8d9d7b948358cea', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}, {'number': 2, 'created': '2016-03-24 01:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/57b8bfcbab83ae5ea55c72c16c6f48a86d59194d', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}, {'number': 3, 'created': '2016-03-25 00:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/9d38e70bf895f5b12bd31d7c7a37b20e01832fcc', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}, {'number': 4, 'created': '2016-04-19 22:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/2497ed63335e40b5fa0326e335954acc358ab56c', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}, {'number': 5, 'created': '2016-05-03 07:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/24d900276aa5e0c15f6c8e57252b7cb771b6d304', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}, {'number': 6, 'created': '2016-05-05 00:20:29.000000000', 'files': ['searchlight/tests/functional/__init__.py'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/101c7349aef75f922a9ae50fa3b3ea8d603744f9', 'message': 'Add cleanup in functional tests\n\nIn unittest, if setUp fails, tearDown is not called. Unittest added a\nfunction addCleanup in python 2.7\n(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)\nthat DOES run even if setUp fails. Add addCleanup call to functional test\nin setUp.\n\nChange-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d\nCloses-bug: #1557287\n'}]",4,295156,101c7349aef75f922a9ae50fa3b3ea8d603744f9,32,5,6,4428,,,0,"Add cleanup in functional tests

In unittest, if setUp fails, tearDown is not called. Unittest added a
function addCleanup in python 2.7
(https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup)
that DOES run even if setUp fails. Add addCleanup call to functional test
in setUp.

Change-Id: I236d4c2fbcb571ee5565d4fc2be3d2c8bee8d71d
Closes-bug: #1557287
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/56/295156/4 && git format-patch -1 --stdout FETCH_HEAD,['searchlight/tests/functional/__init__.py'],1,1b0e8b944e056f558b62616aa8d9d7b948358cea,bug/1557287, self.addCleanup(self.cleanup),,1,0
openstack%2Fopenstack-manuals~master~Ia0856e024053cfabafb4342335a0ee4fa9f09692,openstack/openstack-manuals,master,Ia0856e024053cfabafb4342335a0ee4fa9f09692,[User Guides] Added pci_passthrough:alias to flavor extra specs,MERGED,2016-05-03 17:38:01.000000000,2016-05-05 01:57:24.000000000,2016-05-05 01:57:24.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12171}, {'_account_id': 15334}, {'_account_id': 17973}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-05-03 17:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e4e7860a536945427641b11aa89950959ab9e268', 'message': '[User Guides] Added pci_passthrough:alias to flavor extra specs\n\nChange-Id: Ia0856e024053cfabafb4342335a0ee4fa9f09692\n'}, {'number': 2, 'created': '2016-05-03 20:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e661a0fcf863d7a66fd28cb951f737cec9621dcf', 'message': '[User Guides] Added pci_passthrough:alias to flavor extra specs\n\nChange-Id: Ia0856e024053cfabafb4342335a0ee4fa9f09692\n'}, {'number': 3, 'created': '2016-05-04 12:29:11.000000000', 'files': ['doc/admin-guide/source/compute-flavors.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3762ddf8259818870db5ebbfacd522ed79d0dfc4', 'message': '[User Guides] Added pci_passthrough:alias to flavor extra specs\n\nChange-Id: Ia0856e024053cfabafb4342335a0ee4fa9f09692\nCloses-Bug: 1578187\n'}]",11,312183,3762ddf8259818870db5ebbfacd522ed79d0dfc4,20,7,3,17973,,,0,"[User Guides] Added pci_passthrough:alias to flavor extra specs

Change-Id: Ia0856e024053cfabafb4342335a0ee4fa9f09692
Closes-Bug: 1578187
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/83/312183/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/compute-flavors.rst'],1,e4e7860a536945427641b11aa89950959ab9e268,bug/1578187, PCI passthrough You can assign PCI devices to a guest by specifying them in the flavor. .. code:: console $ openstack flavor set FLAVOR-NAME \ --property pci_passthrough:alias=ALIAS Where: - ALIAS is an opaque string which correspond to a particular PCI device class as configured in the nova configuration file (see `nova.conf configuration options`_). .. Links .. _`nova.conf configuration options`: http://docs.openstack.org/mitaka/config-reference/compute/config-options.html,,17,0
openstack%2Fnova~master~Iba73e582d36fa16f563a8e806073a06f857e1078,openstack/nova,master,Iba73e582d36fa16f563a8e806073a06f857e1078,fix wrong key name in test code,MERGED,2016-05-03 13:07:33.000000000,2016-05-05 01:55:34.000000000,2016-05-05 01:55:33.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 18335}]","[{'number': 1, 'created': '2016-05-03 13:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/baa7e1403a056de1e19a2710e3efe62c35ee8a85', 'message': ""fix wrong key name in test code\n\ntest_default_root_device_name() in nova/tests/unit/virt/libvirt/test_driver.py,\n'detination_type' should be 'destination_type'.\n\nChange-Id: Iba73e582d36fa16f563a8e806073a06f857e1078\nCloses-Bug: #1577758\n""}, {'number': 2, 'created': '2016-05-04 09:47:20.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/91bef29e1696d9c88ff1becff1f4d25abfbac5db', 'message': ""fix wrong key name in test code\n\ntest_default_root_device_name() in\nnova/tests/unit/virt/libvirt/test_driver.py,\n'detination_type' should be 'destination_type'.\n\nChange-Id: Iba73e582d36fa16f563a8e806073a06f857e1078\nCloses-Bug: #1577758\n""}]",1,312051,91bef29e1696d9c88ff1becff1f4d25abfbac5db,23,11,2,21646,,,0,"fix wrong key name in test code

test_default_root_device_name() in
nova/tests/unit/virt/libvirt/test_driver.py,
'detination_type' should be 'destination_type'.

Change-Id: Iba73e582d36fa16f563a8e806073a06f857e1078
Closes-Bug: #1577758
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/312051/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_driver.py'],1,baa7e1403a056de1e19a2710e3efe62c35ee8a85,bug/1577758," 'destination_type': 'volume',"," 'detination_type': 'volume',",1,1
openstack%2Fironic~master~I781b785992598f89fcea897fa78853a4fb71c10c,openstack/ironic,master,I781b785992598f89fcea897fa78853a4fb71c10c,Updating dev-quickstart.rst file links,MERGED,2016-04-21 07:59:55.000000000,2016-05-05 01:52:15.000000000,2016-05-04 09:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7080}, {'_account_id': 7933}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 12459}, {'_account_id': 16237}, {'_account_id': 19072}, {'_account_id': 19896}, {'_account_id': 20311}, {'_account_id': 21242}]","[{'number': 1, 'created': '2016-04-21 07:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36c8acccf61759f99db48a194f184604969f7dd4', 'message': 'Updating links and removing unnecessary dollar symbol from doc page\n\nThis patch updates links in the dev-quickstart.rst file for\nVirtualBox page link and updates the Vagrant page link too. When\nclicking in the Vagrant page link a custom 404 page is being\ndisplayed. Together in this patch is removed an unnecessary dollar\nsymbol that is being displayed in the dev-quickstart page as well.\n\nChange-Id: I781b785992598f89fcea897fa78853a4fb71c10c\n'}, {'number': 2, 'created': '2016-05-02 14:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ca7824a45e0014831e3d6282d5076fc55017d12', 'message': 'Updating links and removing unnecessary dollar symbol from doc page\n\nThis patch updates links in the dev-quickstart.rst file for\nVirtualBox page link and updates the Vagrant page link too. When\nclicking in the Vagrant page link a custom 404 page is being\ndisplayed. Together in this patch is removed an unnecessary dollar\nsymbol that is being displayed in the dev-quickstart page as well.\n\nChange-Id: I781b785992598f89fcea897fa78853a4fb71c10c\n'}, {'number': 3, 'created': '2016-05-03 12:50:21.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0f58de97929fe2185d17949a75eb02a760d9f987', 'message': 'Updating dev-quickstart.rst file links\n\nThis patch updates most links in the dev-quickstart.rst file from http\nto https. The link for Vagrant page is also updated because when open\nit a custom 404 page was being displayed.\n\nChange-Id: I781b785992598f89fcea897fa78853a4fb71c10c\n'}]",2,308821,0f58de97929fe2185d17949a75eb02a760d9f987,48,13,3,19072,,,0,"Updating dev-quickstart.rst file links

This patch updates most links in the dev-quickstart.rst file from http
to https. The link for Vagrant page is also updated because when open
it a custom 404 page was being displayed.

Change-Id: I781b785992598f89fcea897fa78853a4fb71c10c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/308821/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,36c8acccf61759f99db48a194f184604969f7dd4,I781b785992598f89fcea897fa78853a4fb71c10c,"This option requires `virtualbox <https://www.virtualbox.org>`_, `vagrant <https://www.vagrantup.com/downloads.html>`_, and","This option requires `virtualbox <https://www.virtualbox.org//>`_, `vagrant <http://www.vagrantup.com/downloads>`_, and $",2,3
openstack%2Ffreezer-api~master~If2e579d843320b48e426d0bcee53b0ddf33fce2d,openstack/freezer-api,master,If2e579d843320b48e426d0bcee53b0ddf33fce2d,"Replace assertEqual(*, None) with assertIsNone in tests",ABANDONED,2016-01-07 07:58:50.000000000,2016-05-05 01:47:36.000000000,,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14084}, {'_account_id': 14101}]","[{'number': 1, 'created': '2016-01-07 07:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/b68b0950339b4f004a613d13f460e54af06e5331', 'message': 'Replace assertEqual(*, None) with assertIsNone in tests\n\nReplace assertEqual(*, None), assertEquals(*, None) and assertEquals(None, *)\nwith assertIsNone in tests to have more clear messages in case of failure.\n\nChange-Id: If2e579d843320b48e426d0bcee53b0ddf33fce2d\n'}, {'number': 2, 'created': '2016-01-18 10:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/1fadcdc93b7a63f654817df552311fe06204f061', 'message': 'Replace assertEqual(*, None) with assertIsNone in tests\n\nReplace assertEqual(*, None), assertEquals(*, None) and assertEquals(None, *)\nwith assertIsNone in tests to have more clear messages in case of failure.\n\nChange-Id: If2e579d843320b48e426d0bcee53b0ddf33fce2d\n'}, {'number': 3, 'created': '2016-02-29 13:43:48.000000000', 'files': ['freezer_api/tests/unit/test_elastic.py', 'freezer_api/tests/unit/test_db_init.py'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/d4af76c5b548f7d40ed0650dc17efd5d0444e83e', 'message': 'Replace assertEqual(*, None) with assertIsNone in tests\n\nReplace assertEqual(*, None), assertEquals(*, None) and assertEquals(None, *)\nwith assertIsNone in tests to have more clear messages in case of failure.\n\nChange-Id: If2e579d843320b48e426d0bcee53b0ddf33fce2d\n'}]",0,264654,d4af76c5b548f7d40ed0650dc17efd5d0444e83e,14,4,3,14084,,,0,"Replace assertEqual(*, None) with assertIsNone in tests

Replace assertEqual(*, None), assertEquals(*, None) and assertEquals(None, *)
with assertIsNone in tests to have more clear messages in case of failure.

Change-Id: If2e579d843320b48e426d0bcee53b0ddf33fce2d
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/54/264654/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_db_init.py', 'tests/test_elastic.py']",2,b68b0950339b4f004a613d13f460e54af06e5331,assertIsNone, self.assertIsNone(res) self.assertIsNone(res) self.assertIsNone(res)," self.assertEqual(res, None) self.assertEqual(res, None) self.assertEqual(res, None)",10,10
openstack%2Fdragonflow~master~I7e968109117a85ed7e72c3aebd524eed6873714b,openstack/dragonflow,master,I7e968109117a85ed7e72c3aebd524eed6873714b,Fix lock reset error when the lock is timeout,MERGED,2016-05-04 06:28:02.000000000,2016-05-05 01:41:19.000000000,2016-05-05 01:41:19.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}]","[{'number': 1, 'created': '2016-05-04 06:28:02.000000000', 'files': ['dragonflow/db/neutron/lockedobjects_db.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fe0285bfe193fad7758bf6e983ee01a1f173a57f', 'message': 'Fix lock reset error when the lock is timeout\n\nThe lock needs to update its create_time when\nit is acquired by an API session.\n\nChange-Id: I7e968109117a85ed7e72c3aebd524eed6873714b\nCloses-Bug: #1578068\n'}]",0,312330,fe0285bfe193fad7758bf6e983ee01a1f173a57f,8,3,1,7805,,,0,"Fix lock reset error when the lock is timeout

The lock needs to update its create_time when
it is acquired by an API session.

Change-Id: I7e968109117a85ed7e72c3aebd524eed6873714b
Closes-Bug: #1578068
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/30/312330/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/neutron/lockedobjects_db.py'],1,fe0285bfe193fad7758bf6e983ee01a1f173a57f,bug/1578068, # NOTE(nick-ma-z): created_at means the time when the lock is acquired. if session_id: row.created_at = func.now() ,,5,0
openstack%2Fhorizon~stable%2Fliberty~I8d2b5db9e2cb9551ac4bb47564b1f81c088d4ed3,openstack/horizon,stable/liberty,I8d2b5db9e2cb9551ac4bb47564b1f81c088d4ed3,api cinder volume_migrate wrong number of params,MERGED,2016-02-05 14:32:15.000000000,2016-05-05 01:36:27.000000000,2016-02-13 03:56:31.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 9576}, {'_account_id': 10842}, {'_account_id': 12281}]","[{'number': 1, 'created': '2016-02-05 14:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/22d0a9c77e6e4206f56ada5ac5ea6a4b050c4e09', 'message': 'api cinder volume_migrate wrong number of params\n\nWe were missing the lock_volume parameter, causing the call\nto volume_migrate to always fail.\n\nChange-Id: I8d2b5db9e2cb9551ac4bb47564b1f81c088d4ed3\nCo-Authored-By: Dmitry Galkin\nCloses-bug: #1533663\n'}, {'number': 2, 'created': '2016-02-10 09:28:44.000000000', 'files': ['openstack_dashboard/api/cinder.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9b94d9b2f9c8d36de0d815d5101fc9139c3936bc', 'message': 'api cinder volume_migrate wrong number of params\n\nWe were missing the lock_volume parameter, causing the call\nto volume_migrate to always fail.\n\nChange-Id: I8d2b5db9e2cb9551ac4bb47564b1f81c088d4ed3\nCo-Authored-By: Dmitry Galkin\nCloses-bug: #1533663\n(cherry picked from commit 6a8c054097f87fe2ae5c4ee1886b84d4e4c561fb)\n'}]",2,276758,9b94d9b2f9c8d36de0d815d5101fc9139c3936bc,23,7,2,12281,,,0,"api cinder volume_migrate wrong number of params

We were missing the lock_volume parameter, causing the call
to volume_migrate to always fail.

Change-Id: I8d2b5db9e2cb9551ac4bb47564b1f81c088d4ed3
Co-Authored-By: Dmitry Galkin
Closes-bug: #1533663
(cherry picked from commit 6a8c054097f87fe2ae5c4ee1886b84d4e4c561fb)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/276758/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/cinder.py'],1,22d0a9c77e6e4206f56ada5ac5ea6a4b050c4e09,bug/1533663,"def volume_migrate(request, volume_id, host, force_host_copy=False, lock_volume=False): force_host_copy, lock_volume)","def volume_migrate(request, volume_id, host, force_host_copy=False): force_host_copy)",4,2
openstack%2Fopenstack-ansible~stable%2Fmitaka~I15d841106ec9a13555b9737c9388f40557f5bec5,openstack/openstack-ansible,stable/mitaka,I15d841106ec9a13555b9737c9388f40557f5bec5,Integrated updates after the multi-distro changes,MERGED,2016-05-04 15:01:38.000000000,2016-05-05 01:34:52.000000000,2016-05-05 01:34:52.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-04 15:01:38.000000000', 'files': ['requirements.txt', 'playbooks/utility-install.yml', 'playbooks/repo-server.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0c46a99b381c448082bbdc4e82e2a55121b2384e', 'message': 'Integrated updates after the multi-distro changes\n\n* Corrected the repo server log directory. This change updates the repos\n  server log directory which was being incorrectly indexed. The old container\n  build process would create a service log directory based on ""properties"".\n  The ""properties"" log directory is unused or is re-defined by the various\n  service roles. This change simply corrects the log paths which the\n  `rsyslog_client` role uses to ensure all logs are shipped to the right\n  places.\n* Add a log directory creation task to the utility container. This play\n  incorrectly assumed that the log directory based on ""properties"" would\n  be automatically created. This update simply makes that more explicit.\n* paramiko has been pinned to match global requirements and use a version\n  <2. This will ressolve runtime issues in Newton with an unbound\n  requirements.\n\nCloses-Bug: #1576755\nChange-Id: I15d841106ec9a13555b9737c9388f40557f5bec5\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit e971e15997aab2c9d8d1e0cf106a67ee703a3409)\n'}]",0,312584,0c46a99b381c448082bbdc4e82e2a55121b2384e,15,3,1,7353,,,0,"Integrated updates after the multi-distro changes

* Corrected the repo server log directory. This change updates the repos
  server log directory which was being incorrectly indexed. The old container
  build process would create a service log directory based on ""properties"".
  The ""properties"" log directory is unused or is re-defined by the various
  service roles. This change simply corrects the log paths which the
  `rsyslog_client` role uses to ensure all logs are shipped to the right
  places.
* Add a log directory creation task to the utility container. This play
  incorrectly assumed that the log directory based on ""properties"" would
  be automatically created. This update simply makes that more explicit.
* paramiko has been pinned to match global requirements and use a version
  <2. This will ressolve runtime issues in Newton with an unbound
  requirements.

Closes-Bug: #1576755
Change-Id: I15d841106ec9a13555b9737c9388f40557f5bec5
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit e971e15997aab2c9d8d1e0cf106a67ee703a3409)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/84/312584/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'playbooks/utility-install.yml', 'playbooks/repo-server.yml']",3,0c46a99b381c448082bbdc4e82e2a55121b2384e,bug/1576755," rsyslog_client_log_dir: ""/var/log/{{ repo_service_user_name }}"" rsyslog_client_log_rotate_file: lsyncd_log_rotate rsyslog_client_log_dir: ""/var/log/lsyncd"" rsyslog_client_config_name: ""99-lsyncd-rsyslog-client.conf"""," rsyslog_client_log_dir: ""/var/log/nginx"" rsyslog_client_log_rotate_file: repo_log_rotate rsyslog_client_log_dir: ""/var/log/repo"" rsyslog_client_config_name: ""99-repo-rsyslog-client.conf""",13,5
openstack%2Fopenstack-manuals~master~I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde,openstack/openstack-manuals,master,I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde,Modify the 'Block Storage' Operations Guide,MERGED,2016-05-03 01:55:53.000000000,2016-05-05 01:33:51.000000000,2016-05-05 01:33:51.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-05-03 01:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8c4d8b49f3897397dec09d7064c5283614816cb0', 'message': ""Modify the 'Block Storage' Operations Guide\n\nThe 'Cinder Create' cli command output is outdated, this\npatch fix it.\n\nChange-Id: I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde\n""}, {'number': 2, 'created': '2016-05-03 14:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4a2e3f17422f8cdfb9ebd554527465e6aaed65f6', 'message': ""Modify the 'Block Storage' Operations Guide\n\nThe 'Cinder Create' cli command output is outdated, this\npatch fix it.\n\nChange-Id: I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde\n""}, {'number': 3, 'created': '2016-05-04 13:52:00.000000000', 'files': ['doc/ops-guide/source/ops_user_facing_operations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c012643e36e1d28b176f6898d49b59f2353bc9e9', 'message': ""Modify the 'Block Storage' Operations Guide\n\nThe 'Cinder Create' only need 'volume size' parameter, other parameter\nis optional, this patch fix it.\n\nChange-Id: I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde\n""}]",2,311914,c012643e36e1d28b176f6898d49b59f2353bc9e9,13,3,3,14151,,,0,"Modify the 'Block Storage' Operations Guide

The 'Cinder Create' only need 'volume size' parameter, other parameter
is optional, this patch fix it.

Change-Id: I5a180b18e0e90e5d36e6a0f729679f5afe3c1cde
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/14/311914/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops_user_facing_operations.rst'],1,8c4d8b49f3897397dec09d7064c5283614816cb0,create-volume,"To add new volumes, you need only a volume size in gigabytes. +------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+ | ID | Status | Migration Status | Name | Size | Volume Type | Bootable | Multiattach | Attached to | +------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+ | d95a...1aa | available | - | - | 10 | - | false | False | | +------------+-----------+------------------+--------+------+-------------+----------+-------------+-------------+","To add new volumes, you need only a name and a volume size in gigabytes. +------------+---------+--------------------+------+-------------+-------------+ | ID | Status | Display Name | Size | Volume Type | Attached to | +------------+---------+--------------------+------+-------------+-------------+ | 0821...19f | active | test-volume | 10 | None | | +------------+---------+--------------------+------+-------------+-------------+",6,6
openstack%2Fhorizon~master~I0085969bb8981e4ab50e4e45dbcddda19b95b6b7,openstack/horizon,master,I0085969bb8981e4ab50e4e45dbcddda19b95b6b7,Fix volumes no attribute tenant_name error,MERGED,2015-12-15 08:43:15.000000000,2016-05-05 01:09:03.000000000,2016-01-04 09:38:43.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6763}, {'_account_id': 10842}, {'_account_id': 12952}, {'_account_id': 14107}, {'_account_id': 14151}, {'_account_id': 17130}, {'_account_id': 17172}]","[{'number': 1, 'created': '2015-12-15 08:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13ef0293569825636e77caed8a15f4e278f9cb9e', 'message': ""Fix volumes no attribute tenant_name error\n\nThe attribute tenant_name doesn't exist on <Volume: {'status': u'creating',\n'description': None, 'availability_zone': u'nova', 'bootable': u'false',\n'encrypted': False, 'created_at': u'2015-11-26T04:18:50.000000',\n'os-vol-tenant-attr:tenant_id': u'6b9e19bf919e4377b92232f1bd726b77',\n'transfer': None, 'volume_type': None, 'name': u'106ff0dc-c9b5-4427-bd86-be67a8be515e',\n'attachments': [], 'os-vol-host-attr:host': None, 'source_volid': None,\n'snapshot_id': None, 'metadata': {}, 'id': u'106ff0dc-c9b5-4427-bd86-be67a8be515e',\n'size': 1}>.\n\nThis patch fix it\nCloses-Bug: #1526199\n\nChange-Id: I0085969bb8981e4ab50e4e45dbcddda19b95b6b7\n""}, {'number': 2, 'created': '2015-12-31 05:57:57.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3013b48f32eb67f5eb00ef5a55bb557da6868ea9', 'message': 'Fix volumes no attribute tenant_name error\n\nFix the volumes have no attribute tenant_name error,\nwhen the volumes are in the creating/deleting/attaching status.\n\nCloses-Bug: #1526199\n\nChange-Id: I0085969bb8981e4ab50e4e45dbcddda19b95b6b7\n'}]",3,257734,3013b48f32eb67f5eb00ef5a55bb557da6868ea9,16,10,2,14107,,,0,"Fix volumes no attribute tenant_name error

Fix the volumes have no attribute tenant_name error,
when the volumes are in the creating/deleting/attaching status.

Closes-Bug: #1526199

Change-Id: I0085969bb8981e4ab50e4e45dbcddda19b95b6b7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/257734/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/volumes/volumes/tables.py'],1,13ef0293569825636e77caed8a15f4e278f9cb9e,bug/1526199," tenant = tables.Column(lambda obj: getattr(obj, 'tenant_name', None), verbose_name=_(""Project""))"," tenant = tables.Column(""tenant_name"", verbose_name=_(""Project""))",2,1
openstack%2Fopenstack-manuals~master~I31fc763a7b80c315b86a662cf1831fbd17e19538,openstack/openstack-manuals,master,I31fc763a7b80c315b86a662cf1831fbd17e19538,[ops-guide] Cleanup arch scaling chapter,MERGED,2016-05-03 06:46:05.000000000,2016-05-05 00:58:26.000000000,2016-05-05 00:58:26.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-05-03 06:46:05.000000000', 'files': ['doc/ops-guide/source/arch_scaling.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1e8fd3239aae4a929a9ec96231dd2438ce49e1ae', 'message': '[ops-guide] Cleanup arch scaling chapter\n\nChange-Id: I31fc763a7b80c315b86a662cf1831fbd17e19538\nImplements: blueprint ops-guide-rst\n'}]",0,311935,1e8fd3239aae4a929a9ec96231dd2438ce49e1ae,13,4,1,10497,,,0,"[ops-guide] Cleanup arch scaling chapter

Change-Id: I31fc763a7b80c315b86a662cf1831fbd17e19538
Implements: blueprint ops-guide-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/311935/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/arch_scaling.rst'],1,1e8fd3239aae4a929a9ec96231dd2438ce49e1ae,bp/ops-guide-rst,"The default OpenStack flavors are shown in :ref:`table_default_flavors`. .. _table_default_flavors: .. list-table:: Table. OpenStack default flavors.. tip::.. tip::- :term:`Availability zones <availability zone>` and host aggregates, which merely divide a single Compute deployment. :ref:`table_segregation_methods` provides a comparison view of each segregation method currently provided by OpenStack Compute. .. _table_segregation_methods: .. list-table:: Table. OpenStack segregation methods^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^When adding object storage nodes, a :term:`weight` should be specified that reflects the :term:`capability` of the node.","The default OpenStack flavors are shown in the following table. .. list-table:: OpenStack default flavors.. note::.. note::- :term:`Availability zones <availability zone>` and host aggregates, which merely divide a single Compute deployment. The table below provides a comparison view of each segregation method currently provided by OpenStack Compute. .. list-table:: OpenStack segregation methods~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~When adding object storage nodes, a weight should be specified that reflects the capability of the node.",17,13
openstack%2Fmagnum~master~I5161a4c0259a2df89dfc8591453aebc6f037d40d,openstack/magnum,master,I5161a4c0259a2df89dfc8591453aebc6f037d40d,Add docker registry support for swarm,MERGED,2016-04-19 07:55:19.000000000,2016-05-05 00:57:02.000000000,2016-05-05 00:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12053}, {'_account_id': 12175}]","[{'number': 1, 'created': '2016-04-19 07:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e801456b33798f78cf2a482e9e14f0db897e0295', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}, {'number': 2, 'created': '2016-04-19 08:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4ffaa78c6b1823850733e87f21d6871f3b3ad1bb', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}, {'number': 3, 'created': '2016-04-20 08:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d4454bf639b9084b0fd419d771f4a556f4c9916f', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}, {'number': 4, 'created': '2016-04-20 09:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/547767c0165e36aebb786a27bdce3c56e5dcc520', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}, {'number': 5, 'created': '2016-04-21 06:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1af5a2581ee6c2dce5376c943dbaf0f91927d319', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}, {'number': 6, 'created': '2016-05-03 01:51:58.000000000', 'files': ['magnum/templates/swarm/fragments/configure-docker-registry.sh', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/conductor/template_definition.py', 'magnum/templates/swarm/fragments/write-heat-params-node.yaml', 'magnum/tests/unit/conductor/test_template_definition.py', 'magnum/templates/swarm/swarmnode.yaml', 'magnum/templates/swarm/fragments/enable-docker-registry.sh', 'magnum/tests/unit/conductor/handlers/test_swarm_bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7d8d090a46f2c29b7f2030f4d30ec178b53c4022', 'message': 'Add docker registry support for swarm\n\nAdd docker registry support for swarm in heat template. After this\npatch is merged, we can use docker registry in swarm bay.\n\nChange-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d\nPartially-Implements: blueprint registryv2-in-master\n'}]",11,307618,7d8d090a46f2c29b7f2030f4d30ec178b53c4022,31,5,6,12053,,,0,"Add docker registry support for swarm

Add docker registry support for swarm in heat template. After this
patch is merged, we can use docker registry in swarm bay.

Change-Id: I5161a4c0259a2df89dfc8591453aebc6f037d40d
Partially-Implements: blueprint registryv2-in-master
",git fetch https://review.opendev.org/openstack/magnum refs/changes/18/307618/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/swarm/fragments/configure-docker-registry.sh', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/conductor/template_definition.py', 'magnum/templates/swarm/fragments/write-heat-params-node.yaml', 'magnum/tests/unit/conductor/test_template_definition.py', 'magnum/templates/swarm/swarmnode.yaml', 'magnum/templates/swarm/fragments/enable-docker-registry.sh', 'magnum/tests/unit/conductor/handlers/test_swarm_bay_conductor.py']",8,e801456b33798f78cf2a482e9e14f0db897e0295,bp/registryv2-in-master," 'registry_enabled': False, 'registry_enabled': False, 'network_driver': 'network_driver', 'flannel_network_cidr': '10.101.0.0/16', 'flannel_network_subnetlen': '26', 'flannel_backend': 'vxlan', 'trustee_domain_id': '3527620c-b220-4f37-9ebc-6e63a81a9b2f', 'trustee_username': 'fake_trustee', 'trustee_password': 'fake_trustee_password', 'trustee_user_id': '7b489f04-b458-4541-8179-6a48a553e656', 'trust_id': 'bd11efc5-d4e2-4dac-bbce-25e348ddf7de', 'auth_url': 'http://192.168.10.10:5000/v3' } self.assertEqual(expected, definition) @patch('magnum.objects.BayModel.get_by_uuid') def test_extract_template_definition_with_registry( self, mock_objects_baymodel_get_by_uuid): self.baymodel_dict['registry_enabled'] = True baymodel = objects.BayModel(self.context, **self.baymodel_dict) mock_objects_baymodel_get_by_uuid.return_value = baymodel bay = objects.Bay(self.context, **self.bay_dict) cfg.CONF.set_override('swift_region', 'RegionOne', group='docker_registry') (template_path, definition) = bay_conductor._extract_template_definition(self.context, bay) expected = { 'ssh_key_name': 'keypair_id', 'external_network': 'external_network_id', 'dns_nameserver': 'dns_nameserver', 'server_image': 'image_id', 'master_flavor': 'master_flavor_id', 'node_flavor': 'flavor_id', 'number_of_masters': 1, 'number_of_nodes': 1, 'docker_volume_size': 20, 'discovery_url': 'https://discovery.test.io/123456789', 'http_proxy': 'http_proxy', 'https_proxy': 'https_proxy', 'no_proxy': 'no_proxy', 'bay_uuid': '5d12f6fd-a196-4bf0-ae4c-1f639a523a52', 'magnum_url': self.mock_osc.magnum_url.return_value, 'tls_disabled': False, 'registry_enabled': True, 'registry_container': 'docker_registry', 'swift_region': 'RegionOne', 'registry_enabled': False,",,147,1
openstack%2Ftripleo-quickstart~master~Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33,openstack/tripleo-quickstart,master,Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33,lots and lots of comments (2/2),MERGED,2016-04-29 02:49:54.000000000,2016-05-05 00:53:52.000000000,2016-05-05 00:53:52.000000000,"[{'_account_id': 3}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-04-29 02:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1fbd6cf8f4d9982b91f3108c289a5b30916ea9d8', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 2, 'created': '2016-04-29 12:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7701b45961d80a3dadf645822e3e5f3a4f32d164', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 3, 'created': '2016-04-29 14:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/592f6142cb1b8a785f3ff968f9292c99ffbf3371', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 4, 'created': '2016-04-29 16:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/89d881b5883b5cbd1c0162ae101e922b95640a64', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 5, 'created': '2016-05-02 14:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/03d7c1a66b184af15d28eac3b5766174016dd493', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 6, 'created': '2016-05-04 19:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6a35e82faa64e65c5dabe28d7ac1a4f8291a243a', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}, {'number': 7, 'created': '2016-05-04 20:16:04.000000000', 'files': ['playbooks/roles/tripleo/overcloud/tasks/create-scripts.yml', 'playbooks/roles/provision/teardown/tasks/main.yml', 'playbooks/roles/tripleo/overcloud/templates/configure-tempest.sh.j2', 'playbooks/roles/tripleo/undercloud/tasks/create-scripts.yml', 'playbooks/roles/tripleo/undercloud/tasks/post-install.yml', 'playbooks/roles/provision/defaults/main.yml', 'playbooks/roles/tripleo/overcloud/templates/run-tempest.sh.j2', 'playbooks/roles/libvirt/setup/undercloud/scripts/get-undercloud-ip.sh', 'playbooks/roles/tripleo/overcloud/templates/overcloud-deploy-post.sh.j2', 'playbooks/roles/rebuild-inventory/tasks/main.yml', 'playbooks/roles/tripleo/undercloud/templates/undercloud-install-post.sh.j2', 'playbooks/roles/tripleo/overcloud/defaults/main.yml', 'playbooks/roles/tripleo/overcloud/tasks/post-deploy.yml', 'playbooks/roles/tripleo/overcloud/templates/tripleo-pingtest.sh.j2', 'playbooks/roles/tripleo/overcloud/templates/overcloud-deploy.sh.j2', 'playbooks/roles/parts/libvirt/tasks/main.yml', 'playbooks/roles/provision/local/tasks/main.yml', 'playbooks/roles/parts/libvirt/defaults/main.yml', 'playbooks/roles/tripleo/overcloud/tasks/updatessh.yml', 'playbooks/roles/libvirt/setup/undercloud/tasks/fetch_image.yml', 'playbooks/roles/provision/remote/tasks/main.yml', 'playbooks/roles/tripleo/undercloud/templates/undercloud-install.sh.j2', 'playbooks/roles/tripleo/overcloud/templates/overcloud-validate.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5c6763353112466a940edf2a43c0f3df521de75d', 'message': 'lots and lots of comments (2/2)\n\nthis is the second in a series of patches to provide better\ndocumentation throughout the project.\n\nChange-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33\n'}]",0,310981,5c6763353112466a940edf2a43c0f3df521de75d,29,4,7,8745,,,0,"lots and lots of comments (2/2)

this is the second in a series of patches to provide better
documentation throughout the project.

Change-Id: Ieb2ef828636fe7d7f7e0edd9e15b0ec96e24eb33
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/81/310981/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/tripleo/overcloud/tasks/create-scripts.yml', 'playbooks/roles/provision/teardown/tasks/main.yml', 'playbooks/roles/tripleo/undercloud/tasks/create-scripts.yml', 'playbooks/roles/tripleo/undercloud/tasks/post-install.yml', 'playbooks/roles/provision/defaults/main.yml', 'playbooks/roles/rebuild-inventory/tasks/main.yml', 'playbooks/roles/tripleo/overcloud/tasks/post-deploy.yml', 'playbooks/roles/parts/libvirt/tasks/main.yml', 'playbooks/roles/provision/local/tasks/main.yml', 'playbooks/roles/parts/libvirt/defaults/main.yml', 'playbooks/roles/tripleo/overcloud/tasks/updatessh.yml', 'playbooks/roles/provision/remote/tasks/main.yml']",12,1fbd6cf8f4d9982b91f3108c289a5b30916ea9d8,lots-o-docs,"# Create `virt_host_key`, which we will use to log in to the target # host. Note that this tasks runs on the ansible control host # (because of the `delegate_to: localhost`), and we will later copy # the public key to the appropriate location.# Create a non-root user on the target host. This is the user that # will own the virtual infrastructure on which we deploy openstack.# Install the public component of `virt_host_key` in the # `.ssh/authorized_keys` file for the non-root user.# This lets the non-root user access the `qemu://system` endpoint. We # don't need this with the default configuration (which uses # `qemu://session`), but this permits things to work if someone # explicitly passes in `libvirt_uri`.# This is a workaround for [this issue][xdg]. # # [xdg]: https://www.redhat.com/archives/libvirt-users/2016-March/msg00056.html# I'm not always root, but when I am it's because of `sudo`.# This replaces the inventory entry for the virthost. The original # entry had `ansible_user: root`, but from now on we will connect as # the non-root user.",,66,4
openstack%2Ftripleo-quickstart~master~Id3d7409521013af5b11c5f9df328630b1a3845f5,openstack/tripleo-quickstart,master,Id3d7409521013af5b11c5f9df328630b1a3845f5,lots and lots of comments (1/2),MERGED,2016-04-29 02:49:54.000000000,2016-05-05 00:53:46.000000000,2016-05-05 00:53:46.000000000,"[{'_account_id': 3}, {'_account_id': 12715}, {'_account_id': 18846}]","[{'number': 1, 'created': '2016-04-29 02:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e53b27a7bf3b0627837bb37e30950d5794d037e8', 'message': 'lots and lots of comments (1/2)\n\nthe first of a series of patches that adds comments to virtually all\nof our roles.\n\nChange-Id: Id3d7409521013af5b11c5f9df328630b1a3845f5\n'}, {'number': 2, 'created': '2016-05-02 14:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d36d225578203e76195b2398bbd2f8fa8c4d1f29', 'message': 'lots and lots of comments (1/2)\n\nthe first of a series of patches that adds comments to virtually all\nof our roles.\n\nChange-Id: Id3d7409521013af5b11c5f9df328630b1a3845f5\n'}, {'number': 3, 'created': '2016-05-04 19:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4e2b3fe9deadb82e6ac56722ae1a466aa3c5b0f0', 'message': 'lots and lots of comments (1/2)\n\nthe first of a series of patches that adds comments to virtually all\nof our roles.\n\nChange-Id: Id3d7409521013af5b11c5f9df328630b1a3845f5\n'}, {'number': 4, 'created': '2016-05-04 20:15:51.000000000', 'files': ['playbooks/roles/environment/setup/meta/main.yml', 'playbooks/roles/environment/teardown/tasks/main.yml', 'playbooks/roles/common/defaults/main.yml', 'playbooks/roles/libvirt/teardown/user/tasks/main.yml', 'playbooks/roles/environment/meta/main.yml', 'playbooks/roles/libvirt/teardown/meta/main.yml', 'playbooks/roles/libvirt/defaults/main.yml', 'playbooks/roles/libvirt/meta/main.yml', 'playbooks/centosci/minimal.yml', 'playbooks/centosci/minimal_no_netiso.yml', 'playbooks/roles/libvirt/setup/meta/main.yml', 'playbooks/roles/libvirt/setup/undercloud/tasks/main.yml', 'playbooks/roles/parts/kvm/tasks/main.yml', 'playbooks/roles/libvirt/teardown/nodes/tasks/main.yml', 'playbooks/centosci/ha.yml', 'playbooks/roles/environment/setup/tasks/main.yml', 'playbooks/roles/libvirt/setup/overcloud/tasks/main.yml', 'playbooks/roles/libvirt/setup/undercloud/tasks/fetch_image.yml', 'playbooks/quickstart.yml', 'playbooks/provision.yml', 'playbooks/roles/libvirt/setup/user/tasks/main.yml', 'playbooks/roles/libvirt/setup/overcloud/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1bc289f3e3839e63bccdba95e7365270588fd630', 'message': 'lots and lots of comments (1/2)\n\nthe first of a series of patches that adds comments to virtually all\nof our roles.\n\nChange-Id: Id3d7409521013af5b11c5f9df328630b1a3845f5\n'}]",0,310980,1bc289f3e3839e63bccdba95e7365270588fd630,30,3,4,8745,,,0,"lots and lots of comments (1/2)

the first of a series of patches that adds comments to virtually all
of our roles.

Change-Id: Id3d7409521013af5b11c5f9df328630b1a3845f5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/80/310980/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/environment/setup/meta/main.yml', 'playbooks/roles/environment/teardown/tasks/main.yml', 'playbooks/roles/common/defaults/main.yml', 'playbooks/roles/libvirt/teardown/user/tasks/main.yml', 'playbooks/roles/environment/meta/main.yml', 'playbooks/roles/libvirt/teardown/meta/main.yml', 'playbooks/roles/libvirt/defaults/main.yml', 'playbooks/roles/libvirt/meta/main.yml', 'playbooks/centosci/minimal.yml', 'playbooks/centosci/minimal_no_netiso.yml', 'playbooks/roles/libvirt/setup/meta/main.yml', 'playbooks/roles/libvirt/setup/undercloud/tasks/main.yml', 'playbooks/roles/parts/kvm/tasks/main.yml', 'playbooks/roles/libvirt/teardown/nodes/tasks/main.yml', 'playbooks/centosci/ha.yml', 'playbooks/roles/environment/setup/tasks/main.yml', 'playbooks/roles/libvirt/setup/overcloud/tasks/main.yml', 'playbooks/roles/libvirt/setup/undercloud/tasks/fetch_image.yml', 'playbooks/quickstart.yml', 'playbooks/provision.yml', 'playbooks/roles/libvirt/setup/user/tasks/main.yml', 'playbooks/roles/libvirt/setup/overcloud/meta/main.yml']",22,e53b27a7bf3b0627837bb37e30950d5794d037e8,lots-o-docs,# Include the `common` role as a dependency. This makes sure the # variables defined in that role are available here.,,211,20
openstack%2Ftripleo-quickstart~master~I98ed41013ad4a72f43b74ff95fd04a42a845d636,openstack/tripleo-quickstart,master,I98ed41013ad4a72f43b74ff95fd04a42a845d636,use yaml blocks for really long strings,MERGED,2016-04-29 02:49:54.000000000,2016-05-05 00:53:39.000000000,2016-05-05 00:53:39.000000000,"[{'_account_id': 3}, {'_account_id': 8745}, {'_account_id': 12715}, {'_account_id': 18846}]","[{'number': 1, 'created': '2016-04-29 02:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4c31d18844eb4c602da723630eb129b068bb807c', 'message': 'use yaml blocks for really long strings\n\nthis commit modifies the `extra_args` definitions in a couple of\nvariable files to use YAML blocks, rather than a really long quoted\nstring.  This makes the files display better in a number of situations\n(nobody likes massic horizontal scrolls), and it makes the arguments a\nlittle more obvious.\n\nChange-Id: I98ed41013ad4a72f43b74ff95fd04a42a845d636\n'}, {'number': 2, 'created': '2016-05-02 14:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1551c01e385d8643f21e6d836ce32d80daa14cd9', 'message': 'use yaml blocks for really long strings\n\nthis commit modifies the `extra_args` definitions in a couple of\nvariable files to use YAML blocks, rather than a really long quoted\nstring.  This makes the files display better in a number of situations\n(nobody likes massic horizontal scrolls), and it makes the arguments a\nlittle more obvious.\n\nChange-Id: I98ed41013ad4a72f43b74ff95fd04a42a845d636\n'}, {'number': 3, 'created': '2016-05-04 19:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ac245b9748d5fbcb4a919329d21298e9bcadcc9b', 'message': 'use yaml blocks for really long strings\n\nthis commit modifies the `extra_args` definitions in a couple of\nvariable files to use YAML blocks, rather than a really long quoted\nstring.  This makes the files display better in a number of situations\n(nobody likes massic horizontal scrolls), and it makes the arguments a\nlittle more obvious.\n\nChange-Id: I98ed41013ad4a72f43b74ff95fd04a42a845d636\n'}, {'number': 4, 'created': '2016-05-04 20:14:33.000000000', 'files': ['playbooks/centosci/minimal.yml', 'playbooks/centosci/ha.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f85e5d456d537d330f1dc20161500a3744e99383', 'message': 'use yaml blocks for really long strings\n\nthis commit modifies the `extra_args` definitions in a couple of\nvariable files to use YAML blocks, rather than a really long quoted\nstring.  This makes the files display better in a number of situations\n(nobody likes massic horizontal scrolls), and it makes the arguments a\nlittle more obvious.\n\nChange-Id: I98ed41013ad4a72f43b74ff95fd04a42a845d636\n'}]",2,310979,f85e5d456d537d330f1dc20161500a3744e99383,32,4,4,8745,,,0,"use yaml blocks for really long strings

this commit modifies the `extra_args` definitions in a couple of
variable files to use YAML blocks, rather than a really long quoted
string.  This makes the files display better in a number of situations
(nobody likes massic horizontal scrolls), and it makes the arguments a
little more obvious.

Change-Id: I98ed41013ad4a72f43b74ff95fd04a42a845d636
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/79/310979/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/centosci/minimal.yml', 'playbooks/centosci/ha.yml']",2,4c31d18844eb4c602da723630eb129b068bb807c,lots-o-docs,"# Tell tripleo about our environment. extra_args: > --control-scale 3 --neutron-network-type vxlan --neutron-tunnel-types vxlan -e /usr/share/openstack-tripleo-heat-templates/environments/network-isolation.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/net-single-nic-with-vlans.yaml -e ~/network-environment.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/puppet-pacemaker.yaml --ntp-server pool.ntp.org""","extra_args: ""--control-scale 3 --neutron-network-type vxlan --neutron-tunnel-types vxlan -e /usr/share/openstack-tripleo-heat-templates/environments/network-isolation.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/net-single-nic-with-vlans.yaml -e ~/network-environment.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/puppet-pacemaker.yaml --ntp-server pool.ntp.org""",17,2
openstack%2Fnova-specs~master~I0eba6f6f74d3447765d9c90a3cc8068b9f7a3c4b,openstack/nova-specs,master,I0eba6f6f74d3447765d9c90a3cc8068b9f7a3c4b,Remove the object of policy enforcement,ABANDONED,2016-04-13 07:54:18.000000000,2016-05-05 00:51:39.000000000,,"[{'_account_id': 3}, {'_account_id': 5441}, {'_account_id': 5754}]","[{'number': 1, 'created': '2016-04-13 07:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1ed5e62e7296b09f729f79fcda2a08b0b2b81c6e', 'message': 'Remove the object of policy enforcement\n\nThis is problem related to how we model the policy discovery API. So\nseparated that problem out, and describe and discuss it separatly.\n\nRelated to BP remove-the-object-of-policy-enforcement\n\nChange-Id: I0eba6f6f74d3447765d9c90a3cc8068b9f7a3c4b\n'}, {'number': 2, 'created': '2016-04-15 08:03:14.000000000', 'files': ['specs/newton/approved/remove-the-object-of-policy-enforcement.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4a403372de20b541a54af0f1303561f9953856cb', 'message': 'Remove the object of policy enforcement\n\nThis is problem related to how we model the policy discovery API. So\nseparated that problem out, and describe and discuss it separatly.\n\nRelated to BP remove-the-object-of-policy-enforcement\n\nChange-Id: I0eba6f6f74d3447765d9c90a3cc8068b9f7a3c4b\n'}]",0,305026,4a403372de20b541a54af0f1303561f9953856cb,6,3,2,5754,,,0,"Remove the object of policy enforcement

This is problem related to how we model the policy discovery API. So
separated that problem out, and describe and discuss it separatly.

Related to BP remove-the-object-of-policy-enforcement

Change-Id: I0eba6f6f74d3447765d9c90a3cc8068b9f7a3c4b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/26/305026/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/approved/remove-the-object-of-policy-enforcement.rst'],1,1ed5e62e7296b09f729f79fcda2a08b0b2b81c6e,bp/remove-the-object-of-policy-enforcement,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================= Remove the object of policy enforcement ======================================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/remove-the-object-of-policy-enforcement Currently some of APIs policy enforce with object, some of APIs are not. There isn't a decision for this before, this due to we didn't have clear use-case for this. For now, we want to enable policy discoverable feature, the policy discovery API depends the authorization is per-resource or just role based. This spec propose to remove the object when enforce the policy. Problem description =================== Some of APIs policy enforce with object, some of APIs are not. For example, the policy enforcement of server's start/stop action as below: :: instance = self._get_instance(context, id) authorize(context, instance, 'start') But for the server's pause/unpause action: :: authorize(ctxt, action='pause') For start/stop actions, the policy enforce with server object. But for pause/unpause actions are not. For the pause/unpause, the enforcement object is a fake object with two attributes 'project_id' and 'user_id' which get from the request context directly. That means whatever the requested server belong to who, the policy rule always passed with project owner rule. And this lead to a mess about the policy discovery API. If we build policy API at only one endpoint '/policy', but actually for the start/stop action, it is per-resource policy capability, the api endpoint should be '/servers/{id}/policy'. Use Cases --------- This spec didn't propose to add new use-case, it proposes to remove some use-less use-cases. The use-cases which can be when we enforce policy with object as below: * Non-Admin user access other project resources. As the db layer always filter based on tenant_id for non-admin user, this actually doesn't work for now. Even we enable db layer return all projects' resources, that will be a huge performance problem. And this isn't clear use-case. * Admin can't access normal user resource. Actually admin is a super-user, whether admin want to see user's resource based admin wish. * User-owner enforcement. Based on project-owner, the policy also can enforce user-owner with rule like ""user_id:%(user_id)s"". Also not sure whether have user need such requirement in the real world. * Policy enforcement based on the object's attributes. There is only one case `https://github.com/openstack/nova/blob/stable/mitaka/nova/api/openstack/compute/servers.py#L565` But actually it still pass a fake object. Proposed change =============== This spec proposes to reduce the flexiable for the policy enforcement by removing the object of policy enforcement. But still pass a fake object to oslo.policy enforce method which includes the request context's project id and user id, this is for avoid break the existed policy config file. The fake object will be removed in next release. The admin user will be the only user have super power to access all projects resource. For non-admin user, the project-owner checks will be build-in behaviour. This will effect the keypairs API, as in microversion 2.10, the keypairs API enable user-id parameter. And whether user can access other user's keypair can be controlled by policy rule. After remove the object, the rule won't works anymore. We will add new policy rule for user-id parameter: :: ""os_compute_api:os-keypairs:index:user_id"": ""rule:admin_api"" ""os_compute_api:os-keypairs:show:user_id"": ""rule:admin_api"" ""os_compute_api:os-keypairs:create:user_id"": ""rule:admin_api"" ""os_compute_api:os-keypairs:delete:user_id"": ""rule:admin_api"" We will remove the 'admin_or_owner' rule, instead of just use '@', as the project owner is nova build-in behaviour. Alternatives ------------ Pass the object when policy enforcement, this is hard to implement this due to the way we filter resources. And there isn't clear use-case for this. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- * A few new policy rules was added to the keypairs API, user need update their policy.conf. * Some of APIs aren't enforce with object anymore, so if the rule based on object's attribute value won't work anymore. Developer impact ---------------- We needn't pass the object anymore. Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu <hejie.xu@intel.com> Work Items ---------- * add new rule for keypairs API * remove the target parameter from the policy enforcement method. Dependencies ============ * Depend on propose 'Embed policy defaults in code' https://review.openstack.org/290155 will make user easy when upgrade. Testing ======= Adjust existed unittest work with modification. Documentation Impact ==================== Some notes help user understand what happened for the policy enforcment. References ========== None History ======= .. list-table:: Revisions :header-rows: 1 * - Newton - Introduced ",,184,0
openstack%2Fsearchlight-ui~master~I46b36e4dfadc262fbd129ed287bde6f8a84f1f77,openstack/searchlight-ui,master,I46b36e4dfadc262fbd129ed287bde6f8a84f1f77,Add version compatibility matrix to Readme,MERGED,2016-04-21 23:05:15.000000000,2016-05-05 00:47:33.000000000,2016-05-05 00:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 10063}]","[{'number': 1, 'created': '2016-04-21 23:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/7a775c3c91ec7f96e08fc4f603f167bcdc8cdef0', 'message': ""Reformat HTML after Move search bar\n\nBased on upstream's move of the search bar out of the table, this patch\nfollows suit.\n\nThe parent patch actually did the work. This reformats\nthe HTML for patch readability purposes.\n\nChange-Id: I46b36e4dfadc262fbd129ed287bde6f8a84f1f77\nPartial-Bug: 1558772\n""}, {'number': 2, 'created': '2016-04-22 14:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/0c3dc6e0e9157eb2d8790fc860511df9462daad5', 'message': ""Add version compatibility matrix to Readme\n\nBased on upstream's move of the search bar out of the table,\nthere is now a version dependency with horizon upstream.\nThis adds a readme to the repo for quick reference.\n\nChange-Id: I46b36e4dfadc262fbd129ed287bde6f8a84f1f77\nPartial-Bug: 1558772\n""}, {'number': 3, 'created': '2016-04-26 21:37:50.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/0c268301e910ae6cfc279d0ca104e93390df49ba', 'message': ""Add version compatibility matrix to Readme\n\nBased on upstream's move of the search bar out of the table,\nthere is now a version dependency with horizon upstream.\nThis adds a readme to the repo for quick reference.\n\nChange-Id: I46b36e4dfadc262fbd129ed287bde6f8a84f1f77\nPartial-Bug: 1558772\n""}]",0,309212,0c268301e910ae6cfc279d0ca104e93390df49ba,32,5,3,7665,,,0,"Add version compatibility matrix to Readme

Based on upstream's move of the search bar out of the table,
there is now a version dependency with horizon upstream.
This adds a readme to the repo for quick reference.

Change-Id: I46b36e4dfadc262fbd129ed287bde6f8a84f1f77
Partial-Bug: 1558772
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/12/309212/2 && git format-patch -1 --stdout FETCH_HEAD,['searchlight_ui/static/dashboard/project/search/table/search-table.html'],1,7a775c3c91ec7f96e08fc4f603f167bcdc8cdef0,sl-fix," <hz-magic-search-context ng-controller=""searchTableController as table"" client-full-text-search=""false"" search-settings-callback=""table.searchSettings.open"" filter-facets=""table.searchFacets""> <hz-magic-search-bar> </hz-magic-search-bar> <!-- div class=""col-md-2""> <a href="""" ng-click=""table.refresh()"" tooltip=""{$ 'Refresh results' | translate $}"" tooltip-placement=""top"" tooltip-trigger=""mouseenter"" class=""btn btn-default""> <span class=""fa fa-refresh""></span> </a> </div --> <table hz-table ng-cloak st-magic-search st-table=""table.hits"" st-safe-src=""table.hitsSrc"" class=""table table-striped table-hover table-rsp table-detail""> <thead> <tr> <!-- Please note, search result sorting should not be done client side. Searchlight will provide the proper default sorting based on search result scoring. --> <th class=""expander""></th> <th class=""rsp-p1"" translate>Type</th> <th ng-if=""table.searchSettings.settings.general.all_projects"" class=""rsp-p1"" translate> Project </th> <th class=""rsp-p1"" translate>Name</th> <th class=""rsp-p2"" translate>Status</th> <th class=""rsp-p2"" translate>Visibility</th> <th class=""rsp-p2"" translate>Updated</th> <th class=""rsp-p2"" translate>Field Matches</th> <!-- th class=""rsp-p3"" translate>Description</th --> <th class=""actions_column"" translate>Actions</th> </tr> </thead> <tbody> <tr ng-if='table.queryResponse.error'> <td colspan=""8"" translate> {$ table.queryResponse.statusCode | queryStatus $} </td> </tr> <tr ng-if='!table.queryError' ng-repeat-start=""hit in table.hits track by hit._id""> <td class=""expander""> <i class=""fa fa-chevron-right"" hz-expand-detail duration=""200""> </i> </td> <!-- TODO Truncate not working because not in fixed container --> <!-- TODO ng-cloak not working --> <!-- TODO consider adding spinner when search is happening... --> <td class=""rsp-p1 truncate"">{$ hit._type | resourceLabeler $}</td> <td ng-if=""table.searchSettings.settings.general.all_projects"" class=""rsp-p1""> <span tooltip=""{$ hit._source.project_id $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._source.project_id | keystoneProjectName | noValue$} </span> </td> <td ng-cloak class=""rsp-p1""> <a ng-href=""{$ hit | resourceUrl $}""> <hz-search-highlighter hit=""hit"" field=""'name'"" default-value=""hit._source.name || hit._source.id | noValue""> </hz-search-highlighter> </a> </td> <td class=""rsp-p2"">{$ hit._source.status | commonStatus | noValue $} </td> <td class=""rsp-p2""> <span tooltip=""{$ 'Visibility is based on derived data. If Owned by Me, please inspect the resource to determine sharing status.' | translate $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._type | commonVisibility: hit._source:table.userSession.project_id | noValue $} </span> </td> <td class=""rsp-p2"">{$ hit._source.updated_at | date:'short' | noValue $} </td> <td class=""rsp-p2""> <ul class=""list-unstyled"" ng-repeat=""(field, value) in hit.highlight""> <li ng-if=""!field.endsWith('.raw')""> {$ hit._type | resourceLabeler: field $} </li> </ul> </td> <!-- td class=""rsp-p3 truncate""> <hz-search-highlighter hit=""hit"" field=""'description'"" default-value=""hit._source.description | noValue""> </hz-search-highlighter> </td --> <td class=""actions_column""> <actions allowed=""table.registry.getResourceType(hit._type).itemActions"" type=""row"" item=""hit._source"" result-handler=""table.actionResultHandler""> </actions> </td> </tr> <tr ng-repeat-end class=""detail-row""> <!-- Detail-row: Contains detailed information on this item. Can be toggled using the chevron button. Ensure colspan is greater or equal to number of column-headers. --> <td class=""detail"" colspan=""100""> <div class=""row""> <dl class=""dl-horizontal""> <div ng-repeat=""(field, value) in hit._source""> <div ng-if=""['_type'].indexOf(field) === -1""> <dt> <span tooltip=""{$ field $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._type | resourceLabeler: field $} </span> </dt> <dd> <hz-search-highlighter hit=""hit"" field=""field"" default-value=""value | noValue""> </hz-search-highlighter> </dd> </div> </div> </dl> </td> </tr> </tbody> <tfoot hz-table-footer items=""table.hits""></tfoot> </table> </hz-magic-search-context>"," <hz-magic-search-context ng-controller=""searchTableController as table"" client-full-text-search=""false"" search-settings-callback=""table.searchSettings.open"" filter-facets=""table.searchFacets""> <hz-magic-search-bar> </hz-magic-search-bar> <table hz-table ng-cloak st-magic-search st-table=""table.hits"" st-safe-src=""table.hitsSrc"" class=""table table-striped table-hover table-rsp table-detail""> <thead> <tr> <th colspan=""100"" class=""search-header""> </th> <!-- th colspan=""1"" class=""table_caption""> <a href="""" ng-click=""table.refresh()"" tooltip=""{$ 'Refresh results' | translate $}"" tooltip-placement=""top"" tooltip-trigger=""mouseenter"" class=""btn btn-default""> <span class=""fa fa-refresh""></span> </a> <th --> </tr> <tr> <!-- Please note, search result sorting should not be done client side. Searchlight will provide the proper default sorting based on search result scoring. --> <th class=""expander""></th> <th class=""rsp-p1"" translate>Type</th> <th ng-if=""table.searchSettings.settings.general.all_projects"" class=""rsp-p1"" translate> Project </th> <th class=""rsp-p1"" translate>Name</th> <th class=""rsp-p2"" translate>Status</th> <th class=""rsp-p2"" translate>Visibility</th> <th class=""rsp-p2"" translate>Updated</th> <th class=""rsp-p2"" translate>Field Matches</th> <!-- th class=""rsp-p3"" translate>Description</th --> <th class=""actions_column"" translate>Actions</th> </tr> </thead> <tbody> <tr ng-if='table.queryResponse.error'> <td colspan=""8"" translate> {$ table.queryResponse.statusCode | queryStatus $} </td> </tr> <tr ng-if='!table.queryError' ng-repeat-start=""hit in table.hits track by hit._id""> <td class=""expander""> <i class=""fa fa-chevron-right"" hz-expand-detail duration=""200""> </i> </td> <!-- TODO Truncate not working because not in fixed container --> <!-- TODO ng-cloak not working --> <!-- TODO consider adding spinner when search is happening... --> <td class=""rsp-p1 truncate"">{$ hit._type | resourceLabeler $}</td> <td ng-if=""table.searchSettings.settings.general.all_projects"" class=""rsp-p1""> <span tooltip=""{$ hit._source.project_id $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._source.project_id | keystoneProjectName | noValue$} </span> </td> <td ng-cloak class=""rsp-p1""> <a ng-href=""{$ hit | resourceUrl $}""> <hz-search-highlighter hit=""hit"" field=""'name'"" default-value=""hit._source.name || hit._source.id | noValue""> </hz-search-highlighter> </a> </td> <td class=""rsp-p2"">{$ hit._source.status | commonStatus | noValue $}</td> <td class=""rsp-p2""> <span tooltip=""{$ 'Visibility is based on derived data. If Owned by Me, please inspect the resource to determine sharing status.' | translate $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._type | commonVisibility: hit._source:table.userSession.project_id | noValue $} </span> </td> <td class=""rsp-p2"">{$ hit._source.updated_at | date:'short' | noValue $}</td> <td class=""rsp-p2""> <ul class=""list-unstyled"" ng-repeat=""(field, value) in hit.highlight""> <li ng-if=""!field.endsWith('.raw')""> {$ hit._type | resourceLabeler: field $} </li> </ul> </td> <!-- td class=""rsp-p3 truncate""> <hz-search-highlighter hit=""hit"" field=""'description'"" default-value=""hit._source.description | noValue""> </hz-search-highlighter> </td --> <td class=""actions_column""> <actions allowed=""table.registry.getResourceType(hit._type).itemActions"" type=""row"" item=""hit._source"" result-handler=""table.actionResultHandler""> </actions> </td> </tr> <tr ng-repeat-end class=""detail-row""> <!-- Detail-row: Contains detailed information on this item. Can be toggled using the chevron button. Ensure colspan is greater or equal to number of column-headers. --> <td class=""detail"" colspan=""100""> <div class=""row""> <dl class=""dl-horizontal""> <div ng-repeat=""(field, value) in hit._source""> <div ng-if=""['_type'].indexOf(field) === -1""> <dt> <span tooltip=""{$ field $}"" tooltip-placement=""top"" tooltip-popup-delay=""500"" tooltip-trigger=""mouseenter""> {$ hit._type | resourceLabeler: field $} </span> </dt> <dd> <hz-search-highlighter hit=""hit"" field=""field"" default-value=""value | noValue""> </hz-search-highlighter> </dd> </div> </dl> </div> </td> </tr> </tbody> <tfoot hz-table-footer items=""table.hits""></tfoot> </table> </hz-magic-search-context>",147,148
openstack%2Fneutron~stable%2Fliberty~I9801b76829021c9a0e6358982e1136637634a521,openstack/neutron,stable/liberty,I9801b76829021c9a0e6358982e1136637634a521,Cleanup stale OVS flows for physical bridges,MERGED,2016-04-01 11:22:07.000000000,2016-05-05 00:45:55.000000000,2016-05-05 00:45:54.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 10540}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 14611}, {'_account_id': 17505}, {'_account_id': 19797}]","[{'number': 1, 'created': '2016-04-01 11:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b445235d8460645283d44890b9b7e0ae2a9aba57', 'message': 'Cleanup stale OVS flows for physical bridges\n\nPerform deletion of the stale flows in physical bridges consistently with\nbr-int and br-tun, respecting drop_flows_on_start configuration option.\nAdded tests for auxiliary bridge and functional tests for the physical\nbridge using VLAN/flat external network. Fixes part of the bug 1514056;\ntogether with [1] and [2], the bug should be considered fixed.\n\nThe commit also fixes inconsistency between netmask of allocated IP\naddresses assigned in _create_test_port_dict and ip_len in _plug_ports\nof base.py.\n\n[1] https://review.openstack.org/#/c/297211/\n[2] https://review.openstack.org/#/c/297818/\n\nConflicts:\n\tneutron/tests/functional/agent/l2/base.py\n\tneutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py\n\nCo-Authored-By: Jian Wen <wenjianhn@gmail.com>\nPartial-Bug: 1514056\nChange-Id: I9801b76829021c9a0e6358982e1136637634a521\n(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)\n'}, {'number': 2, 'created': '2016-04-01 12:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29676324584485e07f8a458d28be6ed28151c025', 'message': ""Cleanup stale OVS flows for physical bridges\n\nPerform deletion of the stale flows in physical bridges consistently with\nbr-int and br-tun, respecting drop_flows_on_start configuration option.\nAdded tests for auxiliary bridge and functional tests for the physical\nbridge using VLAN/flat external network. Fixes part of the bug 1514056;\ntogether with [1] and [2], the bug should be considered fixed.\n\nThe commit also fixes inconsistency between netmask of allocated IP\naddresses assigned in _create_test_port_dict and ip_len in _plug_ports\nof base.py.\n\n[1] https://review.openstack.org/#/c/297211/\n[2] https://review.openstack.org/#/c/297818/\n\nConflicts:\n\tneutron/tests/functional/agent/l2/base.py\n\tneutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py\n\nCo-Authored-By: Jian Wen <wenjianhn@gmail.com>\nCo-Authored-By: Clayton O'Neill <clayton@oneill.net>\nPartial-Bug: 1514056\nChange-Id: I9801b76829021c9a0e6358982e1136637634a521\n(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)\n""}, {'number': 3, 'created': '2016-04-01 18:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0a538049563a326c56ec54f22aba4369fea23b3', 'message': ""Cleanup stale OVS flows for physical bridges\n\nPerform deletion of the stale flows in physical bridges consistently with\nbr-int and br-tun, respecting drop_flows_on_start configuration option.\nAdded tests for auxiliary bridge and functional tests for the physical\nbridge using VLAN/flat external network. Fixes part of the bug 1514056;\ntogether with [1] and [2], the bug should be considered fixed.\n\nThe commit also fixes inconsistency between netmask of allocated IP\naddresses assigned in _create_test_port_dict and ip_len in _plug_ports\nof base.py.\n\n[1] https://review.openstack.org/#/c/297211/\n[2] https://review.openstack.org/#/c/297818/\n\nConflicts:\n\tneutron/tests/functional/agent/l2/base.py\n\tneutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py\n\nCo-Authored-By: Jian Wen <wenjianhn@gmail.com>\nCo-Authored-By: Clayton O'Neill <clayton@oneill.net>\nPartial-Bug: 1514056\nChange-Id: I9801b76829021c9a0e6358982e1136637634a521\n(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)\n""}, {'number': 4, 'created': '2016-04-04 06:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef1376bba74025b6543c005d746e07e15caaa5d6', 'message': ""Cleanup stale OVS flows for physical bridges\n\nPerform deletion of the stale flows in physical bridges consistently with\nbr-int and br-tun, respecting drop_flows_on_start configuration option.\nAdded tests for auxiliary bridge and functional tests for the physical\nbridge using VLAN/flat external network. Fixes part of the bug 1514056;\ntogether with [1] and [2], the bug should be considered fixed.\n\nThe commit also fixes inconsistency between netmask of allocated IP\naddresses assigned in _create_test_port_dict and ip_len in _plug_ports\nof base.py.\n\nFurther, this commit sets agent UUID to physical bridges similarly to\ntun and int bridges. This is necessary for stale flows cleanup to work\ncorrectly. In upstream, it is treated using OVSBridgeCookieMixin.\n\n[1] https://review.openstack.org/#/c/297211/\n[2] https://review.openstack.org/#/c/297818/\n\nConflicts:\n\tneutron/tests/functional/agent/l2/base.py\n\tneutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py\n\nCo-Authored-By: Jian Wen <wenjianhn@gmail.com>\nCo-Authored-By: Clayton O'Neill <clayton@oneill.net>\nPartial-Bug: 1514056\nChange-Id: I9801b76829021c9a0e6358982e1136637634a521\n(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)\n""}, {'number': 5, 'created': '2016-04-28 21:23:15.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/test_br_phys.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/br_phys.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/br_phys.py', 'neutron/tests/functional/agent/l2/base.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py', 'neutron/tests/functional/agent/test_l2_ovs_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/native/test_br_phys.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d29f38356fc5b840fa8b5c31fcd9d76c0fdd336', 'message': ""Cleanup stale OVS flows for physical bridges\n\nPerform deletion of the stale flows in physical bridges consistently with\nbr-int and br-tun, respecting drop_flows_on_start configuration option.\nAdded tests for auxiliary bridge and functional tests for the physical\nbridge using VLAN/flat external network. Fixes part of the bug 1514056;\ntogether with [1] and [2], the bug should be considered fixed.\n\nThe commit also fixes inconsistency between netmask of allocated IP\naddresses assigned in _create_test_port_dict and ip_len in _plug_ports\nof base.py.\n\nFurther, this commit sets agent UUID to physical bridges similarly to\ntun and int bridges. This is necessary for stale flows cleanup to work\ncorrectly. In upstream, it is treated using OVSBridgeCookieMixin.\n\n[1] https://review.openstack.org/#/c/297211/\n[2] https://review.openstack.org/#/c/297818/\n\nConflicts:\n\tneutron/tests/functional/agent/l2/base.py\n\tneutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py\n\nCo-Authored-By: Jian Wen <wenjianhn@gmail.com>\nCo-Authored-By: Clayton O'Neill <clayton@oneill.net>\nPartial-Bug: 1514056\nChange-Id: I9801b76829021c9a0e6358982e1136637634a521\n(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)\n""}]",0,300424,8d29f38356fc5b840fa8b5c31fcd9d76c0fdd336,52,18,5,19797,,,0,"Cleanup stale OVS flows for physical bridges

Perform deletion of the stale flows in physical bridges consistently with
br-int and br-tun, respecting drop_flows_on_start configuration option.
Added tests for auxiliary bridge and functional tests for the physical
bridge using VLAN/flat external network. Fixes part of the bug 1514056;
together with [1] and [2], the bug should be considered fixed.

The commit also fixes inconsistency between netmask of allocated IP
addresses assigned in _create_test_port_dict and ip_len in _plug_ports
of base.py.

Further, this commit sets agent UUID to physical bridges similarly to
tun and int bridges. This is necessary for stale flows cleanup to work
correctly. In upstream, it is treated using OVSBridgeCookieMixin.

[1] https://review.openstack.org/#/c/297211/
[2] https://review.openstack.org/#/c/297818/

Conflicts:
	neutron/tests/functional/agent/l2/base.py
	neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py

Co-Authored-By: Jian Wen <wenjianhn@gmail.com>
Co-Authored-By: Clayton O'Neill <clayton@oneill.net>
Partial-Bug: 1514056
Change-Id: I9801b76829021c9a0e6358982e1136637634a521
(cherry picked from commit cacde308eef6f1d7005e555b4521332da95d3cf4)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/300424/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/test_br_phys.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/br_phys.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/ovs_ofctl/br_phys.py', 'neutron/tests/functional/agent/l2/base.py', 'neutron/tests/functional/agent/test_l2_ovs_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_tunnel.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/native/test_br_phys.py']",8,b445235d8460645283d44890b9b7e0ae2a9aba57,bug/1514056,," call.delete_flows(),",117,21
openstack%2Fopenstack-manuals~master~I6599ca30676d7dce8a0fb88686cf103f208dc214,openstack/openstack-manuals,master,I6599ca30676d7dce8a0fb88686cf103f208dc214,Windows SSH key for first contributors,MERGED,2016-04-30 18:45:47.000000000,2016-05-05 00:45:12.000000000,2016-05-05 00:45:12.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 170}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 17106}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-04-30 18:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b8ec3c00b3862c157f55fcf973ba1a52a939decb', 'message': 'Windows SSH key for first contributors\n\nChange-Id: I6599ca30676d7dce8a0fb88686cf103f208dc214\n'}, {'number': 2, 'created': '2016-04-30 22:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d89893231b8de5fa2ea6843ea6233d976a831cea', 'message': 'Windows SSH key for first contributors\n\nChange-Id: I6599ca30676d7dce8a0fb88686cf103f208dc214\n'}, {'number': 3, 'created': '2016-05-03 12:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f5c55743822531c245df5e9897f1b5060732565', 'message': 'Windows SSH key for first contributors\n\nChange-Id: I6599ca30676d7dce8a0fb88686cf103f208dc214\n'}, {'number': 4, 'created': '2016-05-04 22:37:44.000000000', 'files': ['doc/contributor-guide/source/quickstart/first-timers.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f44592fe8d0d2eb85c50f66c2f966461a18c01e1', 'message': 'Windows SSH key for first contributors\n\nChange-Id: I6599ca30676d7dce8a0fb88686cf103f208dc214\n'}]",9,311562,f44592fe8d0d2eb85c50f66c2f966461a18c01e1,24,9,4,964,,,0,"Windows SSH key for first contributors

Change-Id: I6599ca30676d7dce8a0fb88686cf103f208dc214
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/311562/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/contributor-guide/source/quickstart/first-timers.rst'],1,b8ec3c00b3862c157f55fcf973ba1a52a939decb,test,"#. View and copy your SSH key: **Linux/Mac** .. code-block:: console $ less ~/.ssh/id_rsa.pub **Windows** In Windows Explorer, browse to c:/Users/<username>/.ssh/ and open the ``id_rsa.pub`` file in Notepad. Use Select All and then copy. .. note:: If you use Windows, our testing shows you must open the ``.pub`` file in Notepad in order for gerrit to accept the key. #. Sign into gerrit at review.openstack.org. #. In the upper right, click your username. Click the `Settings > SSH Public Keys`_ page. Click ``Add Key``. Paste the key in the ``Add SSH Public Key`` web form and click ``Add``.",#. Add your SSH key by logging into gerrit and viewing the `Settings > SSH Public Keys`_ page. ,22,2
openstack%2Fbifrost~master~Iea26467ccbc9256340c871726a0e67b65bd926cd,openstack/bifrost,master,Iea26467ccbc9256340c871726a0e67b65bd926cd,Add Ubuntu 16.04 defaults for ironic role,MERGED,2016-05-04 02:01:02.000000000,2016-05-05 00:45:02.000000000,2016-05-05 00:45:02.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-05-04 02:01:02.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Ubuntu_16.04.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3308b31aaccb4e9e63b5a38806650f59799ca880', 'message': 'Add Ubuntu 16.04 defaults for ironic role\n\nCurrently, the ironic role does not have a\ndefaults file for Ubuntu 16.04.\n\nThis means that it falls back to the\nDebian defaults and uses upstart which\nis not the default on 16.04\n\nThis patch updates the default to use the\nsame one as 15.04\n\nChange-Id: Iea26467ccbc9256340c871726a0e67b65bd926cd\n'}]",0,312303,3308b31aaccb4e9e63b5a38806650f59799ca880,8,3,1,2265,,,0,"Add Ubuntu 16.04 defaults for ironic role

Currently, the ironic role does not have a
defaults file for Ubuntu 16.04.

This means that it falls back to the
Debian defaults and uses upstart which
is not the default on 16.04

This patch updates the default to use the
same one as 15.04

Change-Id: Iea26467ccbc9256340c871726a0e67b65bd926cd
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/03/312303/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Ubuntu_16.04.yml'],1,3308b31aaccb4e9e63b5a38806650f59799ca880,,--- init_template: systemd_template.j2 init_dest_dir: /lib/systemd/system/ init_ext: .service ,,4,0
openstack%2Fopenstack-manuals~master~I163b71c41ccd78fc345f960270006a07dbba70b6,openstack/openstack-manuals,master,I163b71c41ccd78fc345f960270006a07dbba70b6,Correct the not accurate sentence and title,MERGED,2016-05-04 14:39:13.000000000,2016-05-05 00:42:13.000000000,2016-05-05 00:42:13.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-05-04 14:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e44d2eefd8f0900002a92aad831f91703983df1b', 'message': 'Correct the not accurate sentence and title\n\nChange-Id: I163b71c41ccd78fc345f960270006a07dbba70b6\n'}, {'number': 2, 'created': '2016-05-04 14:53:13.000000000', 'files': ['doc/admin-guide/source/dashboard.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8d31bab05383b03768ff1eeb662530ac40d0ff8e', 'message': 'Correct the not accurate sentence and title\n\nChange-Id: I163b71c41ccd78fc345f960270006a07dbba70b6\n'}]",0,312573,8d31bab05383b03768ff1eeb662530ac40d0ff8e,9,3,2,14151,,,0,"Correct the not accurate sentence and title

Change-Id: I163b71c41ccd78fc345f960270006a07dbba70b6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/73/312573/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/dashboard.rst'],1,e44d2eefd8f0900002a92aad831f91703983df1b,end_user_launch_instance,"- To launch instances with the dashboard as an end user, see the `Launch and manage instances <http://docs.openstack.org/user-guide/dashboard_launch_instances.html>`__. in the OpenStack End User Guide.","- To launch instances with the dashboard, see the `OpenStack End User Guide <http://docs.openstack.org/user-guide/dashboard_launch_instances.html>`__.",4,2
openstack%2Fkeystone~stable%2Fliberty~I7d80cf18197f5444044bce59af6fe3385f8ad8ac,openstack/keystone,stable/liberty,I7d80cf18197f5444044bce59af6fe3385f8ad8ac,Updating sample configuration file,MERGED,2016-05-04 22:19:36.000000000,2016-05-05 00:41:43.000000000,2016-05-05 00:41:43.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-05-04 22:19:36.000000000', 'files': ['etc/keystone.conf.sample'], 'web_link': 'https://opendev.org/openstack/keystone/commit/762b0c1783dd28cffd071b012aff1cf0faccec4e', 'message': 'Updating sample configuration file\n\nChange-Id: I7d80cf18197f5444044bce59af6fe3385f8ad8ac\n'}]",0,312772,762b0c1783dd28cffd071b012aff1cf0faccec4e,6,2,1,11131,,,0,"Updating sample configuration file

Change-Id: I7d80cf18197f5444044bce59af6fe3385f8ad8ac
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/312772/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/keystone.conf.sample'],1,762b0c1783dd28cffd071b012aff1cf0faccec4e,openstack/keystone/genconf,"# Print debugging output (set logging level to DEBUG instead of default INFO # level). (boolean value)# If set to false, will disable INFO logging level, making WARNING the default. # (boolean value)# files, see the Python logging module documentation. (string value)# DEPRECATED. A logging.Formatter log message format string which may use any # of the available logging.LogRecord attributes. This option is deprecated. # Please use logging_context_format_string and logging_default_format_string # instead. (string value) #log_format = <None> # Format string for %%(asctime)s in log records. Default: %(default)s . (string# (Optional) Name of log file to output to. If no default is set, logging will # go to stdout. (string value)# (Optional) The base directory used for relative --log-file paths. (string # value)# changed later to honor RFC5424. (boolean value)# (Optional) Enables or disables syslog rfc5424 format for logging. If enabled, # prefixes the MSG part of the syslog message with APP-NAME (RFC5424). The # format without the APP-NAME is deprecated in Kilo, and will be removed in # Mitaka, along with this option. (boolean value) # This option is deprecated for removal. # Its value may be silently ignored in the future. #use_syslog_rfc_format = true # Syslog facility to receive log lines. (string value)# Log output to standard error. (boolean value)# Format string to use for log messages without context. (string value)# Data to append to log format when level is DEBUG. (string value)# List of logger=LEVEL pairs. (list value) #default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN#rpc_zmq_matchmaker = local # ZeroMQ receiver listening port. (integer value) #rpc_zmq_port = 9501# Seconds to wait before a cast expires (TTL). Only supported by impl_zmq.#rpc_cast_timeout = 30 # Heartbeat frequency. (integer value) #matchmaker_heartbeat_freq = 300 # Heartbeat time-to-live. (integer value) #matchmaker_heartbeat_ttl = 600# The Drivers(s) to handle sending notifications. Possible values are # messaging, messagingv2, routing, log, test, noop (multi valued) #notification_driver = # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics #notification_topics = notifications # The messaging driver to use, defaults to rabbit. Other drivers include qpid# requests ""origin"" header. (string value)# requests ""origin"" header. (string value)#max_overflow = <None># Use this port to connect to redis host. (integer value)#password = <None> [matchmaker_ring] # # From oslo.messaging # # Matchmaker ring file (JSON). (string value) # Deprecated group/name - [DEFAULT]/matchmaker_ringfile #ringfile = /etc/oslo/matchmaker_ring.json [oslo_messaging_qpid]# Use durable queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/amqp_durable_queues # Deprecated group/name - [DEFAULT]/rabbit_durable_queues #amqp_durable_queues = false # Auto-delete queues in AMQP. (boolean value) # Deprecated group/name - [DEFAULT]/amqp_auto_delete #amqp_auto_delete = false # Send a single AMQP reply to call message. The current behaviour since oslo- # incubator is to send two AMQP replies - first one with the payload, a second # one to ensure the other have finish to send the payload. We are going to # remove it in the N release, but we must keep backward compatible at the same # time. This option provides such compatibility - it defaults to False in # Liberty and can be turned on for early adopters with a new installations or # for testing. Please note, that this option will be removed in the Mitaka # release. (boolean value) #send_single_reply = false # Qpid broker hostname. (string value) # Deprecated group/name - [DEFAULT]/qpid_hostname #qpid_hostname = localhost # Qpid broker port. (integer value) # Deprecated group/name - [DEFAULT]/qpid_port #qpid_port = 5672 # Qpid HA cluster host:port pairs. (list value) # Deprecated group/name - [DEFAULT]/qpid_hosts #qpid_hosts = $qpid_hostname:$qpid_port # Username for Qpid connection. (string value) # Deprecated group/name - [DEFAULT]/qpid_username #qpid_username = # Password for Qpid connection. (string value) # Deprecated group/name - [DEFAULT]/qpid_password #qpid_password = # Space separated list of SASL mechanisms to use for auth. (string value) # Deprecated group/name - [DEFAULT]/qpid_sasl_mechanisms #qpid_sasl_mechanisms = # Seconds between connection keepalive heartbeats. (integer value) # Deprecated group/name - [DEFAULT]/qpid_heartbeat #qpid_heartbeat = 60 # Transport to use, either 'tcp' or 'ssl'. (string value) # Deprecated group/name - [DEFAULT]/qpid_protocol #qpid_protocol = tcp # Whether to disable the Nagle algorithm. (boolean value) # Deprecated group/name - [DEFAULT]/qpid_tcp_nodelay #qpid_tcp_nodelay = true # The number of prefetched messages held by receiver. (integer value) # Deprecated group/name - [DEFAULT]/qpid_receiver_capacity #qpid_receiver_capacity = 1 # The qpid topology version to use. Version 1 is what was originally used by # impl_qpid. Version 2 includes some backwards-incompatible changes that allow # broker federation to work. Users should update to version 2 when they are # able to take everything down, as it requires a clean break. (integer value) # Deprecated group/name - [DEFAULT]/qpid_topology_version #qpid_topology_version = 1# Send a single AMQP reply to call message. The current behaviour since oslo- # incubator is to send two AMQP replies - first one with the payload, a second # one to ensure the other have finish to send the payload. We are going to # remove it in the N release, but we must keep backward compatible at the same # time. This option provides such compatibility - it defaults to False in # Liberty and can be turned on for early adopters with a new installations or # for testing. Please note, that this option will be removed in the Mitaka # release. (boolean value) #send_single_reply = false # How long to wait before considering a reconnect attempt to have failed. This # value should not be longer than rpc_response_timeout. (integer value) #kombu_reconnect_timeout = 60# The RabbitMQ broker port where a single node is used. (integer value)# Use HA queues in RabbitMQ (x-ha-policy: all). If you change this option, you # must wipe the RabbitMQ database. (boolean value)# # From oslo.middleware # # This option is deprecated for removal. # Its value may be silently ignored in the future.","# If set to true, the logging level will be set to DEBUG instead of the default # INFO level. (boolean value)# If set to false, the logging level will be set to WARNING instead of the # default INFO level. (boolean value)# files, see the Python logging module documentation. Note that when logging # configuration files are used then all logging configuration is set in the # configuration file and other logging configuration options are ignored (for # example, logging_context_format_string). (string value)# Defines the format string for %%(asctime)s in log records. Default: # %(default)s . This option is ignored if log_config_append is set. (string# (Optional) Name of log file to send logging output to. If no default is set, # logging will go to stderr as defined by use_stderr. This option is ignored if # log_config_append is set. (string value)# (Optional) The base directory used for relative log_file paths. This option # is ignored if log_config_append is set. (string value)# Uses logging handler designed to watch file system. When log file is moved or # removed this handler will open a new log file with specified path # instantaneously. It makes sense only if log_file option is specified and # Linux platform is used. This option is ignored if log_config_append is set. # (boolean value) #watch_log_file = false # changed later to honor RFC5424. This option is ignored if log_config_append # is set. (boolean value)# Syslog facility to receive log lines. This option is ignored if # log_config_append is set. (string value)# Log output to standard error. This option is ignored if log_config_append is # set. (boolean value)# Format string to use for log messages when context is undefined. (string # value)# Additional data to append to log message when logging level for the message # is DEBUG. (string value)# Defines the format string for %(user_identity)s that is used in # logging_context_format_string. (string value) #logging_user_identity_format = %(user)s %(tenant)s %(domain)s %(user_domain)s %(project_domain)s # List of package logging levels in logger=LEVEL pairs. This option is ignored # if log_config_append is set. (list value) #default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,dogpile.core.dogpile=INFO# Allowed values: redis, dummy #rpc_zmq_matchmaker = redis # Type of concurrency used. Either ""native"" or ""eventlet"" (string value) #rpc_zmq_concurrency = eventlet# Seconds to wait before a cast expires (TTL). The default value of -1 # specifies an infinite linger period. The value of 0 specifies no linger # period. Pending messages shall be discarded immediately when the socket is # closed. Only supported by impl_zmq. (integer value) #rpc_cast_timeout = -1 # The default number of seconds that poll should wait. Poll raises timeout # exception when timeout expired. (integer value) #rpc_poll_timeout = 1 # Expiration timeout in seconds of a name service record about existing target # ( < 0 means no timeout). (integer value) #zmq_target_expire = 120 # Use PUB/SUB pattern for fanout methods. PUB/SUB always uses proxy. (boolean # value) #use_pub_sub = true # Minimal port number for random ports range. (port value) # Minimum value: 0 # Maximum value: 65535 #rpc_zmq_min_port = 49152 # Maximal port number for random ports range. (integer value) # Minimum value: 1 # Maximum value: 65536 #rpc_zmq_max_port = 65536 # Number of retries to find free port number before fail with ZMQBindError.#rpc_zmq_bind_port_retries = 100# The messaging driver to use, defaults to rabbit. Other drivers include amqp# Enable eventlet backdoor, using the provided path as a unix socket that can # receive connections. This option is mutually exclusive with 'backdoor_port' # in that only one should be provided. If both are provided then the existence # of this option overrides the usage of that option. (string value) #backdoor_socket = <None> # Specify a timeout after which a gracefully shutdown server will exit. Zero # value means endless wait. (integer value) #graceful_shutdown_timeout = 60 # requests ""origin"" header. (list value)# requests ""origin"" header. (list value)#max_overflow = 50# Use this port to connect to redis host. (port value) # Minimum value: 0 # Maximum value: 65535#password = # List of Redis Sentinel hosts (fault tolerance mode) e.g. # [host:port, host1:port ... ] (list value) #sentinel_hosts = # Redis replica set name. (string value) #sentinel_group_name = oslo-messaging-zeromq # Time in ms to wait between connection attempts. (integer value) #wait_timeout = 500 # Time in ms to wait before the transaction is killed. (integer value) #check_timeout = 20000 # Timeout in ms on blocking socket operations (integer value) #socket_timeout = 1000# Space separated list of acceptable SASL mechanisms (string value) # Deprecated group/name - [amqp1]/sasl_mechanisms #sasl_mechanisms = # Path to directory that contains the SASL configuration (string value) # Deprecated group/name - [amqp1]/sasl_config_dir #sasl_config_dir = # Name of configuration file (without .conf suffix) (string value) # Deprecated group/name - [amqp1]/sasl_config_name #sasl_config_name = # User name for message broker authentication (string value) # Deprecated group/name - [amqp1]/username #username = # Password for message broker authentication (string value) # Deprecated group/name - [amqp1]/password #password = [oslo_messaging_notifications]# The Drivers(s) to handle sending notifications. Possible values are # messaging, messagingv2, routing, log, test, noop (multi valued) # Deprecated group/name - [DEFAULT]/notification_driver #driver = # A URL representing the messaging driver to use for notifications. If not set, # we fall back to the same configuration used for RPC. (string value) # Deprecated group/name - [DEFAULT]/notification_transport_url #transport_url = <None> # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics # Deprecated group/name - [DEFAULT]/notification_topics #topics = notifications# EXPERIMENTAL: Possible values are: gzip, bz2. If not set compression will not # be used. This option may notbe available in future versions. (string value) #kombu_compression = <None> # How long to wait a missing client beforce abandoning to send it its replies. # This value should not be longer than rpc_response_timeout. (integer value) # Deprecated group/name - [DEFAULT]/kombu_reconnect_timeout #kombu_missing_consumer_retry_timeout = 60 # Determines how the next RabbitMQ node is chosen in case the one we are # currently connected to becomes unavailable. Takes effect only if more than # one RabbitMQ node is provided in config. (string value) # Allowed values: round-robin, shuffle #kombu_failover_strategy = round-robin# The RabbitMQ broker port where a single node is used. (port value) # Minimum value: 0 # Maximum value: 65535# Maximum interval of RabbitMQ connection retries. Default is 30 seconds. # (integer value) #rabbit_interval_max = 30 # Try to use HA queues in RabbitMQ (x-ha-policy: all). If you change this # option, you must wipe the RabbitMQ database. In RabbitMQ 3.0, queue mirroring # is no longer controlled by the x-ha-policy argument when declaring a queue. # If you just want to make sure that all queues (except those with auto- # generated names) are mirrored across all nodes, run: ""rabbitmqctl set_policy # HA '^(?!amq\.).*' '{""ha-mode"": ""all""}' "" (boolean value)# Positive integer representing duration in seconds for queue TTL (x-expires). # Queues which are unused for the duration of the TTL are automatically # deleted. The parameter affects only reply and fanout queues. (integer value) # Minimum value: 1 #rabbit_transient_queues_ttl = 1800 # Specifies the number of messages to prefetch. Setting to zero allows # unlimited messages. (integer value) #rabbit_qos_prefetch_count = 0 # Maximum number of channels to allow (integer value) #channel_max = <None> # The maximum byte size for an AMQP frame (integer value) #frame_max = <None> # How often to send heartbeats for consumer's connections (integer value) #heartbeat_interval = 1 # Enable SSL (boolean value) #ssl = <None> # Arguments passed to ssl.wrap_socket (dict value) #ssl_options = <None> # Set socket timeout in seconds for connection's socket (floating point value) #socket_timeout = 0.25 # Set TCP_USER_TIMEOUT in seconds for connection's socket (floating point # value) #tcp_user_timeout = 0.25 # Set delay for reconnection to some host which has connection error (floating # point value) #host_connection_reconnect_delay = 0.25 # Maximum number of connections to keep queued. (integer value) #pool_max_size = 10 # Maximum number of connections to create above `pool_max_size`. (integer # value) #pool_max_overflow = 0 # Default number of seconds to wait for a connections to available (integer # value) #pool_timeout = 30 # Lifetime of a connection (since creation) in seconds or None for no # recycling. Expired connections are closed on acquire. (integer value) #pool_recycle = 600 # Threshold at which inactive (since release) connections are considered stale # in seconds or None for no staleness. Stale connections are closed on acquire. # (integer value) #pool_stale = 60 # Persist notification messages. (boolean value) #notification_persistence = false # Exchange name for for sending notifications (string value) #default_notification_exchange = ${control_exchange}_notification # Max number of not acknowledged message which RabbitMQ can send to # notification listener. (integer value) #notification_listener_prefetch_count = 100 # Reconnecting retry count in case of connectivity problem during sending # notification, -1 means infinite retry. (integer value) #default_notification_retry_attempts = -1 # Reconnecting retry delay in case of connectivity problem during sending # notification message (floating point value) #notification_retry_delay = 0.25 # Time to live for rpc queues without consumers in seconds. (integer value) #rpc_queue_expiration = 60 # Exchange name for sending RPC messages (string value) #default_rpc_exchange = ${control_exchange}_rpc # Exchange name for receiving RPC replies (string value) #rpc_reply_exchange = ${control_exchange}_rpc_reply # Max number of not acknowledged message which RabbitMQ can send to rpc # listener. (integer value) #rpc_listener_prefetch_count = 100 # Max number of not acknowledged message which RabbitMQ can send to rpc reply # listener. (integer value) #rpc_reply_listener_prefetch_count = 100 # Reconnecting retry count in case of connectivity problem during sending # reply. -1 means infinite retry during rpc_timeout (integer value) #rpc_reply_retry_attempts = -1 # Reconnecting retry delay in case of connectivity problem during sending # reply. (floating point value) #rpc_reply_retry_delay = 0.25 # Reconnecting retry count in case of connectivity problem during sending RPC # message, -1 means infinite retry. If actual retry attempts in not 0 the rpc # request could be processed more then one time (integer value) #default_rpc_retry_attempts = -1 # Reconnecting retry delay in case of connectivity problem during sending RPC # message (floating point value) #rpc_retry_delay = 0.25 # This option is deprecated for removal. # Its value may be silently ignored in the future.",149,273
openstack%2Fopenstack-ansible~stable%2Fmitaka~I713ac489998e34cf0a916a8acc5ae752e657d163,openstack/openstack-ansible,stable/mitaka,I713ac489998e34cf0a916a8acc5ae752e657d163,Fix LBaaSv2 neutron_plugin_base entry in docs,MERGED,2016-05-04 17:14:06.000000000,2016-05-05 00:37:54.000000000,2016-05-05 00:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12402}]","[{'number': 1, 'created': '2016-05-04 17:14:06.000000000', 'files': ['doc/source/install-guide/configure-network-services-lbaas.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6e126dc81bc2ea63ce95ac0df31d645c162de458', 'message': 'Fix LBaaSv2 neutron_plugin_base entry in docs\n\nThe LBaaSv2 docs reference the short name of the LBaaSv2 plugin but\nthe full name is required.\n\nCloses-bug: 1575798\n\nChange-Id: I713ac489998e34cf0a916a8acc5ae752e657d163\n(cherry picked from commit 34ddd521e58ca15ea00d3254bd0712db04e036f8)\n'}]",0,312644,6e126dc81bc2ea63ce95ac0df31d645c162de458,8,4,1,538,,,0,"Fix LBaaSv2 neutron_plugin_base entry in docs

The LBaaSv2 docs reference the short name of the LBaaSv2 plugin but
the full name is required.

Closes-bug: 1575798

Change-Id: I713ac489998e34cf0a916a8acc5ae752e657d163
(cherry picked from commit 34ddd521e58ca15ea00d3254bd0712db04e036f8)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/44/312644/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install-guide/configure-network-services-lbaas.rst'],1,6e126dc81bc2ea63ce95ac0df31d645c162de458,bug/1575798, - neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2.. include:: navigation.txt , - lbaasv2.. include:: navigation.txt,2,2
openstack%2Fopenstack-ansible~stable%2Fmitaka~If47e7b7abea61d3e7a00fe217a6181f8f03c5f7b,openstack/openstack-ansible,stable/mitaka,If47e7b7abea61d3e7a00fe217a6181f8f03c5f7b,Execute rabbitmq sorts for config tags,MERGED,2016-04-28 14:14:30.000000000,2016-05-05 00:37:48.000000000,2016-05-05 00:37:48.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-04-28 14:14:30.000000000', 'files': ['playbooks/os-neutron-install.yml', 'playbooks/os-horizon-install.yml', 'playbooks/os-heat-install.yml', 'playbooks/os-keystone-install.yml', 'playbooks/os-nova-install.yml', 'playbooks/os-ironic-install.yml', 'playbooks/os-cinder-install.yml', 'playbooks/os-glance-install.yml', 'playbooks/os-aodh-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/28452dd121eaaf1a92e320770249e9a1c3e40cfc', 'message': 'Execute rabbitmq sorts for config tags\n\nThis fix executes the rabbitmq deterministic sorting\nwhile using the product-config tag, e.g. nova-config\nin order rewrite the OpenStack configs (nova/neutron etc)\n\nChange-Id: If47e7b7abea61d3e7a00fe217a6181f8f03c5f7b\nCloses-Bug: #1575297\n(cherry picked from commit e22641abbf30ac7b0c6c6abdaded131731c4932c)\n'}]",0,310786,28452dd121eaaf1a92e320770249e9a1c3e40cfc,8,4,1,14552,,,0,"Execute rabbitmq sorts for config tags

This fix executes the rabbitmq deterministic sorting
while using the product-config tag, e.g. nova-config
in order rewrite the OpenStack configs (nova/neutron etc)

Change-Id: If47e7b7abea61d3e7a00fe217a6181f8f03c5f7b
Closes-Bug: #1575297
(cherry picked from commit e22641abbf30ac7b0c6c6abdaded131731c4932c)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/310786/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/os-neutron-install.yml', 'playbooks/os-horizon-install.yml', 'playbooks/os-heat-install.yml', 'playbooks/os-keystone-install.yml', 'playbooks/os-nova-install.yml', 'playbooks/os-ironic-install.yml', 'playbooks/os-cinder-install.yml', 'playbooks/os-glance-install.yml', 'playbooks/os-aodh-install.yml']",9,28452dd121eaaf1a92e320770249e9a1c3e40cfc,bug/1575297, tags: - always tags: - always,,36,0
openstack%2Fproject-config~master~I4efad0ef4134aa5b3af5afd859f44e66f9e81404,openstack/project-config,master,I4efad0ef4134aa5b3af5afd859f44e66f9e81404,Fix neutron periodic jobs time series request,ABANDONED,2016-05-04 11:21:57.000000000,2016-05-05 00:33:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6524}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-05-04 11:21:57.000000000', 'files': ['grafana/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f1460f16e679c27d3712e295e04d64704163da37', 'message': 'Fix neutron periodic jobs time series request\n\nOne of the jobs in the ""Periodic jobs"" graph was requesting a 12-hour\ntime series while the rest used 24-hours. Grafana rightly complained\nthat it is not possible to draw a graph with different time series.\n\nChange-Id: I4efad0ef4134aa5b3af5afd859f44e66f9e81404\n'}]",0,312456,f1460f16e679c27d3712e295e04d64704163da37,5,3,1,6524,,,0,"Fix neutron periodic jobs time series request

One of the jobs in the ""Periodic jobs"" graph was requesting a 12-hour
time series while the rest used 24-hours. Grafana rightly complained
that it is not possible to draw a graph with different time series.

Change-Id: I4efad0ef4134aa5b3af5afd859f44e66f9e81404
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/312456/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/neutron.yaml'],1,f1460f16e679c27d3712e295e04d64704163da37,periodic-job-hours," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.{SUCCESS,FAILURE})),'24hours'), 'gate-tempest-dsvm-full')"," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.FAILURE),sum(stats_counts.zuul.pipeline.gate.job.gate-tempest-dsvm-full.{SUCCESS,FAILURE})),'12hours'), 'gate-tempest-dsvm-full')",1,1
openstack%2Fsearchlight-ui~master~If921c51f7ec819130a7fc898899980cb3b294968,openstack/searchlight-ui,master,If921c51f7ec819130a7fc898899980cb3b294968,Use Chrome for JS unit tests,MERGED,2016-05-02 20:46:13.000000000,2016-05-05 00:31:44.000000000,2016-05-05 00:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 10063}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-05-02 20:46:13.000000000', 'files': ['package.json', 'searchlight_ui/karma.conf.js'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/faf41c0fc6aa8908006e3caaa601fdfa65b337b0', 'message': 'Use Chrome for JS unit tests\n\nPhantomJS has setup issues and is slowing down the gate with false\nfailures. We should change to Chrome until Phantom is more\nreliable, at which point this patch can be reverted.\n\nThis has been changed on Horizon master. See:\nhttps://review.openstack.org/#/c/304670\n\nChange-Id: If921c51f7ec819130a7fc898899980cb3b294968\nCloses-Bug: 1568325\n'}]",0,311851,faf41c0fc6aa8908006e3caaa601fdfa65b337b0,11,3,1,7665,,,0,"Use Chrome for JS unit tests

PhantomJS has setup issues and is slowing down the gate with false
failures. We should change to Chrome until Phantom is more
reliable, at which point this patch can be reverted.

This has been changed on Horizon master. See:
https://review.openstack.org/#/c/304670

Change-Id: If921c51f7ec819130a7fc898899980cb3b294968
Closes-Bug: 1568325
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/51/311851/1 && git format-patch -1 --stdout FETCH_HEAD,"['package.json', 'searchlight_ui/karma.conf.js']",2,faf41c0fc6aa8908006e3caaa601fdfa65b337b0,bug/1568325," browsers: ['Chrome'], browserNoActivityTimeout: 60000, 'karma-chrome-launcher',"," browsers: ['PhantomJS'], phantomjsLauncher: { // Have phantomjs exit if a ResourceError is encountered // (useful if karma exits without killing phantom) exitOnResourceError: true }, 'karma-phantomjs-launcher',",4,9
openstack%2Fsearchlight-ui~master~Id7cf4394725702fb482c9290f2a8d379638f5198,openstack/searchlight-ui,master,Id7cf4394725702fb482c9290f2a8d379638f5198,Update JS dev dependencies,MERGED,2016-05-02 20:38:38.000000000,2016-05-05 00:18:33.000000000,2016-05-05 00:18:33.000000000,"[{'_account_id': 3}, {'_account_id': 11778}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-05-02 20:38:38.000000000', 'files': ['package.json'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/4aef2ece4dd5f82c5fcacfe41c31546e1d5a8c22', 'message': 'Update JS dev dependencies\n\nA lot of the JavaScript dev dependencies are quite outdated. This patch\nupdates them to match the current Horizon master dependencies.\n\nSee: https://review.openstack.org/#/c/303379/\n\nChange-Id: Id7cf4394725702fb482c9290f2a8d379638f5198\nCloses-Bug: 1569783\n'}]",0,311844,4aef2ece4dd5f82c5fcacfe41c31546e1d5a8c22,15,3,1,7665,,,0,"Update JS dev dependencies

A lot of the JavaScript dev dependencies are quite outdated. This patch
updates them to match the current Horizon master dependencies.

See: https://review.openstack.org/#/c/303379/

Change-Id: Id7cf4394725702fb482c9290f2a8d379638f5198
Closes-Bug: 1569783
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/44/311844/1 && git format-patch -1 --stdout FETCH_HEAD,['package.json'],1,4aef2ece4dd5f82c5fcacfe41c31546e1d5a8c22,bug/1569783," ""jasmine-core"": ""2.4.1"", ""karma"": ""0.13.22"", ""karma-chrome-launcher"": ""0.2.3"", ""karma-cli"": ""0.1.2"", ""karma-coverage"": ""0.5.5"", ""karma-jasmine"": ""0.3.8"", ""karma-ng-html2js-preprocessor"": ""0.2.2"","," ""jasmine-core"": ""2.2.0"", ""karma"": ""0.12.31"", ""karma-chrome-launcher"": ""0.1.8"", ""karma-cli"": ""0.0.4"", ""karma-coverage"": ""0.3.1"", ""karma-jasmine"": ""0.3.5"", ""karma-ng-html2js-preprocessor"": ""0.1.2"",",7,7
openstack%2Fopenstack-ansible-openstack_hosts~master~I891e99fd624589ee36d6ce4892c835fa5ece9671,openstack/openstack-ansible-openstack_hosts,master,I891e99fd624589ee36d6ce4892c835fa5ece9671,global_environment_variable is undefined while templating,MERGED,2016-04-27 08:51:25.000000000,2016-05-05 00:12:13.000000000,2016-04-27 11:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-04-27 08:51:25.000000000', 'files': ['templates/environment.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/848cb5529e80dc458de2be2dccb6d6660d58b15d', 'message': 'global_environment_variable is undefined while templating\n\nopenstack_hosts role uses global_environment_variable for\ncreating its environment.j2. If the variable is not defined\nthe templating will fail.\n\nThis should fix it.\n\nChange-Id: I891e99fd624589ee36d6ce4892c835fa5ece9671\n'}]",0,310377,848cb5529e80dc458de2be2dccb6d6660d58b15d,8,3,1,17068,,,0,"global_environment_variable is undefined while templating

openstack_hosts role uses global_environment_variable for
creating its environment.j2. If the variable is not defined
the templating will fail.

This should fix it.

Change-Id: I891e99fd624589ee36d6ce4892c835fa5ece9671
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/77/310377/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/environment.j2'],1,848cb5529e80dc458de2be2dccb6d6660d58b15d,fix_global_environment_variable,{% if global_environment_variables is defined %}{% endif %} ,{% if global_environment_variables %}{% endif %},2,2
openstack%2Fos-brick~master~I32290beea81d2a39b828fd8bf3ef805358c7f971,openstack/os-brick,master,I32290beea81d2a39b828fd8bf3ef805358c7f971,os-brick refactor get_connector_properties,MERGED,2016-02-03 21:52:56.000000000,2016-05-05 00:12:05.000000000,2016-05-04 17:17:37.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 8543}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12924}, {'_account_id': 14242}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 18402}, {'_account_id': 19151}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-02-03 21:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8bd128df8d576d5867dc017575593a699afa963e', 'message': ""WIP os-brick refactor get_connector_properties\n\nThis is a WIP Patch\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 2, 'created': '2016-02-08 12:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/d390a0dc8e877f694bc9807656ba5a1f53599455', 'message': ""WIP os-brick refactor get_connector_properties\n\nThis is a WIP Patch\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 3, 'created': '2016-03-01 23:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/85f8340a663cde9c33dbd48f287fcb167fad6d3f', 'message': ""WIP os-brick refactor get_connector_properties\n\nThis is a WIP Patch\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 4, 'created': '2016-03-03 21:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fd8fb6b7efcf9cc899a3d6eea51cb9a1cf26f16d', 'message': ""WIP os-brick refactor get_connector_properties\n\nThis is a WIP Patch\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 5, 'created': '2016-03-15 16:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/f2fefaf62230fbfc172d8a9d55674100bd8c12b3', 'message': ""WIP os-brick refactor get_connector_properties\n\nThis is a WIP Patch\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 6, 'created': '2016-03-23 16:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fb1f62640ebaafef5a091286e4a577aaad225055', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 7, 'created': '2016-04-07 20:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/58f29dd7d083b00c5fef88761d9686c43ceab2f0', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 8, 'created': '2016-04-14 15:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/b8d15e0b021ca09f30550019c36d55582d28fbee', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 9, 'created': '2016-04-21 15:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/3203708f54a331a876a6ef8d7623c200bd82f2f8', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's cinnector_properties (initiator)\ninto the connector itself.   It also only calls each connector that matches\nthe platform and the os type.  This will allow us to add Windows based\nconnectors in the future.  So, when os-brick is running on windows, it won't\ncall any of the linux based connectors to fetch the initiator information, as\nthey won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 10, 'created': '2016-04-21 17:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/e95b6d9093317a36617ae70e4d674c9a9c1d3046', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 11, 'created': '2016-04-22 22:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/24814c4aacf43ce6a70031a14896fd3d7ab64b62', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 12, 'created': '2016-04-24 04:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/85cc1d4b16ab73e731e01b31e3852ef2c98a78df', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 13, 'created': '2016-05-03 15:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/b90842619229b313125602c88adbfb57a145f89d', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 14, 'created': '2016-05-03 21:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/e54d67206e500d8709f308f4ff7036602ec317af', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}, {'number': 15, 'created': '2016-05-04 02:52:13.000000000', 'files': ['os_brick/initiator/linuxscsi.py', 'os_brick/tests/initiator/test_connector.py', 'os_brick/utils.py', 'os_brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/80703d3e2070c16a745d75d497dedc5ec1b9e714', 'message': ""os-brick refactor get_connector_properties\n\nThis patch changes how the get_connector_properties works.  It migrates\nthe code for each specific connector type's connector_properties\n(initiator) into the connector itself.   It also only calls each\nconnector that matches the platform and the os type.  This will allow\nus to add Windows based connectors in the future.  So, when os-brick is\nrunning on windows, it won't call any of the linux based connectors to\nfetch the initiator information, as they won't work.\n\nI'm not sure it's necessary to filter by platform as well, but it seemed\neasy to do at the time.\n\nChange-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971\n""}]",57,275943,80703d3e2070c16a745d75d497dedc5ec1b9e714,197,26,15,5997,,,0,"os-brick refactor get_connector_properties

This patch changes how the get_connector_properties works.  It migrates
the code for each specific connector type's connector_properties
(initiator) into the connector itself.   It also only calls each
connector that matches the platform and the os type.  This will allow
us to add Windows based connectors in the future.  So, when os-brick is
running on windows, it won't call any of the linux based connectors to
fetch the initiator information, as they won't work.

I'm not sure it's necessary to filter by platform as well, but it seemed
easy to do at the time.

Change-Id: I32290beea81d2a39b828fd8bf3ef805358c7f971
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/43/275943/13 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/utils.py', 'os_brick/initiator/connector.py']",2,8bd128df8d576d5867dc017575593a699afa963e,bp/os-brick-windows-support,"from oslo_utils import importutilsPLATFORM_ALL = 'ALL' PLATFORM_x86 = 'X86' PLATFORM_S390 = 'S390' OS_TYPE_ALL = 'ALL' OS_TYPE_LINUX = 'LINUX' OS_TYPE_WINDOWS = 'WINDOWS' S390X = ""s390x"" S390 = ""s390"" connector_map = [ 'os_brick.initiator.connector.InitiatorConnector', 'os_brick.initiator.connector.ISCSIConnector', 'os_brick.initiator.connector.FibreChannelConnector', 'os_brick.initiator.connector.FibreChannelConnectorS390X', 'os_brick.initiator.connector.AoEConnector', 'os_brick.initiator.connector.RemoteFsConnector', 'os_brick.initiator.connector.RBDConnector', 'os_brick.initiator.connector.LocalConnector', 'os_brick.initiator.connector.DRBDConnector', 'os_brick.initiator.connector.HuaweiStorHyperConnector', 'os_brick.initiator.connector.HGSTConnector', 'os_brick.initiator.connector.ScaleIOConnector', 'os_brick.initiator.connector.DISCOConnector', ] props['ip'] = my_ip props['host'] = host if host else socket.gethostname() for item in connector_map: connector = importutils.import_class(item) if (utils.platform_matches(props['platform'], connector.platform) and utils.os_matches(props['os_type'], connector.os_type)): LOG.debug(""Fetching connector for %s"" % connector.__name__) props = utils.merge_dict(props, connector.get_connector_properties( root_helper, host=host, multipath=multipath, enforce_multipath=enforce_multipath)) # This object can be used on any platform (x86, S390) platform = PLATFORM_ALL # This object can be used on any os type (linux, windows) os_type = OS_TYPE_LINUX def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" multipath = kwargs['multipath'] enforce_multipath = kwargs['enforce_multipath'] props = {} # TODO(walter-boring) move this into platform specific lib props['multipath'] = (multipath and _check_multipathd_running(root_helper, enforce_multipath)) return props @staticmethod platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" props = {} iscsi = ISCSIConnector(root_helper=root_helper) initiator = iscsi.get_initiator() if initiator: props['initiator'] = initiator return props platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" props = {} fc = linuxfc.LinuxFibreChannel(root_helper) wwpns = fc.get_fc_wwpns() if wwpns: props['wwpns'] = wwpns wwnns = fc.get_fc_wwnns() if wwnns: props['wwnns'] = wwnns return props platform = PLATFORM_S390 os_type = OS_TYPE_LINUX platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} platform = PLATFORM_ALL os_type = OS_TYPE_LINUX @staticmethod def get_connector_properties(root_helper, *args, **kwargs): """"""The generic connector properties."""""" return {} ","S390X = ""s390x"" S390 = ""s390"" iscsi = ISCSIConnector(root_helper=root_helper) fc = linuxfc.LinuxFibreChannel(root_helper=root_helper) props['ip'] = my_ip props['host'] = host if host else socket.gethostname() initiator = iscsi.get_initiator() if initiator: props['initiator'] = initiator wwpns = fc.get_fc_wwpns() if wwpns: props['wwpns'] = wwpns wwnns = fc.get_fc_wwnns() if wwnns: props['wwnns'] = wwnns props['multipath'] = (multipath and _check_multipathd_running(root_helper, enforce_multipath))",201,22
openstack%2Fops-tags-team~master~I6d9351a6b9bbf563b68aa067d880d313e1f9ad4e,openstack/ops-tags-team,master,I6d9351a6b9bbf563b68aa067d880d313e1f9ad4e,Fix JSON syntax,MERGED,2016-05-05 00:11:04.000000000,2016-05-05 00:11:35.000000000,2016-05-05 00:11:35.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2016-05-05 00:11:04.000000000', 'files': ['mitaka/ops-production-use.json'], 'web_link': 'https://opendev.org/openstack/ops-tags-team/commit/7dc312bf0916b482d360dc153572de39e428d5fb', 'message': 'Fix JSON syntax\n\ndirectional quotes were used in ops-production-use rather than\nnon-directional quotes\n\nChange-Id: I6d9351a6b9bbf563b68aa067d880d313e1f9ad4e\n'}]",0,312792,7dc312bf0916b482d360dc153572de39e428d5fb,6,2,1,612,,,0,"Fix JSON syntax

directional quotes were used in ops-production-use rather than
non-directional quotes

Change-Id: I6d9351a6b9bbf563b68aa067d880d313e1f9ad4e
",git fetch https://review.opendev.org/openstack/ops-tags-team refs/changes/92/312792/1 && git format-patch -1 --stdout FETCH_HEAD,['mitaka/ops-production-use.json'],1,7dc312bf0916b482d360dc153572de39e428d5fb,fix-json-sytnax," ""status"": ""93%"" ""status"": ""52%"" ""status"": ""87%"" ""status"": ""88%"" ""status"": ""86%"" ""status"": ""84%"" ""status"": ""81%"" ""status"": ""59%"" ""status"": ""64%"" ""status"": ""17%"" ""status"": ""11%"" ""status"": ""20%"" ""status"": ""2%"" ""status"": ""2%"" ""status"": ""17%"" ""status"": ""11%"" ""status"": ""25%"" ""status"": ""11%"" ""status"": ""15%"" ""status"": ""6%"" ""status"": ""3%"" ""Workflow service (Mistral)"": { ""status"": ""2%"""," ""status"": ""93% ""status"": 52% ""status"": 87% ""status"": 88% ""status"": 86% ""status"": ""84% ""status"": ""81% ""status"": 59% ""status"": ""64% ""status"": 17% ""status"": 11% ""status"": 20% ""status"": 2% ""status"": 2% ""status"": 17% ""status"": 11% ""status"": 25% ""status"": 11% ""status"": 15% ""status"": 6% ""status"": 3% Workflow service (Mistral): { ""status"": 2%",23,23
