id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fkayobe~stable%2Fxena~I339042d9ce405f59aba936dd98df7d89a88bb41e,openstack/kayobe,stable/xena,I339042d9ce405f59aba936dd98df7d89a88bb41e,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-19 18:15:27.000000000,2023-04-20 12:39:28.000000000,2023-04-20 12:38:26.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-19 18:15:27.000000000', 'files': ['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2e31c7f32e094f862d0e1c5b84070cb35af61e66', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)\n""}]",0,880877,2e31c7f32e094f862d0e1c5b84070cb35af61e66,8,3,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

The related change for Kolla-Ansible is also provided:
Id79445c0311916ac6c1beb3986e14f652ee5a63c

Closes-Bug: #2014981
Related-Bug: #2014980
Change-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/77/880877/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml']",3,2e31c7f32e094f862d0e1c5b84070cb35af61e66,dib-yaml-width,{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml(width=131072) }},{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml }},15,2
openstack%2Freleases~master~Ib728e0e053d71b5f3d2f722055ce4e5ea2756d77,openstack/releases,master,Ib728e0e053d71b5f3d2f722055ce4e5ea2756d77,Release manila-ui for stable/xena,ABANDONED,2023-01-16 15:47:44.000000000,2023-04-20 12:35:04.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2023-01-16 15:47:44.000000000', 'files': ['deliverables/xena/manila-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/7d77b98a0ae37cb1eb74209f8da98b447b0852f1', 'message': 'Release manila-ui for stable/xena\n\nThis release picks up new commits to manila-ui since\nthe last release from stable/xena.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\n$ git log --oneline --no-merges 6.0.0..df76944\ndf76944 Drop lower-constraints.txt and its testing\nd3c364f Add platform annotation in bindep.txt\n5443054 Update TOX_CONSTRAINTS_FILE for stable/xena\nb03a56d Update .gitreview for stable/xena\n\nSigned-off-by: Hervé Beraud <hberaud@redhat.com>\nChange-Id: Ib728e0e053d71b5f3d2f722055ce4e5ea2756d77\n'}]",0,870601,7d77b98a0ae37cb1eb74209f8da98b447b0852f1,3,3,1,28522,,,0,"Release manila-ui for stable/xena

This release picks up new commits to manila-ui since
the last release from stable/xena.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

$ git log --oneline --no-merges 6.0.0..df76944
df76944 Drop lower-constraints.txt and its testing
d3c364f Add platform annotation in bindep.txt
5443054 Update TOX_CONSTRAINTS_FILE for stable/xena
b03a56d Update .gitreview for stable/xena

Signed-off-by: Hervé Beraud <hberaud@redhat.com>
Change-Id: Ib728e0e053d71b5f3d2f722055ce4e5ea2756d77
",git fetch https://review.opendev.org/openstack/releases refs/changes/01/870601/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/manila-ui.yaml'],1,7d77b98a0ae37cb1eb74209f8da98b447b0852f1,xena-stable, - version: 6.0.1 projects: - repo: openstack/manila-ui hash: df769444226347e41c6cb7304c72aa892dfe0e0e,,4,0
openstack%2Fcinder~stable%2Fxena~I75cd359269fc26783b069aaaa3ab92528c3bb500,openstack/cinder,stable/xena,I75cd359269fc26783b069aaaa3ab92528c3bb500,PowerMax Driver - Get manageable volumes fix,ABANDONED,2023-02-14 22:06:49.000000000,2023-04-20 12:34:17.000000000,,"[{'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-02-14 22:06:49.000000000', 'files': ['cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'releasenotes/notes/powermax-manageable-volumes-3fb4e5dcf5cc18e3.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/19e8bfbac0b8e447b187eb3209c6af4292c18fd5', 'message': 'PowerMax Driver - Get manageable volumes fix\n\nFor a PowerMax volume to be manageable it can not be in\nmore than one storage group.  Filtering manageable volumes\nlist to remove all devices that are in more than one storage\ngroup.\n\nChange-Id: I3b480b8f6f01925357651a5c5b2145b249706415\n(cherry picked from commit e8e0f8756f071a29216ce8f099102af15a003256)\n\nPowerMax Driver - Add a release note for 784603\n\nForgot to add a release note for issue [1].\nSince we are going to backport it, need to have a release note,\nas was mentioned in [2].\n\n[1] https://review.opendev.org/c/openstack/cinder/+/784603\n[2] https://review.opendev.org/c/openstack/cinder/+/821739\n\nCloses-Bug: #1979668\nChange-Id: I75cd359269fc26783b069aaaa3ab92528c3bb500\n'}]",1,873755,19e8bfbac0b8e447b187eb3209c6af4292c18fd5,14,2,1,31779,,,0,"PowerMax Driver - Get manageable volumes fix

For a PowerMax volume to be manageable it can not be in
more than one storage group.  Filtering manageable volumes
list to remove all devices that are in more than one storage
group.

Change-Id: I3b480b8f6f01925357651a5c5b2145b249706415
(cherry picked from commit e8e0f8756f071a29216ce8f099102af15a003256)

PowerMax Driver - Add a release note for 784603

Forgot to add a release note for issue [1].
Since we are going to backport it, need to have a release note,
as was mentioned in [2].

[1] https://review.opendev.org/c/openstack/cinder/+/784603
[2] https://review.opendev.org/c/openstack/cinder/+/821739

Closes-Bug: #1979668
Change-Id: I75cd359269fc26783b069aaaa3ab92528c3bb500
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/873755/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'releasenotes/notes/powermax-manageable-volumes-3fb4e5dcf5cc18e3.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py']",4,19e8bfbac0b8e447b187eb3209c6af4292c18fd5,," priv_vol_func_response_multi_sg = deepcopy(priv_vol_func_response_single) priv_vol_func_response_multi_sg[0].get('volumeHeader').update( {'numStorageGroups': 2}) priv_vol_func_response_multi_sg[0].get('volumeHeader').update( {'storageGroup': ['SG1', 'SG2']}) ",,20,0
openstack%2Freleases~master~If1be23c012ee13928ff37f75abfb87b3533a5bfa,openstack/releases,master,If1be23c012ee13928ff37f75abfb87b3533a5bfa,[oslo] Transition Xena to EM,MERGED,2023-03-29 12:59:05.000000000,2023-04-20 12:33:01.000000000,2023-04-20 12:33:01.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-03-29 12:59:05.000000000', 'files': ['deliverables/xena/oslo.vmware.yaml', 'deliverables/xena/oslo.metrics.yaml', 'deliverables/xena/automaton.yaml', 'deliverables/xena/oslo.messaging.yaml', 'deliverables/xena/stevedore.yaml', 'deliverables/xena/oslo.privsep.yaml', 'deliverables/xena/oslo.middleware.yaml', 'deliverables/xena/oslo.utils.yaml', 'deliverables/xena/oslo.context.yaml', 'deliverables/xena/castellan.yaml', 'deliverables/xena/oslo.policy.yaml', 'deliverables/xena/oslo.cache.yaml', 'deliverables/xena/oslo.upgradecheck.yaml', 'deliverables/xena/oslo.config.yaml', 'deliverables/xena/oslo.serialization.yaml', 'deliverables/xena/oslo.limit.yaml', 'deliverables/xena/oslo.versionedobjects.yaml', 'deliverables/xena/oslo.db.yaml', 'deliverables/xena/oslo.service.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3afbf4679963362707c5038dba05f8ba842ab983', 'message': '[oslo] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If1be23c012ee13928ff37f75abfb87b3533a5bfa\n'}]",2,878862,3afbf4679963362707c5038dba05f8ba842ab983,8,4,1,17685,,,0,"[oslo] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: If1be23c012ee13928ff37f75abfb87b3533a5bfa
",git fetch https://review.opendev.org/openstack/releases refs/changes/62/878862/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/oslo.vmware.yaml', 'deliverables/xena/oslo.metrics.yaml', 'deliverables/xena/automaton.yaml', 'deliverables/xena/oslo.messaging.yaml', 'deliverables/xena/stevedore.yaml', 'deliverables/xena/oslo.privsep.yaml', 'deliverables/xena/oslo.middleware.yaml', 'deliverables/xena/oslo.utils.yaml', 'deliverables/xena/oslo.context.yaml', 'deliverables/xena/castellan.yaml', 'deliverables/xena/oslo.policy.yaml', 'deliverables/xena/oslo.cache.yaml', 'deliverables/xena/oslo.upgradecheck.yaml', 'deliverables/xena/oslo.config.yaml', 'deliverables/xena/oslo.serialization.yaml', 'deliverables/xena/oslo.limit.yaml', 'deliverables/xena/oslo.versionedobjects.yaml', 'deliverables/xena/oslo.db.yaml', 'deliverables/xena/oslo.service.yaml']",19,3afbf4679963362707c5038dba05f8ba842ab983,xena-em, - version: xena-em projects: - repo: openstack/oslo.service hash: 03d4fdda591222880cab058bd7b7c47e6ea82bf6,,76,0
openstack%2Freleases~master~If9ea1a8965af9e86087619fd272edcb19213a751,openstack/releases,master,If9ea1a8965af9e86087619fd272edcb19213a751,[neutron] Transition Xena to EM,MERGED,2023-03-29 13:03:59.000000000,2023-04-20 12:32:59.000000000,2023-04-20 12:32:59.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/55b2015e336110d04eef6876af07ffeb39cf5010', 'message': '[neutron] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If9ea1a8965af9e86087619fd272edcb19213a751\n'}, {'number': 2, 'created': '2023-04-11 13:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/eead84e5e37160414e2ff6a53c77dc2da7a4ffad', 'message': '[neutron] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If9ea1a8965af9e86087619fd272edcb19213a751\n'}, {'number': 3, 'created': '2023-04-11 14:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/55e62fa6d1520dbbdd745802e0be99d10be6aeec', 'message': '[neutron] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If9ea1a8965af9e86087619fd272edcb19213a751\n'}, {'number': 4, 'created': '2023-04-12 15:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/eb9f03bd68ab7251331f182687877cdee24b3765', 'message': '[neutron] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If9ea1a8965af9e86087619fd272edcb19213a751\n'}, {'number': 5, 'created': '2023-04-12 15:31:45.000000000', 'files': ['deliverables/xena/networking-bgpvpn.yaml', 'deliverables/xena/neutron-vpnaas-dashboard.yaml', 'deliverables/xena/networking-bagpipe.yaml', 'deliverables/xena/neutron-vpnaas.yaml', 'deliverables/xena/python-neutronclient.yaml', 'deliverables/xena/neutron.yaml', 'deliverables/xena/ovsdbapp.yaml', 'deliverables/xena/os-ken.yaml', 'deliverables/xena/neutron-lib.yaml', 'deliverables/xena/ovn-octavia-provider.yaml', 'deliverables/xena/networking-sfc.yaml', 'deliverables/xena/networking-odl.yaml', 'deliverables/xena/neutron-dynamic-routing.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/000970e0beba94ef3f4f9995a37c6c19454e041a', 'message': '[neutron] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: If9ea1a8965af9e86087619fd272edcb19213a751\n'}]",14,878874,000970e0beba94ef3f4f9995a37c6c19454e041a,31,6,5,17685,,,0,"[neutron] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: If9ea1a8965af9e86087619fd272edcb19213a751
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/878874/5 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/networking-bgpvpn.yaml', 'deliverables/xena/neutron-vpnaas-dashboard.yaml', 'deliverables/xena/networking-bagpipe.yaml', 'deliverables/xena/neutron-vpnaas.yaml', 'deliverables/xena/python-neutronclient.yaml', 'deliverables/xena/neutron.yaml', 'deliverables/xena/ovsdbapp.yaml', 'deliverables/xena/os-ken.yaml', 'deliverables/xena/neutron-lib.yaml', 'deliverables/xena/ovn-octavia-provider.yaml', 'deliverables/xena/networking-sfc.yaml', 'deliverables/xena/networking-odl.yaml', 'deliverables/xena/neutron-dynamic-routing.yaml']",13,55b2015e336110d04eef6876af07ffeb39cf5010,xena-em, - version: xena-em projects: - repo: openstack/neutron-dynamic-routing hash: 5648f4001372537a4c633254cf3055b340eed799,,52,0
openstack%2Freleases~master~I063faca8f727a1a85ffb2ccb141fcd4887c9553b,openstack/releases,master,I063faca8f727a1a85ffb2ccb141fcd4887c9553b,[manila] Transition Xena to EM,MERGED,2023-03-29 13:09:49.000000000,2023-04-20 12:28:22.000000000,2023-04-20 12:28:22.000000000,"[{'_account_id': 16643}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29632}]","[{'number': 1, 'created': '2023-03-29 13:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/9d4a8c613ff414af77db87e5e77bb100da246ef2', 'message': '[manila] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b\n'}, {'number': 2, 'created': '2023-04-10 22:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/39218b311a9e3add35f358c0620e5767427ad6e7', 'message': '[manila] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b\n'}, {'number': 3, 'created': '2023-04-10 22:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4d1d2884f10a3a088acffa379cf030c52c8d81e4', 'message': '[manila] Transition Xena to EM\n\nThis transitions the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nChange-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b\n'}, {'number': 4, 'created': '2023-04-10 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/313d749317e9474c2dca5b4a9888e22b85bb5c4b', 'message': '[manila] Transition Xena to EM\n\nThis transitions the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nChange-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b\n'}, {'number': 5, 'created': '2023-04-11 21:40:23.000000000', 'files': ['deliverables/xena/manila-ui.yaml', 'deliverables/xena/python-manilaclient.yaml', 'deliverables/xena/manila.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/89ff4733ac67a89657f05b6ac242e38a57292e6f', 'message': '[manila] Transition Xena to EM\n\nThis transitions the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nChange-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b\n'}]",6,878897,89ff4733ac67a89657f05b6ac242e38a57292e6f,24,5,5,17685,,,0,"[manila] Transition Xena to EM

This transitions the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Change-Id: I063faca8f727a1a85ffb2ccb141fcd4887c9553b
",git fetch https://review.opendev.org/openstack/releases refs/changes/97/878897/3 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/manila-ui.yaml', 'deliverables/xena/python-manilaclient.yaml', 'deliverables/xena/manila.yaml']",3,9d4a8c613ff414af77db87e5e77bb100da246ef2,xena-em, - version: xena-em projects: - repo: openstack/manila hash: 0bc68a62aa1ec6580bc2ba142390c8dc897fec42,,12,0
openstack%2Fceilometer~stable%2Fwallaby~I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,openstack/ceilometer,stable/wallaby,I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,Add vanity names to telemetry polling notifications,MERGED,2023-04-17 05:57:33.000000000,2023-04-20 12:27:07.000000000,2023-04-20 12:26:10.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 05:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/66c039d301449480d2d9d5bb48b25631d71bf0a9', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nDepends-On: https://review.opendev.org/c/openstack/ceilometer/+/880505\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}, {'number': 2, 'created': '2023-04-17 05:58:03.000000000', 'files': ['ceilometer/telemetry/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2ea516e19bb5fcabec37e8bbebaaef3ca7a68dfb', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nDepends-On: https://review.opendev.org/c/openstack/ceilometer/+/880506\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}]",6,880508,2ea516e19bb5fcabec37e8bbebaaef3ca7a68dfb,24,2,2,32240,,,0,"Add vanity names to telemetry polling notifications

This change adds ""project_name"" and ""user_name"" fields
to polling samples which is related to the identification
of vanity names change 79454d6b22787627ae6239aa7b2707101ba30212

Depends-On: https://review.opendev.org/c/openstack/ceilometer/+/880506

Change-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc
(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/880508/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/telemetry/notifications.py'],1,66c039d301449480d2d9d5bb48b25631d71bf0a9,enhanced_metrics-stable/wallaby," user_name=sample_dict['user_name'], project_name=sample_dict['project_name'],",,2,0
openstack%2Fkayobe~stable%2Fyoga~I339042d9ce405f59aba936dd98df7d89a88bb41e,openstack/kayobe,stable/yoga,I339042d9ce405f59aba936dd98df7d89a88bb41e,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-19 18:15:07.000000000,2023-04-20 12:21:18.000000000,2023-04-20 12:20:15.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-19 18:15:07.000000000', 'files': ['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/b394ff396365991b8d16aee179f5c40d0db59507', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)\n""}]",0,880876,b394ff396365991b8d16aee179f5c40d0db59507,8,3,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

The related change for Kolla-Ansible is also provided:
Id79445c0311916ac6c1beb3986e14f652ee5a63c

Closes-Bug: #2014981
Related-Bug: #2014980
Change-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/76/880876/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml']",3,b394ff396365991b8d16aee179f5c40d0db59507,dib-yaml-width,{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml(width=131072) }},{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml }},15,2
openstack%2Fkayobe~stable%2Fzed~I339042d9ce405f59aba936dd98df7d89a88bb41e,openstack/kayobe,stable/zed,I339042d9ce405f59aba936dd98df7d89a88bb41e,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-19 18:14:47.000000000,2023-04-20 11:54:31.000000000,2023-04-20 11:53:25.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-19 18:14:47.000000000', 'files': ['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/59d7cdfc0c60bd7cf8d5a0f23b58ada20a59295f', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)\n""}]",0,880875,59d7cdfc0c60bd7cf8d5a0f23b58ada20a59295f,8,3,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

The related change for Kolla-Ansible is also provided:
Id79445c0311916ac6c1beb3986e14f652ee5a63c

Closes-Bug: #2014981
Related-Bug: #2014980
Change-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/75/880875/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml']",3,59d7cdfc0c60bd7cf8d5a0f23b58ada20a59295f,dib-yaml-width,{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml(width=131072) }},{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml }},15,2
openstack%2Fkolla-ansible~stable%2Fxena~Id79445c0311916ac6c1beb3986e14f652ee5a63c,openstack/kolla-ansible,stable/xena,Id79445c0311916ac6c1beb3986e14f652ee5a63c,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-18 14:54:56.000000000,2023-04-20 11:53:36.000000000,2023-04-20 11:52:33.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-18 14:54:56.000000000', 'files': ['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6dbb86fd0c9678e2db4e0a4d3fb526ba6526b62b', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)\n""}]",0,880758,6dbb86fd0c9678e2db4e0a4d3fb526ba6526b62b,9,3,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

Closes-Bug: #2014980
Related-Bug: #2014981
Change-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/58/880758/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py']",2,6dbb86fd0c9678e2db4e0a4d3fb526ba6526b62b,dib-yaml-width," yaml_width: description: - The maximum width of the YAML document. By default, Ansible uses the PyYAML library which has a default 80 symbol string length limit. To change the limit, the new value can be used here. default: None required: False type: int yaml_width: 131072 yaml_width = self._task.args.get('yaml_width', None) f.write(yaml.dump(output, default_flow_style=False, width=yaml_width)) new_task.args.pop('yaml_width', None)"," f.write(yaml.dump(output, default_flow_style=False))",14,1
openstack%2Fkolla-ansible~stable%2Fyoga~Id79445c0311916ac6c1beb3986e14f652ee5a63c,openstack/kolla-ansible,stable/yoga,Id79445c0311916ac6c1beb3986e14f652ee5a63c,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-18 14:54:33.000000000,2023-04-20 11:53:29.000000000,2023-04-20 11:52:31.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-18 14:54:33.000000000', 'files': ['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/486367ec60ffa32fb58151f84f38460c41956cd2', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)\n""}]",0,880757,486367ec60ffa32fb58151f84f38460c41956cd2,9,3,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

Closes-Bug: #2014980
Related-Bug: #2014981
Change-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/57/880757/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py']",2,486367ec60ffa32fb58151f84f38460c41956cd2,dib-yaml-width," yaml_width: description: - The maximum width of the YAML document. By default, Ansible uses the PyYAML library which has a default 80 symbol string length limit. To change the limit, the new value can be used here. default: None required: False type: int yaml_width: 131072 yaml_width = self._task.args.get('yaml_width', None) f.write(yaml.dump(output, default_flow_style=False, width=yaml_width)) new_task.args.pop('yaml_width', None)"," f.write(yaml.dump(output, default_flow_style=False))",14,1
openstack%2Fproject-config~master~Id484d75e3c742f1302dc92e23a3eb9c8a328c55c,openstack/project-config,master,Id484d75e3c742f1302dc92e23a3eb9c8a328c55c,Add sdk and cli xxx-service-core group,MERGED,2023-04-20 09:55:20.000000000,2023-04-20 11:51:20.000000000,2023-04-20 11:45:04.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-20 09:55:20.000000000', 'files': ['gerrit/acls/openstack/openstacksdk.config', 'gerrit/acls/openstack/python-openstackclient.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a02e1ff8b4f70272548d6bd4a3b55d67ab888c6b', 'message': 'Add sdk and cli xxx-service-core group\n\nIn order to have openstack service representatives having +2 permissions\non sdk and cli to signal the change is ok from their side while still\ncontrolling their ability to gate changes create 2 new groups with only\n+2 vote right. This will help to give services wider ability to review\nand approve changes for their services while still keeping final word on\nthe sdk/cli cores side and thus avoid privileges misuse.\n\nChange-Id: Id484d75e3c742f1302dc92e23a3eb9c8a328c55c\n'}]",0,880933,a02e1ff8b4f70272548d6bd4a3b55d67ab888c6b,7,2,1,27900,,,0,"Add sdk and cli xxx-service-core group

In order to have openstack service representatives having +2 permissions
on sdk and cli to signal the change is ok from their side while still
controlling their ability to gate changes create 2 new groups with only
+2 vote right. This will help to give services wider ability to review
and approve changes for their services while still keeping final word on
the sdk/cli cores side and thus avoid privileges misuse.

Change-Id: Id484d75e3c742f1302dc92e23a3eb9c8a328c55c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/880933/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/openstacksdk.config', 'gerrit/acls/openstack/python-openstackclient.config']",2,a02e1ff8b4f70272548d6bd4a3b55d67ab888c6b,,label-Code-Review = -2..+2 group python-openstackclient-service-core,,2,0
openstack%2Fopenstack-ansible~stable%2Fzed~Ibb9dc3377a4de06af25281bf777b16faad16d261,openstack/openstack-ansible,stable/zed,Ibb9dc3377a4de06af25281bf777b16faad16d261,Gather generic masakari facts,MERGED,2023-04-19 04:30:26.000000000,2023-04-20 11:48:35.000000000,2023-04-20 11:46:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-19 04:30:26.000000000', 'files': ['playbooks/os-masakari-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5a93aebaf5661f8e4d5a618b952a0bc95ea47b5b', 'message': 'Gather generic masakari facts\n\nWith commit [1] we moved extra facts gathering to pre_tasks\nbut with that we did not enable generic facts gathering, which\nled to regression. So we cover this by ensuring that generic\nfacts are also gathered and not only extra ones.\n\n[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833\nCloses-Bug: #1979145\n\nChange-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261\n(cherry picked from commit bb4f1c7b2a46b30de8bca3e695938022efe6be89)\n'}]",2,880606,5a93aebaf5661f8e4d5a618b952a0bc95ea47b5b,12,3,1,28619,,,0,"Gather generic masakari facts

With commit [1] we moved extra facts gathering to pre_tasks
but with that we did not enable generic facts gathering, which
led to regression. So we cover this by ensuring that generic
facts are also gathered and not only extra ones.

[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833
Closes-Bug: #1979145

Change-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261
(cherry picked from commit bb4f1c7b2a46b30de8bca3e695938022efe6be89)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/06/880606/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-masakari-install.yml'],1,5a93aebaf5661f8e4d5a618b952a0bc95ea47b5b,,"- name: Gather masakari facts hosts: masakari_all gather_facts: ""{{ osa_gather_facts | default(True) }}"" tags: - always ",,6,0
openstack%2Fkolla~master~I9ceb041b806d1fb1a52305733b45bb1fec2c014c,openstack/kolla,master,I9ceb041b806d1fb1a52305733b45bb1fec2c014c,"Bump up etcd, lego and prometheus components versions to latest",NEW,2023-04-20 08:27:46.000000000,2023-04-20 11:25:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-20 08:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/82fba6e1ac1ab51769ed8dd52f5d3c5e196ea68c', 'message': 'Bump up etcd, lego and prometheus components versions to latest\n\nChange-Id: I9ceb041b806d1fb1a52305733b45bb1fec2c014c\n'}, {'number': 2, 'created': '2023-04-20 09:44:57.000000000', 'files': ['docker/prometheus/prometheus-blackbox-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-node-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-memcached-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-v2-server/Dockerfile.j2', 'docker/prometheus/prometheus-alertmanager/Dockerfile.j2', 'docker/prometheus/prometheus-cadvisor/Dockerfile.j2', 'docker/prometheus/prometheus-msteams/Dockerfile.j2', 'docker/prometheus/prometheus-ovn-exporter/Dockerfile.j2', 'docker/etcd/Dockerfile.j2', 'docker/letsencrypt/Dockerfile.j2', 'docker/prometheus/prometheus-mtail/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/60dfb32de702c9f8dd21315f365cb9d7493290a6', 'message': 'Bump up etcd, lego and prometheus components versions to latest\n\nChange-Id: I9ceb041b806d1fb1a52305733b45bb1fec2c014c\n'}]",0,880920,60dfb32de702c9f8dd21315f365cb9d7493290a6,5,1,2,22629,,,0,"Bump up etcd, lego and prometheus components versions to latest

Change-Id: I9ceb041b806d1fb1a52305733b45bb1fec2c014c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/20/880920/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/prometheus/prometheus-blackbox-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-node-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-memcached-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-v2-server/Dockerfile.j2', 'docker/prometheus/prometheus-alertmanager/Dockerfile.j2', 'docker/prometheus/prometheus-cadvisor/Dockerfile.j2', 'docker/prometheus/prometheus-msteams/Dockerfile.j2', 'docker/prometheus/prometheus-ovn-exporter/Dockerfile.j2', 'docker/etcd/Dockerfile.j2', 'docker/letsencrypt/Dockerfile.j2', 'docker/prometheus/prometheus-mtail/Dockerfile.j2']",12,82fba6e1ac1ab51769ed8dd52f5d3c5e196ea68c,,ARG prometheus_mtail_version=3.0.0-rc51,ARG prometheus_mtail_version=3.0.0-rc50,17,17
openstack%2Fkolla-ansible~master~I1d8021a1bc780449e3ca96183c6f4abaed17b382,openstack/kolla-ansible,master,I1d8021a1bc780449e3ca96183c6f4abaed17b382,Trivial fix - add int filter for rabbitmq definitions,MERGED,2023-04-19 19:28:07.000000000,2023-04-20 11:16:26.000000000,2023-04-20 11:15:16.000000000,"[{'_account_id': 13252}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 35263}]","[{'number': 1, 'created': '2023-04-19 19:28:07.000000000', 'files': ['ansible/roles/rabbitmq/templates/definitions.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d1b24a413761293f3b3827df967023853ee2d93d', 'message': 'Trivial fix - add int filter for rabbitmq definitions\n\nChange-Id: I1d8021a1bc780449e3ca96183c6f4abaed17b382\n'}]",5,880887,d1b24a413761293f3b3827df967023853ee2d93d,15,5,1,27339,,,0,"Trivial fix - add int filter for rabbitmq definitions

Change-Id: I1d8021a1bc780449e3ca96183c6f4abaed17b382
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/87/880887/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/rabbitmq/templates/definitions.json.j2'],1,d1b24a413761293f3b3827df967023853ee2d93d,," {""vhost"": ""/"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms | int }}{% endif %}}, ""priority"":0}{% if project_name == 'outward_rabbitmq' %}, {""vhost"": ""{{ murano_agent_rabbitmq_vhost }}"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms | int }}{% endif %}}, ""priority"":0}"," {""vhost"": ""/"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms }}{% endif %}}, ""priority"":0}{% if project_name == 'outward_rabbitmq' %}, {""vhost"": ""{{ murano_agent_rabbitmq_vhost }}"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms }}{% endif %}}, ""priority"":0}",2,2
openstack%2Fnova~stable%2Fyoga~Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,openstack/nova,stable/yoga,Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,Fix rescue volume-based instance,MERGED,2023-01-30 13:02:06.000000000,2023-04-20 11:10:32.000000000,2023-04-20 11:08:21.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6962}, {'_account_id': 7166}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-01-30 13:02:06.000000000', 'files': ['releasenotes/notes/rescue-volume-based-instance-c6e3fba236d90be7.yaml', 'nova/tests/functional/test_server_rescue.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4073aa51f79be54e2e6e8143666a7c1f9a00e03d', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n(cherry picked from commit 6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b)\n(cherry picked from commit d00a848a735f98b028f5930798ee69ef205c8e2e)\n'}]",3,872118,4073aa51f79be54e2e6e8143666a7c1f9a00e03d,17,10,1,20733,,,0,"Fix rescue volume-based instance

As of now, when attempting to rescue a volume-based instance
using an image without the hw_rescue_device and/or hw_rescue_bus
properties set, the rescue api call fails (as non-stable rescue
for volume-based instances are not supported) leaving the instance
in error state.

This change checks for hw_rescue_device/hw_rescue_bus image
properties before attempting to rescue and if the property
is not set, then fail with proper error message, without changing
instance state.

Related-Bug: #1978958
Closes-Bug: #1926601
Change-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1
(cherry picked from commit 6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b)
(cherry picked from commit d00a848a735f98b028f5930798ee69ef205c8e2e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/872118/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/rescue-volume-based-instance-c6e3fba236d90be7.yaml', 'nova/tests/functional/test_server_rescue.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py']",4,4073aa51f79be54e2e6e8143666a7c1f9a00e03d,lp_1978958," rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) @mock.patch('nova.objects.instance.Instance.image_meta') mock_get_cn, mock_image_meta): instance.image_meta = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) @mock.patch('nova.objects.image_meta.ImageMeta.from_image_ref') @mock.patch('nova.objects.compute_node.ComputeNode' '.get_by_host_and_nodename') @mock.patch('nova.compute.utils.is_volume_backed_instance', return_value=True) @mock.patch('nova.objects.block_device.BlockDeviceMappingList' '.get_by_instance_uuid') def test_rescue_bfv_with_required_image_properties( self, mock_get_bdms, mock_is_volume_backed, mock_get_cn, mock_image_meta_obj_from_ref): instance = self._create_instance_obj() bdms = objects.BlockDeviceMappingList(objects=[ objects.BlockDeviceMapping( boot_index=0, image_id=uuids.image_id, source_type='image', destination_type='volume', volume_type=None, snapshot_id=None, volume_id=uuids.volume_id, volume_size=None)]) rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) with test.nested( mock.patch.object(self.compute_api.placementclient, 'get_provider_traits'), mock.patch.object(self.compute_api.volume_api, 'get'), mock.patch.object(self.compute_api.volume_api, 'check_attached'), mock.patch.object(instance, 'save'), mock.patch.object(self.compute_api, '_record_action_start'), mock.patch.object(self.compute_api.compute_rpcapi, 'rescue_instance') ) as ( mock_get_traits, mock_get_volume, mock_check_attached, mock_instance_save, mock_record_start, mock_rpcapi_rescue ): # Mock out the returned compute node, image_meta, bdms and volume mock_image_meta_obj_from_ref.return_value = rescue_image_meta_obj mock_get_bdms.return_value = bdms mock_get_volume.return_value = mock.sentinel.volume mock_get_cn.return_value = mock.Mock(uuid=uuids.cn) # Ensure the required trait is returned, allowing BFV rescue mock_trait_info = mock.Mock(traits=[ot.COMPUTE_RESCUE_BFV]) mock_get_traits.return_value = mock_trait_info # Try to rescue the instance self.compute_api.rescue(self.context, instance, rescue_image_ref=uuids.rescue_image_id, allow_bfv_rescue=True) # Assert all of the calls made in the compute API mock_get_bdms.assert_called_once_with(self.context, instance.uuid) mock_get_volume.assert_called_once_with( self.context, uuids.volume_id) mock_check_attached.assert_called_once_with( self.context, mock.sentinel.volume) mock_is_volume_backed.assert_called_once_with( self.context, instance, bdms) mock_get_cn.assert_called_once_with( self.context, instance.host, instance.node) mock_get_traits.assert_called_once_with(self.context, uuids.cn) mock_instance_save.assert_called_once_with( expected_task_state=[None]) mock_record_start.assert_called_once_with( self.context, instance, instance_actions.RESCUE) mock_rpcapi_rescue.assert_called_once_with( self.context, instance=instance, rescue_password=None, rescue_image_ref=uuids.rescue_image_id, clean_shutdown=True) # Assert that the instance task state as set in the compute API self.assertEqual(task_states.RESCUING, instance.task_state) @mock.patch('nova.objects.image_meta.ImageMeta.from_image_ref') @mock.patch('nova.compute.utils.is_volume_backed_instance', return_value=True) @mock.patch('nova.objects.block_device.BlockDeviceMappingList' '.get_by_instance_uuid') def test_rescue_bfv_without_required_image_properties( self, mock_get_bdms, mock_is_volume_backed, mock_image_meta_obj_from_ref): instance = self._create_instance_obj() bdms = objects.BlockDeviceMappingList(objects=[ objects.BlockDeviceMapping( boot_index=0, image_id=uuids.image_id, source_type='image', destination_type='volume', volume_type=None, snapshot_id=None, volume_id=uuids.volume_id, volume_size=None)]) rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {} }) with test.nested( mock.patch.object(self.compute_api.volume_api, 'get'), mock.patch.object(self.compute_api.volume_api, 'check_attached'), ) as ( mock_get_volume, mock_check_attached ): # Mock out the returned bdms, volume and image_meta mock_get_bdms.return_value = bdms mock_get_volume.return_value = mock.sentinel.volume mock_image_meta_obj_from_ref.return_value = rescue_image_meta_obj # Assert that any attempt to rescue a bfv instance on a compute # node that does not report the COMPUTE_RESCUE_BFV trait fails and # raises InstanceNotRescuable self.assertRaises(exception.InstanceNotRescuable, self.compute_api.rescue, self.context, instance, rescue_image_ref=None, allow_bfv_rescue=True) # Assert the calls made in the compute API prior to the failure mock_get_bdms.assert_called_once_with(self.context, instance.uuid) mock_get_volume.assert_called_once_with( self.context, uuids.volume_id) mock_check_attached.assert_called_once_with( self.context, mock.sentinel.volume) mock_is_volume_backed.assert_called_once_with( self.context, instance, bdms) ", rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({}) mock_get_cn):,220,11
openstack%2Fneutron-tempest-plugin~master~I0c5a8d240c46372d84a0bdb3ef78ad74dbca75a2,openstack/neutron-tempest-plugin,master,I0c5a8d240c46372d84a0bdb3ef78ad74dbca75a2,Don't run stadium related jobs when scenario tests are changed,MERGED,2023-04-20 08:57:55.000000000,2023-04-20 11:08:26.000000000,2023-04-20 11:08:26.000000000,"[{'_account_id': 8313}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-20 08:57:55.000000000', 'files': ['zuul.d/master_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/4330ca08687772aaa50867cc48668e2a17098aaf', 'message': ""Don't run stadium related jobs when scenario tests are changed\n\nThere is no need to run all scenario related jobs on patches which\ntouches only files with tests in neutron_tempest_plugin/scenario module.\n\nChange-Id: I0c5a8d240c46372d84a0bdb3ef78ad74dbca75a2\n""}]",1,880928,4330ca08687772aaa50867cc48668e2a17098aaf,8,4,1,11975,,,0,"Don't run stadium related jobs when scenario tests are changed

There is no need to run all scenario related jobs on patches which
touches only files with tests in neutron_tempest_plugin/scenario module.

Change-Id: I0c5a8d240c46372d84a0bdb3ef78ad74dbca75a2
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/28/880928/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/master_jobs.yaml'],1,4330ca08687772aaa50867cc48668e2a17098aaf,improve-neutron-ci, - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$ - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$ - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$ - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$ - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$ - ^neutron_tempest_plugin/scenario/admin/.*$ - ^neutron_tempest_plugin/scenario/test_.*$,,12,0
openstack%2Fceilometer~stable%2Fyoga~I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94,openstack/ceilometer,stable/yoga,I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94,Add vanity names to notification samples,NEW,2023-04-20 05:06:12.000000000,2023-04-20 11:07:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-20 05:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8e7488c630799032d861643258aaca5064bd9dbc', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nConflicts:\n\tceilometer/tests/unit/meter/test_notifications.py\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n(cherry picked from commit 6e339d3e74df5460d372b3e2abce27664ddb1100)\n(cherry picked from commit d9a61da15033a55b5730974a9c6a4868c1d98d0f)\n(cherry picked from commit 600dbfab1e227efc16b03b693d08354eaf1d0f98)\n'}, {'number': 2, 'created': '2023-04-20 09:53:12.000000000', 'files': ['ceilometer/cache_utils.py', 'ceilometer/meter/notifications.py', 'ceilometer/sample.py', 'ceilometer/tests/unit/meter/test_notifications.py', 'ceilometer/polling/manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5191f9466a7a36e3b9c2cc48227cfe40d234bd9f', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nConflicts:\n\tceilometer/tests/unit/meter/test_notifications.py\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n(cherry picked from commit 6e339d3e74df5460d372b3e2abce27664ddb1100)\n(cherry picked from commit d9a61da15033a55b5730974a9c6a4868c1d98d0f)\n(cherry picked from commit 600dbfab1e227efc16b03b693d08354eaf1d0f98)\n'}]",0,880905,5191f9466a7a36e3b9c2cc48227cfe40d234bd9f,5,1,2,32240,,,0,"Add vanity names to notification samples

This change adds ""project_name"" and ""user_name"" fields to the
polling samples created from notifications of ""event_type"".

Also move caching helper functions into ""ceilometer/cache_utils.py""
to make them accessible throughout the project.

Conflicts:
	ceilometer/tests/unit/meter/test_notifications.py

Change-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94
(cherry picked from commit 6e339d3e74df5460d372b3e2abce27664ddb1100)
(cherry picked from commit d9a61da15033a55b5730974a9c6a4868c1d98d0f)
(cherry picked from commit 600dbfab1e227efc16b03b693d08354eaf1d0f98)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/05/880905/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cache_utils.py', 'ceilometer/meter/notifications.py', 'ceilometer/sample.py', 'ceilometer/tests/unit/meter/test_notifications.py', 'ceilometer/polling/manager.py']",5,8e7488c630799032d861643258aaca5064bd9dbc,enhanced_metrics-stable/yoga," cache_utils.resolve_uuid_from_cache( self.manager.conf, ""projects"", sample.project_id cache_utils.resolve_uuid_from_cache( self.manager.conf, ""users"", sample.user_id"," def resolve_uuid_from_cache(self, attr, uuid): if self.cache_client: name = self.cache_client.get(uuid) if name: return name # empty cache_client means either caching is not enabled or # there was an error configuring cache name = self.resolve_uuid_from_keystone(attr, uuid) self.cache_client.set(uuid, name) return name # Retrieve project and user names from Keystone only # if ceilometer doesn't have a caching backend return self.resolve_uuid_from_keystone(attr, uuid) def resolve_uuid_from_keystone(self, attr, uuid): try: return getattr(self.ks_client, attr).get(uuid).name except AttributeError as e: LOG.warning(""Found '%s' while resolving uuid %s to name"", e, uuid) except ka_exceptions.NotFound as e: LOG.warning(e.message) self.resolve_uuid_from_cache( ""projects"", sample.project_id self.resolve_uuid_from_cache( ""users"", sample.user_id",88,46
openstack%2Fopenstack-ansible-ceph_client~stable%2Fzed~I176fbcd4901dfacd4b608fac4d4fbd256d263b2a,openstack/openstack-ansible-ceph_client,stable/zed,I176fbcd4901dfacd4b608fac4d4fbd256d263b2a,Improve regexp for fetching nova secret from files,MERGED,2023-04-14 13:26:24.000000000,2023-04-20 10:57:35.000000000,2023-04-20 10:56:33.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 13:26:24.000000000', 'files': ['tasks/ceph_get_keyrings_from_files.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/e1336af370356729cd95a54bc2586b71518da7d3', 'message': 'Improve regexp for fetching nova secret from files\n\nAt the moment regexp we have does require keyring to contain only\nkey option. If that is full ceph authx file that does also contain\ncaps, regexp will grab them as well, which will result in a play failure\n\nThis patch does improve regexp to grab only key regardless of all other\ncontent that can be present in the file.\n\nChange-Id: I176fbcd4901dfacd4b608fac4d4fbd256d263b2a\n(cherry picked from commit f69d7e922ed2de8040267a7579e450aa7ab76340)\n'}]",0,880493,e1336af370356729cd95a54bc2586b71518da7d3,8,3,1,25023,,,0,"Improve regexp for fetching nova secret from files

At the moment regexp we have does require keyring to contain only
key option. If that is full ceph authx file that does also contain
caps, regexp will grab them as well, which will result in a play failure

This patch does improve regexp to grab only key regardless of all other
content that can be present in the file.

Change-Id: I176fbcd4901dfacd4b608fac4d4fbd256d263b2a
(cherry picked from commit f69d7e922ed2de8040267a7579e450aa7ab76340)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/93/880493/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ceph_get_keyrings_from_files.yml'],1,e1336af370356729cd95a54bc2586b71518da7d3,," set_fact : ceph_nova_secret: stdout: ""{{ (ceph_client_keys[nova_ceph_client] | regex_search('.*^\\s*key\\s*=\\s*(.*)$.*', '\\1', multiline=True))[0] }}"""," command : echo ""{{ ceph_client_keys[nova_ceph_client] | regex_replace('^.*\n.*= (.*)', '\1') }}"" # noqa 206 register: ceph_nova_secret changed_when: false",3,3
openstack%2Ftripleo-ansible~stable%2Fwallaby~Iafa2a4399edad51770247dc76e6871e22022055d,openstack/tripleo-ansible,stable/wallaby,Iafa2a4399edad51770247dc76e6871e22022055d,Always recreate puppet containers,MERGED,2023-04-17 10:18:46.000000000,2023-04-20 10:44:12.000000000,2023-04-20 10:43:13.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-04-17 10:18:46.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/container_puppet_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/50d378325335c5cfcffd430b76f034baa5eef50c', 'message': 'Always recreate puppet containers\n\nPodman module just start an existing container if the container already\nexists and its definition is not changed. This causes a problem with\npuppet containers because detach: false does not take effect when\nrestarting an existing container, which makes the return code from\npuppet ignored.\n\nThis restores the previous behavior to always recreated puppet\ncontainers so that return codes from puppet executions are evaluated.\n\nResolves: rhbz#2185163\nChange-Id: Iafa2a4399edad51770247dc76e6871e22022055d\n'}]",0,880619,50d378325335c5cfcffd430b76f034baa5eef50c,8,3,1,9816,,,0,"Always recreate puppet containers

Podman module just start an existing container if the container already
exists and its definition is not changed. This causes a problem with
puppet containers because detach: false does not take effect when
restarting an existing container, which makes the return code from
puppet ignored.

This restores the previous behavior to always recreated puppet
containers so that return codes from puppet executions are evaluated.

Resolves: rhbz#2185163
Change-Id: Iafa2a4399edad51770247dc76e6871e22022055d
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/19/880619/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/container_puppet_config.py'],1,50d378325335c5cfcffd430b76f034baa5eef50c,," # force recreating the container so that detach: False always takes # effect. 'recreate': True,",,3,0
openstack%2Fopenstack-ansible-os_octavia~master~I6ea6ab4ec1c28a3b354d40f6744434eefb05fcfe,openstack/openstack-ansible-os_octavia,master,I6ea6ab4ec1c28a3b354d40f6744434eefb05fcfe,Change default CIDR for security_group,MERGED,2023-04-14 19:25:21.000000000,2023-04-20 10:43:13.000000000,2023-04-20 10:41:20.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32238}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 19:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/b9fdc8b578c97cdd240b488946eaef76f2e9461a', 'message': ""Change default CIDR for security_group\n\nAt the moment security group allows to access Amphora SSH/API\nfrom any network which is insecure. We're changing default for\nsecurity groups to allow access only from Octavia Management\nnetwork.\n\nChange-Id: I6ea6ab4ec1c28a3b354d40f6744434eefb05fcfe\n""}, {'number': 2, 'created': '2023-04-19 09:51:08.000000000', 'files': ['releasenotes/notes/octavia_security_group_rule_cidr_default-dbf0cdfd17731a73.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/cea4f2e358f778d6a7ad77dcac627482f295459e', 'message': ""Change default CIDR for security_group\n\nAt the moment security group allows to access Amphora SSH/API\nfrom any network which is insecure. We're changing default for\nsecurity groups to allow access only from Octavia Management\nnetwork.\n\nChange-Id: I6ea6ab4ec1c28a3b354d40f6744434eefb05fcfe\n""}]",0,880544,cea4f2e358f778d6a7ad77dcac627482f295459e,12,4,2,28619,,,0,"Change default CIDR for security_group

At the moment security group allows to access Amphora SSH/API
from any network which is insecure. We're changing default for
security groups to allow access only from Octavia Management
network.

Change-Id: I6ea6ab4ec1c28a3b354d40f6744434eefb05fcfe
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/44/880544/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/octavia_security_group_rule_cidr_default-dbf0cdfd17731a73.yaml', 'defaults/main.yml']",2,b9fdc8b578c97cdd240b488946eaef76f2e9461a,osa/ansible-collection-2,"octavia_security_group_rule_cidr: ""{{ octavia_management_net_subnet_cidr }}""",octavia_security_group_rule_cidr:,8,1
openstack%2Fopenstack-ansible-os_octavia~master~I280c064b4d93bcd78092f02a928d5d6dfb4fda68,openstack/openstack-ansible-os_octavia,master,I280c064b4d93bcd78092f02a928d5d6dfb4fda68,Do not limit IP prefix for DHCP rule,MERGED,2023-04-19 09:50:54.000000000,2023-04-20 10:42:23.000000000,2023-04-20 10:41:18.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-19 09:50:54.000000000', 'files': ['tasks/octavia_security_group.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/7c46b9460da678eb4199cbe0db4fcacaf48f44e6', 'message': ""Do not limit IP prefix for DHCP rule\n\nIn case it's needed to limit access to DHCP servers, rules must be\nway more complex then this one, since DHCP uses broadcast.\n\nTo avoid complexity, let's just avoid defining remote_ip_prefix\nthat allows egress traffic for DHCP.\n\nChange-Id: I280c064b4d93bcd78092f02a928d5d6dfb4fda68\n""}]",0,880804,7c46b9460da678eb4199cbe0db4fcacaf48f44e6,8,3,1,28619,,,0,"Do not limit IP prefix for DHCP rule

In case it's needed to limit access to DHCP servers, rules must be
way more complex then this one, since DHCP uses broadcast.

To avoid complexity, let's just avoid defining remote_ip_prefix
that allows egress traffic for DHCP.

Change-Id: I280c064b4d93bcd78092f02a928d5d6dfb4fda68
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/04/880804/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/octavia_security_group.yml'],1,7c46b9460da678eb4199cbe0db4fcacaf48f44e6,,," remote_ip_prefix: ""{{ octavia_security_group_rule_cidr }}""",0,1
openstack%2Fopenstack-helm-infra~master~I017781bd4df836949396c34f8ef5e6bd0f07efab,openstack/openstack-helm-infra,master,I017781bd4df836949396c34f8ef5e6bd0f07efab,Fix ovn db persistence issue,MERGED,2023-04-18 08:02:00.000000000,2023-04-20 10:33:03.000000000,2023-04-20 10:32:05.000000000,"[{'_account_id': 3009}, {'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2023-04-18 08:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/257f82aef706deb1b41530c338160be6705bdb8a', 'message': ""Fix ovn db persistence issue\n\nChange ovn db volume default mount to '/var/lib/ovn', as ovn(sb or nb)\ndefault use this directory.\n\nChange-Id: I017781bd4df836949396c34f8ef5e6bd0f07efab\n""}, {'number': 2, 'created': '2023-04-18 08:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/60aeff911dea6150e8b9a1d810fdb4a1607f791e', 'message': ""Fix ovn db persistence issue\n\nChange ovn db volume default mount to '/var/lib/ovn', as ovn(sb or nb)\ndefault use this directory.\n\nCloses-Bug: #2016844\n\nChange-Id: I017781bd4df836949396c34f8ef5e6bd0f07efab\n""}, {'number': 3, 'created': '2023-04-18 09:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf67eaa3623cf2bfd585c666c37bf96e46329773', 'message': ""Fix ovn db persistence issue\n\nChange ovn db volume default mount to '/var/lib/ovn', as ovn(sb or nb)\ndefault use this directory.\n\nCloses-Bug: #2016844\n\nChange-Id: I017781bd4df836949396c34f8ef5e6bd0f07efab\n""}, {'number': 4, 'created': '2023-04-19 01:41:35.000000000', 'files': ['releasenotes/notes/ovn.yaml', 'ovn/templates/statefulset-nb-db.yaml', 'ovn/Chart.yaml', 'ovn/templates/statefulset-sb-db.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7b8d459d14a751021265cd29dbe9920ceac71f3a', 'message': ""Fix ovn db persistence issue\n\nChange ovn db volume default mount to '/var/lib/ovn', as ovn(sb or nb)\ndefault use this directory.\n\nCloses-Bug: #2016844\n\nChange-Id: I017781bd4df836949396c34f8ef5e6bd0f07efab\n""}]",2,880520,7b8d459d14a751021265cd29dbe9920ceac71f3a,18,5,4,35937,,,0,"Fix ovn db persistence issue

Change ovn db volume default mount to '/var/lib/ovn', as ovn(sb or nb)
default use this directory.

Closes-Bug: #2016844

Change-Id: I017781bd4df836949396c34f8ef5e6bd0f07efab
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/20/880520/4 && git format-patch -1 --stdout FETCH_HEAD,"['ovn/templates/statefulset-nb-db.yaml', 'ovn/templates/statefulset-sb-db.yaml']",2,257f82aef706deb1b41530c338160be6705bdb8a,bug/2016844, mountPath: /var/lib/ovn, mountPath: /data/db,2,2
openstack%2Fcharm-horizon-k8s~main~Ia41efbcbc76574c35bdbcf5bf8082471d528586a,openstack/charm-horizon-k8s,main,Ia41efbcbc76574c35bdbcf5bf8082471d528586a,Template port from database location,MERGED,2023-04-19 11:27:00.000000000,2023-04-20 10:25:38.000000000,2023-04-20 09:24:44.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 11:27:00.000000000', 'files': ['src/templates/local_settings.py.j2'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/baefba763cd787c50d6cc32f3e03753d178bd504', 'message': 'Template port from database location\n\nMySQL Router charm provided endpoint does not use the default MySQL port\n(3306), therefore templating the port is mandatory.\n\nChange-Id: Ia41efbcbc76574c35bdbcf5bf8082471d528586a\n'}]",0,880812,baefba763cd787c50d6cc32f3e03753d178bd504,8,3,1,35761,,,0,"Template port from database location

MySQL Router charm provided endpoint does not use the default MySQL port
(3306), therefore templating the port is mandatory.

Change-Id: Ia41efbcbc76574c35bdbcf5bf8082471d528586a
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/12/880812/1 && git format-patch -1 --stdout FETCH_HEAD,['src/templates/local_settings.py.j2'],1,baefba763cd787c50d6cc32f3e03753d178bd504,template-port," 'PORT': '{{ database.database_host.split(':')[1] }}',",,1,0
openstack%2Freleases~master~If22ee1669b44c739eb4393693b13f4a9b07e4f57,openstack/releases,master,If22ee1669b44c739eb4393693b13f4a9b07e4f57,Add Oslo specific dates for Bobcat schedule,MERGED,2023-04-14 09:08:17.000000000,2023-04-20 09:51:00.000000000,2023-04-20 09:51:00.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 09:08:17.000000000', 'files': ['doc/source/bobcat/schedule.yaml', 'doc/source/bobcat/schedule.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/cea9048240e4cee9ac856d026b40de5461e0380e', 'message': 'Add Oslo specific dates for Bobcat schedule\n\nChange-Id: If22ee1669b44c739eb4393693b13f4a9b07e4f57\n'}]",2,880467,cea9048240e4cee9ac856d026b40de5461e0380e,11,3,1,28522,,,0,"Add Oslo specific dates for Bobcat schedule

Change-Id: If22ee1669b44c739eb4393693b13f4a9b07e4f57
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/880467/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/bobcat/schedule.yaml', 'doc/source/bobcat/schedule.rst']",2,cea9048240e4cee9ac856d026b40de5461e0380e,bobcat_oslo," Oslo ---- .. _b-oslo-feature-freeze: Oslo Feature Freeze ^^^^^^^^^^^^^^^^^^^ All new Oslo features must be proposed and substantially complete, with unit tests by the end of the week.",,13,0
openstack%2Freleases~master~I48f7ee7a7f2e376f889cca687bcd2b3d7205265b,openstack/releases,master,I48f7ee7a7f2e376f889cca687bcd2b3d7205265b,[manila][bobcat] Add project tracking schedule,MERGED,2023-04-10 19:40:15.000000000,2023-04-20 09:49:32.000000000,2023-04-20 09:49:32.000000000,"[{'_account_id': 308}, {'_account_id': 16643}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-10 19:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e5f45a50e8631790662109812c3dd6a5ff5bb28b', 'message': '[manila][bobcat] Add project tracking schedule\n\nAdd manila specific deadlines for maintainers to adhere to.\n\nChange-Id: I48f7ee7a7f2e376f889cca687bcd2b3d7205265b\n'}, {'number': 2, 'created': '2023-04-10 21:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/56e298d471c837acb0bb6a34742b0dc3fce636a5', 'message': '[manila][bobcat] Add project tracking schedule\n\nAdd manila specific deadlines for maintainers to adhere to.\n\nChange-Id: I48f7ee7a7f2e376f889cca687bcd2b3d7205265b\n'}, {'number': 3, 'created': '2023-04-13 19:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3700f28b35e31757ebad122232afae4dc1fa7270', 'message': '[manila][bobcat] Add project tracking schedule\n\nAdd manila specific deadlines for maintainers to adhere to.\n\nChange-Id: I48f7ee7a7f2e376f889cca687bcd2b3d7205265b\n'}, {'number': 4, 'created': '2023-04-13 19:55:00.000000000', 'files': ['doc/source/bobcat/schedule.yaml', 'doc/source/bobcat/schedule.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/be2c09bb3ca724cad6c5189ed5bed437e28109d9', 'message': '[manila][bobcat] Add project tracking schedule\n\nAdd manila specific deadlines for maintainers to adhere to.\n\nChange-Id: I48f7ee7a7f2e376f889cca687bcd2b3d7205265b\n'}]",6,879998,be2c09bb3ca724cad6c5189ed5bed437e28109d9,21,4,4,29632,,,0,"[manila][bobcat] Add project tracking schedule

Add manila specific deadlines for maintainers to adhere to.

Change-Id: I48f7ee7a7f2e376f889cca687bcd2b3d7205265b
",git fetch https://review.opendev.org/openstack/releases refs/changes/98/879998/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/bobcat/schedule.yaml', 'doc/source/bobcat/schedule.rst']",2,e5f45a50e8631790662109812c3dd6a5ff5bb28b,manila," Manila ------ .. _b-manila-spec-freeze: Manila Spec Freeze ^^^^^^^^^^^^^^^^^^ All Manila specs targeted to Bobcat must be approved by the end of the week. .. _b-manila-new-driver-deadline: Manila New Driver Deadline ^^^^^^^^^^^^^^^^^^^^^^^^^^ By the end of the week all new backend drivers for Manila must be substantially complete, with unit tests, and passing 3rd party CI. Drivers do not have to actually merge until feature freeze. .. _b-manila-fpfreeze: Manila Feature Proposal Freeze ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ All new Manila features must be proposed and substantially completed, with unit, functional and integration tests by the end of the week. .. _b-manila-hackathon: Manila Hackathon ^^^^^^^^^^^^^^^^ Manila community event promoted in order to tackle the implementation of features or tech debt areas. .. _b-manila-bugsquash: Manila Bugsquash ^^^^^^^^^^^^^^^^ Manila community event promoted in order to fast-track the closure of bugs.",,51,0
openstack%2Freleases~master~I25980e149389fd7650d77dcda835007a387d29c6,openstack/releases,master,I25980e149389fd7650d77dcda835007a387d29c6,[nova] Transition Xena to EM,MERGED,2023-03-29 12:58:38.000000000,2023-04-20 09:49:30.000000000,2023-04-20 09:49:30.000000000,"[{'_account_id': 7166}, {'_account_id': 16207}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-03-29 12:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/83cd9aabbff1e4ed9e3d81624d80b9a94a0efa10', 'message': '[nova] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I25980e149389fd7650d77dcda835007a387d29c6\n'}, {'number': 2, 'created': '2023-04-13 11:28:22.000000000', 'files': ['deliverables/xena/placement.yaml', 'deliverables/xena/nova.yaml', 'deliverables/xena/os-vif.yaml', 'deliverables/xena/python-novaclient.yaml', 'deliverables/xena/osc-placement.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/30697d66f4d920045fb8653a76d7bb6c74e2747f', 'message': '[nova] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I25980e149389fd7650d77dcda835007a387d29c6\n'}]",4,878860,30697d66f4d920045fb8653a76d7bb6c74e2747f,16,6,2,17685,,,0,"[nova] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I25980e149389fd7650d77dcda835007a387d29c6
",git fetch https://review.opendev.org/openstack/releases refs/changes/60/878860/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/nova.yaml', 'deliverables/xena/placement.yaml', 'deliverables/xena/os-vif.yaml', 'deliverables/xena/python-novaclient.yaml', 'deliverables/xena/osc-placement.yaml']",5,83cd9aabbff1e4ed9e3d81624d80b9a94a0efa10,xena-em, - version: xena-em projects: - repo: openstack/osc-placement hash: 0ea8f1b05d4aa4a6f144adff08771f5b84bda479,,20,0
openstack%2Freleases~master~I4a3b4c5051cd888d824c64c9f93a6bb4e6bd10e5,openstack/releases,master,I4a3b4c5051cd888d824c64c9f93a6bb4e6bd10e5,[horizon] Transition Xena to EM,MERGED,2023-03-29 13:09:39.000000000,2023-04-20 09:49:28.000000000,2023-04-20 09:49:28.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-03-29 13:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/05d6d1f6ded9fdf0865fa66548c1fb1093a79967', 'message': '[horizon] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I4a3b4c5051cd888d824c64c9f93a6bb4e6bd10e5\n'}, {'number': 2, 'created': '2023-04-13 11:29:57.000000000', 'files': ['deliverables/xena/horizon.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c06f6fc2a2ef64beeaffcb3c10b5809ed9e959b0', 'message': '[horizon] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I4a3b4c5051cd888d824c64c9f93a6bb4e6bd10e5\n'}]",4,878896,c06f6fc2a2ef64beeaffcb3c10b5809ed9e959b0,16,4,2,17685,,,0,"[horizon] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I4a3b4c5051cd888d824c64c9f93a6bb4e6bd10e5
",git fetch https://review.opendev.org/openstack/releases refs/changes/96/878896/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/horizon.yaml'],1,05d6d1f6ded9fdf0865fa66548c1fb1093a79967,xena-em, - version: xena-em projects: - repo: openstack/horizon hash: 78c8c811a3dfea12f87ccad95512f58bb980681e,,4,0
openstack%2Ftripleo-ansible~stable%2Fwallaby~I34537db460ff5aaba93da7e104262e26e64cbb1a,openstack/tripleo-ansible,stable/wallaby,I34537db460ff5aaba93da7e104262e26e64cbb1a,Stop using ceph/daemon entrypoint,MERGED,2023-04-14 17:25:02.000000000,2023-04-20 09:42:52.000000000,2023-04-20 09:42:52.000000000,"[{'_account_id': 6796}, {'_account_id': 16643}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 30025}, {'_account_id': 32704}, {'_account_id': 34598}]","[{'number': 1, 'created': '2023-04-14 17:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6317775930be1e9108158ec3c809918b6189e1e0', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}, {'number': 2, 'created': '2023-04-17 10:39:25.000000000', 'files': ['tripleo_ansible/roles/tripleo_cephadm/defaults/main.yml', 'tripleo_ansible/roles/tripleo_cephadm/templates/ceph-nfs.service.j2', 'tripleo_ansible/roles/tripleo_cephadm/tasks/ganesha/distribute_keys.yaml', 'tripleo_ansible/roles/tripleo_cephadm/tasks/nfs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1ec67c34bf2377c07cbdf2154b00466662e0d105', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n(cherry picked from commit a23795e83bbae8d52d9a47570a74d1e509bdc2f1)\n'}]",4,880497,1ec67c34bf2377c07cbdf2154b00466662e0d105,17,9,2,25402,,,0,"Stop using ceph/daemon entrypoint

Due to the recent Ceph 6 (Quincy) container image refactoring,
the old entrypoint is no longer available.
However, the ceph-nfs systemd unit should support both Pacific
and Quincy releases.
This patch introduces a task that is able to detect the version
provided by the ceph container in the Heat stack and renders the
systemd unit accordingly.

Change-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a
(cherry picked from commit a23795e83bbae8d52d9a47570a74d1e509bdc2f1)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/97/880497/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_cephadm/defaults/main.yml', 'tripleo_ansible/roles/tripleo_cephadm/templates/ceph-nfs.service.j2', 'tripleo_ansible/roles/tripleo_cephadm/tasks/nfs.yaml']",3,6317775930be1e9108158ec3c809918b6189e1e0,ganesha_ceph6,"- name: Get Ceph version command: ""{{ tripleo_cephadm_container_cli }} run --rm --entrypoint=ceph {{ ceph_container }} -v"" register: ceph_version vars: ceph_container: ""{{ tripleo_cephadm_container_ns }}/{{ tripleo_cephadm_container_image }}:{{ tripleo_cephadm_container_tag }}"" tripleo_cephadm_ceph_version: ""{{ ceph_version.stdout.split(' ')[2] }}""",,17,1
openstack%2Fovn-bgp-agent~master~I2416393a3c45f2424aefd342380d7f9e07df9123,openstack/ovn-bgp-agent,master,I2416393a3c45f2424aefd342380d7f9e07df9123,Add protection from pyroute crashed,MERGED,2023-04-14 08:28:49.000000000,2023-04-20 09:30:17.000000000,2023-04-20 09:30:17.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-04-14 08:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/9207ff6884c86dce01b2dd72ae121409d6c3e4a9', 'message': 'Add protection from pyroute crashed\n\nIt may happen that if pyroute crashed with a dump interrupted,\nand the exception is not properly handled, the agent will stop\nprocessing further events\n\nChange-Id: I2416393a3c45f2424aefd342380d7f9e07df9123\n'}, {'number': 2, 'created': '2023-04-14 14:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/b1d47f2eb160a79eb39156db03d41c2b2eb9fc47', 'message': 'Add protection from pyroute crashed\n\nIt may happen that if pyroute crashed with a dump interrupted,\nand the exception is not properly handled, the agent will stop\nprocessing further events\n\nChange-Id: I2416393a3c45f2424aefd342380d7f9e07df9123\n'}, {'number': 3, 'created': '2023-04-14 15:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/792e529a57db60afae339abb31af6fb58f7ddbab', 'message': 'Add protection from pyroute crashed\n\nIt may happen that if pyroute crashed with a dump interrupted,\nand the exception is not properly handled, the agent will stop\nprocessing further events\n\nChange-Id: I2416393a3c45f2424aefd342380d7f9e07df9123\n'}, {'number': 4, 'created': '2023-04-20 09:00:41.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/3d45f71476b97f91a88975b97a858e5feaacfc80', 'message': 'Add protection from pyroute crashed\n\nIt may happen that if pyroute crashed with a dump interrupted,\nand the exception is not properly handled, the agent will stop\nprocessing further events\n\nChange-Id: I2416393a3c45f2424aefd342380d7f9e07df9123\n'}]",2,879849,3d45f71476b97f91a88975b97a858e5feaacfc80,15,3,4,23567,,,0,"Add protection from pyroute crashed

It may happen that if pyroute crashed with a dump interrupted,
and the exception is not properly handled, the agent will stop
processing further events

Change-Id: I2416393a3c45f2424aefd342380d7f9e07df9123
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/49/879849/4 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py']",2,9207ff6884c86dce01b2dd72ae121409d6c3e4a9,nb_driver," try: if wire_utils.wire_provider_port( self.ovn_routing_tables_routes, port_ips, bridge_device, bridge_vlan, self.ovn_routing_tables, proxy_cidrs): # Expose the IP now that it is connected bgp_utils.announce_ips(port_ips) for ip in port_ips: self._exposed_ips.setdefault(logical_switch, {}).update( {ip: {'bridge_device': bridge_device, 'bridge_vlan': bridge_vlan}}) except Exception as e: LOG.exception(""Unexpected exception while wiring provider port: "" ""%s"", e) return False try: wire_utils.unwire_provider_port( self.ovn_routing_tables_routes, port_ips, bridge_device, bridge_vlan, self.ovn_routing_tables, proxy_cidrs) except Exception as e: LOG.exception(""Unexpected exception while unwiring provider port: "" ""%s"", e)"," if wire_utils.wire_provider_port( self.ovn_routing_tables_routes, port_ips, bridge_device, bridge_vlan, self.ovn_routing_tables, proxy_cidrs): # Expose the IP now that it is connected bgp_utils.announce_ips(port_ips) for ip in port_ips: self._exposed_ips.setdefault(logical_switch, {}).update( {ip: {'bridge_device': bridge_device, 'bridge_vlan': bridge_vlan}}) wire_utils.unwire_provider_port( self.ovn_routing_tables_routes, port_ips, bridge_device, bridge_vlan, self.ovn_routing_tables, proxy_cidrs)",56,29
openstack%2Fkolla-ansible~master~Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395,openstack/kolla-ansible,master,Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395,ansible: bump min to 2.13 and max to 2.14,MERGED,2023-03-16 16:34:08.000000000,2023-04-20 09:26:11.000000000,2023-04-19 01:26:28.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}, {'_account_id': 24072}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-03-16 16:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c57c966532bd5b54976a93df383f20fc25dc8332', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 2, 'created': '2023-03-17 09:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d10c9280fc6c6f31669e4f043b81a1f5d4e3363f', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 3, 'created': '2023-03-22 11:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1771f5c13718849276de794155c5728ececf151c', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 4, 'created': '2023-03-22 11:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4193d735f3485e7f86d720bd09e6a7153872e3a3', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 5, 'created': '2023-03-29 11:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d41e86d5bbe6c12ea1ed3eb8d73eeeb52a0857d1', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 6, 'created': '2023-04-06 14:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/50de1b5d7df127be4b94b03ae15983bf619274a6', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}, {'number': 7, 'created': '2023-04-13 14:10:28.000000000', 'files': ['tests/run.yml', 'doc/source/user/quickstart.rst', 'doc/source/user/virtual-environments.rst', 'releasenotes/notes/ansible-2.14-d83c5ce197321353.yaml', 'tools/kolla-ansible', 'ansible/roles/prechecks/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9867060b6b3bd36aad121b53b9e5dddfca8a8e4c', 'message': 'ansible: bump min to 2.13 and max to 2.14\n\nChange-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395\n'}]",11,877697,9867060b6b3bd36aad121b53b9e5dddfca8a8e4c,52,5,7,22629,,,0,"ansible: bump min to 2.13 and max to 2.14

Change-Id: Ibc9cc91f64b0450de3cae6e2830b4ff2c52c0395
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/97/877697/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/run.yml', 'releasenotes/notes/ansible-2.14-d83c5ce197321353.yaml', 'tools/kolla-ansible', 'ansible/roles/prechecks/vars/main.yml']",4,c57c966532bd5b54976a93df383f20fc25dc8332,,ansible_version_min: '2.13' ansible_version_max: '2.14',ansible_version_min: '2.12' ansible_version_max: '2.13',13,8
openstack%2Fovn-bgp-agent~master~I00f4c6838865a75136223b98c9770796cc30f3af,openstack/ovn-bgp-agent,master,I00f4c6838865a75136223b98c9770796cc30f3af,Fix error in NB DB watcher that triggered wrong events,MERGED,2023-04-14 10:28:43.000000000,2023-04-20 09:24:56.000000000,2023-04-20 09:24:56.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-04-14 10:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/3375e3a49c4b15fe3bc1055bc91332f554810942', 'message': 'Fix error in NB DB watcher that triggered wrong events\n\nChange-Id: I00f4c6838865a75136223b98c9770796cc30f3af\n'}, {'number': 2, 'created': '2023-04-14 12:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/6c23b33357cde838e6bc4e02ae8bc0aa52b6d890', 'message': 'Fix error in NB DB watcher that triggered wrong events\n\nChange-Id: I00f4c6838865a75136223b98c9770796cc30f3af\n'}, {'number': 3, 'created': '2023-04-14 15:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/af54c0086381701d827d77c7bf47d6ed5d275a3b', 'message': 'Fix error in NB DB watcher that triggered wrong events\n\nChange-Id: I00f4c6838865a75136223b98c9770796cc30f3af\n'}, {'number': 4, 'created': '2023-04-20 09:01:34.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/watchers/nb_bgp_watcher.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/65bd1402e842fa2e8a6247f81bccb8ec2cdeed3c', 'message': 'Fix error in NB DB watcher that triggered wrong events\n\nChange-Id: I00f4c6838865a75136223b98c9770796cc30f3af\n'}]",1,880510,65bd1402e842fa2e8a6247f81bccb8ec2cdeed3c,13,3,4,23567,,,0,"Fix error in NB DB watcher that triggered wrong events

Change-Id: I00f4c6838865a75136223b98c9770796cc30f3af
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/10/880510/4 && git format-patch -1 --stdout FETCH_HEAD,['ovn_bgp_agent/drivers/openstack/watchers/nb_bgp_watcher.py'],1,3375e3a49c4b15fe3bc1055bc91332f554810942,nb_driver," if hasattr(old, 'options'): # check chassis change old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) if old_chassis != self.agent.chassis: return False if not current_chassis or current_chassis != old_chassis: return True if hasattr(old, 'up'): if not old.up: return False if not row.up: return True if current_chassis != old_chassis and current_port_fip: if not row.up and current_port_fip:", old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) if old_chassis != self.agent.chassis: return False if not old.up: return False if (not current_chassis or current_chassis != old_chassis or not row.up): return True if current_chassis != old_chassis: if not row.up:,14,10
openstack%2Fkolla-ansible~master~Id222854480bf77cfd3db85319bba769fda9d7bf2,openstack/kolla-ansible,master,Id222854480bf77cfd3db85319bba769fda9d7bf2,Fix: apply int filter to rabbitmq_queue_expiry_ms,ABANDONED,2023-04-20 08:55:49.000000000,2023-04-20 09:18:27.000000000,,[{'_account_id': 13252}],"[{'number': 1, 'created': '2023-04-20 08:55:49.000000000', 'files': ['ansible/roles/rabbitmq/templates/definitions.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8d25d309bf0119ebbe90ff185f7971e7bc62708b', 'message': 'Fix: apply int filter to rabbitmq_queue_expiry_ms\n\nThe variable ``rabbitmq_queue_expiry_ms`` needs to have the ``int``\nfilter applied in ``definitions.json.j2``.\n\nChange-Id: Id222854480bf77cfd3db85319bba769fda9d7bf2\n'}]",1,880927,8d25d309bf0119ebbe90ff185f7971e7bc62708b,3,1,1,35263,,,0,"Fix: apply int filter to rabbitmq_queue_expiry_ms

The variable ``rabbitmq_queue_expiry_ms`` needs to have the ``int``
filter applied in ``definitions.json.j2``.

Change-Id: Id222854480bf77cfd3db85319bba769fda9d7bf2
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/27/880927/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/rabbitmq/templates/definitions.json.j2'],1,8d25d309bf0119ebbe90ff185f7971e7bc62708b,," {""vhost"": ""/"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms | int }}{% endif %}}, ""priority"":0}{% if project_name == 'outward_rabbitmq' %}, {""vhost"": ""{{ murano_agent_rabbitmq_vhost }}"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms | int }}{% endif %}}, ""priority"":0}"," {""vhost"": ""/"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms }}{% endif %}}, ""priority"":0}{% if project_name == 'outward_rabbitmq' %}, {""vhost"": ""{{ murano_agent_rabbitmq_vhost }}"", ""name"": ""ha-all"", ""pattern"": ""^(?!(amq\\.)|(.*_fanout_)|(reply_)).*"", ""apply-to"": ""all"", ""definition"": {""ha-mode"":{% if rabbitmq_ha_replica_count is not none %}""exactly"",""ha-params"":{{ rabbitmq_ha_replica_count | int }}{% else %}""all""{% endif %}{% if rabbitmq_ha_promote_on_shutdown is not none %},""ha-promote-on-shutdown"":""{{ rabbitmq_ha_promote_on_shutdown }}""{% endif %}{% if rabbitmq_message_ttl_ms is not none %},""message-ttl"":{{ rabbitmq_message_ttl_ms | int }}{% endif %}{% if rabbitmq_queue_expiry_ms is not none %},""expires"":{{ rabbitmq_queue_expiry_ms }}{% endif %}}, ""priority"":0}",2,2
openstack%2Fkolla-ansible~master~I46985202dc8da22601357eefe2727599e7a413e5,openstack/kolla-ansible,master,I46985202dc8da22601357eefe2727599e7a413e5,Configure coordination in default for masakari-api,MERGED,2023-02-22 08:43:30.000000000,2023-04-20 09:13:06.000000000,2023-04-20 09:11:13.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}, {'_account_id': 27339}, {'_account_id': 29268}]","[{'number': 1, 'created': '2023-02-22 08:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cb7594f9e7b92ec8ced45d0a00691f61dacadbad', 'message': 'Configure coordination in default for masakari-api\n\nThis patch introduces distributed lock for masakari-api\nservice when handle the concurrent notifications for the same\nhost failure from multiple masakari-hostmonitor services.\n\nChange-Id: I46985202dc8da22601357eefe2727599e7a413e5\n'}, {'number': 2, 'created': '2023-02-22 09:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e30f00257727204701c26f645f8d5696e735a73c', 'message': 'Configure coordination in default for masakari-api\n\nThis patch introduces distributed lock for masakari-api\nservice when handle the concurrent notifications for the same\nhost failure from multiple masakari-hostmonitor services.\n\nChange-Id: I46985202dc8da22601357eefe2727599e7a413e5\n'}, {'number': 3, 'created': '2023-02-22 13:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e9c32b1c0a58742c56a6f2e8ebe3f51f4f36d6c4', 'message': 'Configure coordination in default for masakari-api\n\nThis patch introduces distributed lock for masakari-api\nservice when handle the concurrent notifications for the same\nhost failure from multiple masakari-hostmonitor services.\n\nChange-Id: I46985202dc8da22601357eefe2727599e7a413e5\n'}, {'number': 4, 'created': '2023-02-23 07:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/75e7275d15ca9a533f7da73e5136150e1b343b03', 'message': 'Configure coordination in default for masakari-api\n\nThis patch introduces distributed lock for masakari-api\nservice when handle the concurrent notifications for the same\nhost failure from multiple masakari-hostmonitor services.\n\nChange-Id: I46985202dc8da22601357eefe2727599e7a413e5\n'}, {'number': 5, 'created': '2023-04-17 18:03:44.000000000', 'files': ['releasenotes/notes/new-variable-masakari-coordination-backend-d3b742315a07aabc.yaml', 'ansible/group_vars/all.yml', 'ansible/roles/masakari/templates/masakari.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/842adf6d2f218e49bfe7d8c3b7dea84e289ece03', 'message': 'Configure coordination in default for masakari-api\n\nThis patch introduces distributed lock for masakari-api\nservice when handle the concurrent notifications for the same\nhost failure from multiple masakari-hostmonitor services.\n\nChange-Id: I46985202dc8da22601357eefe2727599e7a413e5\n'}]",15,874729,842adf6d2f218e49bfe7d8c3b7dea84e289ece03,39,7,5,27339,,,0,"Configure coordination in default for masakari-api

This patch introduces distributed lock for masakari-api
service when handle the concurrent notifications for the same
host failure from multiple masakari-hostmonitor services.

Change-Id: I46985202dc8da22601357eefe2727599e7a413e5
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/29/874729/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/new-variable-masakari-coordination-backend-d3b742315a07aabc.yaml', 'ansible/group_vars/all.yml', 'ansible/roles/masakari/templates/masakari.conf.j2']",3,cb7594f9e7b92ec8ced45d0a00691f61dacadbad,masakari-coordination, {% if service_name == 'masakari-api' %} [coordination] {% if masakari_coordination_backend == 'redis' %} backend_url = {{ redis_connection_string }} {% elif masakari_coordination_backend == 'etcd' %} backend_url = etcd3+{{ internal_protocol }}://{{ kolla_internal_vip_address }}:{{ etcd_client_port }} {% endif %} {% endif %},,75,0
openstack%2Freleases~master~I433ccb6a31cc450a666673374b78dcc1fea1bb7b,openstack/releases,master,I433ccb6a31cc450a666673374b78dcc1fea1bb7b,Fix E275 error with latest flake8,MERGED,2023-04-19 13:02:25.000000000,2023-04-20 09:12:56.000000000,2023-04-20 09:12:56.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-04-19 13:02:25.000000000', 'files': ['openstack_releases/versionutils.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/5ac58d4a9863ced2a4feb466a81aa6ac8a651241', 'message': ""Fix E275 error with latest flake8\n\nhacking 6.0.0 release contains flake8 5.0.4, which started to show the\nfollowing error:\n\n./openstack_releases/versionutils.py:54:14: E275 missing whitespace after keyword\n        yield('Version %s looks like a pre-release and the release '\n\nThis patch adds a whitespace after the 'yield' keyword to make the pep8\njob pass.\n\nChange-Id: I433ccb6a31cc450a666673374b78dcc1fea1bb7b\n""}]",1,880824,5ac58d4a9863ced2a4feb466a81aa6ac8a651241,7,3,1,17685,,,0,"Fix E275 error with latest flake8

hacking 6.0.0 release contains flake8 5.0.4, which started to show the
following error:

./openstack_releases/versionutils.py:54:14: E275 missing whitespace after keyword
        yield('Version %s looks like a pre-release and the release '

This patch adds a whitespace after the 'yield' keyword to make the pep8
job pass.

Change-Id: I433ccb6a31cc450a666673374b78dcc1fea1bb7b
",git fetch https://review.opendev.org/openstack/releases refs/changes/24/880824/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_releases/versionutils.py'],1,5ac58d4a9863ced2a4feb466a81aa6ac8a651241,hacking-6.0.0, yield ('Version %s looks like a pre-release and the release ' 'model does not allow for it' % versionstr), yield('Version %s looks like a pre-release and the release ' 'model does not allow for it' % versionstr),2,2
openstack%2Fkolla-ansible~stable%2Fzed~I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9,openstack/kolla-ansible,stable/zed,I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9,Update notes about CentOS support,MERGED,2023-04-20 08:25:27.000000000,2023-04-20 09:12:31.000000000,2023-04-20 09:11:16.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-20 08:25:27.000000000', 'files': ['doc/source/user/support-matrix.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/60287601136a14ce845d0f5f07c19b893c0dc821', 'message': 'Update notes about CentOS support\n\nRemove notes referring to old releases (Train, Victoria). Add a note to\ncover migration to RL9.\n\nChange-Id: I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9\n(cherry picked from commit 8f82c2948e667d55dd1bd483c280192e09ee4fbd)\n'}]",0,880839,60287601136a14ce845d0f5f07c19b893c0dc821,8,3,1,14826,,,0,"Update notes about CentOS support

Remove notes referring to old releases (Train, Victoria). Add a note to
cover migration to RL9.

Change-Id: I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9
(cherry picked from commit 8f82c2948e667d55dd1bd483c280192e09ee4fbd)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/39/880839/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/support-matrix.rst'],1,60287601136a14ce845d0f5f07c19b893c0dc821,centos7-support-stable/zed," CentOS Stream 8 is no longer supported as a host OS. The Yoga release supports both CentOS Stream 8 and CentOS Stream 9 / Rocky Linux 9, and provides a route for migration."," CentOS 7 is no longer supported as a host OS. The Train release supports both CentOS 7 and 8, and provides a route for migration. See the `Kolla Ansible Train documentation <https://docs.openstack.org/kolla-ansible/train/user/centos8.html>`_ for information on migrating to CentOS 8. .. note:: CentOS Linux 8 (as opposed to CentOS Stream 8) is no longer supported as a host OS. The Victoria release will in future support both CentOS Linux 8 and CentOS Stream 8, and provides a route for migration. ",3,13
openstack%2Fcinder~master~I685d45c4c78541a3885270cca54ea7cd00e9b8d9,openstack/cinder,master,I685d45c4c78541a3885270cca54ea7cd00e9b8d9,Update block-storage-overview to reflect multiattach,NEW,2023-03-29 04:27:17.000000000,2023-04-20 09:03:39.000000000,,"[{'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 04:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b61ccb27e84433ec7a9e11b8560bd073336b4e4c', 'message': 'update doc\n\nChange-Id: I685d45c4c78541a3885270cca54ea7cd00e9b8d9\n'}, {'number': 2, 'created': '2023-03-29 04:28:16.000000000', 'files': ['doc/source/configuration/block-storage/block-storage-overview.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/708255751186db36e2d764da5d6824f7338c0105', 'message': 'Update block-storage-overview to reflect multiattach\n\nAccording to https://docs.openstack.org/cinder/latest/admin/volume-multiattach.html,single volume can be attached to multiple\ninstances simultaneously in active/active or active/standby scenarios.\n\nCloses-Bug: #2004419\nChange-Id: I685d45c4c78541a3885270cca54ea7cd00e9b8d9\n'}]",2,878811,708255751186db36e2d764da5d6824f7338c0105,19,2,2,35833,,,0,"Update block-storage-overview to reflect multiattach

According to https://docs.openstack.org/cinder/latest/admin/volume-multiattach.html,single volume can be attached to multiple
instances simultaneously in active/active or active/standby scenarios.

Closes-Bug: #2004419
Change-Id: I685d45c4c78541a3885270cca54ea7cd00e9b8d9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/878811/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/block-storage/block-storage-overview.rst'],1,b61ccb27e84433ec7a9e11b8560bd073336b4e4c,volume_multiattach,"Prior to the Queens release, the Block Storage service did not provide a shared storage solution like NFS and you could attach a device to only one instance. However, with the introduction of Cinder multiattach, you can now attach a single volume of an appropriate volume type to multiple instances simultaneously in active/active or active/passive scenarios.","The Block Storage service does not provide a shared storage solution like NFS. With the Block Storage service, you can attach a device to only one instance.",5,3
openstack%2Foctavia~stable%2Fzed~I30b81866989c22b94fb77e62e7abd180f0f0af50,openstack/octavia,stable/zed,I30b81866989c22b94fb77e62e7abd180f0f0af50,Pass config to castellan,NEW,2023-04-14 05:45:34.000000000,2023-04-20 09:02:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 05:45:34.000000000', 'files': ['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e8ada397f9a7acc3d25d5557e7ecf6a7742ff319', 'message': ""Pass config to castellan\n\nCurrently castellan can't be configured through octavia.conf as\nconf is not passed while initializing backend.\n\nAlso document castellan configuration options in reference.\n\nBackports on stable branches also include [0] which adds a release note.\n\n[0] Iacc796737bad8881873da7db5273338c2cff9e68\n\nConflicts:\n    etc/config/octavia-config-generator.conf (doesn't exist on stable\n    branches)\n\nChange-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50\n(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)\n""}]",1,880435,e8ada397f9a7acc3d25d5557e7ecf6a7742ff319,4,1,1,29244,,,0,"Pass config to castellan

Currently castellan can't be configured through octavia.conf as
conf is not passed while initializing backend.

Also document castellan configuration options in reference.

Backports on stable branches also include [0] which adds a release note.

[0] Iacc796737bad8881873da7db5273338c2cff9e68

Conflicts:
    etc/config/octavia-config-generator.conf (doesn't exist on stable
    branches)

Change-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50
(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/35/880435/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml']",2,e8ada397f9a7acc3d25d5557e7ecf6a7742ff319,,--- fixes: - | Usage of ``castellan_cert_manager`` as cert_manager has been significantly improved. Now you can define configuration options for castellan in octavia.conf and they will be passed properly to castellan beckend. This allows to use allowed castellan backends as for certificate storage. ,,11,1
openstack%2Fkayobe~master~I0d7ab0d8ff5b16ac5de8e50e63400bd455996555,openstack/kayobe,master,I0d7ab0d8ff5b16ac5de8e50e63400bd455996555,Allow to use own repos.y[a]ml file to build containers,MERGED,2022-06-10 09:56:00.000000000,2023-04-20 08:54:15.000000000,2023-04-20 08:53:11.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23871}, {'_account_id': 24072}, {'_account_id': 25600}, {'_account_id': 27339}]","[{'number': 1, 'created': '2022-06-10 09:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2bebc533e48ef53477209be6856959aa56ce9dd1', 'message': 'Allow to use own repos.yaml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.yaml file to build containers.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 2, 'created': '2022-06-14 11:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/80e9dc89021e7ca34fd6c8468cf209da43813763', 'message': 'Allow to use own repos.yaml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.yaml file to build containers.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 3, 'created': '2022-06-14 12:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/27b5d93f92393e9dcbd3831a60251f4e887eafe1', 'message': 'Allow to use own repos.yaml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.yaml file to build containers.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 4, 'created': '2022-06-14 12:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0d5cf2646567c64a5392b34e8447bded21fcdf18', 'message': 'Allow to use own repos.yaml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.yaml file to build containers.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 5, 'created': '2022-12-07 14:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/019f25918c014e3dda2c7f9b7982861f2309e165', 'message': 'Allow to use own repos.yaml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.yaml file to build containers.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 6, 'created': '2023-04-01 17:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/f8bdebb797b0e8079ca293607cde4f684905f394', 'message': 'Allow to use own repos.y[a]ml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.y[a]ml file to build containers.\nMultiple Environments supported.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 7, 'created': '2023-04-19 16:06:48.000000000', 'files': ['ansible/roles/kolla-build/templates/kolla/kolla-build.conf', 'releasenotes/notes/user-provided-repos-yaml-07e1f872225059a6.yaml', 'ansible/roles/kolla-build/tasks/main.yml', 'doc/source/multiple-environments.rst'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/070621a45df11fd2487ddc38f715c1075524ee93', 'message': 'Allow to use own repos.y[a]ml file to build containers\n\nFollowup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.\nThis change allow to use own repos.y[a]ml file to build containers.\nMultiple Environments supported.\n\nChange-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}]",15,845338,070621a45df11fd2487ddc38f715c1075524ee93,27,8,7,14200,,,0,"Allow to use own repos.y[a]ml file to build containers

Followup the I0b07da22fea27e0ff4e90aaad19e50d84ff9a121 from Kolla.
This change allow to use own repos.y[a]ml file to build containers.
Multiple Environments supported.

Change-Id: I0d7ab0d8ff5b16ac5de8e50e63400bd455996555
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/38/845338/6 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/user-provided-repos-yaml-07e1f872225059a6.yaml', 'ansible/container-image-build.yml', 'ansible/roles/kolla-build/tasks/main.yml']",3,2bebc533e48ef53477209be6856959aa56ce9dd1,user-provided-repos-yaml,"- name: Ensure the custom repos.yml file exists merge_yaml: sources: ""{{ kolla_build_config_paths | product(['/kolla/repos.yml']) | map('join') | unique | list }}"" dest: ""{{ kolla_build_config_path }}/repos.yml"" mode: 0644 ",,20,0
openstack%2Fkolla-ansible~stable%2Fyoga~I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d,openstack/kolla-ansible,stable/yoga,I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d,cli: fix find globals.d,MERGED,2023-04-19 19:27:39.000000000,2023-04-20 08:51:55.000000000,2023-04-20 08:50:50.000000000,"[{'_account_id': 13252}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-19 19:27:39.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3e14223d9ea300feb178d63dd1ce57bad9363ee0', 'message': 'cli: fix find globals.d\n\nCurrently when the /etc/kolla/globals.d directory does not exist\nit writes an error on stderr.\n\nChange-Id: I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d\n(cherry picked from commit 35b92825b1cf428e7de121a217f9064668006f33)\n'}]",0,880886,3e14223d9ea300feb178d63dd1ce57bad9363ee0,10,6,1,14200,,,0,"cli: fix find globals.d

Currently when the /etc/kolla/globals.d directory does not exist
it writes an error on stderr.

Change-Id: I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d
(cherry picked from commit 35b92825b1cf428e7de121a217f9064668006f33)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/86/880886/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla-ansible'],1,3e14223d9ea300feb178d63dd1ce57bad9363ee0,,"EXTRA_GLOBALS=$([ -d ""${GLOBALS_DIR}"" ] && find ${GLOBALS_DIR} -maxdepth 1 -type f -name '*.yml' -printf ' -e @%p' 2>/dev/null)",EXTRA_GLOBALS=$(find ${GLOBALS_DIR} -maxdepth 1 -type f -name '*.yml' -printf ' -e @%p' 2>/dev/null),1,1
openstack%2Fovn-bgp-agent~master~I02e3a0b15123f38995459f011b92d83c138576d6,openstack/ovn-bgp-agent,master,I02e3a0b15123f38995459f011b92d83c138576d6,Add initial wiring configuration to a common function,MERGED,2023-04-03 10:04:42.000000000,2023-04-20 08:39:25.000000000,2023-04-20 08:39:25.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-04-03 10:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/af67d51d6d89f70fbdf8ed97f25e9f1e26623ad1', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 2, 'created': '2023-04-03 10:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/1d537a2a0dd60070912dad32fa1688e4f1d5e286', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 3, 'created': '2023-04-12 10:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/703a4afbb95bde0e2ea98c98050268e37e44569a', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 4, 'created': '2023-04-12 11:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/f664e77df7052bfc390ca58b861d445f76893b09', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 5, 'created': '2023-04-14 07:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/21a1d91d2c2cb234031862a06ccbdf95aab92a08', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 6, 'created': '2023-04-14 07:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/9217a6feba19e3d67c501e61c33d01f548f394ba', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 7, 'created': '2023-04-14 10:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/3c1774ba6a2a88df8a67cbd66d7ff709496e1ebb', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 8, 'created': '2023-04-14 10:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/a647e50f376a67e70d8592e80c6da2666e227bc9', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 9, 'created': '2023-04-14 12:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/6e4aed08616ed02fb5cc45fd1856c2d601d16e14', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 10, 'created': '2023-04-14 15:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/693d8c7f5e5cf99ea8664c69f6e4d832be974e69', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}, {'number': 11, 'created': '2023-04-20 06:16:54.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/utils/wire.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py', 'ovn_bgp_agent/utils/linux_net.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_nb_ovn_bgp_driver.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/watchers/test_nb_bgp_watcher.py', 'ovn_bgp_agent/drivers/openstack/watchers/nb_bgp_watcher.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/6e59cf66caa34dc63b2a561a80fd7d3495435da7', 'message': 'Add initial wiring configuration to a common function\n\nThis is to make the NB driver a bit more independent of the mode\nchoosen to expose the IPs.\n\nChange-Id: I02e3a0b15123f38995459f011b92d83c138576d6\n'}]",6,879291,6e59cf66caa34dc63b2a561a80fd7d3495435da7,33,3,11,23567,,,0,"Add initial wiring configuration to a common function

This is to make the NB driver a bit more independent of the mode
choosen to expose the IPs.

Change-Id: I02e3a0b15123f38995459f011b92d83c138576d6
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/91/879291/9 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/utils/wire.py', 'ovn_bgp_agent/utils/linux_net.py']",4,af67d51d6d89f70fbdf8ed97f25e9f1e26623ad1,nb_driver,"@tenacity.retry( retry=tenacity.retry_if_exception_type( netlink_exceptions.NetlinkDumpInterrupted), wait=tenacity.wait_exponential(multiplier=0.02, max=1), stop=tenacity.stop_after_delay(8), reraise=True) def get_extra_routing_table_for_bridge(ovn_routing_tables, bridge): extra_routes = [] with pyroute2.NDB() as ndb: table_route_dsts = set( [ (r.dst, r.dst_len) for r in ndb.routes.summary().filter( table=ovn_routing_tables[bridge] ) ] ) if not table_route_dsts: return extra_routes for (dst, dst_len) in table_route_dsts: if not dst: # default route try: route = ndb.routes[ {'table': ovn_routing_tables[bridge], 'dst': '', 'family': AF_INET}] if (bridge != ndb.interfaces[{'index': route['oif']}][ 'ifname']): extra_routes.append(route) except KeyError: pass # no ipv4 default rule try: route_6 = ndb.routes[ {'table': ovn_routing_tables[bridge], 'dst': '', 'family': AF_INET6}] if (bridge != ndb.interfaces[{'index': route_6['oif']}][ 'ifname']): extra_routes.append(route_6) except KeyError: pass # no ipv6 default rule else: if get_ip_version(dst) == constants.IP_VERSION_6: extra_routes.append( ndb.routes[{'table': ovn_routing_tables[bridge], 'dst': dst, 'dst_len': dst_len, 'family': AF_INET6}] ) else: extra_routes.append( ndb.routes[{'table': ovn_routing_tables[bridge], 'dst': dst, 'dst_len': dst_len, 'family': AF_INET}] ) return extra_routes ",,242,125
openstack%2Fcharm-keystone-k8s~main~I6841ee9e684c93a097057d644d1c4ed1e171c961,openstack/charm-keystone-k8s,main,I6841ee9e684c93a097057d644d1c4ed1e171c961,Fix can_service_requests call,ABANDONED,2023-04-19 14:46:14.000000000,2023-04-20 08:37:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-19 14:46:14.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/ac94585a0266119cf96e76b8b343ce608af10b79', 'message': 'Fix can_service_requests call\n\nOne of the calls for this method was supplied with an extraneous `event`\nparameter.\n\nChange-Id: I6841ee9e684c93a097057d644d1c4ed1e171c961\n'}]",0,880851,ac94585a0266119cf96e76b8b343ce608af10b79,3,1,1,35761,,,0,"Fix can_service_requests call

One of the calls for this method was supplied with an extraneous `event`
parameter.

Change-Id: I6841ee9e684c93a097057d644d1c4ed1e171c961
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/51/880851/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,ac94585a0266119cf96e76b8b343ce608af10b79,fix/can-service-requests, if self.can_service_requests():, if self.can_service_requests(event):,1,1
openstack%2Fcharm-keystone-k8s~main~I2a7120a4f309886040ec9cf064fd539bd59540c1,openstack/charm-keystone-k8s,main,I2a7120a4f309886040ec9cf064fd539bd59540c1,Fix typo in can_service_requests call,MERGED,2023-04-19 14:50:37.000000000,2023-04-20 08:36:26.000000000,2023-04-20 07:35:20.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 14:50:37.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/ff59f5e98b98e87e16aa09937b46d954aebcad66', 'message': 'Fix typo in can_service_requests call\n\nChange-Id: I2a7120a4f309886040ec9cf064fd539bd59540c1\n'}]",2,880853,ff59f5e98b98e87e16aa09937b46d954aebcad66,9,2,1,12549,,,0,"Fix typo in can_service_requests call

Change-Id: I2a7120a4f309886040ec9cf064fd539bd59540c1
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/53/880853/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,ff59f5e98b98e87e16aa09937b46d954aebcad66,add-creds-fix, if self.can_service_requests():, if self.can_service_requests(event):,1,1
openstack%2Fbarbican~stable%2Fzed~I13c88c3bfdea35205621c3b792164584965d60fe,openstack/barbican,stable/zed,I13c88c3bfdea35205621c3b792164584965d60fe,Zed only: Remove TripleO job,NEW,2023-03-17 15:39:29.000000000,2023-04-20 08:25:23.000000000,,"[{'_account_id': 7973}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-17 15:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/514aa67422ad079f58113839e7ae062db1592df2', 'message': ""Stable-only: Remove TripleO job\n\nUnfortunately, stable/zed branch of TripleO will be unmaintained. Let's\nremove the TripleO job from this branch now before CI is broken.\n\nChange-Id: I13c88c3bfdea35205621c3b792164584965d60fe\n""}, {'number': 2, 'created': '2023-03-17 15:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b5e1c898194e0ad6c204f1a6d36d3061ca88454c', 'message': ""Zed only: Remove TripleO job\n\nUnfortunately, stable/zed branch of TripleO will be unmaintained. Let's\nremove the TripleO job from this branch now before CI is broken.\n\nChange-Id: I13c88c3bfdea35205621c3b792164584965d60fe\n""}, {'number': 3, 'created': '2023-04-18 10:57:41.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/barbican/commit/bec72e87e24f20428eb840adc3d5ecf2a1f5ac70', 'message': ""Zed only: Remove TripleO job\n\nUnfortunately, stable/zed branch of TripleO will be unmaintained. Let's\nremove the TripleO job from this branch now before CI is broken.\n\nChange-Id: I13c88c3bfdea35205621c3b792164584965d60fe\n""}]",1,877812,bec72e87e24f20428eb840adc3d5ecf2a1f5ac70,10,3,3,9816,,,0,"Zed only: Remove TripleO job

Unfortunately, stable/zed branch of TripleO will be unmaintained. Let's
remove the TripleO job from this branch now before CI is broken.

Change-Id: I13c88c3bfdea35205621c3b792164584965d60fe
",git fetch https://review.opendev.org/openstack/barbican refs/changes/12/877812/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,514aa67422ad079f58113839e7ae062db1592df2,remove-tripleo,," # TripleO jobs that deploy Barbican. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - tripleo-ci-centos-9-scenario002-standalone: voting: false",0,7
openstack%2Fcinder~master~I54b81a568a01af44e3f74bcac55e823cdae9bfbf,openstack/cinder,master,I54b81a568a01af44e3f74bcac55e823cdae9bfbf,Restore into sparse volumes,MERGED,2022-08-09 18:06:51.000000000,2023-04-20 08:15:15.000000000,2023-03-18 03:53:05.000000000,"[{'_account_id': 4523}, {'_account_id': 9236}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-08-09 18:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/627559ad05a2ae1f4e99d99e7854803be766e1c8', 'message': 'WIP: Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes.\n\nTODO:\n - Look at drivers that do not inherit from chunkdriver.py\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 2, 'created': '2022-08-17 05:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/69e013d0552593afc513c019a574c5be9186330d', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 3, 'created': '2022-11-24 00:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/293efed07feb18b3810bb255d7130a445d36582a', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 4, 'created': '2022-11-29 19:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8580697b6db9d643882ccb6454e76f0c17c581dd', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 5, 'created': '2022-12-10 00:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7b05baeb15efe17a438abb9e426c6a3d8d84f0a6', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 6, 'created': '2022-12-10 01:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fde3c4ee956f9436a65101252347373a5d4677ed', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 7, 'created': '2023-02-03 16:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/69d7d8cb138dd5f626d7871990d73b548199665e', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 8, 'created': '2023-02-13 22:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed42901d7ee18cea21f5b7b64652c54e9c7ac273', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 9, 'created': '2023-02-16 22:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe9dce3961f1072c5c994469c7d89141a6596516', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 10, 'created': '2023-02-17 16:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/36c8a396fa576feef000334198e5b6d7feecd25c', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 11, 'created': '2023-03-02 06:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc3d913d0c497c204c7b5be8a30ddbabea44e20f', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 12, 'created': '2023-03-04 00:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8174fef737874cb17741ea6b157325d5a12fc17', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\n(This version keeps the dubious ""fresh"" moniker for the time being.)\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 13, 'created': '2023-03-04 03:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/56520a577ebadd93a7bfd5d901a1d017a436ac30', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\n(This version keeps the dubious ""fresh"" moniker for the time being.)\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 14, 'created': '2023-03-06 22:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/19ee81261c5eb976261c1a7210a59c857d52b8ae', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\n(This version keeps the dubious ""fresh"" moniker for the time being.)\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 15, 'created': '2023-03-10 04:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2fec00a100969a1c723ab0a286560d3a9d15790', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 16, 'created': '2023-03-16 00:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/477b1342747ddeb3ab9a586b33c06f1e51f37df8', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}, {'number': 17, 'created': '2023-03-17 23:46:53.000000000', 'files': ['cinder/tests/unit/backup/fake_service.py', 'cinder/backup/api.py', 'cinder/backup/manager.py', 'cinder/backup/rpcapi.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/tests/unit/backup/drivers/test_backup_s3.py', 'cinder/backup/driver.py', 'cinder/tests/unit/backup/drivers/test_backup_google.py', 'releasenotes/notes/backup-sparse-f396b35bfe17332e.yaml', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/backup/test_backup_messages.py', 'cinder/tests/unit/backup/drivers/test_backup_ceph.py', 'cinder/volume/volume_utils.py', 'cinder/backup/drivers/ceph.py', 'cinder/tests/unit/backup/test_chunkeddriver.py', 'cinder/tests/unit/backup/drivers/test_backup_swift.py', 'cinder/tests/unit/backup/test_rpcapi.py', 'cinder/backup/chunkeddriver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b75c29c7d8e0e6ac212b59f9ad8d140874e55251', 'message': 'Restore into sparse volumes\n\nWe take the approach to detect zero data when restoring and not\nwriting it out to the volume. This works exactly as expected\nwhen restoring into Linux LVM volumes and into Ceph RBD volumes,\nprovided they are freshly created.\n\nCloses-bug: #2007615\nChange-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf\n'}]",83,852654,b75c29c7d8e0e6ac212b59f9ad8d140874e55251,416,4,17,597,,,0,"Restore into sparse volumes

We take the approach to detect zero data when restoring and not
writing it out to the volume. This works exactly as expected
when restoring into Linux LVM volumes and into Ceph RBD volumes,
provided they are freshly created.

Closes-bug: #2007615
Change-Id: I54b81a568a01af44e3f74bcac55e823cdae9bfbf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/852654/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/backup/chunkeddriver.py']",2,627559ad05a2ae1f4e99d99e7854803be766e1c8,restore_to_sparse," @staticmethod def _is_all_zero(chunk): """"""Return true is the chunk of bytes is all zeroes. """""" # This is not optimized at all. See what Knuth said about it. return sum(chunk) == 0 def _write_nonzero(self, volume_file, volume_offset, decompressed): """"""Write non-zero parts of `decompressed` into `volume_file`. """""" chunk_length = 1024*1024 for chunk_offset in range(0, len(decompressed), chunk_length): chunk = decompressed[chunk_offset:chunk_offset+chunk_length] # The len(chunk) may be smaller than chunk_length. It's okay. if not ChunkedBackupDriver._is_all_zero(chunk): volume_file.seek(volume_offset + chunk_offset) volume_file.write(chunk) self._write_nonzero(volume_file, obj['offset'], decompressed) self._write_nonzero(volume_file, obj['offset'], body)", volume_file.seek(obj['offset']) volume_file.write(decompressed) volume_file.write(body),177,3
openstack%2Fpuppet-horizon~stable%2Fyoga~If896f922db09396415a095fb9a8062eca32a9d06,openstack/puppet-horizon,stable/yoga,If896f922db09396415a095fb9a8062eca32a9d06,Fix missing comma causing syntax error,MERGED,2023-04-14 07:27:07.000000000,2023-04-20 08:06:27.000000000,2023-04-20 08:06:27.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 07:27:07.000000000', 'files': ['templates/_1499_load_balancer_settings.py.erb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/21224897e7e8d805f9b0e66a9b82283be5d811da', 'message': 'Fix missing comma causing syntax error\n\nThis fixes one missing comma in octavia dashboard configuration to\nfix the syntax error.\n\nCloses-Bug: #2015271\nChange-Id: If896f922db09396415a095fb9a8062eca32a9d06\n(cherry picked from commit bccc7c467d606ed1cd16c836068a8f3c58f3b753)\n(cherry picked from commit 1c961e17d59b833d656421db6654776b427f503f)\n(cherry picked from commit dd00bbd616e1602d733cfda04a8ecd860492b82a)\n'}]",1,880384,21224897e7e8d805f9b0e66a9b82283be5d811da,10,4,1,9816,,,0,"Fix missing comma causing syntax error

This fixes one missing comma in octavia dashboard configuration to
fix the syntax error.

Closes-Bug: #2015271
Change-Id: If896f922db09396415a095fb9a8062eca32a9d06
(cherry picked from commit bccc7c467d606ed1cd16c836068a8f3c58f3b753)
(cherry picked from commit 1c961e17d59b833d656421db6654776b427f503f)
(cherry picked from commit dd00bbd616e1602d733cfda04a8ecd860492b82a)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/84/880384/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/_1499_load_balancer_settings.py.erb'],1,21224897e7e8d805f9b0e66a9b82283be5d811da,bug/2015271,"# }, },",# } },2,2
openstack%2Fopenstack-helm~master~Ia8d291bff59459214032a29dbb4ad6098766fc6c,openstack/openstack-helm,master,Ia8d291bff59459214032a29dbb4ad6098766fc6c,Fix the issue that ovn metadata not work in muti-node enviroment,MERGED,2023-04-18 08:32:58.000000000,2023-04-20 08:06:23.000000000,2023-04-20 08:05:12.000000000,"[{'_account_id': 3009}, {'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 08:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f0a926b4fd284fb13d615787986e36d68aeb111d', 'message': 'Fix the issue that ovn metadata not work\n\nNeutron-ovn-medatadata-agent should run on compute nodes.\n\nCloses-Bug: #2016849\nChange-Id: Ia8d291bff59459214032a29dbb4ad6098766fc6c\n'}, {'number': 2, 'created': '2023-04-19 01:48:14.000000000', 'files': ['neutron/templates/bin/_neutron-ovn-metadata-agent.sh.tpl', 'neutron/Chart.yaml', 'releasenotes/notes/neutron.yaml', 'neutron/values.yaml', 'neutron/values_overrides/ovn.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/427f14909acedbe740fb279c62ef1c00af452435', 'message': 'Fix the issue that ovn metadata not work in muti-node enviroment\n\nNeutron-ovn-medatadata-agent should run on compute nodes.\n\nCloses-Bug: #2016849\nChange-Id: Ia8d291bff59459214032a29dbb4ad6098766fc6c\n'}]",1,880713,427f14909acedbe740fb279c62ef1c00af452435,11,3,2,35937,,,0,"Fix the issue that ovn metadata not work in muti-node enviroment

Neutron-ovn-medatadata-agent should run on compute nodes.

Closes-Bug: #2016849
Change-Id: Ia8d291bff59459214032a29dbb4ad6098766fc6c
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/13/880713/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/templates/bin/_neutron-ovn-metadata-agent.sh.tpl', 'neutron/values.yaml', 'neutron/values_overrides/ovn.yaml']",3,f0a926b4fd284fb13d615787986e36d68aeb111d,bug/2016849, ovn_metadata_enabled: True nova_metadata_host: __NOVA_METADATA_SERVICE_HOST__,,4,1
openstack%2Fhorizon~master~I3a5ebfcb03adb8321da19e59aa7a1498801d2354,openstack/horizon,master,I3a5ebfcb03adb8321da19e59aa7a1498801d2354,"Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form",NEW,2023-03-09 16:53:28.000000000,2023-04-20 07:56:54.000000000,,"[{'_account_id': 841}, {'_account_id': 6914}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-03-09 16:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b256691eed92145ed4064fc70f4279dd9739c8f5', 'message': 'Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form\n\nThis patch adds rbac_policy, subnetpool, and trunk filed in Edit\nQuotas Form which you can find under\nIdentity->Projects->Select a Project->Modify Quotas ->Network tab.\nNow a user can list and update all these Quota fields of Neutron.\n\nCloses-Bug: #2006580\nChange-Id: I3a5ebfcb03adb8321da19e59aa7a1498801d2354\n'}, {'number': 2, 'created': '2023-04-06 04:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2bcc384ba3cdabba00145b7e42d04d5a24dcc22b', 'message': 'Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form\n\nThis patch adds rbac_policy, subnetpool, and trunk filed in Edit\nQuotas Form which you can find under\nIdentity->Projects->Select a Project->Modify Quotas ->Network tab.\nNow a user can list and update all these Quota fields of Neutron.\n\nCloses-Bug: #2006580\nChange-Id: I3a5ebfcb03adb8321da19e59aa7a1498801d2354\n'}, {'number': 3, 'created': '2023-04-15 17:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1aa015c8d0b4dc64a9ba3b542ed7a8e1e978d049', 'message': 'Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form\n\nThis patch adds rbac_policy, subnetpool, and trunk filed in Edit\nQuotas Form which you can find under\nIdentity->Projects->Select a Project->Modify Quotas ->Network tab.\nNow a user can list and update all these Quota fields of Neutron.\n\nCloses-Bug: #2006580\nChange-Id: I3a5ebfcb03adb8321da19e59aa7a1498801d2354\n'}, {'number': 4, 'created': '2023-04-15 18:40:37.000000000', 'files': ['openstack_dashboard/usage/views.py', 'openstack_dashboard/dashboards/admin/defaults/tests.py', 'openstack_dashboard/test/unit/api/rest/test_neutron.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c736e24528b12c6d57e9d50a252c7f733c714ff3', 'message': 'Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form\n\nThis patch adds rbac_policy, subnetpool, and trunk filed in Edit\nQuotas Form which you can find under\nIdentity->Projects->Select a Project->Modify Quotas ->Network tab.\nNow a user can list and update all these Quota fields of Neutron.\n\nCloses-Bug: #2006580\nChange-Id: I3a5ebfcb03adb8321da19e59aa7a1498801d2354\n'}]",12,877004,c736e24528b12c6d57e9d50a252c7f733c714ff3,22,4,4,29313,,,0,"Add RBAC Policies, Subnet Pools, and Trunks field in Edit Quotas Form

This patch adds rbac_policy, subnetpool, and trunk filed in Edit
Quotas Form which you can find under
Identity->Projects->Select a Project->Modify Quotas ->Network tab.
Now a user can list and update all these Quota fields of Neutron.

Closes-Bug: #2006580
Change-Id: I3a5ebfcb03adb8321da19e59aa7a1498801d2354
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/877004/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/usage/views.py', 'openstack_dashboard/dashboards/admin/defaults/tests.py', 'openstack_dashboard/test/unit/api/rest/test_neutron.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py']",6,b256691eed92145ed4064fc70f4279dd9739c8f5,877004," 'rbac_policy': '10', 'subnetpool': '10', 'trunk': '10' 'rbac_policy': {'used': 0, 'quota': 10}, 'subnetpool': {'used': 0, 'quota': 10}, 'trunk': {'used': 0, 'quota': 10},",,26,3
openstack%2Fcharm-ops-openstack~master~Iafabf81ecf3ea719c37144a24915a92643b98d7f,openstack/charm-ops-openstack,master,Iafabf81ecf3ea719c37144a24915a92643b98d7f,Add helper module for testing operator charms.,ABANDONED,2022-10-19 09:15:42.000000000,2023-04-20 07:41:08.000000000,,"[{'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-19 09:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ops-openstack/commit/51a49bf9a4b817282836687572087cecf02b7dad', 'message': 'Add helper module for testing operator charms.\n\nIn our testing we often work around the fact that the operator\nharness does not provide a `network_get()` by customizing the\n_TestingModelBackend class which is a bit fragile. This helper module\nimplements a patch decorator for `network_get()` instead.\n\nChange-Id: Iafabf81ecf3ea719c37144a24915a92643b98d7f\n'}, {'number': 2, 'created': '2022-10-19 10:12:38.000000000', 'files': ['unit_tests/test_ops_openstack.py', 'ops_openstack/testing.py'], 'web_link': 'https://opendev.org/openstack/charm-ops-openstack/commit/47f79f3b727516220b6b229d9fb3a19251344703', 'message': 'Add helper module for testing operator charms.\n\nIn our testing we often work around the fact that the operator\nharness does not provide a `network_get()` by customizing the\n_TestingModelBackend class which is a bit fragile. This helper module\nimplements a patch decorator for `network_get()` instead.\n\nChange-Id: Iafabf81ecf3ea719c37144a24915a92643b98d7f\n'}]",1,861853,47f79f3b727516220b6b229d9fb3a19251344703,8,2,2,15382,,,0,"Add helper module for testing operator charms.

In our testing we often work around the fact that the operator
harness does not provide a `network_get()` by customizing the
_TestingModelBackend class which is a bit fragile. This helper module
implements a patch decorator for `network_get()` instead.

Change-Id: Iafabf81ecf3ea719c37144a24915a92643b98d7f
",git fetch https://review.opendev.org/openstack/charm-ops-openstack refs/changes/53/861853/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_ops_openstack.py', 'ops_openstack/testing.py']",2,51a49bf9a4b817282836687572087cecf02b7dad,feature/testing-helpers,"# Copyright 2022 Canonical Ltd. # See LICENSE file for licensing details. """"""Helpers for testing operator charms."""""" import typing from unittest import mock def patch_network_get(private_address=""10.0.0.10"") -> typing.Callable: def network_get(*args, **kwargs) -> dict: """"""Patch network_get. Creates a patch for the not-yet-implemented testing backend needed for `bind_address`. This patch decorator can be used for cases such as: self.model.get_binding(event.relation).network.bind_address """""" return { ""bind-addresses"": [ { ""addresses"": [{""value"": private_address}], } ], } return mock.patch( ""ops.testing._TestingModelBackend.network_get"", network_get ) ",,40,0
openstack%2Fheat~master~I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b,openstack/heat,master,I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b,handle senlin error msg,NEW,2023-03-29 11:35:54.000000000,2023-04-20 07:40:43.000000000,,"[{'_account_id': 9816}, {'_account_id': 13114}, {'_account_id': 22348}, {'_account_id': 35793}]","[{'number': 1, 'created': '2023-03-29 11:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d5d9e59c59c261e8120f84cf88bda6cb46b1ffa2', 'message': 'handle senlin error msg\n\nWhen heat tries to catch an error coming from senlin but instead of returning an error,\nsenlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin\nstory: 2010636\ntask: 47603\n\nChange-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b\n'}, {'number': 2, 'created': '2023-03-30 01:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ec21e8256c595a94fbc3363af7f824d96b28a28', 'message': 'handle senlin error msg\n\nWhen heat tries to catch an error coming from senlin but instead of returning an error,\nsenlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin\nstory: 2010636\ntask: 47603\n\nChange-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b\n'}, {'number': 3, 'created': '2023-03-30 01:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a4357d18d1b31fc4a294ea1862f7edeadb316e9', 'message': 'handle senlin error msg\n\nWhen heat tries to catch an error coming from senlin but instead of returning an error,\nsenlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin\nstory: 2010636\ntask: 47603\n\nChange-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b\n'}, {'number': 4, 'created': '2023-03-30 03:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e1ab2f6eeab9743fdc3f56bac727aa98ad488282', 'message': 'handle senlin error msg\n\nWhen heat tries to catch an error coming from senlin but instead of returning an error,\nsenlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin\nstory: 2010636\ntask: 47603\n\nChange-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b\n'}, {'number': 5, 'created': '2023-03-30 06:41:27.000000000', 'files': ['heat/engine/clients/os/senlin.py', 'heat/engine/resources/openstack/senlin/policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/23f933b5c658d3926f3769e1ced0d6a4da2d67e6', 'message': 'handle senlin error msg\n\nWhen heat tries to catch an error coming from senlin but instead of returning an error,\nsenlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin\nstory: 2010636\ntask: 47603\n\nChange-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b\n'}]",20,878857,23f933b5c658d3926f3769e1ced0d6a4da2d67e6,18,4,5,35793,,,0,"handle senlin error msg

When heat tries to catch an error coming from senlin but instead of returning an error,
senlin will send an error message with details about the error. This commit help heat hanlde error message coming from senlin
story: 2010636
task: 47603

Change-Id: I7b6a454a63a6ddc4a8c7d9ec24bbebd02e089d0b
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/878857/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/senlin.py', 'heat/engine/resources/openstack/senlin/policy.py']",2,d5d9e59c59c261e8120f84cf88bda6cb46b1ffa2,handle-senlin-error-msg," msg = self.client().detach_policy_from_cluster( bd[self.BD_CLUSTER], self.resource_id) err_msg = msg.get('error') if err_msg: if err_msg.get('code') == 400: # policy didn't attach to cluster, skip. bd['finished'] = True break elif err_msg.get('code') == 409: # cluster is locked, try next time bd['finished'] = False break else: raise Exception(err_msg) bd['action'] = msg['action'] msg = self.client().attach_policy_to_cluster( enabled=bd[self.BD_ENABLED]) err_msg = msg.get('error') if err_msg: raise Exception(err_msg) bd['action'] = msg['action']"," bd['action'] = self.client().detach_policy_from_cluster( bd[self.BD_CLUSTER], self.resource_id)['action'] bd['action'] = self.client().attach_policy_to_cluster( enabled=bd[self.BD_ENABLED])['action']",25,4
openstack%2Fcinder~master~I4cd422cae77167a1c894dfc489e28c3cda6732f4,openstack/cinder,master,I4cd422cae77167a1c894dfc489e28c3cda6732f4,PowerFlex driver - documentation update,MERGED,2023-03-30 17:34:14.000000000,2023-04-20 06:58:38.000000000,2023-04-05 16:15:24.000000000,"[{'_account_id': 5314}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 31779}]","[{'number': 1, 'created': '2023-03-30 17:34:14.000000000', 'files': ['doc/source/configuration/block-storage/drivers/dell-emc-powerflex-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8da58d52ad0bd8902f6652b65c9cce3c2680db0', 'message': 'PowerFlex driver - documentation update\n\nUpdate of our PowerFlex Documentation to add support for PowerFlex\n4.0.x\n\nChange-Id: I4cd422cae77167a1c894dfc489e28c3cda6732f4\n'}]",3,879067,f8da58d52ad0bd8902f6652b65c9cce3c2680db0,26,5,1,35063,,,0,"PowerFlex driver - documentation update

Update of our PowerFlex Documentation to add support for PowerFlex
4.0.x

Change-Id: I4cd422cae77167a1c894dfc489e28c3cda6732f4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/879067/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/block-storage/drivers/dell-emc-powerflex-driver.rst'],1,f8da58d52ad0bd8902f6652b65c9cce3c2680db0,pflexdoc,* PowerFlex 4.0.x ,,2,0
openstack%2Fpuppet-horizon~stable%2Fzed~If896f922db09396415a095fb9a8062eca32a9d06,openstack/puppet-horizon,stable/zed,If896f922db09396415a095fb9a8062eca32a9d06,Fix missing comma causing syntax error,MERGED,2023-04-14 01:52:42.000000000,2023-04-20 06:46:17.000000000,2023-04-20 06:46:17.000000000,"[{'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 01:52:42.000000000', 'files': ['templates/_1499_load_balancer_settings.py.erb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/dd00bbd616e1602d733cfda04a8ecd860492b82a', 'message': 'Fix missing comma causing syntax error\n\nThis fixes one missing comma in octavia dashboard configuration to\nfix the syntax error.\n\nCloses-Bug: #2015271\nChange-Id: If896f922db09396415a095fb9a8062eca32a9d06\n(cherry picked from commit bccc7c467d606ed1cd16c836068a8f3c58f3b753)\n(cherry picked from commit 1c961e17d59b833d656421db6654776b427f503f)\n'}]",1,880376,dd00bbd616e1602d733cfda04a8ecd860492b82a,9,3,1,9816,,,0,"Fix missing comma causing syntax error

This fixes one missing comma in octavia dashboard configuration to
fix the syntax error.

Closes-Bug: #2015271
Change-Id: If896f922db09396415a095fb9a8062eca32a9d06
(cherry picked from commit bccc7c467d606ed1cd16c836068a8f3c58f3b753)
(cherry picked from commit 1c961e17d59b833d656421db6654776b427f503f)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/76/880376/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/_1499_load_balancer_settings.py.erb'],1,dd00bbd616e1602d733cfda04a8ecd860492b82a,bug/2015271,"# }, },",# } },2,2
openstack%2Fos-brick~stable%2Fxena~Ida6359ddebc59091f2f2dfc951950538793d0109,openstack/os-brick,stable/xena,Ida6359ddebc59091f2f2dfc951950538793d0109,[stable-only] Pin tox <4,MERGED,2022-12-22 23:14:51.000000000,2023-04-20 06:24:52.000000000,2023-04-20 06:21:49.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-12-22 23:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cdcb03ba417b5f81928ec3a7d7dda4b9c8f04b9d', 'message': '[stable-only] Pin tox <4\n\nContinue to use tox 3 until we decide how to do the transition\nto tox 4 in the stable branches.\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n'}, {'number': 2, 'created': '2023-01-05 16:40:39.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/96eef24d859fcf0c8dde2987845001459d7a365b', 'message': ""[stable-only] Pin tox <4\n\nContinue to use tox 3 in the stable branches.\n\nTwo changes:\n- .zuul.yaml: set the ensure_tox_version to use <4, which will\n  tell zuul to install tox<4 if it's not present\n- tox.ini: set requires=tox<4 so that if tox has been installed\n  already, our tox-based jobs will use tox 3 to run the tests\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)\n(cherry picked from commit cc704e90c070db59c2e0f97b4c5854379bb02a2a)\n""}]",2,868449,96eef24d859fcf0c8dde2987845001459d7a365b,15,3,2,5314,,,0,"[stable-only] Pin tox <4

Continue to use tox 3 in the stable branches.

Two changes:
- .zuul.yaml: set the ensure_tox_version to use <4, which will
  tell zuul to install tox<4 if it's not present
- tox.ini: set requires=tox<4 so that if tox has been installed
  already, our tox-based jobs will use tox 3 to run the tests

Change-Id: Ida6359ddebc59091f2f2dfc951950538793d0109
(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)
(cherry picked from commit cc704e90c070db59c2e0f97b4c5854379bb02a2a)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/49/868449/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,cdcb03ba417b5f81928ec3a7d7dda4b9c8f04b9d,tox-4-postponed, vars: ensure_tox_version: '<4',,2,0
openstack%2Fos-brick~stable%2Fwallaby~Ida6359ddebc59091f2f2dfc951950538793d0109,openstack/os-brick,stable/wallaby,Ida6359ddebc59091f2f2dfc951950538793d0109,[stable-only] Pin tox <4,MERGED,2022-12-22 23:16:27.000000000,2023-04-20 06:24:46.000000000,2023-04-20 06:21:50.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-12-22 23:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/434f576c4778ef91ca786a5698099703ab423139', 'message': '[stable-only] Pin tox <4\n\nContinue to use tox 3 until we decide how to do the transition\nto tox 4 in the stable branches.\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n'}, {'number': 2, 'created': '2023-01-05 16:41:37.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/e15ca01728df810113b3e1b5e4773c3fbd5da9c0', 'message': ""[stable-only] Pin tox <4\n\nContinue to use tox 3 in the stable branches.\n\nTwo changes:\n- .zuul.yaml: set the ensure_tox_version to use <4, which will\n  tell zuul to install tox<4 if it's not present\n- tox.ini: set requires=tox<4 so that if tox has been installed\n  already, our tox-based jobs will use tox 3 to run the tests\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)\n(cherry picked from commit cc704e90c070db59c2e0f97b4c5854379bb02a2a)\n(cherry picked from commit 96eef24d859fcf0c8dde2987845001459d7a365b)\n""}]",2,868450,e15ca01728df810113b3e1b5e4773c3fbd5da9c0,15,3,2,5314,,,0,"[stable-only] Pin tox <4

Continue to use tox 3 in the stable branches.

Two changes:
- .zuul.yaml: set the ensure_tox_version to use <4, which will
  tell zuul to install tox<4 if it's not present
- tox.ini: set requires=tox<4 so that if tox has been installed
  already, our tox-based jobs will use tox 3 to run the tests

Change-Id: Ida6359ddebc59091f2f2dfc951950538793d0109
(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)
(cherry picked from commit cc704e90c070db59c2e0f97b4c5854379bb02a2a)
(cherry picked from commit 96eef24d859fcf0c8dde2987845001459d7a365b)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/50/868450/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,434f576c4778ef91ca786a5698099703ab423139,tox-4-postponed, vars: ensure_tox_version: '<4',,2,0
openstack%2Fos-brick~stable%2Fyoga~Ida6359ddebc59091f2f2dfc951950538793d0109,openstack/os-brick,stable/yoga,Ida6359ddebc59091f2f2dfc951950538793d0109,[stable-only] Pin tox <4,MERGED,2022-12-22 23:13:26.000000000,2023-04-20 06:24:37.000000000,2023-04-20 06:21:47.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-12-22 23:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/dec9f2f3c027888a7bda4e7d41f4f2f5432c4eff', 'message': '[stable-only] Pin tox <4\n\nContinue to use tox 3 until we decide how to do the transition\nto tox 4 in the stable branches.\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n'}, {'number': 2, 'created': '2023-01-05 16:39:01.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cc704e90c070db59c2e0f97b4c5854379bb02a2a', 'message': ""[stable-only] Pin tox <4\n\nContinue to use tox 3 in the stable branches.\n\nTwo changes:\n- .zuul.yaml: set the ensure_tox_version to use <4, which will\n  tell zuul to install tox<4 if it's not present\n- tox.ini: set requires=tox<4 so that if tox has been installed\n  already, our tox-based jobs will use tox 3 to run the tests\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)\n""}]",3,868448,cc704e90c070db59c2e0f97b4c5854379bb02a2a,17,3,2,5314,,,0,"[stable-only] Pin tox <4

Continue to use tox 3 in the stable branches.

Two changes:
- .zuul.yaml: set the ensure_tox_version to use <4, which will
  tell zuul to install tox<4 if it's not present
- tox.ini: set requires=tox<4 so that if tox has been installed
  already, our tox-based jobs will use tox 3 to run the tests

Change-Id: Ida6359ddebc59091f2f2dfc951950538793d0109
(cherry picked from commit a7dfaf4243ae4a75971462ad35765acfedca6a89)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/48/868448/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,dec9f2f3c027888a7bda4e7d41f4f2f5432c4eff,tox-4-postponed, vars: ensure_tox_version: '<4',,2,0
openstack%2Fos-brick~stable%2Fzed~Ida6359ddebc59091f2f2dfc951950538793d0109,openstack/os-brick,stable/zed,Ida6359ddebc59091f2f2dfc951950538793d0109,[stable-only] Pin tox <4,MERGED,2022-12-22 23:11:54.000000000,2023-04-20 06:19:55.000000000,2023-04-20 06:18:02.000000000,"[{'_account_id': 5314}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-12-22 23:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/420f5e1fd0db387385fb6c5f013c597c914bf51d', 'message': '[stable-only] Pin tox <4\n\nContinue to use tox 3 until we decide how to do the transition\nto tox 4 in the stable branches.\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n'}, {'number': 2, 'created': '2023-01-05 16:36:53.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a7dfaf4243ae4a75971462ad35765acfedca6a89', 'message': ""[stable-only] Pin tox <4\n\nContinue to use tox 3 in the stable branches.\n\nTwo changes:\n- .zuul.yaml: set the ensure_tox_version to use <4, which will\n  tell zuul to install tox<4 if it's not present\n- tox.ini: set requires=tox<4 so that if tox has been installed\n  already, our tox-based jobs will use tox 3 to run the tests\n\nChange-Id: Ida6359ddebc59091f2f2dfc951950538793d0109\n""}]",6,868447,a7dfaf4243ae4a75971462ad35765acfedca6a89,20,4,2,5314,,,0,"[stable-only] Pin tox <4

Continue to use tox 3 in the stable branches.

Two changes:
- .zuul.yaml: set the ensure_tox_version to use <4, which will
  tell zuul to install tox<4 if it's not present
- tox.ini: set requires=tox<4 so that if tox has been installed
  already, our tox-based jobs will use tox 3 to run the tests

Change-Id: Ida6359ddebc59091f2f2dfc951950538793d0109
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/47/868447/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,420f5e1fd0db387385fb6c5f013c597c914bf51d,tox-4-postponed, vars: ensure_tox_version: '<4',,2,0
openstack%2Fpython-cinderclient~stable%2Fzed~Ica4c0a1d4f861e528ce8995766e82541dc710e0f,openstack/python-cinderclient,stable/zed,Ica4c0a1d4f861e528ce8995766e82541dc710e0f,[stable-only] Pin tox <4,MERGED,2023-01-04 23:34:40.000000000,2023-04-20 05:59:23.000000000,2023-04-20 05:56:30.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-04 23:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1141f312e0c426609d18bd930cfa44466bbe1d9a', 'message': '[stable-only] Pin tox <4\n\nContinue to use tox 3 until we decide how to do the transition\nto tox 4 in the stable branches.\n\nChange-Id: Ica4c0a1d4f861e528ce8995766e82541dc710e0f\n'}, {'number': 2, 'created': '2023-01-05 16:47:02.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/22a3169576b3fd91388e7b57ffd39e3760016796', 'message': ""[stable-only] Pin tox <4\n\nContinue to use tox 3 in the stable branches.\n\nTwo changes:\n- .zuul.yaml: set the ensure_tox_version to use <4, which will\n  tell zuul to install tox<4 if it's not present\n- tox.ini: set requires=tox<4 so that if tox has been installed\n  already, our tox-based jobs will use tox 3 to run the tests\n\nChange-Id: Ica4c0a1d4f861e528ce8995766e82541dc710e0f\n""}]",3,869263,22a3169576b3fd91388e7b57ffd39e3760016796,12,3,2,5314,,,0,"[stable-only] Pin tox <4

Continue to use tox 3 in the stable branches.

Two changes:
- .zuul.yaml: set the ensure_tox_version to use <4, which will
  tell zuul to install tox<4 if it's not present
- tox.ini: set requires=tox<4 so that if tox has been installed
  already, our tox-based jobs will use tox 3 to run the tests

Change-Id: Ica4c0a1d4f861e528ce8995766e82541dc710e0f
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/63/869263/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1141f312e0c426609d18bd930cfa44466bbe1d9a,tox-4-postponed, vars: ensure_tox_version: '<4',,2,0
openstack%2Fswift~master~I5e7c41190fcafbcd5dddde20d56e54c1209b2534,openstack/swift,master,I5e7c41190fcafbcd5dddde20d56e54c1209b2534,Tracing: add swift source to middleware spans,ABANDONED,2022-11-25 00:38:46.000000000,2023-04-20 05:47:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-25 00:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/10363a2ca9f2fa6b2fbf498d3662e952bcdcb8b1', 'message': 'Tracing: add swift source to middleware spans\n\nChange-Id: I5e7c41190fcafbcd5dddde20d56e54c1209b2534\n'}, {'number': 2, 'created': '2022-11-25 05:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/afe8d4f9a834193432d0c53a28b8a64d99ec3c57', 'message': 'Tracing: add swift source to middleware spans\n\nChange-Id: I5e7c41190fcafbcd5dddde20d56e54c1209b2534\n'}, {'number': 3, 'created': '2023-01-10 11:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/110af99a074d2cc0f5926ef8779a0033348f3826', 'message': 'Tracing: add swift source to middleware spans\n\nChange-Id: I5e7c41190fcafbcd5dddde20d56e54c1209b2534\n'}, {'number': 4, 'created': '2023-03-24 04:23:08.000000000', 'files': ['swift/common/trace/__init__.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ad3bfabb6b50f8ef8ee33d1d7e487ea9b07d60b2', 'message': 'Tracing: add swift source to middleware spans\n\nChange-Id: I5e7c41190fcafbcd5dddde20d56e54c1209b2534\n'}]",0,865611,ad3bfabb6b50f8ef8ee33d1d7e487ea9b07d60b2,13,1,4,7233,,,0,"Tracing: add swift source to middleware spans

Change-Id: I5e7c41190fcafbcd5dddde20d56e54c1209b2534
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/865611/4 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/trace/__init__.py'],1,10363a2ca9f2fa6b2fbf498d3662e952bcdcb8b1,otel_tracing_tracing_namespace," self.trace_add(""swift.source"", env.get('swift.source', ''))",,1,0
openstack%2Fsenlin~master~I880356207ed6d7cddf6146f6c4dcacced40eadc3,openstack/senlin,master,I880356207ed6d7cddf6146f6c4dcacced40eadc3,"Support create profile with subnet This patch allow to define subnet  in profile, Default network port will find a random subnet to create port on, in this path user can define specific subnet. Change-Id: I8a29dcb7c8b92c8bd1b8c9111134c3ace6ea9a76",ABANDONED,2023-04-19 06:47:41.000000000,2023-04-20 04:56:09.000000000,,[],"[{'number': 1, 'created': '2023-04-19 06:47:41.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py', 'senlin/tests/unit/profiles/test_nova_server_update.py', 'senlin/tests/unit/profiles/test_nova_server_validate.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1176b00faf377efbf35ecb1e925bd5680acd8a41', 'message': 'Support create profile with subnet\nThis patch allow to define subnet  in profile,\nDefault network port will find a random subnet to create port on, in this path user can define specific subnet.\nChange-Id: I8a29dcb7c8b92c8bd1b8c9111134c3ace6ea9a76\n\nChange-Id: I880356207ed6d7cddf6146f6c4dcacced40eadc3\n'}]",2,880795,1176b00faf377efbf35ecb1e925bd5680acd8a41,4,0,1,35793,,,0,"Support create profile with subnet
This patch allow to define subnet  in profile,
Default network port will find a random subnet to create port on, in this path user can define specific subnet.
Change-Id: I8a29dcb7c8b92c8bd1b8c9111134c3ace6ea9a76

Change-Id: I880356207ed6d7cddf6146f6c4dcacced40eadc3
",git fetch https://review.opendev.org/openstack/senlin refs/changes/95/880795/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py', 'senlin/tests/unit/profiles/test_nova_server_update.py', 'senlin/tests/unit/profiles/test_nova_server_validate.py']",4,1176b00faf377efbf35ecb1e925bd5680acd8a41,support-create-network-with-subnet," 'subnet': 'FAKE_SUBNET',",,52,16
openstack%2Fcinder~master~Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6,openstack/cinder,master,Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6,Fix tracking allocated_capacity_gb,NEW,2022-03-31 20:02:22.000000000,2023-04-20 04:21:33.000000000,,"[{'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30858}, {'_account_id': 33543}, {'_account_id': 34598}]","[{'number': 1, 'created': '2022-03-31 20:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d595f46eb8d7a86142618e7e5a17b0c2177c12e6', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas acurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the folling areas\nmigrate_volume\ndelete_group\nextend_volume\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\n""}, {'number': 2, 'created': '2022-04-01 12:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8c223a357793456674fca376609325d2cf677acb', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas acurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the folling areas\nmigrate_volume\ndelete_group\nextend_volume\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 3, 'created': '2022-04-11 12:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/555bb19f62ac05452cf2b9617cc81b6e3fd28e9b', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nextend_volume\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 4, 'created': '2022-04-11 14:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f8b6883ef502ff0a0b2d788f85487efdf056794', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 5, 'created': '2022-05-04 20:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a3e0e2064ef35f75e9da32772613c42e13935cb0', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 6, 'created': '2022-05-10 19:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba9ab007a62c95090d1e775948e65e0432c06fd8', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 7, 'created': '2022-05-18 18:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d638bcdf99a1027a864474300533d20c114eb482', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 8, 'created': '2022-06-02 12:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e4488400a9c56e8919a04ac25356b0b16aabbea9', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 9, 'created': '2022-06-07 12:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2a78281beb128dfa391a5017439ab054ec8d5bb', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 10, 'created': '2022-06-10 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0a7cd4b3110d4ad9a82ec0a9b94ccf8c28711887', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 11, 'created': '2022-08-09 13:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0bab0e64ed7705247e7f62b8a3d3fdc34d92d956', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 12, 'created': '2022-08-10 19:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e3b0537c4c8405a54f382bb37496615abd7d195', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 13, 'created': '2022-09-15 12:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90453adf53e33ec42061c11421e3d7b8283cabaa', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 14, 'created': '2022-09-19 13:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c7b7363beddcfcba5a0e7fbf8af70e1d07e535b0', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 15, 'created': '2022-10-21 14:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5ca94a2924e5caee1216d7abc398f29e627abff7', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 16, 'created': '2022-10-21 14:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea0b26160959e003d2da52caecbaaef28d38eaa0', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 17, 'created': '2022-12-01 14:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/524ea7cf8ca1a1fef516459cf6ec17d68f3f2aff', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 18, 'created': '2023-01-06 15:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5de1ac794fd55063471fc9c55e728ef3d48341f4', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 19, 'created': '2023-01-24 13:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1347a21b34d7f612c4b3da661adda85c64aa377b', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}, {'number': 20, 'created': '2023-03-30 13:51:46.000000000', 'files': ['cinder/volume/manager.py', 'cinder/volume/rpcapi.py', 'releasenotes/notes/fix-allocated-capacity-tracking-46d5dd59db6ff02a.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e72ecc3a666a5b9e6cebdda9663f9fd7c9cf63b', 'message': ""Fix tracking allocated_capacity_gb\n\nThis patch fixes a few issues with correctly updating the\ndriver stats allocated_capacity_gb setting so the scheduler\nhas accurate data.\n\nThis patch updates the volume manager's _update_allocated_capacity()\nto be more generic so that all methods in the volume manager can use it\nto correctly update the driver stats allocated_capacity_gb for pools\nas well as non-pools.\n\nThis patch fixes the following areas\nmigrate_volume\ndelete_group\nrevert_to_snapshot_generic\nextend_volume\n\nThis patch adds a new rpcapi to update the allocated_capacity_gb for a\nremote host after volume migration is completed.\n\nChange-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6\nPartial-Bug: 1910767\n""}]",28,836083,8e72ecc3a666a5b9e6cebdda9663f9fd7c9cf63b,411,5,20,5997,,,0,"Fix tracking allocated_capacity_gb

This patch fixes a few issues with correctly updating the
driver stats allocated_capacity_gb setting so the scheduler
has accurate data.

This patch updates the volume manager's _update_allocated_capacity()
to be more generic so that all methods in the volume manager can use it
to correctly update the driver stats allocated_capacity_gb for pools
as well as non-pools.

This patch fixes the following areas
migrate_volume
delete_group
revert_to_snapshot_generic
extend_volume

This patch adds a new rpcapi to update the allocated_capacity_gb for a
remote host after volume migration is completed.

Change-Id: Ia1535c3d675dafd525eb57b8ea27a8fb1e22f3f6
Partial-Bug: 1910767
",git fetch https://review.opendev.org/openstack/cinder refs/changes/83/836083/13 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,d595f46eb8d7a86142618e7e5a17b0c2177c12e6,bug/1910767," def _update_allocated_capacity(self, vol: objects.Volume, decrement: bool = False, host: Optional[str] = None, size: int = None) -> None: # Update allocated capacity in volume stats host = host or vol['host'] pool = volume_utils.extract_host(host, 'pool') if pool is None: # Legacy volume, put them into default pool pool = self.driver.configuration.safe_get( 'volume_backend_name') or volume_utils.extract_host(host, 'pool', True) # Account for an extending a volume size if size: vol_size = -size if decrement else size else: vol_size = -vol['size'] if decrement else vol['size'] try: self.stats['pools'][pool]['allocated_capacity_gb'] += vol_size except KeyError: self.stats['pools'][pool] = dict( allocated_capacity_gb=max(vol_size, 0)) self._update_allocated_capacity(temp_vol) self._update_allocated_capacity(temp_vol, decrement=True) self._update_allocated_capacity(temp_vol, decrement=True) original_host = volume.host self._update_allocated_capacity(volume, decrement=True, host=original_host) self._update_allocated_capacity(volume) original_host = volume.host self._update_allocated_capacity(volume, decrement=True, host=original_host) self._update_allocated_capacity(volume) self._update_allocated_capacity(vol, decrement=True)"," def _update_allocated_capacity(self, vol: objects.Volume, decrement: bool = False, host: Optional[str] = None) -> None: # Update allocated capacity in volume stats host = host or vol['host'] pool = volume_utils.extract_host(host, 'pool') if pool is None: # Legacy volume, put them into default pool pool = self.driver.configuration.safe_get( 'volume_backend_name') or volume_utils.extract_host(host, 'pool', True) vol_size = -vol['size'] if decrement else vol['size'] try: self.stats['pools'][pool]['allocated_capacity_gb'] += vol_size except KeyError: self.stats['pools'][pool] = dict( allocated_capacity_gb=max(vol_size, 0)) self.stats['allocated_capacity_gb'] -= vol.size",39,22
openstack%2Fdesignate-tempest-plugin~master~Icf18d59a8fdf67e1e9ee893954703a53b0b9f070,openstack/designate-tempest-plugin,master,Icf18d59a8fdf67e1e9ee893954703a53b0b9f070,Fix shared zones tests for scoped tokens,MERGED,2023-04-17 23:17:22.000000000,2023-04-20 03:29:41.000000000,2023-04-20 03:28:40.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-04-17 23:17:22.000000000', 'files': ['designate_tempest_plugin/tests/api/v2/test_shared_zones.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/64a70abee1e7b17e61878e1a7c50ebd450987514', 'message': 'Fix shared zones tests for scoped tokens\n\nScoped tokens do not have a project_id, which caused some of the new\nshared zones tests to fail. This patch corrects that issue by using sudo\nproject ids if scoped tokens is enabled for the test.\n\nChange-Id: Icf18d59a8fdf67e1e9ee893954703a53b0b9f070\n'}]",0,880690,64a70abee1e7b17e61878e1a7c50ebd450987514,8,2,1,11628,,,0,"Fix shared zones tests for scoped tokens

Scoped tokens do not have a project_id, which caused some of the new
shared zones tests to fail. This patch corrects that issue by using sudo
project ids if scoped tokens is enabled for the test.

Change-Id: Icf18d59a8fdf67e1e9ee893954703a53b0b9f070
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/90/880690/1 && git format-patch -1 --stdout FETCH_HEAD,['designate_tempest_plugin/tests/api/v2/test_shared_zones.py'],1,64a70abee1e7b17e61878e1a7c50ebd450987514,," 'Admin user creates shared zone for Alt tenant ' 'using ""x-auth-all-projects"" header') # Scoped tokens do not have a project ID, work around that here if CONF.enforce_scope.designate: headers = self.all_projects_header.copy() headers.update( {'x-auth-sudo-project-id': self.share_zone_client.project_id}) else: headers = self.all_projects_header headers=headers)[1] shared_zone['id'], headers=self.all_projects_header) if CONF.enforce_scope.designate: self.assertEqual(self.share_zone_client.project_id, shared_zone['project_id']) else: self.assertEqual(self.adm_shr_client.project_id, shared_zone['project_id']) # Scoped tokens do not have a project ID, work around that here if CONF.enforce_scope.designate: headers = self.all_projects_header.copy() headers.update( {'x-auth-sudo-project-id': self.share_zone_client.project_id}) else: headers = self.all_projects_header headers=headers)[1] shared_zone['id'], headers=self.all_projects_header) self.zone['id'], shared_zone['id'], headers=self.all_projects_header)[1] # Scoped tokens do not have a project ID, work around that here if CONF.enforce_scope.designate: headers = self.all_projects_header.copy() headers.update( {'x-auth-sudo-project-id': self.share_zone_client.project_id}) else: headers = self.all_projects_header headers=headers)[1] shared_zone['id'], headers=self.all_projects_header) headers=headers)[1] shared_zone['id'], headers=self.all_projects_header) self.zone['id'], headers=self.all_projects_header)[1]"," 'Admin user creates shared zone for Alt tenant' ' using ""x-auth-all-projects"" header') all_projects_header = self.all_projects_header headers=all_projects_header)[1] shared_zone['id'], headers=all_projects_header) self.assertEqual(self.adm_shr_client.project_id, shared_zone['project_id']) all_projects_header = self.all_projects_header headers=all_projects_header)[1] shared_zone['id'], headers=all_projects_header) self.zone['id'], shared_zone['id'], headers=all_projects_header)[1] all_projects_header = self.all_projects_header headers=all_projects_header)[1] shared_zone['id'], headers=all_projects_header) headers=all_projects_header)[1] shared_zone['id'], headers=all_projects_header) self.zone['id'], headers=all_projects_header)[1]",43,17
openstack%2Fcinder~stable%2F2023.1~I3ab2cc28bef7524cec4f161c9d5417597df56b89,openstack/cinder,stable/2023.1,I3ab2cc28bef7524cec4f161c9d5417597df56b89,"Update url of ""Unity Replication White Paper""",MERGED,2023-03-27 02:23:06.000000000,2023-04-20 02:48:46.000000000,2023-04-10 16:07:01.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-27 02:23:06.000000000', 'files': ['doc/source/configuration/block-storage/drivers/dell-emc-unity-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/63e6dfdb081685e6955409082ed0fadd73b5166b', 'message': 'Update url of ""Unity Replication White Paper""\n\nThe website ""www.emc.com"" has been discontinued.\n\nReplace the outdated link\n""https://www.emc.com/collateral/white-papers/h15088-dell-emc-unity-replication-technologies.pdf""\nwith the link\n""https://dl.dell.com/content/docu69886_dell-emc-unity-replication-technologies-a-detailed-review.pdf"".\n\nChange-Id: I3ab2cc28bef7524cec4f161c9d5417597df56b89\n(cherry picked from commit 9714ae828e126f33a804b4cb6890e68ecde760b6)\n'}]",1,878601,63e6dfdb081685e6955409082ed0fadd73b5166b,13,3,1,33787,,,0,"Update url of ""Unity Replication White Paper""

The website ""www.emc.com"" has been discontinued.

Replace the outdated link
""https://www.emc.com/collateral/white-papers/h15088-dell-emc-unity-replication-technologies.pdf""
with the link
""https://dl.dell.com/content/docu69886_dell-emc-unity-replication-technologies-a-detailed-review.pdf"".

Change-Id: I3ab2cc28bef7524cec4f161c9d5417597df56b89
(cherry picked from commit 9714ae828e126f33a804b4cb6890e68ecde760b6)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/878601/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/block-storage/drivers/dell-emc-unity-driver.rst'],1,63e6dfdb081685e6955409082ed0fadd73b5166b,update-url-stable/2023.1,<https://dl.dell.com/content/docu69886_dell-emc-unity-replication-technologies-a-detailed-review.pdf>`_<https://dl.dell.com/content/docu69886_dell-emc-unity-replication-technologies-a-detailed-review.pdf>`_,<https://www.emc.com/collateral/white-papers/h15088-dell-emc-unity-replication-technologies.pdf>`_<https://www.emc.com/collateral/white-papers/h15088-dell-emc-unity-replication-technologies.pdf>`_,2,2
openstack%2Fproject-config~master~I83583afb05e22d92002d92792f2bdf51507e06f2,openstack/project-config,master,I83583afb05e22d92002d92792f2bdf51507e06f2,acl : remove NO_CODE_CHANGE from Allow-Post-Review,MERGED,2023-04-19 05:05:33.000000000,2023-04-20 02:48:25.000000000,2023-04-20 02:01:43.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 05:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/efb29264805cbaeb915fc1ffdc46519daf0ce9d1', 'message': ""acl : remove NO_CODE_CHANGE from Allow-Post-Review\n\nThis is a special label that triggers jobs in a post-review pipeline\nthat has access to secrets.  Core members can trigger this to validate\na change that needs access to those secrets before merge.\n\nThis has been running with the NO_CODE_CHANGE copy-condition since\nit's inception since that is the default state; it was just added\nalong with all others explicity in prior change\nI1f11c07e3786bd1a68b43d908d939fde42ddb99c.\n\nHowever, it's probably best this label specify no copy conditions, so\nany modification at all resets it.  This removes it.\n\nChange-Id: I83583afb05e22d92002d92792f2bdf51507e06f2\n""}, {'number': 2, 'created': '2023-04-20 00:56:54.000000000', 'files': ['gerrit/acls/openstack/openstacksdk.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/89aabb8c671ecca65c27a57ca4ed62ca49525f15', 'message': ""acl : remove NO_CODE_CHANGE from Allow-Post-Review\n\nThis is a special label that triggers jobs in a post-review pipeline\nthat has access to secrets.  Core members can trigger this to validate\na change that needs access to those secrets before merge.\n\nThis has been running with the NO_CODE_CHANGE copy-condition since\nit's inception since that is the default state; it was just added\nalong with all others explicity in prior change\nI1f11c07e3786bd1a68b43d908d939fde42ddb99c.\n\nHowever, it's probably best this label specify no copy conditions, so\nany modification at all resets it.  This removes it.\n\nChange-Id: I83583afb05e22d92002d92792f2bdf51507e06f2\n""}]",0,880792,89aabb8c671ecca65c27a57ca4ed62ca49525f15,11,4,2,7118,,,0,"acl : remove NO_CODE_CHANGE from Allow-Post-Review

This is a special label that triggers jobs in a post-review pipeline
that has access to secrets.  Core members can trigger this to validate
a change that needs access to those secrets before merge.

This has been running with the NO_CODE_CHANGE copy-condition since
it's inception since that is the default state; it was just added
along with all others explicity in prior change
I1f11c07e3786bd1a68b43d908d939fde42ddb99c.

However, it's probably best this label specify no copy conditions, so
any modification at all resets it.  This removes it.

Change-Id: I83583afb05e22d92002d92792f2bdf51507e06f2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/880792/2 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/openstacksdk.config'],1,efb29264805cbaeb915fc1ffdc46519daf0ce9d1,nocodechange,,copyCondition = changekind:NO_CODE_CHANGE,0,1
openstack%2Fproject-config~master~I1f11c07e3786bd1a68b43d908d939fde42ddb99c,openstack/project-config,master,I1f11c07e3786bd1a68b43d908d939fde42ddb99c,gerrit/acls : add NO_CODE_CHANGE,MERGED,2023-04-12 01:39:06.000000000,2023-04-20 02:34:18.000000000,2023-04-20 02:00:29.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 01:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7f90fec609c4d7e4b1145d81e806c00f0c66f61e', 'message': 'gerrit/acls : add NO_CODE_CHANGE\n\nThe old copyAllScoresIfNoChange flag defaults to true, so any ACLs\nwithout it explicitly set to ""false"" (i.e. all of ours) have had the\nequivalant copy-condition flag ""changekind:NO_CODE_CHANGE"" added\nduring migration (see [1]).\n\nAny ACL\'s that were not specifying changekind:NO_CODE_CHANGE are\nupdated so that we are in sync with what is committed in Gerrit.\n\nWe know that updates that match changekind:TRIVIAL_REBASE also match\nchangekind:NO_CODE_CHANGE; however the migration has still added the\nlatter to all rules.  Thus to avoid confusion, we also add it here.\n\n[1] https://bugs.chromium.org/p/gerrit/issues/detail?id=16839\n\nChange-Id: I1f11c07e3786bd1a68b43d908d939fde42ddb99c\n'}, {'number': 2, 'created': '2023-04-19 05:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/66c99e87df21802bd1239312785dbe53f5794e9f', 'message': 'gerrit/acls : add NO_CODE_CHANGE\n\nThe old copyAllScoresIfNoChange flag defaults to true, so any ACLs\nwithout it explicitly set to ""false"" (i.e. all of ours) have had the\nequivalant copy-condition flag ""changekind:NO_CODE_CHANGE"" added\nduring migration (see [1]).\n\nAny ACL\'s that were not specifying changekind:NO_CODE_CHANGE are\nupdated so that we are in sync with what is committed in Gerrit.\n\nWe know that updates that match changekind:TRIVIAL_REBASE also match\nchangekind:NO_CODE_CHANGE; however the migration has still added the\nlatter to all rules.  Thus to avoid confusion, we also add it here.\n\n[1] https://bugs.chromium.org/p/gerrit/issues/detail?id=16839\n\nChange-Id: I1f11c07e3786bd1a68b43d908d939fde42ddb99c\n'}, {'number': 3, 'created': '2023-04-20 00:56:54.000000000', 'files': ['gerrit/acls/x/monasca-vagrant.config', 'gerrit/acls/openstack/os-vif.config', 'gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/placement.config', 'gerrit/acls/openstack/monasca-ui.config', 'gerrit/acls/openstack/python-novaclient.config', 'gerrit/acls/openstack/releases.config', 'gerrit/acls/openstack/release-test.config', 'gerrit/acls/openstack/kolla.config', 'gerrit/acls/openstack/monasca.config', 'gerrit/acls/starlingx/governance.config', 'gerrit/acls/openstack/openstacksdk.config', 'gerrit/acls/openinfra/transparency-policy.config', 'gerrit/acls/openstack/nova-specs.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/opendev/infra-specs.config', 'gerrit/acls/openstack/kayobe.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6f70d8914590a290adf0c3947a96940fb6cb1b66', 'message': 'gerrit/acls : add NO_CODE_CHANGE\n\nThe old copyAllScoresIfNoChange flag defaults to true, so any ACLs\nwithout it explicitly set to ""false"" (i.e. all of ours) have had the\nequivalant copy-condition flag ""changekind:NO_CODE_CHANGE"" added\nduring migration (see [1]).\n\nAny ACL\'s that were not specifying changekind:NO_CODE_CHANGE are\nupdated so that we are in sync with what is committed in Gerrit.\n\nWe know that updates that match changekind:TRIVIAL_REBASE also match\nchangekind:NO_CODE_CHANGE; however the migration has still added the\nlatter to all rules.  Thus to avoid confusion, we also add it here.\n\n[1] https://bugs.chromium.org/p/gerrit/issues/detail?id=16839\n\nChange-Id: I1f11c07e3786bd1a68b43d908d939fde42ddb99c\n'}]",6,880115,6f70d8914590a290adf0c3947a96940fb6cb1b66,17,4,3,7118,,,0,"gerrit/acls : add NO_CODE_CHANGE

The old copyAllScoresIfNoChange flag defaults to true, so any ACLs
without it explicitly set to ""false"" (i.e. all of ours) have had the
equivalant copy-condition flag ""changekind:NO_CODE_CHANGE"" added
during migration (see [1]).

Any ACL's that were not specifying changekind:NO_CODE_CHANGE are
updated so that we are in sync with what is committed in Gerrit.

We know that updates that match changekind:TRIVIAL_REBASE also match
changekind:NO_CODE_CHANGE; however the migration has still added the
latter to all rules.  Thus to avoid confusion, we also add it here.

[1] https://bugs.chromium.org/p/gerrit/issues/detail?id=16839

Change-Id: I1f11c07e3786bd1a68b43d908d939fde42ddb99c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/15/880115/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/x/monasca-vagrant.config', 'gerrit/acls/openstack/os-vif.config', 'gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/placement.config', 'gerrit/acls/openstack/monasca-ui.config', 'gerrit/acls/openstack/python-novaclient.config', 'gerrit/acls/openstack/releases.config', 'gerrit/acls/openstack/release-test.config', 'gerrit/acls/openstack/kolla.config', 'gerrit/acls/openstack/monasca.config', 'gerrit/acls/starlingx/governance.config', 'gerrit/acls/openstack/openstacksdk.config', 'gerrit/acls/openinfra/transparency-policy.config', 'gerrit/acls/openstack/nova-specs.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/opendev/infra-specs.config', 'gerrit/acls/openstack/kayobe.config']",18,7f90fec609c4d7e4b1145d81e806c00f0c66f61e,nocodechange,copyCondition = changekind:NO_CODE_CHANGE OR is:ANYcopyCondition = changekind:NO_CODE_CHANGE OR is:ANY,copyCondition = is:ANYcopyCondition = is:ANY,24,23
openstack%2Fvirtualpdu~master~I8d988040cd14a6f7c874ec7592cffd7787b9948b,openstack/virtualpdu,master,I8d988040cd14a6f7c874ec7592cffd7787b9948b,Fix gitreview; Minor update to readme,MERGED,2023-04-19 23:01:12.000000000,2023-04-20 02:28:21.000000000,2023-04-20 02:26:52.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 23:01:12.000000000', 'files': ['.gitreview', 'README.rst'], 'web_link': 'https://opendev.org/openstack/virtualpdu/commit/7a4388b95f50dc726a56217543175c328942492b', 'message': 'Fix gitreview; Minor update to readme\n\nFixes .gitreview file to point to proper repo location.\n\nThis removes an old link to internap, and slightly improves the readme.\n\nThis likely needs more help, but merging a change will cause the github\nmirror for this repo to sync; which is a needed operation right now.\n\nChange-Id: I8d988040cd14a6f7c874ec7592cffd7787b9948b\n'}]",0,880894,7a4388b95f50dc726a56217543175c328942492b,8,2,1,10342,,,0,"Fix gitreview; Minor update to readme

Fixes .gitreview file to point to proper repo location.

This removes an old link to internap, and slightly improves the readme.

This likely needs more help, but merging a change will cause the github
mirror for this repo to sync; which is a needed operation right now.

Change-Id: I8d988040cd14a6f7c874ec7592cffd7787b9948b
",git fetch https://review.opendev.org/openstack/virtualpdu refs/changes/94/880894/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'README.rst']",2,7a4388b95f50dc726a56217543175c328942492b,,This software is intended for CI and development use only. Please do not run VirtualPDU in a production environment for any reason.* Source: http://opendev.org/openstack/virtualpdu,virtualpdu is licensed under the Apache License like the rest of OpenStack.* Source: http://git.openstack.org/cgit/openstack/virtualpdu* Container version: https://github.com/internap/virtualpdu-container,4,4
openstack%2Fcinder~stable%2F2023.1~Ie7fcaba2e0fcab97a8bdfcada1665405beb778f0,openstack/cinder,stable/2023.1,Ie7fcaba2e0fcab97a8bdfcada1665405beb778f0,Update .gitreview for stable/2023.1,MERGED,2023-03-08 12:43:20.000000000,2023-04-20 01:55:08.000000000,2023-03-08 15:40:08.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-08 12:43:20.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2c8e4ea82810426c442f09ed1dd69acec9ccd827', 'message': 'Update .gitreview for stable/2023.1\n\nChange-Id: Ie7fcaba2e0fcab97a8bdfcada1665405beb778f0\n'}]",0,876857,2c8e4ea82810426c442f09ed1dd69acec9ccd827,13,2,1,22816,,,0,"Update .gitreview for stable/2023.1

Change-Id: Ie7fcaba2e0fcab97a8bdfcada1665405beb778f0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/57/876857/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,2c8e4ea82810426c442f09ed1dd69acec9ccd827,create-2023.1,defaultbranch=stable/2023.1,,1,0
openstack%2Fcinder~master~If1ef9bceae96ef044209c758eee2fd22b44efa49,openstack/cinder,master,If1ef9bceae96ef044209c758eee2fd22b44efa49,Make PowerMax tests stable,MERGED,2023-03-16 20:40:18.000000000,2023-04-19 23:40:16.000000000,2023-03-17 23:31:54.000000000,"[{'_account_id': 5314}, {'_account_id': 12670}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-03-16 20:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb3de1db4b1672d03977db667eca448014d5c859', 'message': 'Make PowerMax tests stable\n\nThe problem manifests itself as an unstable result of\ntest_check_force. It fails at Zuul once in a while. But this\nseems impossible: there is no randomness or timing component.\n\nBut apparently someone forgot a deepcopy().\n\nStill, we also make test_check_force not to depend on the\nglobal specs, seems like an obvious oversight.\n\nChange-Id: If1ef9bceae96ef044209c758eee2fd22b44efa49\n'}, {'number': 2, 'created': '2023-03-17 15:16:52.000000000', 'files': ['cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_rest.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7cf4a89abf68404bb32f0798fe590e846a62164', 'message': 'Make PowerMax tests stable\n\nThe problem manifests itself as an unstable result of\ntest_check_force. It fails at Zuul once in a while. But this\nseems impossible: there is no randomness or timing component\nin this test. The randomness occurs because of cross-test\ninterference.\n\nThe root cause is that apparently someone forgot a deepcopy().\n\nWe also make test_check_force not to depend on the global specs,\nseems like an obvious oversight. It is not the fix, only tidies\nthe code.\n\nChange-Id: If1ef9bceae96ef044209c758eee2fd22b44efa49\n'}]",11,877717,d7cf4a89abf68404bb32f0798fe590e846a62164,54,4,2,597,,,0,"Make PowerMax tests stable

The problem manifests itself as an unstable result of
test_check_force. It fails at Zuul once in a while. But this
seems impossible: there is no randomness or timing component
in this test. The randomness occurs because of cross-test
interference.

The root cause is that apparently someone forgot a deepcopy().

We also make test_check_force not to depend on the global specs,
seems like an obvious oversight. It is not the fix, only tidies
the code.

Change-Id: If1ef9bceae96ef044209c758eee2fd22b44efa49
",git fetch https://review.opendev.org/openstack/cinder refs/changes/17/877717/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_rest.py'],1,bb3de1db4b1672d03977db667eca448014d5c859,powermax_check_force," extra_specs = deepcopy(self.data.extra_specs) extra_specs.pop(utils.FORCE_VOL_EDIT, None) extra_specs, force_flag=False)) extra_specs, force_flag=True))"," extra_specs = self.data.extra_specs if extra_specs.get(utils.FORCE_VOL_EDIT): del extra_specs[utils.FORCE_VOL_EDIT] self.data.extra_specs, force_flag=False)) self.data.extra_specs, force_flag=True))",4,5
openstack%2Fnova~master~I823fbf660948c062581d4e0aaaadc6a6983de2a3,openstack/nova,master,I823fbf660948c062581d4e0aaaadc6a6983de2a3,hyperv: Mark driver as experimental,MERGED,2022-11-07 17:44:03.000000000,2023-04-19 23:32:21.000000000,2023-04-19 13:26:47.000000000,"[{'_account_id': 4393}, {'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 17:44:03.000000000', 'files': ['nova/virt/hyperv/driver.py', 'releasenotes/notes/hyperv-experimental-antelope-372e18a05cafc295.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/9baade7ea16d8273c6cd139d6a0c4cdb9de716f7', 'message': 'hyperv: Mark driver as experimental\n\nCloudbase have changed priorities and will no longer be testing the\nHyper-V driver. We need to mark this as experimental and consider\nremoving it in the future.\n\nChange-Id: I823fbf660948c062581d4e0aaaadc6a6983de2a3\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",9,863910,9baade7ea16d8273c6cd139d6a0c4cdb9de716f7,25,5,1,15334,,,0,"hyperv: Mark driver as experimental

Cloudbase have changed priorities and will no longer be testing the
Hyper-V driver. We need to mark this as experimental and consider
removing it in the future.

Change-Id: I823fbf660948c062581d4e0aaaadc6a6983de2a3
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/863910/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/driver.py', 'releasenotes/notes/hyperv-experimental-antelope-372e18a05cafc295.yaml']",2,9baade7ea16d8273c6cd139d6a0c4cdb9de716f7,deprecate-virt-drivers,--- deprecations: - | The hyperv driver is marked as experimental and may be removed in a future release. The driver is not tested by the OpenStack project and does not have a clear maintainer. ,,14,0
openstack%2Fproject-config~master~Iced8bed78448957e86ab92602b9917b741cb139f,openstack/project-config,master,Iced8bed78448957e86ab92602b9917b741cb139f,Enable IRC notifications for virtualpdu for ironic,MERGED,2023-04-19 23:04:20.000000000,2023-04-19 23:28:00.000000000,2023-04-19 23:25:27.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 23:04:20.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3f576963f1aa47799511c8033b761e636d370a1c', 'message': 'Enable IRC notifications for virtualpdu for ironic\n\nVirtualPDU is part of Ironic again; notify in channel about new patches\nthere.\n\nChange-Id: Iced8bed78448957e86ab92602b9917b741cb139f\n'}]",0,880895,3f576963f1aa47799511c8033b761e636d370a1c,8,3,1,10342,,,0,"Enable IRC notifications for virtualpdu for ironic

VirtualPDU is part of Ironic again; notify in channel about new patches
there.

Change-Id: Iced8bed78448957e86ab92602b9917b741cb139f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/880895/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,3f576963f1aa47799511c8033b761e636d370a1c,, - openstack/virtualpdu,,1,0
openstack%2Fopenstack-ansible~stable%2Fyoga~I43baaa6de2ea370ea4a4d14b5ab69f1c15a86b70,openstack/openstack-ansible,stable/yoga,I43baaa6de2ea370ea4a4d14b5ab69f1c15a86b70,Bump OpenStack-Ansible Yoga,MERGED,2023-04-14 10:50:44.000000000,2023-04-19 23:06:56.000000000,2023-04-19 23:05:32.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 10:50:44.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ee8854879f0aa88e35f7f527a53235e8b96cb2c5', 'message': 'Bump OpenStack-Ansible Yoga\n\nChange-Id: I43baaa6de2ea370ea4a4d14b5ab69f1c15a86b70\n'}]",2,880479,ee8854879f0aa88e35f7f527a53235e8b96cb2c5,14,3,1,28619,,,0,"Bump OpenStack-Ansible Yoga

Change-Id: I43baaa6de2ea370ea4a4d14b5ab69f1c15a86b70
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/79/880479/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml']",5,ee8854879f0aa88e35f7f527a53235e8b96cb2c5,bump_osa, version: a3e7a1f41bf86a2dbb70b919ae084af2b6a94275 shallow_since: '2023-04-03' version: 41a6363db560426836a611f9b91bc112f91d8d1a shallow_since: '2023-04-03' version: 3d1c5c97412b29bb727460ea2c4465cf19f468e8 shallow_since: '2023-04-03' version: b6d171bc9bbcf623db5f3324ecf85fcec4c83016 shallow_since: '2023-04-09' version: 2c5c5ca1622197e106e3885bb253c135aab8de97 shallow_since: '2023-04-05' version: 75d3ec90bc4a30d3b75fea157313a3fb59b494ca shallow_since: '2023-04-10' version: de3b061e954d3259e0a48e2e55878f598ef3a9c1 shallow_since: '2023-04-11' version: 9f44aa21b08b042c22e4e5fd3eae47c64c4d5ba2 shallow_since: '2023-04-10' version: c4a492a248c89c0710489a0f0cd0f95546e6be26 shallow_since: '2023-04-10' version: 01b22161b2bdc102af0863749b4053959b712d9c shallow_since: '2023-03-30', version: 4acaf657873452e0720a1b3f5ba2f889ab88d96e shallow_since: '2023-02-21' version: 522d55b27c6a882d00bfeb0870392ae0bc015981 shallow_since: '2022-12-27' version: ca4951b1d52f284690ed914b5cbba48e5fcf5e23 shallow_since: '2023-02-12' version: 826343637a990f9a97cf7cc214a729eeded9bab3 shallow_since: '2022-06-19' version: 9438ed438a2fc4c94b376694555f8db4532bdabb shallow_since: '2022-06-19' version: 5a6968b4298d785124ab4aa0c431765f184a8d99 shallow_since: '2023-03-02' version: dc35da415cd908f85bbbd733a2f554e00ba0e1d4 shallow_since: '2022-06-22' version: 47c1110f4d8d4855f50aa445da643978e4428387 shallow_since: '2023-03-06' version: dacff1ed6ede207b8afcbfff5e990d875580893b shallow_since: '2022-06-14' version: 54adfc9a3525fec10e1bfd0105d188f7a366f05e shallow_since: '2023-01-11',40,40
openstack%2Fcinder~master~I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05,openstack/cinder,master,I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05,Clean old temporary tracking,NEW,2021-10-22 18:05:41.000000000,2023-04-19 22:34:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-10-22 18:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f05a12f0101323bcad91e2b8a90d15f159d1636b', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 2, 'created': '2021-10-27 09:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6fad034ca2e16c1719b1b0c91357ef4f1a8e99e1', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 3, 'created': '2021-10-27 11:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f277e2b5890f58654ae4625c2f91e6f5a94ca5f0', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 4, 'created': '2021-10-27 20:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/79e68531e7d36581f645923f198cb511209886d4', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 5, 'created': '2021-10-28 08:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2c333fa638d4c079fcfe4f38103abd41d104488d', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 6, 'created': '2021-10-28 11:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/739b589e630b5da9f78d70127f608a3dd04d04f2', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 7, 'created': '2021-11-10 19:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0da85f74afe831a6837bfec62723a343fe5c223d', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 8, 'created': '2021-11-29 18:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e66e1668d9c8c01fe3d4dc2b503e34202aceb92', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 9, 'created': '2021-11-30 17:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e1e5c1eb854c93cceadc52d29f4527688d15a28', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 10, 'created': '2022-02-14 14:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74ad4a50b1e34e1b55cfce3ac0f77f4d6b4c34fb', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 11, 'created': '2022-05-26 11:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/92d08ab7fd1cc55df136dfb23d8f3bebb457aaae', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 12, 'created': '2022-08-29 15:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/723c093e63bc7153469ccc157efb40b6bc7b8fd9', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 13, 'created': '2022-08-29 15:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d58cd0b1095ac7efb5d3456b5bf46a673fad6ba5', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}, {'number': 14, 'created': '2023-03-14 18:08:06.000000000', 'files': ['cinder/db/migrations/versions/9ab1b092a404_make_use_quota_non_nullable.py', 'cinder/tests/unit/test_db_api.py', 'cinder/volume/manager.py', 'cinder/tests/unit/utils.py', 'cinder/cmd/manage.py', 'cinder/db/api.py', 'cinder/db/sqlalchemy/api.py', 'cinder/objects/snapshot.py', 'cinder/tests/unit/volume/flows/test_create_volume_flow.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/volume/driver.py', 'cinder/objects/volume.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/db/sqlalchemy/models.py', 'cinder/tests/unit/db/test_migrations.py', 'cinder/tests/unit/objects/test_snapshot.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/af8f5b0aaf1f520b2c730f4c555d48bb74703735', 'message': 'Clean old temporary tracking\n\nOn Xena we added the use_quota DB field to volumes and snapshots to\nunify the tracking of temporary resources, but we still had to keep\ncompatibility code for the old mechanisms (due to rolling\nupgrades).\n\nThis patch removes compatibility code with the old mechanism and adds\nadditional cleanup code to remove the tracking in the volume metadata.\n\nChange-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05\n'}]",0,815146,af8f5b0aaf1f520b2c730f4c555d48bb74703735,242,1,14,9535,,,0,"Clean old temporary tracking

On Xena we added the use_quota DB field to volumes and snapshots to
unify the tracking of temporary resources, but we still had to keep
compatibility code for the old mechanisms (due to rolling
upgrades).

This patch removes compatibility code with the old mechanism and adds
additional cleanup code to remove the tracking in the volume metadata.

Change-Id: I3f9ed65b0fe58f7b7a0867c0e5ebc0ac3c703b05
",git fetch https://review.opendev.org/openstack/cinder refs/changes/46/815146/12 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/migrations/versions/9ab1b092a404_make_use_quota_non_nullable.py', 'cinder/tests/unit/test_db_api.py', 'cinder/volume/manager.py', 'cinder/cmd/manage.py', 'cinder/db/api.py', 'cinder/db/sqlalchemy/api.py', 'cinder/objects/snapshot.py', 'cinder/tests/unit/volume/flows/test_create_volume_flow.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/volume/driver.py', 'cinder/objects/volume.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/db/sqlalchemy/models.py', 'cinder/tests/unit/db/test_migrations.py', 'cinder/tests/unit/objects/test_snapshot.py']",17,f05a12f0101323bcad91e2b8a90d15f159d1636b,new-quota-prework,,"from cinder.objects import base as ovo_base @ddt.data('1.38', '1.39') def test_obj_make_compatible_use_quota_added(self, version): snapshot = objects.Snapshot(self.context, use_quota=False) serializer = ovo_base.CinderObjectSerializer(version) primitive = serializer.serialize_entity(self.context, snapshot) converted_snapshot = objects.Snapshot.obj_from_primitive(primitive) expected = version != '1.39' self.assertIs(expected, converted_snapshot.use_quota) ",142,372
openstack%2Frequirements~master~Ia6bcf800a284284e88610aad2edd1d60b75142e6,openstack/requirements,master,Ia6bcf800a284284e88610aad2edd1d60b75142e6,Fix overlong line,MERGED,2023-04-19 19:16:05.000000000,2023-04-19 22:05:35.000000000,2023-04-19 22:04:43.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 19:16:05.000000000', 'files': ['openstack_requirements/cmds/update.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4eb4cf59bfcc50e2d77eff1d40f0fac51b35d6a5', 'message': 'Fix overlong line\n\nhacking 6.0.0 was released and this now detects a line that is too long,\nbut went unnoticed before.\n\nSigned-off-by: Dr. Jens Harbott <harbott@osism.tech>\nChange-Id: Ia6bcf800a284284e88610aad2edd1d60b75142e6\n'}]",0,880884,4eb4cf59bfcc50e2d77eff1d40f0fac51b35d6a5,7,2,1,13252,,,0,"Fix overlong line

hacking 6.0.0 was released and this now detects a line that is too long,
but went unnoticed before.

Signed-off-by: Dr. Jens Harbott <harbott@osism.tech>
Change-Id: Ia6bcf800a284284e88610aad2edd1d60b75142e6
",git fetch https://review.opendev.org/openstack/requirements refs/changes/84/880884/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_requirements/cmds/update.py'],1,4eb4cf59bfcc50e2d77eff1d40f0fac51b35d6a5,fix-pep8,"_setup_py_text = """"""\ # Copyright (c) 2013 Hewlett-Packard Development Company, L.P.","_setup_py_text = """"""# Copyright (c) 2013 Hewlett-Packard Development Company, L.P.",2,1
openstack%2Ftripleo-ansible~stable%2Fwallaby~I7c415f97d037922b5545671a3bcb3ab9224835d1,openstack/tripleo-ansible,stable/wallaby,I7c415f97d037922b5545671a3bcb3ab9224835d1,Fix ceph issues on standalone with short hostnames,MERGED,2023-04-18 09:04:59.000000000,2023-04-19 21:40:48.000000000,2023-04-19 21:40:48.000000000,"[{'_account_id': 8367}, {'_account_id': 9976}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}]","[{'number': 1, 'created': '2023-04-18 09:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a7d69e9b2e0de0708e8703bf543badbba6be16ca', 'message': ""Fix ceph issues on standalone with short hostnames\n\nTo resolve ceph stray daemon/hosts issue, [1] is one of the fixes\nwhere shortnames are used in case of tls configuration but it doesn't\nwork for standalone as default hostname itself is\n'standalone.localdomain'\n\nThis patch will fix it by creating host list based on the 'tld' option.\n\n[1] https://review.opendev.org/c/openstack/tripleo-ansible/+/879486\n\nChange-Id: I7c415f97d037922b5545671a3bcb3ab9224835d1\n""}, {'number': 2, 'created': '2023-04-18 12:45:11.000000000', 'files': ['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c2d4176a662407fd878d55bce0815ffc2f293368', 'message': ""Fix ceph issues on standalone with short hostnames\n\nTo resolve ceph stray daemon/hosts issue, [1] is one of the fixes\nwhere shortnames are used in case of tls configuration but it doesn't\nwork for standalone as default hostname itself is\n'standalone.localdomain'\n\nThis patch will fix it by creating host list based on the 'tld' option.\n\n[1] https://review.opendev.org/c/openstack/tripleo-ansible/+/879486\n\nCloses-Bug: lp#2016861\nChange-Id: I7c415f97d037922b5545671a3bcb3ab9224835d1\n""}]",6,880521,c2d4176a662407fd878d55bce0815ffc2f293368,21,5,2,34598,,,0,"Fix ceph issues on standalone with short hostnames

To resolve ceph stray daemon/hosts issue, [1] is one of the fixes
where shortnames are used in case of tls configuration but it doesn't
work for standalone as default hostname itself is
'standalone.localdomain'

This patch will fix it by creating host list based on the 'tld' option.

[1] https://review.opendev.org/c/openstack/tripleo-ansible/+/879486

Closes-Bug: lp#2016861
Change-Id: I7c415f97d037922b5545671a3bcb3ab9224835d1
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/21/880521/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'],1,a7d69e9b2e0de0708e8703bf543badbba6be16ca,fix_standalone_stray, cephadm_admin_hosts: >- {%- if tld_option -%} {{ cephadm_admin_hosts + [ item.hostname.split('.')[0] ] }} {%- else -%} {{ cephadm_admin_hosts + [ item.hostname ] }} {%- endif -%} cephadm_non_admin_hosts: >- {%- if tld_option -%} {{ cephadm_non_admin_hosts + [ item.hostname.split('.')[0] ] }} {%- else -%} {{ cephadm_non_admin_hosts + [ item.hostname ] }} {%- endif -%}," cephadm_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname.split('.')[0] ] }}"" cephadm_non_admin_hosts: ""{{ cephadm_non_admin_hosts + [ item.hostname.split('.')[0] ] }}""",12,2
openstack%2Fcinder~master~Ifb52819ddc4db22507805c77c5562ca3e3600e1a,openstack/cinder,master,Ifb52819ddc4db22507805c77c5562ca3e3600e1a,Add note about MYSQL_REDUCE_MEMORY,MERGED,2023-03-30 16:11:35.000000000,2023-04-19 21:03:06.000000000,2023-04-05 21:03:31.000000000,"[{'_account_id': 9535}, {'_account_id': 13425}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-03-30 16:11:35.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/513690a81c5de7a35da5ca15f884777610b8e4d1', 'message': ""Add note about MYSQL_REDUCE_MEMORY\n\nAdded a note to the two CI jobs that increase host memory about\na recently added devstack option [0] so that we don't forget about\nit.\n\n[0] I7b223391d3de\n\nChange-Id: Ifb52819ddc4db22507805c77c5562ca3e3600e1a\n""}]",3,879057,513690a81c5de7a35da5ca15f884777610b8e4d1,36,4,1,5314,,,0,"Add note about MYSQL_REDUCE_MEMORY

Added a note to the two CI jobs that increase host memory about
a recently added devstack option [0] so that we don't forget about
it.

[0] I7b223391d3de

Change-Id: Ifb52819ddc4db22507805c77c5562ca3e3600e1a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/57/879057/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,513690a81c5de7a35da5ca15f884777610b8e4d1,mem-usage-note," # NOTE: if jobs are having memory problems, may want # to turn this on (currently defaults to false): # MYSQL_REDUCE_MEMORY: true # NOTE: if jobs are having memory problems, may want # to turn this on (currently defaults to false): # MYSQL_REDUCE_MEMORY: true",,6,0
openstack%2Fkolla-ansible~stable%2Fzed~Ic650ba6be1f192e3cbeaa94de3d00507636c1c92,openstack/kolla-ansible,stable/zed,Ic650ba6be1f192e3cbeaa94de3d00507636c1c92,Fix create sasl account before config file is ready,MERGED,2023-04-18 19:26:43.000000000,2023-04-19 20:37:10.000000000,2023-04-19 20:35:26.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-18 19:26:43.000000000', 'files': ['releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/228ff5744ec2a892d511fb27221ed83afc9d8f73', 'message': 'Fix create sasl account before config file is ready\n\nAdd checking for container readiness before create sasl user\n\nCloses-Bug: #2015589\nChange-Id: Ic650ba6be1f192e3cbeaa94de3d00507636c1c92\n(cherry picked from commit 46415123d59fbb6d281b4d0f32e4dbf527fe8c6e)\n'}]",0,880776,228ff5744ec2a892d511fb27221ed83afc9d8f73,10,5,1,14200,,,0,"Fix create sasl account before config file is ready

Add checking for container readiness before create sasl user

Closes-Bug: #2015589
Change-Id: Ic650ba6be1f192e3cbeaa94de3d00507636c1c92
(cherry picked from commit 46415123d59fbb6d281b4d0f32e4dbf527fe8c6e)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/880776/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml']",2,228ff5744ec2a892d511fb27221ed83afc9d8f73,bug/2015589," nova_libvirt_notify: ""{{ ['Checking libvirt container is ready', 'Create libvirt SASL user'] if libvirt_enable_sasl | bool else [] }}"" # need to wait kolla_set_configs script to overwrite sasl config file - name: Checking libvirt container is ready become: true shell: cmd: > set -o pipefail && {{ kolla_container_engine }} exec -i nova_libvirt ls /run/libvirtd.pid executable: /bin/bash register: libvirt_container_ready until: libvirt_container_ready is succeeded retries: 10 "," nova_libvirt_notify: ""{{ ['Create libvirt SASL user'] if libvirt_enable_sasl | bool else [] }}""",18,1
openstack%2Fkolla-ansible~stable%2Fzed~Id79445c0311916ac6c1beb3986e14f652ee5a63c,openstack/kolla-ansible,stable/zed,Id79445c0311916ac6c1beb3986e14f652ee5a63c,Fix maximum width of the DIB Multiline-YAML,MERGED,2023-04-18 14:54:10.000000000,2023-04-19 20:36:24.000000000,2023-04-19 20:35:22.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-18 14:54:10.000000000', 'files': ['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c78f8569b389a5a24c7b124f0ff4eebe1a0a9bca', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)\n""}]",0,880756,c78f8569b389a5a24c7b124f0ff4eebe1a0a9bca,9,4,1,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

Closes-Bug: #2014980
Related-Bug: #2014981
Change-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 47862b56bd90c3edaab3345577901367a73cfd98)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/56/880756/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py']",2,c78f8569b389a5a24c7b124f0ff4eebe1a0a9bca,dib-yaml-width," yaml_width: description: - The maximum width of the YAML document. By default, Ansible uses the PyYAML library which has a default 80 symbol string length limit. To change the limit, the new value can be used here. default: None required: False type: int yaml_width: 131072 yaml_width = self._task.args.get('yaml_width', None) f.write(yaml.dump(output, default_flow_style=False, width=yaml_width)) new_task.args.pop('yaml_width', None)"," f.write(yaml.dump(output, default_flow_style=False))",14,1
openstack%2Fgrenade~master~Ie5acf1ad7f8dca39db07f7e61035a8916439004d,openstack/grenade,master,Ie5acf1ad7f8dca39db07f7e61035a8916439004d,[ironic] Add an instance wait setting for nova resources,MERGED,2023-04-05 16:57:04.000000000,2023-04-19 20:36:22.000000000,2023-04-19 20:35:09.000000000,"[{'_account_id': 4393}, {'_account_id': 8556}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-04-05 16:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/929dde1625448933e9c7e56ae3260d52a44cbe1f', 'message': ""[ironic] Add an instance wait setting for nova resources\n\nIn troubleshooting grenade failures in ironic,\nwe've observed a sporatic failure causing the\nironic-grenade job to fail upwards of 20-40%\nof the time where it seems cirros, due to the\nboot sequencing and interfaces, is not\nonline for networking until after sixty seconds\nhave passed. In one case 83 seconds before the\nnetworking was fully online.\n\nIn consulting with neutron contributors, a random\njob check seems to reveal that even with pure VM\nworkloads, it takes on average 35 seconds into the\nping check. As such, it seems reasonable to make\nthe setting configurable so ironic-grenade can\nexecute with an increased timeout more appropriate\nto the job settings and test environment.\n\nAdds a INSTANCE_WAIT variable, which defaults to\nthe prior setting which was static, 60 seconds.\n\nChange-Id: Ie5acf1ad7f8dca39db07f7e61035a8916439004d\n""}, {'number': 2, 'created': '2023-04-05 17:56:46.000000000', 'files': ['projects/60_nova/resources.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/d8294440e7dede370b5ee80facf49a511dc7eb09', 'message': ""[ironic] Add an instance wait setting for nova resources\n\nIn troubleshooting grenade failures in ironic,\nwe've observed a sporatic failure causing the\nironic-grenade job to fail upwards of 20-40%\nof the time where it seems cirros, due to the\nboot sequencing and interfaces, is not\nonline for networking until after sixty seconds\nhave passed. In one case 83 seconds before the\nnetworking was fully online.\n\nIn consulting with neutron contributors, a random\njob check seems to reveal that even with pure VM\nworkloads, it takes on average 35 seconds into the\nping check. As such, it seems reasonable to make\nthe setting configurable so ironic-grenade can\nexecute with an increased timeout more appropriate\nto the job settings and test environment.\n\nAdds a INSTANCE_WAIT variable, which defaults to\nthe prior setting which was static, 60 seconds.\n\nChange-Id: Ie5acf1ad7f8dca39db07f7e61035a8916439004d\n""}]",7,879674,d8294440e7dede370b5ee80facf49a511dc7eb09,24,6,2,11655,,,0,"[ironic] Add an instance wait setting for nova resources

In troubleshooting grenade failures in ironic,
we've observed a sporatic failure causing the
ironic-grenade job to fail upwards of 20-40%
of the time where it seems cirros, due to the
boot sequencing and interfaces, is not
online for networking until after sixty seconds
have passed. In one case 83 seconds before the
networking was fully online.

In consulting with neutron contributors, a random
job check seems to reveal that even with pure VM
workloads, it takes on average 35 seconds into the
ping check. As such, it seems reasonable to make
the setting configurable so ironic-grenade can
execute with an increased timeout more appropriate
to the job settings and test environment.

Adds a INSTANCE_WAIT variable, which defaults to
the prior setting which was static, 60 seconds.

Change-Id: Ie5acf1ad7f8dca39db07f7e61035a8916439004d
",git fetch https://review.opendev.org/openstack/grenade refs/changes/74/879674/2 && git format-patch -1 --stdout FETCH_HEAD,['projects/60_nova/resources.sh'],1,929dde1625448933e9c7e56ae3260d52a44cbe1f,,INSTANCE_WAIT=$(INSTANCE_WAIT:-60} ping_check_public $ip $INSTANCE_WAIT ping_check_public $server_ip $INSTANCE_WAIT, ping_check_public $ip 60 ping_check_public $server_ip 60,3,2
openstack%2Fkolla-ansible~stable%2Fzed~Ia056aa40e996b1f0fed43c0f672466c7e4a2f547,openstack/kolla-ansible,stable/zed,Ia056aa40e996b1f0fed43c0f672466c7e4a2f547,Remove RabbitMQ ha-all policy when not required,MERGED,2023-03-08 10:28:17.000000000,2023-04-19 20:35:24.000000000,2023-04-19 20:35:24.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-03-08 10:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8ee59b8f82a5a2ce784a304261f6550da1306ecd', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. The `ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n(cherry picked from commit e5c0fe4bfa8d5573e0c4346825b7f2775c96a538)\n'}, {'number': 2, 'created': '2023-04-19 08:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/632a492fe07bd172f9ea5dbf102113998bfdc5b7', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. The `ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n(cherry picked from commit e5c0fe4bfa8d5573e0c4346825b7f2775c96a538)\n'}, {'number': 3, 'created': '2023-04-19 14:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d56778517d4c1311ce723e4f0cf68bf0da455cc6', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. It is also now used in the deploy task. The\n`ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n(cherry picked from commit c85b64d1589a515da2f3cf2dcc082d15df1d6edd)\n'}, {'number': 4, 'created': '2023-04-19 14:52:19.000000000', 'files': ['ansible/roles/rabbitmq/tasks/upgrade.yml', 'ansible/roles/rabbitmq/tasks/deploy.yml', 'releasenotes/notes/rabbitmq-remove-ha-all-policy-when-not-required-81dcf64542c4805f.yaml', 'ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3dfca54dfb3be04283e2c5d6800e27cc5a3d8776', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. It is also now used in the deploy task. The\n`ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n(cherry picked from commit c85b64d1589a515da2f3cf2dcc082d15df1d6edd)\n'}]",0,876829,3dfca54dfb3be04283e2c5d6800e27cc5a3d8776,16,4,4,35263,,,0,"Remove RabbitMQ ha-all policy when not required

With the addition of the variable
`om_enable_rabbitmq_high_availability`, this feature in the upgrade
task should be brought back. It is also now used in the deploy task. The
`ha-all` policy is cleared only when
`om_enable_rabbitmq_high_availability` is set to `false`.

Change-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547
(cherry picked from commit c85b64d1589a515da2f3cf2dcc082d15df1d6edd)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/29/876829/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/tasks/upgrade.yml', 'releasenotes/notes/rabbitmq-remove-ha-all-policy-when-not-required-81dcf64542c4805f.yaml']",2,8ee59b8f82a5a2ce784a304261f6550da1306ecd,remove-ha-all-when-not-required-stable/zed,"--- fixes: - | When upgrading RabbitMQ, the policy `ha-all` is cleared if `om_enable_rabbitmq_high_availability` is set to `false`. ",,28,0
openstack%2Fneutron~master~I3888d457d1c069c24eb8943fb54b9a9dc9f14819,openstack/neutron,master,I3888d457d1c069c24eb8943fb54b9a9dc9f14819,ovn: allow RA and NA for stateless SGs by default,ABANDONED,2023-03-09 23:43:19.000000000,2023-04-19 20:02:18.000000000,,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-09 23:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0504fc935c0ccc483d35f81b4b9ab2ddf1cdbbdd', 'message': 'ovn: allow RA and NA for stateless SGs by default\n\nWith this patch, stateless SGs will allow service ipv6 traffic by\ndefault. This is needed to allow VMs to configure their SLAAC and DHCPv6\naddresses.\n\nCloses-Bug: #2006949\nChange-Id: I3888d457d1c069c24eb8943fb54b9a9dc9f14819\n'}, {'number': 2, 'created': '2023-03-10 02:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcd69797eb8808bb895f5eac9c3b82b6bf4cd193', 'message': 'ovn: allow RA and NA for stateless SGs by default\n\nWith this patch, stateless SGs will allow service ipv6 traffic by\ndefault. This is needed to allow VMs to configure their SLAAC and DHCPv6\naddresses.\n\nCloses-Bug: #2006949\nChange-Id: I3888d457d1c069c24eb8943fb54b9a9dc9f14819\n'}, {'number': 3, 'created': '2023-03-29 20:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44efd4a14d2cd9fe7f5aab294fbdfe6e1f54d3a2', 'message': 'ovn: allow RA and NA for stateless SGs by default\n\nWith this patch, stateless SGs will allow service ipv6 traffic by\ndefault. This is needed to allow VMs to configure their SLAAC and DHCPv6\naddresses.\n\nCloses-Bug: #2006949\nChange-Id: I3888d457d1c069c24eb8943fb54b9a9dc9f14819\n'}, {'number': 4, 'created': '2023-03-29 20:58:31.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/tests/unit/common/ovn/test_acl.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py', 'neutron/common/ovn/acl.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f8f32f0c5276ee4cd419f00aa512e68da1a760b', 'message': 'ovn: allow RA and NA for stateless SGs by default\n\nWith this patch, stateless SGs will allow service ipv6 traffic by\ndefault. This is needed to allow VMs to configure their SLAAC and DHCPv6\naddresses.\n\nCloses-Bug: #2006949\nChange-Id: I3888d457d1c069c24eb8943fb54b9a9dc9f14819\n'}]",11,877049,8f8f32f0c5276ee4cd419f00aa512e68da1a760b,31,7,4,9656,,,0,"ovn: allow RA and NA for stateless SGs by default

With this patch, stateless SGs will allow service ipv6 traffic by
default. This is needed to allow VMs to configure their SLAAC and DHCPv6
addresses.

Closes-Bug: #2006949
Change-Id: I3888d457d1c069c24eb8943fb54b9a9dc9f14819
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/877049/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/tests/unit/common/ovn/test_acl.py', 'neutron/common/ovn/acl.py']",3,0504fc935c0ccc483d35f81b4b9ab2ddf1cdbbdd,bug/2006949,"def get_metadata_acl(security_group_id): return metadata_acl def get_icmpv6_acl(security_group_id, icmp_type, icmp_code): icmp_rule = { 'direction': const.INGRESS_DIRECTION, 'ethertype': const.IPv6, 'normalized_cidr': const.IPv6_ANY, 'remote_group_id': None, 'protocol': const.PROTO_NAME_IPV6_ICMP, 'port_range_min': icmp_type, 'port_range_max': icmp_code, 'id': None, } icmp_acl = _add_sg_rule_acl_for_port_group( utils.ovn_port_group_name(security_group_id), False, icmp_rule) return icmp_acl def get_stateless_acls(security_group_id): metadata_acl = get_metadata_acl(security_group_id) ra_acl = get_icmpv6_acl(security_group_id, const.ICMPV6_TYPE_RA, 0) na_acl = get_icmpv6_acl(security_group_id, const.ICMPV6_TYPE_NA, 0) def service_acl(acl): acl = acl.copy() acl[ovn_const.OVN_SG_EXT_ID_KEY] = security_group_id return acl return [service_acl(acl) for acl in (metadata_acl, ra_acl, na_acl)]","def get_stateless_acls(security_group_id): metadata_acl[ovn_const.OVN_SG_EXT_ID_KEY] = security_group_id return [ metadata_acl, ]",73,13
openstack%2Fneutron~master~I1f519147bca11f12a335f7821e92652da8ea1f57,openstack/neutron,master,I1f519147bca11f12a335f7821e92652da8ea1f57,ovn: store neutron:revision_number for Port_Groups,ABANDONED,2023-03-07 03:10:47.000000000,2023-04-19 20:01:56.000000000,,"[{'_account_id': 1131}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-03-07 03:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a2b5ae62e2a67816d42d460bbf22e0c9d88e4e4', 'message': 'ovn: store neutron:revision_number for Port_Groups\n\nA consequent patch will utilize it to detect db inconsistencies between\nneutron and ovn databases.\n\nRelated-Bug: #2009053\nChange-Id: I1f519147bca11f12a335f7821e92652da8ea1f57\n'}, {'number': 2, 'created': '2023-03-09 00:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1db308bb7c4b8138cd332343da030c20de4deae', 'message': 'ovn: store neutron:revision_number for Port_Groups\n\nA consequent patch will utilize it to detect db inconsistencies between\nneutron and ovn databases.\n\nRelated-Bug: #2009053\nChange-Id: I1f519147bca11f12a335f7821e92652da8ea1f57\n'}, {'number': 3, 'created': '2023-03-09 21:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/731130425c2226005637bb833b1c623a0e9cb4ec', 'message': 'ovn: store neutron:revision_number for Port_Groups\n\nA consequent patch will utilize it to detect db inconsistencies between\nneutron and ovn databases.\n\nRelated-Bug: #2009053\nChange-Id: I1f519147bca11f12a335f7821e92652da8ea1f57\n'}, {'number': 4, 'created': '2023-03-29 20:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e245cb6b9d6d51b19518ba987c9b359e44c72ede', 'message': 'ovn: store neutron:revision_number for Port_Groups\n\nA consequent patch will utilize it to detect db inconsistencies between\nneutron and ovn databases.\n\nRelated-Bug: #2006949\nChange-Id: I1f519147bca11f12a335f7821e92652da8ea1f57\n'}, {'number': 5, 'created': '2023-03-29 20:58:31.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_maintenance.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d103d9d983bb03ce44fa3da7458d46bffdcc49ea', 'message': 'ovn: store neutron:revision_number for Port_Groups\n\nA consequent patch will utilize it to detect db inconsistencies between\nneutron and ovn databases.\n\nRelated-Bug: #2006949\nChange-Id: I1f519147bca11f12a335f7821e92652da8ea1f57\n'}]",21,876658,d103d9d983bb03ce44fa3da7458d46bffdcc49ea,44,7,5,9656,,,0,"ovn: store neutron:revision_number for Port_Groups

A consequent patch will utilize it to detect db inconsistencies between
neutron and ovn databases.

Related-Bug: #2006949
Change-Id: I1f519147bca11f12a335f7821e92652da8ea1f57
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/876658/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_maintenance.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py']",5,1a2b5ae62e2a67816d42d460bbf22e0c9d88e4e4,bug/2006949," 'ovn_update': self._ovn_client.update_security_group, # The migration will run just once per neutron-server instance. If the lock # is held by some other neutron-server instance in the cloud, we'll attempt # to perform the migration every 10 seconds until completed. # TODO(ihrachys): Remove this after the first SLURP release after Bobcat. @periodics.periodic(spacing=10, run_immediately=True) def populate_revision_numbers_for_port_groups(self): """"""Populate revision numbers for port groups, which is used to detect inconsistencies. """""" # Collect names of PGs that miss revision numbers in ovn db sg_ids = {} for name, pg in self._nb_idl.get_sg_port_groups().items(): ext_ids = pg['external_ids'] if ovn_const.OVN_REV_NUM_EXT_ID_KEY not in ext_ids: sg_ids[ext_ids[ovn_const.OVN_SG_EXT_ID_KEY]] = pg['name'] if not sg_ids: raise periodics.NeverAgain() # Extract revision numbers from neutron api context = n_context.get_admin_context() sgs = self._ovn_client._plugin.get_security_groups( context, filters={'id': set(sg_ids.keys())}, fields=('id', 'revision_number')) # Execute ovn db commands to update revision numbers cmds = [] for sg in sgs: revision_number = sg.get('revision_number') if not revision_number: continue external_ids = { ovn_const.OVN_REV_NUM_EXT_ID_KEY: str(revision_number), } cmds.append(self._nb_idl.db_set( 'Port_Group', sg_ids[sg['id']], ('external_ids', external_ids))) if cmds: with self._nb_idl.transaction(check_error=True) as txn: for cmd in cmds: txn.add(cmd) # Don't repeat this migration step in this thread anymore raise periodics.NeverAgain() "," elif row.resource_type == ovn_const.TYPE_SECURITY_GROUPS: # In OVN, we don't care about updates to security groups, # so just bump the revision number to whatever it's # supposed to be. revision_numbers_db.bump_revision(context, n_obj, row.resource_type)",80,26
openstack%2Fcharm-nova-compute-nvidia-vgpu~master~Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d,openstack/charm-nova-compute-nvidia-vgpu,master,Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:10:57.000000000,2023-04-19 19:46:07.000000000,2023-04-19 19:46:07.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-nvidia-vgpu/commit/eeebcef96b91025323642a3b6166cb6480f4b6c1', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d\n'}, {'number': 2, 'created': '2023-04-14 15:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-nvidia-vgpu/commit/cceb4eb538b3bb1d4bfcdba303f8cfededef56ed', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nDepends-On: https://review.opendev.org/c/openstack/charm-rabbitmq-server/+/880234\nChange-Id: Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d\n'}, {'number': 3, 'created': '2023-04-17 14:30:18.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml', 'tests/bundles/lunar-antelope.yaml', 'tests/bundles/jammy-antelope.yaml', 'tests/bundles/jammy-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-nvidia-vgpu/commit/ea0f81ad9c4717eeb9f017961696b0646899018a', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Drop source key for rabbitmq-server and mysql-innodb-cluster\n\nDepends-On: https://review.opendev.org/c/openstack/charm-rabbitmq-server/+/880234\nChange-Id: Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d\n'}]",6,878995,ea0f81ad9c4717eeb9f017961696b0646899018a,23,4,3,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Drop source key for rabbitmq-server and mysql-innodb-cluster

Depends-On: https://review.opendev.org/c/openstack/charm-rabbitmq-server/+/880234
Change-Id: Ic3d462816f2a189e35406aa2fab6153ed8bb2e1d
",git fetch https://review.opendev.org/openstack/charm-nova-compute-nvidia-vgpu refs/changes/95/878995/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,eeebcef96b91025323642a3b6166cb6480f4b6c1,antelope-voting,, - kinetic-zed - kinetic-zed,0,230
openstack%2Fovsdbapp~stable%2F2023.1~I9cfb99ea7c5c28ee8ff168e32131406fb30583ea,openstack/ovsdbapp,stable/2023.1,I9cfb99ea7c5c28ee8ff168e32131406fb30583ea,Update TOX_CONSTRAINTS_FILE for stable/2023.1,MERGED,2023-03-02 13:26:30.000000000,2023-04-19 19:20:16.000000000,2023-04-19 19:18:31.000000000,"[{'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-02 13:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/e5c89575adb9c67a2c466de002a7e3a47a4693b3', 'message': 'Update TOX_CONSTRAINTS_FILE for stable/2023.1\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/2023.1 branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I9cfb99ea7c5c28ee8ff168e32131406fb30583ea\n'}, {'number': 2, 'created': '2023-04-19 16:45:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/b24ea98df959e9883e88f75d2a9ebc876af22f87', 'message': 'Update TOX_CONSTRAINTS_FILE for stable/2023.1\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/2023.1 branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I9cfb99ea7c5c28ee8ff168e32131406fb30583ea\n'}]",0,876092,b24ea98df959e9883e88f75d2a9ebc876af22f87,13,4,2,22816,,,0,"Update TOX_CONSTRAINTS_FILE for stable/2023.1

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/2023.1 branch, tests will
continue to use the upper-constraints list on master.

Change-Id: I9cfb99ea7c5c28ee8ff168e32131406fb30583ea
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/92/876092/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e5c89575adb9c67a2c466de002a7e3a47a4693b3,create-2023.1, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/2023.1} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/2023.1}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/xena},2,2
openstack%2Fwhitebox-tempest-plugin~master~Ie32e84b3c5d015cab2c7737fdf5fd9f3a8ea8ea1,openstack/whitebox-tempest-plugin,master,Ie32e84b3c5d015cab2c7737fdf5fd9f3a8ea8ea1,[WIP] Map container/srv names to compute nodes,NEW,2023-04-14 20:19:21.000000000,2023-04-19 19:19:37.000000000,,"[{'_account_id': 8864}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 20:19:21.000000000', 'files': ['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/7be1d0915ef3d953aec28deeed769059524dca7e', 'message': ""[WIP] Map container/srv names to compute nodes\n\nPOC'ing mapping container and services names to respective compute nodes\nvia dictionary mapping in tempest.conf. This is to address the fact that\nnova modularized libvirt with Wallaby.\n\nChange-Id: Ie32e84b3c5d015cab2c7737fdf5fd9f3a8ea8ea1\n""}]",11,880546,7be1d0915ef3d953aec28deeed769059524dca7e,4,3,1,31033,,,0,"[WIP] Map container/srv names to compute nodes

POC'ing mapping container and services names to respective compute nodes
via dictionary mapping in tempest.conf. This is to address the fact that
nova modularized libvirt with Wallaby.

Change-Id: Ie32e84b3c5d015cab2c7737fdf5fd9f3a8ea8ea1
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/46/880546/1 && git format-patch -1 --stdout FETCH_HEAD,"['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/config.py']",2,7be1d0915ef3d953aec28deeed769059524dca7e,multi_rhel_naming," cfg.DictOpt( 'mixed_rhel_libvirt_container_mapping', default=None, help='Dictionary of control plane addresses. The keys are the'), cfg.DictOpt( 'mixed_rhel_service_mapping', default=None, help='Dictionary of control plane addresses. The keys are the')",,43,6
openstack%2Fovsdbapp~stable%2F2023.1~I883b1acf1b495281b929284f8892a336560872a5,openstack/ovsdbapp,stable/2023.1,I883b1acf1b495281b929284f8892a336560872a5,Update .gitreview for stable/2023.1,MERGED,2023-03-02 13:26:29.000000000,2023-04-19 19:19:27.000000000,2023-04-19 19:18:30.000000000,"[{'_account_id': 5756}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-02 13:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/604d1c79b53159713099036d44b37a2e8dee0986', 'message': 'Update .gitreview for stable/2023.1\n\nChange-Id: I883b1acf1b495281b929284f8892a336560872a5\n'}, {'number': 2, 'created': '2023-04-19 16:44:53.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/ea7c4253c1b392d84d569944f51fd422f40f6aa6', 'message': 'Update .gitreview for stable/2023.1\n\nChange-Id: I883b1acf1b495281b929284f8892a336560872a5\n'}]",1,876091,ea7c4253c1b392d84d569944f51fd422f40f6aa6,15,3,2,22816,,,0,"Update .gitreview for stable/2023.1

Change-Id: I883b1acf1b495281b929284f8892a336560872a5
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/91/876091/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,604d1c79b53159713099036d44b37a2e8dee0986,create-2023.1,defaultbranch=stable/2023.1,,1,0
openstack%2Fkayobe~master~Ia956cfea7e7bfe47bf1e73c9edcac602caf45579,openstack/kayobe,master,Ia956cfea7e7bfe47bf1e73c9edcac602caf45579,Adds support for custom Multipathd configuration.,MERGED,2023-03-31 16:02:11.000000000,2023-04-19 18:49:45.000000000,2023-04-19 18:48:44.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-03-31 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bf2ee8d29436dfa50fbbd3313a51bf966cd8327d', 'message': 'Adds support for custom Multipathd configuration.\n\nChange-Id: Ia956cfea7e7bfe47bf1e73c9edcac602caf45579\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 2, 'created': '2023-04-01 12:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e894952c06e73c2d594d13618dd307fa0d507252', 'message': 'Adds support for custom Multipathd configuration.\n\nChange-Id: Ia956cfea7e7bfe47bf1e73c9edcac602caf45579\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 3, 'created': '2023-04-13 20:56:14.000000000', 'files': ['ansible/roles/kolla-openstack/tasks/config.yml', 'doc/source/configuration/reference/kolla-ansible.rst', 'ansible/roles/kolla-openstack/molecule/enable-everything/tests/test_default.py', 'ansible/roles/kolla-openstack/molecule/enable-everything/molecule.yml', 'releasenotes/notes/add-extended-multipath-conf-a6b874fb0f43fed5.yaml', 'ansible/roles/kolla-openstack/templates/multipath.conf.j2', 'ansible/roles/kolla-openstack/defaults/main.yml', 'ansible/kolla-openstack.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/25fe761e62f647ed828dc5441d651fb4433c8bf0', 'message': 'Adds support for custom Multipathd configuration.\n\nChange-Id: Ia956cfea7e7bfe47bf1e73c9edcac602caf45579\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}]",5,879190,25fe761e62f647ed828dc5441d651fb4433c8bf0,18,3,3,14200,,,0,"Adds support for custom Multipathd configuration.

Change-Id: Ia956cfea7e7bfe47bf1e73c9edcac602caf45579
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/90/879190/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-openstack/tasks/config.yml', 'doc/source/configuration/reference/kolla-ansible.rst', 'ansible/roles/kolla-openstack/molecule/enable-everything/tests/test_default.py', 'ansible/roles/kolla-openstack/molecule/enable-everything/molecule.yml', 'releasenotes/notes/add-extended-multipath-conf-a6b874fb0f43fed5.yaml', 'ansible/roles/kolla-openstack/defaults/main.yml', 'ansible/roles/kolla-openstack/templates/multipath.conf.j2', 'ansible/kolla-openstack.yml']",8,bf2ee8d29436dfa50fbbd3313a51bf966cd8327d,add-multipathd-config-support," - { name: multipathd, file: multipath.conf } kolla_extra_multipathd: ""{{ kolla_extra_config.multipathd | default }}""",,31,0
openstack%2Fkolla-ansible~master~I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d,openstack/kolla-ansible,master,I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d,cli: fix find globals.d,MERGED,2023-03-31 12:03:17.000000000,2023-04-19 18:30:42.000000000,2023-04-19 18:29:39.000000000,"[{'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-31 12:03:17.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/35b92825b1cf428e7de121a217f9064668006f33', 'message': 'cli: fix find globals.d\n\nCurrently when the /etc/kolla/globals.d directory does not exist\nit writes an error on stderr.\n\nChange-Id: I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d\n'}]",1,879154,35b92825b1cf428e7de121a217f9064668006f33,12,3,1,22629,,,0,"cli: fix find globals.d

Currently when the /etc/kolla/globals.d directory does not exist
it writes an error on stderr.

Change-Id: I2d4b3dd9dde3d383af213dc6fd376bc14c650a7d
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/54/879154/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla-ansible'],1,35b92825b1cf428e7de121a217f9064668006f33,,"EXTRA_GLOBALS=$([ -d ""${GLOBALS_DIR}"" ] && find ${GLOBALS_DIR} -maxdepth 1 -type f -name '*.yml' -printf ' -e @%p' || true 2>/dev/null)",EXTRA_GLOBALS=$(find ${GLOBALS_DIR} -maxdepth 1 -type f -name '*.yml' -printf ' -e @%p' || true 2>/dev/null),1,1
openstack%2Fovsdbapp~master~Iff708c259a5500848eab73b05da70300ff8e4134,openstack/ovsdbapp,master,Iff708c259a5500848eab73b05da70300ff8e4134,Add 'no timeout' option to wait_for_change,MERGED,2022-09-15 04:58:32.000000000,2023-04-19 17:20:26.000000000,2023-04-19 17:19:23.000000000,"[{'_account_id': 4694}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2022-09-15 04:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/ffc7642e8c1c16f0ae04d19e14e837e4513ecf16', 'message': ""WIP: Add 'no timeout' option to wait_for_change\n\nNeutron currently overrides wait_for_change because it needs a\nversion without a timeout. This adds the ability to set either\ntimeout=None or timeout <= 0 to not timeout.\n\nTODO:\nWrite tests\n\nChange-Id: Iff708c259a5500848eab73b05da70300ff8e4134\n""}, {'number': 2, 'created': '2022-09-16 04:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/ca2162fed72fc69ffaa406f24b6c7a1268d91f60', 'message': ""Add 'no timeout' option to wait_for_change\n\nNeutron currently overrides wait_for_change because it needs a\nversion without a timeout. This adds the ability to set either\ntimeout=None or timeout <= 0 to not timeout.\n\nChange-Id: Iff708c259a5500848eab73b05da70300ff8e4134\n""}, {'number': 3, 'created': '2023-04-18 21:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/3ee5d0f4826ab1e165605ce565291dbcd86b6db0', 'message': ""Add 'no timeout' option to wait_for_change\n\nNeutron currently overrides wait_for_change because it needs a\nversion without a timeout. This adds the ability to set either\ntimeout=None or timeout <= 0 to not timeout.\n\nChange-Id: Iff708c259a5500848eab73b05da70300ff8e4134\n""}, {'number': 4, 'created': '2023-04-18 21:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/f991dc901c5f57c1622949f482c6f19de571fbcc', 'message': ""Add 'no timeout' option to wait_for_change\n\nNeutron currently overrides wait_for_change because it needs a\nversion without a timeout. This adds the ability to set either\ntimeout=None or timeout <= 0 to not timeout.\n\nChange-Id: Iff708c259a5500848eab73b05da70300ff8e4134\n""}, {'number': 5, 'created': '2023-04-18 23:25:07.000000000', 'files': ['ovsdbapp/backend/ovs_idl/idlutils.py', 'ovsdbapp/tests/unit/backend/ovs_idl/test_idlutils.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/d1afa56c2d5fc794e9b6304c664c98d7fb97f531', 'message': ""Add 'no timeout' option to wait_for_change\n\nNeutron currently overrides wait_for_change because it needs a\nversion without a timeout. This adds the ability to set either\ntimeout=None or timeout <= 0 to not timeout.\n\nChange-Id: Iff708c259a5500848eab73b05da70300ff8e4134\n""}]",22,857806,d1afa56c2d5fc794e9b6304c664c98d7fb97f531,32,6,5,5756,,,0,"Add 'no timeout' option to wait_for_change

Neutron currently overrides wait_for_change because it needs a
version without a timeout. This adds the ability to set either
timeout=None or timeout <= 0 to not timeout.

Change-Id: Iff708c259a5500848eab73b05da70300ff8e4134
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/06/857806/2 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/backend/ovs_idl/idlutils.py'],1,ffc7642e8c1c16f0ae04d19e14e837e4513ecf16,,"def wait_for_change(_idl, timeout=None, seqno=None): """"""Wait for the Idl seqno to change :param _idl: The Idl instance :type: ovs.db.idl.Idl :param timeout: raise a TimeoutException after if timeout > 0/not None :type: int or None """""" if timeout <= 0: timeout = None stop = time.time() + timeout if timeout else None if timeout: ovs_poller.timer_wait(timeout * 1000) if stop and time.time() > stop: raise exceptions.TimeoutException()","def wait_for_change(_idl, timeout, seqno=None): stop = time.time() + timeout ovs_poller.timer_wait(timeout * 1000) if time.time() > stop: raise Exception(""Timeout"") # TODO(twilson) use TimeoutException?",15,5
openstack%2Fovsdbapp~stable%2F2023.1~I61195cd3ebf8a5015890d3ba3988c3d9795ee817,openstack/ovsdbapp,stable/2023.1,I61195cd3ebf8a5015890d3ba3988c3d9795ee817,Use OVN's OVS submodule for functional tests,MERGED,2023-04-19 13:01:05.000000000,2023-04-19 17:20:19.000000000,2023-04-19 17:19:25.000000000,"[{'_account_id': 5756}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 13:01:05.000000000', 'files': ['tools/setup-ovs.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/14bc41fcdf475e58dd235248756e9a2b608418eb', 'message': ""Use OVN's OVS submodule for functional tests\n\nThe OVN tree for several years has had an OVS submodule that pulls\nin the version of OVS it is guaranteed to work with. There is\ncurrently a patch in OVS master that breaks the build of OVN main\nso switch to using the submodule.\n\nChange-Id: I61195cd3ebf8a5015890d3ba3988c3d9795ee817\n(cherry picked from commit ee28e381fb46a04be3451de65a5166dd457eede8)\n""}]",1,880830,14bc41fcdf475e58dd235248756e9a2b608418eb,11,3,1,16688,,,0,"Use OVN's OVS submodule for functional tests

The OVN tree for several years has had an OVS submodule that pulls
in the version of OVS it is guaranteed to work with. There is
currently a patch in OVS master that breaks the build of OVN main
so switch to using the submodule.

Change-Id: I61195cd3ebf8a5015890d3ba3988c3d9795ee817
(cherry picked from commit ee28e381fb46a04be3451de65a5166dd457eede8)
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/30/880830/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/setup-ovs.sh', 'tox.ini']",2,14bc41fcdf475e58dd235248756e9a2b608418eb,, OVS_SRCDIR={envdir}/src/ovn/ovs VTEP_SRCDIR={envdir}src/ovn/ovs/vtep, OVS_SRCDIR={envdir}/src/ovs VTEP_SRCDIR={envdir}/src/ovs/vtep OVS_BRANCH={env:OVS_BRANCH:},11,21
openstack%2Fkolla-ansible~master~I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9,openstack/kolla-ansible,master,I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9,Update notes about CentOS support,MERGED,2023-03-27 15:45:56.000000000,2023-04-19 17:13:01.000000000,2023-04-19 17:11:06.000000000,"[{'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26264}]","[{'number': 1, 'created': '2023-03-27 15:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/45933cb60b901268e7bd149cdc3c13c99dace171', 'message': 'Drop note about CentOS 7 support\n\nThe Train release shipped more than 3 years ago. It is time to remove\nthis note.\n\nChange-Id: I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9\n'}, {'number': 2, 'created': '2023-03-29 10:02:46.000000000', 'files': ['doc/source/user/support-matrix.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8f82c2948e667d55dd1bd483c280192e09ee4fbd', 'message': 'Update notes about CentOS support\n\nRemove notes referring to old releases (Train, Victoria). Add a note to\ncover migration to RL9.\n\nChange-Id: I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9\n'}]",2,878698,8f82c2948e667d55dd1bd483c280192e09ee4fbd,12,4,2,15197,,,0,"Update notes about CentOS support

Remove notes referring to old releases (Train, Victoria). Add a note to
cover migration to RL9.

Change-Id: I57bcc9c3967fb6cdea56cb9a252255322ec2f1c9
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/98/878698/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/support-matrix.rst'],1,45933cb60b901268e7bd149cdc3c13c99dace171,centos7-support,," CentOS 7 is no longer supported as a host OS. The Train release supports both CentOS 7 and 8, and provides a route for migration. See the `Kolla Ansible Train documentation <https://docs.openstack.org/kolla-ansible/train/user/centos8.html>`_ for information on migrating to CentOS 8. .. note:: ",0,10
openstack%2Fkolla~master~Ic7871c79d0916b99f3fd2243a0fa4f9d84aca37e,openstack/kolla,master,Ic7871c79d0916b99f3fd2243a0fa4f9d84aca37e,Update Stackalytics links,MERGED,2023-03-14 08:49:28.000000000,2023-04-19 17:12:33.000000000,2023-04-19 17:11:09.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-14 08:49:28.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6789bf8d58954ed936300cbce7cb99b2809e28f5', 'message': 'Update Stackalytics links\n\nChange-Id: Ic7871c79d0916b99f3fd2243a0fa4f9d84aca37e\n'}]",1,877346,6789bf8d58954ed936300cbce7cb99b2809e28f5,9,2,1,32657,,,0,"Update Stackalytics links

Change-Id: Ic7871c79d0916b99f3fd2243a0fa4f9d84aca37e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/46/877346/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,6789bf8d58954ed936300cbce7cb99b2809e28f5,,code <https://stackalytics.io/?module=kolla-group&metric=commits>`__ andreviews <https://stackalytics.io/?module=kolla-group&metric=marks>`__.,code <https://stackalytics.com/?module=kolla-group&metric=commits>`__ andreviews <https://stackalytics.com/?module=kolla-group&metric=marks>`__.,2,2
openstack%2Fkolla-ansible~master~Ic5e64998bd01923162204f7bb289cc110187feec,openstack/kolla-ansible,master,Ic5e64998bd01923162204f7bb289cc110187feec,Add precheck to fail if RabbitMQ HA needs configuring,MERGED,2023-04-13 08:59:51.000000000,2023-04-19 17:12:12.000000000,2023-04-19 17:11:04.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-13 08:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9072d9138f78420731b5db611353f9e7ee070c00', 'message': 'RabbitMQ: Add instructions for migrating to durable queues\n\nEnabling the flag ``om_enable_rabbitmq_high_availability`` will\nreconfigure RabbitMQ and the OpenStack services which use it to use\nclassic queue mirroring and durable queues. However, queue durability\ncannot be changed on existing queues. As such, there are additional\nsteps required to migrate from transient to durable queues. This adds\ndocumentation to describe these steps.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}, {'number': 2, 'created': '2023-04-14 11:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8aa4b3a516c98dd7888d021915e7d703831d0c40', 'message': 'Add precheck to fail if RabbitMQ HA needs configuring\n\nCurrently, the process of enabling RabbitMQ HA with the variable\n``om_enable_rabbitmq_high_availbility`` requires some manual steps to\nmigrate from transient to mirrored queues. In preparation for setting\nthis variable to ``True`` by default, this adds a precheck that will\nfail if a system is currently running non-mirrored queues and\n``om_enable_rabbitmq_high_availbility`` is set to ``True``.\n\nIncludes a helpful message informing the operator of their choice.\nEither follow the manual procedure to migrate the queues described in\nthe docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.\n\nThe RabbitMQ HA section of the reference docs is updated to include\nthese instructions.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}, {'number': 3, 'created': '2023-04-14 12:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5a4cc774c6dc874a366777cc73f0149988b49218', 'message': 'Add precheck to fail if RabbitMQ HA needs configuring\n\nCurrently, the process of enabling RabbitMQ HA with the variable\n``om_enable_rabbitmq_high_availbility`` requires some manual steps to\nmigrate from transient to mirrored queues. In preparation for setting\nthis variable to ``True`` by default, this adds a precheck that will\nfail if a system is currently running non-mirrored queues and\n``om_enable_rabbitmq_high_availbility`` is set to ``True``.\n\nIncludes a helpful message informing the operator of their choice.\nEither follow the manual procedure to migrate the queues described in\nthe docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.\n\nThe RabbitMQ HA section of the reference docs is updated to include\nthese instructions.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}, {'number': 4, 'created': '2023-04-17 09:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8572550fd1d1146a2b810f49749a2595d7e6e7b2', 'message': 'Add precheck to fail if RabbitMQ HA needs configuring\n\nCurrently, the process of enabling RabbitMQ HA with the variable\n``om_enable_rabbitmq_high_availbility`` requires some manual steps to\nmigrate from transient to mirrored queues. In preparation for setting\nthis variable to ``True`` by default, this adds a precheck that will\nfail if a system is currently running non-mirrored queues and\n``om_enable_rabbitmq_high_availbility`` is set to ``True``.\n\nIncludes a helpful message informing the operator of their choice.\nEither follow the manual procedure to migrate the queues described in\nthe docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.\n\nThe RabbitMQ HA section of the reference docs is updated to include\nthese instructions.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}, {'number': 5, 'created': '2023-04-17 15:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d53e4dbb02fb11df6e700981d1181710e9d38c60', 'message': 'Add precheck to fail if RabbitMQ HA needs configuring\n\nCurrently, the process of enabling RabbitMQ HA with the variable\n``om_enable_rabbitmq_high_availbility`` requires some manual steps to\nmigrate from transient to mirrored queues. In preparation for setting\nthis variable to ``True`` by default, this adds a precheck that will\nfail if a system is currently running non-mirrored queues and\n``om_enable_rabbitmq_high_availbility`` is set to ``True``.\n\nIncludes a helpful message informing the operator of their choice.\nEither follow the manual procedure to migrate the queues described in\nthe docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.\n\nThe RabbitMQ HA section of the reference docs is updated to include\nthese instructions.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}, {'number': 6, 'created': '2023-04-19 08:45:48.000000000', 'files': ['doc/source/reference/message-queues/rabbitmq.rst', 'ansible/roles/rabbitmq/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a5331d3208a0bcb4aada9b65acb71c51353cd9b9', 'message': 'Add precheck to fail if RabbitMQ HA needs configuring\n\nCurrently, the process of enabling RabbitMQ HA with the variable\n``om_enable_rabbitmq_high_availbility`` requires some manual steps to\nmigrate from transient to mirrored queues. In preparation for setting\nthis variable to ``True`` by default, this adds a precheck that will\nfail if a system is currently running non-mirrored queues and\n``om_enable_rabbitmq_high_availbility`` is set to ``True``.\n\nIncludes a helpful message informing the operator of their choice.\nEither follow the manual procedure to migrate the queues described in\nthe docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.\n\nThe RabbitMQ HA section of the reference docs is updated to include\nthese instructions.\n\nChange-Id: Ic5e64998bd01923162204f7bb289cc110187feec\n'}]",12,880274,a5331d3208a0bcb4aada9b65acb71c51353cd9b9,39,4,6,35263,,,0,"Add precheck to fail if RabbitMQ HA needs configuring

Currently, the process of enabling RabbitMQ HA with the variable
``om_enable_rabbitmq_high_availbility`` requires some manual steps to
migrate from transient to mirrored queues. In preparation for setting
this variable to ``True`` by default, this adds a precheck that will
fail if a system is currently running non-mirrored queues and
``om_enable_rabbitmq_high_availbility`` is set to ``True``.

Includes a helpful message informing the operator of their choice.
Either follow the manual procedure to migrate the queues described in
the docs, or set ``om_enable_rabbitmq_high_availbility`` to ``False``.

The RabbitMQ HA section of the reference docs is updated to include
these instructions.

Change-Id: Ic5e64998bd01923162204f7bb289cc110187feec
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/74/880274/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/message-queues/rabbitmq.rst'],1,9072d9138f78420731b5db611353f9e7ee070c00,," After enabling this value on a running system, there are some additional steps needed to migrate from transient to durable queues. 1. Stop all OpenStack services which use RabbitMQ. 2. Reset the state on each RabbitMQ node with the following commands. Each command must be run on all RabbitMQ nodes before moving on to the next command. This will remove all queues. .. code-block:: console rabbitmqctl stop_app rabbitmqctl force_reset rabbitmqctl start_app 3. Start the OpenStack services again, at which point they will recreate the appropriate queues as durable.",,18,0
openstack%2Fkolla~stable%2Fyoga~I66ea5711810ed0060cf89192a780bfcc92e79770,openstack/kolla,stable/yoga,I66ea5711810ed0060cf89192a780bfcc92e79770,Replace invisible unicode chars,MERGED,2023-03-28 15:58:35.000000000,2023-04-19 17:12:00.000000000,2023-04-19 17:11:01.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 32657}]","[{'number': 1, 'created': '2023-03-28 15:58:35.000000000', 'files': ['docker/base/Dockerfile.j2', 'specs/logging-with-heka.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/59dd65a99ba4614137bae0a6ed5ba719877ba2a2', 'message': ""Replace invisible unicode chars\n\nThey're believed to have no special meaning and were put by accident.\n\nTrivialFix\n\nChange-Id: I66ea5711810ed0060cf89192a780bfcc92e79770\n(cherry picked from commit 2ddf0aeb204d754636ded6ff2be4e2dcfc3ee421)\n""}]",0,878666,59dd65a99ba4614137bae0a6ed5ba719877ba2a2,10,4,1,22629,,,0,"Replace invisible unicode chars

They're believed to have no special meaning and were put by accident.

TrivialFix

Change-Id: I66ea5711810ed0060cf89192a780bfcc92e79770
(cherry picked from commit 2ddf0aeb204d754636ded6ff2be4e2dcfc3ee421)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/66/878666/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'specs/logging-with-heka.rst']",2,59dd65a99ba4614137bae0a6ed5ba719877ba2a2,,spec proposes with Heka. But this would mean running a JVM on each cluster,spec proposes with Heka. But this would mean running a JVM on each cluster,3,3
openstack%2Fkolla~stable%2Fzed~I66ea5711810ed0060cf89192a780bfcc92e79770,openstack/kolla,stable/zed,I66ea5711810ed0060cf89192a780bfcc92e79770,Replace invisible unicode chars,MERGED,2023-03-28 15:58:26.000000000,2023-04-19 16:46:42.000000000,2023-04-19 16:44:44.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 32657}]","[{'number': 1, 'created': '2023-03-28 15:58:26.000000000', 'files': ['docker/base/Dockerfile.j2', 'specs/logging-with-heka.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2cb59e45a592056b01b2f3a401535738f87de35c', 'message': ""Replace invisible unicode chars\n\nThey're believed to have no special meaning and were put by accident.\n\nTrivialFix\n\nChange-Id: I66ea5711810ed0060cf89192a780bfcc92e79770\n(cherry picked from commit 2ddf0aeb204d754636ded6ff2be4e2dcfc3ee421)\n""}]",0,878665,2cb59e45a592056b01b2f3a401535738f87de35c,10,4,1,22629,,,0,"Replace invisible unicode chars

They're believed to have no special meaning and were put by accident.

TrivialFix

Change-Id: I66ea5711810ed0060cf89192a780bfcc92e79770
(cherry picked from commit 2ddf0aeb204d754636ded6ff2be4e2dcfc3ee421)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/65/878665/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'specs/logging-with-heka.rst']",2,2cb59e45a592056b01b2f3a401535738f87de35c,,spec proposes with Heka. But this would mean running a JVM on each cluster,spec proposes with Heka. But this would mean running a JVM on each cluster,3,3
openstack%2Fkayobe~master~I03a826e98a18b158774ba100cfa2987299eb6c25,openstack/kayobe,master,I03a826e98a18b158774ba100cfa2987299eb6c25,Fix an issue when 'acl' package can be forgotten,MERGED,2022-09-29 12:41:40.000000000,2023-04-19 16:31:49.000000000,2023-04-19 16:29:47.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-09-29 12:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/cf9197e00f06d8fbe652774fd66944f7939cc38d', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 2, 'created': '2022-10-14 09:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/ff83d85f359b673dd5e858630484124b2171fe63', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 3, 'created': '2022-10-14 10:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/843f7e44a4e555f168bbf23767fb1270aba39535', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 4, 'created': '2022-10-14 10:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2105d9a13c1efb21aebc94e561478ccc4ba5bafc', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 5, 'created': '2023-02-21 17:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e2d2c7b3f552ad6da2bb4547b0deb68dccccafce', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 6, 'created': '2023-02-21 20:49:56.000000000', 'files': ['ansible/roles/dev-tools/defaults/main.yml', 'doc/source/configuration/reference/hosts.rst'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/5e8a8233da46b321f03d9323a746e72422ba7670', 'message': ""Fix an issue when 'acl' package can be forgotten\n\nThis is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to\navoid user accidentely forgot the 'acl' package when override the\ndev_tools_packages_default in their custom configuration. Also this\nadds an ability to customise list of packages installed in addition\nto the default list.\n\nChange-Id: I03a826e98a18b158774ba100cfa2987299eb6c25\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}]",12,859842,5e8a8233da46b321f03d9323a746e72422ba7670,30,4,6,14200,,,0,"Fix an issue when 'acl' package can be forgotten

This is folllowup on I69bf810632d09eddaa3983ae56e833debe9fd03b to
avoid user accidentely forgot the 'acl' package when override the
dev_tools_packages_default in their custom configuration. Also this
adds an ability to customise list of packages installed in addition
to the default list.

Change-Id: I03a826e98a18b158774ba100cfa2987299eb6c25
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/42/859842/5 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/dev-tools/defaults/main.yml'],1,cf9197e00f06d8fbe652774fd66944f7939cc38d,fix-acl-forgotten,"# List of extra packages to install. dev_tools_packages_extra: [] # List of required packages to install. dev_tools_packages_system: # NOTE(mgoddard): The acl package is required for the setfacl command, used by # become_user. - acl dev_tools_packages: ""{{ dev_tools_packages_default + dev_tools_packages_extra + dev_tools_packages_system }}"""," # NOTE(mgoddard): The acl package is required for the setfacl command, used by # become_user. - acldev_tools_packages: ""{{ dev_tools_packages_default }}""",10,4
openstack%2Fkayobe~master~I339042d9ce405f59aba936dd98df7d89a88bb41e,openstack/kayobe,master,I339042d9ce405f59aba936dd98df7d89a88bb41e,Fix maximum width of the DIB Multiline-YAML,MERGED,2022-03-14 14:35:32.000000000,2023-04-19 16:31:00.000000000,2023-04-19 16:29:44.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-03-14 14:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2a571cec772cc7d2e03579a867b9375f93ff2c3c', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe dependent change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nDepends-On: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 2, 'created': '2022-03-15 15:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e594e57840625843c1890b8daada4f6568928822', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe dependent change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nDepends-On: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 3, 'created': '2022-03-15 17:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0f33b7fa5934d1dc67215a96f54899d009e8131c', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe dependent change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nDepends-On: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 4, 'created': '2022-03-15 19:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bb94814f971befac5fb55157b47d102a6d420e60', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe dependent change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nDepends-On: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 5, 'created': '2022-03-15 19:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/fe4f9291f00e7dd3067d20df567a8d5422af354f', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe dependent change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nDepends-On: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 6, 'created': '2023-04-02 00:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/954272c7b7271160b35240bf94503e67bf2be994', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 7, 'created': '2023-04-02 00:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/775774c6c25afcb88d84d0b4d564e8caa43cec76', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 8, 'created': '2023-04-13 10:59:29.000000000', 'files': ['ansible/roles/kolla-bifrost/tasks/main.yml', 'kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nThe related change for Kolla-Ansible is also provided:\nId79445c0311916ac6c1beb3986e14f652ee5a63c\n\nCloses-Bug: #2014981\nRelated-Bug: #2014980\nChange-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}]",10,833634,5cf750c3135a8cbbcbe8b003269cb79ef6f0e8ab,35,4,8,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

The related change for Kolla-Ansible is also provided:
Id79445c0311916ac6c1beb3986e14f652ee5a63c

Closes-Bug: #2014981
Related-Bug: #2014980
Change-Id: I339042d9ce405f59aba936dd98df7d89a88bb41e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/34/833634/8 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/plugins/action/merge_yaml.py', 'ansible/roles/kolla-bifrost/templates/kolla/config/bifrost/dib.yml']",2,2a571cec772cc7d2e03579a867b9375f93ff2c3c,dib-yaml-width,{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml(width=131072) }},{{ {'dib_env_vars': kolla_bifrost_dib_env_vars} | to_nice_yaml }},12,2
openstack%2Fironic~stable%2Fzed~I1730279d2225f1248ecf7fe403a5e503b6c3ff87,openstack/ironic,stable/zed,I1730279d2225f1248ecf7fe403a5e503b6c3ff87,[iRMC] Handle IPMI incompatibility in iRMC S6 2.x,MERGED,2023-01-18 04:56:30.000000000,2023-04-19 15:59:10.000000000,2023-04-19 15:57:49.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-18 04:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/302a119d6a3bd60a0e41c8943586cd08fc8fb412', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}, {'number': 2, 'created': '2023-01-20 05:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9690af499a3b2f24d9971213fde5c547137cb62', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}, {'number': 3, 'created': '2023-01-20 07:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/542565bb6ad795ec18eeed6ac51c1ee0574f9c32', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}, {'number': 4, 'created': '2023-01-23 07:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/608bb1d215af3c68512c4a2a995012f108b478ae', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}, {'number': 5, 'created': '2023-02-06 02:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f05ea7e2c391d2061ea71395b8a7fc4b51c8885a', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}, {'number': 6, 'created': '2023-03-06 12:00:48.000000000', 'files': ['ironic/tests/unit/drivers/modules/irmc/test_power.py', 'releasenotes/notes/fix-irmc-s6-2.00-ipmi-incompatibility-118484a424df02b1.yaml', 'ironic/drivers/modules/irmc/common.py', 'ironic/drivers/modules/irmc/management.py', 'ironic/drivers/modules/irmc/power.py', 'ironic/tests/unit/drivers/modules/irmc/test_inspect.py', 'doc/source/admin/drivers/irmc.rst', 'ironic/tests/unit/drivers/modules/irmc/test_management.py', 'ironic/drivers/modules/irmc/inspect.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e928980e78a4bdc2711b05f4f51749e0df4337f6', 'message': ""[iRMC] Handle IPMI incompatibility in iRMC S6 2.x\n\nSince iRMC S6 2.00, iRMC firmware disables IPMI over LAN\nwith default iRMC firmware configuration.\n\nTo deal with this firmware incompatibility, this commit\nmodifies driver's methods which use IPMI to first try\nIPMI and, if IPMI fails, try to use Redfish API.\n\nStory: 2010396\nTask: 46746\nChange-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87\n(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)\n""}]",5,870881,e928980e78a4bdc2711b05f4f51749e0df4337f6,41,3,6,30566,,,0,"[iRMC] Handle IPMI incompatibility in iRMC S6 2.x

Since iRMC S6 2.00, iRMC firmware disables IPMI over LAN
with default iRMC firmware configuration.

To deal with this firmware incompatibility, this commit
modifies driver's methods which use IPMI to first try
IPMI and, if IPMI fails, try to use Redfish API.

Story: 2010396
Task: 46746
Change-Id: I1730279d2225f1248ecf7fe403a5e503b6c3ff87
(cherry picked from commit d23f72ee501a5bdcc89806eb0ebbba929a36e64d)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/81/870881/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/irmc/test_power.py', 'releasenotes/notes/fix-irmc-s6-2.00-ipmi-incompatibility-118484a424df02b1.yaml', 'ironic/drivers/modules/irmc/common.py', 'ironic/drivers/modules/irmc/management.py', 'ironic/drivers/modules/irmc/power.py', 'ironic/tests/unit/drivers/modules/irmc/test_inspect.py', 'doc/source/admin/drivers/irmc.rst', 'ironic/tests/unit/drivers/modules/irmc/test_management.py', 'ironic/drivers/modules/irmc/inspect.py']",9,302a119d6a3bd60a0e41c8943586cd08fc8fb412,handle_irmc_s6_2.00_incompatibility_zed,"irmc = importutils.try_import('scciclient.irmc')def _get_capabilities_properties_without_ipmi(d_info, cap_props, current_cap, props): capabilities = {} snmp_client = snmp.SNMPClient( address=d_info['irmc_address'], port=d_info['irmc_snmp_port'], version=d_info['irmc_snmp_version'], read_community=d_info['irmc_snmp_community'], user=d_info.get('irmc_snmp_user'), auth_proto=d_info.get('irmc_snmp_auth_proto'), auth_key=d_info.get('irmc_snmp_auth_password'), priv_proto=d_info.get('irmc_snmp_priv_proto'), priv_key=d_info.get('irmc_snmp_priv_password')) if 'rom_firmware_version' in cap_props: capabilities['rom_firmware_version'] = \ irmc.snmp.get_bios_firmware_version(snmp_client) if 'irmc_firmware_version' in cap_props: capabilities['irmc_firmware_version'] = \ irmc.snmp.get_irmc_firmware_version(snmp_client) if 'server_model' in cap_props: capabilities['server_model'] = irmc.snmp.get_server_model( snmp_client) capabilities = utils.get_updated_capabilities(current_cap, capabilities) if capabilities: props['capabilities'] = capabilities return props props = irmc.scci.get_essential_properties( if node.driver_internal_info.get('irmc_ipmi_succeed'): capabilities = irmc.scci.get_capabilities_properties( d_info, capabilities_props, gpu_ids, fpga_ids=fpga_ids, **kwargs) if capabilities: if capabilities.get('pci_gpu_devices') == 0: capabilities.pop('pci_gpu_devices') cpu_fpga = capabilities.pop('cpu_fpga', 0) if cpu_fpga == 0 and 'CUSTOM_CPU_FPGA' in new_traits: new_traits.remove('CUSTOM_CPU_FPGA') elif cpu_fpga != 0 and 'CUSTOM_CPU_FPGA' not in new_traits: new_traits.append('CUSTOM_CPU_FPGA') # Ironic no longer supports trusted boot capabilities.pop('trusted_boot', None) capabilities = utils.get_updated_capabilities( node.properties.get('capabilities', ''), capabilities) if capabilities: props['capabilities'] = capabilities else: props = _get_capabilities_properties_without_ipmi( d_info, capabilities_props, node.properties.get('capabilities', ''), props) except (irmc.scci.SCCIInvalidInputError, irmc.scci.SCCIClientError,","scci = importutils.try_import('scciclient.irmc.scci') props = scci.get_essential_properties( capabilities = scci.get_capabilities_properties( d_info, capabilities_props, gpu_ids, fpga_ids=fpga_ids, **kwargs) if capabilities: if capabilities.get('pci_gpu_devices') == 0: capabilities.pop('pci_gpu_devices') cpu_fpga = capabilities.pop('cpu_fpga', 0) if cpu_fpga == 0 and 'CUSTOM_CPU_FPGA' in new_traits: new_traits.remove('CUSTOM_CPU_FPGA') elif cpu_fpga != 0 and 'CUSTOM_CPU_FPGA' not in new_traits: new_traits.append('CUSTOM_CPU_FPGA') # Ironic no longer supports trusted boot capabilities.pop('trusted_boot', None) capabilities = utils.get_updated_capabilities( node.properties.get('capabilities'), capabilities) if capabilities: props['capabilities'] = capabilities except (scci.SCCIInvalidInputError, scci.SCCIClientError,",791,86
openstack%2Foctavia~stable%2Fwallaby~I02804b7075edac72776b0377b7b283d0c7bfd8a2,openstack/octavia,stable/wallaby,I02804b7075edac72776b0377b7b283d0c7bfd8a2,Fix failover when the last listener is deleted,NEW,2023-04-14 06:49:28.000000000,2023-04-19 15:53:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-04-14 06:49:28.000000000', 'files': ['octavia/amphorae/backends/health_daemon/health_daemon.py', 'releasenotes/notes/Fix-listener-delete-causing-failover-251efdb79af24c0a.yaml', 'octavia/tests/unit/amphorae/backends/health_daemon/test_health_daemon.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f81563f9ee1c7ee98c7d879eede9330b8bf15f33', 'message': 'Fix failover when the last listener is deleted\n\nThis patch fixes an issue when deleting the last listener from a load balancer\nmay trigger a failover.\n\nStory: 2010652\nTask: 47683\nChange-Id: I02804b7075edac72776b0377b7b283d0c7bfd8a2\n(cherry picked from commit ba92aeb946343c045e8363a2aae78e0a17a6cb82)\n(cherry picked from commit e7f4b1b4c21d0a2b12022032caa38602f5341a20)\n(cherry picked from commit 658173e5b7f5dcbe5e309801b7d8488442f858e4)\n(cherry picked from commit 4e15e81208e198553163ff01e90a47ae0d481ced)\n(cherry picked from commit c58f2cb591055f5968f92d762abcd5005e68e324)\n'}]",2,880455,f81563f9ee1c7ee98c7d879eede9330b8bf15f33,6,2,1,29244,,,0,"Fix failover when the last listener is deleted

This patch fixes an issue when deleting the last listener from a load balancer
may trigger a failover.

Story: 2010652
Task: 47683
Change-Id: I02804b7075edac72776b0377b7b283d0c7bfd8a2
(cherry picked from commit ba92aeb946343c045e8363a2aae78e0a17a6cb82)
(cherry picked from commit e7f4b1b4c21d0a2b12022032caa38602f5341a20)
(cherry picked from commit 658173e5b7f5dcbe5e309801b7d8488442f858e4)
(cherry picked from commit 4e15e81208e198553163ff01e90a47ae0d481ced)
(cherry picked from commit c58f2cb591055f5968f92d762abcd5005e68e324)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/55/880455/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/health_daemon/health_daemon.py', 'releasenotes/notes/Fix-listener-delete-causing-failover-251efdb79af24c0a.yaml', 'octavia/tests/unit/amphorae/backends/health_daemon/test_health_daemon.py']",3,f81563f9ee1c7ee98c7d879eede9330b8bf15f33,," @mock.patch('octavia.amphorae.backends.utils.haproxy_query.HAProxyQuery') def test_get_stats_exception(self, mock_query): mock_query.side_effect = Exception('Boom') stats, pool_status = health_daemon.get_stats('TEST') self.assertEqual([], stats) self.assertEqual({}, pool_status) ",,22,3
openstack%2Fmanila~master~I0caadcd64469b14a95392978159dba4ea3a10fe8,openstack/manila,master,I0caadcd64469b14a95392978159dba4ea3a10fe8,Remove stanza check from netapp driver code,ABANDONED,2023-04-19 13:26:50.000000000,2023-04-19 15:44:02.000000000,,[],"[{'number': 1, 'created': '2023-04-19 13:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/40fbfa9ca102c5fd790051f4323792e74267566c', 'message': 'Remove stanza check from netapp driver code\n\nChange-Id: I0caadcd64469b14a95392978159dba4ea3a10fe8\nCloses-Bug: #2012742\n'}]",0,880831,40fbfa9ca102c5fd790051f4323792e74267566c,6,0,1,35879,,,0,"Remove stanza check from netapp driver code

Change-Id: I0caadcd64469b14a95392978159dba4ea3a10fe8
Closes-Bug: #2012742
",git fetch https://review.opendev.org/openstack/manila refs/changes/31/880831/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,40fbfa9ca102c5fd790051f4323792e74267566c,oslo.config backend driver compatibility,,,0,0
openstack%2Fcharm-keystone~master~I9fe0f9f73c5b6bb4261e45a900a8c1f0274ee586,openstack/charm-keystone,master,I9fe0f9f73c5b6bb4261e45a900a8c1f0274ee586,Defer adding service to keystone for https,ABANDONED,2023-04-13 12:36:52.000000000,2023-04-19 15:30:47.000000000,,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/9f968e2e3b3cccecbe8e8db836d98434f5907d9d', 'message': 'Defer adding service to keystone for https\n\nIf a certificate relation exists, defer adding a service to\nkeystone until the certificate data exists on the relation. This\nwill ensure the keystone server port matches the port used in\nthe add_service_to_keystone() call.\n\nCloses-Bug: #2015103\nChange-Id: I9fe0f9f73c5b6bb4261e45a900a8c1f0274ee586\n'}, {'number': 2, 'created': '2023-04-13 12:53:49.000000000', 'files': ['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/8be9e394cbe5d9e163c8f111513364cd13973a3b', 'message': 'Defer adding service to keystone for https\n\nIf a certificate relation exists, defer adding a service to\nkeystone until the certificate data exists on the relation. This\nwill ensure the keystone server port matches the port used in\nthe add_service_to_keystone() call.\n\nCloses-Bug: #2015103\nChange-Id: I9fe0f9f73c5b6bb4261e45a900a8c1f0274ee586\n'}]",1,880297,8be9e394cbe5d9e163c8f111513364cd13973a3b,7,3,2,11805,,,0,"Defer adding service to keystone for https

If a certificate relation exists, defer adding a service to
keystone until the certificate data exists on the relation. This
will ensure the keystone server port matches the port used in
the add_service_to_keystone() call.

Closes-Bug: #2015103
Change-Id: I9fe0f9f73c5b6bb4261e45a900a8c1f0274ee586
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/97/880297/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py']",2,9f968e2e3b3cccecbe8e8db836d98434f5907d9d,," if relation_ids('certificates') and not https(): log(""Certificate data requested but not available yet"", level=INFO) return ",,28,1
openstack%2Fopenstack-ansible-rabbitmq_server~stable%2Fwallaby~Ifac1481b459707b289a9804aa4240ebbf55f6ab7,openstack/openstack-ansible-rabbitmq_server,stable/wallaby,Ifac1481b459707b289a9804aa4240ebbf55f6ab7,Switch rabbitmq repo back to packagecloud,NEW,2023-04-13 13:47:00.000000000,2023-04-19 15:23:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 13:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/6f1c4b1ac5d73ccbfbc03fb6ecc2d5fc118a63ce', 'message': ""Switch rabbitmq repo back to packagecloud\n\nDue to decision made during PTG, we're switching back source for\nRabbitMQ to packagcloud, since cloudsmith does rotate versions\ntoo aggressively and we can't keep up with them.\nWith that we're leaving erlang source to be cloudsmith, since\nthere're simply no other good sources for Ubuntu/Debian.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/879671\nChange-Id: Ifac1481b459707b289a9804aa4240ebbf55f6ab7\n(cherry picked from commit 84d88c5a265e2f783c7daa15d71251f45bcfc4b8)\n(cherry picked from commit 07b6debace6e21865a9966e6c9c8be14c24820d5)\n""}, {'number': 2, 'created': '2023-04-19 13:41:38.000000000', 'files': ['vars/redhat.yml', 'files/gpg/4D206F89', 'vars/debian.yml', 'files/gpg/C072C960'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/5152dc744e0c7fd19a0f04606e18f7eade16fff7', 'message': ""Switch rabbitmq repo back to packagecloud\n\nDue to decision made during PTG, we're switching back source for\nRabbitMQ to packagcloud, since cloudsmith does rotate versions\ntoo aggressively and we can't keep up with them.\nWith that we're leaving erlang source to be cloudsmith, since\nthere're simply no other good sources for Ubuntu/Debian.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/879671\nChange-Id: Ifac1481b459707b289a9804aa4240ebbf55f6ab7\n(cherry picked from commit 84d88c5a265e2f783c7daa15d71251f45bcfc4b8)\n(cherry picked from commit 07b6debace6e21865a9966e6c9c8be14c24820d5)\n""}]",0,880324,5152dc744e0c7fd19a0f04606e18f7eade16fff7,4,1,2,28619,,,0,"Switch rabbitmq repo back to packagecloud

Due to decision made during PTG, we're switching back source for
RabbitMQ to packagcloud, since cloudsmith does rotate versions
too aggressively and we can't keep up with them.
With that we're leaving erlang source to be cloudsmith, since
there're simply no other good sources for Ubuntu/Debian.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/879671
Change-Id: Ifac1481b459707b289a9804aa4240ebbf55f6ab7
(cherry picked from commit 84d88c5a265e2f783c7daa15d71251f45bcfc4b8)
(cherry picked from commit 07b6debace6e21865a9966e6c9c8be14c24820d5)
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/24/880324/2 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'files/gpg/4D206F89', 'vars/debian.yml', 'files/gpg/C072C960']",4,6f1c4b1ac5d73ccbfbc03fb6ecc2d5fc118a63ce,,,-----BEGIN PGP PUBLIC KEY BLOCK----- Version: GnuPG v2 mQGNBGAyemoBDADMwGfwPLzN0G0TOoiJdboRZOHUk51mtkBemD+JX2XiTvykjj4p M5MyRfGKV5YFRw5IkFXqYaNP/dqCAbWkfQG1aNpzPVIqlwwOkNEnNR2dKpiEpiq9 Q53HbAjMa9eHxvWN65MtvDIXGUIoupVMZAbycsYD9+fZWJrQgRlSb/Lk9cCvYKoy dXsfS1TOmglI3yFRgSvr+CM54gIOKpqWJVE+u2ZFq2rw9yh0GQzcOLXmrMStfbla akgqe3jpdXKIlI4tSoRaOsIFUjc1DeyZcEJGZyKlo4h1cgVNha8HDiMB9a7bdTCm W06ZbUrEz1vTmyFN6WFsLuZ4MRiWkuz0RAA9ePGMYz8DsQoMqusaoFAoQkgJQH4d MF+/3MFnK6CXMtkDYqwstcSDqtzbgvW+sOCzA/WGUzw37nwoh+mxIctVPxYsuipT aX8O9T449mQ61AOFw9MoTRSnf0XNfFUlkh9fQlUK/BWxM0X7A4UUtdMcZC54LsMF KHDCC4WHeOpDy1sAEQEAAbRFQ2xvdWRzbWl0aCBQYWNrYWdlIChyYWJiaXRtcS9y YWJiaXRtcS1zZXJ2ZXIpIDxzdXBwb3J0QGNsb3Vkc21pdGguaW8+iQG3BBMBCAAh BQJgMnpqAhsvBQsJCAcDBRUKCQgLBRYCAwEAAh4BAheAAAoJEJ9Fh/ImIINCM+4M AJmb/bXlShUTN4J1XCSOoUk4rBe0jBb6YbvB0YJrD1FZr/nfwV08sqCxfBvXR41W 9PwCCPYKUXo1K4TxehfOR4RpiHou+YxnqMiZjLKB9nSTnGj7kSJ8OLEcqUrgV/Uv Fk0w2IGQf25u6D6NumKuk6CElFxBG5OzBXtBAxUSLzQ7Xz/3IuqaPuA8KPRD25s8 yDjj2auyZxlfaD+wUNkqaLQ9quXd8IJuUqvz9wNbOItooWypEk2tX48w5i+wd1pP AW+NjKuwd0G88nO6J+7oFYXcsh7n3nblJZT0bmUZC9M6kL9llt8Vy/FBkHnP3dX3 +6EfEXeXPhVJTI7nkNP64XssO4zHg9vQd3rLd6RCfUnA/NjEXvpR6pjoEsPMlD99 8hsK1c0AhAntSsB2sky7E5p7Rzq8X/SM8aZGDmkitkN2VdnAQsJP0UVq7FnpqBFS pMxOxGveS5d5sjU3LoHPTg1uOcARcsOH245szVBPtklXOzg7Fazcc+BHmjYmrgeu QQ== =CfXb -----END PGP PUBLIC KEY BLOCK----- ,73,34
openstack%2Fkolla-ansible~master~I3a899411001834a0c88e37f45a756247ee11563d,openstack/kolla-ansible,master,I3a899411001834a0c88e37f45a756247ee11563d,Use the upgraded image to run Nova upgrade checks,MERGED,2023-01-20 13:56:43.000000000,2023-04-19 15:18:25.000000000,2023-04-19 14:16:19.000000000,"[{'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-01-20 13:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9342b5f5cc6cfd855aaf55e74c9994c2c52be35f', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 2, 'created': '2023-01-20 14:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2716d2ed4f5244d22a8a52e1cc0ef8ced59efd96', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 3, 'created': '2023-02-13 14:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/09a4c1468e405dbe379f375906c4abc5b5dafc10', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 4, 'created': '2023-02-13 15:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5d2a3833790bbb02b421f144c7557a82a02463d4', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nCloses-Bug: #2007157\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 5, 'created': '2023-02-13 15:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/57596a47bafb67a11e05e090a52bd5bd382492dc', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nCloses-Bug: #2007157\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 6, 'created': '2023-03-27 20:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b5696a75e9fca07a92ed3e286304438f1c40560c', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nCloses-Bug: #1957080\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}, {'number': 7, 'created': '2023-03-28 07:11:55.000000000', 'files': ['releasenotes/notes/perform-nova-upgrade-checks-with-upgraded-image-dca9c515bcd89ec8.yaml', 'ansible/roles/nova/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e34fbb174c7042f61fc7742363ee7e81569aaba5', 'message': 'Use the upgraded image to run Nova upgrade checks\n\nWhen upgrading Nova, we sometimes hit an error where an old hypervisor\nthat hasn’t been upgraded recently (for example due to broken hardware)\nis preventing Nova API from starting properly. This can be detected\nusing the tool ``nova-status upgrade check`` to make sure that there are\nno ``nova-compute`` that are older than N-1 releases. This is already\nused in the Kolla Ansible upgrade task for Nova. However, this task uses\nthe current ``nova-api`` container, so computes which will be too old\nafter the upgrade are not caught.\n\nThis patch changes Kolla Ansible so that the upgraded ``nova-api`` image\nis used to run the upgrade checks, allowing computes that will be too\nold to be detected before the upgrades are performed.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/878744\n\nCloses-Bug: #1957080\nCo-Authored-By: Pierre Riteau <pierre@stackhpc.com>\nChange-Id: I3a899411001834a0c88e37f45a756247ee11563d\n'}]",41,871279,e34fbb174c7042f61fc7742363ee7e81569aaba5,51,6,7,35263,,,0,"Use the upgraded image to run Nova upgrade checks

When upgrading Nova, we sometimes hit an error where an old hypervisor
that hasn’t been upgraded recently (for example due to broken hardware)
is preventing Nova API from starting properly. This can be detected
using the tool ``nova-status upgrade check`` to make sure that there are
no ``nova-compute`` that are older than N-1 releases. This is already
used in the Kolla Ansible upgrade task for Nova. However, this task uses
the current ``nova-api`` container, so computes which will be too old
after the upgrade are not caught.

This patch changes Kolla Ansible so that the upgraded ``nova-api`` image
is used to run the upgrade checks, allowing computes that will be too
old to be detected before the upgrades are performed.

Depends-On: https://review.opendev.org/c/openstack/kolla/+/878744

Closes-Bug: #1957080
Co-Authored-By: Pierre Riteau <pierre@stackhpc.com>
Change-Id: I3a899411001834a0c88e37f45a756247ee11563d
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/79/871279/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/perform-nova-upgrade-checks-with-upgraded-image-dca9c515bcd89ec8.yaml', 'ansible/roles/nova/tasks/upgrade.yml']",2,9342b5f5cc6cfd855aaf55e74c9994c2c52be35f,bug/1957080,"- name: Run Nova API upgrade checks container become: true vars: nova_api: ""{{ nova_services['nova-api'] }}"" kolla_docker: action: ""start_container"" common_options: ""{{ docker_common_options }}"" environment: KOLLA_UPGRADE: KOLLA_CONFIG_STRATEGY: ""{{ config_strategy }}"" image: ""{{ nova_api.image }}"" labels: UPGRADE: name: ""nova_api_upgrade_checks"" restart_policy: no volumes: ""{{ nova_api_default_volumes }}"" register: checks_container_result changed_when: checks_container_result.stdout | default("""") | length > 0 command: ""{{ kolla_container_engine }} exec -t nova_api_upgrade_checks nova-status upgrade check""- name: Remove Nova API upgrade checks container become: true kolla_docker: action: ""stop_and_remove_container"" name: ""nova_api_upgrade_checks"" - name: Fail always fail: msg: ""Failing to not do upgrade."" when: True "," command: ""{{ kolla_container_engine }} exec -t nova_api nova-status upgrade check""",40,1
openstack%2Fkolla-ansible~master~Ib877d04cf1b3c9d375a092271059a9065e04dfe8,openstack/kolla-ansible,master,Ib877d04cf1b3c9d375a092271059a9065e04dfe8,Add Grafana anonymous access,ABANDONED,2022-04-11 12:12:07.000000000,2023-04-19 15:02:16.000000000,,"[{'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2022-04-11 12:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/48648526b750c3593580eb886d84aa5636eef07b', 'message': 'Add Grafana anonymous access:\n  * Disable by default.\n  * Introduce two new vars.\n\nChange-Id: Ib877d04cf1b3c9d375a092271059a9065e04dfe8\nCloses-bug: #196855\n'}, {'number': 2, 'created': '2022-04-11 12:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4a48bb844b838185ee7de53b30de2571bd357437', 'message': 'Add Grafana anonymous access:\n  * Disable by default.\n  * Introduce two new vars.\n\nChange-Id: Ib877d04cf1b3c9d375a092271059a9065e04dfe8\nCloses-bug: #1968551\n'}, {'number': 3, 'created': '2022-04-11 12:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/40c88283cccc5d86c0e74e32995a4a118f5b5bd4', 'message': 'Add Grafana anonymous access\n\nFeature disabled by default.\nIntroduce two new vars.\n\nChange-Id: Ib877d04cf1b3c9d375a092271059a9065e04dfe8\nCloses-bug: #1968551\n'}, {'number': 4, 'created': '2022-04-11 12:30:07.000000000', 'files': ['ansible/roles/grafana/defaults/main.yml', 'ansible/roles/grafana/templates/grafana.ini.j2', 'releasenotes/notes/add-grafana-anonymous-b01e4667caef39e4.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9831772ae9e251333979a2a45eafbcb73e71a024', 'message': 'Add Grafana anonymous access\n\nAllow operators to publish RO dashboard anonymously.\nUseful for KPI/Status page oriented dashboard.\n\nChange-Id: Ib877d04cf1b3c9d375a092271059a9065e04dfe8\nCloses-bug: #1968551\n'}]",4,837302,9831772ae9e251333979a2a45eafbcb73e71a024,12,2,4,32398,,,0,"Add Grafana anonymous access

Allow operators to publish RO dashboard anonymously.
Useful for KPI/Status page oriented dashboard.

Change-Id: Ib877d04cf1b3c9d375a092271059a9065e04dfe8
Closes-bug: #1968551
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/02/837302/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/grafana/defaults/main.yml', 'ansible/roles/grafana/templates/grafana.ini.j2', 'releasenotes/notes/add-grafana-anonymous-b01e4667caef39e4.yaml']",3,48648526b750c3593580eb886d84aa5636eef07b,bug/1968551,--- features: - | Adds support for anonymous access on public and RO Grafana's dashboard. Grafana admins can now publish dashboard such as status pages or KPI that won't require any login for customers or management. ,,17,0
openstack%2Fkolla-ansible~master~Idc888f4ef3d118684069e90fa23d6bb673931a90,openstack/kolla-ansible,master,Idc888f4ef3d118684069e90fa23d6bb673931a90,Add Grafana SMTP support,ABANDONED,2022-04-11 13:48:52.000000000,2023-04-19 15:01:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-04-11 13:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c34738d09d1e764808f7e2ff6ef9aa2c6a2c594c', 'message': 'Add Grafana SMTP support\n\nAllow operators to enable SMTP support of Grafana.\nUseful for email based alerts notification channels.\n\nChange-Id: Idc888f4ef3d118684069e90fa23d6bb673931a90\nCloses-bug: #1968560\n'}, {'number': 2, 'created': '2022-04-11 14:00:53.000000000', 'files': ['releasenotes/notes/add-grafana-smtp-8cfb09a2dde60bde.yaml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/grafana/templates/grafana.ini.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6e348ce94d4ae84cfbc9f43e3b724d222c0319b1', 'message': 'Add Grafana SMTP support\n\nAllow operators to enable SMTP support of Grafana.\nUseful for email based alerts notification channels.\n\nChange-Id: Idc888f4ef3d118684069e90fa23d6bb673931a90\nCloses-bug: #1968560\n'}]",2,837345,6e348ce94d4ae84cfbc9f43e3b724d222c0319b1,8,1,2,32398,,,0,"Add Grafana SMTP support

Allow operators to enable SMTP support of Grafana.
Useful for email based alerts notification channels.

Change-Id: Idc888f4ef3d118684069e90fa23d6bb673931a90
Closes-bug: #1968560
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/45/837345/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-grafana-smtp-8cfb09a2dde60bde.yaml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/grafana/templates/grafana.ini.j2']",3,c34738d09d1e764808f7e2ff6ef9aa2c6a2c594c,bug/1968560, {% if grafana_enable_smtp %} [smtp] enabled = true host = {{ grafana_smtp_host }} user = {{ grafana_smtp_user }} password = {{ grafana_smtp_password }} cert_file = {{ grafana_smtp_tls_certificate_path }} key_file = {{ grafana_smtp_tls_keyfile_path }} skip_verify = {{ grafana_smtp_tls_verify }} from_address = {{ grafana_smtp_sender_addr }} from_name = {{ grafana_smtp_sender_name }} ehlo_identity = {{ grafana_smtp_ehlo_identity }} startTLS_policy = {{ grafana_smtp_startTLS_policy }} {% endif %},,35,0
openstack%2Fkolla-ansible~master~I5ad57ac58f6f2185470900c410ac2c2089aba276,openstack/kolla-ansible,master,I5ad57ac58f6f2185470900c410ac2c2089aba276,Add additional grafana plugins install support:,ABANDONED,2022-07-22 14:50:30.000000000,2023-04-19 15:00:00.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-07-22 14:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d4b9b8c0705e85346e997f2150d706aa392c49f4', 'message': 'Add additional grafana plugins install support:\n\n  - Add a way to install additional grafana plugins.\n  - Add a way to install them offline.\n\nChange-Id: I5ad57ac58f6f2185470900c410ac2c2089aba276\nClose-Bug: #1982588\n'}, {'number': 2, 'created': '2022-07-22 14:52:53.000000000', 'files': ['ansible/group_vars/all.yml', 'ansible/roles/grafana/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6c876753cda4d412a2ae4f3acc40ba93d1453449', 'message': 'Add additional grafana plugins install support:\n\n  - Add a way to install additional grafana plugins.\n  - Add a way to install them offline.\n\nChange-Id: I5ad57ac58f6f2185470900c410ac2c2089aba276\nCloses-Bug: #1982588\n'}]",2,850760,6c876753cda4d412a2ae4f3acc40ba93d1453449,11,1,2,32398,,,0,"Add additional grafana plugins install support:

  - Add a way to install additional grafana plugins.
  - Add a way to install them offline.

Change-Id: I5ad57ac58f6f2185470900c410ac2c2089aba276
Closes-Bug: #1982588
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/60/850760/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'ansible/roles/grafana/defaults/main.yml']",2,d4b9b8c0705e85346e997f2150d706aa392c49f4,bug/1982588,"grafana_plugins_offline_install: False grafana_plugins_repositrory_url: """" ",,5,0
openstack%2Fcinder~stable%2Fzed~I0d266a57f68221a3b1740a7376e152bb64cac729,openstack/cinder,stable/zed,I0d266a57f68221a3b1740a7376e152bb64cac729,Dell PowerFlex: Additionnal params for enabling self signed certificates,NEW,2023-04-14 12:46:57.000000000,2023-04-19 14:16:03.000000000,,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-04-14 12:46:57.000000000', 'files': ['cinder/volume/drivers/dell_emc/powerflex/driver.py', 'releasenotes/notes/dell-powerflex-bugfix-1998136-self-signed-certificates-62e3cb444ab7ff2b.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9048659b4d1302efa7a4c777ebf22fb4c5bc3155', 'message': 'Dell PowerFlex: Additionnal params for enabling self signed certificates\n\nInitially before the change\nhttps://review.opendev.org/c/openstack/os-brick/+/810419 was merged\nto close the bug https://bugs.launchpad.net/os-brick/+bug/1929223,\nverify_cert was always set to False which can lead to security issues.\nIt has been decided through this change that this option can be set\nto True or False based upon security requirements. This change\nintroduced a regression failure as the value set to the option\nis not part of connection_properties.\n\nThis patch adds additional params during initialization so that it\ncan be carried over os-brick and get adequate REST API response.\n\nCloses-Bug: 1990136\nChange-Id: I0d266a57f68221a3b1740a7376e152bb64cac729\n(cherry picked from commit 82823ace4d714ac10427ea3c6fed320c27b56f7d)\n'}]",1,880492,9048659b4d1302efa7a4c777ebf22fb4c5bc3155,13,4,1,31779,,,0,"Dell PowerFlex: Additionnal params for enabling self signed certificates

Initially before the change
https://review.opendev.org/c/openstack/os-brick/+/810419 was merged
to close the bug https://bugs.launchpad.net/os-brick/+bug/1929223,
verify_cert was always set to False which can lead to security issues.
It has been decided through this change that this option can be set
to True or False based upon security requirements. This change
introduced a regression failure as the value set to the option
is not part of connection_properties.

This patch adds additional params during initialization so that it
can be carried over os-brick and get adequate REST API response.

Closes-Bug: 1990136
Change-Id: I0d266a57f68221a3b1740a7376e152bb64cac729
(cherry picked from commit 82823ace4d714ac10427ea3c6fed320c27b56f7d)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/880492/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/powerflex/driver.py', 'releasenotes/notes/dell-powerflex-bugfix-1998136-self-signed-certificates-62e3cb444ab7ff2b.yaml']",2,9048659b4d1302efa7a4c777ebf22fb4c5bc3155,bug/1990136-stable/zed,"--- fixes: - | Dell PowerFlex driver `bug #1998136 <https://bugs.launchpad.net/cinder/+bug/1998136>`_: When using self signed certificates, the option sent to os-brick via the connection_properties was not correctly handled. It has now been fixed by adding the 'verify_certificate' and 'certificate_path' to the driver when initializing the connection. ",,16,0
openstack%2Fkolla-ansible~stable%2Fyoga~I5ae1d911c5df423e0b70dab306709320083b7b69,openstack/kolla-ansible,stable/yoga,I5ae1d911c5df423e0b70dab306709320083b7b69,opensearch: default dashboards tag to opensearch_tag,MERGED,2023-04-18 04:58:00.000000000,2023-04-19 14:14:49.000000000,2023-04-19 14:13:32.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-18 04:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/31b7e89a0defba3385c543d92fc345b58b210f8f', 'message': 'opensearch: default dashboards tag to opensearch_tag\n\nCloses-Bug: #2016627\n\nChange-Id: I5ae1d911c5df423e0b70dab306709320083b7b69\n(cherry picked from commit c0a45c7eb74224557c1e86883eed4e1cd33f8c61)\n'}, {'number': 2, 'created': '2023-04-18 05:00:22.000000000', 'files': ['ansible/roles/opensearch/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0b9e5cc887c645c91177d4406348fd103ab516a0', 'message': 'opensearch: default dashboards tag to opensearch_tag\n\nCloses-Bug: #2016627\n\nChange-Id: I5ae1d911c5df423e0b70dab306709320083b7b69\n(cherry picked from commit c0a45c7eb74224557c1e86883eed4e1cd33f8c61)\n'}]",1,880599,0b9e5cc887c645c91177d4406348fd103ab516a0,16,3,2,22629,,,0,"opensearch: default dashboards tag to opensearch_tag

Closes-Bug: #2016627

Change-Id: I5ae1d911c5df423e0b70dab306709320083b7b69
(cherry picked from commit c0a45c7eb74224557c1e86883eed4e1cd33f8c61)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/99/880599/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/opensearch/defaults/main.yml'],1,31b7e89a0defba3385c543d92fc345b58b210f8f,,"<<<<<<< HEAD (c8f11d Fix merge action plugins verbose output)======= opensearch_dashboards_image: ""{{ docker_registry ~ '/' if docker_registry else '' }}{{ docker_namespace }}/opensearch-dashboards"" opensearch_dashboards_tag: ""{{ opensearch_tag }}"" >>>>>>> CHANGE (c0a45c opensearch: default dashboards tag to opensearch_tag)",,5,0
openstack%2Fopenstack-ansible-rabbitmq_server~stable%2Fwallaby~I8db5bffceee1425b957150a8983dcb774d8c4c77,openstack/openstack-ansible-rabbitmq_server,stable/wallaby,I8db5bffceee1425b957150a8983dcb774d8c4c77,Bump erlang versions,ABANDONED,2023-03-07 09:52:14.000000000,2023-04-19 13:41:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-07 09:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/bc069550b4906ac94c5af99d689840f81af999fe', 'message': 'Bump erlang versions\n\nChange-Id: I8db5bffceee1425b957150a8983dcb774d8c4c77\n'}, {'number': 2, 'created': '2023-04-19 13:41:26.000000000', 'files': ['vars/redhat.yml', 'vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/dad098bb73eaf21e7f265eef082fb8f426bd497b', 'message': 'Bump erlang versions\n\nChange-Id: I8db5bffceee1425b957150a8983dcb774d8c4c77\n'}]",0,876708,dad098bb73eaf21e7f265eef082fb8f426bd497b,4,1,2,28619,,,0,"Bump erlang versions

Change-Id: I8db5bffceee1425b957150a8983dcb774d8c4c77
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/08/876708/2 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'vars/debian.yml']",2,bc069550b4906ac94c5af99d689840f81af999fe,,"_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:23.3.4.18-1', '1:22.*') }}""","_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:23.3.4.15-1', '1:22.*') }}""",2,2
openstack%2Fopenstack-ansible~stable%2Fxena~Ibb9dc3377a4de06af25281bf777b16faad16d261,openstack/openstack-ansible,stable/xena,Ibb9dc3377a4de06af25281bf777b16faad16d261,Gather generic masakari facts,MERGED,2023-04-19 04:30:52.000000000,2023-04-19 13:31:21.000000000,2023-04-19 13:28:30.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-19 04:30:52.000000000', 'files': ['playbooks/os-masakari-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/eb7f45fcdc7dd7118647efac43eeb7004a2c271b', 'message': 'Gather generic masakari facts\n\nWith commit [1] we moved extra facts gathering to pre_tasks\nbut with that we did not enable generic facts gathering, which\nled to regression. So we cover this by ensuring that generic\nfacts are also gathered and not only extra ones.\n\n[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833\nCloses-Bug: #1979145\n\nChange-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261\n(cherry picked from commit bb4f1c7b2a46b30de8bca3e695938022efe6be89)\n'}]",0,880608,eb7f45fcdc7dd7118647efac43eeb7004a2c271b,8,3,1,28619,,,0,"Gather generic masakari facts

With commit [1] we moved extra facts gathering to pre_tasks
but with that we did not enable generic facts gathering, which
led to regression. So we cover this by ensuring that generic
facts are also gathered and not only extra ones.

[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833
Closes-Bug: #1979145

Change-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261
(cherry picked from commit bb4f1c7b2a46b30de8bca3e695938022efe6be89)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/08/880608/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-masakari-install.yml'],1,eb7f45fcdc7dd7118647efac43eeb7004a2c271b,,"- name: Gather masakari facts hosts: masakari_all gather_facts: ""{{ osa_gather_facts | default(True) }}"" tags: - always ",,6,0
openstack%2Fopenstack-ansible~stable%2Fxena~I26295527babe3a739fd6f5b834653e223502fd44,openstack/openstack-ansible,stable/xena,I26295527babe3a739fd6f5b834653e223502fd44,Bump OpenStack-Ansible Xena,MERGED,2023-04-14 10:17:54.000000000,2023-04-19 13:29:48.000000000,2023-04-19 13:28:28.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 10:17:54.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/27afe79f374d16172d2166d6480af29e4e029a58', 'message': 'Bump OpenStack-Ansible Xena\n\nChange-Id: I26295527babe3a739fd6f5b834653e223502fd44\n'}]",1,880478,27afe79f374d16172d2166d6480af29e4e029a58,10,3,1,28619,,,0,"Bump OpenStack-Ansible Xena

Change-Id: I26295527babe3a739fd6f5b834653e223502fd44
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/78/880478/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml']",5,27afe79f374d16172d2166d6480af29e4e029a58,bump_osa,### HEAD as of 14.04.2023 ### version: 88e340a58ed906ae033238f4270a685601c343fc shallow_since: '2023-04-03' version: 5d2b436d5a2bd2810a4d5e2ae2b892f45b59a0db shallow_since: '2023-04-02' version: 954ea7013054ed7fbed65006a02d5126716da0ea shallow_since: '2023-04-12' version: e84617d70ed3c9e320ee7cc30619cdfe5e01b1a4 shallow_since: '2023-04-11' version: 9f44aa21b08b042c22e4e5fd3eae47c64c4d5ba2 shallow_since: '2023-04-10' version: c4a492a248c89c0710489a0f0cd0f95546e6be26 shallow_since: '2023-04-10',### HEAD as of 15.03.2023 ### version: 96d9f4586c6c3c800e0e7e229d731783bfa3aafe shallow_since: '2022-12-28' version: ec8dbb0958f1447aafee62f6d131fd90c783a852 shallow_since: '2022-12-28' version: f9c4d9e46d91824766ceab026b74c86442718b4e shallow_since: '2023-03-06' version: 806bab77201c0ba2c056609f13a6079f59456169 shallow_since: '2023-03-01' version: 1a10e189cb3ef0986c216c0ccaaaea58df1c27d2 shallow_since: '2023-03-13' version: dacff1ed6ede207b8afcbfff5e990d875580893b shallow_since: '2022-06-14',32,32
openstack%2Fceilometer~stable%2Fwallaby~Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,openstack/ceilometer,stable/wallaby,Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,Add user/project names to polled samples,MERGED,2023-04-17 05:54:18.000000000,2023-04-19 13:23:49.000000000,2023-04-19 13:22:25.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 05:54:18.000000000', 'files': ['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f7aab07bc57becb60970ba29430f3c42a9d5444e', 'message': 'Add user/project names to polled samples\n\nProject and user names would be first fetched from cache, if not found,\nthey will be requested from keystone and then cached. Using cache will\nsignificanlty reduce the number of calls made to keystone.\n\nIf ceilometer is configured with no caching backend, the results\nwill always be fetched by querying request to keystone.\n\nA new config option, `tenant_name_discovery` is introduced\nto operate this feature. This feature is optional and is disabled by default.\n\nNo attempts to identify names will be made if uuids are found to be `None`.\n\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)\n(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)\n'}]",0,880506,f7aab07bc57becb60970ba29430f3c42a9d5444e,10,2,1,32240,,,0,"Add user/project names to polled samples

Project and user names would be first fetched from cache, if not found,
they will be requested from keystone and then cached. Using cache will
significanlty reduce the number of calls made to keystone.

If ceilometer is configured with no caching backend, the results
will always be fetched by querying request to keystone.

A new config option, `tenant_name_discovery` is introduced
to operate this feature. This feature is optional and is disabled by default.

No attempts to identify names will be made if uuids are found to be `None`.

Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27
(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)
(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/06/880506/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py']",6,f7aab07bc57becb60970ba29430f3c42a9d5444e,enhanced_metrics-stable/wallaby," ks_client = mock.Mock(auth_token='fake_token') ks_client.projects.get.return_value = mock.Mock( name='admin', id='4465ecd1438b4d23a866cf8447387a7b' ) ks_client.users.get.return_value = mock.Mock( name='admin', id='c0c935468e654d5a8baae1a08adf4dfb' ) self.useFixture(fixtures.MockPatch( 'ceilometer.keystone_client.get_client', return_value=ks_client)) self.ks_client = ks_client",,138,2
openstack%2Fovsdbapp~master~I251f555c7c2fb69af99065dc3ee0a8d252d12c44,openstack/ovsdbapp,master,I251f555c7c2fb69af99065dc3ee0a8d252d12c44,Add support for clearing map column keys,ABANDONED,2023-04-03 17:19:36.000000000,2023-04-19 13:13:57.000000000,,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-03 17:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/9d92fe74d8a5875f2a9e9f1af3948186512db78b', 'message': 'Add support for clearing map column keys\n\nThe various ctl commands for OVS/OVN support clearing a specific\nkey in a map column, which we were missing. There aren\'t really\nany good alternatives (setting an empty value still leaves the key,\netc.) so db_clear() is modified to take an optional ""key"" argument.\n\nCloses-Bug: 2015108\nChange-Id: I251f555c7c2fb69af99065dc3ee0a8d252d12c44\n'}, {'number': 2, 'created': '2023-04-03 20:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/32bfe0dfad24a7924555913e7169cb56677a5f00', 'message': 'Add support for clearing map column keys\n\nThe various ctl commands for OVS/OVN support clearing a specific\nkey in a map column, which we were missing. There aren\'t really\nany good alternatives (setting an empty value still leaves the key,\netc.) so db_clear() is modified to take an optional ""key"" argument.\n\nCloses-Bug: 2015108\nChange-Id: I251f555c7c2fb69af99065dc3ee0a8d252d12c44\n'}, {'number': 3, 'created': '2023-04-03 20:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/8e37d962ccccde31a335e131d16077e1a3db7636', 'message': 'Add support for clearing map column keys\n\nThe various ctl commands for OVS/OVN support clearing a specific\nkey in a map column, which we were missing. There aren\'t really\nany good alternatives (setting an empty value still leaves the key,\netc.) so db_clear() is modified to take an optional ""key"" argument.\n\nCloses-Bug: 2015108\nChange-Id: I251f555c7c2fb69af99065dc3ee0a8d252d12c44\n'}, {'number': 4, 'created': '2023-04-18 16:37:34.000000000', 'files': ['ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/__init__.py', 'ovsdbapp/api.py', 'ovsdbapp/tests/functional/schema/open_vswitch/test_common_db.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/831ae23f49a044b5bf6ab6f18ce08915be03fd3a', 'message': 'Add support for clearing map column keys\n\nThe various ctl commands for OVS/OVN support clearing a specific\nkey in a map column, which we were missing. There aren\'t really\nany good alternatives (setting an empty value still leaves the key,\netc.) so db_clear() is modified to take an optional ""key"" argument.\n\nCloses-Bug: 2015108\nChange-Id: I251f555c7c2fb69af99065dc3ee0a8d252d12c44\n'}]",7,879367,831ae23f49a044b5bf6ab6f18ce08915be03fd3a,14,6,4,5756,,,0,"Add support for clearing map column keys

The various ctl commands for OVS/OVN support clearing a specific
key in a map column, which we were missing. There aren't really
any good alternatives (setting an empty value still leaves the key,
etc.) so db_clear() is modified to take an optional ""key"" argument.

Closes-Bug: 2015108
Change-Id: I251f555c7c2fb69af99065dc3ee0a8d252d12c44
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/67/879367/4 && git format-patch -1 --stdout FETCH_HEAD,"['ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/__init__.py', 'ovsdbapp/api.py', 'ovsdbapp/tests/functional/schema/open_vswitch/test_common_db.py']",4,9d92fe74d8a5875f2a9e9f1af3948186512db78b,," def test_db_clear(self): brname = self.bridges[0]['name'] protocols = ['OpenFlow13'] self.api.db_set( 'Bridge', brname, ('protocols', protocols)).execute(check_error=True) br = self.api.lookup('Bridge', brname) self.assertEqual(['OpenFlow13'], br.protocols) self.api.db_clear( 'Bridge', brname, 'protocols').execute(check_error=True) self.assertEqual([], br.protocols) def test_db_clear_map(self): brname = self.bridges[0]['name'] key = 'to_delete' ext_id = {key: 'value'} additional_extid = {'otherkey': 'othervalue'} ext_id.update(additional_extid) self.api.db_set( 'Bridge', brname, ('external_ids', ext_id)).execute(check_error=True) br = self.api.lookup('Bridge', brname) self.assertEqual(ext_id, br.external_ids) self.api.db_clear( 'Bridge', brname, 'external_ids', key).execute(check_error=True) self.assertNotIn(key, br.external_ids) self.assertEqual(additional_extid, br.external_ids)",,38,4
openstack%2Fkolla-ansible~stable%2Fzed~I5ae1d911c5df423e0b70dab306709320083b7b69,openstack/kolla-ansible,stable/zed,I5ae1d911c5df423e0b70dab306709320083b7b69,opensearch: default dashboards tag to opensearch_tag,MERGED,2023-04-18 04:57:41.000000000,2023-04-19 12:50:32.000000000,2023-04-19 12:49:22.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-18 04:57:41.000000000', 'files': ['ansible/roles/opensearch/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f764be111be2b2e5881dd3ac1b6ab309886fa943', 'message': 'opensearch: default dashboards tag to opensearch_tag\n\nCloses-Bug: #2016627\n\nChange-Id: I5ae1d911c5df423e0b70dab306709320083b7b69\n(cherry picked from commit c0a45c7eb74224557c1e86883eed4e1cd33f8c61)\n'}]",1,880598,f764be111be2b2e5881dd3ac1b6ab309886fa943,14,3,1,22629,,,0,"opensearch: default dashboards tag to opensearch_tag

Closes-Bug: #2016627

Change-Id: I5ae1d911c5df423e0b70dab306709320083b7b69
(cherry picked from commit c0a45c7eb74224557c1e86883eed4e1cd33f8c61)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/98/880598/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/opensearch/defaults/main.yml'],1,f764be111be2b2e5881dd3ac1b6ab309886fa943,,"opensearch_dashboards_tag: ""{{ opensearch_tag }}""","opensearch_dashboards_tag: ""{{ openstack_tag }}""",1,1
openstack%2Fironic-python-agent-builder~master~I6d6ebbb217886ed0e65137b8c8f0825d97abec81,openstack/ironic-python-agent-builder,master,I6d6ebbb217886ed0e65137b8c8f0825d97abec81,Move ubuntu jobs to jammy,MERGED,2023-04-05 09:40:07.000000000,2023-04-19 12:34:32.000000000,2023-04-19 12:32:23.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-04-05 09:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/ede3f996c86c1e294355a3c22c146dda91c33a24', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 2, 'created': '2023-04-06 07:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/4c505a2dbb339c6ff61cad7e78ac1dbfb1edbed9', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 3, 'created': '2023-04-07 07:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/864ef924b040a7c6a908f2653df164ae346defca', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 4, 'created': '2023-04-07 12:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3ff14615d763a891037318f2a74f78650f41c7da', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 5, 'created': '2023-04-07 15:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/39f3fc5c3d9ec60f8214c542f230ba2abf8420fd', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 6, 'created': '2023-04-11 14:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/d6a908091ed9cf3381f0c83af75f43dc1edd7a71', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nAlso do not use emmoery tmpfs to build images, we have 80gb in the\nhdd that we can use instead.\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 7, 'created': '2023-04-12 07:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/35e91d8613dcf3b538c744df56adf417b5d04fc3', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nAlso do not use emmoery tmpfs to build images, we have 80gb in the\nhdd that we can use instead.\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 8, 'created': '2023-04-12 07:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/e92aa2797fac51bb8deb87356cbc66f387ece4e5', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nAlso do not use tmpfs to build images, we have 80gb in the\nhdd that we can use instead.\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}, {'number': 9, 'created': '2023-04-12 11:58:54.000000000', 'files': ['zuul.d/ironic-python-agent-builder-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/8cad404502ec975915127cf380b40633846cd394', 'message': 'Move ubuntu jobs to jammy\n\nRemove focal support\nThis is long due\n\nDO not use tmpfs to build the jammy image, use the disk space instead.\nThis is to avoid increasing the tmpfs mounted partition, we have 80gb\ndisk space available.\n\nChange-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81\n'}]",4,879538,8cad404502ec975915127cf380b40633846cd394,33,4,9,23851,,,0,"Move ubuntu jobs to jammy

Remove focal support
This is long due

DO not use tmpfs to build the jammy image, use the disk space instead.
This is to avoid increasing the tmpfs mounted partition, we have 80gb
disk space available.

Change-Id: I6d6ebbb217886ed0e65137b8c8f0825d97abec81
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/38/879538/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-python-agent-builder-jobs.yaml'],1,ede3f996c86c1e294355a3c22c146dda91c33a24,jammy-support, nodeset: ubuntu-jammy image_release: 'jammy', nodeset: ubuntu-focal image_release: 'focal',2,2
openstack%2Freleases~master~I4489cdbc79b418421e57f459779e40be72d87cc4,openstack/releases,master,I4489cdbc79b418421e57f459779e40be72d87cc4,bumping release for tripleo-validations,ABANDONED,2023-03-03 13:35:40.000000000,2023-04-19 12:29:45.000000000,,"[{'_account_id': 308}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-03 13:35:40.000000000', 'files': ['deliverables/wallaby/tripleo-validations.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5490f20eea60872475092bb1c7791ffef801645e', 'message': 'bumping release for tripleo-validations\n\nSigned-off-by: David J Peacock <david.j.peacock@gmail.com>\nChange-Id: I4489cdbc79b418421e57f459779e40be72d87cc4\n'}]",5,876359,5490f20eea60872475092bb1c7791ffef801645e,8,6,1,27427,,,0,"bumping release for tripleo-validations

Signed-off-by: David J Peacock <david.j.peacock@gmail.com>
Change-Id: I4489cdbc79b418421e57f459779e40be72d87cc4
",git fetch https://review.opendev.org/openstack/releases refs/changes/59/876359/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/tripleo-validations.yaml'],1,5490f20eea60872475092bb1c7791ffef801645e,, - version: 14.3.2 hash: 9edbff37b744eb98c00954931a2a94665f971d13, - version: wallaby-em hash: d74d3fc952aea6eda73192eb235217c3ba1052f3,2,2
openstack%2Fopenstack-manuals~master~I6d2e60ccfb0a3b5f8549bb053213635960d46fcf,openstack/openstack-manuals,master,I6d2e60ccfb0a3b5f8549bb053213635960d46fcf,"Remove redundant ""Guide"" word",MERGED,2023-04-18 15:44:28.000000000,2023-04-19 12:18:30.000000000,2023-04-19 11:55:34.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 15:44:28.000000000', 'files': ['www/project-data/yoga.yaml', 'www/project-data/zed.yaml', 'www/project-data/2023.1.yaml', 'www/project-data/latest.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f11811c4a7b17f711629364139c407652cf690dd', 'message': 'Remove redundant ""Guide"" word\n\nAll deployment guides are prepended with ""Guide"" word. So adding\nit in the middle of the text adds duplicated ""Guide"" word to the\ndescription once page is renderred.\n\nChange-Id: I6d2e60ccfb0a3b5f8549bb053213635960d46fcf\n'}]",0,880763,f11811c4a7b17f711629364139c407652cf690dd,7,2,1,28619,,,0,"Remove redundant ""Guide"" word

All deployment guides are prepended with ""Guide"" word. So adding
it in the middle of the text adds duplicated ""Guide"" word to the
description once page is renderred.

Change-Id: I6d2e60ccfb0a3b5f8549bb053213635960d46fcf
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/880763/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/project-data/yoga.yaml', 'www/project-data/zed.yaml', 'www/project-data/2023.1.yaml', 'www/project-data/latest.yaml']",4,f11811c4a7b17f711629364139c407652cf690dd,, service: OpenStack-Ansible Deployment (in LXC Containers or on Bare Metal), service: OpenStack-Ansible Deployment Guide (in LXC Containers or on Bare Metal),4,4
openstack%2Fopenstack-ansible-os_cinder~master~Ic3ecdddd7dcc2dd617c8606278590c8e59230fdf,openstack/openstack-ansible-os_cinder,master,Ic3ecdddd7dcc2dd617c8606278590c8e59230fdf,Move online data migrations to post-restart step,MERGED,2023-04-12 17:06:47.000000000,2023-04-19 12:18:06.000000000,2023-04-19 12:17:05.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-12 17:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/7c338aa733765eb33dfd3fd221aa6be057945900', 'message': ""Move online data migrations to post-restart step\n\nIt's supposed that online migrations are executed once services are\nupgraded and restarted after upgrade. Eventually, you can run\nonline migrations before the next upgrade according to the doc [1]\n\nSo we move that to a separate file that is executed after all services\nare upgraded and handlers are flushed. Tasks are delegated to API hosts\nand we clean up facts for them as well.\n\n[1] https://docs.openstack.org/cinder/latest/admin/upgrades.html#database-upgrades\n\nChange-Id: Ic3ecdddd7dcc2dd617c8606278590c8e59230fdf\n""}, {'number': 2, 'created': '2023-04-12 17:09:41.000000000', 'files': ['tasks/main.yml', 'tasks/cinder_db_post_setup.yml', 'tasks/cinder_db_sync.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/7e076b39a42371a40b0622b4a59e9e52e34440aa', 'message': ""Move online data migrations to post-restart step\n\nIt's supposed that online migrations are executed once services are\nupgraded and restarted after upgrade. Eventually, you can run\nonline migrations before the next upgrade according to the doc [1]\n\nSo we move that to a separate file that is executed after all services\nare upgraded and handlers are flushed. Tasks are delegated to API hosts\nand we clean up facts for them as well.\n\n[1] https://docs.openstack.org/cinder/latest/admin/upgrades.html#database-upgrades\n\nChange-Id: Ic3ecdddd7dcc2dd617c8606278590c8e59230fdf\n""}]",0,880210,7e076b39a42371a40b0622b4a59e9e52e34440aa,9,3,2,28619,,,0,"Move online data migrations to post-restart step

It's supposed that online migrations are executed once services are
upgraded and restarted after upgrade. Eventually, you can run
online migrations before the next upgrade according to the doc [1]

So we move that to a separate file that is executed after all services
are upgraded and handlers are flushed. Tasks are delegated to API hosts
and we clean up facts for them as well.

[1] https://docs.openstack.org/cinder/latest/admin/upgrades.html#database-upgrades

Change-Id: Ic3ecdddd7dcc2dd617c8606278590c8e59230fdf
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/10/880210/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/cinder_db_post_setup.yml', 'tasks/cinder_db_sync.yml', 'vars/main.yml']",4,7c338aa733765eb33dfd3fd221aa6be057945900,,"_cinder_is_last_api_play_host: ""{{ (cinder_services['cinder-api']['group'] in group_names and inventory_hostname == (groups[cinder_services['cinder-api']['group']] | intersect(ansible_play_hosts)) | last) | bool }}"" _cinder_is_last_volume_play_host: ""{{ (cinder_services['cinder-volume']['group'] in group_names and inventory_hostname == (groups[cinder_services['cinder-volume']['group']] | intersect(ansible_play_hosts)) | last) | bool }}""","_cinder_is_last_play_host: ""{{ (cinder_services['cinder-api']['group'] in group_names and inventory_hostname == (groups[cinder_services['cinder-api']['group']] | intersect(ansible_play_hosts)) | last) | bool }}""",72,43
openstack%2Fgovernance~master~Ie21c6a8b89adfac2ecd03f7d63591280a72ca627,openstack/governance,master,Ie21c6a8b89adfac2ecd03f7d63591280a72ca627,TripleO: switch to distributed project leadership,MERGED,2023-03-28 21:41:40.000000000,2023-04-19 12:05:59.000000000,2023-04-19 12:04:04.000000000,"[{'_account_id': 5314}, {'_account_id': 8449}, {'_account_id': 8556}, {'_account_id': 9816}, {'_account_id': 9976}, {'_account_id': 10342}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-03-28 21:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/9a0121fa11fbd21f1cefb9f7eab0877b2e80451e', 'message': 'TripleO: switch to distributed project leadership\n\nTripleO is not maintained after Zed, and is switching to the distributed\nproject leadership model.\n\nopenstack-discuss threads:\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-February/032083.html\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-March/032663.html\n\nSigned-off-by: James Slagle <jslagle@redhat.com>\nChange-Id: Ie21c6a8b89adfac2ecd03f7d63591280a72ca627\n'}, {'number': 2, 'created': '2023-03-29 16:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/8d428d822160c5b048cc2b2afce4a2fbabe19daa', 'message': 'TripleO: switch to distributed project leadership\n\nTripleO is not maintained after Zed, and is switching to the distributed\nproject leadership model.\n\nopenstack-discuss threads:\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-February/032083.html\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-March/032663.html\n\nSigned-off-by: James Slagle <jslagle@redhat.com>\nChange-Id: Ie21c6a8b89adfac2ecd03f7d63591280a72ca627\n'}, {'number': 3, 'created': '2023-03-30 16:12:48.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/8c1990d8a8eedc5deaa538ad5146ac36a24701c0', 'message': 'TripleO: switch to distributed project leadership\n\nTripleO is not maintained after Zed, and is switching to the distributed\nproject leadership model.\n\nopenstack-discuss threads:\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-February/032083.html\nhttps://lists.openstack.org/pipermail/openstack-discuss/2023-March/032663.html\n\nSigned-off-by: James Slagle <jslagle@redhat.com>\nChange-Id: Ie21c6a8b89adfac2ecd03f7d63591280a72ca627\n'}]",8,878799,8c1990d8a8eedc5deaa538ad5146ac36a24701c0,25,9,3,7144,,,0,"TripleO: switch to distributed project leadership

TripleO is not maintained after Zed, and is switching to the distributed
project leadership model.

openstack-discuss threads:
https://lists.openstack.org/pipermail/openstack-discuss/2023-February/032083.html
https://lists.openstack.org/pipermail/openstack-discuss/2023-March/032663.html

Signed-off-by: James Slagle <jslagle@redhat.com>
Change-Id: Ie21c6a8b89adfac2ecd03f7d63591280a72ca627
",git fetch https://review.opendev.org/openstack/governance refs/changes/99/878799/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,9a0121fa11fbd21f1cefb9f7eab0877b2e80451e,formal-vote, leadership_type: distributed, ptl: name: APPOINTMENT NEEDED irc: No nick supplied email: example@example.org,1,4
openstack%2Fgovernance~master~I05d716e1e5b5070bf4424117ac9fc25cf95a5345,openstack/governance,master,I05d716e1e5b5070bf4424117ac9fc25cf95a5345,Appoint Tim Burke as Swift PTL,MERGED,2023-03-22 21:58:24.000000000,2023-04-19 12:05:07.000000000,2023-04-19 12:04:03.000000000,"[{'_account_id': 935}, {'_account_id': 5314}, {'_account_id': 8556}, {'_account_id': 10342}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-03-22 21:58:24.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/91f20f9335e8dfff8c78fa11c825c2223432eba4', 'message': 'Appoint Tim Burke as Swift PTL\n\nChange-Id: I05d716e1e5b5070bf4424117ac9fc25cf95a5345\n'}]",3,878286,91f20f9335e8dfff8c78fa11c825c2223432eba4,15,7,1,15343,,,0,"Appoint Tim Burke as Swift PTL

Change-Id: I05d716e1e5b5070bf4424117ac9fc25cf95a5345
",git fetch https://review.opendev.org/openstack/governance refs/changes/86/878286/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,91f20f9335e8dfff8c78fa11c825c2223432eba4,formal-vote, name: Tim Burke irc: timburke email: tburke@nvidia.com - 2023.2, name: APPOINTMENT NEEDED irc: No nick supplied email: example@example.org,4,3
openstack%2Fopenstack-ansible-os_neutron~master~I50b99306a52f1a2379e55f390653b274afd5885f,openstack/openstack-ansible-os_neutron,master,I50b99306a52f1a2379e55f390653b274afd5885f,Use include instead of import for conditional tasks,MERGED,2023-02-23 17:48:35.000000000,2023-04-19 11:50:56.000000000,2023-04-19 11:49:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-02-23 17:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/a4848415cd981e7faef4c60582a087159725f404', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 2, 'created': '2023-04-04 10:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/5ed0164bf49f12d34d2affe8753a95bf437a9320', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 3, 'created': '2023-04-04 14:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/a4dc7657ef1176325c8e3112c87e579a43379456', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 4, 'created': '2023-04-13 17:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/8ef3243ba0e314d0870ce52dad860cfa23e12bee', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 5, 'created': '2023-04-13 17:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/de0c8de0dd33245c41d8218f619d83d5555c63ae', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 6, 'created': '2023-04-13 17:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/5ee750b331c626f351f10ac1a7eed3d18baf0ed6', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}, {'number': 7, 'created': '2023-04-13 17:16:07.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/956896e8a75616c1b0f79dd5d10e59c7a497803c', 'message': 'Use include instead of import for conditional tasks\n\nWhen import is used ansible loads imported role or tasks which\nresults in plenty of skipped tasks which also consume time. With\nincludes ansible does not try to load play so time not wasted on\nskipping things.\n\nChange-Id: I50b99306a52f1a2379e55f390653b274afd5885f\n'}]",0,874949,956896e8a75616c1b0f79dd5d10e59c7a497803c,17,3,7,28619,,,0,"Use include instead of import for conditional tasks

When import is used ansible loads imported role or tasks which
results in plenty of skipped tasks which also consume time. With
includes ansible does not try to load play so time not wasted on
skipping things.

Change-Id: I50b99306a52f1a2379e55f390653b274afd5885f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/49/874949/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/neutron_install.yml']",2,a4848415cd981e7faef4c60582a087159725f404,, include_role:, import_role:,15,7
openstack%2Fovn-octavia-provider~master~I5705c490bcd36e7e2edcc62954a3ffa0ff645519,openstack/ovn-octavia-provider,master,I5705c490bcd36e7e2edcc62954a3ffa0ff645519,Use ovsdbapp commands to add/del backends to ip_port_mappings,MERGED,2023-02-20 10:47:30.000000000,2023-04-19 11:40:52.000000000,2023-04-19 11:39:55.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-02-20 10:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/36dab8299788c524f1cb6ba4a846e0555d733247', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted.\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 2, 'created': '2023-02-20 11:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/60d5f8e5bdb6eacabb3b373301b63cbdeb3b55c8', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted.\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 3, 'created': '2023-02-22 09:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/613295926aef55937cb6ac58ac317acc6e089045', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted.\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 4, 'created': '2023-03-10 16:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/dedd5d830a74b1ecb8514c64778637471c6bfe37', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted. Also\ntaking care about the possibility of the same backend_ip could be\npointed by other member, under a different HM.\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 5, 'created': '2023-03-13 08:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/690f879226a20a1c34db481e03835b1c20acea1f', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted. Also\ntaking care about the possibility of the same backend_ip could be\npointed by other member, under a different HM.\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 6, 'created': '2023-03-13 09:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/50a7c2260dec22d010ab480ad2f6d31ab753ac4a', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted. Also\ntaking care about the possibility of the same backend_ip could be\npointed by other member, under a different HM.\n\novsdbapp bumps to 2.1.0 to be able to use those new functionalities [1]\n\n[1] https://github.com/openstack/ovsdbapp/commit/f3c5da5402ea2d1c129684a84c91dbc72556f14f\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}, {'number': 7, 'created': '2023-04-03 08:17:23.000000000', 'files': ['requirements.txt', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/e40e0d62ac089afd14c03102d80990e792211af3', 'message': 'Use ovsdbapp commands to add/del backends to ip_port_mappings\n\nLB ip_port_mapping is updated just adding and deleting every member\nafter any related operation over the LB-HM, this operation was done\nin two steps, a db_clear and a db_set.\n\nThis patch takes ovsdbapp specific commands for add/del backends to\nthe ip_port_mapping in a more appropiate way, reducing any further\noperation from OVN DBs not related to the member added/deleted. Also\ntaking care about the possibility of the same backend_ip could be\npointed by other member, under a different HM.\n\novsdbapp bumps to 2.1.0 to be able to use those new functionalities [1]\n\n[1] https://github.com/openstack/ovsdbapp/commit/f3c5da5402ea2d1c129684a84c91dbc72556f14f\n\nCloses-Bug: 2007835\nChange-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519\n'}]",21,874384,e40e0d62ac089afd14c03102d80990e792211af3,29,4,7,34451,,,0,"Use ovsdbapp commands to add/del backends to ip_port_mappings

LB ip_port_mapping is updated just adding and deleting every member
after any related operation over the LB-HM, this operation was done
in two steps, a db_clear and a db_set.

This patch takes ovsdbapp specific commands for add/del backends to
the ip_port_mapping in a more appropiate way, reducing any further
operation from OVN DBs not related to the member added/deleted. Also
taking care about the possibility of the same backend_ip could be
pointed by other member, under a different HM.

ovsdbapp bumps to 2.1.0 to be able to use those new functionalities [1]

[1] https://github.com/openstack/ovsdbapp/commit/f3c5da5402ea2d1c129684a84c91dbc72556f14f

Closes-Bug: 2007835
Change-Id: I5705c490bcd36e7e2edcc62954a3ffa0ff645519
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/84/874384/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/helper.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",2,36dab8299788c524f1cb6ba4a846e0555d733247,," def test__update_hm_member_no_members(self): pool_key = 'pool_%s' % self.pool_id self.ovn_lb.external_ids[pool_key] = '' self.assertTrue( self.helper._update_hm_member(self.ovn_lb, pool_key, '10.0.0.4')) @mock.patch.object(ovn_helper.OvnProviderHelper, '_ensure_hm_ovn_port') def test__update_hm_member_hm_port_multiple_ip(self, ensure_hm_port): hm_port = { 'fixed_ips': [{ 'subnet_id': 'ipv6_foo', 'ip_address': '2001:db8::199'}, { 'subnet_id': self.member_subnet_id, 'ip_address': '10.0.0.4'}]} ensure_hm_port.return_value = hm_port pool_key = 'pool_%s' % self.pool_id with mock.patch.object(ovn_helper.OvnProviderHelper, '_get_member_lsp'): self.assertTrue( self.helper._update_hm_member(self.ovn_lb, pool_key, self.member_address)) def test__update_ip_port_mappings(self): src_ip = '10.22.33.4' fakes.FakeOvsdbRow.create_one_ovsdb_row( attrs={'ip': self.member_address, 'logical_port': 'a-logical-port', 'src_ip': src_ip, 'port': self.member_port, 'protocol': self.ovn_hm_lb.protocol, 'status': ovn_const.HM_EVENT_MEMBER_PORT_ONLINE}) self.helper._update_ip_port_mappings( self.ovn_lb, self.member_address, 'a-logical-port', src_ip) self.helper.ovn_nbdb_api.lb_add_ip_port_mapping.assert_called_once_with( self.ovn_lb.uuid, self.member_address, 'a-logical-port', src_ip) self.helper._update_ip_port_mappings( self.ovn_lb, self.member_address, 'a-logical-port', src_ip, delete=True) self.helper.ovn_nbdb_api.lb_del_ip_port_mapping.assert_called_once_with( self.ovn_lb.uuid, self.member_address) @mock.patch.object(ovn_helper.OvnProviderHelper, '_update_hm_member')"," @mock.patch.object(ovn_helper.OvnProviderHelper, '_update_hm_members')",120,85
openstack%2Fgovernance~master~I5859cb517c07bb558cdd6bcdec4cae3f3941067b,openstack/governance,master,I5859cb517c07bb558cdd6bcdec4cae3f3941067b,Switch project and OpenStack versions in releases,ABANDONED,2023-03-01 15:54:45.000000000,2023-04-19 11:39:47.000000000,,"[{'_account_id': 4393}, {'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-01 15:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/200168b335d79766e786e9d0896bf61f6b131f46', 'message': ""Switch project and OpenStack versions in releases\n\nThere are several reasons why project versions worth to have main focus\ncomparing to openstack versions.\n\n1. Under release notes having OpenStack version first is quite confusing\naspart of the content there are differences between minor versions.\nFor example this would be quite hard to read:\n* OpenStack 2023.1 (Nova 27.0.0)\n* OpenStack 2023.1 (Nova 27.0.1)\n* OpenStack 2023.1 (Nova 27.1.0)\n\nWe also don't really have usecases when project version should not be\nmentioned at all in release notes, as our releasing assume having\nat least one tag for the service.\n\n2. Projects with independant release model are not tighten to any\nrelease. Thus versioning for then will not look harmonized.\nFor example, when using list of all projects we're going to have\nas of today:\n* OpenStack 2023.1 (Nova 27.0.0)\n* Tempest 33.0.0\n* OpenStack 2023.1 (Neutron 23.0.0)\n\n3. It might be also be valuable for projects that are used as standalone\nones to prioritize project versions over OpenStack versions. At the same\ntime proposed option should be a tradeoff where we still promoting\nOpenStack by including it into docs/renos/etc but harmonizing resulting\ndocumentation.\n\nThis patch is alternative proposal to [1]\n\n[1] https://review.opendev.org/c/openstack/governance/+/874484\n\nChange-Id: I5859cb517c07bb558cdd6bcdec4cae3f3941067b\n""}, {'number': 2, 'created': '2023-03-01 16:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/1bcbb77307ffb5792d1e1bab0aa5c7bbbc5f9a47', 'message': ""Switch project and OpenStack versions in releases\n\nThere are several reasons why project versions worth to have main focus\ncomparing to openstack versions.\n\n1. Under release notes having OpenStack version first is quite confusing\naspart of the content there are differences between minor versions.\nFor example this would be quite hard to read:\n* OpenStack 2023.1 (Nova 27.0.0)\n* OpenStack 2023.1 (Nova 27.0.1)\n* OpenStack 2023.1 (Nova 27.1.0)\n\nWe also don't really have usecases when project version should not be\nmentioned at all in release notes, as our releasing assume having\nat least one tag for the service.\n\n2. Projects with independant release model are not tighten to any\nrelease. Thus versioning for then will not look harmonized.\nFor example, when using list of all projects we're going to have\nas of today:\n* OpenStack 2023.1 (Nova 27.0.0)\n* Tempest 33.0.0\n* OpenStack 2023.1 (Neutron 23.0.0)\n\n3. It might be also be valuable for projects that are used as standalone\nones to prioritize project versions over OpenStack versions. At the same\ntime proposed option should be a tradeoff where we still promoting\nOpenStack by including it into docs/renos/etc but harmonizing resulting\ndocumentation.\n\nThis patch is alternative proposal to [1]\n\n[1] https://review.opendev.org/c/openstack/governance/+/874484\n\nChange-Id: I5859cb517c07bb558cdd6bcdec4cae3f3941067b\n""}, {'number': 3, 'created': '2023-03-01 16:51:47.000000000', 'files': ['reference/release-naming.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/bb6cb7af5fffba537e0ebb9000fb4ce009743b9f', 'message': ""Switch project and OpenStack versions in releases\n\nThere are several reasons why project versions worth to have main focus\ncomparing to openstack versions.\n\n1. Under release notes having OpenStack version first is quite confusing\naspart of the content there are differences between minor versions.\nFor example this would be quite hard to read:\n* OpenStack 2023.1 (Nova 27.0.0)\n* OpenStack 2023.1 (Nova 27.0.1)\n* OpenStack 2023.1 (Nova 27.1.0)\n\nWe also don't really have usecases when project version should not be\nmentioned at all in release notes, as our releasing assume having\nat least one tag for the service.\n\n2. Projects with independant release model are not tighten to any\nrelease. Thus versioning for then will not look harmonized.\nFor example, when using list of all projects we're going to have\nas of today:\n* OpenStack 2023.1 (Nova 27.0.0)\n* Tooz 3.2.0\n* OpenStack 2023.1 (Neutron 23.0.0)\n\n3. It might be also be valuable for projects that are used as standalone\nones to prioritize project versions over OpenStack versions. At the same\ntime proposed option should be a tradeoff where we still promoting\nOpenStack by including it into docs/renos/etc but harmonizing resulting\ndocumentation.\n\nThis patch is alternative proposal to [1]\n\n[1] https://review.opendev.org/c/openstack/governance/+/874484\n\nChange-Id: I5859cb517c07bb558cdd6bcdec4cae3f3941067b\n""}]",17,875942,bb6cb7af5fffba537e0ebb9000fb4ce009743b9f,22,4,3,28619,,,0,"Switch project and OpenStack versions in releases

There are several reasons why project versions worth to have main focus
comparing to openstack versions.

1. Under release notes having OpenStack version first is quite confusing
aspart of the content there are differences between minor versions.
For example this would be quite hard to read:
* OpenStack 2023.1 (Nova 27.0.0)
* OpenStack 2023.1 (Nova 27.0.1)
* OpenStack 2023.1 (Nova 27.1.0)

We also don't really have usecases when project version should not be
mentioned at all in release notes, as our releasing assume having
at least one tag for the service.

2. Projects with independant release model are not tighten to any
release. Thus versioning for then will not look harmonized.
For example, when using list of all projects we're going to have
as of today:
* OpenStack 2023.1 (Nova 27.0.0)
* Tooz 3.2.0
* OpenStack 2023.1 (Neutron 23.0.0)

3. It might be also be valuable for projects that are used as standalone
ones to prioritize project versions over OpenStack versions. At the same
time proposed option should be a tradeoff where we still promoting
OpenStack by including it into docs/renos/etc but harmonizing resulting
documentation.

This patch is alternative proposal to [1]

[1] https://review.opendev.org/c/openstack/governance/+/874484

Change-Id: I5859cb517c07bb558cdd6bcdec4cae3f3941067b
",git fetch https://review.opendev.org/openstack/governance refs/changes/42/875942/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/release-naming.rst'],1,200168b335d79766e786e9d0896bf61f6b131f46,formal-vote,"* Release notes: For the version of specific project use combined the project's version and OpenStack release, like ""Nova 27.X.Y (OpenStack 2023.1)"". * Nova 27.0.0 (OpenStack 2023.1) * Nova 27.1.0 (OpenStack 2023.1) Projects with independent release cycle can use only project versions. Examples: * Tempest 33.0.0 * Tooz 3.2.0 * Project specific documentation: use version of the project combined with release name. Examples: * Nova 27.0.0 (OpenStack 2023.1) * Neutron 23.0.0 (OpenStack 2023.2) Projects with independent release cycle can use only project versions.* Other, non-marketing related places: use version of the project combined with release name unless there is clear reason to use OpenStack release name instead. * Nova 27.0.0 (OpenStack 2023.1) * Neutron 23.0.0 (OpenStack 2023.2) Projects with independent release cycle can use only project versions: * Tempest 33.0.0 * Tooz 3.2.0 ","* Release notes: For the version of specific project use combined OpenStack release and the project's version, like ""OpenStack 2023.1 (Nova 27.X.Y)"". * OpenStack 2023.1 (Nova 27.0.0) * OpenStack 2023.2 (Neutron 23.0.0)* Project specific documentation: use release name combined with version of the project. Examples: * OpenStack 2023.1 (Nova 27.0.0) * OpenStack 2023.2 (Neutron 23.0.0)* Other, non-marketing related places: use release name combined with version of the project unless there is clear reason to use OpenStack release name instead. * OpenStack 2023.1 (Nova 27.0.0) * OpenStack 2023.2 (Neutron 23.0.0)",29,14
openstack%2Fcharm-keystone-k8s~main~I4f3a1c51af71b04bab3d7fd4f66c15d30898c92b,openstack/charm-keystone-k8s,main,I4f3a1c51af71b04bab3d7fd4f66c15d30898c92b,Check for unprocessed client requests,MERGED,2023-04-18 14:44:35.000000000,2023-04-19 11:37:30.000000000,2023-04-19 10:36:33.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 14:44:35.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/f60786233f066f4f19e2927463d9f10c81b9e89f', 'message': 'Check for unprocessed client requests\n\nDefered events can be lost if a pod is recreated. If an event is\ndeferred before this happens then the event will be lost. This\npatch causes the charm to check for outstanding requests.\n\nChange-Id: I4f3a1c51af71b04bab3d7fd4f66c15d30898c92b\n'}]",1,880754,f60786233f066f4f19e2927463d9f10c81b9e89f,9,2,1,12549,,,0,"Check for unprocessed client requests

Defered events can be lost if a pod is recreated. If an event is
deferred before this happens then the event will be lost. This
patch causes the charm to check for outstanding requests.

Change-Id: I4f3a1c51af71b04bab3d7fd4f66c15d30898c92b
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/54/880754/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,f60786233f066f4f19e2927463d9f10c81b9e89f,check-client-requests,"import json IDSVC_RELATION_NAME = ""identity-service"" IDCREDS_RELATION_NAME = ""identity-credentials"" ""Deferring _on_peer_data_changed event as node is not "" ""bootstrapped yet"" for relation in self.model.relations[self.IDSVC_RELATION_NAME] for relation in self.model.relations[self.IDSVC_RELATION_NAME] if self.can_add_handler(self.IDSVC_RELATION_NAME, handlers): self.IDSVC_RELATION_NAME, self.register_service_from_event, if self.can_add_handler(self.IDCREDS_RELATION_NAME, handlers): self.IDCREDS_RELATION_NAME, self.add_credentials_from_event, def can_service_requests(self) -> bool: """"""Check if unit can process client requests."""""" if self.bootstrapped() and self.unit.is_leader(): logger.debug(""Can service client requests"") return True else: logger.debug( ""Cannot service client requests. "" ""Bootstrapped: {} Leader {}"".format( self.bootstrapped(), self.unit.is_leader() ) ) return False def check_outstanding_requests(self) -> bool: """"""Process any outstanding client requests."""""" logger.debug(""Checking for outstanding client requests"") if not self.can_service_requests(): return for relation in self.framework.model.relations[ self.IDSVC_RELATION_NAME ]: app_data = relation.data[relation.app] if relation.data[self.app].get(""service-credentials""): logger.debug( ""Identity service request already processed for "" f""{relation.app.name} {relation.name}/{relation.id}"" ) else: if app_data.get(""service-endpoints""): logger.debug( ""Processing register service request for "" f""{relation.app.name} {relation.name}/{relation.id}"" ) self.register_service( relation.id, relation.name, json.loads(app_data[""service-endpoints""]), app_data[""region""], relation.app.name, ) else: logger.debug( ""Cannot process client request, 'service-endpoints' "" ""not supplied"" ) for relation in self.framework.model.relations[ self.IDCREDS_RELATION_NAME ]: app_data = relation.data[relation.app] if relation.data[self.app].get(""credentials""): logger.debug( ""Credential request already processed for "" f""{relation.app.name} {relation.name}/{relation.id}"" ) else: if app_data.get(""username""): logger.debug( ""Processing credentials request from "" f""{relation.app.name} {relation.name}/{relation.id}"" ) self.add_credentials( relation.id, relation.name, app_data[""username""] ) else: logger.debug( ""Cannot process client request, 'username' not "" ""supplied"" ) def register_service_from_event(self, event): """"""Process service request event. NOTE: The event will not be deferred. If it cannot be processed now then it will be picked up by `check_outstanding_requests` """""" if self.can_service_requests(): self.register_service( event.relation_id, event.relation_name, event.service_endpoints, event.region, event.client_app_name, ) def register_service( self, relation_id: str, relation_name: str, service_endpoints: str, region: str, client_app_name: str, ): logger.debug(f""Registering service requested by {client_app_name}"") relation = self.model.get_relation(relation_name, relation_id) for ep_data in service_endpoints: client_app_name.replace(""-"", ""_"") relation_name, relation_id region=region, relation_name, relation_id, def add_credentials_from_event(self, event): """"""Process service request event. NOTE: The event will not be deferred. If it cannot be processed now then it will be picked up by `check_outstanding_requests` """""" if self.can_service_requests(event): self.add_credentials( event.relation_id, event.relation_name, event.username ) def add_credentials( self, relation_id: str, relation_name: str, username: str ): logger.debug(""Processing credentials request"") relation = self.model.get_relation(relation_name, relation_id) event_relation = self.model.get_relation(relation_name, relation_id) credentials_id = self._retrieve_or_set_secret(username, scope) logger.warning(f""Secret for {username} not found"") username=username, relation_name=relation_name, relation_id=relation_id, self.IDSVC_RELATION_NAME self.IDSVC_RELATION_NAME self.IDSVC_RELATION_NAME self.check_outstanding_requests()"," ""Deferring _on_peer_data_changed event as node is not bootstrapped yet"" for relation in self.model.relations[""identity-service""] for relation in self.model.relations[""identity-service""] if self.can_add_handler(""identity-service"", handlers): ""identity-service"", self.register_service, if self.can_add_handler(""identity-credentials"", handlers): ""identity-credentials"", self.add_credentials, def register_service(self, event): if not self.bootstrapped(): event.defer() return if not self.unit.is_leader(): return relation = self.model.get_relation( event.relation_name, event.relation_id ) for ep_data in event.service_endpoints: event.client_app_name.replace(""-"", ""_"") event.relation_name, event.relation_id region=event.region, event.relation_name, event.relation_id, def add_credentials(self, event): if not self.unit.is_leader(): logger.debug( ""Current unit is not the leader unit, deferring "" ""credential creation to leader unit."" ) return if not self.bootstrapped(): logger.debug( ""Keystone is not bootstrapped, deferring credential "" ""creation until after bootstrap."" ) event.defer() return relation = self.model.get_relation( event.relation_name, event.relation_id ) event_relation = self.model.get_relation( event.relation_name, event.relation_id ) credentials_id = self._retrieve_or_set_secret( event.username, scope ) logger.warning(f""Secret for {event.username} not found"") username=event.username, relation_name=event.relation_name, relation_id=event.relation_id, ""identity-service"" ""identity-service"" ""identity-service""",140,56
openstack%2Frequirements~master~Iaf2ac36d89359592a0e27a5e48c1f414a0ed4116,openstack/requirements,master,Iaf2ac36d89359592a0e27a5e48c1f414a0ed4116,bump SQLAlchemy-Utils to 0.40.0 in uc,ABANDONED,2023-04-19 08:31:24.000000000,2023-04-19 11:19:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-19 08:31:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7474f0f6f727971be5e0e5ad6ec2d8051cc67887', 'message': 'bump SQLAlchemy-Utils to 0.40.0 in uc\n\nThis brings SQLAlchemy 2 support. See\nhttps://github.com/kvesteri/sqlalchemy-utils/releases/tag/0.40.0\n\nChange-Id: Iaf2ac36d89359592a0e27a5e48c1f414a0ed4116\n'}]",0,880524,7474f0f6f727971be5e0e5ad6ec2d8051cc67887,3,1,1,18816,,,0,"bump SQLAlchemy-Utils to 0.40.0 in uc

This brings SQLAlchemy 2 support. See
https://github.com/kvesteri/sqlalchemy-utils/releases/tag/0.40.0

Change-Id: Iaf2ac36d89359592a0e27a5e48c1f414a0ed4116
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/880524/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,7474f0f6f727971be5e0e5ad6ec2d8051cc67887,bump_sqlalchemy_utils,SQLAlchemy-Utils===0.40.0,SQLAlchemy-Utils===0.38.3,1,1
openstack%2Fkolla~stable%2Fyoga~Ie067d72bd468467c6ccb8d1ca80695c769ec403e,openstack/kolla,stable/yoga,Ie067d72bd468467c6ccb8d1ca80695c769ec403e,rabbitmq: update to RabbitMQ 3.10,NEW,2023-04-19 08:26:15.000000000,2023-04-19 11:13:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 35263}]","[{'number': 1, 'created': '2023-04-19 08:26:15.000000000', 'files': ['docker/base/apt_preferences.ubuntu', 'docker/base/apt_preferences.debian', 'docker/rabbitmq/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/29d7f6836f126f433dd15c3e7fee77448117a7af', 'message': 'rabbitmq: update to RabbitMQ 3.10\n\nYoga provides RabbitMQ 3.9 series which is not supported anymore.\n\nRabbitMQ 3.10 is a final RMQ update in stable/wallaby branch.\n\nAccording to upstream [1] 3.9 -> 3.10 migration is fine while 3.9 -> 3.11\nshould be done through 3.10 so we can not move to 3.11 version here.\n\n1. https://www.rabbitmq.com/upgrade.html#rabbitmq-version-upgradability\n\nChange-Id: Ie067d72bd468467c6ccb8d1ca80695c769ec403e\n'}]",1,880799,29d7f6836f126f433dd15c3e7fee77448117a7af,5,3,1,22629,,,0,"rabbitmq: update to RabbitMQ 3.10

Yoga provides RabbitMQ 3.9 series which is not supported anymore.

RabbitMQ 3.10 is a final RMQ update in stable/wallaby branch.

According to upstream [1] 3.9 -> 3.10 migration is fine while 3.9 -> 3.11
should be done through 3.10 so we can not move to 3.11 version here.

1. https://www.rabbitmq.com/upgrade.html#rabbitmq-version-upgradability

Change-Id: Ie067d72bd468467c6ccb8d1ca80695c769ec403e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/99/880799/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/apt_preferences.ubuntu', 'docker/base/apt_preferences.debian', 'docker/rabbitmq/Dockerfile.j2']",3,29d7f6836f126f433dd15c3e7fee77448117a7af,, 'rabbitmq-server-3.10.*', 'rabbitmq-server-3.9.*',3,3
openstack%2Fcinder~master~I5e12a7555b465a5fd8510d5a9b80d5caa30ce507,openstack/cinder,master,I5e12a7555b465a5fd8510d5a9b80d5caa30ce507,Update functional jobs for 2023.2,MERGED,2023-04-17 21:35:31.000000000,2023-04-19 11:01:43.000000000,2023-04-18 17:02:25.000000000,"[{'_account_id': 4523}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-04-17 21:35:31.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3febae752925d98e97e80d45e0699177e9770ae9', 'message': 'Update functional jobs for 2023.2\n\nBased on the python runtimes for 2023.2 [0], we should be running\nfunctional jobs on python 3.9 and python 3.10.\n\nThis patch does not remove the ability to run the functional jobs\nlocally on python 3.8, as it may be useful to test changes that\nare intended to be backported.\n\n[0] https://governance.openstack.org/tc/reference/runtimes/2023.2.html\n\nChange-Id: I5e12a7555b465a5fd8510d5a9b80d5caa30ce507\n'}]",1,880684,3febae752925d98e97e80d45e0699177e9770ae9,26,3,1,5314,,,0,"Update functional jobs for 2023.2

Based on the python runtimes for 2023.2 [0], we should be running
functional jobs on python 3.9 and python 3.10.

This patch does not remove the ability to run the functional jobs
locally on python 3.8, as it may be useful to test changes that
are intended to be backported.

[0] https://governance.openstack.org/tc/reference/runtimes/2023.2.html

Change-Id: I5e12a7555b465a5fd8510d5a9b80d5caa30ce507
",git fetch https://review.opendev.org/openstack/cinder refs/changes/84/880684/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3febae752925d98e97e80d45e0699177e9770ae9,2023.2-functests, - openstack-tox-functional-py39:, - openstack-tox-functional-py38:,1,1
openstack%2Fskyline-console~master~I88f3a842bcf3a91d1cd8a0f20e847f1e5e57ed7d,openstack/skyline-console,master,I88f3a842bcf3a91d1cd8a0f20e847f1e5e57ed7d,feat: optimize the clicking event in the select-table,MERGED,2023-04-19 06:38:05.000000000,2023-04-19 10:11:37.000000000,2023-04-19 10:10:37.000000000,"[{'_account_id': 22348}, {'_account_id': 28706}, {'_account_id': 33689}]","[{'number': 1, 'created': '2023-04-19 06:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/ee2bb0ffba0b552b8b1feeb94c5b1a9c06d642f1', 'message': 'feat: optimize the clicking event in the select-table\n\nOptimize the clicking event in the select-table component, when click the row of the table in the component, the row will be selected, but when click the button in the row, the selection does not change.\n\nChange-Id: I88f3a842bcf3a91d1cd8a0f20e847f1e5e57ed7d\n'}, {'number': 2, 'created': '2023-04-19 06:45:27.000000000', 'files': ['src/components/TableButton/RuleButton.jsx', 'src/pages/compute/containers/Instance/actions/StepCreate/NetworkStep/index.jsx', 'src/components/TableButton/index.jsx', 'src/pages/compute/containers/Instance/actions/CreateIronic/NetworkStep/index.jsx', 'src/pages/compute/containers/Instance/Detail/SecurityGroup/action/ManageSecurityGroup.jsx', 'src/components/ModalButton/index.jsx', 'src/pages/compute/containers/Instance/actions/ManageSecurityGroup.jsx', 'src/pages/network/containers/Port/actions/ManageSecurityGroup.jsx'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/56230e524e48b77ccd7672f0c18a0c71499d2be5', 'message': 'feat: optimize the clicking event in the select-table\n\nOptimize the clicking event in the select-table component, when click the row of the table in the component, the row will be selected, but when click the button in the row, the selection does not change.\n\nChange-Id: I88f3a842bcf3a91d1cd8a0f20e847f1e5e57ed7d\n'}]",0,880793,56230e524e48b77ccd7672f0c18a0c71499d2be5,9,3,2,30434,,,0,"feat: optimize the clicking event in the select-table

Optimize the clicking event in the select-table component, when click the row of the table in the component, the row will be selected, but when click the button in the row, the selection does not change.

Change-Id: I88f3a842bcf3a91d1cd8a0f20e847f1e5e57ed7d
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/93/880793/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/components/TableButton/RuleButton.jsx', 'src/pages/compute/containers/Instance/actions/StepCreate/NetworkStep/index.jsx', 'src/components/TableButton/index.jsx', 'src/pages/compute/containers/Instance/actions/CreateIronic/NetworkStep/index.jsx', 'src/pages/compute/containers/Instance/Detail/SecurityGroup/action/ManageSecurityGroup.jsx', 'src/components/ModalButton/index.jsx', 'src/pages/compute/containers/Instance/actions/ManageSecurityGroup.jsx', 'src/pages/network/containers/Port/actions/ManageSecurityGroup.jsx']",8,ee2bb0ffba0b552b8b1feeb94c5b1a9c06d642f1,select-table,," onRow: () => {},",97,14
openstack%2Fopenstack-ansible-os_ironic~master~Ibb15f08fbeaf03e8a4f453066614a511ce7f250c,openstack/openstack-ansible-os_ironic,master,Ibb15f08fbeaf03e8a4f453066614a511ce7f250c,Add example networking-generic-switch user role for Arista switch,MERGED,2023-04-19 07:37:03.000000000,2023-04-19 09:57:34.000000000,2023-04-19 09:56:20.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-19 07:37:03.000000000', 'files': ['doc/source/configure-lxc-example.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/72cbb5c5e0f35db05d245f87551c925f37cbb623', 'message': 'Add example networking-generic-switch user role for Arista switch\n\nChange-Id: Ibb15f08fbeaf03e8a4f453066614a511ce7f250c\n'}]",0,880797,72cbb5c5e0f35db05d245f87551c925f37cbb623,8,3,1,25023,,,0,"Add example networking-generic-switch user role for Arista switch

Change-Id: Ibb15f08fbeaf03e8a4f453066614a511ce7f250c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/97/880797/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configure-lxc-example.rst'],1,72cbb5c5e0f35db05d245f87551c925f37cbb623,,"on the Cisco Nexus switch create a role:A similar config can be made on an Arista switch, where a much more explicit list of allowed CLI commands must be defined using regular expressions. .. code-block:: bash role neutron-role 10 permit mode exec command configure 20 permit mode exec command terminal width 511 30 permit mode exec command terminal length 0 40 permit mode exec command enable 50 permit mode exec command copy running-config startup-config 60 permit mode config command interface 70 permit mode if-Et([1-9]|27|29)\/1 command switchport mode access 80 permit mode if-Et([1-9]|27|29)\/1 command (no )*switchport access vlan (3003|3966) 90 permit mode if-Et([1-9]|27|29)\/1 command no switchport mode trunk 100 permit mode if-Et([1-9]|27|29)\/1 command switchport trunk allowed vlan none 110 permit mode config command copy running-config startup-config ",on the switch create a role:,20,1
openstack%2Fmanila~master~I0d5cd436171977f4c70f2dd6ac47ef8578b9ba59,openstack/manila,master,I0d5cd436171977f4c70f2dd6ac47ef8578b9ba59,WIP: api: Log current status of share,ABANDONED,2023-04-04 10:21:20.000000000,2023-04-19 09:47:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-04 10:21:20.000000000', 'files': ['manila/share/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f3a7f42f4408b899a2eeed846cbb179d5ac5e3f6', 'message': ""WIP: api: Log current status of share\n\nCurrently, if you attempt to delete a share or related resource that is\nin an invalid state, it will fail with a warning like so:\n\n  Invalid share: Share status must be one of ('available', 'error',\n  'inactive')\n\nThis doesn't tell us what the current state actually is. To get that,\nyou need to inspect the share. Modify the error message slightly so that\nthe current state is included in the error message, avoiding this\ninterim step and making debugging slightly easier.\n\n  Invalid share: Share status must be one of ('available', 'error',\n  'inactive'), not creating\n\nWIP because tests need updating.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I0d5cd436171977f4c70f2dd6ac47ef8578b9ba59\n""}]",0,879438,f3a7f42f4408b899a2eeed846cbb179d5ac5e3f6,6,1,1,15334,,,0,"WIP: api: Log current status of share

Currently, if you attempt to delete a share or related resource that is
in an invalid state, it will fail with a warning like so:

  Invalid share: Share status must be one of ('available', 'error',
  'inactive')

This doesn't tell us what the current state actually is. To get that,
you need to inspect the share. Modify the error message slightly so that
the current state is included in the error message, avoiding this
interim step and making debugging slightly easier.

  Invalid share: Share status must be one of ('available', 'error',
  'inactive'), not creating

WIP because tests need updating.

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: I0d5cd436171977f4c70f2dd6ac47ef8578b9ba59
",git fetch https://review.opendev.org/openstack/manila refs/changes/38/879438/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/api.py'],1,f3a7f42f4408b899a2eeed846cbb179d5ac5e3f6,sqlalchemy-20," msg = _( ""Share status must be one of %(statuses)s, not %(status)r"" ) % {""statuses"": statuses, ""status"": share['status']} msg = _( ""Share status must be one of %(statuses)s, not %(status)r"" ) % {""statuses"": statuses, ""status"": share['status']} msg = _( ""Share instance status must be one of %(statuses)s, not "" ""%(status)r"" ) % {""statuses"": statuses, ""status"": share_instance['status']} msg = _( ""Source share status must be one of %(statuses)s, not "" ""%(status)r"" ) % { ""statuses"": (constants.STATUS_AVAILABLE,), ""status"": share['status'], } msg = _( ""Share instance status must be one of %(statuses)s, not "" ""%(status)r"" ) % { ""statuses"": (constants.STATUS_AVAILABLE,), ""status"": share_instance['status'], } msg = _( ""Share snapshot status must be one of %(statuses)s, not "" ""%(status)r"" ) % {""statuses"": statuses, ""status"": snapshot['status']}"," msg = _(""Share status must be one of %(statuses)s"") % { ""statuses"": statuses} msg = _(""Share status must be one of %(statuses)s"") % { ""statuses"": statuses} msg = _(""Share instance status must be one of %(statuses)s"") % { ""statuses"": statuses} msg = _(""Source share status must be "" ""%s"") % constants.STATUS_AVAILABLE msg = _('Share instance %(instance_id)s status must be available, ' 'but current status is: %(instance_status)s.') % { 'instance_id': share_instance['id'], 'instance_status': share_instance['status']} msg = _(""Share Snapshot status must be one of %(statuses)s."") % { ""statuses"": statuses}",28,14
openstack%2Fneutron~stable%2F2023.1~Iba7ff50efc8f6d027fe9151fc64f547aa421b995,openstack/neutron,stable/2023.1,Iba7ff50efc8f6d027fe9151fc64f547aa421b995,[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``,MERGED,2023-04-14 15:38:12.000000000,2023-04-19 09:44:39.000000000,2023-04-19 09:43:20.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 15:38:12.000000000', 'files': ['neutron/db/dvr_mac_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d543824a6dccd653fc73b55cc959c2bc233fe41', 'message': '[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``\n\nCloses-Bug: #2016142\nChange-Id: Iba7ff50efc8f6d027fe9151fc64f547aa421b995\n(cherry picked from commit 69f30c92ef595f1bfc57208f88c4c1c5a555f55c)\n'}]",1,880496,2d543824a6dccd653fc73b55cc959c2bc233fe41,10,5,1,16688,,,0,"[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``

Closes-Bug: #2016142
Change-Id: Iba7ff50efc8f6d027fe9151fc64f547aa421b995
(cherry picked from commit 69f30c92ef595f1bfc57208f88c4c1c5a555f55c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/880496/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/dvr_mac_db.py'],1,2d543824a6dccd653fc73b55cc959c2bc233fe41,bug/2016142-stable/2023.1, @db_api.CONTEXT_READER,,1,0
openstack%2Fneutron-lib~stable%2Fzed~Ibde6acdb99555a6e43ca253523df7cbe4d150787,openstack/neutron-lib,stable/zed,Ibde6acdb99555a6e43ca253523df7cbe4d150787,Return properly elevated context by get_admin_context() helper,MERGED,2023-04-12 13:07:42.000000000,2023-04-19 09:37:05.000000000,2023-04-19 09:36:05.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 13:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/7306bd4fe7895728073640cc79d226bd6e24a2f7', 'message': ""Return properly elevated context by get_admin_context() helper\n\nIn neutron_lib.context module there are two simple helper functions:\nget_admin_context and get_admin_context_without_session.\nBoth returned Context object with is_admin=True but without admin role\nset and due to that it wasn't proper admin context when new secure RBAC\npolicies are used.\nWith this patch both those helper functions returns properly elevated\nContext object with admin role set.\n\nCloses-Bug: #2015987\nChange-Id: Ibde6acdb99555a6e43ca253523df7cbe4d150787\n""}, {'number': 2, 'created': '2023-04-12 18:08:26.000000000', 'files': ['neutron_lib/context.py', 'neutron_lib/tests/unit/test_context.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/cbfb104f90c66f2fb774cad90067597e1ade13c7', 'message': ""Return properly elevated context by get_admin_context() helper\n\nIn neutron_lib.context module there are two simple helper functions:\nget_admin_context and get_admin_context_without_session.\nBoth returned Context object with is_admin=True but without admin role\nset and due to that it wasn't proper admin context when new secure RBAC\npolicies are used.\nWith this patch both those helper functions returns properly elevated\nContext object with admin role set.\n\nCloses-Bug: #2015987\nChange-Id: Ibde6acdb99555a6e43ca253523df7cbe4d150787\n(cherry picked from commit 09af59caa93e23447c164b480f6f0f4ec865842c)\n""}]",1,880103,cbfb104f90c66f2fb774cad90067597e1ade13c7,11,4,2,16688,,,0,"Return properly elevated context by get_admin_context() helper

In neutron_lib.context module there are two simple helper functions:
get_admin_context and get_admin_context_without_session.
Both returned Context object with is_admin=True but without admin role
set and due to that it wasn't proper admin context when new secure RBAC
policies are used.
With this patch both those helper functions returns properly elevated
Context object with admin role set.

Closes-Bug: #2015987
Change-Id: Ibde6acdb99555a6e43ca253523df7cbe4d150787
(cherry picked from commit 09af59caa93e23447c164b480f6f0f4ec865842c)
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/03/880103/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/context.py', 'neutron_lib/tests/unit/test_context.py']",2,7306bd4fe7895728073640cc79d226bd6e24a2f7,bug/2015987-stable/2023.1-stable/zed," self.assertIn('admin', ctx_dict['roles']) self.assertIn('admin', ctx_dict['roles'])",,10,4
openstack%2Fkolla-ansible~master~Ic61fe981825c5fa6f50e53c9555b6a102f42f522,openstack/kolla-ansible,master,Ic61fe981825c5fa6f50e53c9555b6a102f42f522,mariadb: add mariadb_datadir_volume parameter,MERGED,2023-03-06 22:45:50.000000000,2023-04-19 08:29:18.000000000,2023-04-19 08:27:42.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}, {'_account_id': 32761}, {'_account_id': 35263}]","[{'number': 1, 'created': '2023-03-06 22:45:50.000000000', 'files': ['releasenotes/notes/mariadb_datadir_volum-c9a597766c2c8bc8.yaml', 'ansible/group_vars/all.yml', 'ansible/roles/mariadb/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b327ae4a56b3a7e3f929b3f884bc9501e712c60d', 'message': 'mariadb: add mariadb_datadir_volume parameter\n\nWith the parameter ``mariadb_datadir_volume`` it is possible\nto use a directory as volume for the mariadb service. By default,\na volume named mariadb is used (the previous default).\n\nChange-Id: Ic61fe981825c5fa6f50e53c9555b6a102f42f522\n'}]",2,876649,b327ae4a56b3a7e3f929b3f884bc9501e712c60d,17,5,1,167,,,0,"mariadb: add mariadb_datadir_volume parameter

With the parameter ``mariadb_datadir_volume`` it is possible
to use a directory as volume for the mariadb service. By default,
a volume named mariadb is used (the previous default).

Change-Id: Ic61fe981825c5fa6f50e53c9555b6a102f42f522
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/49/876649/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/mariadb_datadir_volum-c9a597766c2c8bc8.yaml', 'ansible/group_vars/all.yml', 'ansible/roles/mariadb/defaults/main.yml']",3,b327ae4a56b3a7e3f929b3f884bc9501e712c60d,mariadb_datadir_volume," - ""{{ mariadb_datadir_volume }}:/var/lib/mysql"""," - ""mariadb:/var/lib/mysql""",9,1
openstack%2Fpuppet-ceilometer~stable%2Fwallaby~I5e0af169ccdb2f4c56318dbc0198f480ab4b15fa,openstack/puppet-ceilometer,stable/wallaby,I5e0af169ccdb2f4c56318dbc0198f480ab4b15fa,Use oslo::coordination to manage coordination parameters,ABANDONED,2023-04-18 10:55:28.000000000,2023-04-19 08:22:29.000000000,,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 10:55:28.000000000', 'files': ['releasenotes/notes/coordination-6e5105e0558f3e5b.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb', 'manifests/coordination.pp', 'spec/classes/ceilometer_coordination_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/887c2ead0026a7b846c455a262e2831cf781f67d', 'message': 'Use oslo::coordination to manage coordination parameters\n\nThis change replaces current implementation about coordination\nparameters by oslo::coordination resource type, so that we can gather\nall logics related to coordination in a single place.\n\nDepends-on: https://review.opendev.org/791628\nChange-Id: I5e0af169ccdb2f4c56318dbc0198f480ab4b15fa\n(cherry picked from commit 1155b41db051e95e9246aa02eed2205f1f0f845a)\n'}]",1,880731,887c2ead0026a7b846c455a262e2831cf781f67d,4,2,1,32240,,,0,"Use oslo::coordination to manage coordination parameters

This change replaces current implementation about coordination
parameters by oslo::coordination resource type, so that we can gather
all logics related to coordination in a single place.

Depends-on: https://review.opendev.org/791628
Change-Id: I5e0af169ccdb2f4c56318dbc0198f480ab4b15fa
(cherry picked from commit 1155b41db051e95e9246aa02eed2205f1f0f845a)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/31/880731/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/coordination-6e5105e0558f3e5b.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb', 'manifests/coordination.pp', 'spec/classes/ceilometer_coordination_spec.rb']",5,887c2ead0026a7b846c455a262e2831cf781f67d,,"require 'spec_helper' describe 'ceilometer::coordination' do shared_examples 'ceilometer::coordination' do context 'with default parameters' do it { is_expected.to contain_oslo__coordination('ceilometer_config').with( :backend_url => '<SERVICE DEFAULT>' ) } end context 'with specified parameters' do let :params do { :backend_url => 'etcd3+http://127.0.0.1:2379', } end it { is_expected.to contain_oslo__coordination('ceilometer_config').with( :backend_url => 'etcd3+http://127.0.0.1:2379' ) } end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge(OSDefaults.get_facts()) end it_behaves_like 'ceilometer::coordination' end end end ",,83,17
openstack%2Fcinder~master~Idbf8f11677872b27c91700544dfd238387cd0665,openstack/cinder,master,Idbf8f11677872b27c91700544dfd238387cd0665,db: Remove unnecessary sqlalchemy abstraction,NEW,2021-10-08 16:38:33.000000000,2023-04-19 08:20:57.000000000,,"[{'_account_id': 4523}, {'_account_id': 9535}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 31779}]","[{'number': 1, 'created': '2021-10-08 16:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e9cbcb59a98f9c830c92a48f7a32356285d480d', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2021-10-12 16:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d75d919d6f3e0eb18dc34cb4884e8432d6981be2', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2021-11-04 16:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c29c2b0d697f86ff1ba3d0b8bcc8eebad7a90391', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2021-12-15 10:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e23b0401f6e5a8c92fdecc5e9fe7d026808f202c', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2022-01-31 18:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30d85c55c678876051153a91c04a42c8ddee0b4b', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2022-02-20 19:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/24d50e90c59d8b7e94b5198244fc2cc96c4bdf58', 'message': ""WIP: db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'nova.db.sqlalchemy.api' into 'nova.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nWIP because I've clearly missed some stuff, as the failing tests show.\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 7, 'created': '2022-04-12 10:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/349c7b156b0a2e349b63f001f80dc5f52bba2ede', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 8, 'created': '2022-04-14 18:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ee0e3a2155b3a02b77ecaa96ba1d6c627b3ddad', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 9, 'created': '2022-04-14 18:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0a29ef841ae00ff9ca7835dd67667c0d0aa155f5', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 10, 'created': '2022-06-16 13:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50943763242621231b7787ef3e1f6c2369eba112', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 11, 'created': '2022-06-17 10:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fa82e0a00af622f6a3991e8f71a3e980f2b835d8', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 12, 'created': '2022-07-18 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3da035192179765422c45cc1fb30383c61907bfe', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 13, 'created': '2022-07-28 16:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc6ff021039b27a0cf4e23fa7ab50d546838b064', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 14, 'created': '2022-08-31 08:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80499857d622af49eec3192d050506d67d994ae2', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 15, 'created': '2023-02-22 10:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/68c544dfc62e8977f9b5020c52cec8ff5f543a9e', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 16, 'created': '2023-02-22 18:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ac822a75709e3d08ef4efbb5d9f37e96d5faa5cf', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 17, 'created': '2023-03-30 16:15:04.000000000', 'files': ['cinder/tests/unit/api/v3/test_volumes.py', 'cinder/tests/unit/test_db_api.py', 'cinder/tests/unit/group/test_groups_api.py', 'cinder/tests/unit/objects/test_base.py', 'cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/tests/unit/db/test_cluster.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/objects/test_group_snapshot.py', 'cinder/cmd/manage.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/unit/scheduler/test_allocated_capacity_weigher.py', 'cinder/tests/unit/objects/test_group_type.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/group/test_groups_manager.py', 'cinder/tests/unit/fake_service.py', 'cinder/tests/unit/api/v3/test_snapshot_metadata.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/attachments/test_attachments_manager.py', 'cinder/tests/unit/fake_cluster.py', 'cinder/db/migration.py', 'cinder/tests/unit/objects/test_qos.py', 'cinder/tests/unit/volume/test_connection.py', 'cinder/tests/unit/api/contrib/test_snapshot_manage.py', 'cinder/tests/unit/test_paginate_query.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/interface/volume_consistencygroup_driver.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/db/api.py', 'cinder/tests/unit/volume/drivers/test_lvm_driver.py', 'cinder/tests/unit/image/test_cache.py', 'cinder/tests/unit/objects/test_service.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/scheduler/test_volume_number_weigher.py', 'cinder/volume/volume_utils.py', 'cinder/api/contrib/quota_classes.py', 'cinder/db/alembic.ini', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_mirror_fc.py', 'cinder/tests/unit/volume/flows/test_manage_snapshot_flow.py', 'cinder/tests/unit/volume/test_volume_migration.py', 'cinder/tests/unit/api/contrib/test_volume_manage.py', 'cinder/tests/unit/db/test_migration.py', 'cinder/tests/unit/objects/test_group.py', 'cinder/tests/unit/volume/drivers/dell_emc/powerflex/test_create_snapshot.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/tests/unit/volume/drivers/hpe/xp/test_hpe_xp_rest_iscsi.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_fc.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/api/v3/test_cluster.py', 'cinder/tests/unit/volume/drivers/test_spdk.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/volume/drivers/hpe/xp/test_hpe_xp_rest_fc.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/tests/unit/cmd/test_status.py', 'cinder/tests/unit/objects/test_cluster.py', 'doc/source/conf.py', 'cinder/tests/unit/api/v3/test_snapshots.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_iscsi.py', 'cinder/volume/driver.py', 'cinder/db/models.py', 'cinder/db/sqlalchemy/__init__.py', 'cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/tests/unit/test.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_iscsi.py', 'doc/source/contributor/api_conditional_updates.rst', 'cinder/db/migrations/env.py', 'cinder/tests/unit/test_service.py', 'cinder/tests/unit/db/test_migrations.py', 'cinder/tests/unit/db/test_orm_relationships.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bed1410566d0979f9f1522d5b7590b2731a19a3', 'message': ""db: Remove unnecessary sqlalchemy abstraction\n\nThere is only one ORM in use in Cinder nowadays. There's no reason to\npretend we're going to support others. Remove the abstraction layer that\nallows users to select different backends and merge\n'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older\nmodule were replaced like so:\n\n  $ cd cinder\n  $ find cinder -type f -name '*.py' \\\n      -exec sed -i 's/\\<db\\>\\.sqlalchemy/db/g' {} \\;\n\nAfter this, three files needed single line changes to fix import\nordering:\n\n  cinder/cmd/manage.py\n  cinder/tests/unit/test.py\n  cinder/tests/unit/db/test_migration.py\n\nNote that git can get confused here and not realize that we're deleting\n'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to\n'cinder/db/api.py' with some changes. You can view the actual diff to\nthe latter by running the following with this commit checked out:\n\n  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py\n  git show HEAD:cinder/db/api.py > api-new.py\n  diff api-old.py api-new.py\n\nThere's probably a nicer way to do this :)\n\nChange-Id: Idbf8f11677872b27c91700544dfd238387cd0665\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",13,813229,9bed1410566d0979f9f1522d5b7590b2731a19a3,328,5,17,15334,,,0,"db: Remove unnecessary sqlalchemy abstraction

There is only one ORM in use in Cinder nowadays. There's no reason to
pretend we're going to support others. Remove the abstraction layer that
allows users to select different backends and merge
'cinder.db.sqlalchemy.api' into 'cinder.db.api'. References to the older
module were replaced like so:

  $ cd cinder
  $ find cinder -type f -name '*.py' \
      -exec sed -i 's/\<db\>\.sqlalchemy/db/g' {} \;

After this, three files needed single line changes to fix import
ordering:

  cinder/cmd/manage.py
  cinder/tests/unit/test.py
  cinder/tests/unit/db/test_migration.py

Note that git can get confused here and not realize that we're deleting
'cinder/db/api.py' and then renaming 'cinder/db/sqlalchemy/api.py' to
'cinder/db/api.py' with some changes. You can view the actual diff to
the latter by running the following with this commit checked out:

  git show HEAD~:cinder/db/sqlalchemy/api.py > api-old.py
  git show HEAD:cinder/db/api.py > api-new.py
  diff api-old.py api-new.py

There's probably a nicer way to do this :)

Change-Id: Idbf8f11677872b27c91700544dfd238387cd0665
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/813229/17 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/api/v3/test_volumes.py', 'cinder/tests/unit/test_db_api.py', 'cinder/tests/unit/group/test_groups_api.py', 'cinder/tests/unit/objects/test_base.py', 'cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/tests/unit/db/test_cluster.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/objects/test_group_snapshot.py', 'cinder/cmd/manage.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/unit/scheduler/test_allocated_capacity_weigher.py', 'cinder/tests/unit/objects/test_group_type.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/group/test_groups_manager.py', 'cinder/tests/unit/fake_service.py', 'cinder/tests/unit/api/v3/test_snapshot_metadata.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/attachments/test_attachments_manager.py', 'cinder/tests/unit/fake_cluster.py', 'cinder/db/migration.py', 'cinder/tests/unit/objects/test_qos.py', 'cinder/tests/unit/volume/test_connection.py', 'cinder/tests/unit/api/contrib/test_snapshot_manage.py', 'cinder/tests/unit/test_paginate_query.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/interface/volume_consistencygroup_driver.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/db/api.py', 'cinder/tests/unit/volume/drivers/test_lvm_driver.py', 'cinder/tests/unit/image/test_cache.py', 'cinder/tests/unit/objects/test_service.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/test_db_worker_api.py', 'cinder/tests/unit/scheduler/test_volume_number_weigher.py', 'cinder/volume/volume_utils.py', 'cinder/api/contrib/quota_classes.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/volume/flows/test_manage_snapshot_flow.py', 'cinder/tests/unit/volume/test_volume_migration.py', 'cinder/tests/unit/api/contrib/test_volume_manage.py', 'cinder/tests/unit/db/test_migration.py', 'cinder/tests/unit/objects/test_group.py', 'cinder/tests/unit/volume/drivers/dell_emc/powerflex/test_create_snapshot.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/api/v3/test_cluster.py', 'cinder/tests/unit/volume/drivers/test_spdk.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/tests/unit/cmd/test_status.py', 'cinder/tests/unit/objects/test_cluster.py', 'cinder/tests/unit/api/v3/test_snapshots.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_iscsi.py', 'cinder/volume/driver.py', 'cinder/db/models.py', 'cinder/db/sqlalchemy/__init__.py', 'cinder/tests/unit/test.py', 'doc/source/contributor/api_conditional_updates.rst', 'cinder/db/migrations/env.py', 'cinder/tests/unit/test_service.py', 'cinder/tests/unit/db/test_migrations.py', 'cinder/tests/unit/db/test_orm_relationships.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py']",77,9e9cbcb59a98f9c830c92a48f7a32356285d480d,remove-legacyfacade, @mock.patch('cinder.db.api.service_get_all'), @mock.patch('cinder.db.sqlalchemy.api.service_get_all'),7134,8925
openstack%2Freleases~master~I75328f25ff355f05b1bd16a977af76bae87c9441,openstack/releases,master,I75328f25ff355f05b1bd16a977af76bae87c9441,Release hacking 6.0.0,MERGED,2023-04-17 22:20:52.000000000,2023-04-19 08:00:15.000000000,2023-04-19 08:00:15.000000000,"[{'_account_id': 308}, {'_account_id': 13252}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-17 22:20:52.000000000', 'files': ['deliverables/_independent/hacking.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/cdf67ff86260f32af5213ed688bb8db314949241', 'message': 'Release hacking 6.0.0\n\nhacking is moved to flake8 version 4 to 5 so bumping the\nmajor version for hacking also.\n\nChange-Id: I75328f25ff355f05b1bd16a977af76bae87c9441\n'}]",1,880686,cdf67ff86260f32af5213ed688bb8db314949241,10,5,1,8556,,,0,"Release hacking 6.0.0

hacking is moved to flake8 version 4 to 5 so bumping the
major version for hacking also.

Change-Id: I75328f25ff355f05b1bd16a977af76bae87c9441
",git fetch https://review.opendev.org/openstack/releases refs/changes/86/880686/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/hacking.yaml'],1,cdf67ff86260f32af5213ed688bb8db314949241,, - version: 6.0.0 projects: - repo: openstack/hacking hash: 3fde1e570a064ce38e7c512b16610ff4650426c3,,4,0
openstack%2Freleases~master~Ia196021dcd624efcda639c0d9dd954dbdc2768c6,openstack/releases,master,Ia196021dcd624efcda639c0d9dd954dbdc2768c6,Tag final kolla stable/xena releases,MERGED,2023-04-14 08:00:26.000000000,2023-04-19 07:52:09.000000000,2023-04-19 07:52:09.000000000,"[{'_account_id': 308}, {'_account_id': 14826}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 08:00:26.000000000', 'files': ['deliverables/xena/kolla.yaml', 'deliverables/xena/kayobe.yaml', 'deliverables/xena/kolla-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f1f4fdcce8c5beb223806087d82b173089a3d420', 'message': 'Tag final kolla stable/xena releases\n\nChange-Id: Ia196021dcd624efcda639c0d9dd954dbdc2768c6\n'}]",0,880458,f1f4fdcce8c5beb223806087d82b173089a3d420,9,5,1,13252,,,0,"Tag final kolla stable/xena releases

Change-Id: Ia196021dcd624efcda639c0d9dd954dbdc2768c6
",git fetch https://review.opendev.org/openstack/releases refs/changes/58/880458/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/kolla.yaml', 'deliverables/xena/kayobe.yaml', 'deliverables/xena/kolla-ansible.yaml']",3,f1f4fdcce8c5beb223806087d82b173089a3d420,kolla-stable-monthly, - version: 13.9.0 projects: - repo: openstack/kolla-ansible hash: 163b4dd25309a05949749a49868bd4fcf1ca6045,,12,0
openstack%2Fcinder~master~I0e6d9606bdee79f1f6ffa741cb9556afb75a8eb4,openstack/cinder,master,I0e6d9606bdee79f1f6ffa741cb9556afb75a8eb4,Remove six from cinder/zonemanager/*,NEW,2023-03-30 16:40:26.000000000,2023-04-19 07:07:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2023-03-30 16:40:26.000000000', 'files': ['cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_san_lookup_service.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_client_cli.py', 'cinder/zonemanager/drivers/brocade/brcd_rest_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/466fd12bc6730a8f420fc2e5249d88d3393a1c72', 'message': 'Remove six from cinder/zonemanager/*\n\nRemove python-six usage here (only ""text_type"" calls).\n\nChange-Id: I0e6d9606bdee79f1f6ffa741cb9556afb75a8eb4\n'}]",2,879062,466fd12bc6730a8f420fc2e5249d88d3393a1c72,32,2,1,4523,,,0,"Remove six from cinder/zonemanager/*

Remove python-six usage here (only ""text_type"" calls).

Change-Id: I0e6d9606bdee79f1f6ffa741cb9556afb75a8eb4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/879062/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_san_lookup_service.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_client_cli.py', 'cinder/zonemanager/drivers/brocade/brcd_rest_fc_zone_client.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py']",8,466fd12bc6730a8f420fc2e5249d88d3393a1c72,," ) % {'cfg_name': cfg_name, 'err': str(e)} ) % {'cfg_name': cfg_name, 'err': str(e)} ) % {'cmd': cmd, 'err': str(e)} ""error=%(err)s)."") % {'cmd': cmd, 'err': str(e)} 'err': str(e)}","import six ) % {'cfg_name': cfg_name, 'err': six.text_type(e)} ) % {'cfg_name': cfg_name, 'err': six.text_type(e)} ) % {'cmd': cmd, 'err': six.text_type(e)} ""error=%(err)s)."") % {'cmd': cmd, 'err': six.text_type(e)} 'err': six.text_type(e)}",53,61
openstack%2Fansible-collections-openstack~master~I142f14dd35720557539b9cf3489a3c12c31f342a,openstack/ansible-collections-openstack,master,I142f14dd35720557539b9cf3489a3c12c31f342a,Publish 2.1.0 release,MERGED,2023-04-18 06:46:25.000000000,2023-04-19 07:01:34.000000000,2023-04-19 07:01:34.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-04-18 06:46:25.000000000', 'files': ['galaxy.yml', 'changelogs/changelog.yaml', 'CHANGELOG.rst'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c30e4db77c4736ad30df054b3167acfa53d4d316', 'message': 'Publish 2.1.0 release\n\nChange-Id: I142f14dd35720557539b9cf3489a3c12c31f342a\n'}]",0,880708,c30e4db77c4736ad30df054b3167acfa53d4d316,12,4,1,32962,,,0,"Publish 2.1.0 release

Change-Id: I142f14dd35720557539b9cf3489a3c12c31f342a
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/08/880708/1 && git format-patch -1 --stdout FETCH_HEAD,"['galaxy.yml', 'changelogs/changelog.yaml', 'CHANGELOG.rst']",3,c30e4db77c4736ad30df054b3167acfa53d4d316,release,v2.1.0 ====== Release Summary --------------- New module for Ironic and bugfixes Minor Changes ------------- - Add baremetal_deploy_template module - Highlight our mode of operation more prominently Bugfixes -------- - Change security group rules only when instructed to do so - Fix for AttributeError: 'dict' object has no attribute 'status' - Fix issue with multiple records in recordset - Fix mistake in compute_flavor_access notes - Fixed private option in inventory plugin - Respect description option and delete security group rules first - Use true and false instead of yes and no for boolean values ,,41,1
openstack%2Fpuppet-openstack-integration~stable%2F2023.1~I79b8603fe61e42d8444dc2fee77725434da9c69c,openstack/puppet-openstack-integration,stable/2023.1,I79b8603fe61e42d8444dc2fee77725434da9c69c,Copy ovn ssl certs and keys to config directories,MERGED,2023-04-12 01:17:27.000000000,2023-04-19 05:48:08.000000000,2023-04-19 05:48:08.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 01:17:27.000000000', 'files': ['manifests/neutron.pp', 'manifests/ovn.pp', 'manifests/octavia.pp', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/03c2460a4ac4f8bafa117610e717383e91c0ee2d', 'message': 'Copy ovn ssl certs and keys to config directories\n\nCurrently some AVC denials are appearing in audit.log, because neutron\nand octavia are not allowed to access to cert/key files in openvswitch\ndirectories. This change ensures these cert/key files are copied to\nindividual config directories.\n\nChange-Id: I79b8603fe61e42d8444dc2fee77725434da9c69c\n(cherry picked from commit a0372071ba61692ddcbccd1b4b86ada25319317c)\n'}]",1,880093,03c2460a4ac4f8bafa117610e717383e91c0ee2d,11,3,1,9816,,,0,"Copy ovn ssl certs and keys to config directories

Currently some AVC denials are appearing in audit.log, because neutron
and octavia are not allowed to access to cert/key files in openvswitch
directories. This change ensures these cert/key files are copied to
individual config directories.

Change-Id: I79b8603fe61e42d8444dc2fee77725434da9c69c
(cherry picked from commit a0372071ba61692ddcbccd1b4b86ada25319317c)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/93/880093/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/neutron.pp', 'manifests/ovn.pp', 'manifests/octavia.pp', 'manifests/config.pp']",4,03c2460a4ac4f8bafa117610e717383e91c0ee2d,ovn-certs," $ovn_proto = 'ssl' $ovn_proto = 'tcp' $ovn_nb_connection = ""${ovn_proto}:${ip_for_url}:6641"" $ovn_sb_connection = ""${ovn_proto}:${ip_for_url}:6642""",,101,57
openstack%2Fproject-config~master~I637351c4b6eecbd2410f8b4752242ed37569c99d,openstack/project-config,master,I637351c4b6eecbd2410f8b4752242ed37569c99d,Add Dell Storage App to StarlingX,MERGED,2023-04-06 14:36:01.000000000,2023-04-19 05:35:48.000000000,2023-04-19 04:49:10.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}, {'_account_id': 28410}]","[{'number': 1, 'created': '2023-04-06 14:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1148639f5c63c8c29e0c12f1cfeac62241937a78', 'message': 'Add Dell Storage App to StarlingX\n\nSigned-off-by: Gustavo Ornaghi Antunes <gustavo.ornaghiantunes@windriver.com>\nChange-Id: I637351c4b6eecbd2410f8b4752242ed37569c99d\n'}, {'number': 2, 'created': '2023-04-06 14:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bb80b526515b2ff770ef489be332786b4477eac4', 'message': 'Add Dell Storage App to StarlingX\n\nSigned-off-by: Gustavo Ornaghi Antunes <gustavo.ornaghiantunes@windriver.com>\nChange-Id: I637351c4b6eecbd2410f8b4752242ed37569c99d\n'}, {'number': 3, 'created': '2023-04-06 14:56:00.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml', 'gerrit/acls/starlingx/app-dell-storage.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1ffe5cb208338fe5fc4d3eba8c680f6789b2265d', 'message': 'Add Dell Storage App to StarlingX\n\nStory: 2010693\nTask: 47801\n\nSigned-off-by: Gustavo Ornaghi Antunes <gustavo.ornaghiantunes@windriver.com>\nChange-Id: I637351c4b6eecbd2410f8b4752242ed37569c99d\n'}]",0,879744,1ffe5cb208338fe5fc4d3eba8c680f6789b2265d,13,4,3,35114,,,0,"Add Dell Storage App to StarlingX

Story: 2010693
Task: 47801

Signed-off-by: Gustavo Ornaghi Antunes <gustavo.ornaghiantunes@windriver.com>
Change-Id: I637351c4b6eecbd2410f8b4752242ed37569c99d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/879744/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/main.yaml', 'gerrit/acls/starlingx/app-dell-storage.config']",3,1148639f5c63c8c29e0c12f1cfeac62241937a78,,"[access ""refs/for/refs/*""] pushMerge = group starlingx-release [access ""refs/heads/*""] abandon = group starlingx-app-dell-storage-core create = group starlingx-release label-Code-Review = -2..+2 group starlingx-app-dell-storage-core label-Workflow = -1..+1 group starlingx-app-dell-storage-core [access ""refs/tags/*""] createSignedTag = group starlingx-release [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = True ",,24,0
openstack%2Fproject-config~master~I778b99d65a1a97926c009dbfec4963e73795325e,openstack/project-config,master,I778b99d65a1a97926c009dbfec4963e73795325e,Add TC repos in gerritbot,MERGED,2023-04-12 19:29:08.000000000,2023-04-19 05:03:54.000000000,2023-04-19 04:46:00.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 19:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2ffe07391feeaef3e9b2c140f971905216e47354', 'message': 'Add TC repos in gerritbot\n\nWe have more repo owned under TC now and having\nthem in gerritbot will help to keep those repo review\nupto date.\n\n- https://github.com/openstack/governance/blob/master/reference/technical-committee-repos.yaml\n\nChange-Id: I778b99d65a1a97926c009dbfec4963e73795325e\n'}, {'number': 2, 'created': '2023-04-12 19:51:21.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/45c5dd1949a6626fc79cb69d1fc269d555907275', 'message': 'Add TC repos in gerritbot\n\nWe have more repo owned under TC now and having\nthem in gerritbot will help to keep those repo review\nupto date.\n\n- https://github.com/openstack/governance/blob/master/reference/technical-committee-repos.yaml\n\nChange-Id: I778b99d65a1a97926c009dbfec4963e73795325e\n'}]",3,880235,45c5dd1949a6626fc79cb69d1fc269d555907275,12,4,2,8556,,,0,"Add TC repos in gerritbot

We have more repo owned under TC now and having
them in gerritbot will help to keep those repo review
upto date.

- https://github.com/openstack/governance/blob/master/reference/technical-committee-repos.yaml

Change-Id: I778b99d65a1a97926c009dbfec4963e73795325e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/880235/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,2ffe07391feeaef3e9b2c140f971905216e47354,, - openstack/api-site - openstack/goal-tools - openstack/openstack - openstack/openstack-manuals - openstack/service-types-authority,,5,0
openstack%2Fpuppet-openstack-integration~master~I8a5955d34615da67ca6f09d009fca5af2a026de0,openstack/puppet-openstack-integration,master,I8a5955d34615da67ca6f09d009fca5af2a026de0,dnm: testing ...,ABANDONED,2023-03-28 03:08:05.000000000,2023-04-19 04:15:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-28 03:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/3c23042885319ade8a94576eac5f00cb366b99e0', 'message': 'dnm: testing ...\n\nChange-Id: I8a5955d34615da67ca6f09d009fca5af2a026de0\n'}, {'number': 2, 'created': '2023-03-28 07:28:02.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c5af7ff9bffce1a0e88d4b64a4428c4883fed8e3', 'message': 'dnm: testing ...\n\nChange-Id: I8a5955d34615da67ca6f09d009fca5af2a026de0\n'}]",0,878735,c5af7ff9bffce1a0e88d4b64a4428c4883fed8e3,5,1,2,9816,,,0,"dnm: testing ...

Change-Id: I8a5955d34615da67ca6f09d009fca5af2a026de0
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/35/878735/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,3c23042885319ade8a94576eac5f00cb366b99e0,,$tempest_binary run --list-tests --include-list=/tmp/openstack/tempest/test-include-list.txt,$tempest_binary run -l --include-list=/tmp/openstack/tempest/test-include-list.txt,1,1
openstack%2Fcinder~master~I2735d902af256f979fc75a697f605b7a8ae65178,openstack/cinder,master,I2735d902af256f979fc75a697f605b7a8ae65178,Hitachi: Fix key error when backend is down,MERGED,2023-01-30 09:57:06.000000000,2023-04-19 01:36:49.000000000,2023-03-03 17:14:54.000000000,"[{'_account_id': 597}, {'_account_id': 5314}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 28403}]","[{'number': 1, 'created': '2023-01-30 09:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94e177ad0a1cf958fc81203a83b8c4555e54ddd9', 'message': 'Hitachi: Fix key error when backend is down\n\nThis patch is to fix the cause of key error in cinder scheduler\nwhen a backend is down.\nThis patch can fix the bug in OEM drivers.\n\nCloses-Bug: #2004140\nChange-Id: I2735d902af256f979fc75a697f605b7a8ae65178\n'}, {'number': 2, 'created': '2023-01-31 10:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/826164fdb0e75864f1192d82b706367a6076bb17', 'message': 'Hitachi: Fix key error when backend is down\n\nThis patch is to fix the cause of key error in cinder scheduler when a backend is down.\nThis patch can fix the bug in OEM drivers.\n\nCloses-Bug: #2004140\nChange-Id: I2735d902af256f979fc75a697f605b7a8ae65178\n'}, {'number': 3, 'created': '2023-02-03 08:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/23dbdaaca1be27d4a672d418d8de76bcb8a62330', 'message': 'Hitachi: Fix key error when backend is down\n\nThis patch is to fix the cause of key error in cinder scheduler\nwhen a backend is down.\nThis patch can fix the bug in OEM drivers.\n\nCloses-Bug: #2004140\nChange-Id: I2735d902af256f979fc75a697f605b7a8ae65178\n'}, {'number': 4, 'created': '2023-02-27 04:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed5073b1ffc188c4a65bcecf77d6c2e8d3c128ac', 'message': 'Hitachi: Fix key error when backend is down\n\nThis patch is to fix the cause of key error in cinder scheduler\nwhen a backend is down.\nThis patch can fix the bug in OEM drivers.\n\nCloses-Bug: #2004140\nChange-Id: I2735d902af256f979fc75a697f605b7a8ae65178\n'}, {'number': 5, 'created': '2023-03-02 13:30:16.000000000', 'files': ['cinder/volume/drivers/hitachi/hbsd_iscsi.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'releasenotes/notes/hitachi-vsp-fix-keyerr-when-backend-down-a5a35b15dc8f1132.yaml', 'cinder/volume/drivers/hitachi/hbsd_utils.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3eb8bb739b3ea2a44d2a847d4c0f77233f7317eb', 'message': 'Hitachi: Fix key error when backend is down\n\nThis patch is to fix the cause of key error in cinder scheduler\nwhen a backend is down.\nThis patch can fix the bug in OEM drivers.\n\nCloses-Bug: #2004140\nChange-Id: I2735d902af256f979fc75a697f605b7a8ae65178\n'}]",22,871269,3eb8bb739b3ea2a44d2a847d4c0f77233f7317eb,172,6,5,33473,,,0,"Hitachi: Fix key error when backend is down

This patch is to fix the cause of key error in cinder scheduler
when a backend is down.
This patch can fix the bug in OEM drivers.

Closes-Bug: #2004140
Change-Id: I2735d902af256f979fc75a697f605b7a8ae65178
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/871269/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/hitachi-vsp-fix-keyerr-when-backend-down-a5a35b15dc8f1132.yaml', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_common.py']",3,94e177ad0a1cf958fc81203a83b8c4555e54ddd9,bug/2004140,"# Copyright (C) 2020, 2023, Hitachi, Ltd. cfg.StrOpt( default=None, help='Pool number or pool name of the DP pool.'), def create_ldev(self, size): try: ldev = self.create_ldev(volume['size']) def _copy_on_storage(self, pvol, size, is_snapshot=False): svol = self.create_ldev(size) try: self.create_pair_on_storage(pvol, svol, is_snapshot) new_ldev = self._copy_on_storage(ldev, size) new_ldev = self._copy_on_storage(ldev, size, True) def get_pool_info(self): single_pool = {} single_pool.update(dict( pool_name=data['volume_backend_name'], reserved_percentage=self.conf.safe_get('reserved_percentage'), QoS_support=False, thin_provisioning_support=True, thick_provisioning_support=False, multiattach=True, consistencygroup_support=True, consistent_group_snapshot_enabled=True, max_over_subscription_ratio=( volume_utils.get_max_over_subscription_ratio( self.conf.safe_get('max_over_subscription_ratio'), True)), )) try: (total_capacity, free_capacity, provisioned_capacity) = self.get_pool_info() except exception.VolumeDriverException: single_pool.update(dict( total_capacity_gb=0, free_capacity_gb=0, provisioned_capacity_gb=0, backend_state='down')) data[""pools""].append(single_pool) LOG.debug(""Updating volume status. (%s)"", data) utils.output_log( MSG.POOL_INFO_RETRIEVAL_FAILED, pool=self.conf.hitachi_pool) return data single_pool.update(dict( total_capacity_gb=total_capacity, free_capacity_gb=free_capacity, provisioned_capacity_gb=provisioned_capacity, )) single_pool.update(dict(backend_state='up')) data[""pools""].append(single_pool)","# Copyright (C) 2020, 2022, Hitachi, Ltd. cfg.ListOpt( default=[], help='Pool number[s] or pool name[s] of the DP pool.'), def get_pool_id_of_volume(self, volume): pools = self._stats['pools'] if len(pools) == 1: return pools[0]['location_info']['pool_id'] pool_name = volume_utils.extract_host(volume['host'], 'pool') for pool in pools: if pool['pool_name'] == pool_name: return pool['location_info']['pool_id'] return None def create_ldev(self, size, pool_id): pool_id = self.get_pool_id_of_volume(volume) try: ldev = self.create_ldev(volume['size'], pool_id) def _copy_on_storage( self, pvol, size, pool_id, is_snapshot=False): svol = self.create_ldev(size, pool_id) try: self.create_pair_on_storage(pvol, svol, is_snapshot=is_snapshot) pool_id = self.get_pool_id_of_volume(volume) new_ldev = self._copy_on_storage(ldev, size, pool_id) pool_id = self.get_pool_id_of_volume(snapshot['volume']) new_ldev = self._copy_on_storage( ldev, size, pool_id, is_snapshot=True) def get_pool_info(self, pool_id, result=None): def get_pool_infos(self, pool_ids): """"""Return the total and free capacity of the storage pools."""""" raise NotImplementedError() def _create_single_pool_data(self, pool_id, pool_name, cap_data): location_info = { 'storage_id': self.conf.hitachi_storage_id, 'pool_id': pool_id, 'snap_pool_id': self.storage_info['snap_pool_id'], 'ldev_range': self.storage_info['ldev_range']} single_pool = {} single_pool.update(dict( pool_name=pool_name, reserved_percentage=self.conf.safe_get('reserved_percentage'), QoS_support=False, thick_provisioning_support=False, multiattach=True, consistencygroup_support=True, consistent_group_snapshot_enabled=True, location_info=location_info )) if cap_data is None: single_pool.update(dict( provisioned_capacity_gb=0, backend_state='down')) utils.output_log(MSG.POOL_INFO_RETRIEVAL_FAILED, pool=pool_name) return single_pool total_capacity, free_capacity, provisioned_capacity = cap_data single_pool.update(dict( total_capacity_gb=total_capacity, free_capacity_gb=free_capacity, provisioned_capacity_gb=provisioned_capacity, max_over_subscription_ratio=( volume_utils.get_max_over_subscription_ratio( self.conf.safe_get('max_over_subscription_ratio'), True)), thin_provisioning_support=True )) single_pool.update(dict(backend_state='up')) return single_pool for pool_id, pool_name, cap_data in zip( self.storage_info['pool_id'], self.conf.hitachi_pool, self.get_pool_infos(self.storage_info['pool_id'])): single_pool = self._create_single_pool_data( pool_id, pool_name if len(self.conf.hitachi_pool) > 1 else data['volume_backend_name'], cap_data) data['pools'].append(single_pool) self._stats = data for pool in self.conf.hitachi_pool: if len(pool) == 0: msg = utils.output_log( MSG.INVALID_PARAMETER, param=self.driver_info['param_prefix'] + '_pool') self.raise_error(msg)",117,117
openstack%2Fpython-cinderclient~master~Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77,openstack/python-cinderclient,master,Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77,DNM: check functional jobs,ABANDONED,2023-01-04 14:54:03.000000000,2023-04-19 01:10:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-04 14:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/fd954e1438cc2abb0825cf8b396af75af450e842', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 2, 'created': '2023-01-04 15:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2cdb5911e87a6ea0e9e90e6522e7a3f239b6fe5d', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nnew change: Removed the basepython from [testenv] because it looks\nlike that is affecting what python is being installed in the\nfunctional envs.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 3, 'created': '2023-01-04 20:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/65abcefbbd8f41748379568a9c3bfb1de0df0838', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nnew change: Removed the basepython from [testenv] because it looks\nlike that is affecting what python is being installed in the\nfunctional envs.\n\nnewer change: Added explicit base_python to each functional testenv.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 4, 'created': '2023-01-05 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/9cd18b90065007637b354ae5dcc404c3e8a19c54', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 5, 'created': '2023-01-05 22:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a27470aa941c862b55b89031252f48208dd59603', 'message': 'DNM: check functional jobs\n\nWe\'re seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it\'s an occasionaly anomaly or something more\nsinister.\n\nalso:\n- removed usedevelop=true (see comment inline)\n- removed basepython which seems to be causing the ""could not find\n  python interpreter matching any of the specs functional-py39"" error\n  (which I think is independent of the usedevelop issue).\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n'}, {'number': 6, 'created': '2023-01-06 22:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d4c381b3fd30f7e89138a89d826f4f0c24438843', 'message': 'DNM: check functional jobs\n\nWe\'re seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it\'s an occasionaly anomaly or something more\nsinister.\n\nalso:\n- removed basepython which seems to be causing the ""could not find\n  python interpreter matching any of the specs functional-py39"" error\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n'}, {'number': 7, 'created': '2023-01-09 13:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/27b359f8e9ce48039c9179439ab775c1c085a52e', 'message': 'DNM: check functional jobs\n\nWe\'re seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it\'s an occasionaly anomaly or something more\nsinister.\n\nalso:\n- removed basepython which seems to be causing the ""could not find\n  python interpreter matching any of the specs functional-py39"" error\n- but no basepython seems to cause the functional-py38 job to time out\n  in zuul, so setting it explicitly for that testenv\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n'}, {'number': 8, 'created': '2023-01-11 17:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/411796321bf089b9e8cc030b4e7838c2c8f5863c', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 9, 'created': '2023-02-16 01:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/c669b88df55fb3c850129d187268b6cdf1549f43', 'message': ""DNM: check functional jobs\n\nWe're seeing a weird pause in the functional-py38 job.  This patch\nruns *only* the functional-py38 and -py39 jobs so we can get quicker\nresults to see if it's an occasionaly anomaly or something more\nsinister.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n""}, {'number': 10, 'created': '2023-04-17 22:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/591f75e725d3cdc31a2f7f3777a7e604128d33ea', 'message': 'DNM: check functional jobs\n\nFor a while, we were seeing weird pauses in some functional\njobs.  This patch runs *only* the functional jobs we should\nbe interested in for 2023.2, namely functional-py39 and\nfunctional-py310.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n'}, {'number': 11, 'created': '2023-04-17 23:04:09.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/3742c7cb3efbf5b806f155edd0708c08e4875b8b', 'message': 'DNM: check functional jobs\n\nFor a while, we were seeing weird pauses in some functional\njobs.  This patch runs *only* the functional jobs we should\nbe interested in for 2023.2, namely functional-py39 and\nfunctional-py310.\n\nChange-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77\n'}]",5,869226,3742c7cb3efbf5b806f155edd0708c08e4875b8b,32,1,11,5314,,,0,"DNM: check functional jobs

For a while, we were seeing weird pauses in some functional
jobs.  This patch runs *only* the functional jobs we should
be interested in for 2023.2, namely functional-py39 and
functional-py310.

Change-Id: Ie22ed07a8fd848204fcca8f6dc42dfd321bd1f77
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/26/869226/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,fd954e1438cc2abb0825cf8b396af75af450e842,check-func-jobs,, templates: - check-requirements - lib-forward-testing-python3 - openstack-cover-jobs - openstack-python3-antelope-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 - openstack-tox-pylint: voting: false,0,9
openstack%2Ftaskflow~master~I048faf06d89ebf980efe0598e647f2ec89f65ada,openstack/taskflow,master,I048faf06d89ebf980efe0598e647f2ec89f65ada,Fix parsing of zookeeper jobboard backend options,MERGED,2022-12-09 07:50:34.000000000,2023-04-19 00:13:03.000000000,2023-04-19 00:11:52.000000000,"[{'_account_id': 9816}, {'_account_id': 11628}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 28619}, {'_account_id': 29244}]","[{'number': 1, 'created': '2022-12-09 07:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1eab7e5186247ef6c1805c47e5eb3b695c7349b3', 'message': 'Fix parsing of zookeeper jobboard backend options\n\nFix the zookeeper backend options when values are passed as strings,\na ""False"" string is now treated as the False boolean.\n\nCloses: #1999174\nChange-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada\n'}, {'number': 2, 'created': '2022-12-09 07:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f67c0be44e3a2243e5d18db9052afb9d85f78a6f', 'message': 'Fix parsing of zookeeper jobboard backend options\n\nFix the zookeeper backend options when values are passed as strings,\na ""False"" string is now treated as the False boolean.\n\nCloses-Bug: #1999174\nChange-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada\n'}, {'number': 3, 'created': '2022-12-12 17:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b0102a6c87487625896ba97503e059740152ed10', 'message': 'Fix parsing of zookeeper jobboard backend options\n\nFix the zookeeper backend options when values are passed as strings,\na ""False"" string is now treated as the False boolean.\n\nCloses-Bug: #1999174\nChange-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada\n'}, {'number': 4, 'created': '2023-01-11 17:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/42942f8b6e0603920de306be3e14d6245e6ab7ac', 'message': 'Fix parsing of zookeeper jobboard backend options\n\nFix the zookeeper backend options when values are passed as strings,\na ""False"" string is now treated as the False boolean.\n\nCloses-Bug: #1999174\nChange-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada\n'}, {'number': 5, 'created': '2023-01-12 08:59:41.000000000', 'files': ['taskflow/persistence/backends/impl_zookeeper.py', 'releasenotes/notes/fix-zookeeper-option-parsing-f9d37fbc39af47f4.yaml', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/test_utils_kazoo_utils.py', 'taskflow/utils/kazoo_utils.py', 'taskflow/tests/unit/jobs/test_zk_job.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/086b3e4335194cbe2bbfcd8c422fa21952124b44', 'message': 'Fix parsing of zookeeper jobboard backend options\n\nFix the zookeeper backend options when values are passed as strings,\na ""False"" string is now treated as the False boolean.\n\nCloses-Bug: #1999174\nChange-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada\n'}]",10,867083,086b3e4335194cbe2bbfcd8c422fa21952124b44,30,7,5,29244,,,0,"Fix parsing of zookeeper jobboard backend options

Fix the zookeeper backend options when values are passed as strings,
a ""False"" string is now treated as the False boolean.

Closes-Bug: #1999174
Change-Id: I048faf06d89ebf980efe0598e647f2ec89f65ada
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/83/867083/5 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-zookeeper-option-parsing-f9d37fbc39af47f4.yaml', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/test_utils_kazoo_utils.py', 'taskflow/utils/kazoo_utils.py', 'taskflow/tests/unit/jobs/test_zk_job.py']",5,1eab7e5186247ef6c1805c47e5eb3b695c7349b3,," def test_connect_check_compatible(self): # Valid version client = fake_client.FakeClient() board = impl_zookeeper.ZookeeperJobBoard( 'test-board', {'check_compatible': True}, client=client) self.addCleanup(board.close) self.addCleanup(self.close_client, client) with base.connect_close(board): pass # Invalid version, no check client = fake_client.FakeClient(server_version=(3, 2, 0)) board = impl_zookeeper.ZookeeperJobBoard( 'test-board', {'check_compatible': False}, client=client) self.addCleanup(board.close) self.addCleanup(self.close_client, client) with base.connect_close(board): pass # Invalid version, check_compatible=True client = fake_client.FakeClient(server_version=(3, 2, 0)) board = impl_zookeeper.ZookeeperJobBoard( 'test-board', {'check_compatible': True}, client=client) self.addCleanup(board.close) self.addCleanup(self.close_client, client) self.assertRaises(excp.IncompatibleVersion, board.connect) # Invalid version, check_compatible='False' client = fake_client.FakeClient(server_version=(3, 2, 0)) board = impl_zookeeper.ZookeeperJobBoard( 'test-board', {'check_compatible': 'False'}, client=client) self.addCleanup(board.close) self.addCleanup(self.close_client, client) with base.connect_close(board): pass",,142,9
openstack%2Ftripleo-ansible~master~I34537db460ff5aaba93da7e104262e26e64cbb1a,openstack/tripleo-ansible,master,I34537db460ff5aaba93da7e104262e26e64cbb1a,Stop using ceph/daemon entrypoint,MERGED,2023-04-13 21:16:03.000000000,2023-04-18 21:58:01.000000000,2023-04-18 21:58:01.000000000,"[{'_account_id': 6796}, {'_account_id': 16643}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 30025}, {'_account_id': 32704}, {'_account_id': 34598}]","[{'number': 1, 'created': '2023-04-13 21:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6e056ac13fc4226067f7072183145e2a823da422', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}, {'number': 2, 'created': '2023-04-13 21:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/62cdfb85a398503694cf1196ab1413678fcd0cf5', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}, {'number': 3, 'created': '2023-04-14 05:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/bdc70a533936d0a46dd6e3660501e945a7839e02', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}, {'number': 4, 'created': '2023-04-16 16:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/62127ce57eb80a942e4eb7ac50d988ab98383734', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}, {'number': 5, 'created': '2023-04-17 07:15:23.000000000', 'files': ['tripleo_ansible/roles/tripleo_cephadm/defaults/main.yml', 'tripleo_ansible/roles/tripleo_cephadm/templates/ceph-nfs.service.j2', 'tripleo_ansible/roles/tripleo_cephadm/tasks/ganesha/distribute_keys.yaml', 'tripleo_ansible/roles/tripleo_cephadm/tasks/nfs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a23795e83bbae8d52d9a47570a74d1e509bdc2f1', 'message': 'Stop using ceph/daemon entrypoint\n\nDue to the recent Ceph 6 (Quincy) container image refactoring,\nthe old entrypoint is no longer available.\nHowever, the ceph-nfs systemd unit should support both Pacific\nand Quincy releases.\nThis patch introduces a task that is able to detect the version\nprovided by the ceph container in the Heat stack and renders the\nsystemd unit accordingly.\n\nChange-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a\n'}]",16,880368,a23795e83bbae8d52d9a47570a74d1e509bdc2f1,27,8,5,25402,,,0,"Stop using ceph/daemon entrypoint

Due to the recent Ceph 6 (Quincy) container image refactoring,
the old entrypoint is no longer available.
However, the ceph-nfs systemd unit should support both Pacific
and Quincy releases.
This patch introduces a task that is able to detect the version
provided by the ceph container in the Heat stack and renders the
systemd unit accordingly.

Change-Id: I34537db460ff5aaba93da7e104262e26e64cbb1a
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/68/880368/5 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_cephadm/templates/ceph-nfs.service.j2', 'tripleo_ansible/roles/tripleo_cephadm/tasks/nfs.yaml']",2,6e056ac13fc4226067f7072183145e2a823da422,ganesha_ceph6,"- name: Get Ceph version command: ""{{ tripleo_cephadm_container_cli }} run --rm --entrypoint=ceph {{ ceph_container }} -v"" register: ceph_version vars: ceph_container: ""{{ tripleo_cephadm_container_ns }}/{{ tripleo_cephadm_container_image }}:{{ tripleo_cephadm_container_tag }}"" tripleo_cephadm_ceph_version: ""{{ ceph_version.stdout.split(' ')[2] }}""",,14,1
openstack%2Fswift~master~Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11,openstack/swift,master,Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11,info: Add support for sha256 and sha512; deprecate sha1,NEW,2022-07-23 04:41:37.000000000,2023-04-18 21:44:33.000000000,,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-23 04:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b2b4d35b59889b148e02e076bd48989919a435fe', 'message': 'info: Add support for sha256 and sha512; deprecate sha1\n\nThis brings it in line with what tempurl and formpost are doing.\n\nChange-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11\n'}, {'number': 2, 'created': '2022-07-30 00:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/663389a60be8af152127a69ef2279ad23063b775', 'message': 'info: Add support for sha256 and sha512; deprecate sha1\n\nThis brings it in line with what tempurl and formpost are doing.\n\nNote that we only consider which digests are allowed if an admin_key is\nset. If it is not, no deprecation warnings will be emitted and no\ninformation about allowed or deprecated digests will be published in\n/info.\n\nChange-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11\n'}, {'number': 3, 'created': '2022-08-05 18:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/46dd3bc62760fc5a307c80e04581ebacc7e960b9', 'message': 'info: Add support for sha256 and sha512; deprecate sha1\n\nThis brings it in line with what tempurl and formpost are doing.\n\nNote that we only consider which digests are allowed if an admin_key is\nset. If it is not, no deprecation warnings will be emitted and no\ninformation about allowed or deprecated digests will be published in\n/info.\n\nChange-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11\n'}, {'number': 4, 'created': '2022-11-10 20:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ff417e2c25ea48926f7c2a6ba8204e50fcd697f2', 'message': 'info: Add support for sha256 and sha512; deprecate sha1\n\nThis brings it in line with what tempurl and formpost are doing.\n\nNote that we only consider which digests are allowed if an admin_key is\nset. If it is not, no deprecation warnings will be emitted and no\ninformation about allowed or deprecated digests will be published in\n/info.\n\nChange-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11\n'}, {'number': 5, 'created': '2023-01-06 23:49:13.000000000', 'files': ['swift/proxy/controllers/info.py', 'test/unit/proxy/controllers/test_info.py', 'test/unit/proxy/test_server.py', 'etc/proxy-server.conf-sample', 'swift/proxy/server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9d78dbad9cf746f8a90ee1f7222668d52a19d826', 'message': 'info: Add support for sha256 and sha512; deprecate sha1\n\nThis brings it in line with what tempurl and formpost are doing.\n\nNote that we only consider which digests are allowed if an admin_key is\nset. If it is not, no deprecation warnings will be emitted and no\ninformation about allowed or deprecated digests will be published in\n/info.\n\nChange-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11\n'}]",14,850787,9d78dbad9cf746f8a90ee1f7222668d52a19d826,21,3,5,15343,,,0,"info: Add support for sha256 and sha512; deprecate sha1

This brings it in line with what tempurl and formpost are doing.

Note that we only consider which digests are allowed if an admin_key is
set. If it is not, no deprecation warnings will be emitted and no
information about allowed or deprecated digests will be published in
/info.

Change-Id: Ic0f573aefd920087c11fcb047bffc3c9c6ee0a11
",git fetch https://review.opendev.org/openstack/swift refs/changes/87/850787/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/proxy/controllers/info.py', 'swift/proxy/server.py']",2,b2b4d35b59889b148e02e076bd48989919a435fe,bug/1733634,"from swift.common.digest import get_allowed_digests self.allowed_digests, deprecated_digests = get_allowed_digests( conf, self.logger) info_dict = dict( info_allowed_digests=sorted(self.allowed_digests), if deprecated_digests: info_dict['info_deprecated_digests'] = sorted(deprecated_digests) register_swift_info(**info_dict)", register_swift_info(,19,4
openstack%2Fopenstack-ansible~master~Ibb9dc3377a4de06af25281bf777b16faad16d261,openstack/openstack-ansible,master,Ibb9dc3377a4de06af25281bf777b16faad16d261,Gather generic masakari facts,MERGED,2023-04-14 08:16:38.000000000,2023-04-18 20:42:58.000000000,2023-04-18 20:41:40.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 08:16:38.000000000', 'files': ['playbooks/os-masakari-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bb4f1c7b2a46b30de8bca3e695938022efe6be89', 'message': 'Gather generic masakari facts\n\nWith commit [1] we moved extra facts gathering to pre_tasks\nbut with that we did not enable generic facts gathering, which\nled to regression. So we cover this by ensuring that generic\nfacts are also gathered and not only extra ones.\n\n[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833\nCloses-Bug: #1979145\n\nChange-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261\n'}]",0,880459,bb4f1c7b2a46b30de8bca3e695938022efe6be89,9,4,1,28619,,,0,"Gather generic masakari facts

With commit [1] we moved extra facts gathering to pre_tasks
but with that we did not enable generic facts gathering, which
led to regression. So we cover this by ensuring that generic
facts are also gathered and not only extra ones.

[1] https://opendev.org/openstack/openstack-ansible/commit/8bc9b167ab9a4854aab5d49a10709c27e96ff833
Closes-Bug: #1979145

Change-Id: Ibb9dc3377a4de06af25281bf777b16faad16d261
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/59/880459/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-masakari-install.yml'],1,bb4f1c7b2a46b30de8bca3e695938022efe6be89,,"- name: Gather masakari facts hosts: masakari_all gather_facts: ""{{ osa_gather_facts | default(True) }}"" tags: - always ",,6,0
openstack%2Fopenstack-ansible-os_masakari~master~Ife81410d59e8a646aab741bc1a5ef01784bf13b0,openstack/openstack-ansible-os_masakari,master,Ife81410d59e8a646aab741bc1a5ef01784bf13b0,Drop apt_package_pinning from role requirements,MERGED,2023-04-13 19:32:32.000000000,2023-04-18 20:40:56.000000000,2023-04-18 20:39:46.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-13 19:32:32.000000000', 'files': ['tests/ansible-role-requirements.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/7582a277616d834ff08dbbaf0f54b99b725c8d74', 'message': ""Drop apt_package_pinning from role requirements\n\nWe don't pin packages in masakari role, so dependency on\napt_package_pinning role can be safely removed.\n\nChange-Id: Ife81410d59e8a646aab741bc1a5ef01784bf13b0\nRelated-Bug: #1979145\n""}]",0,880360,7582a277616d834ff08dbbaf0f54b99b725c8d74,9,4,1,28619,,,0,"Drop apt_package_pinning from role requirements

We don't pin packages in masakari role, so dependency on
apt_package_pinning role can be safely removed.

Change-Id: Ife81410d59e8a646aab741bc1a5ef01784bf13b0
Related-Bug: #1979145
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/60/880360/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'meta/main.yml']",2,7582a277616d834ff08dbbaf0f54b99b725c8d74,,dependencies: [],dependencies: - role: apt_package_pinning when: - ansible_facts['pkg_mgr'] == 'apt',1,8
openstack%2Foctavia~master~Ibeb9132e65706b50706249df3e8b6c455863513c,openstack/octavia,master,Ibeb9132e65706b50706249df3e8b6c455863513c,Remove specific handling of amphorav1 parameters,MERGED,2023-03-02 06:55:26.000000000,2023-04-18 20:39:01.000000000,2023-04-18 20:37:36.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-03-02 06:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/da21de58f59c99137118932644ed97a1ae83f2d1', 'message': 'Remove specific handling of amphorav1 parameters\n\nSome functions in the drivers accepted 2 different types for the same\nparameters: provider dict or provider data models.\nNow that amphorav1 is removed, we can remove the cases that handle both\ntypes.\n\nChange-Id: Ibeb9132e65706b50706249df3e8b6c455863513c\n'}, {'number': 2, 'created': '2023-03-02 17:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c84e1a89622b63af6d9d227e0226be5f8d66d7cc', 'message': 'Remove specific handling of amphorav1 parameters\n\nSome functions in the drivers accepted 2 different types for the same\nparameters: provider dict or provider data models.\nNow that amphorav1 is removed, we can remove the cases that handle both\ntypes.\n\nChange-Id: Ibeb9132e65706b50706249df3e8b6c455863513c\n'}, {'number': 3, 'created': '2023-03-29 07:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/43d43860201702f8cb2ac2cdb76aca857edcc0d1', 'message': 'Remove specific handling of amphorav1 parameters\n\nSome functions in the drivers accepted 2 different types for the same\nparameters: provider dict or provider data models.\nNow that amphorav1 is removed, we can remove the cases that handle both\ntypes.\n\nChange-Id: Ibeb9132e65706b50706249df3e8b6c455863513c\n'}, {'number': 4, 'created': '2023-04-05 15:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/78ef74155bc0451770500340adea42eef6fe3198', 'message': 'Remove specific handling of amphorav1 parameters\n\nSome functions in the drivers accepted 2 different types for the same\nparameters: provider dict or provider data models.\nNow that amphorav1 is removed, we can remove the cases that handle both\ntypes.\n\nChange-Id: Ibeb9132e65706b50706249df3e8b6c455863513c\n'}, {'number': 5, 'created': '2023-04-07 08:28:32.000000000', 'files': ['octavia/tests/unit/amphorae/drivers/keepalived/jinja/test_jinja_cfg.py', 'octavia/controller/worker/v2/tasks/amphora_driver_tasks.py', 'octavia/amphorae/drivers/keepalived/jinja/jinja_cfg.py', 'octavia/amphorae/drivers/haproxy/rest_api_driver.py', 'octavia/tests/unit/amphorae/drivers/noop_driver/test_driver.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_amphora_driver_tasks.py', 'octavia/amphorae/drivers/noop_driver/driver.py', 'octavia/amphorae/drivers/driver_base.py', 'octavia/tests/unit/amphorae/drivers/haproxy/test_rest_api_driver_1_0.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/324c3528ec7726fb6c69f70473b75b14357ff14a', 'message': 'Remove specific handling of amphorav1 parameters\n\nSome functions in the drivers accepted 2 different types for the same\nparameters: provider dict or provider data models.\nNow that amphorav1 is removed, we can remove the cases that handle both\ntypes.\n\nChange-Id: Ibeb9132e65706b50706249df3e8b6c455863513c\n'}]",7,876035,324c3528ec7726fb6c69f70473b75b14357ff14a,26,3,5,29244,,,0,"Remove specific handling of amphorav1 parameters

Some functions in the drivers accepted 2 different types for the same
parameters: provider dict or provider data models.
Now that amphorav1 is removed, we can remove the cases that handle both
types.

Change-Id: Ibeb9132e65706b50706249df3e8b6c455863513c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/35/876035/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/amphorae/drivers/keepalived/jinja/test_jinja_cfg.py', 'octavia/amphorae/drivers/keepalived/jinja/jinja_cfg.py', 'octavia/amphorae/drivers/haproxy/rest_api_driver.py', 'octavia/tests/unit/amphorae/drivers/haproxy/test_rest_api_driver_1_0.py']",4,da21de58f59c99137118932644ed97a1ae83f2d1,amphorav1-removal," host_routes=[])).to_dict(recurse=True) vip_subnet = mock.MagicMock() vip_subnet.cidr = FAKE_CIDR vip_subnet.gateway_ip = FAKE_GATEWAY vip_subnet.host_routes = self.host_routes vip_subnet.to_dict.return_value = { amphorae_network_config = mock.MagicMock() amphorae_network_config.get().vip_subnet = vip_subnet self.driver.post_vip_plug(self.amp, self.lb, amphorae_network_config, vrrp_port=self.port, vip_subnet=vip_subnet, additional_vip_data=[]) vip_subnet = mock.MagicMock() vip_subnet.cidr = FAKE_CIDR vip_subnet.gateway_ip = FAKE_GATEWAY vip_subnet.host_routes = self.host_routes vip_subnet.to_dict.return_value = { amphorae_network_config = mock.MagicMock() amphorae_network_config.get().vip_subnet = vip_subnet vip1_subnet = mock.MagicMock() vip1_subnet.cidr = mock.Mock() vip1_subnet.gateway_ip = mock.Mock() vip1_subnet.host_routes = self.host_routes vip1_subnet.to_dict.return_value = { 'cidr': vip1_subnet.cidr, 'gateway_ip': vip1_subnet.gateway_ip, 'host_routes': [ hr.to_dict(recurse=True) for hr in self.host_routes] } additional_vip1.subnet = vip1_subnet self.driver.post_vip_plug( self.amp, self.lb, amphorae_network_config, vrrp_port=self.port, vip_subnet=vip_subnet, additional_vip_data=additional_vip_data)"," host_routes=[])) amphorae_network_config = mock.MagicMock() amphorae_network_config.get().vip_subnet.cidr = FAKE_CIDR amphorae_network_config.get().vip_subnet.gateway_ip = FAKE_GATEWAY amphorae_network_config.get().vip_subnet.host_routes = self.host_routes amphorae_network_config.get().vip_subnet.to_dict.return_value = { self.driver.post_vip_plug(self.amp, self.lb, amphorae_network_config) amphorae_network_config = mock.MagicMock() amphorae_network_config.get().vip_subnet.cidr = FAKE_CIDR amphorae_network_config.get().vip_subnet.gateway_ip = FAKE_GATEWAY amphorae_network_config.get().vip_subnet.host_routes = self.host_routes amphorae_network_config.get().vip_subnet.to_dict.return_value = { additional_vip1.subnet.cidr = mock.Mock() additional_vip1.subnet.gateway_ip = mock.Mock() additional_vip1.subnet.host_routes = self.host_routes self.driver.post_vip_plug(self.amp, self.lb, amphorae_network_config, additional_vip_data=additional_vip_data)",49,49
openstack%2Fkolla-ansible~master~Ia056aa40e996b1f0fed43c0f672466c7e4a2f547,openstack/kolla-ansible,master,Ia056aa40e996b1f0fed43c0f672466c7e4a2f547,Remove RabbitMQ ha-all policy when not required,MERGED,2023-03-02 10:03:24.000000000,2023-04-18 20:25:56.000000000,2023-04-18 20:24:54.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-03-02 10:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e5c0fe4bfa8d5573e0c4346825b7f2775c96a538', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. The `ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n'}, {'number': 2, 'created': '2023-03-13 14:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/58c7a276789c3e7ff9efced203353c680b843517', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. It is also now used in the deploy task. The\n`ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n'}, {'number': 3, 'created': '2023-03-14 10:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e9087eab9220b1169215fab80dd75bea61a7ad21', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. It is also now used in the deploy task. The\n`ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n'}, {'number': 4, 'created': '2023-04-13 13:58:25.000000000', 'files': ['ansible/roles/rabbitmq/tasks/upgrade.yml', 'ansible/roles/rabbitmq/tasks/deploy.yml', 'releasenotes/notes/rabbitmq-remove-ha-all-policy-when-not-required-81dcf64542c4805f.yaml', 'ansible/roles/rabbitmq/tasks/remove-ha-all-policy.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c85b64d1589a515da2f3cf2dcc082d15df1d6edd', 'message': 'Remove RabbitMQ ha-all policy when not required\n\nWith the addition of the variable\n`om_enable_rabbitmq_high_availability`, this feature in the upgrade\ntask should be brought back. It is also now used in the deploy task. The\n`ha-all` policy is cleared only when\n`om_enable_rabbitmq_high_availability` is set to `false`.\n\nChange-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547\n'}]",6,876053,c85b64d1589a515da2f3cf2dcc082d15df1d6edd,25,3,4,35263,,,0,"Remove RabbitMQ ha-all policy when not required

With the addition of the variable
`om_enable_rabbitmq_high_availability`, this feature in the upgrade
task should be brought back. It is also now used in the deploy task. The
`ha-all` policy is cleared only when
`om_enable_rabbitmq_high_availability` is set to `false`.

Change-Id: Ia056aa40e996b1f0fed43c0f672466c7e4a2f547
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/53/876053/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/tasks/upgrade.yml', 'releasenotes/notes/rabbitmq-remove-ha-all-policy-when-not-required-81dcf64542c4805f.yaml']",2,e5c0fe4bfa8d5573e0c4346825b7f2775c96a538,remove-ha-all-when-not-required,"--- fixes: - | When upgrading RabbitMQ, the policy `ha-all` is cleared if `om_enable_rabbitmq_high_availability` is set to `false`. ",,28,0
openstack%2Fcharm-octavia~stable%2Fzed~I2cae5f0e307c8cd14f1831f3416d890ad604b705,openstack/charm-octavia,stable/zed,I2cae5f0e307c8cd14f1831f3416d890ad604b705,Wait for management interface IP to be assigned,NEW,2023-01-11 05:22:44.000000000,2023-04-18 19:31:02.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-11 05:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/b5128d53a81b2b3cc803b2544f06c41d23a7f1bb', 'message': ""Wait for management interface IP to be assigned\n\nThere can be a delay between the interface being created,\nand an IP address getting assigned,\nwhich previously caused a race condition where\nthe config could be rendered before the IP address was ready\nresulting in the health manager bind_ip to be empty.\n\nThis ensures that the IP address will be ready before continuing,\nwhich will ensure that the config rendering will not happen until ready,\nand the configure-resources action will only return once it's all done.\n\nCloses-Bug: #1961088\nChange-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705\n""}, {'number': 2, 'created': '2023-01-11 05:23:02.000000000', 'files': ['src/lib/charm/openstack/octavia.py', 'unit_tests/test_lib_charm_openstack_api_crud.py', 'src/reactive/octavia_handlers.py', 'unit_tests/test_lib_charm_openstack_octavia.py', 'src/lib/charm/openstack/api_crud.py'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/72d372e257dc40f681cde540f7d504b74c9950de', 'message': ""Wait for management interface IP to be assigned\n\nThere can be a delay between the interface being created,\nand an IP address getting assigned,\nwhich previously caused a race condition where\nthe config could be rendered before the IP address was ready\nresulting in the health manager bind_ip to be empty.\n\nThis ensures that the IP address will be ready before continuing,\nwhich will ensure that the config rendering will not happen until ready,\nand the configure-resources action will only return once it's all done.\n\nCloses-Bug: #1961088\nChange-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705\n""}]",3,869646,72d372e257dc40f681cde540f7d504b74c9950de,10,2,2,8108,,,0,"Wait for management interface IP to be assigned

There can be a delay between the interface being created,
and an IP address getting assigned,
which previously caused a race condition where
the config could be rendered before the IP address was ready
resulting in the health manager bind_ip to be empty.

This ensures that the IP address will be ready before continuing,
which will ensure that the config rendering will not happen until ready,
and the configure-resources action will only return once it's all done.

Closes-Bug: #1961088
Change-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/46/869646/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/octavia.py', 'src/reactive/octavia_handlers.py', 'unit_tests/test_lib_charm_openstack_api_crud.py', 'unit_tests/test_lib_charm_openstack_octavia.py', 'src/lib/charm/openstack/api_crud.py']",5,b5128d53a81b2b3cc803b2544f06c41d23a7f1bb,fix-health-bind-ip-stable/zed,"import timeclass NoMgmtInterface(Exception): """"""Exception raised when no mgmt interface could not be found."""""" def wait_for_address_on_mgmt_interface(): """""" Poll for an address on the management interface. :returns: True if an address was found before timing out :rtype: bool """""" for _ in range(90): ch_core.hookenv.log('polling for address on mgmt interface', level=ch_core.hookenv.DEBUG) if octavia.get_address_on_mgmt_interface(): ch_core.hookenv.log( 'address found on mgmt interface', level=ch_core.hookenv.INFO ) return True time.sleep(10) # 90 * 10 = 15 minutes ch_core.hookenv.log('timed out waiting for address on mgmt interface', level=ch_core.hookenv.INFO) return False # If there's no mgmt interface, this is a hard error with no simple fix. # So raising an uncaught exception is ok. if not wait_for_address_on_mgmt_interface(): raise NoMgmtInterface() ",,117,19
openstack%2Fkolla-ansible~master~Ic650ba6be1f192e3cbeaa94de3d00507636c1c92,openstack/kolla-ansible,master,Ic650ba6be1f192e3cbeaa94de3d00507636c1c92,Fix create sasl account before config file is ready,MERGED,2023-04-07 18:23:21.000000000,2023-04-18 19:03:38.000000000,2023-04-18 18:57:00.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-07 18:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a42267d40fdbea34e719f98b6046e7ae9713b05f', 'message': 'Fix create sasl account before config file is ready\n\nAdd checking for container readiness before create sasl user\n\nCloses-Bug: #2015589\nChange-Id: Ic650ba6be1f192e3cbeaa94de3d00507636c1c92\n'}, {'number': 2, 'created': '2023-04-08 17:50:24.000000000', 'files': ['releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/46415123d59fbb6d281b4d0f32e4dbf527fe8c6e', 'message': 'Fix create sasl account before config file is ready\n\nAdd checking for container readiness before create sasl user\n\nCloses-Bug: #2015589\nChange-Id: Ic650ba6be1f192e3cbeaa94de3d00507636c1c92\n'}]",14,879909,46415123d59fbb6d281b4d0f32e4dbf527fe8c6e,30,5,2,35908,,,0,"Fix create sasl account before config file is ready

Add checking for container readiness before create sasl user

Closes-Bug: #2015589
Change-Id: Ic650ba6be1f192e3cbeaa94de3d00507636c1c92
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/09/879909/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/nova-cell/tasks/create_sasl_user.yml', 'releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml', 'ansible/roles/nova-cell/tasks/deploy.yml']",4,a42267d40fdbea34e719f98b6046e7ae9713b05f,bug/2015589,- include_tasks: create_sasl_user.yml when: - libvirt_enable_sasl | bool ,,34,15
openstack%2Fglance_store~master~Iaf5131927bc2a0a953ec87c8b4d2e40f5d61d878,openstack/glance_store,master,Iaf5131927bc2a0a953ec87c8b4d2e40f5d61d878,Run cinder driver unit tests,MERGED,2023-04-18 15:33:31.000000000,2023-04-18 18:43:10.000000000,2023-04-18 18:41:41.000000000,"[{'_account_id': 4393}, {'_account_id': 8122}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 15:33:31.000000000', 'files': ['test-requirements.txt', 'glance_store/tests/unit/cinder/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/6741951591ca7d6144f6089678df8cee4f0a7030', 'message': 'Run cinder driver unit tests\n\nWe have all these nice tests, might as well execute them.\n\nChange-Id: Iaf5131927bc2a0a953ec87c8b4d2e40f5d61d878\n'}]",2,880762,6741951591ca7d6144f6089678df8cee4f0a7030,10,3,1,5314,,,0,"Run cinder driver unit tests

We have all these nice tests, might as well execute them.

Change-Id: Iaf5131927bc2a0a953ec87c8b4d2e40f5d61d878
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/62/880762/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'glance_store/tests/unit/cinder/__init__.py']",2,6741951591ca7d6144f6089678df8cee4f0a7030,cinder-tests,,,1,0
openstack%2Fnova~stable%2Fyoga~Idb7fcbce0c9562e7b9bd3e80f2a6d4b9bc286830,openstack/nova,stable/yoga,Idb7fcbce0c9562e7b9bd3e80f2a6d4b9bc286830,Avoid n-cond startup abort for keystone failures,MERGED,2022-09-22 23:07:28.000000000,2023-04-18 18:18:49.000000000,2023-04-18 18:17:12.000000000,"[{'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-22 23:07:28.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/19346082058d51c78bb157ca5e1304d15691dd9a', 'message': 'Avoid n-cond startup abort for keystone failures\n\nConductor creates a placement client for the potential case where\nit needs to make a call for certain operations. A transient network\nor keystone failure will currently cause it to abort startup, which\nmeans it is not available for other unrelated activities, such as\nDB proxying for compute.\n\nThis makes conductor test the placement client on startup, but only\nabort startup on errors that are highly likely to be permanent\nconfiguration errors, and only warn about things like being unable\nto contact keystone/placement during initialization. If a non-fatal\nerror is encountered at startup, later operations needing the\nplacement client will retry initialization.\n\nConflicts:\n    nova/tests/unit/conductor/test_conductor.py\n\nNOTE(melwitt): The conflict is because change\nId5b04cf2f6ca24af8e366d23f15cf0e5cac8e1cc\n(Use unittest.mock instead of third party mock) is not in Yoga.\n\nCloses-Bug: #1846820\nChange-Id: Idb7fcbce0c9562e7b9bd3e80f2a6d4b9bc286830\n(cherry picked from commit 232684b44022f1bc4d72b07045900780de456e63)\n'}]",4,858998,19346082058d51c78bb157ca5e1304d15691dd9a,17,3,1,4690,,,0,"Avoid n-cond startup abort for keystone failures

Conductor creates a placement client for the potential case where
it needs to make a call for certain operations. A transient network
or keystone failure will currently cause it to abort startup, which
means it is not available for other unrelated activities, such as
DB proxying for compute.

This makes conductor test the placement client on startup, but only
abort startup on errors that are highly likely to be permanent
configuration errors, and only warn about things like being unable
to contact keystone/placement during initialization. If a non-fatal
error is encountered at startup, later operations needing the
placement client will retry initialization.

Conflicts:
    nova/tests/unit/conductor/test_conductor.py

NOTE(melwitt): The conflict is because change
Id5b04cf2f6ca24af8e366d23f15cf0e5cac8e1cc
(Use unittest.mock instead of third party mock) is not in Yoga.

Closes-Bug: #1846820
Change-Id: Idb7fcbce0c9562e7b9bd3e80f2a6d4b9bc286830
(cherry picked from commit 232684b44022f1bc4d72b07045900780de456e63)
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/858998/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/conductor/manager.py']",3,19346082058d51c78bb157ca5e1304d15691dd9a,bug/1846820,"from keystoneauth1 import exceptions as ks_exc try: # Test our placement client during initialization self.report_client except (ks_exc.EndpointNotFound, ks_exc.DiscoveryFailure, ks_exc.RequestTimeout, ks_exc.GatewayTimeout, ks_exc.ConnectFailure) as e: # Non-fatal, likely transient (although not definitely); # continue startup but log the warning so that when things # fail later, it will be clear why we can not do certain # things. LOG.warning('Unable to initialize placement client (%s); ' 'Continuing with startup, but some operations ' 'will not be possible.', e) except (ks_exc.MissingAuthPlugin, ks_exc.Unauthorized) as e: # This is almost definitely fatal mis-configuration. The # Unauthorized error might be transient, but it is # probably reasonable to consider it fatal. LOG.error('Fatal error initializing placement client; ' 'config is incorrect or incomplete: %s', e) raise except Exception as e: # Unknown/unexpected errors here are fatal LOG.error('Fatal error initializing placement client: %s', e) raise @property def report_client(self): return report.report_client_singleton() ", self.report_client = report.report_client_singleton(),87,1
openstack%2Fnova~stable%2Fyoga~Iab8a791f64323f996e1d6e6d5a7e7a7c34eb4fb3,openstack/nova,stable/yoga,Iab8a791f64323f996e1d6e6d5a7e7a7c34eb4fb3,Unify placement client singleton implementations,MERGED,2022-09-22 23:07:28.000000000,2023-04-18 17:57:03.000000000,2023-04-18 17:55:52.000000000,"[{'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-22 23:07:28.000000000', 'files': ['nova/scheduler/manager.py', 'nova/scheduler/client/report.py', 'nova/tests/unit/compute/test_compute.py', 'nova/cmd/manage.py', 'nova/tests/unit/compute/test_api.py', 'nova/limit/placement.py', 'nova/test.py', 'nova/conductor/tasks/migrate.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/request_filter.py', 'nova/conductor/manager.py', 'nova/quota.py', 'nova/api/openstack/compute/services.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/77273f067d96a4ec401c3b36f2922d63c4ad7103', 'message': 'Unify placement client singleton implementations\n\nWe have many places where we implement singleton behavior for the\nplacement client. This unifies them into a single place and\nimplementation. Not only does this DRY things up, but may cause us\nto initialize it fewer times and also allows for emitting a common\nset of error messages about expected failures for better\ntroubleshooting.\n\nChange-Id: Iab8a791f64323f996e1d6e6d5a7e7a7c34eb4fb3\nRelated-Bug: #1846820\n(cherry picked from commit c178d9360665c219cbcc71c9f37b9e6e3055a5e5)\n'}]",2,858997,77273f067d96a4ec401c3b36f2922d63c4ad7103,10,3,1,4690,,,0,"Unify placement client singleton implementations

We have many places where we implement singleton behavior for the
placement client. This unifies them into a single place and
implementation. Not only does this DRY things up, but may cause us
to initialize it fewer times and also allows for emitting a common
set of error messages about expected failures for better
troubleshooting.

Change-Id: Iab8a791f64323f996e1d6e6d5a7e7a7c34eb4fb3
Related-Bug: #1846820
(cherry picked from commit c178d9360665c219cbcc71c9f37b9e6e3055a5e5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/858997/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/manager.py', 'nova/scheduler/client/report.py', 'nova/tests/unit/compute/test_compute.py', 'nova/cmd/manage.py', 'nova/tests/unit/compute/test_api.py', 'nova/limit/placement.py', 'nova/test.py', 'nova/conductor/tasks/migrate.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/request_filter.py', 'nova/conductor/manager.py', 'nova/quota.py', 'nova/api/openstack/compute/services.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/compute/resource_tracker.py']",16,77273f067d96a4ec401c3b36f2922d63c4ad7103,bug/1846820, self.reportclient = reportclient or report.report_client_singleton(), self.reportclient = reportclient or report.SchedulerReportClient(),115,44
openstack%2Fcinder~master~Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4,openstack/cinder,master,Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4,db: Use cinder.db.api directly,NEW,2022-06-16 13:54:36.000000000,2023-04-18 17:29:53.000000000,,"[{'_account_id': 5997}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-06-16 13:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d2429507496f708d2c3412e9f10dba4922c1c70', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2022-06-17 10:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/977cadca87d1c4ee3434eb1cc334ce859a51869d', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2022-07-18 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39ae3d39f7977fd98d11cd47cacc5eae92f05a8e', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2022-07-28 16:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9d649ef53f2b691fb8cd53573592e102f313fd40', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2022-08-31 08:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/25fc8fc3f30b483d4f8a63118c0e532e5fb8b2d6', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2023-02-22 10:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5819dd3cfa1c221c80d36d167e56494e0c2a46b6', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly, or\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 7, 'created': '2023-02-22 18:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/85c6436e6884a4a1bdab5e72513b75bf6e6f910b', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly, or\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 8, 'created': '2023-03-30 16:15:04.000000000', 'files': ['cinder/tests/unit/test_db_api.py', 'cinder/volume/manager.py', 'cinder/tests/unit/group/test_groups_api.py', 'cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/volume/targets/driver.py', 'cinder/api/v3/group_specs.py', 'cinder/tests/unit/api/contrib/test_volume_transfer.py', 'cinder/tests/unit/db/test_cluster.py', 'cinder/tests/unit/api/v3/test_volume_transfer.py', 'cinder/objects/cleanable.py', 'cinder/tests/unit/objects/test_group_snapshot.py', 'cinder/tests/unit/test_volume_cleanup.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta5_nfs.py', 'cinder/tests/unit/volume/test_driver.py', 'cinder/cmd/manage.py', 'cinder/tests/unit/volume/test_snapshot.py', 'cinder/tests/unit/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/tests/unit/backup/drivers/test_backup_s3.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/group/test_groups_manager.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta5_iscsi.py', 'cinder/tests/unit/volume/test_availability_zone.py', 'cinder/tests/unit/db/test_reset_backend.py', 'cinder/tests/unit/attachments/test_attachments_manager.py', 'cinder/tests/unit/volume/test_init_host.py', 'cinder/tests/unit/backup/drivers/test_backup_swift.py', 'cinder/tests/unit/objects/test_qos.py', 'cinder/tests/unit/api/contrib/test_scheduler_hints.py', 'cinder/tests/unit/objects/test_cleanable.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/objects/test_service.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/backup/drivers/test_backup_driver_base.py', 'cinder/tests/unit/test_db_worker_api.py', 'cinder/volume/volume_utils.py', 'cinder/objects/consistencygroup.py', 'cinder/tests/unit/api/contrib/test_quotas.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/api/v3/test_volume_metadata.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_iscsi.py', 'cinder/tests/unit/volume/test_volume_migration.py', 'cinder/api/v3/workers.py', 'cinder/tests/unit/objects/test_group.py', 'cinder/tests/unit/volume/drivers/dell_emc/powerflex/test_create_snapshot.py', 'cinder/tests/unit/volume/test_volume_retype.py', 'cinder/db/__init__.py', 'cinder/tests/unit/volume/drivers/lightos/test_lightos_storage.py', 'cinder/scheduler/weights/volume_number.py', 'cinder/tests/unit/test_cleanable_manager.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/api/v3/default_types.py', 'cinder/tests/unit/api/v3/test_workers.py', 'cinder/tests/unit/test_volume_glance_metadata.py', 'cinder/tests/unit/volume/flows/test_create_volume_flow.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/objects/volume_type.py', 'cinder/tests/unit/volume/drivers/test_gpfs.py', 'cinder/tests/unit/db/test_default_types.py', 'cinder/objects/group.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_common.py', 'cinder/tests/unit/api/v3/test_cluster.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/objects/base.py', 'cinder/tests/unit/volume/test_manage_volume.py', 'cinder/tests/unit/api/contrib/test_volume_image_metadata.py', 'cinder/tests/unit/api/contrib/test_admin_actions.py', 'cinder/tests/unit/api/contrib/test_cgsnapshots.py', 'cinder/tests/unit/objects/test_cluster.py', 'cinder/tests/unit/volume/test_volume_manager.py', 'cinder/tests/unit/policies/test_volume_metadata.py', 'cinder/tests/unit/volume/test_volume_usage_audit.py', 'cinder/tests/unit/volume/drivers/toyou/test_acs5000.py', 'cinder/tests/unit/volume/test_rpcapi.py', 'cinder/tests/unit/api/v3/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_replication.py', 'cinder/tests/unit/policies/test_volume.py', 'cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py', 'cinder/manager.py', 'cinder/tests/unit/api/v3/test_volumes.py', 'cinder/api/contrib/quotas.py', 'cinder/tests/unit/volume/drivers/test_rbd.py', 'cinder/api/contrib/admin_actions.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/tests/unit/api/contrib/test_snapshot_unmanage.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/api/v3/test_groups.py', 'cinder/tests/unit/api/contrib/test_capabilities.py', 'cinder/tests/unit/test_volume_types_extra_specs.py', 'cinder/objects/qos_specs.py', 'cinder/objects/group_snapshot.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/objects/backup.py', 'cinder/tests/unit/db/test_qos_specs.py', 'cinder/tests/unit/api/v3/test_snapshot_metadata.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/cmd/status.py', 'cinder/tests/unit/db/test_name_id.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_fc_driver.py', 'cinder/tests/unit/volume/test_connection.py', 'cinder/tests/unit/api/v3/test_group_snapshots.py', 'cinder/db/base.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/tests/unit/volume/test_replication_manager.py', 'cinder/tests/unit/volume/drivers/test_remotefs.py', 'cinder/tests/unit/volume/drivers/test_lvm_driver.py', 'cinder/objects/service.py', 'cinder/tests/unit/backup/drivers/test_backup_google.py', 'cinder/tests/unit/keymgr/test_migration.py', 'cinder/objects/cgsnapshot.py', 'cinder/tests/unit/test_cmd.py', 'cinder/api/contrib/volume_encryption_metadata.py', 'cinder/tests/unit/backup/drivers/test_backup_ceph.py', 'cinder/tests/unit/api/contrib/test_quotas_classes.py', 'cinder/api/contrib/quota_classes.py', 'cinder/tests/unit/api/v3/test_group_specs.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/volume/api.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/policies/test_volume_type.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/volume/volume_types.py', 'cinder/tests/unit/api/contrib/test_qos_specs_manage.py', 'cinder/tests/unit/api/contrib/test_volume_type_access.py', 'cinder/objects/cluster.py', 'cinder/tests/unit/backup/test_backup_messages.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/objects/volume.py', 'cinder/tests/unit/db/test_volume_type.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_iscsi_driver.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/quota.py', 'cinder/group/api.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/api/v3/test_types.py', 'cinder/volume/volume_migration.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/tests/unit/cmd/test_status.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_fc.py', 'cinder/tests/unit/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_hosts.py', 'cinder/tests/unit/policies/test_groups.py', 'cinder/objects/snapshot.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta.py', 'cinder/volume/group_types.py', 'cinder/volume/driver.py', 'cinder/tests/unit/policies/test_default_volume_types.py', 'cinder/tests/unit/scheduler/test_host_manager.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/volume/qos_specs.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_types_manage.py', 'cinder/objects/volume_attachment.py', 'cinder/tests/unit/test_service.py', 'cinder/api/contrib/hosts.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/56baf866b8445b9625f26214f68023d63266daf4', 'message': ""db: Use cinder.db.api directly\n\ncinder/db/__init__.py was importing * from cinder.db.api. This meant that\nany time any code anywhere within the cinder.db package was imported\nthen cinder.db.api was too, leading to a cascade of imports that may\nnot have been desired. Also, in general, code in __init__.py is a pain.\n\nTherefore, this change adjusts code that so that either:\n\n* cinder.db.api is used directly, or\n* cinder.db.api is imported as 'db'\n\nIn either case, the functionality remains the same.\n\nThe primary goal of this change was to make it possible to import the model\nfiles without having to import the DB API. This looks like a very large\nchange, but it is essentially adjusting package names.\n\nNote that nova did this some time back in change\nIc1fd7c87ceda05eeb96735da2a415ef37060bb1a.\n\nChange-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",5,846173,56baf866b8445b9625f26214f68023d63266daf4,166,2,8,15334,,,0,"db: Use cinder.db.api directly

cinder/db/__init__.py was importing * from cinder.db.api. This meant that
any time any code anywhere within the cinder.db package was imported
then cinder.db.api was too, leading to a cascade of imports that may
not have been desired. Also, in general, code in __init__.py is a pain.

Therefore, this change adjusts code that so that either:

* cinder.db.api is used directly, or
* cinder.db.api is imported as 'db'

In either case, the functionality remains the same.

The primary goal of this change was to make it possible to import the model
files without having to import the DB API. This looks like a very large
change, but it is essentially adjusting package names.

Note that nova did this some time back in change
Ic1fd7c87ceda05eeb96735da2a415ef37060bb1a.

Change-Id: Ie73c74c0eeeda185a8d648444a88f7ddcbdf83b4
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/846173/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_db_api.py', 'cinder/volume/manager.py', 'cinder/tests/unit/group/test_groups_api.py', 'cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/volume/targets/driver.py', 'cinder/api/v3/group_specs.py', 'cinder/tests/unit/api/contrib/test_volume_transfer.py', 'cinder/tests/unit/db/test_cluster.py', 'cinder/tests/unit/api/v3/test_volume_transfer.py', 'cinder/objects/cleanable.py', 'cinder/tests/unit/objects/test_group_snapshot.py', 'cinder/tests/unit/test_volume_cleanup.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta5_nfs.py', 'cinder/tests/unit/volume/test_driver.py', 'cinder/cmd/manage.py', 'cinder/tests/unit/volume/test_snapshot.py', 'cinder/tests/unit/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/tests/unit/backup/drivers/test_backup_s3.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/group/test_groups_manager.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta5_iscsi.py', 'cinder/tests/unit/volume/test_availability_zone.py', 'cinder/tests/unit/db/test_reset_backend.py', 'cinder/tests/unit/attachments/test_attachments_manager.py', 'cinder/tests/unit/volume/test_init_host.py', 'cinder/tests/unit/backup/drivers/test_backup_swift.py', 'cinder/tests/unit/objects/test_qos.py', 'cinder/tests/unit/api/contrib/test_scheduler_hints.py', 'cinder/tests/unit/objects/test_cleanable.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/objects/test_service.py', 'cinder/tests/unit/objects/test_cgsnapshot.py', 'cinder/tests/unit/backup/drivers/test_backup_driver_base.py', 'cinder/tests/unit/test_db_worker_api.py', 'cinder/volume/volume_utils.py', 'cinder/objects/consistencygroup.py', 'cinder/tests/unit/api/contrib/test_quotas.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/api/v3/test_volume_metadata.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_iscsi.py', 'cinder/tests/unit/volume/test_volume_migration.py', 'cinder/api/v3/workers.py', 'cinder/tests/unit/objects/test_group.py', 'cinder/tests/unit/volume/drivers/dell_emc/powerflex/test_create_snapshot.py', 'cinder/tests/unit/volume/test_volume_retype.py', 'cinder/db/__init__.py', 'cinder/tests/unit/volume/drivers/lightos/test_lightos_storage.py', 'cinder/scheduler/weights/volume_number.py', 'cinder/tests/unit/test_cleanable_manager.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/api/v3/default_types.py', 'cinder/tests/unit/api/v3/test_workers.py', 'cinder/tests/unit/test_volume_glance_metadata.py', 'cinder/tests/unit/volume/flows/test_create_volume_flow.py', 'cinder/tests/unit/volume/test_volume.py', 'cinder/objects/volume_type.py', 'cinder/tests/unit/volume/drivers/test_gpfs.py', 'cinder/tests/unit/db/test_default_types.py', 'cinder/objects/group.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_common.py', 'cinder/tests/unit/api/v3/test_cluster.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/objects/test_consistencygroup.py', 'cinder/objects/base.py', 'cinder/tests/unit/volume/test_manage_volume.py', 'cinder/tests/unit/api/contrib/test_volume_image_metadata.py', 'cinder/tests/unit/api/contrib/test_admin_actions.py', 'cinder/tests/unit/api/contrib/test_cgsnapshots.py', 'cinder/tests/unit/objects/test_cluster.py', 'cinder/tests/unit/policies/test_volume_metadata.py', 'cinder/tests/unit/volume/test_volume_usage_audit.py', 'cinder/tests/unit/volume/drivers/toyou/test_acs5000.py', 'cinder/tests/unit/volume/test_rpcapi.py', 'cinder/tests/unit/api/v3/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_replication.py', 'cinder/tests/unit/policies/test_volume.py', 'cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py', 'cinder/manager.py', 'cinder/tests/unit/api/v3/test_volumes.py', 'cinder/api/contrib/quotas.py', 'cinder/tests/unit/volume/drivers/test_rbd.py', 'cinder/api/contrib/admin_actions.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/objects/test_backup.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/tests/unit/api/contrib/test_snapshot_unmanage.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/api/v3/test_groups.py', 'cinder/tests/unit/api/contrib/test_capabilities.py', 'cinder/tests/unit/test_volume_types_extra_specs.py', 'cinder/objects/qos_specs.py', 'cinder/objects/group_snapshot.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/objects/backup.py', 'cinder/tests/unit/db/test_qos_specs.py', 'cinder/tests/unit/api/v3/test_snapshot_metadata.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/cmd/status.py', 'cinder/tests/unit/db/test_name_id.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_fc_driver.py', 'cinder/tests/unit/volume/test_connection.py', 'cinder/tests/unit/api/v3/test_group_snapshots.py', 'cinder/db/base.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/tests/unit/volume/test_replication_manager.py', 'cinder/tests/unit/volume/drivers/test_remotefs.py', 'cinder/tests/unit/volume/drivers/test_lvm_driver.py', 'cinder/objects/service.py', 'cinder/tests/unit/backup/drivers/test_backup_google.py', 'cinder/tests/unit/keymgr/test_migration.py', 'cinder/objects/cgsnapshot.py', 'cinder/tests/unit/test_cmd.py', 'cinder/api/contrib/volume_encryption_metadata.py', 'cinder/tests/unit/backup/drivers/test_backup_ceph.py', 'cinder/tests/unit/api/contrib/test_quotas_classes.py', 'cinder/api/contrib/quota_classes.py', 'cinder/tests/unit/api/v3/test_group_specs.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/volume/api.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/policies/test_volume_type.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/objects/test_volume_type.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/volume/volume_types.py', 'cinder/tests/unit/api/contrib/test_qos_specs_manage.py', 'cinder/tests/unit/api/contrib/test_volume_type_access.py', 'cinder/objects/cluster.py', 'cinder/tests/unit/backup/test_backup_messages.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/objects/volume.py', 'cinder/tests/unit/db/test_volume_type.py', 'cinder/tests/unit/volume/drivers/inspur/instorage/test_iscsi_driver.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/quota.py', 'cinder/group/api.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/api/v3/test_types.py', 'cinder/volume/volume_migration.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/tests/unit/cmd/test_status.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_fc.py', 'cinder/tests/unit/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_hosts.py', 'cinder/tests/unit/policies/test_groups.py', 'cinder/objects/snapshot.py', 'cinder/tests/unit/volume/drivers/nexenta/test_nexenta.py', 'cinder/volume/group_types.py', 'cinder/volume/driver.py', 'cinder/tests/unit/policies/test_default_volume_types.py', 'cinder/tests/unit/scheduler/test_host_manager.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/volume/qos_specs.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_types_manage.py', 'cinder/objects/volume_attachment.py', 'cinder/tests/unit/test_service.py', 'cinder/api/contrib/hosts.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/objects/test_volume_attachment.py']",173,6d2429507496f708d2c3412e9f10dba4922c1c70,remove-legacyfacade,from cinder.db import api as db @mock.patch('cinder.db.api.volume_attachment_update') @mock.patch('cinder.db.api.volume_attachment_get_all_by_volume_id') @mock.patch('cinder.db.api.volume_attachment_get_all_by_host') @mock.patch('cinder.db.api.volume_attachment_get_all_by_instance_uuid'),from cinder import db @mock.patch('cinder.db.volume_attachment_update') @mock.patch('cinder.db.volume_attachment_get_all_by_volume_id') @mock.patch('cinder.db.volume_attachment_get_all_by_host') @mock.patch('cinder.db.volume_attachment_get_all_by_instance_uuid'),653,659
openstack%2Fdevstack~master~I0f5e4c644e2d14d1b8bb5bc0096d1469febe5fcc,openstack/devstack,master,I0f5e4c644e2d14d1b8bb5bc0096d1469febe5fcc,Remove support for opensuse,MERGED,2023-01-24 16:40:50.000000000,2023-04-18 17:16:43.000000000,2023-04-18 17:15:32.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-24 16:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a35e3766feba110f97e7fcbcbe3603ac8f6f0506', 'message': ""Remove support for opensuse\n\nWe haven't been testing the distro for a while in CI, e.g. in\nTempest, the jobs on opensuse15 haven't been executed for a year\nnow.\nTherefore the patch removes opensuse support from devstack.\n\nCloses-Bug: #2002900\nChange-Id: I0f5e4c644e2d14d1b8bb5bc0096d1469febe5fcc\n""}, {'number': 2, 'created': '2023-02-16 11:01:46.000000000', 'files': ['doc/source/plugins.rst', 'lib/ldap', 'files/rpms-suse/dstat', 'files/rpms-suse/general', 'files/rpms-suse/ldap', 'lib/neutron_plugins/ovs_base', 'lib/nova', 'files/rpms-suse/nova', 'tests/test_package_ordering.sh', 'lib/nova_plugins/functions-libvirt', 'files/rpms-suse/swift', 'files/rpms-suse/ceph', 'lib/lvm', 'functions-common', 'lib/swift', 'lib/glance', 'files/rpms-suse/baremetal', 'files/rpms-suse/horizon', 'files/rpms-suse/neutron-common', 'files/rpms-suse/q-l3', 'lib/horizon', 'stack.sh', 'lib/databases/mysql', 'files/rpms-suse/keystone', 'lib/cinder', 'lib/neutron_plugins/ovs_source', 'files/rpms-suse/n-cpu', 'lib/nova_plugins/hypervisor-libvirt', 'files/rpms-suse/n-api', 'files/rpms-suse/neutron-agent', 'lib/databases/postgresql', 'files/rpms-suse/q-agt', 'lib/rpc_backend', 'files/rpms-suse/os-brick', 'files/rpms-suse/neutron-l3', 'doc/source/index.rst', 'inc/python', 'files/rpms-suse/openvswitch', 'files/rpms-suse/cinder', 'lib/tls', 'tools/fixup_stuff.sh', 'tools/install_prereqs.sh', 'lib/apache'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ec07b343d25e9964db57ef9c3e2a89deeb5ac56e', 'message': ""Remove support for opensuse\n\nWe haven't been testing the distro for a while in CI, e.g. in\nTempest, the jobs on opensuse15 haven't been executed for a year\nnow.\nTherefore the patch removes opensuse support from devstack.\n\nCloses-Bug: #2002900\nChange-Id: I0f5e4c644e2d14d1b8bb5bc0096d1469febe5fcc\n""}]",10,871641,ec07b343d25e9964db57ef9c3e2a89deeb5ac56e,15,3,2,22873,,,0,"Remove support for opensuse

We haven't been testing the distro for a while in CI, e.g. in
Tempest, the jobs on opensuse15 haven't been executed for a year
now.
Therefore the patch removes opensuse support from devstack.

Closes-Bug: #2002900
Change-Id: I0f5e4c644e2d14d1b8bb5bc0096d1469febe5fcc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/41/871641/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/plugins.rst', 'lib/ldap', 'files/rpms-suse/dstat', 'files/rpms-suse/general', 'files/rpms-suse/ldap', 'lib/neutron_plugins/ovs_base', 'lib/nova', 'files/rpms-suse/nova', 'tests/test_package_ordering.sh', 'lib/nova_plugins/functions-libvirt', 'files/rpms-suse/swift', 'files/rpms-suse/ceph', 'lib/lvm', 'functions-common', 'lib/swift', 'lib/glance', 'files/rpms-suse/baremetal', 'files/rpms-suse/horizon', 'files/rpms-suse/neutron-common', 'files/rpms-suse/q-l3', 'lib/horizon', 'stack.sh', 'lib/databases/mysql', 'files/rpms-suse/keystone', 'lib/cinder', 'lib/neutron_plugins/ovs_source', 'files/rpms-suse/n-cpu', 'lib/nova_plugins/hypervisor-libvirt', 'files/rpms-suse/n-api', 'files/rpms-suse/neutron-agent', 'lib/databases/postgresql', 'files/rpms-suse/q-agt', 'lib/rpc_backend', 'files/rpms-suse/os-brick', 'files/rpms-suse/neutron-l3', 'doc/source/index.rst', 'inc/python', 'files/rpms-suse/openvswitch', 'files/rpms-suse/cinder', 'lib/tls', 'tools/fixup_stuff.sh', 'tools/install_prereqs.sh', 'lib/apache']",43,a35e3766feba110f97e7fcbcbe3603ac8f6f0506,," if is_ubuntu; then# On Fedora, any file in /etc/httpd/conf.d/ whose name ends with .conf is enabled. elif is_fedora; then elif is_fedora; then elif is_fedora; then","elif is_suse; then APACHE_NAME=apache2 APACHE_CONF_DIR=${APACHE_CONF_DIR:-/etc/$APACHE_NAME/vhosts.d} APACHE_SETTINGS_DIR=${APACHE_SETTINGS_DIR:-/etc/$APACHE_NAME/conf.d} elif is_suse; then if ! a2enmod -q $mod ; then sudo a2enmod $mod restart_apache_server fi elif [[ $os_VENDOR =~ openSUSE ]]; then install_package uwsgi \ uwsgi-python3 \ apache2-mod_uwsgi if is_ubuntu || is_suse ; then elif is_suse; then install_package apache2 apache2-mod_wsgi# On Fedora and openSUSE, any file in /etc/httpd/conf.d/ whose name ends with .conf is enabled. elif is_fedora || is_suse; then elif is_fedora || is_suse; then elif is_fedora || is_suse; then",24,336
openstack%2Fopenstack-ansible~master~I180f6d2e74a9cfded4b8f90e6b01390e73a7e3f6,openstack/openstack-ansible,master,I180f6d2e74a9cfded4b8f90e6b01390e73a7e3f6,Add missing blazar haproxy service,MERGED,2023-04-15 11:58:31.000000000,2023-04-18 16:53:52.000000000,2023-04-18 16:52:14.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-15 11:58:31.000000000', 'files': ['inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6bd4aca83f98c8fe78c6c42fc783335f46467842', 'message': 'Add missing blazar haproxy service\n\nWe are missing haproxy service for blazar. This patch adds it.\n\nChange-Id: I180f6d2e74a9cfded4b8f90e6b01390e73a7e3f6\n'}]",2,880564,6bd4aca83f98c8fe78c6c42fc783335f46467842,13,3,1,32666,,,0,"Add missing blazar haproxy service

We are missing haproxy service for blazar. This patch adds it.

Change-Id: I180f6d2e74a9cfded4b8f90e6b01390e73a7e3f6
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/880564/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/haproxy/haproxy.yml'],1,6bd4aca83f98c8fe78c6c42fc783335f46467842,,"haproxy_blazar_api_service: haproxy_service_name: blazar_api haproxy_backend_nodes: ""{{ groups['blazar_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 1234 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['blazar_api'] is defined and groups['blazar_api'] | length > 0 }}"" - service: ""{{ haproxy_blazar_api_service | combine(haproxy_blazar_api_service_overrides | default({})) }}""",,12,0
openstack%2Ftripleo-heat-templates~master~Idc0c999dd5beb19394bfc5215043ba619da2fad8,openstack/tripleo-heat-templates,master,Idc0c999dd5beb19394bfc5215043ba619da2fad8,Change designate IP configuration to step 3,ABANDONED,2023-03-13 20:37:01.000000000,2023-04-18 16:40:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-13 20:37:01.000000000', 'files': ['deployment/designate/designate-bind-container.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/910345059c101a860c0cc55f0eb72f9d01cfc816', 'message': 'Change designate IP configuration to step 3\n\nSetting and /128 IPv6 address on the external network interface seems to\nconfuse something in the haproxy endpoint configuraiton and causes a\ngeneral. Moving the designate related code to step 3 seems to workaround\nthis problem.\n\nCloses-Bug: #2011476\nChange-Id: Idc0c999dd5beb19394bfc5215043ba619da2fad8\n'}]",0,877322,910345059c101a860c0cc55f0eb72f9d01cfc816,3,1,1,6681,,,0,"Change designate IP configuration to step 3

Setting and /128 IPv6 address on the external network interface seems to
confuse something in the haproxy endpoint configuraiton and causes a
general. Moving the designate related code to step 3 seems to workaround
this problem.

Closes-Bug: #2011476
Change-Id: Idc0c999dd5beb19394bfc5215043ba619da2fad8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/877322/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/designate/designate-bind-container.yaml'],1,910345059c101a860c0cc55f0eb72f9d01cfc816,, - step|int == 3 when: step|int == 3 when: step|int == 3, - step|int == 1 when: step|int == 1 when: step|int == 1,3,3
openstack%2Fkolla-ansible~master~Ie0fbc39d61aff82757d5c69f38f156801100a453,openstack/kolla-ansible,master,Ie0fbc39d61aff82757d5c69f38f156801100a453,Use Docker healthchecks for mariadb services,ABANDONED,2021-03-13 05:57:04.000000000,2023-04-18 16:05:01.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2021-03-13 05:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bc850efd65a8561f23cc2d37301175cf6df66eeb', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\nImplements: blueprint container-health-check\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}, {'number': 2, 'created': '2021-03-13 06:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dc7668ef2a2bb0883222a0d9e73e001aef8cb028', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\nImplements: blueprint container-health-check\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}, {'number': 3, 'created': '2021-03-28 08:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b2cc456b883d9213de6ac3ba420b0be8b1c07f74', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\nImplements: blueprint container-health-check\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}, {'number': 4, 'created': '2021-03-29 12:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d4ff9ede70b20ddc50f74c0c4fb6503094cc4d1f', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\nImplements: blueprint container-health-check\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}, {'number': 5, 'created': '2021-04-27 02:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4f5c92e8b352ad4344379dfcbd37e36f93d423a0', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\nImplements: blueprint container-health-check\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}, {'number': 6, 'created': '2021-05-11 01:05:16.000000000', 'files': ['ansible/roles/mariadb/handlers/main.yml', 'ansible/roles/mariadb/tasks/recover_cluster.yml', 'releasenotes/notes/implement-docker-healthchecks-for-mariadb-f02761950435dab6.yaml', 'ansible/roles/mariadb/tasks/check-containers.yml', 'ansible/roles/mariadb/tasks/restart_services.yml', 'ansible/roles/mariadb/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2922433ad00a3e38955e1598120b7a870208c51f', 'message': 'Use Docker healthchecks for mariadb services\n\nThis change enables the use of Docker healthchecks for mariadb services.\n\nImplements: blueprint container-health-check\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/785401\n\nChange-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453\n'}]",5,780404,2922433ad00a3e38955e1598120b7a870208c51f,25,3,6,31506,,,0,"Use Docker healthchecks for mariadb services

This change enables the use of Docker healthchecks for mariadb services.

Implements: blueprint container-health-check
Depends-On: https://review.opendev.org/c/openstack/kolla/+/785401

Change-Id: Ie0fbc39d61aff82757d5c69f38f156801100a453
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/04/780404/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/mariadb/handlers/main.yml', 'ansible/roles/mariadb/tasks/recover_cluster.yml', 'releasenotes/notes/implement-docker-healthchecks-for-mariadb-f02761950435dab6.yaml', 'ansible/roles/mariadb/tasks/check-containers.yml', 'ansible/roles/mariadb/tasks/restart_services.yml', 'ansible/roles/mariadb/defaults/main.yml']",6,bc850efd65a8561f23cc2d37301175cf6df66eeb,container-health-check," healthcheck: ""{{ mariadb_healthcheck }}"" healthcheck: ""{{ mariadb_clustercheck_healthcheck }}""mariadb_enable_healthchecks: ""{{ enable_container_healthchecks }}"" mariadb_healthcheck_interval: ""{{ default_container_healthcheck_interval }}"" mariadb_healthcheck_retries: ""{{ default_container_healthcheck_retries }}"" mariadb_healthcheck_start_period: ""{{ default_container_healthcheck_start_period }}"" mariadb_healthcheck_test: [""CMD-SHELL"", ""healthcheck_listen {{ mariadb_port }}""] mariadb_healthcheck_timeout: ""{{ default_container_healthcheck_timeout }}"" mariadb_healthcheck: interval: ""{{ mariadb_healthcheck_interval }}"" retries: ""{{ mariadb_healthcheck_retries }}"" start_period: ""{{ mariadb_healthcheck_start_period }}"" test: ""{% if mariadb_enable_healthchecks | bool %}{{ mariadb_healthcheck_test }}{% else %}NONE{% endif %}"" timeout: ""{{ mariadb_healthcheck_timeout }}"" mariadb_clustercheck_enable_healthchecks: ""{{ enable_container_healthchecks }}"" mariadb_clustercheck_healthcheck_interval: ""{{ default_container_healthcheck_interval }}"" mariadb_clustercheck_healthcheck_retries: ""{{ default_container_healthcheck_retries }}"" mariadb_clustercheck_healthcheck_start_period: ""{{ default_container_healthcheck_start_period }}"" mariadb_clustercheck_healthcheck_test: [""CMD-SHELL"", ""healthcheck_listen xinetd {{ mariadb_clustercheck_port }}""] mariadb_clustercheck_healthcheck_timeout: ""{{ default_container_healthcheck_timeout }}"" mariadb_clustercheck_healthcheck: interval: ""{{ mariadb_clustercheck_healthcheck_interval }}"" retries: ""{{ mariadb_clustercheck_healthcheck_retries }}"" start_period: ""{{ mariadb_clustercheck_healthcheck_start_period }}"" test: ""{% if mariadb_clustercheck_enable_healthchecks | bool %}{{ mariadb_clustercheck_healthcheck_test }}{% else %}NONE{% endif %}"" timeout: ""{{ mariadb_clustercheck_healthcheck_timeout }}"" ",,38,0
openstack%2Fkolla-ansible~master~I9f7692f222befa815b3ca393e4610aa3197484d8,openstack/kolla-ansible,master,I9f7692f222befa815b3ca393e4610aa3197484d8,Issues with xen and required os-xenapi packages,ABANDONED,2019-04-24 21:28:42.000000000,2023-04-18 16:01:33.000000000,,"[{'_account_id': 14826}, {'_account_id': 20451}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2019-04-24 21:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/019004bb8934144036d594a63b5fce0575af842e', 'message': 'Installing the correct and up-to-date version of os-xenapi\n\nChange-Id: I9f7692f222befa815b3ca393e4610aa3197484d8\n'}, {'number': 2, 'created': '2019-04-25 15:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a51bb0b67d39739bf8f15731b68a2e0c412f68cf', 'message': 'Closes-Bug :\nInstalling the correct and up-to-date version of os-xenapi. Discussed \nwith mgoddard, the RDO package is missing and complicated to \ndifferenciate between master and specific branch version.  Pip is \nsimplier than incorporating it into the docker image.  Pip will install\nthe latest version of the package.\n\nChange-Id: I9f7692f222befa815b3ca393e4610aa3197484d8\n'}, {'number': 3, 'created': '2019-04-25 15:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fec8e70fb27ea439cffcc04d659421ed3d224242', 'message': 'Closes-bug: #655570\nInstalling the correct and up-to-date version of os-xenapi. Discussed\nwith mgoddard, the RDO package is missing and complicated to\ndifferenciate between master and specific branch version.  Pip is\nsimplier than incorporating it into the docker image.  Pip will install\nthe latest version of the package.\n\nChange-Id: I9f7692f222befa815b3ca393e4610aa3197484d8\n'}, {'number': 4, 'created': '2019-04-25 15:19:23.000000000', 'files': ['ansible/roles/nova/tasks/bootstrap_xenapi.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2f221dc5d1983a2c8d086b9cbae31edd7fe1d718', 'message': ""Issues with xen and required os-xenapi packages\n\nDiscussed with mgoddard, the RDO package is missing and complicated to\ndifferenciate between master and specific branch version.  Pip is simplier than\nincorporating it into the docker image.  Pip will install the latest version of\nthe package.\n\nMichal, I had a clean install of centos7 min. for domU, it seems like\nthe deb package was missing. There are issues also with the nova_compute\ndocker image which I'm also working on. That's the error log that\nmgoddard posted.\n\nCloses-bug: #1826269\nChange-Id: I9f7692f222befa815b3ca393e4610aa3197484d8\n""}]",3,655570,2f221dc5d1983a2c8d086b9cbae31edd7fe1d718,18,4,4,20451,,,0,"Issues with xen and required os-xenapi packages

Discussed with mgoddard, the RDO package is missing and complicated to
differenciate between master and specific branch version.  Pip is simplier than
incorporating it into the docker image.  Pip will install the latest version of
the package.

Michal, I had a clean install of centos7 min. for domU, it seems like
the deb package was missing. There are issues also with the nova_compute
docker image which I'm also working on. That's the error log that
mgoddard posted.

Closes-bug: #1826269
Change-Id: I9f7692f222befa815b3ca393e4610aa3197484d8
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/70/655570/4 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/tasks/bootstrap_xenapi.yml'],1,019004bb8934144036d594a63b5fce0575af842e,bug/a1826269, pip: name: os-xenapi, package: name: python-os-xenapi,2,2
openstack%2Fkolla~master~I7092b561d81c362ca24f84a3d753e777e5625ab3,openstack/kolla,master,I7092b561d81c362ca24f84a3d753e777e5625ab3,docker: use python3-venv to create virtual env,MERGED,2023-03-20 16:45:16.000000000,2023-04-18 15:53:12.000000000,2023-04-18 15:52:14.000000000,"[{'_account_id': 14200}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-03-20 16:45:16.000000000', 'files': ['docker/openstack-base/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ca16f7ae7da77102db2c1d533c401094479fe1ae', 'message': ""docker: use python3-venv to create virtual env\n\nDebian 'bookworm' does not like when someone installs Python packages\ninto system directories. So instead of installing 'virtualenv' from pip\nwe move to use 'python3 -m venv' which we install from distribution\nrepositories (on Debian/Ubuntu as EL9 has it in base 'python3').\n\nChange-Id: I7092b561d81c362ca24f84a3d753e777e5625ab3\n""}]",1,877986,ca16f7ae7da77102db2c1d533c401094479fe1ae,16,4,1,24072,,,0,"docker: use python3-venv to create virtual env

Debian 'bookworm' does not like when someone installs Python packages
into system directories. So instead of installing 'virtualenv' from pip
we move to use 'python3 -m venv' which we install from distribution
repositories (on Debian/Ubuntu as EL9 has it in base 'python3').

Change-Id: I7092b561d81c362ca24f84a3d753e777e5625ab3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/86/877986/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/openstack-base/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2']",2,ca16f7ae7da77102db2c1d533c401094479fe1ae,bookworm-preparation," 'python3-venv', && python3 -m venv --system-site-packages {{ virtualenv_path }}", 'virtualenv' && virtualenv --system-site-packages {{ virtualenv_path }},4,4
openstack%2Fnova~master~Ic2a587c1ef4e674488d783e09d14e074947d50be,openstack/nova,master,Ic2a587c1ef4e674488d783e09d14e074947d50be,[DNM] build apline image in nova-next,ABANDONED,2023-04-01 20:51:33.000000000,2023-04-18 15:52:33.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-01 20:51:33.000000000', 'files': ['roles/build_alpine/tests/test.yml', 'roles/build_alpine/vars/main.yml', 'roles/build_alpine/handlers/main.yml', 'playbooks/alpine/pre.yaml', 'roles/build_alpine/defaults/main.yml', '.zuul.yaml', 'roles/build_alpine/molecule/default/molecule.yml', 'roles/build_alpine/molecule/default/verify.yml', 'roles/build_alpine/tasks/main.yml', 'roles/build_alpine/.yamllint', 'roles/build_alpine/README.md', 'roles/build_alpine/tests/inventory', 'roles/build_alpine/molecule/default/converge.yml', 'roles/build_alpine/molecule/default/deps.sh', 'roles/build_alpine/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/nova/commit/78ddff08d099ee415922f615f48e2966ea30b070', 'message': '[DNM] build apline image in nova-next\n\nDepends-On: https://review.opendev.org/c/openstack/diskimage-builder/+/755410\nChange-Id: Ic2a587c1ef4e674488d783e09d14e074947d50be\n'}]",0,879220,78ddff08d099ee415922f615f48e2966ea30b070,4,1,1,11604,,,0,"[DNM] build apline image in nova-next

Depends-On: https://review.opendev.org/c/openstack/diskimage-builder/+/755410
Change-Id: Ic2a587c1ef4e674488d783e09d14e074947d50be
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/879220/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/build_alpine/tests/test.yml', 'roles/build_alpine/vars/main.yml', 'roles/build_alpine/handlers/main.yml', 'playbooks/alpine/pre.yaml', 'roles/build_alpine/defaults/main.yml', '.zuul.yaml', 'roles/build_alpine/molecule/default/molecule.yml', 'roles/build_alpine/molecule/default/verify.yml', 'roles/build_alpine/tasks/main.yml', 'roles/build_alpine/.yamllint', 'roles/build_alpine/README.md', 'roles/build_alpine/tests/inventory', 'roles/build_alpine/molecule/default/converge.yml', 'roles/build_alpine/molecule/default/deps.sh', 'roles/build_alpine/meta/main.yml']",15,78ddff08d099ee415922f615f48e2966ea30b070,alpine,"galaxy_info: author: your name namespace: openstack description: your role description company: your company (optional) # If the issue tracker for your role is not on github, uncomment the # next line and provide a value # issue_tracker_url: http://example.com/issue/tracker # Choose a valid license ID from https://spdx.org - some suggested licenses: # - BSD-3-Clause (default) # - MIT # - GPL-2.0-or-later # - GPL-3.0-only # - Apache-2.0 # - CC-BY-4.0 license: license (GPL-2.0-or-later, MIT, etc) min_ansible_version: 2.1 # If this a Container Enabled role, provide the minimum Ansible Container version. # min_ansible_container_version: # # Provide a list of supported platforms, and for each platform a list of versions. # If you don't wish to enumerate all versions for a particular platform, use 'all'. # To view available platforms and versions (or releases), visit: # https://galaxy.ansible.com/api/v1/platforms/ # # platforms: # - name: Fedora # versions: # - all # - 25 # - name: SomePlatform # versions: # - all # - 1.0 # - 7 # - 99.99 galaxy_tags: [] # List tags for your role here, one per line. A tag is a keyword that describes # and categorizes the role. Users find roles by searching for tags. Be sure to # remove the '[]' above, if you add tags to this list. # # NOTE: A tag is limited to a single word comprised of alphanumeric characters. # Maximum 20 tags per role. dependencies: []",,302,48
openstack%2Fkayobe~master~I61a61ca59652b13687c2247d5881012b51f666a7,openstack/kayobe,master,I61a61ca59652b13687c2247d5881012b51f666a7,Stop using kolla-ansible bootstrap-servers,MERGED,2022-01-17 17:23:40.000000000,2023-04-18 15:51:54.000000000,2023-04-18 15:49:59.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}, {'_account_id': 28048}]","[{'number': 1, 'created': '2022-01-17 17:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/d06e3361bac69a3e699ac9f8aee7048e10803145', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 2, 'created': '2022-02-15 15:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/042225434e1761e300f26f68bf986cc449b1515b', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 3, 'created': '2022-02-15 17:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/96eea3a4633e956da3b364e790de532cf80aa31f', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/821206\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 4, 'created': '2022-02-16 17:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/5ab920b4d29c2eeafb153d84d255b7d120874ee3', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/821206\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 5, 'created': '2022-02-16 17:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/3a97514d49b343ea644fb2b2db2d7c4bd0ea48bc', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 6, 'created': '2022-02-16 17:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/1994017dabb03221798d0412987651d5a7bf9979', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 7, 'created': '2022-02-16 17:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/b9ffefb59ed86e1f384085229fb05d254b13b3a4', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 8, 'created': '2022-02-21 15:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/3ba1596d51e89381720d542096759815e2a6c426', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 9, 'created': '2022-02-21 17:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/01ffa9b3330434f6ecb6a158640c8b8b0fe94c65', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 10, 'created': '2022-02-22 11:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0006f11e7799cf19271e9693ee81cbc450c2d7c0', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 11, 'created': '2022-02-22 13:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0f7c1e7d23fbb8678656059cc641f5757a2f7d34', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 12, 'created': '2022-02-22 14:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/d8a7e4eb1499d8a29b509d617b5a13ef2a3bdf54', 'message': 'Stop using kolla-ansible bootstrap-servers\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n'}, {'number': 13, 'created': '2022-02-22 15:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0ad667144937811b087caf2b36641e6f46fbd792', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 14, 'created': '2022-02-22 16:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/6f9f80f5378b0dacc4edef68f8ebaee8f7a39255', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 15, 'created': '2022-02-22 17:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/762302001323c93c3bd8c02fa8497677d9af2460', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 16, 'created': '2022-02-28 15:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/8bf64a971b2e34d9dd8718d06fec3feb0c367468', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 17, 'created': '2022-03-02 13:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e99e994c58a6c9b5b39e023ffbdeb2de84d348b7', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 18, 'created': '2022-03-17 13:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/1576114e771ccbc13f3366f6673c5072c7b8a128', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 19, 'created': '2022-04-06 15:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/0ec7e6d2d87e5be0dd8a95d18d40f31c2cd83352', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 20, 'created': '2022-06-30 12:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/50910a5d2ada89fc4eb4d272691476482c8e9c44', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 21, 'created': '2022-07-01 08:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/f65122ca4f2d9ad1675a81cc81169549299b0479', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 22, 'created': '2022-08-08 10:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/39df7b9fbc3e56cafc70f5acd0d0bf63ec486ef8', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 23, 'created': '2022-09-07 14:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/63c1935472a08f8b2b7fc5b5ffaf4cbe72c63277', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 24, 'created': '2022-09-13 08:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/cc72ca0c05d3c3f39e7109513bc3ee41381a382a', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 25, 'created': '2023-02-21 16:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/742ecfc230f95ad32b999f394d4ce96a617a3a7d', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}, {'number': 26, 'created': '2023-03-30 13:52:54.000000000', 'files': ['kayobe/tests/unit/cli/test_commands.py', 'playbooks/kayobe-tox-ansible-syntax/pre.yml', 'ansible/overcloud-host-configure.yml', '.gitignore', 'ansible/apparmor-libvirt.yml', 'ansible/roles/firewall-debian/defaults/main.yml', 'ansible/inventory/group_vars/all/docker', 'ansible/roles/etc-hosts/tasks/etc-hosts.yml', 'doc/source/configuration/reference/hosts.rst', 'ansible/roles/kolla-ansible/defaults/main.yml', 'ansible/roles/docker/templates/daemon.json.j2', 'playbooks/kayobe-overcloud-base/run.yml', 'ansible/firewall.yml', 'playbooks/kayobe-overcloud-host-configure-base/run.yml', 'ansible/etc-hosts.yml', 'ansible/overcloud-docker-sdk-upgrade.yml', 'ansible/kayobe-target-venv.yml', 'ansible/roles/docker/handlers/main.yml', 'ansible/roles/gather-facts-delegated/defaults/main.yml', 'ansible/roles/docker/tasks/main.yml', 'ansible/roles/firewall-debian/tasks/main.yml', 'ansible/kolla-ansible.yml', 'ansible/roles/etc-hosts/tasks/main.yml', 'ansible/docker.yml', 'ansible/roles/gather-facts-delegated/tasks/main.yml', 'ansible/roles/kolla-ansible/templates/kolla/globals.yml', 'ansible/roles/docker/defaults/main.yml', 'releasenotes/notes/drop-bootstrap-servers-4d75713c7009153f.yaml', 'ansible/roles/etc-hosts/defaults/main.yml', 'ansible/roles/kolla-ansible/tasks/config.yml', 'kayobe/cli/commands.py', 'ansible/seed-host-configure.yml', 'ansible/kolla-packages.yml', 'ansible/kayobe-ansible-user.yml', 'tox.ini', 'zuul.d/jobs.yaml', 'ansible/overcloud-host-upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/c9f8d80ba63e28ba2278803cecd12da07e8e6516', 'message': ""Stop using kolla-ansible bootstrap-servers\n\nThe 'kayobe * host configure' commands no longer use the 'kolla-ansible\nbootstrap-servers' command, and associated 'baremetal' role in Kolla\nAnsible. The functionality provided by the 'baremetal' role has been\nextracted into the openstack.kolla Ansible collection, and split\ninto separate roles. This allows Kayobe to use it directly, and only the\nnecessary parts.\n\nThis change improves failure handling in these Kayobe commands, and aims\nto reduce confusion over which '--limit' and '--tags' arguments to\nprovide.  This ensures that if a host fails during a host configuration\ncommand, other hosts are able to continue to completion. Previously, if\nany host failed during the Kayobe playbooks, the 'kolla-ansible\nbootstrap-servers' command would not run. This is useful at scale, where\nhost failures occur more frequently.\n\nThis change has implications for configuration of Kayobe, since some\nvariables that were previously in Kolla Ansible are now in Kayobe.\n\nSeveral parts of the baremetal role have been split out and used here:\n\n* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.\n* docker: Docker installation & configuration. The docker role in\n  openstack.kolla combines functionality from kolla-ansible and kayobe.\n* etc-hosts: it proved difficult to generalise this, so we have some\n  almost duplicated the code from kolla-ansible here. Requires delegated\n  fact gathering for the case when --limit is used.\n* firewall: support to disable UFW, for feature parity.\n* kolla-packages: miscellaneous package installs & removals.\n\nThe addition of the stack user to the docker group has been moved to the\nuser bootstrapping playbook, and the docker SDK installation has been\nmoved to the virtualenv setup playbook.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587\n\nStory: 2009854\nTask: 44505\n\nChange-Id: I61a61ca59652b13687c2247d5881012b51f666a7\n""}]",7,824998,c9f8d80ba63e28ba2278803cecd12da07e8e6516,72,7,26,14826,,,0,"Stop using kolla-ansible bootstrap-servers

The 'kayobe * host configure' commands no longer use the 'kolla-ansible
bootstrap-servers' command, and associated 'baremetal' role in Kolla
Ansible. The functionality provided by the 'baremetal' role has been
extracted into the openstack.kolla Ansible collection, and split
into separate roles. This allows Kayobe to use it directly, and only the
necessary parts.

This change improves failure handling in these Kayobe commands, and aims
to reduce confusion over which '--limit' and '--tags' arguments to
provide.  This ensures that if a host fails during a host configuration
command, other hosts are able to continue to completion. Previously, if
any host failed during the Kayobe playbooks, the 'kolla-ansible
bootstrap-servers' command would not run. This is useful at scale, where
host failures occur more frequently.

This change has implications for configuration of Kayobe, since some
variables that were previously in Kolla Ansible are now in Kayobe.

Several parts of the baremetal role have been split out and used here:

* apparmor-libvirt: disable AppArmor rules for libvirt on Ubuntu.
* docker: Docker installation & configuration. The docker role in
  openstack.kolla combines functionality from kolla-ansible and kayobe.
* etc-hosts: it proved difficult to generalise this, so we have some
  almost duplicated the code from kolla-ansible here. Requires delegated
  fact gathering for the case when --limit is used.
* firewall: support to disable UFW, for feature parity.
* kolla-packages: miscellaneous package installs & removals.

The addition of the stack user to the docker group has been moved to the
user bootstrapping playbook, and the docker SDK installation has been
moved to the virtualenv setup playbook.

Depends-On: https://review.opendev.org/c/openstack/ansible-collection-kolla/+/829587

Story: 2009854
Task: 44505

Change-Id: I61a61ca59652b13687c2247d5881012b51f666a7
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/98/824998/14 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/tests/unit/cli/test_commands.py', 'ansible/roles/docker/handlers/main.yml', 'ansible/overcloud-host-configure.yml', 'ansible/roles/firewall-debian/defaults/main.yml', 'ansible/roles/docker/tasks/main.yml', 'ansible/roles/firewall-debian/tasks/main.yml', 'ansible/roles/etc-hosts/tasks/etc-hosts.yml', 'ansible/roles/etc-hosts/tasks/main.yml', 'ansible/docker.yml', 'ansible/roles/docker/defaults/main.yml', 'ansible/baremetal.yml', 'ansible/roles/etc-hosts/defaults/main.yml', 'ansible/firewall.yml', 'kayobe/cli/commands.py', 'ansible/etc-hosts.yml', 'ansible/seed-host-configure.yml']",16,d06e3361bac69a3e699ac9f8aee7048e10803145,,"- import_playbook: ""docker.yml"" - import_playbook: ""baremetal.yml"" - import_playbook: ""kolla-host.yml""",,140,199
openstack%2Fcharm-keystone-k8s~main~I2d6eeec1ce4a1afd4af86ec69808cb5193355462,openstack/charm-keystone-k8s,main,I2d6eeec1ce4a1afd4af86ec69808cb5193355462,Switch back to using v0.identity_credentials,MERGED,2023-04-13 07:00:02.000000000,2023-04-18 15:44:30.000000000,2023-04-18 14:42:08.000000000,"[{'_account_id': 935}, {'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 07:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/0182ca7a192a9a8a2effcc6939837781449a1b50', 'message': 'Rebuild after ops_sunbeam update\n\nTrigger rebuild to pick up revert to using v0.identity_credentials\nin ops_sunbeam.\n(Ia985e8c147d92ef593b785d18a1c31132d9b1551)\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}, {'number': 2, 'created': '2023-04-13 07:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/85526668d0fb1659ef0aff2f99ccd169e564d0cc', 'message': 'Switch back to using v0.identity_credentials\n\nI misunderstood and v0 Identity credentials actually supersedes v1\ncloud credentials so this change reverts to using\nv0 Identity credentials and implements the update to\nv0 Identity credentials to include internal and public endpoints\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}, {'number': 3, 'created': '2023-04-13 07:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/dbf11fce38fcccc0b1328b6d6fc8c21a7526e12a', 'message': 'Switch back to using v0.identity_credentials\n\nI misunderstood and v0 Identity credentials actually supersedes v1\ncloud credentials so this change reverts to using\nv0 Identity credentials and implements the update to\nv0 Identity credentials to include internal and public endpoints\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}, {'number': 4, 'created': '2023-04-13 08:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/b65092576b9454cebf7532f2679c6ec00c56c5be', 'message': 'Switch back to using v0.identity_credentials\n\nI misunderstood and v0 Identity credentials actually supersedes v1\ncloud credentials so this change reverts to using\nv0 Identity credentials and implements the update to\nv0 Identity credentials to include internal and public endpoints\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}, {'number': 5, 'created': '2023-04-13 19:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/13bc7848e31286faf6df8c85475de2763b46d1ec', 'message': 'Switch back to using v0.identity_credentials\n\nI misunderstood and v0 Identity credentials actually supersedes v1\ncloud credentials so this change reverts to using\nv0 Identity credentials and implements the update to\nv0 Identity credentials to include internal and public endpoints\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}, {'number': 6, 'created': '2023-04-18 11:59:06.000000000', 'files': ['lib/charms/keystone_k8s/v0/identity_credentials.py', 'src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/749b6e4c9b6e4391df8ee52f6c66326c9c5eaaa7', 'message': 'Switch back to using v0.identity_credentials\n\nI misunderstood and v0 Identity credentials actually supersedes v1\ncloud credentials so this change reverts to using\nv0 Identity credentials and implements the update to\nv0 Identity credentials to include internal and public endpoints\n\nChange-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462\n'}]",3,880268,749b6e4c9b6e4391df8ee52f6c66326c9c5eaaa7,23,3,6,12549,,,0,"Switch back to using v0.identity_credentials

I misunderstood and v0 Identity credentials actually supersedes v1
cloud credentials so this change reverts to using
v0 Identity credentials and implements the update to
v0 Identity credentials to include internal and public endpoints

Change-Id: I2d6eeec1ce4a1afd4af86ec69808cb5193355462
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/68/880268/4 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,0182ca7a192a9a8a2effcc6939837781449a1b50,rebuild-for-lib-change,# Trigger charm rebuild 923ca0ae-d9c8-11ed-b815-934ed108d15a ,,2,0
openstack%2Fopenstack-ansible-os_keystone~master~Ibc8267a1c27e1de7ed5bce716199f3264e8c136d,openstack/openstack-ansible-os_keystone,master,Ibc8267a1c27e1de7ed5bce716199f3264e8c136d,Use chain cert file for apache,MERGED,2023-04-07 23:38:26.000000000,2023-04-18 15:30:26.000000000,2023-04-18 15:29:23.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-07 23:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/339dfb2e0e12c9d9f1a034539852ef6a9d144b4a', 'message': 'Use chain cert file for apache\n\nApache needs to respond with all intermediate CA certificates.\nOtherwise, haproxy will not be able to validate backend certificate.\nThat is why -chain.crt file needs to be installed for keystone.\n\nChange-Id: Ibc8267a1c27e1de7ed5bce716199f3264e8c136d\n'}, {'number': 2, 'created': '2023-04-08 12:52:43.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/931695475cbb261678e4571c2523bf6bd4c2bef5', 'message': 'Use chain cert file for apache\n\nApache needs to respond with all intermediate CA certificates.\nOtherwise, haproxy will not be able to validate backend certificate.\nThat is why -chain.crt file needs to be installed for keystone.\n\nChange-Id: Ibc8267a1c27e1de7ed5bce716199f3264e8c136d\n'}]",6,879914,931695475cbb261678e4571c2523bf6bd4c2bef5,18,3,2,32666,,,0,"Use chain cert file for apache

Apache needs to respond with all intermediate CA certificates.
Otherwise, haproxy will not be able to validate backend certificate.
That is why -chain.crt file needs to be installed for keystone.

Change-Id: Ibc8267a1c27e1de7ed5bce716199f3264e8c136d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/14/879914/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,339dfb2e0e12c9d9f1a034539852ef6a9d144b4a,tls-backend," - src: ""{{ keystone_user_ssl_cert | default(keystone_pki_certs_path ~ 'keystone_' ~ ansible_facts['hostname'] ~ '-chain.crt') }}"" condition: ""{{ keystone_user_ssl_ca_cert }}"""," - src: ""{{ keystone_user_ssl_cert | default(keystone_pki_certs_path ~ 'keystone_' ~ ansible_facts['hostname'] ~ '.crt') }}"" condition: ""{{ keystone_ssl }}""",2,2
openstack%2Fironic-python-agent-builder~master~Ifbb1f38700e6b57e1da7be80c27c532aa9949493,openstack/ironic-python-agent-builder,master,Ifbb1f38700e6b57e1da7be80c27c532aa9949493,Add the option to not use tmpfs to build dib images,MERGED,2023-04-12 11:35:06.000000000,2023-04-18 14:58:04.000000000,2023-04-18 14:57:08.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 11:35:06.000000000', 'files': ['roles/ipa-build-dib-image/tasks/main.yaml', 'roles/ipa-build-dib-image/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/5cb69100439e16afdf94f7d9acc0160936e208d7', 'message': 'Add the option to not use tmpfs to build dib images\n\nCurrently the dib images are built on tmpfs mounted partition.\nAs the images become bigger and bigger we may want to use disk\nspace instead of increasing the tmpfs, considering that a\nstandard VM in CI has around 80gb disk space while only\n8gb of RAM.\n\nChange-Id: Ifbb1f38700e6b57e1da7be80c27c532aa9949493\n'}]",1,880146,5cb69100439e16afdf94f7d9acc0160936e208d7,13,3,1,23851,,,0,"Add the option to not use tmpfs to build dib images

Currently the dib images are built on tmpfs mounted partition.
As the images become bigger and bigger we may want to use disk
space instead of increasing the tmpfs, considering that a
standard VM in CI has around 80gb disk space while only
8gb of RAM.

Change-Id: Ifbb1f38700e6b57e1da7be80c27c532aa9949493
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/46/880146/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ipa-build-dib-image/tasks/main.yaml', 'roles/ipa-build-dib-image/defaults/main.yaml']",2,5cb69100439e16afdf94f7d9acc0160936e208d7,dib-no-tmpfs,dib_no_tmpfs: 0,,6,0
openstack%2Fkolla-ansible~master~Id79445c0311916ac6c1beb3986e14f652ee5a63c,openstack/kolla-ansible,master,Id79445c0311916ac6c1beb3986e14f652ee5a63c,Fix maximum width of the DIB Multiline-YAML,MERGED,2022-03-14 14:19:02.000000000,2023-04-18 14:52:51.000000000,2023-04-18 14:51:39.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2022-03-14 14:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c0335710576b912425703b515c6fcbfe5d5d0adc', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 2, 'created': '2022-03-15 15:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/69dd54408d189fc76c6a4d2efabd316b69972a56', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 3, 'created': '2022-03-15 18:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0d3b8c6093092188f927cf4d210ef10985948733', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 4, 'created': '2022-03-15 19:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/99eef51850735af99a9e9a5f8202984bf41cc4e2', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 5, 'created': '2022-03-16 12:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/990db5bcdd7e9215c5e2eb9b4beff3d50126963e', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 6, 'created': '2022-03-16 13:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4c5d275e0fb7efecc06a02ea35443bc390943408', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 7, 'created': '2023-04-02 00:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/68824623902674cd887473699798c94cea4d25c7', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 8, 'created': '2023-04-02 00:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/386c1452dfd11f02b4acb483e30555537c5b6ea0', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 9, 'created': '2023-04-13 10:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cfffaa6c25c751f9039e9544213db4b0df9a4a9e', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}, {'number': 10, 'created': '2023-04-14 13:36:48.000000000', 'files': ['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/47862b56bd90c3edaab3345577901367a73cfd98', 'message': ""Fix maximum width of the DIB Multiline-YAML\n\nThe dib_env_vars variable in the Bifrost's dib.yml file can contain\nthe DIB_BLOCK_DEVICE_CONFIG environment variable which is always the\nMultiline-YAML data. By default, the format of the data is not\npreserved while the configuration is merged and saved for the\nbifrost-deploy container.\n\nThis is because Ansible uses the PyYAML library which has a default\n80 symbol string length limit. The official Ansible documentation [1]\nrecommends using to_yaml or to_nice_yaml filters with width parameter.\nThis change adds the same ability to the merge_yaml Ansible plugin.\n\n1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json\n\nThe related change for the diskimage-builder to solve the issue with\nincorrect data provided by Kolla-Ansible is also provided:\nI3b74ede69eb064ad813a9108ec68a228e549e8bb\n\nCloses-Bug: #2014980\nRelated-Bug: #2014981\nChange-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}]",16,833633,47862b56bd90c3edaab3345577901367a73cfd98,44,5,10,14200,,,0,"Fix maximum width of the DIB Multiline-YAML

The dib_env_vars variable in the Bifrost's dib.yml file can contain
the DIB_BLOCK_DEVICE_CONFIG environment variable which is always the
Multiline-YAML data. By default, the format of the data is not
preserved while the configuration is merged and saved for the
bifrost-deploy container.

This is because Ansible uses the PyYAML library which has a default
80 symbol string length limit. The official Ansible documentation [1]
recommends using to_yaml or to_nice_yaml filters with width parameter.
This change adds the same ability to the merge_yaml Ansible plugin.

1. https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#formatting-data-yaml-and-json

The related change for the diskimage-builder to solve the issue with
incorrect data provided by Kolla-Ansible is also provided:
I3b74ede69eb064ad813a9108ec68a228e549e8bb

Closes-Bug: #2014980
Related-Bug: #2014981
Change-Id: Id79445c0311916ac6c1beb3986e14f652ee5a63c
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/33/833633/10 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/bifrost/tasks/config.yml', 'ansible/action_plugins/merge_yaml.py']",2,c0335710576b912425703b515c6fcbfe5d5d0adc,dib-yaml-width," yaml_width: description: - The maximum width of the YAML document. By default Ansible uses the PyYAML library which has a default 80 symbol string length limit. To break the limit the new value can be used here. default: None required: False type: int yaml_width: 131072 yaml_width = self._task.args.get('yaml_width', None) f.write(dump(output, default_flow_style=False, width=yaml_width))"," f.write(dump(output, default_flow_style=False))",12,1
openstack%2Fopenstack-helm-images~master~I3d9b3454aa253543f29f6f3dfa6048241ae70900,openstack/openstack-helm-images,master,I3d9b3454aa253543f29f6f3dfa6048241ae70900,fix ceph-daemon image missing dependencies.,MERGED,2023-04-13 03:10:18.000000000,2023-04-18 14:17:00.000000000,2023-04-18 13:15:34.000000000,"[{'_account_id': 3009}, {'_account_id': 22348}, {'_account_id': 29974}]","[{'number': 1, 'created': '2023-04-13 03:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/2a32987c3701c60b09925ef7f31362fd8cd8f58c', 'message': 'fix ceph-daemon image based on ubuntu_focal missing dependencies.\n\nThis PS fix ceph mgr modules having failed dependencies\nin ceph-daemon image based on ubuntu_focal.\n\nStory: #47814\nChange-Id: I3d9b3454aa253543f29f6f3dfa6048241ae70900\n'}, {'number': 2, 'created': '2023-04-13 03:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b146c3c0e937f482467f266073644b6fdc10abed', 'message': 'fix ceph-daemon image missing dependencies.\n\nThis PS fix ceph mgr modules having failed dependencies\nin ceph-daemon image based on ubuntu_focal.\n\nStory: #2010697\nChange-Id: I3d9b3454aa253543f29f6f3dfa6048241ae70900\n'}, {'number': 3, 'created': '2023-04-14 02:07:33.000000000', 'files': ['ceph-daemon/Dockerfile.ubuntu_focal'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/699154703cea944e62a2bc00b08d6bfba3a40302', 'message': ""fix ceph-daemon image missing dependencies.\n\nThis PS fix ceph mgr modules having failed dependency with\npython six module in ceph-daemon image based on ubuntu_focal.\n\nBefore this fix, the module six could be found in\n/usr/local/lib/python3.8/dist-packages, and this path is in python3\nsys.path, but somehow, ceph mgr modules can not find\nmodule six. Add '--ignore-installed' in pip3 install cmd can fix this.\n\nStory: #2010697\nChange-Id: I3d9b3454aa253543f29f6f3dfa6048241ae70900\n""}]",9,880253,699154703cea944e62a2bc00b08d6bfba3a40302,20,3,3,32001,,,0,"fix ceph-daemon image missing dependencies.

This PS fix ceph mgr modules having failed dependency with
python six module in ceph-daemon image based on ubuntu_focal.

Before this fix, the module six could be found in
/usr/local/lib/python3.8/dist-packages, and this path is in python3
sys.path, but somehow, ceph mgr modules can not find
module six. Add '--ignore-installed' in pip3 install cmd can fix this.

Story: #2010697
Change-Id: I3d9b3454aa253543f29f6f3dfa6048241ae70900
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/53/880253/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_focal'],1,2a32987c3701c60b09925ef7f31362fd8cd8f58c,story/2010697, python3-pip \ pip3 --no-cache-dir install --upgrade --ignore-installed \, curl -sSL https://bootstrap.pypa.io/pip/3.6/get-pip.py | python3 ;\ pip3 --no-cache-dir install --upgrade \,2,2
openstack%2Ftripleo-ansible~stable%2Fwallaby~If4ce603c432f7790c8f247af76fa469054d38d6c,openstack/tripleo-ansible,stable/wallaby,If4ce603c432f7790c8f247af76fa469054d38d6c,Skip restarting one-short containers unnecessarily,NEW,2023-04-18 03:15:07.000000000,2023-04-18 13:17:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-18 03:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4d88e736e35257694dd92b6a355cb55a52e50b5c', 'message': 'Skip restarting on-short containers unnecessarily\n\nCurrently containers without restart: true flag is always started\nduring deployment, because PodmanManager tries to start an existing\ncontainer even if its definition is not updated.\n\nThis introduces the pre-check to avoid that redundant execution of\nthe container. Containers without restart: true should be re-executed\nonly when container definition (eg. TRIPLEO_CONFIG_HASH environment)\nis changed. In case a specific container should be executed in every\ndeployment attempt then that can be enforced by adding\nthe TRIPLEO_DEPLOYMENT_IDENTIFIER environment.\n\nChange-Id: If4ce603c432f7790c8f247af76fa469054d38d6c\n'}, {'number': 2, 'created': '2023-04-18 04:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/94d54a04fe4447a8efd8e0516a73784a13264dbb', 'message': 'Skip restarting one-short containers unnecessarily\n\nCurrently containers without restart: true flag is always started\nduring deployment, because PodmanManager tries to start an existing\ncontainer even if its definition is not updated.\n\nThis introduces the pre-check to avoid that redundant execution of\nthe container. Containers without restart: true should be re-executed\nonly when container definition (eg. TRIPLEO_CONFIG_HASH environment)\nis changed. In case a specific container should be executed in every\ndeployment attempt then that can be enforced by adding\nthe TRIPLEO_DEPLOYMENT_IDENTIFIER environment.\n\nChange-Id: If4ce603c432f7790c8f247af76fa469054d38d6c\n'}, {'number': 3, 'created': '2023-04-18 12:14:08.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_container_manage.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8e8337a79f490c8b841a243321bb3b7907782cc1', 'message': 'Skip restarting one-short containers unnecessarily\n\nCurrently containers without restart: true flag is always started\nduring deployment, because PodmanManager tries to start an existing\ncontainer even if its definition is not updated.\n\nThis introduces the pre-check to avoid that redundant execution of\nthe container. Containers without restart: true should be re-executed\nonly when container definition (eg. TRIPLEO_CONFIG_HASH environment)\nis changed. In case a specific container should be executed in every\ndeployment attempt then that can be enforced by adding\nthe TRIPLEO_DEPLOYMENT_IDENTIFIER environment.\n\nChange-Id: If4ce603c432f7790c8f247af76fa469054d38d6c\n'}]",1,880702,8e8337a79f490c8b841a243321bb3b7907782cc1,5,1,3,9816,,,0,"Skip restarting one-short containers unnecessarily

Currently containers without restart: true flag is always started
during deployment, because PodmanManager tries to start an existing
container even if its definition is not updated.

This introduces the pre-check to avoid that redundant execution of
the container. Containers without restart: true should be re-executed
only when container definition (eg. TRIPLEO_CONFIG_HASH environment)
is changed. In case a specific container should be executed in every
deployment attempt then that can be enforced by adding
the TRIPLEO_DEPLOYMENT_IDENTIFIER environment.

Change-Id: If4ce603c432f7790c8f247af76fa469054d38d6c
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/02/880702/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/tripleo_container_manage.py'],1,4d88e736e35257694dd92b6a355cb55a52e50b5c,," manager = PodmanManager(self.module, container_opts) if manager.recreate or manager.container.different: manager.execute()"," PodmanManager(self.module, container_opts).execute()",3,1
openstack%2Fcharm-octavia~stable%2Fzed~Ic91d1c2ecfdc98671782377b5ff87793c3d1df61,openstack/charm-octavia,stable/zed,Ic91d1c2ecfdc98671782377b5ff87793c3d1df61,"Drop ""voting: false"" for jammy-zed jobs.",MERGED,2023-03-22 13:57:54.000000000,2023-04-18 13:13:56.000000000,2023-04-18 13:13:56.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-22 13:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/de95fd076c59d1789cc4fec8ce2e7d28a536dce3', 'message': 'Drop ""voting: false"" for jammy-zed jobs.\n\nChange-Id: Ic91d1c2ecfdc98671782377b5ff87793c3d1df61\n'}, {'number': 2, 'created': '2023-04-17 17:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/f7dff7ba5f9bd5de7d650cd10d58f9782f3de095', 'message': 'Drop ""voting: false"" for jammy-zed jobs.\n\nSummary of changes:\n\n- Update ovn-* channel from 22.03 to 22.09\n\nChange-Id: Ic91d1c2ecfdc98671782377b5ff87793c3d1df61\n'}, {'number': 3, 'created': '2023-04-17 20:09:18.000000000', 'files': ['src/tests/bundles/kinetic-zed-ha-ovn.yaml', 'osci.yaml', 'src/tests/bundles/jammy-zed-ha-ovn.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/4a58f9735b794393432b237e8b294b26781db6d9', 'message': 'Drop ""voting: false"" for jammy-zed jobs.\n\nSummary of changes:\n\n- Update ovn-* channel from 22.03 to 22.09\n- Fix zosci jobs dependencies\n\nChange-Id: Ic91d1c2ecfdc98671782377b5ff87793c3d1df61\n'}]",5,878224,4a58f9735b794393432b237e8b294b26781db6d9,20,4,3,2424,,,0,"Drop ""voting: false"" for jammy-zed jobs.

Summary of changes:

- Update ovn-* channel from 22.03 to 22.09
- Fix zosci jobs dependencies

Change-Id: Ic91d1c2ecfdc98671782377b5ff87793c3d1df61
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/24/878224/2 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'tox.ini']",2,de95fd076c59d1789cc4fec8ce2e7d28a536dce3,voting-jobs, charm-tools<3.1, git+https://github.com/juju/charm-tools.git,3,5
openstack%2Fcharm-octavia~stable%2Fzed~I93320047cfa70edfbd4ef35fc278b80c7f0a4ddc,openstack/charm-octavia,stable/zed,I93320047cfa70edfbd4ef35fc278b80c7f0a4ddc,Update charmcraft to 2.1 and fix CI,ABANDONED,2023-02-15 15:02:38.000000000,2023-04-18 13:08:41.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-15 15:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/398b7d6b06dbf817a0078cc56bcc30244c621d9b', 'message': 'Update charmcraft to 2.1\n\nChange-Id: I93320047cfa70edfbd4ef35fc278b80c7f0a4ddc\n'}, {'number': 2, 'created': '2023-02-16 15:53:36.000000000', 'files': ['osci.yaml', 'charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/f617f424d0a3699d084d3cb1acc20b4d9e67532a', 'message': 'Update charmcraft to 2.1 and fix CI\n\nChange-Id: I93320047cfa70edfbd4ef35fc278b80c7f0a4ddc\n'}]",1,873938,f617f424d0a3699d084d3cb1acc20b4d9e67532a,9,2,2,14567,,,0,"Update charmcraft to 2.1 and fix CI

Change-Id: I93320047cfa70edfbd4ef35fc278b80c7f0a4ddc
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/38/873938/1 && git format-patch -1 --stdout FETCH_HEAD,['osci.yaml'],1,398b7d6b06dbf817a0078cc56bcc30244c621d9b,, charmcraft_channel: 2.1/stable, charmcraft_channel: 2.0/stable,1,1
openstack%2Fansible-collections-openstack~master~I4a0cda46cb160b5321913b63ff1123d8b8a19705,openstack/ansible-collections-openstack,master,I4a0cda46cb160b5321913b63ff1123d8b8a19705,Change security group rules only when instructed to do so,MERGED,2023-04-06 06:54:03.000000000,2023-04-18 13:02:17.000000000,2023-04-18 13:02:17.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-04-06 06:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/398b2a1c8d5142a8ec85c8c8e4bdb47d67b5b9ca', 'message': 'Change security group rules only when instructed to do so\n\nSecurity group rules in module openstack.cloud.security_group\nare changed/updated only when option \'security_group_rules\' was\ndefined explicitly. This follows our policy of ""apply no change""\nwhen module options in our Ansible modules have not been set.\n\nStory: 2010691\nTask: 47795\nChange-Id: I4a0cda46cb160b5321913b63ff1123d8b8a19705\n'}, {'number': 2, 'created': '2023-04-06 08:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2500c73842eeacb054e3dce80852591c8484afad', 'message': 'Change security group rules only when instructed to do so\n\nSecurity group rules in module openstack.cloud.security_group\nare changed/updated only when option \'security_group_rules\' was\ndefined explicitly. This follows our policy of ""apply no change""\nwhen module options in our Ansible modules have not been set.\n\nStory: 2010691\nTask: 47795\nChange-Id: I4a0cda46cb160b5321913b63ff1123d8b8a19705\n'}, {'number': 3, 'created': '2023-04-18 06:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/de975b7e0fffff812478226d6302b339d41d55b8', 'message': 'Change security group rules only when instructed to do so\n\nSecurity group rules in module openstack.cloud.security_group\nare changed/updated only when option \'security_group_rules\' was\ndefined explicitly. This follows our policy of ""apply no change""\nwhen module options in our Ansible modules have not been set.\n\nStory: 2010691\nTask: 47795\nChange-Id: I4a0cda46cb160b5321913b63ff1123d8b8a19705\n'}, {'number': 4, 'created': '2023-04-18 06:46:25.000000000', 'files': ['plugins/modules/security_group.py', 'ci/roles/security_group/tasks/rules.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ab6f2e45c6daf02ec43e8c142cf3852608e47fa1', 'message': 'Change security group rules only when instructed to do so\n\nSecurity group rules in module openstack.cloud.security_group\nare changed/updated only when option \'security_group_rules\' was\ndefined explicitly. This follows our policy of ""apply no change""\nwhen module options in our Ansible modules have not been set.\n\nStory: 2010691\nTask: 47795\nChange-Id: I4a0cda46cb160b5321913b63ff1123d8b8a19705\n'}]",0,879725,ab6f2e45c6daf02ec43e8c142cf3852608e47fa1,12,4,4,32962,,,0,"Change security group rules only when instructed to do so

Security group rules in module openstack.cloud.security_group
are changed/updated only when option 'security_group_rules' was
defined explicitly. This follows our policy of ""apply no change""
when module options in our Ansible modules have not been set.

Story: 2010691
Task: 47795
Change-Id: I4a0cda46cb160b5321913b63ff1123d8b8a19705
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/25/879725/4 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/security_group.py'],1,398b2a1c8d5142a8ec85c8c8e4bdb47d67b5b9ca,release," - When I(security_group_rules) is not set, existing security group rules which are not listed in I(security_group_rules) will be deleted. if self.params['security_group_rules'] is None: # Consider a change of security group rules only when option # 'security_group_rules' was defined explicitly, because undefined # options in our Ansible modules denote ""apply no change"" return {} ", - Existing security group rules which are not listed in I(security_group_rules) will be deleted.,8,2
openstack%2Fcharm-glance-k8s~main~Ib0e5154d2e678ec341a83ed75e09aa266680b55f,openstack/charm-glance-k8s,main,Ib0e5154d2e678ec341a83ed75e09aa266680b55f,tests: Switch to using mysql stable channel,MERGED,2023-04-17 14:49:52.000000000,2023-04-18 12:51:01.000000000,2023-04-18 11:50:09.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 14:49:52.000000000', 'files': ['tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/444dfbbd3d6060a065099b19f0599787f4a80a68', 'message': 'tests: Switch to using mysql stable channel\n\nUpdate mysql-k8s to 8.0/stable channel.\n\nChange-Id: Ib0e5154d2e678ec341a83ed75e09aa266680b55f\n'}]",1,880642,444dfbbd3d6060a065099b19f0599787f4a80a68,7,2,1,935,,,0,"tests: Switch to using mysql stable channel

Update mysql-k8s to 8.0/stable channel.

Change-Id: Ib0e5154d2e678ec341a83ed75e09aa266680b55f
",git fetch https://review.opendev.org/openstack/charm-glance-k8s refs/changes/42/880642/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/smoke.yaml'],1,444dfbbd3d6060a065099b19f0599787f4a80a68,use-stable-mysql, channel: 8.0/stable, channel: edge,1,1
openstack%2Fcharm-cinder-k8s~main~I5e63fd94bff77c0a236a1327ce18d3992e4a3590,openstack/charm-cinder-k8s,main,I5e63fd94bff77c0a236a1327ce18d3992e4a3590,tests: Use mysql stable channel,MERGED,2023-04-17 14:47:20.000000000,2023-04-18 12:50:56.000000000,2023-04-18 11:49:49.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 14:47:20.000000000', 'files': ['tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-k8s/commit/39c0a1346447a3464446b2c4b9b1b41d8a9dad36', 'message': 'tests: Use mysql stable channel\n\nSwitch channel for mysql-k8s to 8.0/stable.\n\nChange-Id: I5e63fd94bff77c0a236a1327ce18d3992e4a3590\n'}]",1,880641,39c0a1346447a3464446b2c4b9b1b41d8a9dad36,7,2,1,935,,,0,"tests: Use mysql stable channel

Switch channel for mysql-k8s to 8.0/stable.

Change-Id: I5e63fd94bff77c0a236a1327ce18d3992e4a3590
",git fetch https://review.opendev.org/openstack/charm-cinder-k8s refs/changes/41/880641/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/smoke.yaml'],1,39c0a1346447a3464446b2c4b9b1b41d8a9dad36,use-stable-mysql, channel: 8.0/stable, channel: edge,1,1
openstack%2Fcharm-cinder-ceph-k8s~main~Iefb83137dafa724ae01af0d0925b03d3f3d2b452,openstack/charm-cinder-ceph-k8s,main,Iefb83137dafa724ae01af0d0925b03d3f3d2b452,tests: use mysql-k8s stable channel,MERGED,2023-04-17 14:46:27.000000000,2023-04-18 12:50:16.000000000,2023-04-18 11:49:17.000000000,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 14:46:27.000000000', 'files': ['tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph-k8s/commit/f067f1b2f9d7ae64c406617b8c63952a1b385601', 'message': 'tests: use mysql-k8s stable channel\n\nUpdate channel for mysql-k8s to 8.0/stable.\n\nChange-Id: Iefb83137dafa724ae01af0d0925b03d3f3d2b452\n'}]",1,880640,f067f1b2f9d7ae64c406617b8c63952a1b385601,8,3,1,935,,,0,"tests: use mysql-k8s stable channel

Update channel for mysql-k8s to 8.0/stable.

Change-Id: Iefb83137dafa724ae01af0d0925b03d3f3d2b452
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph-k8s refs/changes/40/880640/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/smoke.yaml'],1,f067f1b2f9d7ae64c406617b8c63952a1b385601,use-stable-mysql, channel: 8.0/stable, channel: edge,1,1
openstack%2Ftripleo-ansible~master~Iae5e0c8272eeb3282f232ab5f35911ec1b82a048,openstack/tripleo-ansible,master,Iae5e0c8272eeb3282f232ab5f35911ec1b82a048,Add flag to enable nmstate provider for os-net-config,MERGED,2023-03-17 05:59:59.000000000,2023-04-18 12:50:07.000000000,2023-04-18 12:49:00.000000000,"[{'_account_id': 12398}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2023-03-17 05:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b37908be7c5e44a185b499ed9d364a0bb47f4ee1', 'message': 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py\n\nChange-Id: Iae5e0c8272eeb3282f232ab5f35911ec1b82a048\n'}, {'number': 2, 'created': '2023-03-17 06:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0549ae9d1ac71cfcb236b501a428b835fb2598c1', 'message': 'Add flag to enable nmstate provider for os-net-config\n\nos-net-config will support new provider nmstate [1].\nTo choose nmstate during deployment [2], updating\nbaremetal schema to support the flag\n\n[1] https://issues.redhat.com/browse/NFV-2564\n[2] https://github.com/openstack/tripleo-ansible/blob/master/tripleo_ansible/roles/tripleo_network_config/defaults/main.yml#L29\n\nChange-Id: Iae5e0c8272eeb3282f232ab5f35911ec1b82a048\n'}, {'number': 3, 'created': '2023-04-04 12:27:22.000000000', 'files': ['tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6973ae093bee9ab33de03aa4155b112ae96a582d', 'message': 'Add flag to enable nmstate provider for os-net-config\n\nos-net-config will support new provider nmstate.\nTo choose nmstate during deployment [1], updating\nbaremetal schema to support the flag\n\n[1] https://github.com/openstack/tripleo-ansible/blob/master/tripleo_ansible/roles/tripleo_network_config/defaults/main.yml#L29\n\nChange-Id: Iae5e0c8272eeb3282f232ab5f35911ec1b82a048\n'}]",0,877738,6973ae093bee9ab33de03aa4155b112ae96a582d,14,5,3,33688,,,0,"Add flag to enable nmstate provider for os-net-config

os-net-config will support new provider nmstate.
To choose nmstate during deployment [1], updating
baremetal schema to support the flag

[1] https://github.com/openstack/tripleo-ansible/blob/master/tripleo_ansible/roles/tripleo_network_config/defaults/main.yml#L29

Change-Id: Iae5e0c8272eeb3282f232ab5f35911ec1b82a048
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/38/877738/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py'],1,b37908be7c5e44a185b499ed9d364a0bb47f4ee1,osnet_nm_updt," 'nmstate': {'type': 'boolean'},",,1,0
openstack%2Fcharm-ceph-mon~stable%2Foctopus~I183207e91e4dea66dd128f2b42b8d03382b655e4,openstack/charm-ceph-mon,stable/octopus,I183207e91e4dea66dd128f2b42b8d03382b655e4,Update charmcraft.yaml's run-on,MERGED,2023-03-31 16:28:25.000000000,2023-04-18 12:49:35.000000000,2023-04-18 12:49:35.000000000,"[{'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-31 16:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/d274058d37647c146d1f1584ee7fa6fb8dcb8c49', 'message': ""Update charmcraft.yaml's run-on\n\nChange-Id: I183207e91e4dea66dd128f2b42b8d03382b655e4\n""}, {'number': 2, 'created': '2023-03-31 16:58:37.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/c329580dab235bb9e6a5741d95dd7061fd1748f0', 'message': ""Update charmcraft.yaml's run-on\n\nThis patchset updates the charmcraft.yaml file so that it's set to\nrun on 20.04, thus supporting the focal series on the charm's\noctopus channel.\n\nChange-Id: I183207e91e4dea66dd128f2b42b8d03382b655e4\nCloses-bug: #2013987\n""}]",4,879197,c329580dab235bb9e6a5741d95dd7061fd1748f0,14,4,2,33717,,,0,"Update charmcraft.yaml's run-on

This patchset updates the charmcraft.yaml file so that it's set to
run on 20.04, thus supporting the focal series on the charm's
octopus channel.

Change-Id: I183207e91e4dea66dd128f2b42b8d03382b655e4
Closes-bug: #2013987
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/97/879197/2 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,d274058d37647c146d1f1584ee7fa6fb8dcb8c49,fix-build-on-octopus," - name: ubuntu channel: ""20.04"" architectures: [amd64, s390x, ppc64el, arm64]",,3,0
openstack%2Ftrove~master~Ica14e66d2130dbc5949a6567673e68e8bb450061,openstack/trove,master,Ica14e66d2130dbc5949a6567673e68e8bb450061,Fix inspect.getargspec() deprecation warning,MERGED,2021-05-10 09:41:51.000000000,2023-04-18 12:49:18.000000000,2023-04-18 12:48:06.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-05-10 09:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0df1d49d0ae6ff156a09931fb7a89766c9452d74', 'message': 'Fix inspect.getargspec() deprecation warning\n\nDeprecationWarning: inspect.getargspec() is deprecated,\nuse inspect.signature() or inspect.getfullargspec()\n\n[1] https://docs.python.org/3/library/inspect.html#inspect.getargspec\n\nChange-Id: Ica14e66d2130dbc5949a6567673e68e8bb450061\n'}, {'number': 2, 'created': '2023-04-18 09:46:58.000000000', 'files': ['trove/cmd/manage.py', 'trove/common/utils.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/18a83dbaf1e72b4b7ea3b4598328e947d5a372b2', 'message': 'Fix inspect.getargspec() deprecation warning\n\nDeprecationWarning: inspect.getargspec() is deprecated,\nuse inspect.signature() or inspect.getfullargspec()\n\n[1] https://docs.python.org/3/library/inspect.html#inspect.getargspec\n\nStory: 2010694\nTask: 47804\n\nChange-Id: Ica14e66d2130dbc5949a6567673e68e8bb450061\n'}]",1,790392,18a83dbaf1e72b4b7ea3b4598328e947d5a372b2,11,3,2,32029,,,0,"Fix inspect.getargspec() deprecation warning

DeprecationWarning: inspect.getargspec() is deprecated,
use inspect.signature() or inspect.getfullargspec()

[1] https://docs.python.org/3/library/inspect.html#inspect.getargspec

Story: 2010694
Task: 47804

Change-Id: Ica14e66d2130dbc5949a6567673e68e8bb450061
",git fetch https://review.opendev.org/openstack/trove refs/changes/92/790392/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/cmd/manage.py', 'trove/common/utils.py']",2,0df1d49d0ae6ff156a09931fb7a89766c9452d74,deprecation-warning, return inspect.getfullargspec(self._func), return inspect.getargspec(self._func),2,2
openstack%2Ftripleo-validations~stable%2Fwallaby~Ia433af1bfd9b55d5f12e03312610066eabe78aa5,openstack/tripleo-validations,stable/wallaby,Ia433af1bfd9b55d5f12e03312610066eabe78aa5,Remove oslo validations for backup and restore,MERGED,2023-04-12 16:12:09.000000000,2023-04-18 12:49:02.000000000,2023-04-18 12:49:02.000000000,"[{'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 22954}]","[{'number': 1, 'created': '2023-04-12 16:12:09.000000000', 'files': ['playbooks/oslo-config-validator.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/c768acb842be135b54207f0944dd4f10de203d80', 'message': 'Remove oslo validations for backup and restore\n\nOslo validations are used to verify the configuration of the running services, and this is not relevant for the backup and restore workflow so this change removes backup and restore from the group list\n\nChange-Id: Ia433af1bfd9b55d5f12e03312610066eabe78aa5\n(cherry picked from commit 12bad0a811801bbd1abc2a99a842818fe6b406eb)\n'}]",0,880171,c768acb842be135b54207f0944dd4f10de203d80,6,3,1,34423,,,0,"Remove oslo validations for backup and restore

Oslo validations are used to verify the configuration of the running services, and this is not relevant for the backup and restore workflow so this change removes backup and restore from the group list

Change-Id: Ia433af1bfd9b55d5f12e03312610066eabe78aa5
(cherry picked from commit 12bad0a811801bbd1abc2a99a842818fe6b406eb)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/71/880171/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/oslo-config-validator.yaml'],1,c768acb842be135b54207f0944dd4f10de203d80,bnr-remove-oslo-stable/zed-stable/wallaby,, - backup-and-restore,0,1
openstack%2Fcharm-nova-k8s~main~Ie8002b0ffe0ae1926c22979b412734e01444d69b,openstack/charm-nova-k8s,main,Ie8002b0ffe0ae1926c22979b412734e01444d69b,tests: Use mysql stable channel,MERGED,2023-04-17 14:54:14.000000000,2023-04-18 12:48:52.000000000,2023-04-18 11:48:10.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 14:54:14.000000000', 'files': ['tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-k8s/commit/1eeade0626b730d909010c0ba9f7d64b78516c6f', 'message': 'tests: Use mysql stable channel\n\nUpdate mysql-k8s to use 8.0/stable channel.\n\nChange-Id: Ie8002b0ffe0ae1926c22979b412734e01444d69b\n'}]",1,880647,1eeade0626b730d909010c0ba9f7d64b78516c6f,7,2,1,935,,,0,"tests: Use mysql stable channel

Update mysql-k8s to use 8.0/stable channel.

Change-Id: Ie8002b0ffe0ae1926c22979b412734e01444d69b
",git fetch https://review.opendev.org/openstack/charm-nova-k8s refs/changes/47/880647/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/smoke.yaml'],1,1eeade0626b730d909010c0ba9f7d64b78516c6f,use-stable-mysql, channel: 8.0/stable, channel: edge,1,1
openstack%2Fcharm-neutron-k8s~main~If17553e614c00e7060f28d79b9fac022642faf08,openstack/charm-neutron-k8s,main,If17553e614c00e7060f28d79b9fac022642faf08,tests: Use mysql stable channel,MERGED,2023-04-17 14:53:10.000000000,2023-04-18 12:44:02.000000000,2023-04-18 11:42:55.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 14:53:10.000000000', 'files': ['tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/a0e7cd7dc03611c07f4868660e8dde2753a5c391', 'message': 'tests: Use mysql stable channel\n\nUpdate mysql-k8s to use 8.0/stable channel.\n\nChange-Id: If17553e614c00e7060f28d79b9fac022642faf08\n'}]",1,880645,a0e7cd7dc03611c07f4868660e8dde2753a5c391,7,2,1,935,,,0,"tests: Use mysql stable channel

Update mysql-k8s to use 8.0/stable channel.

Change-Id: If17553e614c00e7060f28d79b9fac022642faf08
",git fetch https://review.opendev.org/openstack/charm-neutron-k8s refs/changes/45/880645/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/smoke.yaml'],1,a0e7cd7dc03611c07f4868660e8dde2753a5c391,use-stable-mysql, channel: 8.0/stable, channel: edge,1,1
openstack%2Fcharm-keystone-k8s~main~I50183414b86ccbee7e38e6f6f8437bdb2dbfce74,openstack/charm-keystone-k8s,main,I50183414b86ccbee7e38e6f6f8437bdb2dbfce74,Update kubernetes_service_patch to v1,MERGED,2023-04-13 08:13:57.000000000,2023-04-18 12:44:00.000000000,2023-04-18 11:42:43.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 08:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/074ecb0ef2eb8fe9fe674d3f9cde6f5563347171', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}, {'number': 2, 'created': '2023-04-13 10:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/a1ae70f438e15ae7f2a4fc28c3bbcd622c96e0bd', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}, {'number': 3, 'created': '2023-04-13 17:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/336216d912e52c7e5bfdfad3ba58fd62a0d95357', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}, {'number': 4, 'created': '2023-04-14 07:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/2fd860db7167ffc8d75a8aa9b979b3cf16a97667', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}, {'number': 5, 'created': '2023-04-18 06:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/087f814eae603b38a7f925119982d19bb09c08e4', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}, {'number': 6, 'created': '2023-04-18 10:09:29.000000000', 'files': ['tests/tests.yaml', 'lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/bundles/smoke.yaml', 'tests/unit/test_keystone_charm.py', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/622382805d0a8c71aa618e8dbbde978fd4888b64', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74\n'}]",6,880271,622382805d0a8c71aa618e8dbbde978fd4888b64,24,2,6,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
Change-Id: I50183414b86ccbee7e38e6f6f8437bdb2dbfce74
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/71/880271/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/unit/test_keystone_charm.py', 'fetch-libs.sh']",3,074ecb0ef2eb8fe9fe674d3f9cde6f5563347171,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,charmcraft fetch-lib charms.observability_libs.v0.kubernetes_service_patch,113,51
openstack%2Fcinder~master~I227d2db4ccfbca2b8eab9930edbcc374c63e742a,openstack/cinder,master,I227d2db4ccfbca2b8eab9930edbcc374c63e742a,Fix reference in datera unit tests,NEW,2023-04-12 17:09:08.000000000,2023-04-18 12:39:22.000000000,,"[{'_account_id': 4523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 17:09:08.000000000', 'files': ['cinder/tests/unit/volume/drivers/test_datera.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a30942135d8095201849d8354388e499edcd876a', 'message': ""Fix reference in datera unit tests\n\nThis has suddenly started failing for me locally in py310.  Not sure\nwhy it took so long, because the cinder.volume.utils module hasn't\nexisted since change I3cdf445ac9ab89b about 4 years ago.\n\nChange-Id: I227d2db4ccfbca2b8eab9930edbcc374c63e742a\n""}]",1,880211,a30942135d8095201849d8354388e499edcd876a,21,2,1,5314,,,0,"Fix reference in datera unit tests

This has suddenly started failing for me locally in py310.  Not sure
why it took so long, because the cinder.volume.utils module hasn't
existed since change I3cdf445ac9ab89b about 4 years ago.

Change-Id: I227d2db4ccfbca2b8eab9930edbcc374c63e742a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/880211/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/volume/drivers/test_datera.py'],1,a30942135d8095201849d8354388e499edcd876a,datera, 'cinder.volume.volume_utils.paginate_entries_list') \ as mpage:, 'cinder.volume.utils.paginate_entries_list') as mpage:,2,1
openstack%2Fpuppet-openstack-integration~stable%2F2023.1~Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8,openstack/puppet-openstack-integration,stable/2023.1,Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8,"Revert ""Ubuntu: Add nova to kvm group""",MERGED,2023-04-18 01:59:31.000000000,2023-04-18 12:34:23.000000000,2023-04-18 12:34:23.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 01:59:31.000000000', 'files': ['manifests/nova.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/e1eb6b09f24deaf38210823a4a9b7afe0be4fa0b', 'message': 'Revert ""Ubuntu: Add nova to kvm group""\n\nThis reverts commit f1d729fc6172e7d8b3c2896ad8abebaf5a51ba14.\n\nReason for revert:\nThe issue has been fixed in the latest nova package in UCA.\n\nRelated-Bug: #2011535\nChange-Id: Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8\n(cherry picked from commit 5e832f8446f35045257f225c91b22cdafd9e3a3a)\n'}]",1,880597,e1eb6b09f24deaf38210823a4a9b7afe0be4fa0b,10,2,1,9816,,,0,"Revert ""Ubuntu: Add nova to kvm group""

This reverts commit f1d729fc6172e7d8b3c2896ad8abebaf5a51ba14.

Reason for revert:
The issue has been fixed in the latest nova package in UCA.

Related-Bug: #2011535
Change-Id: Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8
(cherry picked from commit 5e832f8446f35045257f225c91b22cdafd9e3a3a)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/97/880597/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/nova.pp'],1,e1eb6b09f24deaf38210823a4a9b7afe0be4fa0b,,," # Remove this once fix for bug 2011535 is released if $facts['os']['name'] == 'Ubuntu' { user { 'nova': ensure => present, name => 'nova', groups => ['nova', 'kvm', 'libvirt-qemu'], require => Anchor['nova::install::end'], before => Anchor['nova::service::begin'], } } ",0,11
openstack%2Freleases~master~I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7,openstack/releases,master,I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7,Release tooz 4.0.0,MERGED,2023-04-17 16:07:04.000000000,2023-04-18 12:22:22.000000000,2023-04-18 12:22:22.000000000,"[{'_account_id': 15334}, {'_account_id': 16137}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-04-17 16:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fd8dccf6d71d21526cde2075863d4123514ac26e', 'message': 'Release tooz 3.3.0\n\nChange-Id: I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7\n'}, {'number': 2, 'created': '2023-04-18 10:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0bedec9cc320f40c77dafa863d834b7fc4fd0232', 'message': 'Release tooz 3.3.0\n\nChange-Id: I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7\n'}, {'number': 3, 'created': '2023-04-18 10:33:22.000000000', 'files': ['deliverables/_independent/tooz.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a6eb6ac0f38909992b87ebe3d9040d4ad4e01a3a', 'message': 'Release tooz 4.0.0\n\nChange-Id: I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7\n'}]",2,880662,a6eb6ac0f38909992b87ebe3d9040d4ad4e01a3a,16,6,3,12404,,,0,"Release tooz 4.0.0

Change-Id: I0af8f54bc159ed3d3c969ba8f56cce29ad15efe7
",git fetch https://review.opendev.org/openstack/releases refs/changes/62/880662/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/tooz.yaml'],1,fd8dccf6d71d21526cde2075863d4123514ac26e,release-tooz, - version: 3.3.0 projects: - repo: openstack/tooz hash: db64c2175c01f896f40ee2aa420cbb58ce30e4dd,,4,0
openstack%2Fopenstack-helm-images~master~I43b28c9176e2589684d7f1d3354a59d565c3f36a,openstack/openstack-helm-images,master,I43b28c9176e2589684d7f1d3354a59d565c3f36a,WIP: Debug: Jammy Overrides and ubuntu-focal-dpdk,ABANDONED,2023-04-11 17:19:44.000000000,2023-04-18 12:22:04.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-11 17:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/39651a30cd2fba075a39b0c8cfc716b1ce3997e4', 'message': 'Debug: Jammy Overrides and ubuntu-focal-dpdk\n\nChange-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a\n'}, {'number': 2, 'created': '2023-04-11 18:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f58ed4d9e582459d945826a916f210657629de92', 'message': 'Debug: Jammy Overrides and ubuntu-focal-dpdk\n\nChange-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a\n'}, {'number': 3, 'created': '2023-04-11 20:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/66c1947fc8c533be23c00bd89203b453ff8177d2', 'message': 'Debug: Jammy Overrides and ubuntu-focal-dpdk\n\nChange-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a\n'}, {'number': 4, 'created': '2023-04-11 20:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/56f5eb9a29b5aabe3204dd406023a9fde6ec8643', 'message': 'Debug: Jammy Overrides and ubuntu-focal-dpdk\n\nChange-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a\n'}, {'number': 5, 'created': '2023-04-12 00:13:10.000000000', 'files': ['libvirt/ubuntu-install-libvirt-jammy-override.sh', 'Makefile', 'libvirt/Dockerfile.ubuntu_jammy', 'openvswitch/Dockerfile.ubuntu_focal-dpdk', 'zuul.d/openvswitch.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/91af3136d00125280b667e02bd15f9d5e8b49845', 'message': 'WIP: Debug: Jammy Overrides and ubuntu-focal-dpdk\n\nChange-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a\n'}]",0,880072,91af3136d00125280b667e02bd15f9d5e8b49845,10,1,5,3009,,,0,"WIP: Debug: Jammy Overrides and ubuntu-focal-dpdk

Change-Id: I43b28c9176e2589684d7f1d3354a59d565c3f36a
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/72/880072/1 && git format-patch -1 --stdout FETCH_HEAD,"['libvirt/ubuntu-install-libvirt-jammy-override.sh', 'Makefile', 'libvirt/Dockerfile.ubuntu_jammy', 'openvswitch/Dockerfile.ubuntu_focal-dpdk', 'zuul.d/openvswitch.yaml']",5,39651a30cd2fba075a39b0c8cfc716b1ce3997e4,," dockerfile: Dockerfile.ubuntu_focal-dpdk tags: - latest-ubuntu_focal-dpdk - ""ubuntu_focal-dpdk-{{ currentdate }}"""," dockerfile: Dockerfile.ubuntu_bionic-dpdk tags: - latest-ubuntu_bionic-dpdk - ""ubuntu_bionic-dpdk-{{ currentdate }}""",72,12
openstack%2Fcinder~master~Id3dc2f30695c3685d81e8562f4b12048112fda83,openstack/cinder,master,Id3dc2f30695c3685d81e8562f4b12048112fda83,DNM - Netapp test to add upstream-check REST jobs with file filter to trigger only in Netapp driver on Cinder,NEW,2023-04-14 17:27:01.000000000,2023-04-18 12:02:56.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 17:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3ec7599690abd4f7026ce1c1ec3def08aef8078f', 'message': 'DNM - Netapp test to add upstream-check REST jobs with file filter to trigger only in Netapp driver on Cinder\n\nChange-Id: Id3dc2f30695c3685d81e8562f4b12048112fda83\n'}, {'number': 2, 'created': '2023-04-17 13:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8cbae144bf0d5e7221114516bee263388ac6fe75', 'message': 'DNM - Netapp test to add upstream-check REST jobs with file filter to trigger only in Netapp driver on Cinder\n\nChange-Id: Id3dc2f30695c3685d81e8562f4b12048112fda83\n'}, {'number': 3, 'created': '2023-04-17 13:38:23.000000000', 'files': ['cinder/volume/drivers/netapp/common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/489cc69c05e29cca0a99bbec82a4ab6deeb63712', 'message': 'DNM - Netapp test to add upstream-check REST jobs with file filter to trigger only in Netapp driver on Cinder\n\nChange-Id: Id3dc2f30695c3685d81e8562f4b12048112fda83\n'}]",4,880513,489cc69c05e29cca0a99bbec82a4ab6deeb63712,40,1,3,35002,,,0,"DNM - Netapp test to add upstream-check REST jobs with file filter to trigger only in Netapp driver on Cinder

Change-Id: Id3dc2f30695c3685d81e8562f4b12048112fda83
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/880513/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/netapp/common.py'],1,3ec7599690abd4f7026ce1c1ec3def08aef8078f,,#Teste Netapp luizsantos,#Teste Netapp,1,1
openstack%2Fansible-collections-openstack~master~I7c0680ca084d05ad46d25c6fe74fcee56482634d,openstack/ansible-collections-openstack,master,I7c0680ca084d05ad46d25c6fe74fcee56482634d,VPN ike policy module,NEW,2023-04-14 14:04:46.000000000,2023-04-18 11:58:55.000000000,,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-04-14 14:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bc826c0212de4c3e105a83e863ebf9b82b672629', 'message': 'VPN ike policy module\n\nChange-Id: I7c0680ca084d05ad46d25c6fe74fcee56482634d\n'}, {'number': 2, 'created': '2023-04-14 21:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/060a1f6084749340868d9213160b5291c2c1134b', 'message': 'VPN ike policy module\n\nChange-Id: I7c0680ca084d05ad46d25c6fe74fcee56482634d\n'}, {'number': 3, 'created': '2023-04-18 10:24:00.000000000', 'files': ['plugins/modules/vpn_ike_policy.py', 'meta/runtime.yml', 'ci/roles/vpn_service/tasks/main.yml', 'ci/roles/vpn_service/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/20caae664b73db4a03969328a66d86f244e91605', 'message': 'VPN ike policy module\n\nChange-Id: I7c0680ca084d05ad46d25c6fe74fcee56482634d\n'}]",18,880531,20caae664b73db4a03969328a66d86f244e91605,9,3,3,32787,,,0,"VPN ike policy module

Change-Id: I7c0680ca084d05ad46d25c6fe74fcee56482634d
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/31/880531/1 && git format-patch -1 --stdout FETCH_HEAD,"['meta/runtime.yml', 'plugins/modules/ike_policy.py', 'ci/roles/vpn_service/tasks/main.yml', 'ci/roles/vpn_service/defaults/main.yml']",4,bc826c0212de4c3e105a83e863ebf9b82b672629,ike-policy,,,283,0
openstack%2Fpuppet-openstack-integration~stable%2F2023.1~I9f57a2b81d705731f7edc2711bc528dfe5185d92,openstack/puppet-openstack-integration,stable/2023.1,I9f57a2b81d705731f7edc2711bc528dfe5185d92,Ubuntu: Stop installing unused packages for neutron tests,MERGED,2023-04-18 01:59:21.000000000,2023-04-18 11:53:37.000000000,2023-04-18 11:53:37.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 01:59:21.000000000', 'files': ['manifests/tempest.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/0d8fc51464678076683a6e6eb504dea9ee698054', 'message': ""Ubuntu: Stop installing unused packages for neutron tests\n\nWe do not really run in-tree tests from neutron repo but we use only\ntempest and neutron-tempest-plugin. Because the required packages are\nnow installed within virtualenv we don't have to install these packages\nadditionally.\n\nChange-Id: I9f57a2b81d705731f7edc2711bc528dfe5185d92\n(cherry picked from commit 78101a0174a26bb244c70a98ef06040ef02416a9)\n""}]",1,880596,0d8fc51464678076683a6e6eb504dea9ee698054,10,2,1,9816,,,0,"Ubuntu: Stop installing unused packages for neutron tests

We do not really run in-tree tests from neutron repo but we use only
tempest and neutron-tempest-plugin. Because the required packages are
now installed within virtualenv we don't have to install these packages
additionally.

Change-Id: I9f57a2b81d705731f7edc2711bc528dfe5185d92
(cherry picked from commit 78101a0174a26bb244c70a98ef06040ef02416a9)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/96/880596/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/tempest.pp'],1,0d8fc51464678076683a6e6eb504dea9ee698054,,," # Install missed dependency for neutron tests # https://github.com/openstack/neutron/blob/master/test-requirements.txt#L20 if $facts['os']['name'] == 'Ubuntu' { package { ['python3-ddt', 'python3-oslotest', 'python3-gabbi']: ensure => present } } ",0,8
openstack%2Fkolla-ansible~stable%2Fxena~I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,openstack/kolla-ansible,stable/xena,I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,Add note about removing leading tabs in ceph.conf files,MERGED,2023-04-13 13:46:50.000000000,2023-04-18 11:49:51.000000000,2023-04-18 11:48:42.000000000,"[{'_account_id': 612}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-13 13:46:50.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ca81e2052dae918137ee97563fbaf15ed5d059a5', 'message': ""Add note about removing leading tabs in ceph.conf files\n\nAs reported in bug #1914814, common ways to generate ceph config files\nresult in files that have leading tabs. These tabs make Kolla Ansible's\nini parser unhappy, so add a note to remind users to remove them.\n\nCloses-Bug: #1914814\nChange-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616\n(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)\n""}]",0,880323,ca81e2052dae918137ee97563fbaf15ed5d059a5,10,5,1,14200,,,0,"Add note about removing leading tabs in ceph.conf files

As reported in bug #1914814, common ways to generate ceph config files
result in files that have leading tabs. These tabs make Kolla Ansible's
ini parser unhappy, so add a note to remind users to remove them.

Closes-Bug: #1914814
Change-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616
(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/23/880323/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,ca81e2052dae918137ee97563fbaf15ed5d059a5,1914814-stable/xena,.. note:: Commands like ``ceph config generate-minimal-conf`` generate configuration files that have leading tabs. These tabs break Kolla Ansible's ini parser. Be sure to remove the leading tabs from your ``ceph.conf`` files when copying them in the following sections. ,,8,0
openstack%2Fkolla-ansible~stable%2Fyoga~I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,openstack/kolla-ansible,stable/yoga,I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,Add note about removing leading tabs in ceph.conf files,MERGED,2023-04-13 12:53:56.000000000,2023-04-18 11:49:47.000000000,2023-04-18 11:48:40.000000000,"[{'_account_id': 612}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-13 12:53:56.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3930e70ae9a3c36fb61ff22332433a19e390b902', 'message': ""Add note about removing leading tabs in ceph.conf files\n\nAs reported in bug #1914814, common ways to generate ceph config files\nresult in files that have leading tabs. These tabs make Kolla Ansible's\nini parser unhappy, so add a note to remind users to remove them.\n\nCloses-Bug: #1914814\nChange-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616\n(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)\n""}]",0,880321,3930e70ae9a3c36fb61ff22332433a19e390b902,10,5,1,14826,,,0,"Add note about removing leading tabs in ceph.conf files

As reported in bug #1914814, common ways to generate ceph config files
result in files that have leading tabs. These tabs make Kolla Ansible's
ini parser unhappy, so add a note to remind users to remove them.

Closes-Bug: #1914814
Change-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616
(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/21/880321/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,3930e70ae9a3c36fb61ff22332433a19e390b902,1914814-stable/yoga,.. note:: Commands like ``ceph config generate-minimal-conf`` generate configuration files that have leading tabs. These tabs break Kolla Ansible's ini parser. Be sure to remove the leading tabs from your ``ceph.conf`` files when copying them in the following sections. ,,8,0
openstack%2Fkolla-ansible~stable%2Fzed~I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,openstack/kolla-ansible,stable/zed,I4b06eae75bf238f2f093bfb76ba37c7f75dfd616,Add note about removing leading tabs in ceph.conf files,MERGED,2023-04-13 12:53:46.000000000,2023-04-18 11:49:46.000000000,2023-04-18 11:48:39.000000000,"[{'_account_id': 612}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-13 12:53:46.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b892a569fa75acd1d469d4a528d1834bd8a429b2', 'message': ""Add note about removing leading tabs in ceph.conf files\n\nAs reported in bug #1914814, common ways to generate ceph config files\nresult in files that have leading tabs. These tabs make Kolla Ansible's\nini parser unhappy, so add a note to remind users to remove them.\n\nCloses-Bug: #1914814\nChange-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616\n(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)\n""}]",0,880320,b892a569fa75acd1d469d4a528d1834bd8a429b2,10,5,1,14826,,,0,"Add note about removing leading tabs in ceph.conf files

As reported in bug #1914814, common ways to generate ceph config files
result in files that have leading tabs. These tabs make Kolla Ansible's
ini parser unhappy, so add a note to remind users to remove them.

Closes-Bug: #1914814
Change-Id: I4b06eae75bf238f2f093bfb76ba37c7f75dfd616
(cherry picked from commit 9070c4fa9d06dc11820cb8eaac0374ef62b445f7)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/20/880320/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,b892a569fa75acd1d469d4a528d1834bd8a429b2,1914814-stable/zed,.. note:: Commands like ``ceph config generate-minimal-conf`` generate configuration files that have leading tabs. These tabs break Kolla Ansible's ini parser. Be sure to remove the leading tabs from your ``ceph.conf`` files when copying them in the following sections. ,,8,0
openstack%2Fkolla~stable%2Fwallaby~I989cedce7a9af3882b5510d3479b29150139e861,openstack/kolla,stable/wallaby,I989cedce7a9af3882b5510d3479b29150139e861,nova-libvirt: Fix for missing libvirt-daemon-driver-nodedev package,MERGED,2023-04-12 06:24:59.000000000,2023-04-18 11:49:40.000000000,2023-04-18 11:48:37.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-04-12 06:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5d69d958a76159d8c91a45ed0f0580c4171d22ae', 'message': 'nova-libvirt: Fix for missing libvirt-daemon-driver-nodedev package\n\nCloses-Bug: #2012821\nChange-Id: I989cedce7a9af3882b5510d3479b29150139e861\n(cherry picked from commit 2783fb710710103fe6aca3ff18c976590ca15e09)\n'}, {'number': 2, 'created': '2023-04-12 21:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8b01bce205bb0942e31b83cbb57c7ac36e23085f', 'message': 'nova-libvirt: Fix for missing libvirt-daemon-driver-nodedev package\n\nCloses-Bug: #2012821\nChange-Id: I989cedce7a9af3882b5510d3479b29150139e861\n(cherry picked from commit 2783fb710710103fe6aca3ff18c976590ca15e09)\n'}, {'number': 3, 'created': '2023-04-13 10:46:56.000000000', 'files': ['docker/nova/nova-libvirt/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2b0574dcec2059c333622ce1e23e914c1c5c1f3e', 'message': 'nova-libvirt: Fix for missing libvirt-daemon-driver-nodedev package\n\nCloses-Bug: #2012821\nChange-Id: I989cedce7a9af3882b5510d3479b29150139e861\n(cherry picked from commit 2783fb710710103fe6aca3ff18c976590ca15e09)\n'}]",0,880100,2b0574dcec2059c333622ce1e23e914c1c5c1f3e,16,5,3,34940,,,0,"nova-libvirt: Fix for missing libvirt-daemon-driver-nodedev package

Closes-Bug: #2012821
Change-Id: I989cedce7a9af3882b5510d3479b29150139e861
(cherry picked from commit 2783fb710710103fe6aca3ff18c976590ca15e09)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/880100/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova/nova-libvirt/Dockerfile.j2'],1,5d69d958a76159d8c91a45ed0f0580c4171d22ae,," 'libvirt-daemon-driver-nodedev',",,1,0
openstack%2Fkayobe~stable%2Fwallaby~I666d7011bde0050ebc509b427c1d4f5a66b6231a,openstack/kayobe,stable/wallaby,I666d7011bde0050ebc509b427c1d4f5a66b6231a,Support configuring VLANs with systemd-networkd syntax,MERGED,2023-03-20 09:43:03.000000000,2023-04-18 11:30:02.000000000,2023-04-18 11:28:44.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-03-20 09:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/1462ea92f80f176a3e1747f4a61ae1bf03b0d346', 'message': 'Support configuring VLANs with systemd-networkd syntax\n\nThis allows operators to configure arbitrarily named VLAN interfaces\nusing systemd-networkd.\n\nStory: 2010266\nTask: 46178\n\nChange-Id: I666d7011bde0050ebc509b427c1d4f5a66b6231a\n(cherry picked from commit 6d7b8812ae82b481519818a00293bb1aec32d058)\n'}, {'number': 2, 'created': '2023-03-20 09:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/95ef19cf59c7c8d3197fc96c33a4173de8e5e75f', 'message': 'Support configuring VLANs with systemd-networkd syntax\n\nThis allows operators to configure arbitrarily named VLAN interfaces\nusing systemd-networkd.\n\nStory: 2010266\nTask: 46178\n\nChange-Id: I666d7011bde0050ebc509b427c1d4f5a66b6231a\n(cherry picked from commit 6d7b8812ae82b481519818a00293bb1aec32d058)\n'}, {'number': 3, 'created': '2023-04-12 15:45:42.000000000', 'files': ['kayobe/plugins/filter/networkd.py', 'kayobe/tests/unit/plugins/filter/test_networkd.py', 'playbooks/kayobe-overcloud-host-configure-base/overrides.yml.j2', 'releasenotes/notes/systemd-networkd-vlans-5022f0d1b8214329.yaml', 'kayobe/tests/unit/plugins/action/test_kolla_ansible_host_vars.py', 'kayobe/plugins/filter/networks.py', 'kayobe/plugins/action/kolla_ansible_host_vars.py', 'playbooks/kayobe-overcloud-host-configure-base/tests/test_overcloud_host_configure.py', 'doc/source/configuration/reference/network.rst'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/8b74232727c659632a047f77d6712cdfb1da9022', 'message': 'Support configuring VLANs with systemd-networkd syntax\n\nThis allows operators to configure arbitrarily named VLAN interfaces\nusing systemd-networkd.\n\nAlso, this change contains some fixes for tests introduces in\nI3f821937b0930a0ac9341178de7ae5123d82b957.\n\nStory: 2010266\nTask: 46178\n\nChange-Id: I666d7011bde0050ebc509b427c1d4f5a66b6231a\n(cherry picked from commit 6d7b8812ae82b481519818a00293bb1aec32d058)\n'}]",4,877763,8b74232727c659632a047f77d6712cdfb1da9022,16,4,3,14826,,,0,"Support configuring VLANs with systemd-networkd syntax

This allows operators to configure arbitrarily named VLAN interfaces
using systemd-networkd.

Also, this change contains some fixes for tests introduces in
I3f821937b0930a0ac9341178de7ae5123d82b957.

Story: 2010266
Task: 46178

Change-Id: I666d7011bde0050ebc509b427c1d4f5a66b6231a
(cherry picked from commit 6d7b8812ae82b481519818a00293bb1aec32d058)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/63/877763/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/plugins/filter/networkd.py', 'kayobe/tests/unit/plugins/filter/test_networkd.py', 'playbooks/kayobe-overcloud-host-configure-base/overrides.yml.j2', 'releasenotes/notes/systemd-networkd-vlans-5022f0d1b8214329.yaml', 'kayobe/tests/unit/plugins/action/test_kolla_ansible_host_vars.py', 'kayobe/plugins/filter/networks.py', 'kayobe/plugins/action/kolla_ansible_host_vars.py', 'playbooks/kayobe-overcloud-host-configure-base/tests/test_overcloud_host_configure.py', 'doc/source/configuration/reference/network.rst']",9,1462ea92f80f176a3e1747f4a61ae1bf03b0d346,systemd-networkd-vlans-stable/zed-stable/yoga-stable/xena-stable/wallaby,"``parent`` The name of the parent interface, when configuring a VLAN interface using ``systemd-networkd`` syntax.network to the name of the VLAN interface. The interface name must normally be of the form ``<parent interface>.<VLAN ID>`` to ensure compatibility with all supported host operating systems.Alternatively, when using Ubuntu as a host operating system, VLAN interfaces can be named arbitrarily using syntax supported by ``systemd-networkd``. In this case, a ``parent`` attribute must specify the underlying interface: .. code-block:: yaml :caption: ``inventory/group_vars/<group>/network-interfaces`` example_interface: ""myvlan{{ example_vlan }}"" example_parent: ""eth2"" ",network to the name of the VLAN interface. The interface name must be of the form ``<parent interface>.<VLAN ID>``.,170,17
openstack%2Fkolla-ansible~stable%2Fxena~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kolla-ansible,stable/xena,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 09:57:48.000000000,2023-04-18 11:16:10.000000000,2023-04-18 11:14:56.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 09:57:48.000000000', 'files': ['ansible/action_plugins/merge_yaml.py', 'ansible/action_plugins/merge_configs.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ecd035e4eb05a753d8951aafd7c91b2d22869fb9', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nAlso, this change contains fixes already applied in the Kayobe\nproject to improve and synchronize the code of the plugins between\nprojects.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)\n""}]",0,880477,ecd035e4eb05a753d8951aafd7c91b2d22869fb9,9,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Also, this change contains fixes already applied in the Kayobe
project to improve and synchronize the code of the plugins between
projects.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/77/880477/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/action_plugins/merge_configs.py', 'ansible/action_plugins/merge_yaml.py']",2,ecd035e4eb05a753d8951aafd7c91b2d22869fb9,fix-merge-action-plugins,"import yaml if source and os.access(source, os.R_OK): result = yaml.safe_load(template_data) f.write(yaml.dump(output, default_flow_style=False)) copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)","from yaml import dump from yaml import safe_load if os.access(source, os.R_OK): result = safe_load(template_data) f.write(dump(output, default_flow_style=False)) result.update(copy_action.run(task_vars=task_vars))",16,9
openstack%2Fcinder~master~I471ce2887a9884a5478a303e4b4db9cf8e55b6fb,openstack/cinder,master,I471ce2887a9884a5478a303e4b4db9cf8e55b6fb,test_rbd_iscsi: Make tests compatible with python 3.11,MERGED,2023-01-05 19:44:28.000000000,2023-04-18 10:38:16.000000000,2023-04-17 20:58:39.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 30615}, {'_account_id': 32029}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-01-05 19:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/075da9e05b793e38238faeb9a476c9bcdefbcb8f', 'message': 'test_rbd_iscsi: Make tests compatible with python 3.11\n\nThis makes these tests work in Python 3.11.\n\nAlso includes a few cleanups such as reducing storing\nthe driver in ""self"", and removal of unneeded fakes code\nfor rbd_iscsi_client.\n\nRelated-Bug: #2000436\nChange-Id: I471ce2887a9884a5478a303e4b4db9cf8e55b6fb\n'}, {'number': 2, 'created': '2023-03-01 04:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16ccb9558b471f523fbcc382b1f8b01c2d909d84', 'message': 'test_rbd_iscsi: Make tests compatible with python 3.11\n\nThis makes these tests work in Python 3.11.\n\nAlso includes a few cleanups such as reducing storing\nthe driver in ""self"", and removal of unneeded fakes code\nfor rbd_iscsi_client.\n\nRelated-Bug: #2000436\nChange-Id: I471ce2887a9884a5478a303e4b4db9cf8e55b6fb\n'}, {'number': 3, 'created': '2023-03-07 15:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/55b928649d6448f775e70d7e5dfbb95fb0205cf5', 'message': 'test_rbd_iscsi: Make tests compatible with python 3.11\n\nThis makes these tests work in Python 3.11.\n\nAlso includes a few cleanups such as reducing storing\nthe driver in ""self"", and removal of unneeded fakes code\nfor rbd_iscsi_client.\n\nRelated-Bug: #2000436\nChange-Id: I471ce2887a9884a5478a303e4b4db9cf8e55b6fb\n'}, {'number': 4, 'created': '2023-03-07 17:28:50.000000000', 'files': ['cinder/tests/unit/volume/drivers/ceph/test_rbd_iscsi.py', 'cinder/tests/unit/volume/drivers/ceph/fake_rbd_iscsi_client.py', 'cinder/tests/unit/volume/drivers/ceph/fake_rbd_iscsi_client_exceptions.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c75b3260c844464829bcbc18460684cc69e89259', 'message': 'test_rbd_iscsi: Make tests compatible with python 3.11\n\nThis makes these tests work in Python 3.11.\n\nAlso includes a few cleanups such as reducing storing\nthe driver in ""self"", and removal of unneeded fakes code\nfor rbd_iscsi_client.\n\nRelated-Bug: #2000436\nChange-Id: I471ce2887a9884a5478a303e4b4db9cf8e55b6fb\n'}]",13,869396,c75b3260c844464829bcbc18460684cc69e89259,72,7,4,4523,,,0,"test_rbd_iscsi: Make tests compatible with python 3.11

This makes these tests work in Python 3.11.

Also includes a few cleanups such as reducing storing
the driver in ""self"", and removal of unneeded fakes code
for rbd_iscsi_client.

Related-Bug: #2000436
Change-Id: I471ce2887a9884a5478a303e4b4db9cf8e55b6fb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/96/869396/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/ceph/test_rbd_iscsi.py', 'cinder/tests/unit/volume/drivers/ceph/fake_rbd_iscsi_client.py', 'cinder/tests/unit/volume/drivers/ceph/fake_rbd_iscsi_client_exceptions.py']",3,075da9e05b793e38238faeb9a476c9bcdefbcb8f,,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""Fake client exceptions to use."""""" class UnsupportedVersion(Exception): """"""Unsupported version of the client."""""" pass class ClientException(Exception): """"""The base exception class for these fake exceptions."""""" _error_code = None _error_desc = None _error_ref = None _debug1 = None _debug2 = None def __init__(self, error=None): if error: if 'code' in error: self._error_code = error['code'] if 'desc' in error: self._error_desc = error['desc'] if 'ref' in error: self._error_ref = error['ref'] if 'debug1' in error: self._debug1 = error['debug1'] if 'debug2' in error: self._debug2 = error['debug2'] def get_code(self): return self._error_code def get_description(self): return self._error_desc def get_ref(self): return self._error_ref def __str__(self): formatted_string = self.message if self.http_status: formatted_string += "" (HTTP %s)"" % self.http_status if self._error_code: formatted_string += "" %s"" % self._error_code if self._error_desc: formatted_string += "" - %s"" % self._error_desc if self._error_ref: formatted_string += "" - %s"" % self._error_ref if self._debug1: formatted_string += "" (1: '%s')"" % self._debug1 if self._debug2: formatted_string += "" (2: '%s')"" % self._debug2 return formatted_string class HTTPConflict(ClientException): http_status = 409 message = ""Conflict"" def __init__(self, error=None): if error: super(HTTPConflict, self).__init__(error) if 'message' in error: self._error_desc = error['message'] def get_description(self): return self._error_desc class HTTPNotFound(ClientException): http_status = 404 message = ""Not found"" class HTTPForbidden(ClientException): http_status = 403 message = ""Forbidden"" class HTTPBadRequest(ClientException): http_status = 400 message = ""Bad request"" class HTTPUnauthorized(ClientException): http_status = 401 message = ""Unauthorized"" class HTTPServerError(ClientException): http_status = 500 message = ""Error"" def __init__(self, error=None): if error and 'message' in error: self._error_desc = error['message'] def get_description(self): return self._error_desc ",81,220
openstack%2Fneutron-lib~stable%2Fwallaby~I2a44e3843dd25b9db387c12f536a084d1fafbcd1,openstack/neutron-lib,stable/wallaby,I2a44e3843dd25b9db387c12f536a084d1fafbcd1,Fix pep8 errors with pytlint v2.16.0,MERGED,2023-02-20 11:27:09.000000000,2023-04-18 10:29:39.000000000,2023-04-18 10:28:37.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-20 11:27:09.000000000', 'files': ['neutron_lib/db/standard_attr.py', 'neutron_lib/api/attributes.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/025e0d72eebe81dcf8ba931e78bfdbe72ecd122b', 'message': 'Fix pep8 errors with pytlint v2.16.0\n\nChange-Id: I2a44e3843dd25b9db387c12f536a084d1fafbcd1\nCloses-Bug: #2004538\n(cherry picked from commit b1a4f783daa1c48057cb450e58198f1bf93931c6)\n'}]",10,874412,025e0d72eebe81dcf8ba931e78bfdbe72ecd122b,26,4,1,16688,,,0,"Fix pep8 errors with pytlint v2.16.0

Change-Id: I2a44e3843dd25b9db387c12f536a084d1fafbcd1
Closes-Bug: #2004538
(cherry picked from commit b1a4f783daa1c48057cb450e58198f1bf93931c6)
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/12/874412/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/db/standard_attr.py', 'neutron_lib/api/attributes.py']",2,025e0d72eebe81dcf8ba931e78bfdbe72ecd122b,bug/2004538," msg_dict = {'attr': attr, 'reason': res}"," msg_dict = dict(attr=attr, reason=res)",6,6
openstack%2Fcharm-keystone-k8s~main~I8cb69a8689208b4adbb85417301393b85c4a87a9,openstack/charm-keystone-k8s,main,I8cb69a8689208b4adbb85417301393b85c4a87a9,Disable scaling tests,ABANDONED,2023-04-18 08:34:25.000000000,2023-04-18 10:28:28.000000000,,[],"[{'number': 1, 'created': '2023-04-18 08:34:25.000000000', 'files': ['tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/6e57156ac6f4cb3d21a73ee86e83a275d4ff918f', 'message': 'Disable scaling tests\n\nThere are issues with the keystone units after scale-out returning\n500 errors. While these are worked on disable scaling tests to\nunblock gate.\n\nChange-Id: I8cb69a8689208b4adbb85417301393b85c4a87a9\n'}]",0,880715,6e57156ac6f4cb3d21a73ee86e83a275d4ff918f,2,0,1,12549,,,0,"Disable scaling tests

There are issues with the keystone units after scale-out returning
500 errors. While these are worked on disable scaling tests to
unblock gate.

Change-Id: I8cb69a8689208b4adbb85417301393b85c4a87a9
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/15/880715/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/tests.yaml'],1,6e57156ac6f4cb3d21a73ee86e83a275d4ff918f,remove-scaling-tests, - zaza.openstack.charm_tests.tempest.tests.TempestTestWithKeystoneMinimal, - zaza.openstack.charm_tests.keystone.tests.KeystoneTempestTestK8S,1,1
openstack%2Ftripleo-validations~stable%2Fzed~Ibfd143149b641304a8bb4baefc4d0c4f20457efd,openstack/tripleo-validations,stable/zed,Ibfd143149b641304a8bb4baefc4d0c4f20457efd,Adapt cepth health validation to the new API,MERGED,2023-04-13 11:51:26.000000000,2023-04-18 10:06:57.000000000,2023-04-18 10:05:39.000000000,"[{'_account_id': 6816}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 25402}, {'_account_id': 31245}, {'_account_id': 32926}]","[{'number': 1, 'created': '2023-04-13 11:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/547dba2fd397d9ca8dafc602b1dee90b787ac5c8', 'message': 'Adapt cepth health validation to the new API\n\nThe API for health verification and OSD stats has changed in wallaby, now it is used cephadm command instead of connecting to the ceph mon container. This patch adapts the validation to the new API\n\nChange-Id: Ibfd143149b641304a8bb4baefc4d0c4f20457efd\n'}, {'number': 2, 'created': '2023-04-13 12:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/db7bb94968f86658c00ec339c2c4a278f0a29149', 'message': 'Adapt cepth health validation to the new API\n\nThe API for health verification and OSD stats has changed in wallaby, now it is used cephadm command instead of connecting to the ceph mon container. This patch adapts the validation to the new API\n\nChange-Id: Ibfd143149b641304a8bb4baefc4d0c4f20457efd\n'}, {'number': 3, 'created': '2023-04-17 12:45:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/a9894735d154705609e9cd519062e554df60aaa6', 'message': 'Adapt cepth health validation to the new API\n\nThe API for health verification and OSD stats has changed in wallaby, now it is used cephadm command instead of connecting to the ceph mon container. This patch adapts the validation to the new API\n\nThis change solves rhbz#2187307\n\nChange-Id: Ibfd143149b641304a8bb4baefc4d0c4f20457efd\n'}, {'number': 4, 'created': '2023-04-17 13:05:53.000000000', 'files': ['roles/ceph/tasks/ceph-health.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/e427f2e9acaa3b3fe18faf3c37e8ff29a8b325d5', 'message': 'Adapt cepth health validation to the new API\n\nThe API for health verification and OSD stats has changed in wallaby, now it is used cephadm command instead of connecting to the ceph mon container. This patch adapts the validation to the new API\n\nResolves: rhbz#2187307\n\nChange-Id: Ibfd143149b641304a8bb4baefc4d0c4f20457efd\n'}]",11,880286,e427f2e9acaa3b3fe18faf3c37e8ff29a8b325d5,28,9,4,34423,,,0,"Adapt cepth health validation to the new API

The API for health verification and OSD stats has changed in wallaby, now it is used cephadm command instead of connecting to the ceph mon container. This patch adapts the validation to the new API

Resolves: rhbz#2187307

Change-Id: Ibfd143149b641304a8bb4baefc4d0c4f20457efd
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/86/880286/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ceph/tasks/ceph-health.yaml'],1,547dba2fd397d9ca8dafc602b1dee90b787ac5c8,ceph-health-api-fix," shell: ""cephadm shell -- {{ ceph_cluster_name.stdout }} health"" cephadm shell -- ""{{ ceph_cluster_name.stdout }}"" osd stat -f json | jq '{{ jq_osd_percentage_filter }}'"," - name: Check for docker cli stat: path: ""/var/run/docker.sock"" register: check_docker_cli check_mode: false - name: Set container_client fact set_fact: container_client: |- {% set container_client = 'podman' %} {% if check_docker_cli.stat.exists|bool %} {% set container_client = 'docker' %} {% endif %} {{ container_client }} - name: Set container filter format set_fact: container_filter_format: !unsafe ""--format '{{ .Names }}'"" - name: Set ceph_mon_container name become: true shell: ""{{ container_client }} ps {{ container_filter_format }} | grep ceph-mon"" register: ceph_mon_container changed_when: false shell: ""{{ container_client }} exec {{ ceph_mon_container.stdout }} ceph --cluster {{ ceph_cluster_name.stdout }} health | awk '{print $1}'"" ""{{ container_client }}"" exec ""{{ ceph_mon_container.stdout }}"" ceph --cluster ""{{ ceph_cluster_name.stdout }}"" osd stat -f json | jq '{{ jq_osd_percentage_filter }}'",3,28
openstack%2Fkolla-ansible~master~I01bfb641acf692d28fd5d04191f5d2cafd5163ab,openstack/kolla-ansible,master,I01bfb641acf692d28fd5d04191f5d2cafd5163ab,[DNM] Fix create sasl account before config file is ready,ABANDONED,2023-04-17 19:03:01.000000000,2023-04-18 09:55:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-17 19:03:01.000000000', 'files': ['releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ca3fc4c7feff27a91f063d203f46b65f3808d83d', 'message': '[DNM] Fix create sasl account before config file is ready\n\nAdd checking for container readiness before create sasl user\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/877986\nChange-Id: I01bfb641acf692d28fd5d04191f5d2cafd5163ab\n'}]",1,880678,ca3fc4c7feff27a91f063d203f46b65f3808d83d,5,1,1,27339,,,0,"[DNM] Fix create sasl account before config file is ready

Add checking for container readiness before create sasl user

Depends-On: https://review.opendev.org/c/openstack/kolla/+/877986
Change-Id: I01bfb641acf692d28fd5d04191f5d2cafd5163ab
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/78/880678/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-2015589-94427c14cd857c98.yaml', 'ansible/roles/nova-cell/handlers/main.yml']",2,ca3fc4c7feff27a91f063d203f46b65f3808d83d,dnm-sasl-account-test," nova_libvirt_notify: ""{{ ['Checking libvirt container is ready', 'Create libvirt SASL user'] if libvirt_enable_sasl | bool else [] }}"" # need to wait kolla_set_configs script to overwrite sasl config file - name: Checking libvirt container is ready become: true shell: cmd: > set -o pipefail && {{ kolla_container_engine }} exec -i nova_libvirt ls /run/libvirtd.pid executable: /bin/bash register: libvirt_container_ready until: libvirt_container_ready is succeeded retries: 10 "," nova_libvirt_notify: ""{{ ['Create libvirt SASL user'] if libvirt_enable_sasl | bool else [] }}""",18,1
openstack%2Fskyline-console~master~I68691c9743aca6196f1e2258cb2acaf2a82066dc,openstack/skyline-console,master,I68691c9743aca6196f1e2258cb2acaf2a82066dc,Add Designate (DNS) UI to Skyline-Console,MERGED,2023-03-28 12:21:47.000000000,2023-04-18 09:37:33.000000000,2023-04-18 09:36:37.000000000,"[{'_account_id': 22348}, {'_account_id': 30434}, {'_account_id': 33689}, {'_account_id': 34589}]","[{'number': 1, 'created': '2023-03-28 12:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/0e86e57e1e3c545fc7ab2eb36772c7403ea7284d', 'message': 'Add Designate (DNS) UI to Skyline-Console\n\nChange-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc\n'}, {'number': 2, 'created': '2023-03-28 13:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/ca2a346becf2d440ad0b24f29ce28487fb3c070a', 'message': 'Add Designate (DNS) UI to Skyline-Console\n\nChange-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc\n'}, {'number': 3, 'created': '2023-03-29 05:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/c16dfc2ae44660861870fa2f18fb349d071e7406', 'message': 'Add Designate (DNS) UI to Skyline-Console\n\nChange-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc\n'}, {'number': 4, 'created': '2023-04-10 13:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/0f6a464b8ee00211ae8abd1f4067e1b309ad7c10', 'message': 'Add Designate (DNS) UI to Skyline-Console\n\nChange-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc\n'}, {'number': 5, 'created': '2023-04-10 13:14:02.000000000', 'files': ['src/stores/designate/recordSets.js', 'src/pages/network/containers/DNS/Reverse/actions/Unset.jsx', 'src/pages/network/containers/DNS/Reverse/actions/Set.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/Update.jsx', 'src/pages/network/containers/DNS/Reverse/Detail/BaseDetail.jsx', 'src/pages/network/containers/DNS/Zones/actions/Update.jsx', 'src/pages/network/containers/DNS/Zones/Detail/index.jsx', 'src/resources/dns/record.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/index.jsx', 'src/stores/designate/zones.js', 'src/pages/network/containers/DNS/Zones/Detail/BaseDetail/index.jsx', 'src/pages/network/containers/DNS/Zones/actions/Create.jsx', 'src/pages/network/containers/DNS/Reverse/actions/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/Detail/BaseDetail/index.jsx', 'src/pages/network/containers/DNS/Zones/actions/Records/Create.jsx', 'src/pages/network/containers/DNS/Zones/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/index.jsx', 'src/pages/network/containers/DNS/Reverse/Detail/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/Detail/index.jsx', 'src/layouts/menu.jsx', 'src/pages/network/containers/DNS/Zones/actions/Delete.jsx', 'src/client/client/constants.js', 'src/client/designate/index.js', 'src/pages/network/routes/index.js', 'src/utils/dns-rrtype.js', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/Delete.jsx', 'src/pages/network/containers/DNS/Zones/actions/index.jsx', 'src/pages/network/containers/DNS/Reverse/index.jsx', 'src/stores/designate/reverse.js'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/ce20a90c1e29df3285cb710639ab04bbe902859c', 'message': 'Add Designate (DNS) UI to Skyline-Console\n\nChange-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc\n'}]",29,878769,ce20a90c1e29df3285cb710639ab04bbe902859c,20,4,5,34680,,,0,"Add Designate (DNS) UI to Skyline-Console

Change-Id: I68691c9743aca6196f1e2258cb2acaf2a82066dc
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/69/878769/4 && git format-patch -1 --stdout FETCH_HEAD,"['src/stores/designate/recordSets.js', 'src/pages/network/containers/DNS/Reverse/actions/Unset.jsx', 'src/pages/network/containers/DNS/Reverse/actions/Set.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/Update.jsx', 'src/pages/network/containers/DNS/Reverse/Detail/BaseDetail.jsx', 'src/pages/network/containers/DNS/Zones/actions/Update.jsx', 'src/pages/network/containers/DNS/Zones/Detail/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/index.jsx', 'src/stores/designate/zones.js', 'src/pages/network/containers/DNS/Zones/Detail/BaseDetail/index.jsx', 'src/pages/network/containers/DNS/Zones/actions/Create.jsx', 'src/pages/network/containers/DNS/Reverse/actions/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/Detail/BaseDetail/index.jsx', 'src/pages/network/containers/DNS/Zones/actions/Records/Create.jsx', 'src/pages/network/containers/DNS/Zones/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/index.jsx', 'src/pages/network/containers/DNS/Reverse/Detail/index.jsx', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/Detail/index.jsx', 'src/layouts/menu.jsx', 'src/pages/network/containers/DNS/Zones/actions/Delete.jsx', 'src/pages/network/containers/DNS/App.jsx', 'src/client/designate/index.js', 'src/pages/network/routes/index.js', 'src/pages/network/containers/DNS/Zones/Detail/RecordSets/actions/Delete.jsx', 'src/pages/network/containers/DNS/Zones/actions/index.jsx', 'src/pages/network/containers/DNS/Reverse/index.jsx', 'src/stores/designate/reverse.js']",27,0e86e57e1e3c545fc7ab2eb36772c7403ea7284d,,"// Licensed under the Apache License, Version 2.0 (the ""License""); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an ""AS IS"" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. import { action } from 'mobx'; import client from 'client'; import Base from 'stores/base'; export class ReverseStore extends Base { get client() { return client.designate.reverse.floatingips; } get reverseClient() { return client.designate.reverse; } get isSubResource() { return true; } detailFetchByClient(resourceParams) { const { id } = resourceParams; return this.reverseClient.reverseDetail(id); } get paramsFunc() { return () => { }; } @action set = ({ id }, body) => this.submitting(this.reverseClient.setReverse(id, body)); @action unset = ({ id }, body) => this.submitting(this.reverseClient.unsetReverse(id, body)); } const globalReverseStore = new ReverseStore(); export default globalReverseStore;",,1795,0
openstack%2Freleases~master~I45a8b558279f6222c52b20ae5caeb0d5d9a49631,openstack/releases,master,I45a8b558279f6222c52b20ae5caeb0d5d9a49631,Retire puppet-tacker,MERGED,2023-03-31 08:28:00.000000000,2023-04-18 09:36:59.000000000,2023-04-18 09:36:59.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-31 08:28:00.000000000', 'files': ['deliverables/bobcat/puppet-tacker.yaml', 'deliverables/victoria/puppet-tacker.yaml', 'deliverables/ussuri/puppet-tacker.yaml', 'deliverables/zed/puppet-tacker.yaml', 'deliverables/wallaby/puppet-tacker.yaml', 'deliverables/xena/puppet-tacker.yaml', 'deliverables/antelope/puppet-tacker.yaml', 'deliverables/train/puppet-tacker.yaml', 'deliverables/yoga/puppet-tacker.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/4b18596dc3870c8414c6ab394f0000481a8a7b14', 'message': 'Retire puppet-tacker\n\npuppet-tacker is being retired[1]. This marks the project as retired\nand remove the file for 2023.1/2 because we no longer create a new\nrelease.\n\n[1] https://review.opendev.org/c/openstack/governance/+/875295\n\nChange-Id: I45a8b558279f6222c52b20ae5caeb0d5d9a49631\n'}]",4,879141,4b18596dc3870c8414c6ab394f0000481a8a7b14,9,3,1,9816,,,0,"Retire puppet-tacker

puppet-tacker is being retired[1]. This marks the project as retired
and remove the file for 2023.1/2 because we no longer create a new
release.

[1] https://review.opendev.org/c/openstack/governance/+/875295

Change-Id: I45a8b558279f6222c52b20ae5caeb0d5d9a49631
",git fetch https://review.opendev.org/openstack/releases refs/changes/41/879141/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/bobcat/puppet-tacker.yaml', 'deliverables/victoria/puppet-tacker.yaml', 'deliverables/ussuri/puppet-tacker.yaml', 'deliverables/wallaby/puppet-tacker.yaml', 'deliverables/zed/puppet-tacker.yaml', 'deliverables/xena/puppet-tacker.yaml', 'deliverables/antelope/puppet-tacker.yaml', 'deliverables/train/puppet-tacker.yaml', 'deliverables/yoga/puppet-tacker.yaml']",9,4b18596dc3870c8414c6ab394f0000481a8a7b14,retire-puppet-tacker, openstack/puppet-tacker: flags: - retired, openstack/puppet-tacker: {},21,21
openstack%2Freleases~master~I51938fcedeb56198750d0f53fa7ee9efebc8faa1,openstack/releases,master,I51938fcedeb56198750d0f53fa7ee9efebc8faa1,oslo.db 13.0.0,MERGED,2023-04-17 15:52:19.000000000,2023-04-18 09:36:05.000000000,2023-04-18 09:36:05.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-04-17 15:52:19.000000000', 'files': ['deliverables/bobcat/oslo.db.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f13d600c45fdcab6fcdc3cbc0c8b8f11688e9eda', 'message': 'oslo.db 13.0.0\n\nThis is a big one. Full SQLAlchemy 2.0 support, at last.\n\nChange-Id: I51938fcedeb56198750d0f53fa7ee9efebc8faa1\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",1,880659,f13d600c45fdcab6fcdc3cbc0c8b8f11688e9eda,9,4,1,15334,,,0,"oslo.db 13.0.0

This is a big one. Full SQLAlchemy 2.0 support, at last.

Change-Id: I51938fcedeb56198750d0f53fa7ee9efebc8faa1
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/59/880659/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.db.yaml'],1,f13d600c45fdcab6fcdc3cbc0c8b8f11688e9eda,oslo.db,releases: - version: 13.0.0 projects: - repo: openstack/oslo.db hash: a7c03ba9de6f9a98aa5c36a67e1ecfab77acde9a,,5,0
openstack%2Foctavia~master~Iecedb9e9c8f293cd4c067900e1696f5050769ee8,openstack/octavia,master,Iecedb9e9c8f293cd4c067900e1696f5050769ee8,Send IP advertisements when plugging a new member subnet,MERGED,2023-04-07 15:00:05.000000000,2023-04-18 09:35:50.000000000,2023-04-18 09:34:42.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-04-07 15:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8dd5e590b855f144bb32fdeca30b54a715701450', 'message': 'WIP Send GARP when plugging a new member subnet\n\nChange-Id: Iecedb9e9c8f293cd4c067900e1696f5050769ee8\n'}, {'number': 2, 'created': '2023-04-11 13:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/23fdf27be9ce343f52c9749a1386c3bb47a311b4', 'message': 'Send GARP when plugging a new member subnet\n\nWhen plugging a new subnet, the amphora sends a GARP advertising the IP\naddress of the port. In case previously deallocated IP addresses are\nre-used, it helps the other resources on the same L2 network to flush\nthe old ARP entries.\n\nCloses-Bug: #2015572\n\nChange-Id: Iecedb9e9c8f293cd4c067900e1696f5050769ee8\n'}, {'number': 3, 'created': '2023-04-12 19:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3716eba9fa0d5ee1398cfedd5fc78ecdec050c59', 'message': 'Send IP advertisements when plugging a new member subnet\n\nWhen plugging a new subnet, the amphora sends a packet advertising the\nIP address of the port. In case previously deallocated IP addresses are\nre-used, it helps the other resources on the same L2 network to flush\nthe old ARP entries.\n\nCloses-Bug: #2015572\n\nChange-Id: Iecedb9e9c8f293cd4c067900e1696f5050769ee8\n'}, {'number': 4, 'created': '2023-04-13 06:46:43.000000000', 'files': ['octavia/amphorae/backends/agent/api_server/plug.py', 'releasenotes/notes/members-subnet-ip-advertisements-af2264844079ef6b.yaml', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_plug.py', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_util.py', 'octavia/amphorae/backends/agent/api_server/util.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/18cd1f34c8a918ab6f969a3271ac74132c4ac736', 'message': 'Send IP advertisements when plugging a new member subnet\n\nWhen plugging a new subnet, the amphora sends a packet advertising the\nIP address of the port. In case previously deallocated IP addresses are\nre-used, it helps the other resources on the same L2 network to flush\nthe old ARP entries.\n\nCloses-Bug: #2015572\n\nChange-Id: Iecedb9e9c8f293cd4c067900e1696f5050769ee8\n'}]",6,879898,18cd1f34c8a918ab6f969a3271ac74132c4ac736,20,3,4,29244,,,0,"Send IP advertisements when plugging a new member subnet

When plugging a new subnet, the amphora sends a packet advertising the
IP address of the port. In case previously deallocated IP addresses are
re-used, it helps the other resources on the same L2 network to flush
the old ARP entries.

Closes-Bug: #2015572

Change-Id: Iecedb9e9c8f293cd4c067900e1696f5050769ee8
",git fetch https://review.opendev.org/openstack/octavia refs/changes/98/879898/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/agent/api_server/plug.py', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_plug.py', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_util.py', 'octavia/amphorae/backends/agent/api_server/util.py']",4,8dd5e590b855f144bb32fdeca30b54a715701450,,"from octavia.common import utils def send_member_advertisements(fixed_ips): try: for fixed_ip in fixed_ips: ip_address = fixed_ip['ip_address'] if utils.is_ipv4(ip_address): interface = network_utils.get_interface_name( ip_address, net_ns=consts.AMPHORA_NAMESPACE) ip_advertisement.send_ip_advertisement( interface, ip_address, net_ns=consts.AMPHORA_NAMESPACE) except Exception as e: LOG.debug('Send member advertisement failed due to: %s', str(e))",,65,3
openstack%2Fovn-bgp-agent~master~I3f5fcfc2f4f52627a0fc8ed3d3ac8bf6b55360ef,openstack/ovn-bgp-agent,master,I3f5fcfc2f4f52627a0fc8ed3d3ac8bf6b55360ef,Ensure cover information is recreated upon coverage failure,MERGED,2023-04-17 13:14:19.000000000,2023-04-18 09:35:22.000000000,2023-04-18 09:34:22.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 13:14:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/921d93896b780930760b84fb491e091d9ccfc3b0', 'message': 'Ensure cover information is recreated upon coverage failure\n\nChange-Id: I3f5fcfc2f4f52627a0fc8ed3d3ac8bf6b55360ef\n'}]",0,880519,921d93896b780930760b84fb491e091d9ccfc3b0,7,2,1,23567,,,0,"Ensure cover information is recreated upon coverage failure

Change-Id: I3f5fcfc2f4f52627a0fc8ed3d3ac8bf6b55360ef
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/19/880519/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,921d93896b780930760b84fb491e091d9ccfc3b0,, coverage report --fail-under=87 --skip-covered --omit='*tests*', coverage report --fail-under=87 --skip-covered --omit='*tests*',1,1
openstack%2Fironic-python-agent-builder~master~I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d,openstack/ironic-python-agent-builder,master,I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d,Collect disk usage info post CI jobs run,MERGED,2023-04-07 07:17:55.000000000,2023-04-18 09:34:48.000000000,2023-04-18 09:32:54.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-04-07 07:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/0e170e3b2bc2a74c9bd1f802243511c67c235e5e', 'message': 'Collect disk usage info post CI jobs run\n\nChange-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d\n'}, {'number': 2, 'created': '2023-04-07 07:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/e55654cac9cd0f0a92333bf3e4a7db4ae2691d3d', 'message': 'Collect disk usage info post CI jobs run\n\nChange-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d\n'}, {'number': 3, 'created': '2023-04-07 12:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/17465bddadf9eef48e0505ee1a5970854d92c4ff', 'message': 'Collect disk usage info post CI jobs run\n\nChange-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d\n'}, {'number': 4, 'created': '2023-04-07 15:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/ce5eb594fd46875d88bc9f1a625bbcbe192bb8d6', 'message': 'Collect disk usage info post CI jobs run\n\nChange-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d\n'}, {'number': 5, 'created': '2023-04-12 11:20:33.000000000', 'files': ['playbooks/ironic-python-agent-build-image/extra-logs.yaml', 'zuul.d/ironic-python-agent-builder-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/f997078c99515eb182b95e93161d134f78d119fd', 'message': 'Collect disk usage info post CI jobs run\n\nAdd extra-logs playbook to collect more logs in the post phase.\n\nChange-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d\n'}]",3,879826,f997078c99515eb182b95e93161d134f78d119fd,20,4,5,23851,,,0,"Collect disk usage info post CI jobs run

Add extra-logs playbook to collect more logs in the post phase.

Change-Id: I4f9144f45a8c38b098ed67b2fdacffd3a596ae0d
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/26/879826/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/ironic-python-agent-build-image/post.yaml'],1,0e170e3b2bc2a74c9bd1f802243511c67c235e5e,collect-df-output," - name: Get extra logs tasks: - name: Get disk usage info shell: ""df > {{ zuul_output_dir }}/logs/df.txt"" become: yes",,6,0
openstack%2Ftripleo-heat-templates~master~Ie29699a131c3fcb08c25ef54c281442f24623394,openstack/tripleo-heat-templates,master,Ie29699a131c3fcb08c25ef54c281442f24623394,[OSP-17.1] Report running containers as healthy,ABANDONED,2023-03-21 13:12:30.000000000,2023-04-18 09:28:23.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-21 13:12:30.000000000', 'files': ['container_config_scripts/monitoring/collectd_check_health.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eeda99c8afef6773b87f7709d92a8abe1df99b90', 'message': ""[OSP-17.1] Report running containers as healthy\n\nContainers which are running and don't have heatlhchecks are reported\nas unhealthy, which is false negative.\n\nResolves: rhbz#2179006\nChange-Id: Ie29699a131c3fcb08c25ef54c281442f24623394\n""}]",0,878075,eeda99c8afef6773b87f7709d92a8abe1df99b90,3,1,1,5241,,,0,"[OSP-17.1] Report running containers as healthy

Containers which are running and don't have heatlhchecks are reported
as unhealthy, which is false negative.

Resolves: rhbz#2179006
Change-Id: Ie29699a131c3fcb08c25ef54c281442f24623394
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/878075/1 && git format-patch -1 --stdout FETCH_HEAD,['container_config_scripts/monitoring/collectd_check_health.py'],1,eeda99c8afef6773b87f7709d92a8abe1df99b90,, healthy = item['healthy'] == 'healthy' or item['status'] == 'running' item['healthy'] = int(healthy), item['healthy'] = int(item['healthy'] == 'healthy'),2,1
openstack%2Ftripleo-heat-templates~master~I1bdd34f029ff0883888d284448a4fd7a9995c035,openstack/tripleo-heat-templates,master,I1bdd34f029ff0883888d284448a4fd7a9995c035,[OSP-17.1] Add missing configuration,ABANDONED,2023-03-27 15:40:33.000000000,2023-04-18 09:28:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-27 15:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec96159765f395435c99ac02115bcbe17330128d', 'message': '[WIP] Add missing configuration\n\nNewer version of rsyslog is missing configuration options to be functional.\n\nResolves: rhbz#2180883\nChange-Id: I1bdd34f029ff0883888d284448a4fd7a9995c035\n'}, {'number': 2, 'created': '2023-03-28 10:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/59bb7a85ab81d50888a16b09c223da4aca2452ea', 'message': '[WIP] Add missing configuration\n\nNewer version of rsyslog is missing configuration options to be functional.\n\nResolves: rhbz#2180883\nChange-Id: I1bdd34f029ff0883888d284448a4fd7a9995c035\n'}, {'number': 3, 'created': '2023-03-28 14:42:01.000000000', 'files': ['deployment/logging/rsyslog-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e17dceeece463fd0faa5c21362c5579dd9f467bc', 'message': '[OSP-17.1] Add missing configuration\n\nNewer version of rsyslog is missing configuration options to be functional.\n\nResolves: rhbz#2180883\nChange-Id: I1bdd34f029ff0883888d284448a4fd7a9995c035\n'}]",0,878697,e17dceeece463fd0faa5c21362c5579dd9f467bc,7,1,3,5241,,,0,"[OSP-17.1] Add missing configuration

Newer version of rsyslog is missing configuration options to be functional.

Resolves: rhbz#2180883
Change-Id: I1bdd34f029ff0883888d284448a4fd7a9995c035
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/878697/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/logging/rsyslog-container-puppet.yaml'],1,ec96159765f395435c99ac02115bcbe17330128d,rsyslog-fix, default: true RsyslogMaxMessageSize: default: '32k' description: Maximum supported message size (both for sending and receiving) for rsyslogd. type: string - rsyslog::config::global_config: workDirectory: target: '00_rsyslog.conf' value: '/var/lib/rsyslog' maxMessageSize: target: '00_rsyslog.conf' value: {get_param: RsyslogMaxMessageSize} rsyslog::confdir: /etc/rsyslog.d, default: false - rsyslog::confdir: /etc/rsyslog.d,13,2
openstack%2Ftripleo-heat-templates~master~I4858faaab20ddfe2ae21942a19b38f28a944e9b6,openstack/tripleo-heat-templates,master,I4858faaab20ddfe2ae21942a19b38f28a944e9b6,Switch to Ansible for script download,ABANDONED,2022-12-06 20:04:23.000000000,2023-04-18 09:28:10.000000000,,"[{'_account_id': 4264}, {'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-12-06 20:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/86e468a53f2c160ba58423a83b6e5e13f9597b24', 'message': ""Switch to Ansible for script download\n\nCurrently script download via Puppet doesn't work correctly anyway.\n\nChange-Id: I4858faaab20ddfe2ae21942a19b38f28a944e9b6\n""}, {'number': 2, 'created': '2022-12-12 13:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/29cc5d833b75c89b393ccfc125c611d1efbdfad2', 'message': ""Switch to Ansible for script download\n\nCurrently script download via Puppet doesn't work correctly anyway.\n\nChange-Id: I4858faaab20ddfe2ae21942a19b38f28a944e9b6\n""}, {'number': 3, 'created': '2023-01-12 10:53:11.000000000', 'files': ['deployment/metrics/collectd-container-ansible.yaml', 'deployment/metrics/collectd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6f47171e82748a933aa52e2df0bb082d7491fc65', 'message': ""Switch to Ansible for script download\n\nCurrently script download via Puppet doesn't work correctly anyway.\n\nThis is meant for fixing the feature in stable/wallaby\n\nChange-Id: I4858faaab20ddfe2ae21942a19b38f28a944e9b6\n""}]",6,866799,6f47171e82748a933aa52e2df0bb082d7491fc65,22,7,3,5241,,,0,"Switch to Ansible for script download

Currently script download via Puppet doesn't work correctly anyway.

This is meant for fixing the feature in stable/wallaby

Change-Id: I4858faaab20ddfe2ae21942a19b38f28a944e9b6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/866799/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/metrics/collectd-container-puppet.yaml'],1,86e468a53f2c160ba58423a83b6e5e13f9597b24,exec-scripts-ansible," List of hashes of scripts for download for sensubility usage. Value has to be in following format: [{""name"": ""<script name>"", ""source"": ""<http URI to download script>"", ""checksum"": ""<alogithm:sum>""}] default: [] default: /config-scripts/collectd_check_health.py - path: /scripts owner: collectd:collectd recurse: true - /var/lib/container-config-scripts:/config-scripts:ro - /var/lib/container-user-scripts:/scripts:z - { 'path': /var/lib/container-user-scripts/, 'setype': container_file_t, 'mode': '0755' } - name: download exec scripts ansible.builtin.get_url: url: ""{{ item.source }}"" checksum: ""{{ item.checksum }}"" dest: ""/var/lib/container-user-scripts/{{ item.name }}"" mode: ""0755"" with_items: {get_param: CollectdSensubilityScripts}"," Hash of scripts for download for sensubility usage. The hash has to be in following format: {""script-name"": {""source"": ""<http URI to download script>"", ""checksum"": ""<md5sum of the script file>"", ""create_bin_link"": true/false <creates /usr/bin/sensubility_script-name if true which is default>}} default: {} default: /scripts/collectd_check_health.py tripleo::profile::base::metrics::collectd::sensubility::scripts: get_param: CollectdSensubilityScripts - /var/lib/container-config-scripts:/scripts:ro",17,8
openstack%2Fdevstack~stable%2F2023.1~I1785b49b2ef72ca1f817f504d5ea56021410c052,openstack/devstack,stable/2023.1,I1785b49b2ef72ca1f817f504d5ea56021410c052,[ovs] Reload ovs kernel module always,MERGED,2023-04-14 14:37:46.000000000,2023-04-18 09:22:18.000000000,2023-04-18 09:21:17.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-14 14:37:46.000000000', 'files': ['lib/neutron_plugins/ovs_source'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f1d555d1e7af0fc5097a89c3df044bc4a35ec53f', 'message': '[ovs] Reload ovs kernel module always\n\nIrrespective of build_modules is True\nor False reload ovs modules always.\n\nIf ovs is installed from package before(like\nwith multi-node-bridge role), then installing\novs from source requires openvswitch kernel\nmodule to be reloaded.\n\nThe issue was not seen before jammy as there\nmodule was reloaded when build_modules was set\nto True.\n\nCloses-Bug: #2015364\nChange-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052\n(cherry picked from commit 42517968ff7bdced07c5bc08b6cb2b8d10d246cc)\n'}]",1,880494,f1d555d1e7af0fc5097a89c3df044bc4a35ec53f,8,3,1,13861,,,0,"[ovs] Reload ovs kernel module always

Irrespective of build_modules is True
or False reload ovs modules always.

If ovs is installed from package before(like
with multi-node-bridge role), then installing
ovs from source requires openvswitch kernel
module to be reloaded.

The issue was not seen before jammy as there
module was reloaded when build_modules was set
to True.

Closes-Bug: #2015364
Change-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052
(cherry picked from commit 42517968ff7bdced07c5bc08b6cb2b8d10d246cc)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/94/880494/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ovs_source'],1,f1d555d1e7af0fc5097a89c3df044bc4a35ec53f,bug/2015364-stable/2023.1, reload_ovs_kernel_modules, reload_ovs_kernel_modules else load_ovs_kernel_modules,1,3
openstack%2Fdevstack~stable%2Fzed~I1785b49b2ef72ca1f817f504d5ea56021410c052,openstack/devstack,stable/zed,I1785b49b2ef72ca1f817f504d5ea56021410c052,[ovs] Reload ovs kernel module always,MERGED,2023-04-14 14:39:04.000000000,2023-04-18 09:22:10.000000000,2023-04-18 09:21:19.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-14 14:39:04.000000000', 'files': ['lib/neutron_plugins/ovs_source'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4181791e065c54d396748f79367673309f84acb6', 'message': '[ovs] Reload ovs kernel module always\n\nIrrespective of build_modules is True\nor False reload ovs modules always.\n\nIf ovs is installed from package before(like\nwith multi-node-bridge role), then installing\novs from source requires openvswitch kernel\nmodule to be reloaded.\n\nThe issue was not seen before jammy as there\nmodule was reloaded when build_modules was set\nto True.\n\nCloses-Bug: #2015364\nChange-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052\n(cherry picked from commit 42517968ff7bdced07c5bc08b6cb2b8d10d246cc)\n(cherry picked from commit f1d555d1e7af0fc5097a89c3df044bc4a35ec53f)\n'}]",1,880495,4181791e065c54d396748f79367673309f84acb6,8,3,1,13861,,,0,"[ovs] Reload ovs kernel module always

Irrespective of build_modules is True
or False reload ovs modules always.

If ovs is installed from package before(like
with multi-node-bridge role), then installing
ovs from source requires openvswitch kernel
module to be reloaded.

The issue was not seen before jammy as there
module was reloaded when build_modules was set
to True.

Closes-Bug: #2015364
Change-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052
(cherry picked from commit 42517968ff7bdced07c5bc08b6cb2b8d10d246cc)
(cherry picked from commit f1d555d1e7af0fc5097a89c3df044bc4a35ec53f)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/880495/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ovs_source'],1,4181791e065c54d396748f79367673309f84acb6,bug/2015364-stable/2023.1-stable/zed, reload_ovs_kernel_modules, reload_ovs_kernel_modules else load_ovs_kernel_modules,1,3
openstack%2Ftripleo-common~stable%2Fwallaby~I80d44b15e92563df7f0cce8c2c52097f406780cb,openstack/tripleo-common,stable/wallaby,I80d44b15e92563df7f0cce8c2c52097f406780cb,Stop using dumb-init entry for nova-libvirt image,MERGED,2023-04-05 12:11:44.000000000,2023-04-18 09:17:59.000000000,2023-04-18 09:17:01.000000000,"[{'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-04-05 12:11:44.000000000', 'files': ['container-images/tcib/base/os/nova-base/nova-libvirt/nova-libvirt.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c2195211e470a7b26fc2a1c8a364615d5a64e34c', 'message': ""Stop using dumb-init entry for nova-libvirt image\n\nContainers that use nova-libvirt image are mostly run in the\nhost'd pid namespace, and require no artificial init.\nThis solves the problem for nova libvirt container, that execute\nlibvirtd in a transient systemd unit, when its parent dumb-init\nprocess dies for *reasons*.\n\nChange-Id: I80d44b15e92563df7f0cce8c2c52097f406780cb\nRelated: rhbz#2168530\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}]",3,879488,c2195211e470a7b26fc2a1c8a364615d5a64e34c,12,6,1,6926,,,0,"Stop using dumb-init entry for nova-libvirt image

Containers that use nova-libvirt image are mostly run in the
host'd pid namespace, and require no artificial init.
This solves the problem for nova libvirt container, that execute
libvirtd in a transient systemd unit, when its parent dumb-init
process dies for *reasons*.

Change-Id: I80d44b15e92563df7f0cce8c2c52097f406780cb
Related: rhbz#2168530
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/88/879488/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/os/nova-base/nova-libvirt/nova-libvirt.yaml'],1,c2195211e470a7b26fc2a1c8a364615d5a64e34c,,tcib_entrypoint: '',,1,0
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ia72c9d088326f4652e5844f09dd283dfcea4f8b8,openstack/tripleo-heat-templates,stable/wallaby,Ia72c9d088326f4652e5844f09dd283dfcea4f8b8,Use dumb-init for nova migration target cmd,MERGED,2023-04-05 12:16:15.000000000,2023-04-18 09:17:03.000000000,2023-04-18 09:17:03.000000000,"[{'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}, {'_account_id': 34598}]","[{'number': 1, 'created': '2023-04-05 12:16:15.000000000', 'files': ['deployment/nova/nova-migration-target-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/829a6574a887a333e855594da51fb8413ee4779f', 'message': ""Use dumb-init for nova migration target cmd\n\nThe libvirt container image used for the subject container\nno longer contains dumb-init in its entrypoint, because\nother (not init-like) containers that use it, run in the host\npid namespace.\n\nAdd dumb-init to the migration target container directly as it\ndoesn't run in the host pid ns.\n\nDepends-On: I80d44b15e92563df7f0cce8c2c52097f406780cb\nRelated: rhbz#2168530\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: Ia72c9d088326f4652e5844f09dd283dfcea4f8b8\n""}]",3,879543,829a6574a887a333e855594da51fb8413ee4779f,12,7,1,6926,,,0,"Use dumb-init for nova migration target cmd

The libvirt container image used for the subject container
no longer contains dumb-init in its entrypoint, because
other (not init-like) containers that use it, run in the host
pid namespace.

Add dumb-init to the migration target container directly as it
doesn't run in the host pid ns.

Depends-On: I80d44b15e92563df7f0cce8c2c52097f406780cb
Related: rhbz#2168530
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
Change-Id: Ia72c9d088326f4652e5844f09dd283dfcea4f8b8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/879543/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-migration-target-container-puppet.yaml'],1,829a6574a887a333e855594da51fb8413ee4779f,," template: ""dumb-init --single-child -- /usr/sbin/sshd -D -p SSHDPORT"""," template: ""/usr/sbin/sshd -D -p SSHDPORT""",1,1
openstack%2Fceilometer~stable%2Fxena~I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,openstack/ceilometer,stable/xena,I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,Add vanity names to telemetry polling notifications,MERGED,2023-04-17 05:56:21.000000000,2023-04-18 08:56:29.000000000,2023-04-18 08:54:38.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 05:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3d66c030b254517e4b18dbfae65c0aad24b9c30d', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nDepends-On: https://review.opendev.org/c/openstack/ceilometer/+/877647\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}, {'number': 2, 'created': '2023-04-17 05:56:39.000000000', 'files': ['ceilometer/telemetry/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ec42d03fab70789764fc69794c508581a1b1b263', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nDepends-On: https://review.opendev.org/c/openstack/ceilometer/+/880505\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}]",1,880507,ec42d03fab70789764fc69794c508581a1b1b263,13,2,2,32240,,,0,"Add vanity names to telemetry polling notifications

This change adds ""project_name"" and ""user_name"" fields
to polling samples which is related to the identification
of vanity names change 79454d6b22787627ae6239aa7b2707101ba30212

Depends-On: https://review.opendev.org/c/openstack/ceilometer/+/880505

Change-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc
(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/07/880507/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/telemetry/notifications.py'],1,3d66c030b254517e4b18dbfae65c0aad24b9c30d,enhanced_metrics-stable/xena," user_name=sample_dict['user_name'], project_name=sample_dict['project_name'],",,2,0
openstack%2Fceilometer~master~I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94,openstack/ceilometer,master,I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94,Add vanity names to notification samples,MERGED,2023-04-04 05:43:05.000000000,2023-04-18 08:55:52.000000000,2023-04-18 08:54:40.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-04 05:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/592a0aa23f60eec9d317dc56851dc4f47fd41471', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n'}, {'number': 2, 'created': '2023-04-04 07:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/125cf78318b105171a89659b23d3e4dbe5a2b4c7', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n'}, {'number': 3, 'created': '2023-04-04 12:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/99745bd5ba633f055cc313015772147b3ed90735', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n'}, {'number': 4, 'created': '2023-04-04 12:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1c8964bbbcb6fd9528d0a97293bb5188ab0a353c', 'message': 'Include vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n'}, {'number': 5, 'created': '2023-04-04 13:32:58.000000000', 'files': ['ceilometer/cache_utils.py', 'ceilometer/meter/notifications.py', 'ceilometer/sample.py', 'ceilometer/tests/unit/meter/test_notifications.py', 'ceilometer/polling/manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6e339d3e74df5460d372b3e2abce27664ddb1100', 'message': 'Add vanity names to notification samples\n\nThis change adds ""project_name"" and ""user_name"" fields to the\npolling samples created from notifications of ""event_type"".\n\nAlso move caching helper functions into ""ceilometer/cache_utils.py""\nto make them accessible throughout the project.\n\nChange-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94\n'}]",7,879418,6e339d3e74df5460d372b3e2abce27664ddb1100,15,2,5,32240,,,0,"Add vanity names to notification samples

This change adds ""project_name"" and ""user_name"" fields to the
polling samples created from notifications of ""event_type"".

Also move caching helper functions into ""ceilometer/cache_utils.py""
to make them accessible throughout the project.

Change-Id: I68bd4ee096b28a2fd952e749d56a6b3eed9bfb94
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/879418/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cache_utils.py', 'ceilometer/meter/notifications.py', 'ceilometer/sample.py', 'ceilometer/polling/manager.py']",4,592a0aa23f60eec9d317dc56851dc4f47fd41471,enhanced_metrics," cache_utils.resolve_uuid_from_cache( self.manager.conf, ""projects"", sample.project_id cache_utils.resolve_uuid_from_cache( self.manager.conf, ""users"", sample.user_id"," def resolve_uuid_from_cache(self, attr, uuid): if self.cache_client: name = self.cache_client.get(uuid) if name: return name # empty cache_client means either caching is not enabled or # there was an error configuring cache name = self.resolve_uuid_from_keystone(attr, uuid) self.cache_client.set(uuid, name) return name # Retrieve project and user names from Keystone only # if ceilometer doesn't have a caching backend return self.resolve_uuid_from_keystone(attr, uuid) def resolve_uuid_from_keystone(self, attr, uuid): try: return getattr(self.ks_client, attr).get(uuid).name except AttributeError as e: LOG.warning(""Found '%s' while resolving uuid %s to name"", e, uuid) except ka_exceptions.NotFound as e: LOG.warning(e.message) self.resolve_uuid_from_cache( ""projects"", sample.project_id self.resolve_uuid_from_cache( ""users"", sample.user_id",50,30
openstack%2Fceilometer~stable%2Fxena~Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,openstack/ceilometer,stable/xena,Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,Add user/project names to polled samples,MERGED,2023-04-17 05:41:44.000000000,2023-04-18 08:55:42.000000000,2023-04-18 08:54:36.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 05:41:44.000000000', 'files': ['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a43afad30f9fa96417f95cc25580d687b8acdf2e', 'message': 'Add user/project names to polled samples\n\nProject and user names would be first fetched from cache, if not found,\nthey will be requested from keystone and then cached. Using cache will\nsignificanlty reduce the number of calls made to keystone.\n\nIf ceilometer is configured with no caching backend, the results\nwill always be fetched by querying request to keystone.\n\nA new config option, `tenant_name_discovery` is introduced\nto operate this feature. This feature is optional and is disabled by default.\n\nNo attempts to identify names will be made if uuids are found to be `None`.\n\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)\n(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)\n'}]",0,880505,a43afad30f9fa96417f95cc25580d687b8acdf2e,9,2,1,32240,,,0,"Add user/project names to polled samples

Project and user names would be first fetched from cache, if not found,
they will be requested from keystone and then cached. Using cache will
significanlty reduce the number of calls made to keystone.

If ceilometer is configured with no caching backend, the results
will always be fetched by querying request to keystone.

A new config option, `tenant_name_discovery` is introduced
to operate this feature. This feature is optional and is disabled by default.

No attempts to identify names will be made if uuids are found to be `None`.

Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27
(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)
(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/05/880505/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py']",6,a43afad30f9fa96417f95cc25580d687b8acdf2e,enhanced_metrics-stable/xena," ks_client = mock.Mock(auth_token='fake_token') ks_client.projects.get.return_value = mock.Mock( name='admin', id='4465ecd1438b4d23a866cf8447387a7b' ) ks_client.users.get.return_value = mock.Mock( name='admin', id='c0c935468e654d5a8baae1a08adf4dfb' ) self.useFixture(fixtures.MockPatch( 'ceilometer.keystone_client.get_client', return_value=ks_client)) self.ks_client = ks_client",,138,2
openstack%2Fpuppet-openstack-integration~stable%2F2023.1~I2947d21ee75b53c3916b50151a401d26180590c9,openstack/puppet-openstack-integration,stable/2023.1,I2947d21ee75b53c3916b50151a401d26180590c9,Exclude system packages from tempest virtualenv,MERGED,2023-04-18 00:26:58.000000000,2023-04-18 08:52:05.000000000,2023-04-18 08:52:05.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 00:26:58.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7c3df318b0f5d0977def5ebd3514002da9fa25cb', 'message': 'Exclude system packages from tempest virtualenv\n\nIn Debian/Ubuntu we install tempest from source, thus all system\npackages should be excluded to avoid conflicts between system packages\nand packages installed by pip.\n\nChange-Id: I2947d21ee75b53c3916b50151a401d26180590c9\n(cherry picked from commit 1fa65898cfaabe366b4b7910fe147aee28e613ad)\n'}]",3,880594,7c3df318b0f5d0977def5ebd3514002da9fa25cb,12,2,1,9816,,,0,"Exclude system packages from tempest virtualenv

In Debian/Ubuntu we install tempest from source, thus all system
packages should be excluded to avoid conflicts between system packages
and packages installed by pip.

Change-Id: I2947d21ee75b53c3916b50151a401d26180590c9
(cherry picked from commit 1fa65898cfaabe366b4b7910fe147aee28e613ad)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/94/880594/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,7c3df318b0f5d0977def5ebd3514002da9fa25cb,," python3 -m virtualenv run_tempest /tmp/openstack/tempest/run_tempest/bin/pip3 install -c https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt -U -r requirements.txt /tmp/openstack/tempest/run_tempest/bin/python3 setup.py install # TODO(tobias-urdin): We must have the neutron-tempest-plugin to even test Neutron, is also required by # vpnaas and dynamic routing projects. if [ -d /home/zuul/src/opendev.org/openstack/neutron-tempest-plugin ]; then cp -R /home/zuul/src/opendev.org/openstack/neutron-tempest-plugin /tmp/openstack/neutron-tempest-plugin else git clone https://opendev.org/openstack/neutron-tempest-plugin /tmp/openstack/neutron-tempest-plugin fi pushd /tmp/openstack/neutron-tempest-plugin /tmp/openstack/tempest/run_tempest/bin/pip3 install -c https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt -U -r requirements.txt /tmp/openstack/tempest/run_tempest/bin/pip3 setup.py install popd "," # TODO(tobias-urdin): We must have the neutron-tempest-plugin to even test Neutron, is also required by # vpnaas and dynamic routing projects. $SUDO apt install -y python3-pip if [ -d /home/zuul/src/opendev.org/openstack/neutron-tempest-plugin ]; then cp -R /home/zuul/src/opendev.org/openstack/neutron-tempest-plugin /tmp/openstack/neutron-tempest-plugin else git clone https://opendev.org/openstack/neutron-tempest-plugin /tmp/openstack/neutron-tempest-plugin fi pushd /tmp/openstack/neutron-tempest-plugin $SUDO pip3 install . popd python3 -m virtualenv --system-site-packages run_tempest run_tempest/bin/pip3 install -c https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt -U -r requirements.txt run_tempest/bin/python3 setup.py install",16,15
openstack%2Fmistral-dashboard~master~If727ccd873977643670bcae8a4e402445feeb0ed,openstack/mistral-dashboard,master,If727ccd873977643670bcae8a4e402445feeb0ed,Update master for stable/2023.1,NEW,2023-03-06 09:19:33.000000000,2023-04-18 08:44:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-03-06 09:19:33.000000000', 'files': ['releasenotes/source/index.rst', 'releasenotes/source/2023.1.rst'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/0acbba2fb460b0dbc814330c780c2675b82f99bc', 'message': 'Update master for stable/2023.1\n\nAdd file to the reno documentation build to show release notes for\nstable/2023.1.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/2023.1.\n\nSem-Ver: feature\nChange-Id: If727ccd873977643670bcae8a4e402445feeb0ed\n'}]",0,876546,0acbba2fb460b0dbc814330c780c2675b82f99bc,4,3,1,22816,,,0,"Update master for stable/2023.1

Add file to the reno documentation build to show release notes for
stable/2023.1.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/2023.1.

Sem-Ver: feature
Change-Id: If727ccd873977643670bcae8a4e402445feeb0ed
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/46/876546/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/index.rst', 'releasenotes/source/2023.1.rst']",2,0acbba2fb460b0dbc814330c780c2675b82f99bc,reno-2023.1,=========================== 2023.1 Series Release Notes =========================== .. release-notes:: :branch: stable/2023.1 ,,7,0
openstack%2Fheat~master~Ia417e6c8ed9adc2ad0007fc58756baca01654a91,openstack/heat,master,Ia417e6c8ed9adc2ad0007fc58756baca01654a91,wip: Add timeout to AWS token generation request,NEW,2023-04-18 07:12:56.000000000,2023-04-18 08:33:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-18 07:12:56.000000000', 'files': ['heat/tests/api/aws/test_api_ec2token.py', 'heat/api/aws/ec2token.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/eff3b1894407186dc879bac8b938b8f2d631877f', 'message': 'wip: Add timeout to AWS token generation request\n\nChange-Id: Ia417e6c8ed9adc2ad0007fc58756baca01654a91\n'}]",0,880711,eff3b1894407186dc879bac8b938b8f2d631877f,3,1,1,9816,,,0,"wip: Add timeout to AWS token generation request

Change-Id: Ia417e6c8ed9adc2ad0007fc58756baca01654a91
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/880711/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/api/aws/test_api_ec2token.py', 'heat/api/aws/ec2token.py']",2,eff3b1894407186dc879bac8b938b8f2d631877f,," cfg.FloatOpt('timeout', default=30, help=_('Timeout in seconds for http requests to generate ' 'EC2 token')), try: response = requests.post(keystone_ec2_uri, data=creds_json, headers=headers, verify=self.ssl_options['verify'], cert=self.ssl_options['cert'], timeout=self._conf_get('timeout')) except: requests.exception.Timeout: LOG.exception('Authentication request timed out') raise exception.HeatInternalFailureError(_('Authentication ' 'request timed out')) "," response = requests.post(keystone_ec2_uri, data=creds_json, headers=headers, verify=self.ssl_options['verify'], cert=self.ssl_options['cert'])",37,15
openstack%2Fansible-collections-openstack~master~I2d1b89e7cbd1a7e847f54ffd62778f953ba65863,openstack/ansible-collections-openstack,master,I2d1b89e7cbd1a7e847f54ffd62778f953ba65863,Add baremetal_deploy_template module,MERGED,2023-02-22 10:07:46.000000000,2023-04-18 08:30:01.000000000,2023-04-17 23:37:52.000000000,"[{'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-02-22 10:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/36126271488d744efa81984a21dbcc432457fc5b', 'message': 'Add baremetal_deploy_template module\n\nThis module supports managing deploy template resources in OpenStack\nIronic.\n\nhttps: //docs.openstack.org/ironic/latest/admin/node-deployment.html#deploy-templates\n\nChange-Id: I2d1b89e7cbd1a7e847f54ffd62778f953ba65863\n'}, {'number': 2, 'created': '2023-03-28 12:05:38.000000000', 'files': ['ci/roles/baremetal_deploy_template/defaults/main.yml', 'ci/roles/baremetal_deploy_template/tasks/main.yml', 'meta/runtime.yml', 'plugins/modules/baremetal_deploy_template.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/454a05452b6f1298a225b8f92c1d63ecfe7f161a', 'message': 'Add baremetal_deploy_template module\n\nThis module supports managing deploy template resources in OpenStack\nIronic.\n\nhttps: //docs.openstack.org/ironic/latest/admin/node-deployment.html#deploy-templates\n\nChange-Id: I2d1b89e7cbd1a7e847f54ffd62778f953ba65863\n'}]",5,874755,454a05452b6f1298a225b8f92c1d63ecfe7f161a,13,5,2,14826,,,0,"Add baremetal_deploy_template module

This module supports managing deploy template resources in OpenStack
Ironic.

https: //docs.openstack.org/ironic/latest/admin/node-deployment.html#deploy-templates

Change-Id: I2d1b89e7cbd1a7e847f54ffd62778f953ba65863
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/55/874755/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/baremetal_deploy_template/defaults/main.yml', 'ci/roles/baremetal_deploy_template/tasks/main.yml', 'meta/runtime.yml', 'plugins/modules/baremetal_deploy_template.py']",4,36126271488d744efa81984a21dbcc432457fc5b,,"#!/usr/bin/python # -*- coding: utf-8 -*- # Copyright (c) 2023 StackHPC Ltd. # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt) DOCUMENTATION = r''' module: baremetal_deploy_template short_description: Create/Delete Bare Metal deploy template Resources from OpenStack author: OpenStack Ansible SIG description: - Create, Update and Remove ironic deploy templates from OpenStack. options: extra: description: - A set of one or more arbitrary metadata key and value pairs. type: dict id: description: - ID of the deploy template. - Will be auto-generated if not specified. type: str aliases: ['uuid'] name: description: - Name of the deploy template. - Must be formatted as a trait name (see API reference). - Required when the deploy template is created, after which the name or ID may be used. type: str steps: description: - List of deploy steps to apply. - Required when the deploy template is created. type: list elements: dict state: description: - Indicates desired state of the resource choices: ['present', 'absent'] default: present type: str extends_documentation_fragment: - openstack.cloud.openstack ''' EXAMPLES = r''' - name: Create Bare Metal deploy template openstack.cloud.baremetal_deploy_template: cloud: devstack state: present name: CUSTOM_FOO steps: - interface: bios step: apply_configuration args: settings: - name: LogicalProc value: Enabled priority: 110 extra: something: extra register: result - name: Delete Bare Metal deploy template openstack.cloud.baremetal_deploy_template: cloud: devstack state: absent id: 1a85ebca-22bf-42eb-ad9e-f640789b8098 register: result - name: Update Bare Metal deploy template openstack.cloud.baremetal_deploy_template: cloud: devstack state: present id: 1a85ebca-22bf-42eb-ad9e-f640789b8098 extra: something: new ''' RETURN = r''' template: description: A deploy template dictionary, subset of the dictionary keys listed below may be returned, depending on your cloud provider. returned: success type: dict contains: created_at: description: Bare Metal deploy template created at timestamp. returned: success type: str extra: description: A set of one or more arbitrary metadata key and value pairs. returned: success type: dict id: description: The UUID for the Baremetal Deploy Template resource. returned: success type: str links: description: A list of relative links, including the self and bookmark links. returned: success type: list location: description: Cloud location of this resource (cloud, project, region, zone) returned: success type: dict name: description: Bare Metal deploy template name. returned: success type: str steps: description: A list of deploy steps. returned: success type: list elements: dict updated_at: description: Bare Metal deploy template updated at timestamp. returned: success type: str ''' from ansible_collections.openstack.cloud.plugins.module_utils.openstack import ( OpenStackModule ) class BaremetalDeployTemplateModule(OpenStackModule): argument_spec = dict( extra=dict(type='dict'), id=dict(aliases=['uuid']), name=dict(), steps=dict(type='list', elements='dict'), state=dict(default='present', choices=['present', 'absent']), ) module_kwargs = dict( required_one_of=[ ('id', 'name'), ], ) def run(self): template = self._find_deploy_template() state = self.params['state'] if state == 'present': # create or update deploy template kwargs = {} for k in ['extra', 'id', 'name', 'steps']: if self.params[k] is not None: kwargs[k] = self.params[k] changed = True if not template: # create deploy template template = self.conn.baremetal.create_deploy_template(**kwargs) else: # update deploy template updates = dict((k, v) for k, v in kwargs.items() if v != template[k]) if updates: template = \ self.conn.baremetal.update_deploy_template(template['id'], **updates) else: changed = False self.exit_json(changed=changed, template=template.to_dict(computed=False)) if state == 'absent': # remove deploy template if not template: self.exit_json(changed=False) template = self.conn.baremetal.delete_deploy_template(template['id']) self.exit_json(changed=True) def _find_deploy_template(self): id_or_name = self.params['id'] if self.params['id'] else self.params['name'] try: return self.conn.baremetal.get_deploy_template(id_or_name) except self.sdk.exceptions.ResourceNotFound: return None def main(): module = BaremetalDeployTemplateModule() module() if __name__ == ""__main__"": main() ",,264,0
openstack%2Fcharm-ops-sunbeam~main~I92ab284877e39bb81065ba4c9f996e64c5144b0f,openstack/charm-ops-sunbeam,main,I92ab284877e39bb81065ba4c9f996e64c5144b0f,Lazy import KubernetesServicePatch,MERGED,2023-04-15 05:27:25.000000000,2023-04-18 08:29:57.000000000,2023-04-18 08:29:57.000000000,"[{'_account_id': 12549}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-15 05:27:25.000000000', 'files': ['ops_sunbeam/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-ops-sunbeam/commit/b8581a293cfe30cc3bd1cf3b4e9296d876e395bd', 'message': 'Lazy import KubernetesServicePatch\n\nKubernetesServicePatch is not required by\nOSBaseOperatorCharm and any machine charms that\nextend OSBaseOperatorCharm. However the global\nlevel import mandates the machine charm to\ninclude observability_libs. To avoid this,\nlazy import KubernetesServicePatch in OSBaseOperatorAPICharm.\n\nChange-Id: I92ab284877e39bb81065ba4c9f996e64c5144b0f\n'}]",0,880563,b8581a293cfe30cc3bd1cf3b4e9296d876e395bd,6,2,1,10366,,,0,"Lazy import KubernetesServicePatch

KubernetesServicePatch is not required by
OSBaseOperatorCharm and any machine charms that
extend OSBaseOperatorCharm. However the global
level import mandates the machine charm to
include observability_libs. To avoid this,
lazy import KubernetesServicePatch in OSBaseOperatorAPICharm.

Change-Id: I92ab284877e39bb81065ba4c9f996e64c5144b0f
",git fetch https://review.opendev.org/openstack/charm-ops-sunbeam refs/changes/63/880563/1 && git format-patch -1 --stdout FETCH_HEAD,['ops_sunbeam/charm.py'],1,b8581a293cfe30cc3bd1cf3b4e9296d876e395bd,ops-kube-patcher-v1," from charms.observability_libs.v1.kubernetes_service_patch import ( KubernetesServicePatch, ) self.service_patcher = KubernetesServicePatch(",import charms.observability_libs.v1.kubernetes_service_patch as kube_svc_patch self.service_patcher = kube_svc_patch.KubernetesServicePatch(,5,2
openstack%2Fcinder~stable%2Fxena~I437767dda99a6f075fb3bf8cae626e2e32e2d0ac,openstack/cinder,stable/xena,I437767dda99a6f075fb3bf8cae626e2e32e2d0ac,DNM: Test change in run-tempest role,ABANDONED,2023-01-12 10:04:52.000000000,2023-04-18 08:26:11.000000000,,"[{'_account_id': 22348}, {'_account_id': 30615}, {'_account_id': 35679}]","[{'number': 1, 'created': '2023-01-12 10:04:52.000000000', 'files': ['cinder/api/common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/51857b51f83d10e5d300bd649149a83dcfc938c3', 'message': 'DNM: Test change in run-tempest role\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/869440\nChange-Id: I437767dda99a6f075fb3bf8cae626e2e32e2d0ac\n'}]",2,869920,51857b51f83d10e5d300bd649149a83dcfc938c3,15,3,1,30674,,,0,"DNM: Test change in run-tempest role

Depends-On: https://review.opendev.org/c/openstack/tempest/+/869440
Change-Id: I437767dda99a6f075fb3bf8cae626e2e32e2d0ac
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/869920/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/common.py'],1,51857b51f83d10e5d300bd649149a83dcfc938c3,test/updated-run-tempest-role," 'resource returns in a single response.'),"," 'resource returns in a single response'),",1,1
openstack%2Fpuppet-openstack-integration~master~I09437ee4c507e711954fa5f95fc986e5971db220,openstack/puppet-openstack-integration,master,I09437ee4c507e711954fa5f95fc986e5971db220,Updated from Puppet OpenStack modules constraints,MERGED,2023-04-18 02:21:52.000000000,2023-04-18 08:17:09.000000000,2023-04-18 08:17:09.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-18 02:21:52.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/aa4a07a43ff442c4f21e7487ea0bcaa22f9a4450', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: I09437ee4c507e711954fa5f95fc986e5971db220\n'}]",0,880699,aa4a07a43ff442c4f21e7487ea0bcaa22f9a4450,6,2,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: I09437ee4c507e711954fa5f95fc986e5971db220
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/99/880699/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,aa4a07a43ff442c4f21e7487ea0bcaa22f9a4450,openstack/puppet/constraints, :ref => 'v14.0.0', :ref => 'v13.3.0',1,1
openstack%2Fpuppet-ceilometer~stable%2Fyoga~I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8,openstack/puppet-ceilometer,stable/yoga,I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8,Add new parameter `tenant_name_discovery`,MERGED,2023-03-17 07:04:12.000000000,2023-04-18 07:44:39.000000000,2023-04-18 07:43:47.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-17 07:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/c61a10564980b7a4c94f339d16037a645fcae847', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-on: https://review.opendev.org/852948\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 2, 'created': '2023-03-17 07:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/b896d1badacdfbd50f3690718eba184638d45f9c', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-on: https://review.opendev.org/852948\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 3, 'created': '2023-03-17 07:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/6fa923a4fad1113e04a28544a103da30b5dd62b7', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-on: https://review.opendev.org/877647\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 4, 'created': '2023-03-27 09:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/5fc16985cdd61367ed4e47b624e79a514403b28a', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-on: https://review.opendev.org/852948\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 5, 'created': '2023-03-27 09:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/e6f23bdd25c1870ca76a3d314da2a958e20e73d8', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-on: https://review.opendev.org/852948\nDepends-on: https://review.opendev.org/c/openstack/puppet-ceilometer/+/878434\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 6, 'created': '2023-03-27 09:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/13b61aa970429491d7f5031f8e5314c0e8268511', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nDepends-On: https://review.opendev.org/852948\nDepends-On: https://review.opendev.org/c/openstack/puppet-ceilometer/+/878434\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}, {'number': 7, 'created': '2023-03-27 09:58:59.000000000', 'files': ['releasenotes/notes/add_tenant_name_discovery-4671aec3daae9622.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/9d54bcd658b659758db3c79887e42222368c9f44', 'message': 'Add new parameter `tenant_name_discovery`\n\nEnabling this parameter will identify user and project\nnames from the polled metrics [1].\n\nThese details are collected by making additional requests\nto keystone service, depending upon the scale of environment,\nnumber of projects/users and the count of metrics polled in\nevery iteration, enabling this could overwhelm the keystone\nservice.\n\n[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n\nConflicts:\n\tmanifests/agent/polling.pp\n\nDepends-On: https://review.opendev.org/877647\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8\n(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)\n'}]",3,877648,9d54bcd658b659758db3c79887e42222368c9f44,23,3,7,32240,,,0,"Add new parameter `tenant_name_discovery`

Enabling this parameter will identify user and project
names from the polled metrics [1].

These details are collected by making additional requests
to keystone service, depending upon the scale of environment,
number of projects/users and the count of metrics polled in
every iteration, enabling this could overwhelm the keystone
service.

[1] Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27

Conflicts:
	manifests/agent/polling.pp

Depends-On: https://review.opendev.org/877647
Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: I045c7cd7a86d0f7f97a9078cbfc74353dcff0eb8
(cherry picked from commit b00000fb86e2882c11fb399d9adf410812a895bd)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/48/877648/5 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add_tenant_name_discovery-4671aec3daae9622.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb']",3,c61a10564980b7a4c94f339d16037a645fcae847,enhanced_metrics-stable/yoga," should contain_ceilometer_config('DEFAULT/tenant_name_discovery').with_value('<SERVICE DEFAULT>')<<<<<<< HEAD (f43133 Update TOX_CONSTRAINTS_FILE for stable/yoga) ======= context 'with central parameters set' do before do params.merge!( :tenant_name_discovery => false ) end it { should contain_ceilometer_config('DEFAULT/tenant_name_discovery').with_value(false) } end context 'with compute namespace disabled' do before do params.merge!( :compute_namespace => false ) end it { should contain_ceilometer_config('DEFAULT/polling_namespaces').with_value('central,ipmi') should contain_ceilometer_config('compute/instance_discovery_method').with_ensure('absent') should contain_ceilometer_config('compute/resource_update_interval').with_ensure('absent') should contain_ceilometer_config('compute/resource_cache_expiry').with_ensure('absent') } end context 'with central namespace disabled' do before do params.merge!( :central_namespace => false, ) end it { should contain_ceilometer_config('DEFAULT/polling_namespaces').with_value('compute,ipmi') should contain_ceilometer_config('DEFAULT/tenant_name_discovery').with_ensure('absent') } end >>>>>>> CHANGE (b00000 Add new parameter `tenant_name_discovery`)",,73,0
openstack%2Fcharm-keystone~master~I049ff3971a1afa6270f466e62ca660f8b92f5ae8,openstack/charm-keystone,master,I049ff3971a1afa6270f466e62ca660f8b92f5ae8,Add relation with Prometheus and Grafana,ABANDONED,2021-08-16 14:46:31.000000000,2023-04-18 07:25:54.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 32363}]","[{'number': 1, 'created': '2021-08-16 14:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/d6111cf2b4f3039da7d94a823afefc4ab178ab64', 'message': 'add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\nChange-Id: I99c685a476ed671f76262d24cbdfcb5e67fc698b\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 2, 'created': '2021-08-16 14:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/94d29224a3a8ae57dcbd99878884d5a99fe2abfb', 'message': 'add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 3, 'created': '2021-08-25 10:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/38f7019578214aeb873ee43b168b1058cad1b33c', 'message': 'add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 4, 'created': '2021-08-27 10:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/40d3d8f034896eacb7ee525f5a96884c62021898', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 5, 'created': '2021-08-27 10:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b08cae05a4932193710b499eaa76e20e58296165', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 6, 'created': '2021-11-15 16:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/450e4bb23e1b60ce03fed1a0e9f7cc21a140ecd4', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 7, 'created': '2021-11-16 07:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/599f2c2350bbf58faae358f04d607f81f526686b', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n - chamrhelpers has been sync for  PR [2] tesning only\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n[2]: https://github.com/juju/charm-helpers/pull/630\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 8, 'created': '2021-11-16 13:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/bbc12d474fc4f89162bb5004440dc072958b8b78', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n - chamrhelpers has been sync for  PR [2] tesning only\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n[2]: https://github.com/juju/charm-helpers/pull/630\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}, {'number': 9, 'created': '2021-12-15 15:11:52.000000000', 'files': ['charmhelpers/contrib/templating/__init__.py', 'charmhelpers/contrib/templating/contexts.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/fetch/snap.py', 'config.yaml', 'hooks/keystone_hooks.py', 'hooks/grafana-relation-deoarted', 'charmhelpers/contrib/openstack/cert_utils.py', 'charm-helpers-hooks.yaml', 'charmhelpers/core/strutils.py', 'charmhelpers/contrib/charmsupport/volumes.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/core/unitdata.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/neutron.py', 'charmhelpers/contrib/templating/pyformat.py', 'charmhelpers/contrib/openstack/deferred_events.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/fetch/__init__.py', 'charmhelpers/contrib/hardening/utils.py', 'charmhelpers/contrib/openstack/templates/grafana-haproxy-dashboard.json.j2', 'charmhelpers/contrib/storage/linux/lvm.py', 'charmhelpers/contrib/openstack/files/policy_rc_d_script.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'hooks/haproxy-exporter-relation-deoarted', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/core/host_factory/ubuntu.py', 'README.md', 'charmhelpers/fetch/python/packages.py', 'hooks/haproxy-exporter-relation-joined', 'hooks/grafana-relation-joined', 'charmhelpers/core/host.py', 'charmhelpers/contrib/templating/jinja.py', 'unit_tests/test_keystone_hooks.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/hardening/host/templates/login.defs', 'metadata.yaml', 'hooks/haproxy-exporter-relation-changed', 'hooks/grafana-relation-changed'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/9cd49d294e5fab5e8ee0334c928f5f539821f210', 'message': 'Add relation with Prometheus and Grafana\n\n - add prometheus-relation-{joined,changed}\n   - this will ensure that prometheus collects metrics of HAProxy\n - add prometheus-relation-departed\n - add grafana-relation-{joined,changed}\n   - this will create a new dashboard for HAProxy\n - add grafana-relation-departed\n - this depends on [1]\n - chamrhelpers has been sync for  PR [2] tesning only\n\n[1]: https://github.com/juju/charm-helpers/issues/629\n[2]: https://github.com/juju/charm-helpers/pull/630\n\nChange-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8\n'}]",20,804760,9cd49d294e5fab5e8ee0334c928f5f539821f210,35,3,9,32363,,,0,"Add relation with Prometheus and Grafana

 - add prometheus-relation-{joined,changed}
   - this will ensure that prometheus collects metrics of HAProxy
 - add prometheus-relation-departed
 - add grafana-relation-{joined,changed}
   - this will create a new dashboard for HAProxy
 - add grafana-relation-departed
 - this depends on [1]
 - chamrhelpers has been sync for  PR [2] tesning only

[1]: https://github.com/juju/charm-helpers/issues/629
[2]: https://github.com/juju/charm-helpers/pull/630

Change-Id: I049ff3971a1afa6270f466e62ca660f8b92f5ae8
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/60/804760/9 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/grafana-relation-joined', 'unit_tests/test_keystone_hooks.py', 'hooks/prometheus-relation-joined', 'config.yaml', 'hooks/keystone_hooks.py', 'hooks/grafana-relation-deoarted', 'hooks/prometheus-relation-changed', 'metadata.yaml', 'hooks/prometheus-relation-deoarted', 'README.md', 'hooks/grafana-relation-changed']",11,d6111cf2b4f3039da7d94a823afefc4ab178ab64,change-804760,keystone_hooks.py,,141,0
openstack%2Fskyline-console~master~Ibde82772c509babfbde06d6ce1db663a2340b317,openstack/skyline-console,master,Ibde82772c509babfbde06d6ce1db663a2340b317,fix: fix the pool data,MERGED,2023-04-18 03:34:35.000000000,2023-04-18 07:00:34.000000000,2023-04-18 06:59:29.000000000,"[{'_account_id': 22348}, {'_account_id': 28706}, {'_account_id': 33196}, {'_account_id': 33689}]","[{'number': 1, 'created': '2023-04-18 03:34:35.000000000', 'files': ['src/pages/monitor/containers/StorageCluster/RenderTabs.jsx'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/d792dfc654c56b7748f5512e45420076f0a2be9a', 'message': ""fix: fix the pool data\n\nUpdate the custom key name to better filter the tab data, the api's response data may have the key 'type'.\n\nChange-Id: Ibde82772c509babfbde06d6ce1db663a2340b317\n""}]",0,880703,d792dfc654c56b7748f5512e45420076f0a2be9a,9,4,1,30434,,,0,"fix: fix the pool data

Update the custom key name to better filter the tab data, the api's response data may have the key 'type'.

Change-Id: Ibde82772c509babfbde06d6ce1db663a2340b317
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/03/880703/1 && git format-patch -1 --stdout FETCH_HEAD,['src/pages/monitor/containers/StorageCluster/RenderTabs.jsx'],1,d792dfc654c56b7748f5512e45420076f0a2be9a,pool," tabType: 'pool', tabType: 'osd', let originData = data.filter((d) => d.tabType === tab);"," type: 'pool', type: 'osd', let originData = data.filter((d) => d.type === tab);",3,3
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ieeea6267b7c35a76f83a463a7247802cba99c4b5,openstack/tripleo-heat-templates,stable/wallaby,Ieeea6267b7c35a76f83a463a7247802cba99c4b5,Add update of OVN cluster container.,MERGED,2023-02-13 16:15:41.000000000,2023-04-18 06:58:42.000000000,2023-04-18 06:58:42.000000000,"[{'_account_id': 6681}, {'_account_id': 8655}, {'_account_id': 9816}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 32432}]","[{'number': 1, 'created': '2023-02-13 16:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75c7b71f171e2e3695bb66966bb2dbfe176cb0fd', 'message': 'Add update of OVN cluster container.\n\nAs no deploy step above 0 exists, and all configuration is done in\nansible (vs puppet), the update process was not picking up the new\ncontainer from deployment tasks.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nCloses-Bug: #2004575\nResolved-conflicts:\n- deployment/ovn/ovn-dbs-cluster-ansible.yaml\nupgrade_tasks ""Remove OVNDBs from pacemaker"" in wallaby only\n\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n(cherry picked from commit 73b0fc546788050e8f5aab69327244e6090a404e)\n'}, {'number': 2, 'created': '2023-02-21 12:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1ba060551bd238854d5a574ed57a5842fa865ece', 'message': 'Add update of OVN cluster container.\n\nCurrently OVN cluster images are not updated during update.\n\nFor container to be updated we rely on either:\n- explicit update tasks: like it\'s done for pacemaker for instance;\n- docker_config tasks: those triggered by common_deploy_steps_tasks;\n\nHere the ovn cluster is setup using ansible and no extra update tasks\nare present, which makes the update process to ignore change in the\ncontainer image configuration.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nFurthermore we move the generation of the new container definition (in\n/var/lib/tripleo-config/container-startup-config) earlier in the\nupdate process. Doing so enable the new image definition to be\navailable during the update tasks.\n\nCloses-Bug: #2004575\nResolved-conflicts:\n- deployment/ovn/ovn-dbs-cluster-ansible.yaml\nupgrade_tasks ""Remove OVNDBs from pacemaker"" in wallaby only\n\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n(cherry picked from commit 73b0fc546788050e8f5aab69327244e6090a404e)\n'}, {'number': 3, 'created': '2023-03-16 14:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80d236191d943e55cce7bd08f79d03fc8c2098e7', 'message': 'Add update of OVN cluster container.\n\nCurrently OVN cluster images are not updated during update.\n\nFor container to be updated we rely on either:\n- explicit update tasks: like it\'s done for pacemaker for instance;\n- docker_config tasks: those triggered by common_deploy_steps_tasks;\n\nHere the ovn cluster is setup using ansible and no extra update tasks\nare present, which makes the update process to ignore change in the\ncontainer image configuration.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nFurthermore we move the generation of the new container definition (in\n/var/lib/tripleo-config/container-startup-config) earlier in the\nupdate process. Doing so enable the new image definition to be\navailable during the update tasks.\n\nCloses-Bug: #2004575\nResolved-conflicts:\n- deployment/ovn/ovn-dbs-cluster-ansible.yaml\nupgrade_tasks ""Remove OVNDBs from pacemaker"" in wallaby only\n\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n(cherry picked from commit 7c788313f7af394c1002ca8c9c5a6db6fd848979)\n'}, {'number': 4, 'created': '2023-03-23 01:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4c5d423cd65b6ba7295620b052a62328a9ab091', 'message': 'Add update of OVN cluster container.\n\nCurrently OVN cluster images are not updated during update.\n\nFor container to be updated we rely on either:\n- explicit update tasks: like it\'s done for pacemaker for instance;\n- docker_config tasks: those triggered by common_deploy_steps_tasks;\n\nHere the ovn cluster is setup using ansible and no extra update tasks\nare present, which makes the update process to ignore change in the\ncontainer image configuration.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nFurthermore we move the generation of the new container definition (in\n/var/lib/tripleo-config/container-startup-config) earlier in the\nupdate process. Doing so enable the new image definition to be\navailable during the update tasks.\n\nCloses-Bug: #2004575\nResolved-conflicts:\n- deployment/ovn/ovn-dbs-cluster-ansible.yaml\nupgrade_tasks ""Remove OVNDBs from pacemaker"" in wallaby only\n\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n(cherry picked from commit 3780ed21bb7f4a77cf2d124a43e4edc7245cef07)\n'}, {'number': 5, 'created': '2023-03-23 01:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dd4b2fa82a8d2037d1f01078da0759719315527e', 'message': 'Add update of OVN cluster container.\n\nCurrently OVN cluster images are not updated during update.\n\nFor container to be updated we rely on either:\n- explicit update tasks: like it\'s done for pacemaker for instance;\n- docker_config tasks: those triggered by common_deploy_steps_tasks;\n\nHere the ovn cluster is setup using ansible and no extra update tasks\nare present, which makes the update process to ignore change in the\ncontainer image configuration.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nFurthermore we move the generation of the new container definition (in\n/var/lib/tripleo-config/container-startup-config) earlier in the\nupdate process. Doing so enable the new image definition to be\navailable during the update tasks.\n\nCloses-Bug: #2004575\nResolved-conflicts:\n- deployment/ovn/ovn-dbs-cluster-ansible.yaml\nupgrade_tasks ""Remove OVNDBs from pacemaker"" in wallaby only\n\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n(cherry picked from commit 3780ed21bb7f4a77cf2d124a43e4edc7245cef07)\n'}, {'number': 6, 'created': '2023-04-14 07:19:08.000000000', 'files': ['common/deploy-steps.j2', 'deployment/ovn/ovn-dbs-cluster-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ff9272b85775fca203919f42e1012eb96f9ed3a', 'message': ""Add update of OVN cluster container.\n\nCurrently OVN cluster images are not updated during update.\n\nFor container to be updated we rely on either:\n- explicit update tasks: like it's done for pacemaker for instance;\n- docker_config tasks: those triggered by common_deploy_steps_tasks;\n\nHere the ovn cluster is setup using ansible and no extra update tasks\nare present, which makes the update process to ignore change in the\ncontainer image configuration.\n\nWe add the necessary code block in the update tasks so that the\ncluster container are updated using anchor and alias to avoid\nrepetition.\n\nFurthermore we move the generation of the new container definition (in\n/var/lib/tripleo-config/container-startup-config) earlier in the\nupdate process. Doing so enable the new image definition to be\navailable during the update tasks.\n\nCloses-Bug: #2004575\nChange-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5\n""}]",3,873602,4ff9272b85775fca203919f42e1012eb96f9ed3a,29,6,6,33080,,,0,"Add update of OVN cluster container.

Currently OVN cluster images are not updated during update.

For container to be updated we rely on either:
- explicit update tasks: like it's done for pacemaker for instance;
- docker_config tasks: those triggered by common_deploy_steps_tasks;

Here the ovn cluster is setup using ansible and no extra update tasks
are present, which makes the update process to ignore change in the
container image configuration.

We add the necessary code block in the update tasks so that the
cluster container are updated using anchor and alias to avoid
repetition.

Furthermore we move the generation of the new container definition (in
/var/lib/tripleo-config/container-startup-config) earlier in the
update process. Doing so enable the new image definition to be
available during the update tasks.

Closes-Bug: #2004575
Change-Id: Ieeea6267b7c35a76f83a463a7247802cba99c4b5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/873602/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-dbs-cluster-ansible.yaml'],1,75c7b71f171e2e3695bb66966bb2dbfe176cb0fd,," - block: &configure_ovn_db_northd - name: Configure OVN DBs and northd include_role: name: tripleo_ovn_cluster vars: tripleo_ovn_cluster_dbs_protocol: ""{{ enable_internal_tls | ternary('ssl', 'tcp', 'tcp') }}"" tripleo_ovn_cluster_network: {get_param: [ServiceNetMap, OvnDbsNetwork]} tripleo_ovn_cluster_nb_db_port: {get_param: OVNNorthboundServerPort} tripleo_ovn_cluster_sb_db_port: {get_param: OVNSouthboundServerPort} tripleo_ovn_cluster_nb_local_port: {get_param: OVNNorthboundClusterPort} tripleo_ovn_cluster_nb_remote_port: {get_param: OVNNorthboundClusterPort} tripleo_ovn_cluster_sb_local_port: {get_param: OVNSouthboundClusterPort} tripleo_ovn_cluster_sb_remote_port: {get_param: OVNSouthboundClusterPort} tripleo_ovn_cluster_northd_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_sb_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_nb_ssl_ca_cert: {get_param: InternalTLSCAFile} - block: &ovn_dbs_containers - name: Start OVN container include_role: name: tripleo_container_manage vars: tripleo_container_manage_config: ""/var/lib/tripleo-config/container-startup-config/step_0"" tripleo_container_manage_config_id: ""{{ ovn_container }}"" tripleo_container_manage_config_patterns: ""{{ ovn_container }}.json"" loop: - ovn_cluster_north_db_server - ovn_cluster_south_db_server - ovn_cluster_northd loop_control: loop_var: ovn_container update_tasks: - name: Configure OVN cluster during update when: step|int == 4 block: *configure_ovn_db_northd - name: Update OVN cluster containers when: step|int == 4 block: *ovn_dbs_containers"," - name: Configure OVN DBs and northd include_role: name: tripleo_ovn_cluster vars: tripleo_ovn_cluster_dbs_protocol: ""{{ enable_internal_tls | ternary('ssl', 'tcp', 'tcp') }}"" tripleo_ovn_cluster_network: {get_param: [ServiceNetMap, OvnDbsNetwork]} tripleo_ovn_cluster_nb_db_port: {get_param: OVNNorthboundServerPort} tripleo_ovn_cluster_sb_db_port: {get_param: OVNSouthboundServerPort} tripleo_ovn_cluster_nb_local_port: {get_param: OVNNorthboundClusterPort} tripleo_ovn_cluster_nb_remote_port: {get_param: OVNNorthboundClusterPort} tripleo_ovn_cluster_sb_local_port: {get_param: OVNSouthboundClusterPort} tripleo_ovn_cluster_sb_remote_port: {get_param: OVNSouthboundClusterPort} tripleo_ovn_cluster_northd_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_sb_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_nb_ssl_ca_cert: {get_param: InternalTLSCAFile} - name: Start OVN container include_role: name: tripleo_container_manage vars: tripleo_container_manage_config: ""/var/lib/tripleo-config/container-startup-config/step_0"" tripleo_container_manage_config_id: ""{{ ovn_container }}"" tripleo_container_manage_config_patterns: ""{{ ovn_container }}.json"" tripleo_container_manage_systemd_order: true loop: - ovn_cluster_north_db_server - ovn_cluster_south_db_server - ovn_cluster_northd loop_control: loop_var: ovn_container update_tasks: []",37,30
openstack%2Fcinder~master~I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7,openstack/cinder,master,I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7,Cinder Message API create failure,NEW,2023-03-06 15:25:58.000000000,2023-04-18 06:44:17.000000000,,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-06 15:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9ca67132565fbe2b219b0046279ec47faa87629', 'message': 'Cinder Message API create failure\n\nIf action is None, message event_id\nin message_record dict throws NoneType\nkeyerror.\n\nChange-Id: I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7\n'}, {'number': 2, 'created': '2023-03-06 16:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/354ae297afdd59bfb817a3933ff836f68ab3e7f6', 'message': 'Cinder Message API create failure\n\nIf action is None, message event_id\nin message_record dict throws NoneType\nkeyerror.\nCloses-Bug: #2009483\n\nChange-Id: I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7\n'}, {'number': 3, 'created': '2023-03-06 18:47:30.000000000', 'files': ['cinder/message/api.py', 'cinder/tests/unit/message/test_api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5fcb35546069d37763335a8dcbaa3261f2675129', 'message': 'Cinder Message API create failure\n\nIf action is None, message event_id\nin message_record dict throws NoneType\nkeyerror.\nCloses-Bug: #2009483\n\nChange-Id: I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7\n'}]",6,876587,5fcb35546069d37763335a8dcbaa3261f2675129,34,3,3,27741,,,0,"Cinder Message API create failure

If action is None, message event_id
in message_record dict throws NoneType
keyerror.
Closes-Bug: #2009483

Change-Id: I41c7487f7b78a3ca43b5b4ede18a0ea75c0e58f7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/876587/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/message/api.py'],1,d9ca67132565fbe2b219b0046279ec47faa87629,cinder_message_api_create_action_keyerror," action_id = action[0] if action else '' 'action_id': action_id, action_id,"," 'action_id': action[0] if action else '', action[0],",3,2
openstack%2Fplacement~master~I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2,openstack/placement,master,I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2,Bugtracker link update,MERGED,2023-03-07 17:03:05.000000000,2023-04-18 06:39:13.000000000,2023-04-18 06:38:17.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-03-07 17:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/f34dfef54d87289901bdeb7b94715b8ee6bac191', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker\nlink from storyboard to launchpad\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}, {'number': 2, 'created': '2023-03-07 17:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/7d1b8560b765ab8bbcbef17574f8736e6e4ea60b', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker,\nlink from storyboard to launchpad, so new bugs should be reported in\nlaunchpad instead storyboad.\n\nWhats not updated:\n- all links of storyboard which do not point to bugs\n- links of existing stories, features, docs etc\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}, {'number': 3, 'created': '2023-03-29 05:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/70748f19c0f546dfd8e939dbc19b91b30d130df0', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker,\nlink from storyboard to launchpad, so new bugs should be reported in\nlaunchpad instead storyboad.\n\nWhats not updated:\n- all links of storyboard which do not point to bugs\n- links of existing stories, features, docs etc\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}, {'number': 4, 'created': '2023-03-29 05:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2136261050e3996a59f68a0e7728330270ffd3e9', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker,\nlink from storyboard to launchpad, so new bugs should be reported in\nlaunchpad instead storyboad.\n\nWhats not updated:\n- all links of storyboard which do not point to bugs\n- links of existing stories, features, docs etc\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}, {'number': 5, 'created': '2023-03-29 16:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/a3e219b8ab3ce53ab9895af1fd8b4767b9f67cf6', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker,\nlink from storyboard to launchpad, so new bugs should be reported in\nlaunchpad instead storyboad.\n\nWhats not updated:\n- all links of storyboard which do not point to bugs\n- links of existing stories, features, docs etc\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}, {'number': 6, 'created': '2023-03-30 05:38:52.000000000', 'files': ['doc/source/contributor/contributing.rst', 'CONTRIBUTING.rst', 'README.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/placement/commit/972dfd4825a682e2d245daf5023363cd417cafbc', 'message': 'Bugtracker link update\n\nAs discussed in the upstream meeting, update the placement bug tracker,\nlink from storyboard to launchpad, so new bugs should be reported in\nlaunchpad instead storyboad.\n\nWhats not updated:\n- all links of storyboard which do not point to bugs\n- links of existing stories, features, docs etc\n\nChange-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2\n'}]",44,876768,972dfd4825a682e2d245daf5023363cd417cafbc,35,8,6,34860,,,0,"Bugtracker link update

As discussed in the upstream meeting, update the placement bug tracker,
link from storyboard to launchpad, so new bugs should be reported in
launchpad instead storyboad.

Whats not updated:
- all links of storyboard which do not point to bugs
- links of existing stories, features, docs etc

Change-Id: I64b9d6feb4fb35f36c5a290b8b79d9b78736efd2
",git fetch https://review.opendev.org/openstack/placement refs/changes/68/876768/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,f34dfef54d87289901bdeb7b94715b8ee6bac191,update-bug-tracker-link,- `Bug Tracker <https://bugs.launchpad.net/placement>`__,- `Bug Tracker <https://storyboard.openstack.org/#!/project/openstack/placement>`__,1,1
openstack%2Fceilometer~stable%2Fyoga~I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,openstack/ceilometer,stable/yoga,I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc,Add vanity names to telemetry polling notifications,MERGED,2023-03-27 09:56:12.000000000,2023-04-18 06:15:23.000000000,2023-04-18 06:13:05.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-27 09:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5489a36e707d0c8f8caf85a9e62f16d892488bb9', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}, {'number': 2, 'created': '2023-03-27 09:57:30.000000000', 'files': ['ceilometer/telemetry/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3517aceafce02b779387febaad16bae35b06cfac', 'message': 'Add vanity names to telemetry polling notifications\n\nThis change adds ""project_name"" and ""user_name"" fields\nto polling samples which is related to the identification\nof vanity names change 79454d6b22787627ae6239aa7b2707101ba30212\n\nDepends-On: https://review.opendev.org/c/openstack/ceilometer/+/877647\n\nChange-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc\n(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)\n'}]",1,878653,3517aceafce02b779387febaad16bae35b06cfac,13,2,2,32240,,,0,"Add vanity names to telemetry polling notifications

This change adds ""project_name"" and ""user_name"" fields
to polling samples which is related to the identification
of vanity names change 79454d6b22787627ae6239aa7b2707101ba30212

Depends-On: https://review.opendev.org/c/openstack/ceilometer/+/877647

Change-Id: I5fbe97439e7fadbdd8fd2641c49f1c88fbc416fc
(cherry picked from commit 2a5f63da95a26dae46707a2a22e593604726aeae)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/53/878653/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/telemetry/notifications.py'],1,5489a36e707d0c8f8caf85a9e62f16d892488bb9,enhanced_metrics-stable/yoga," user_name=sample_dict['user_name'], project_name=sample_dict['project_name'],",,2,0
openstack%2Fceilometer~stable%2Fyoga~Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,openstack/ceilometer,stable/yoga,Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27,Add user/project names to polled samples,MERGED,2023-03-17 06:54:55.000000000,2023-04-18 06:14:21.000000000,2023-04-18 06:13:03.000000000,"[{'_account_id': 4264}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-17 06:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bffc0ef7a2edd496c2779dcb944f05488820b5e1', 'message': 'Add user/project names to polled samples\n\nProject and user names would be first fetched from cache, if not found,\nthey will be requested from keystone and then cached. Using cache will\nsignificanlty reduce the number of calls made to keystone.\n\nIf ceilometer is configured with no caching backend, the results\nwill always be fetched by querying request to keystone.\n\nA new config option, `tenant_name_discovery` is introduced\nto operate this feature. This feature is optional and is disabled by default.\n\nNo attempts to identify names will be made if uuids are found to be `None`.\n\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)\n(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)\n'}, {'number': 2, 'created': '2023-04-17 10:05:22.000000000', 'files': ['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c6f00257d4586eebfcaf4a208824f5be3a63c3f4', 'message': 'Add user/project names to polled samples\n\nProject and user names would be first fetched from cache, if not found,\nthey will be requested from keystone and then cached. Using cache will\nsignificanlty reduce the number of calls made to keystone.\n\nIf ceilometer is configured with no caching backend, the results\nwill always be fetched by querying request to keystone.\n\nA new config option, `tenant_name_discovery` is introduced to operate this feature. This feature is optional and is disabled by default.\n\nNo attempts to identify names will be made if uuids are found to be `None`.\n\nSigned-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>\nChange-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27\n(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)\n(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)\n'}]",12,877647,c6f00257d4586eebfcaf4a208824f5be3a63c3f4,31,3,2,32240,,,0,"Add user/project names to polled samples

Project and user names would be first fetched from cache, if not found,
they will be requested from keystone and then cached. Using cache will
significanlty reduce the number of calls made to keystone.

If ceilometer is configured with no caching backend, the results
will always be fetched by querying request to keystone.

A new config option, `tenant_name_discovery` is introduced to operate this feature. This feature is optional and is disabled by default.

No attempts to identify names will be made if uuids are found to be `None`.

Signed-off-by: Yadnesh Kulkarni <ykulkarn@redhat.com>
Change-Id: Iee5dbf09a1fd3ac571746fc66d2683eb8e6a1b27
(cherry picked from commit 79454d6b22787627ae6239aa7b2707101ba30212)
(cherry picked from commit 1da0e14bef969c7ccff57910f1b4408234d50f5c)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/47/877647/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cache_utils.py', 'ceilometer/sample.py', 'ceilometer/publisher/utils.py', 'releasenotes/notes/add-tenant-name-discovery-668260bb4b2b0e8c.yaml', 'ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py']",6,bffc0ef7a2edd496c2779dcb944f05488820b5e1,enhanced_metrics-stable/yoga," ks_client = mock.Mock(auth_token='fake_token') ks_client.projects.get.return_value = mock.Mock( name='admin', id='4465ecd1438b4d23a866cf8447387a7b' ) ks_client.users.get.return_value = mock.Mock( name='admin', id='c0c935468e654d5a8baae1a08adf4dfb' ) self.useFixture(fixtures.MockPatch( 'ceilometer.keystone_client.get_client', return_value=ks_client)) self.ks_client = ks_client",,138,2
openstack%2Fpuppet-ceilometer~stable%2Fxena~I21c1f7b46c008131301a86ab01616dd9b63b610d,openstack/puppet-ceilometer,stable/xena,I21c1f7b46c008131301a86ab01616dd9b63b610d,compute: Add support for tunables parameters,MERGED,2023-04-17 07:02:01.000000000,2023-04-18 06:12:21.000000000,2023-04-18 06:11:22.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 07:02:01.000000000', 'files': ['releasenotes/notes/compute-params-ecee48b43a1bdad2.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/69460b94275261a52fd4f5b224b7164635346c0e', 'message': 'compute: Add support for tunables parameters\n\nChange-Id: I21c1f7b46c008131301a86ab01616dd9b63b610d\n(cherry picked from commit 6892474ace1d02260f074c48eabf409cb16fdfb9)\n'}]",0,880584,69460b94275261a52fd4f5b224b7164635346c0e,8,3,1,32240,,,0,"compute: Add support for tunables parameters

Change-Id: I21c1f7b46c008131301a86ab01616dd9b63b610d
(cherry picked from commit 6892474ace1d02260f074c48eabf409cb16fdfb9)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/84/880584/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/compute-params-ecee48b43a1bdad2.yaml', 'manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb']",3,69460b94275261a52fd4f5b224b7164635346c0e,," it { should contain_ceilometer_config('compute/instance_discovery_method').with_value('<SERVICE DEFAULT>') should contain_ceilometer_config('compute/resource_update_interval').with_value('<SERVICE DEFAULT>') should contain_ceilometer_config('compute/resource_cache_expiry').with_value('<SERVICE DEFAULT>') } context 'when compute parameters set' do params.merge!( :instance_discovery_method => 'naive', :resource_update_interval => 0, :resource_cache_expiry => 3600, ) it { should contain_ceilometer_config('compute/instance_discovery_method').with_value('naive') should contain_ceilometer_config('compute/resource_update_interval').with_value(0) should contain_ceilometer_config('compute/resource_cache_expiry').with_value(3600) }", it { should contain_ceilometer_config('compute/instance_discovery_method').with_value('<SERVICE DEFAULT>') } context 'when setting instance_discovery_method' do params.merge!( :instance_discovery_method => 'naive' ) it { should contain_ceilometer_config('compute/instance_discovery_method').with_value('naive') },35,5
openstack%2Fpuppet-ceilometer~stable%2Fxena~I0eeb25b131385ad4448fc8cec04efbdce0b7d87a,openstack/puppet-ceilometer,stable/xena,I0eeb25b131385ad4448fc8cec04efbdce0b7d87a,polling: Ensure unused parameters are cleared,MERGED,2023-04-17 07:02:01.000000000,2023-04-18 06:11:20.000000000,2023-04-18 06:11:20.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 07:02:01.000000000', 'files': ['manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/b32543f8d91698cf1e3d41ac25c39eb7b0ac941f', 'message': 'polling: Ensure unused parameters are cleared\n\n... instead of leaving the parameters unmanaged.\n\nChange-Id: I0eeb25b131385ad4448fc8cec04efbdce0b7d87a\n(cherry picked from commit 2c48365980cd93de53aa17f25dc2531c8bcbfc6e)\n(cherry picked from commit 7768fad0e1d44b53fa26709fe6817d9e13b8ddf6)\n'}]",0,880583,b32543f8d91698cf1e3d41ac25c39eb7b0ac941f,7,3,1,32240,,,0,"polling: Ensure unused parameters are cleared

... instead of leaving the parameters unmanaged.

Change-Id: I0eeb25b131385ad4448fc8cec04efbdce0b7d87a
(cherry picked from commit 2c48365980cd93de53aa17f25dc2531c8bcbfc6e)
(cherry picked from commit 7768fad0e1d44b53fa26709fe6817d9e13b8ddf6)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/83/880583/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agent/polling.pp', 'spec/classes/ceilometer_agent_polling_spec.rb']",2,b32543f8d91698cf1e3d41ac25c39eb7b0ac941f,," context 'with compute namespace disabled' do before do params.merge!( :compute_namespace => false ) end it { should contain_ceilometer_config('DEFAULT/polling_namespaces').with_value('central,ipmi') should contain_ceilometer_config('compute/instance_discovery_method').with_ensure('absent') should contain_ceilometer_config('compute/resource_update_interval').with_ensure('absent') should contain_ceilometer_config('compute/resource_cache_expiry').with_ensure('absent') } end params.merge!( :central_namespace => false, :ipmi_namespace => false ) context 'with all namespaces disabled' do before do params.merge!( :compute_namespace => false, :central_namespace => false, :ipmi_namespace => false ) end it { should contain_ceilometer_config('DEFAULT/polling_namespaces').with_ensure('absent') } end "," params.merge!( :central_namespace => false, :ipmi_namespace => false )",51,10
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ib70a0f0bfdf47eceeecf5e1336670e8575f46e36,openstack/tripleo-heat-templates,stable/wallaby,Ib70a0f0bfdf47eceeecf5e1336670e8575f46e36,Parameters for API policies to show a host status,MERGED,2023-03-16 16:17:15.000000000,2023-04-18 05:08:02.000000000,2023-04-18 05:07:04.000000000,"[{'_account_id': 4690}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-03-16 16:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87d1243b33f1e47f3d29e3cd4b75c5c78c865244', 'message': ""Parameters for API policies to show a host status\n\nAdd NovaShowHostStatus parameter to allow custom policies for\naccessing the full/limited compute host statuses in the requested Nova\nserver details. If enabled without further policy customization, it\ngrants access to that information via the System/Project read only\nAPIs. That shows the requested full or limited host status among the\nother Nova server details available for non-admins.\n\nAdditional policies specified using NovaApiPolicies get merged with\nthis customizable NovaApiHostStatusPolicy.\n\nThe compute microversion of at lest 2.16 is required for that.\n\nIt uses role:reader since Tripleo deployments won't be enforcing scope\nyet. Once it will be, we should use rule:system_or_project_reader.\n\n Conflicts:\n\tdeployment/nova/nova-api-container-puppet.yaml\n\nChange-Id: Ib70a0f0bfdf47eceeecf5e1336670e8575f46e36\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 98af8699423e106fc1acbd6b4ba12ebb0b55ee91)\n""}, {'number': 2, 'created': '2023-03-24 12:57:49.000000000', 'files': ['deployment/nova/nova-api-container-puppet.yaml', 'releasenotes/notes/nova_api_show_host_status-f0dfaf4c2b0c536f.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad8ff1ea5076be798751ce6cd52aab806a26f312', 'message': ""Parameters for API policies to show a host status\n\nAdd NovaShowHostStatus parameter to allow custom policies for\naccessing the full/limited compute host statuses in the requested Nova\nserver details. If enabled without further policy customization, it\ngrants access to that information via the System/Project read only\nAPIs. That shows the requested full or limited host status among the\nother Nova server details available for non-admins.\n\nAdditional policies specified using NovaApiPolicies get merged with\nthis customizable NovaApiHostStatusPolicy.\n\nThe compute microversion of at lest 2.16 is required for that.\n\nIt uses role:reader since Tripleo deployments won't be enforcing scope\nyet. Once it will be, we should use rule:system_or_project_reader.\n\n Conflicts:\n\tdeployment/nova/nova-api-container-puppet.yaml\n\nChange-Id: Ib70a0f0bfdf47eceeecf5e1336670e8575f46e36\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 98af8699423e106fc1acbd6b4ba12ebb0b55ee91)\n""}]",12,877696,ad8ff1ea5076be798751ce6cd52aab806a26f312,20,9,2,6926,,,0,"Parameters for API policies to show a host status

Add NovaShowHostStatus parameter to allow custom policies for
accessing the full/limited compute host statuses in the requested Nova
server details. If enabled without further policy customization, it
grants access to that information via the System/Project read only
APIs. That shows the requested full or limited host status among the
other Nova server details available for non-admins.

Additional policies specified using NovaApiPolicies get merged with
this customizable NovaApiHostStatusPolicy.

The compute microversion of at lest 2.16 is required for that.

It uses role:reader since Tripleo deployments won't be enforcing scope
yet. Once it will be, we should use rule:system_or_project_reader.

 Conflicts:
	deployment/nova/nova-api-container-puppet.yaml

Change-Id: Ib70a0f0bfdf47eceeecf5e1336670e8575f46e36
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit 98af8699423e106fc1acbd6b4ba12ebb0b55ee91)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/877696/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-api-container-puppet.yaml', 'releasenotes/notes/nova_api_show_host_status-f0dfaf4c2b0c536f.yaml']",2,87d1243b33f1e47f3d29e3cd4b75c5c78c865244,,"--- features: - | Add `NovaShowHostStatus` to allow overriding API policies to access the compute host status in the requested Nova server details. The default value 'hidden' allows only admins to access it. Setting it to 'all' ('unknown-only') without additional fine-grained tuning of `NovaApiHostStatusPolicy` shows the full (limited) `host_status` to the system/project readers. Add `NovaApiHostStatusPolicy` that defines a custom API policy for `os_compute_api:servers:show:host_status and `os_compute_api:servers:show:host_status:unknown-only`. These rules, or roles, replace the admins-only policies based on the given `NovaShowHostStatus`: 'unknown-only' shows the limited host status UNKNOWN whenever a heartbeat was not received within the configured threshold, and 'all' also reveals UP, DOWN, or MAINTENANCE statuses in the Nova server details. Finally, `NovaShowHostStatus`: 'hidden' puts it back being visible only for admins. Additional policies specified using `NovaApiPolicies` get merged with this policy. ",,64,1
openstack%2Fpython-aodhclient~master~I2b3d81668fb6c4f5009f44e8083c94f6e8344702,openstack/python-aodhclient,master,I2b3d81668fb6c4f5009f44e8083c94f6e8344702,Move test requirements to tox.ini,MERGED,2023-04-17 14:32:05.000000000,2023-04-18 04:21:30.000000000,2023-04-18 04:20:37.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}, {'_account_id': 32240}]","[{'number': 1, 'created': '2023-04-17 14:32:05.000000000', 'files': ['requirements.txt', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/8636fb0574e0d58c00452f819ecb774aef9c5d12', 'message': 'Move test requirements to tox.ini\n\nThey were listed in requirements.txt despite not being runtime\nrequirements of aodhclient. Correct this.\n\nChange-Id: I2b3d81668fb6c4f5009f44e8083c94f6e8344702\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,880639,8636fb0574e0d58c00452f819ecb774aef9c5d12,8,3,1,15334,,,0,"Move test requirements to tox.ini

They were listed in requirements.txt despite not being runtime
requirements of aodhclient. Correct this.

Change-Id: I2b3d81668fb6c4f5009f44e8083c94f6e8344702
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/39/880639/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'setup.cfg']",2,8636fb0574e0d58c00452f819ecb774aef9c5d12,trivial, # FIXME: Remove these caps when aodh supports SQLAlchemy 2.0 SQLAlchemy-Utils<=0.38.3 sqlalchemy-migrate<=0.13.0 SQLAlchemy<=1.4.41 oslo.db<=12.3.1,,5,8
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ic3bd499c07a5c309211de26d58df9b2776db438d,openstack/tripleo-heat-templates,stable/wallaby,Ic3bd499c07a5c309211de26d58df9b2776db438d,DNM: Simulating command failure,ABANDONED,2023-04-10 08:41:53.000000000,2023-04-18 02:58:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-10 08:41:53.000000000', 'files': ['deployment/keystone/keystone-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b9fc5c04337d2cfbba50bca91652b7d0feed2ef1', 'message': 'DNM: Simulating command failure\n\nChange-Id: Ic3bd499c07a5c309211de26d58df9b2776db438d\n'}]",0,879944,b9fc5c04337d2cfbba50bca91652b7d0feed2ef1,3,1,1,9816,,,0,"DNM: Simulating command failure

Change-Id: Ic3bd499c07a5c309211de26d58df9b2776db438d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/879944/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/keystone/keystone-container-puppet.yaml'],1,b9fc5c04337d2cfbba50bca91652b7d0feed2ef1,," [ 'keystone', '/usr/bin/bootstrap_host_exec', 'keystone' ,'keystone-manage', 'boostrap' ]"," [ 'keystone', '/usr/bin/bootstrap_host_exec', 'keystone' ,'keystone-manage', 'bootstrap' ]",1,1
openstack%2Fcharm-vault~stable%2F1.5~I5a151b5f075068cce4e9cf3cc70b86c5489029fc,openstack/charm-vault,stable/1.5,I5a151b5f075068cce4e9cf3cc70b86c5489029fc,"Revert ""Implement cert cache for vault units (v3)""",MERGED,2023-04-14 18:06:02.000000000,2023-04-18 02:35:43.000000000,2023-04-18 02:35:43.000000000,"[{'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 18:06:02.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/ada98383683942e61d7fe0d8ac1b75379e410647', 'message': 'Revert ""Implement cert cache for vault units (v3)""\n\nThis reverts commit 1148004e344c9f64226bfd24fcb4ad6fa63ce001.\n\nReason for revert:\n\nReason for revert:\n\nThe bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]\n\n[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103\n[2] LP #1940549\n[3] LP #1983269\n[4] LP #1845961\n\nChange-Id: I5a151b5f075068cce4e9cf3cc70b86c5489029fc\n'}]",0,880502,ada98383683942e61d7fe0d8ac1b75379e410647,8,6,1,20870,,,0,"Revert ""Implement cert cache for vault units (v3)""

This reverts commit 1148004e344c9f64226bfd24fcb4ad6fa63ce001.

Reason for revert:

Reason for revert:

The bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]

[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103
[2] LP #1940549
[3] LP #1983269
[4] LP #1845961

Change-Id: I5a151b5f075068cce4e9cf3cc70b86c5489029fc
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/02/880502/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,ada98383683942e61d7fe0d8ac1b75379e410647,,from unittest.mock import patch self.patches = [],"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",22,922
openstack%2Fcharm-vault~stable%2F1.6~I5f07f65c4cb857d94710ab6195c8d29c8b43bc59,openstack/charm-vault,stable/1.6,I5f07f65c4cb857d94710ab6195c8d29c8b43bc59,"Revert ""Implement cert cache for vault units (v3)""",MERGED,2023-04-14 18:05:35.000000000,2023-04-18 02:35:42.000000000,2023-04-18 02:35:42.000000000,"[{'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 18:05:35.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/c68ccefef66d83dd2414b13969e8e83c4342d22b', 'message': 'Revert ""Implement cert cache for vault units (v3)""\n\nThis reverts commit fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371.\n\nReason for revert:\n\nReason for revert:\n\nThe bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]\n\n[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103\n[2] LP #1940549\n[3] LP #1983269\n[4] LP #1845961\n\nChange-Id: I5f07f65c4cb857d94710ab6195c8d29c8b43bc59\n'}]",0,880501,c68ccefef66d83dd2414b13969e8e83c4342d22b,8,6,1,20870,,,0,"Revert ""Implement cert cache for vault units (v3)""

This reverts commit fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371.

Reason for revert:

Reason for revert:

The bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]

[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103
[2] LP #1940549
[3] LP #1983269
[4] LP #1845961

Change-Id: I5f07f65c4cb857d94710ab6195c8d29c8b43bc59
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/01/880501/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,c68ccefef66d83dd2414b13969e8e83c4342d22b,,from unittest.mock import patch self.patches = [],"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",22,922
openstack%2Fcharm-vault~stable%2F1.7~I1a6b0e98917a8160622a80367a250d22eb24d48c,openstack/charm-vault,stable/1.7,I1a6b0e98917a8160622a80367a250d22eb24d48c,"Revert ""Implement cert cache for vault units (v3)""",MERGED,2023-04-14 18:05:08.000000000,2023-04-18 02:30:35.000000000,2023-04-18 02:30:35.000000000,"[{'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 18:05:08.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/00a2243d1c9c3d122666c02eab6580c41c2ff6b3', 'message': 'Revert ""Implement cert cache for vault units (v3)""\n\nThis reverts commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c.\n\nReason for revert:\n\nReason for revert:\n\nThe bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]\n\n[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103\n[2] LP #1940549\n[3] LP #1983269\n[4] LP #1845961\n\nChange-Id: I1a6b0e98917a8160622a80367a250d22eb24d48c\n'}]",0,880500,00a2243d1c9c3d122666c02eab6580c41c2ff6b3,8,6,1,20870,,,0,"Revert ""Implement cert cache for vault units (v3)""

This reverts commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c.

Reason for revert:

Reason for revert:

The bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]

[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103
[2] LP #1940549
[3] LP #1983269
[4] LP #1845961

Change-Id: I1a6b0e98917a8160622a80367a250d22eb24d48c
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/00/880500/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,00a2243d1c9c3d122666c02eab6580c41c2ff6b3,,from unittest.mock import patch self.patches = [],"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",23,917
openstack%2Fcharm-vault~stable%2F1.8~Idccc01de8f3f3dcb22daf007b9b904a90205ef7b,openstack/charm-vault,stable/1.8,Idccc01de8f3f3dcb22daf007b9b904a90205ef7b,"Revert ""Implement cert cache for vault units (v3)""",MERGED,2023-04-14 18:04:19.000000000,2023-04-18 02:30:34.000000000,2023-04-18 02:30:34.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 18:04:19.000000000', 'files': ['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/7a94b1bebbc4c727df9da51b9ee5c94b3c9d7741', 'message': 'Revert ""Implement cert cache for vault units (v3)""\n\nThis reverts commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694.\n\nReason for revert:\n\nReason for revert:\n\nThe bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]\n\n[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103\n[2] LP #1940549\n[3] LP #1983269\n[4] LP #1845961\n\nChange-Id: Idccc01de8f3f3dcb22daf007b9b904a90205ef7b\n'}]",1,880499,7a94b1bebbc4c727df9da51b9ee5c94b3c9d7741,11,6,1,20870,,,0,"Revert ""Implement cert cache for vault units (v3)""

This reverts commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694.

Reason for revert:

Reason for revert:

The bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]

[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103
[2] LP #1940549
[3] LP #1983269
[4] LP #1845961

Change-Id: Idccc01de8f3f3dcb22daf007b9b904a90205ef7b
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/99/880499/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,7a94b1bebbc4c727df9da51b9ee5c94b3c9d7741,bug/1983269-stable/1.8,from unittest.mock import patch self.patches = [],"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",22,916
openstack%2Fcharm-vault~master~I8a794fbb30e921e5322e9023b891d5e17e0e6e8b,openstack/charm-vault,master,I8a794fbb30e921e5322e9023b891d5e17e0e6e8b,"Revert ""Implement cert cache for vault units (v3)""",MERGED,2023-04-14 18:03:42.000000000,2023-04-18 02:04:15.000000000,2023-04-18 02:04:15.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 8992}, {'_account_id': 10058}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 18:03:42.000000000', 'files': ['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/38e00f460d6248627b49a53916fad76769a9a6b3', 'message': 'Revert ""Implement cert cache for vault units (v3)""\n\nThis reverts commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d.\n\nReason for revert:\n\nThe bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]\n\n[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103\n[2] LP #1940549\n[3] LP #1983269\n[4] LP #1845961\n\nChange-Id: I8a794fbb30e921e5322e9023b891d5e17e0e6e8b\n'}]",1,880498,38e00f460d6248627b49a53916fad76769a9a6b3,10,8,1,20870,,,0,"Revert ""Implement cert cache for vault units (v3)""

This reverts commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d.

Reason for revert:

The bug in [1] caused all the yoga tests to fail in integration testing.  Testing with a version of the charm without this commit allowed tests to complete.  Thus reverting this until a more complete solution can be found to the original bug(s) [2..4]

[1] https://bugs.launchpad.net/charm-keystone/+bug/2015103
[2] LP #1940549
[3] LP #1983269
[4] LP #1845961

Change-Id: I8a794fbb30e921e5322e9023b891d5e17e0e6e8b
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/98/880498/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,38e00f460d6248627b49a53916fad76769a9a6b3,bug/1983269,from unittest.mock import patch self.patches = [],"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",22,916
openstack%2Fcharm-manila-generic~stable%2Fyoga~I6cf5a8a0b9e0d7074d49d469123ef2be56121773,openstack/charm-manila-generic,stable/yoga,I6cf5a8a0b9e0d7074d49d469123ef2be56121773,Ensure that the .charm artefact is ignored,MERGED,2022-12-02 14:19:13.000000000,2023-04-18 01:56:09.000000000,2023-04-18 01:56:09.000000000,"[{'_account_id': 2424}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-02 14:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/a188d12bb5d55f2942c464acb9944a68be8e6296', 'message': 'Ensure that the .charm artefact is ignored\n\nChange-Id: I6cf5a8a0b9e0d7074d49d469123ef2be56121773\n'}, {'number': 2, 'created': '2023-02-22 16:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/97552f9fb67496c9662964dfe2f6fc7d6f34d7af', 'message': 'Ensure that the .charm artefact is ignored\n\nChange-Id: I6cf5a8a0b9e0d7074d49d469123ef2be56121773\n'}, {'number': 3, 'created': '2023-02-22 18:03:54.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/73c13a287a53240d55d0123e430e6b4408cdab06', 'message': 'Ensure that the .charm artefact is ignored\n\nChange-Id: I6cf5a8a0b9e0d7074d49d469123ef2be56121773\n'}]",0,866457,73c13a287a53240d55d0123e430e6b4408cdab06,18,4,3,20870,,,0,"Ensure that the .charm artefact is ignored

Change-Id: I6cf5a8a0b9e0d7074d49d469123ef2be56121773
",git fetch https://review.opendev.org/openstack/charm-manila-generic refs/changes/57/866457/3 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,a188d12bb5d55f2942c464acb9944a68be8e6296,ignore-charm-artefact,*.charm,,1,0
openstack%2Fcharm-manila-generic~stable%2Fyoga~I9db130663fb3e1c821c744c9a7aed8b25653181e,openstack/charm-manila-generic,stable/yoga,I9db130663fb3e1c821c744c9a7aed8b25653181e,Pin tox to < 4.0.0,MERGED,2023-01-13 20:04:13.000000000,2023-04-18 01:56:08.000000000,2023-04-18 01:56:08.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/bd96f30d886143f2feb6080db2caa3e16d20ba0a', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I9db130663fb3e1c821c744c9a7aed8b25653181e\n""}, {'number': 2, 'created': '2023-02-22 17:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/e4d92de92241153768d7245e4b17cbd69c7dd13f', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAlso:\n\n * ensure charm artefact is ignored\n * add bindep file for libpq-dev\n\nRelated-Bug: #2002788\nChange-Id: I9db130663fb3e1c821c744c9a7aed8b25653181e\n""}, {'number': 3, 'created': '2023-02-22 17:50:09.000000000', 'files': ['bindep.txt', '.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/a55df3e3bdeb722f80cd72ae5d0dd99f114377f3', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAlso:\n\n * add bindep file for libpq-dev\n * remove py35 charm jobs\n\nRelated-Bug: #2002788\nChange-Id: I9db130663fb3e1c821c744c9a7aed8b25653181e\n""}]",3,870151,a55df3e3bdeb722f80cd72ae5d0dd99f114377f3,14,5,3,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Also:

 * add bindep file for libpq-dev
 * remove py35 charm jobs

Related-Bug: #2002788
Change-Id: I9db130663fb3e1c821c744c9a7aed8b25653181e
",git fetch https://review.opendev.org/openstack/charm-manila-generic refs/changes/51/870151/3 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,bd96f30d886143f2feb6080db2caa3e16d20ba0a,pin-tox-yoga, tox < 4.0.0,,1,0
openstack%2Fpuppet-openstack-integration~master~Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8,openstack/puppet-openstack-integration,master,Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8,"Revert ""Ubuntu: Add nova to kvm group""",MERGED,2023-04-12 01:50:30.000000000,2023-04-18 01:55:46.000000000,2023-04-18 01:55:46.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 01:50:30.000000000', 'files': ['manifests/nova.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/5e832f8446f35045257f225c91b22cdafd9e3a3a', 'message': 'Revert ""Ubuntu: Add nova to kvm group""\n\nThis reverts commit f1d729fc6172e7d8b3c2896ad8abebaf5a51ba14.\n\nReason for revert:\nThe issue has been fixed in the latest nova package in UCA.\n\nRelated-Bug: #2011535\nChange-Id: Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8\n'}]",5,880116,5e832f8446f35045257f225c91b22cdafd9e3a3a,14,4,1,9816,,,0,"Revert ""Ubuntu: Add nova to kvm group""

This reverts commit f1d729fc6172e7d8b3c2896ad8abebaf5a51ba14.

Reason for revert:
The issue has been fixed in the latest nova package in UCA.

Related-Bug: #2011535
Change-Id: Ie1fd92cb9f0cdfbd04b805f959f83b6628363ae8
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/16/880116/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/nova.pp'],1,5e832f8446f35045257f225c91b22cdafd9e3a3a,,," # Remove this once fix for bug 2011535 is released if $facts['os']['name'] == 'Ubuntu' { user { 'nova': ensure => present, name => 'nova', groups => ['nova', 'kvm', 'libvirt-qemu'], require => Anchor['nova::install::end'], before => Anchor['nova::service::begin'], } } ",0,11
openstack%2Fswift~master~Idf9b5118e9b64843e0c4dd7088b498b165f33db4,openstack/swift,master,Idf9b5118e9b64843e0c4dd7088b498b165f33db4,ssync: Round-trip offsets in meta/ctype Timestamps,MERGED,2023-02-17 01:19:20.000000000,2023-04-18 00:02:42.000000000,2023-04-18 00:01:42.000000000,"[{'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-17 01:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/822a0a0bf88fef9939c3232d1dd9b356f0c65a66', 'message': 'ssync: Round-trip offsets in meta/ctype Timestamps\n\nUse double-underscore to separate to ensure old code blows up rather\nthan misinterpret encoded offsets.\n\nChange-Id: Idf9b5118e9b64843e0c4dd7088b498b165f33db4\n'}, {'number': 2, 'created': '2023-02-22 15:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8fb7f35d5e126f3ecccf478a82017a1cebcb55e1', 'message': 'ssync: Round-trip offsets in meta/ctype Timestamps\n\nUse double-underscore to separate to ensure old code blows up rather\nthan misinterpret encoded offsets.\n\nChange-Id: Idf9b5118e9b64843e0c4dd7088b498b165f33db4\n'}, {'number': 3, 'created': '2023-02-24 10:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f7e0df126715d82a33fb025e656098fa7234b56', 'message': 'ssync: Round-trip offsets in meta/ctype Timestamps\n\nUse double-underscore to separate to ensure old code blows up rather\nthan misinterpret encoded offsets.\n\nChange-Id: Idf9b5118e9b64843e0c4dd7088b498b165f33db4\n'}, {'number': 4, 'created': '2023-04-17 12:26:05.000000000', 'files': ['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_ssync.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4e74e7f558c44068a45556be02c184a753476c56', 'message': 'ssync: Round-trip offsets in meta/ctype Timestamps\n\nUse double-underscore to separate to ensure old code blows up rather\nthan misinterpret encoded offsets.\n\nChange-Id: Idf9b5118e9b64843e0c4dd7088b498b165f33db4\n'}]",13,874184,4e74e7f558c44068a45556be02c184a753476c56,33,2,4,15343,,,0,"ssync: Round-trip offsets in meta/ctype Timestamps

Use double-underscore to separate to ensure old code blows up rather
than misinterpret encoded offsets.

Change-Id: Idf9b5118e9b64843e0c4dd7088b498b165f33db4
",git fetch https://review.opendev.org/openstack/swift refs/changes/84/874184/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_ssync_sender.py', 'swift/obj/ssync_sender.py', 'swift/obj/ssync_receiver.py']",3,822a0a0bf88fef9939c3232d1dd9b356f0c65a66,p-ssync-fix-meta-ts," v, _, o = v.partition('__') delta=int(v, 16), offset=int(o or '0', 16)) elif k == 't': v, _, o = v.partition('__') delta=int(v, 16), offset=int(o or '0', 16))"," delta=int(v, 16)) elif k == 't': delta=int(v, 16))",33,2
openstack%2Fswift~stable%2Fwallaby~I52c535bd2078f25bb57c42a2c2c966247cd3094b,openstack/swift,stable/wallaby,I52c535bd2078f25bb57c42a2c2c966247cd3094b,Drop bandit check B309,MERGED,2023-04-06 16:11:18.000000000,2023-04-17 23:40:29.000000000,2023-04-17 23:39:18.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-06 16:11:18.000000000', 'files': ['bandit.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/f94f6a2bcb1b8df34ba079056c5aa129b0f21cee', 'message': 'Drop bandit check B309\n\nIt was retired upstream: https://github.com/PyCQA/bandit/pull/858\n\nContinuing to list it causes CI failures like\n\n    ERROR\tUnknown test found in profile: B309\n\nChange-Id: I52c535bd2078f25bb57c42a2c2c966247cd3094b\n(cherry picked from commit 479a010165cefccf8da522e99a478ab9c780e9cd)\n'}]",1,879752,f94f6a2bcb1b8df34ba079056c5aa129b0f21cee,11,2,1,15343,,,0,"Drop bandit check B309

It was retired upstream: https://github.com/PyCQA/bandit/pull/858

Continuing to list it causes CI failures like

    ERROR	Unknown test found in profile: B309

Change-Id: I52c535bd2078f25bb57c42a2c2c966247cd3094b
(cherry picked from commit 479a010165cefccf8da522e99a478ab9c780e9cd)
",git fetch https://review.opendev.org/openstack/swift refs/changes/52/879752/1 && git format-patch -1 --stdout FETCH_HEAD,['bandit.yaml'],1,f94f6a2bcb1b8df34ba079056c5aa129b0f21cee,,"tests: [B102, B103, B302, B303, B304, B305, B306, B308, B310, B401, B501, B502, B506, B601, B602, B609]","# B309 : httpsconnectiontests: [B102, B103, B302, B303, B304, B305, B306, B308, B309, B310, B401, B501, B502, B506, B601, B602, B609]",1,2
openstack%2Fopenstack-tempest-skiplist~master~Ieb9648f3d0b1e80f3934349f4699fd2eeb858114,openstack/openstack-tempest-skiplist,master,Ieb9648f3d0b1e80f3934349f4699fd2eeb858114,Retire patrole projects,MERGED,2023-04-12 19:04:44.000000000,2023-04-17 23:18:19.000000000,2023-04-17 23:17:23.000000000,"[{'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-12 19:04:44.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/3f66d538b829996d49f9e1b78054fb08c167687f', 'message': 'Retire patrole projects\n\npatrole project is not maintained and in QA\nPTG, we decided to retire it.\n\n- https://etherpad.opendev.org/p/qa-bobcat-ptg\n\nDepends-On: https://review.opendev.org/c/openstack/governance/+/880014\nChange-Id: Ieb9648f3d0b1e80f3934349f4699fd2eeb858114\n'}]",2,880226,3f66d538b829996d49f9e1b78054fb08c167687f,9,2,1,8556,,,0,"Retire patrole projects

patrole project is not maintained and in QA
PTG, we decided to retire it.

- https://etherpad.opendev.org/p/qa-bobcat-ptg

Depends-On: https://review.opendev.org/c/openstack/governance/+/880014
Change-Id: Ieb9648f3d0b1e80f3934349f4699fd2eeb858114
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/26/880226/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,3f66d538b829996d49f9e1b78054fb08c167687f,retire-patrole,, - test: 'patrole_tempest_plugin' deployment: - 'overcloud' releases: - name: 'master' reason: 'Not supported in TripleO/tempestconf' lp: 'https://bugs.launchpad.net/tripleo/+bug/invalid' - name: 'victoria' reason: 'Not supported in TripleO/tempestconf' lp: 'https://bugs.launchpad.net/tripleo/+bug/invalid' - name: 'train' reason: 'Not supported in TripleO/tempestconf' lp: 'https://bugs.launchpad.net/tripleo/+bug/invalid' - name: 'ussuri' reason: 'Not supported in TripleO/tempestconf' lp: 'https://bugs.launchpad.net/tripleo/+bug/invalid' - name: 'zed' reason: 'Not supported in TripleO/tempestconf' lp: 'https://bugs.launchpad.net/tripleo/+bug/invalid' jobs: [],0,20
openstack%2Fopenstack-ansible-os_octavia~master~I4a3346c90825a4bf0b416943286696fa529f526d,openstack/openstack-ansible-os_octavia,master,I4a3346c90825a4bf0b416943286696fa529f526d,Ensure service is restarted on unit file changes,MERGED,2023-04-13 16:11:04.000000000,2023-04-17 22:14:28.000000000,2023-04-17 22:13:36.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-13 16:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/24eeaf72c974b313b46f7a343bee7ec6aa68d596', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nChange-Id: I4a3346c90825a4bf0b416943286696fa529f526d\n""}, {'number': 2, 'created': '2023-04-14 19:26:26.000000000', 'files': ['handlers/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/c672dc1848391a60bb2da4f84922372eb481a8d3', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nChange-Id: I4a3346c90825a4bf0b416943286696fa529f526d\n""}]",1,880339,c672dc1848391a60bb2da4f84922372eb481a8d3,11,3,2,28619,,,0,"Ensure service is restarted on unit file changes

At the moment we don't restart services if systemd unit file is changed.

We knowingly prevent systemd_service role handlers to execute
by providing `state: started` as otherwise service will be restarted twice.
With that now  we ensure that role handlers will also listen for systemd
unit changes.

Change-Id: I4a3346c90825a4bf0b416943286696fa529f526d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/39/880339/2 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'vars/main.yml']",2,24eeaf72c974b313b46f7a343bee7ec6aa68d596,osa/systemd_restart_on_unit_change," 'enabled': value['enabled'] | default(True), 'state': value['state'] | default('started'),"," 'enabled': 'yes',",3,1
openstack%2Fswift~master~I24a5680d19af609b92588249610e4a1f128bdad3,openstack/swift,master,I24a5680d19af609b92588249610e4a1f128bdad3,tests: Fix PriorityQueue import,MERGED,2023-04-13 17:16:35.000000000,2023-04-17 21:36:23.000000000,2023-04-17 21:35:21.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 17:16:35.000000000', 'files': ['test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/12bfcb5cd602eaef6c090e47172edb02a196e538', 'message': ""tests: Fix PriorityQueue import\n\nNot sure how we didn't catch this before; py2 gate jobs still seem to run these\ntests and they'd pass??\n\nChange-Id: I24a5680d19af609b92588249610e4a1f128bdad3\n""}]",0,880346,12bfcb5cd602eaef6c090e47172edb02a196e538,8,2,1,15343,,,0,"tests: Fix PriorityQueue import

Not sure how we didn't catch this before; py2 gate jobs still seem to run these
tests and they'd pass??

Change-Id: I24a5680d19af609b92588249610e4a1f128bdad3
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/880346/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_updater.py'],1,12bfcb5cd602eaef6c090e47172edb02a196e538,,from six.moves.queue import PriorityQueue,from queue import PriorityQueue ,1,2
openstack%2Fopenstack-ansible-os_octavia~master~I861797fdddbf2c82ef7b1409df577475e7424414,openstack/openstack-ansible-os_octavia,master,I861797fdddbf2c82ef7b1409df577475e7424414,Adopt info modules fetch to collection 2.0,MERGED,2023-04-10 16:37:45.000000000,2023-04-17 21:06:34.000000000,2023-04-17 21:05:25.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32238}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-10 16:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/0d6caa302355b46943ea1b934f8a666be8e67971', 'message': 'Adopt info modules fetch to collection 2.0\n\nWith ansible-collection version 2.0 return of project_info module\nhas changed. We need to adopt usage of module return to the new format.\n\nChange-Id: I861797fdddbf2c82ef7b1409df577475e7424414\n'}, {'number': 2, 'created': '2023-04-11 10:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/cdf1ab13c5894e9a399dce9491f833e55d883ba7', 'message': 'Adopt info modules fetch to collection 2.0\n\nWith ansible-collection version 2.0 return of project_info module\nhas changed. We need to adopt usage of module return to the new format.\n\nChange-Id: I861797fdddbf2c82ef7b1409df577475e7424414\n'}, {'number': 3, 'created': '2023-04-14 19:21:15.000000000', 'files': ['tasks/octavia_amp_image.yml', 'tasks/octavia_post_install.yml', 'tasks/octavia_security_group.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/aeebb5bdd4c26ca2686e5d5426900c15b5793fff', 'message': ""Adopt info modules fetch to collection 2.0\n\nWith ansible-collection version 2.0 return of project_info module\nhas changed. We need to adopt usage of module return to the new format.\n\nWe also add security group rule for dhcp, since in case DHCP is enabled\nfor the network, it won't be provided in metadata on config-drive anymore.\n\nChange-Id: I861797fdddbf2c82ef7b1409df577475e7424414\n""}]",0,879988,aeebb5bdd4c26ca2686e5d5426900c15b5793fff,13,4,3,28619,,,0,"Adopt info modules fetch to collection 2.0

With ansible-collection version 2.0 return of project_info module
has changed. We need to adopt usage of module return to the new format.

We also add security group rule for dhcp, since in case DHCP is enabled
for the network, it won't be provided in metadata on config-drive anymore.

Change-Id: I861797fdddbf2c82ef7b1409df577475e7424414
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/88/879988/3 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/octavia_amp_image.yml', 'tasks/octavia_post_install.yml']",2,0d6caa302355b46943ea1b934f8a666be8e67971,osa/ansible-collection-2," octavia_nova_flavor_uuid: ""{{ get_flavor_info.flavors[0].id }}"" octavia_amp_image_owner_id: ""{{ get_project_info.projects[0].id }}"""," octavia_nova_flavor_uuid: ""{{ get_flavor_info.openstack_flavors[0].id }}"" octavia_amp_image_owner_id: ""{{ get_project_info.openstack_projects[0].id }}""",4,4
openstack%2Fkayobe~stable%2Fxena~I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,openstack/kayobe,stable/xena,I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,Fix kayobe_config_path description in globals.yml,MERGED,2023-04-13 21:01:05.000000000,2023-04-17 21:05:04.000000000,2023-04-17 21:04:06.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 21:01:05.000000000', 'files': ['etc/kayobe/globals.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/aec7807b2d3c2c0b0c88d783c860561b81bd3377', 'message': ""Fix kayobe_config_path description in globals.yml\n\nThis change fixes the description accidently copied from the\n'kayobe_env_config_path' description.\n\nTrivialFix\n\nChange-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)\n""}]",1,880367,aec7807b2d3c2c0b0c88d783c860561b81bd3377,11,2,1,14200,,,0,"Fix kayobe_config_path description in globals.yml

This change fixes the description accidently copied from the
'kayobe_env_config_path' description.

TrivialFix

Change-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/67/880367/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/globals.yml'],1,aec7807b2d3c2c0b0c88d783c860561b81bd3377,fix-globals-description,# Path to Kayobe configuration directory on Ansible control host.,"# Path to Kayobe configuration directory on Ansible control host, with an # environment path appended if kayobe_environment is set.",1,2
openstack%2Fdevstack~master~I1785b49b2ef72ca1f817f504d5ea56021410c052,openstack/devstack,master,I1785b49b2ef72ca1f817f504d5ea56021410c052,[ovs] Reload ovs kernel module always,MERGED,2023-04-14 14:36:29.000000000,2023-04-17 20:59:36.000000000,2023-04-17 20:58:36.000000000,"[{'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-14 14:36:29.000000000', 'files': ['lib/neutron_plugins/ovs_source'], 'web_link': 'https://opendev.org/openstack/devstack/commit/42517968ff7bdced07c5bc08b6cb2b8d10d246cc', 'message': '[ovs] Reload ovs kernel module always\n\nIrrespective of build_modules is True\nor False reload ovs modules always.\n\nIf ovs is installed from package before(like\nwith multi-node-bridge role), then installing\novs from source requires openvswitch kernel\nmodule to be reloaded.\n\nThe issue was not seen before jammy as there\nmodule was reloaded when build_modules was set\nto True.\n\nCloses-Bug: #2015364\nChange-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052\n'}]",5,880533,42517968ff7bdced07c5bc08b6cb2b8d10d246cc,15,6,1,13861,,,0,"[ovs] Reload ovs kernel module always

Irrespective of build_modules is True
or False reload ovs modules always.

If ovs is installed from package before(like
with multi-node-bridge role), then installing
ovs from source requires openvswitch kernel
module to be reloaded.

The issue was not seen before jammy as there
module was reloaded when build_modules was set
to True.

Closes-Bug: #2015364
Change-Id: I1785b49b2ef72ca1f817f504d5ea56021410c052
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/880533/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ovs_source'],1,42517968ff7bdced07c5bc08b6cb2b8d10d246cc,bug/2015364, reload_ovs_kernel_modules, reload_ovs_kernel_modules else load_ovs_kernel_modules,1,3
openstack%2Fos-brick~master~I50944c3efc7e2010d3c6475dd4c79a27c9f94cf6,openstack/os-brick,master,I50944c3efc7e2010d3c6475dd4c79a27c9f94cf6,Bump mypy to 1.1.1,MERGED,2023-03-21 13:53:28.000000000,2023-04-17 20:49:49.000000000,2023-04-17 20:48:05.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2023-03-21 13:53:28.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/e04d0de40bd1dd5364a6aa31df41d5a641760794', 'message': 'Bump mypy to 1.1.1\n\nChange-Id: I50944c3efc7e2010d3c6475dd4c79a27c9f94cf6\n'}]",3,878090,e04d0de40bd1dd5364a6aa31df41d5a641760794,21,3,1,4523,,,0,"Bump mypy to 1.1.1

Change-Id: I50944c3efc7e2010d3c6475dd4c79a27c9f94cf6
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/90/878090/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e04d0de40bd1dd5364a6aa31df41d5a641760794,,mypy>=1.1.1 # MIT,mypy>=0.982 # MIT,1,1
openstack%2Fos-brick~master~Iefc691ae8d5eb001c9abbf554600a8f8132e038c,openstack/os-brick,master,Iefc691ae8d5eb001c9abbf554600a8f8132e038c,LVM: Fix supports_full_pool_create,MERGED,2023-03-21 13:53:28.000000000,2023-04-17 20:48:59.000000000,2023-04-17 20:48:04.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2023-03-21 13:53:28.000000000', 'files': ['os_brick/local_dev/lvm.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/9496bb2e477e2b519271b021c1bb6aab58df0749', 'message': 'LVM: Fix supports_full_pool_create\n\nmypy detected this problem -- the\nsupports_full_pool_create property will always\nreturn True when referenced via the class instead\nof via an instance.\n\nChange-Id: Iefc691ae8d5eb001c9abbf554600a8f8132e038c\n'}]",3,877929,9496bb2e477e2b519271b021c1bb6aab58df0749,18,3,1,4523,,,0,"LVM: Fix supports_full_pool_create

mypy detected this problem -- the
supports_full_pool_create property will always
return True when referenced via the class instead
of via an instance.

Change-Id: Iefc691ae8d5eb001c9abbf554600a8f8132e038c
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/29/877929/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/local_dev/lvm.py'],1,9496bb2e477e2b519271b021c1bb6aab58df0749,, if self.supports_full_pool_create:, if LVM.supports_full_pool_create:,1,1
openstack%2Fos-brick~stable%2F2023.1~Ie3eaf0d16e27e35ec30635c82b38c634db9c4541,openstack/os-brick,stable/2023.1,Ie3eaf0d16e27e35ec30635c82b38c634db9c4541,Add Python 3.10 to setup.cfg metadata,MERGED,2023-03-16 03:07:23.000000000,2023-04-17 20:48:56.000000000,2023-04-17 20:48:02.000000000,"[{'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-16 03:07:23.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/9bcd759e987aa2d28a79bdd6d9d0e2fac85f7eea', 'message': 'Add Python 3.10 to setup.cfg metadata\n\nWe support 3.10 as of Antelope.\n\nChange-Id: Ie3eaf0d16e27e35ec30635c82b38c634db9c4541\n(cherry picked from commit e15edf6c17449899ec8401c37482f7cb5de207d3)\n'}]",3,877505,9bcd759e987aa2d28a79bdd6d9d0e2fac85f7eea,9,3,1,4523,,,0,"Add Python 3.10 to setup.cfg metadata

We support 3.10 as of Antelope.

Change-Id: Ie3eaf0d16e27e35ec30635c82b38c634db9c4541
(cherry picked from commit e15edf6c17449899ec8401c37482f7cb5de207d3)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/05/877505/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9bcd759e987aa2d28a79bdd6d9d0e2fac85f7eea,, Programming Language :: Python :: 3.10,,1,0
openstack%2Fcinder~stable%2Fxena~I553be293142c3e9525ca9aedfeb1a788830570cb,openstack/cinder,stable/xena,I553be293142c3e9525ca9aedfeb1a788830570cb,mypy: Allow mypy to pass with requests-packaged urllib3,MERGED,2023-01-19 20:54:38.000000000,2023-04-17 19:55:54.000000000,2023-04-17 19:53:48.000000000,"[{'_account_id': 5314}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-19 20:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/42c11f0cd11e3cc5ece3187b926761d38475dba5', 'message': 'mypy: Allow mypy to pass with requests-packaged urllib3\n\nmypy fails with:\n    error: Module has no attribute ""packages""\n\nSet type ignores for requests.packages.urllib3.\n\nChange-Id: I553be293142c3e9525ca9aedfeb1a788830570cb\n'}, {'number': 2, 'created': '2023-01-19 21:35:23.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ce8469eb1ce07c46fbde10adec91e10d9769e02', 'message': 'mypy: Allow mypy to pass with requests-packaged urllib3\n\nmypy fails with:\n    error: Module has no attribute ""packages""\n\nSet type ignores for requests.packages.urllib3.\n\nChange-Id: I553be293142c3e9525ca9aedfeb1a788830570cb\n(cherry picked from commit 54ac21f73b01a671c4e90d707fa2e49b3bf03d54)\n'}]",5,871179,0ce8469eb1ce07c46fbde10adec91e10d9769e02,30,4,2,4523,,,0,"mypy: Allow mypy to pass with requests-packaged urllib3

mypy fails with:
    error: Module has no attribute ""packages""

Set type ignores for requests.packages.urllib3.

Change-Id: I553be293142c3e9525ca9aedfeb1a788830570cb
(cherry picked from commit 54ac21f73b01a671c4e90d707fa2e49b3bf03d54)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/871179/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,42c11f0cd11e3cc5ece3187b926761d38475dba5,, rpu = requests.packages.urllib3 # type: ignore rpu.disable_warnings(rpu.exceptions.InsecureRequestWarning) rpu.disable_warnings(rpu.exceptions.InsecurePlatformWarning), requests.packages.urllib3.disable_warnings( requests.packages.urllib3.exceptions.InsecureRequestWarning) requests.packages.urllib3.disable_warnings( requests.packages.urllib3.exceptions.InsecurePlatformWarning),3,4
openstack%2Fcinder~stable%2Fxena~Ie2b7a163ee3a83121c04a21808ef437d740426d5,openstack/cinder,stable/xena,Ie2b7a163ee3a83121c04a21808ef437d740426d5,Fix Infinidat driver to return all iSCSI portals,MERGED,2022-12-20 12:49:17.000000000,2023-04-17 19:54:54.000000000,2023-04-17 19:53:45.000000000,"[{'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30615}, {'_account_id': 32425}]","[{'number': 1, 'created': '2022-12-20 12:49:17.000000000', 'files': ['releasenotes/notes/bug-1981354-infinidat-iscsi-fix-multipath-3f8a0be5f541c66e.yaml', 'cinder/tests/unit/volume/drivers/test_infinidat.py', 'cinder/volume/drivers/infinidat.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e2b049555e701e3742af6239c1bb991514b05aa', 'message': 'Fix Infinidat driver to return all iSCSI portals\n\nInfinidat Cinder driver truncates the list of configured iSCSI\nportals and returns only the first IP for a given network space.\nAnd in case of network path failure we lose access to the data.\n\nTo fix this issue, we need to return all configured and enabled\niSCSI portals for a given configured network space.\n\nCloses-bug: #1981354\nChange-Id: Ie2b7a163ee3a83121c04a21808ef437d740426d5\nCo-authored-by: Alexander Deiter <adeiter@infinidat.com>\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\n(cherry picked from commit a25dcc85180124f3f8db836ec49c0ee5b5741b62)\n(cherry picked from commit bb510b64a5c77c60950ee13ce3a05c39ec667f01)\n'}]",5,868178,4e2b049555e701e3742af6239c1bb991514b05aa,23,5,1,35075,,,0,"Fix Infinidat driver to return all iSCSI portals

Infinidat Cinder driver truncates the list of configured iSCSI
portals and returns only the first IP for a given network space.
And in case of network path failure we lose access to the data.

To fix this issue, we need to return all configured and enabled
iSCSI portals for a given configured network space.

Closes-bug: #1981354
Change-Id: Ie2b7a163ee3a83121c04a21808ef437d740426d5
Co-authored-by: Alexander Deiter <adeiter@infinidat.com>
Signed-off-by: Alexander Deiter <adeiter@infinidat.com>
(cherry picked from commit a25dcc85180124f3f8db836ec49c0ee5b5741b62)
(cherry picked from commit bb510b64a5c77c60950ee13ce3a05c39ec667f01)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/868178/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1981354-infinidat-iscsi-fix-multipath-3f8a0be5f541c66e.yaml', 'cinder/tests/unit/volume/drivers/test_infinidat.py', 'cinder/volume/drivers/infinidat.py']",3,4e2b049555e701e3742af6239c1bb991514b05aa,bug/1981354-stable/yoga-stable/xena,"# Copyright 2022 Infinidat Ltd. 1.7 - fixed iSCSI to return all portals VERSION = '1.7' def _get_iscsi_portals(self, netspace): port = netspace.get_properties().iscsi_tcp_port portals = [""%s:%s"" % (interface.ip_address, port) for interface in netspace.get_ips() if interface.enabled] if portals: return portals netspace_portals = self._get_iscsi_portals(netspace) target_portals.extend(netspace_portals) target_iqns.extend([netspace.get_properties().iscsi_iqn] * len(netspace_portals)) target_luns.extend([lun] * len(netspace_portals))","# Copyright 2016 Infinidat Ltd. VERSION = '1.6' def _get_iscsi_portal(self, netspace): for netpsace_interface in netspace.get_ips(): if netpsace_interface.enabled: port = netspace.get_properties().iscsi_tcp_port return ""%s:%s"" % (netpsace_interface.ip_address, port) target_portals.append(self._get_iscsi_portal(netspace)) target_iqns.append(netspace.get_properties().iscsi_iqn) target_luns.append(lun)",197,52
openstack%2Fneutron-lib~master~Ib6807d3ccdcea4b440961f1fb7f212f9b982b2c5,openstack/neutron-lib,master,Ib6807d3ccdcea4b440961f1fb7f212f9b982b2c5,FUP Suppress IPv6 metadata DAD failure and delete address,MERGED,2023-04-17 07:38:04.000000000,2023-04-17 19:47:47.000000000,2023-04-17 19:46:44.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 07:38:04.000000000', 'files': ['neutron_lib/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/a7b950cf8b5f322b7526b2b3eafb397b4f054c28', 'message': 'FUP Suppress IPv6 metadata DAD failure and delete address\n\nIn the partial fix\nhttps://review.opendev.org/c/openstack/neutron/+/876566 to bug #1953165,\nwe changed the metadata cidr netmask from /64 to /128.\n\nThis patch updates neutron-lib accordingly.\n\nChange-Id: Ib6807d3ccdcea4b440961f1fb7f212f9b982b2c5\nRelated-Bug: #1953165\n'}]",1,880588,a7b950cf8b5f322b7526b2b3eafb397b4f054c28,12,3,1,15554,,,0,"FUP Suppress IPv6 metadata DAD failure and delete address

In the partial fix
https://review.opendev.org/c/openstack/neutron/+/876566 to bug #1953165,
we changed the metadata cidr netmask from /64 to /128.

This patch updates neutron-lib accordingly.

Change-Id: Ib6807d3ccdcea4b440961f1fb7f212f9b982b2c5
Related-Bug: #1953165
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/88/880588/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/constants.py'],1,a7b950cf8b5f322b7526b2b3eafb397b4f054c28,bug/1953165,METADATA_V6_CIDR = 'fe80::a9fe:a9fe/128',METADATA_V6_CIDR = 'fe80::a9fe:a9fe/64',1,1
openstack%2Fcharm-guide~master~I803ca1a3a522f464db1c34630c1932c58fe86d7d,openstack/charm-guide,master,I803ca1a3a522f464db1c34630c1932c58fe86d7d,Add service user password rotation release note,MERGED,2023-03-30 09:37:01.000000000,2023-04-17 19:38:11.000000000,2023-04-17 19:37:09.000000000,"[{'_account_id': 2424}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2023-03-30 09:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/c1ca7ce48a8f70c3a330ae0571e28137fad89a8f', 'message': 'Add service user password rotation release note\n\nThis is a new feature for the keystone, mysql-innodb-cluster and\nrabbitmq-server charms.\n\nChange-Id: I803ca1a3a522f464db1c34630c1932c58fe86d7d\n'}, {'number': 2, 'created': '2023-03-30 12:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/65e7818664b696584535266b036ba587bd90efb0', 'message': 'Add service user password rotation release note\n\nThis is a new feature for the keystone, mysql-innodb-cluster and\nrabbitmq-server charms.\n\nChange-Id: I803ca1a3a522f464db1c34630c1932c58fe86d7d\n'}, {'number': 3, 'created': '2023-04-17 11:54:12.000000000', 'files': ['doc/source/release-notes/antelope.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/c921eea6595c2bf96bc84e21b93ba863de4d3e50', 'message': 'Add service user password rotation release note\n\nThis is a new feature for the keystone, mysql-innodb-cluster and\nrabbitmq-server charms.\n\nChange-Id: I803ca1a3a522f464db1c34630c1932c58fe86d7d\n'}]",19,879032,c921eea6595c2bf96bc84e21b93ba863de4d3e50,14,3,3,20870,,,0,"Add service user password rotation release note

This is a new feature for the keystone, mysql-innodb-cluster and
rabbitmq-server charms.

Change-Id: I803ca1a3a522f464db1c34630c1932c58fe86d7d
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/32/879032/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/release-notes/antelope.rst'],1,c1ca7ce48a8f70c3a330ae0571e28137fad89a8f,antelope-release-note,"Service User Password Rotation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The keystone, mysql-innodb-cluster and rabbitmq-server charms have gained actions to assist with rotating, or changing, the passwords for the service users in an OpenStack model. Service users are the applications that provide services within an OpenStack system. Examples are glance, nova, heat, and keystone. Two actions are provided on each of the keystone, mysql-innodb-cluster and rabbitmq-server charms: ``list-service-usernames`` and ``rotate-service-user-password``. The ``list-service-usernames`` action provides a list of usernames that can be rotated, whilst the ``rotate-service-user-password`` actually performs a password rotation for a single service user. There may be a control plane interruption when a password is rotated. This is due to the password being changed in the service provider (MySQL, keystone and RabbmitMQ) before it has been pushed out to the service user applications. However, this is likely to be mitigated and minimised to the restart of the service application which will force a re-authentication of the service. Note that there is not a 'rotate all service user passwords' action but this can be mitigated by accessing the list from ``list-service-usernames`` and cycling through them with ``rotate-service-user-password``. ",,25,0
openstack%2Fkolla~master~I32ee2d25b950055e959d8f7453b7a8b224509807,openstack/kolla,master,I32ee2d25b950055e959d8f7453b7a8b224509807,Update job name to altcomp,NEW,2023-01-20 11:41:35.000000000,2023-04-17 19:18:26.000000000,,"[{'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-01-20 11:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/630dd42aec5af9e7e51d7ed1be4c1af3b0d482e9', 'message': 'Update job name to altcomp\n\nThe job name is being changed in [1].\n\n[1] https://review.opendev.org/c/openstack/kolla-ansible/+/851204\n\nChange-Id: I32ee2d25b950055e959d8f7453b7a8b224509807\n'}, {'number': 2, 'created': '2023-01-20 11:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/165e46cc7570c63a70a20e18bd3d84a8f13cca09', 'message': 'Update job name to altcomp\n\nThe job name is being changed in [1].\n\n[1] https://review.opendev.org/c/openstack/kolla-ansible/+/851204\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/871273\n\nChange-Id: I32ee2d25b950055e959d8f7453b7a8b224509807\n'}, {'number': 3, 'created': '2023-01-20 11:56:25.000000000', 'files': ['.zuul.d/ubuntu.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/aa4a5f549de76cc218b5cb1fbe4d931602b18ae2', 'message': 'Update job name to altcomp\n\nThe job name is being changed in kolla-ansible.\n\nDepends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/851204\n\nChange-Id: I32ee2d25b950055e959d8f7453b7a8b224509807\n'}]",6,871273,aa4a5f549de76cc218b5cb1fbe4d931602b18ae2,15,2,3,15197,,,0,"Update job name to altcomp

The job name is being changed in kolla-ansible.

Depends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/851204

Change-Id: I32ee2d25b950055e959d8f7453b7a8b224509807
",git fetch https://review.opendev.org/openstack/kolla refs/changes/73/871273/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/ubuntu.yaml'],1,630dd42aec5af9e7e51d7ed1be4c1af3b0d482e9,, - kolla-ansible-ubuntu-altcomp:, - kolla-ansible-ubuntu-zun:,1,1
openstack%2Fpuppet-openstack-integration~master~I9f57a2b81d705731f7edc2711bc528dfe5185d92,openstack/puppet-openstack-integration,master,I9f57a2b81d705731f7edc2711bc528dfe5185d92,Ubuntu: Stop installing unused packages for neutron tests,MERGED,2023-04-12 03:12:02.000000000,2023-04-17 19:06:12.000000000,2023-04-17 19:06:12.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 03:12:02.000000000', 'files': ['manifests/tempest.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/78101a0174a26bb244c70a98ef06040ef02416a9', 'message': ""Ubuntu: Stop installing unused packages for neutron tests\n\nWe do not really run in-tree tests from neutron repo but we use only\ntempest and neutron-tempest-plugin. Because the required packages are\nnow installed within virtualenv we don't have to install these packages\nadditionally.\n\nChange-Id: I9f57a2b81d705731f7edc2711bc528dfe5185d92\n""}]",1,880119,78101a0174a26bb244c70a98ef06040ef02416a9,9,3,1,9816,,,0,"Ubuntu: Stop installing unused packages for neutron tests

We do not really run in-tree tests from neutron repo but we use only
tempest and neutron-tempest-plugin. Because the required packages are
now installed within virtualenv we don't have to install these packages
additionally.

Change-Id: I9f57a2b81d705731f7edc2711bc528dfe5185d92
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/19/880119/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/tempest.pp'],1,78101a0174a26bb244c70a98ef06040ef02416a9,,," # Install missed dependency for neutron tests # https://github.com/openstack/neutron/blob/master/test-requirements.txt#L20 if $facts['os']['name'] == 'Ubuntu' { package { ['python3-ddt', 'python3-oslotest', 'python3-gabbi']: ensure => present } } ",0,8
openstack%2Ftripleo-quickstart~master~I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af,openstack/tripleo-quickstart,master,I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af,"Revert ""Exclude latest gnupg2 & Pin to last good version""",MERGED,2023-04-11 06:35:00.000000000,2023-04-17 19:01:03.000000000,2023-04-17 18:59:55.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 29775}]","[{'number': 1, 'created': '2023-04-11 06:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/0c7584cf6977ab13313bb8aeecfd1e7c1ef9bb3d', 'message': 'Revert ""Exclude latest gnupg2 & Pin to last good version""\n\nThis reverts commit 7467dd032d3873c1e0c1153713298c6b1f56793b.\n\nReason for revert: Testing the revert\n\nChange-Id: I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af\n'}, {'number': 2, 'created': '2023-04-12 04:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3745bac1ab6e5eac58152ba5914784243b6da6df', 'message': 'Revert ""Exclude latest gnupg2 & Pin to last good version""\n\nThis reverts commit 7467dd032d3873c1e0c1153713298c6b1f56793b.\n\nReason for revert: Testing the revert\n\nChange-Id: I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af\n'}, {'number': 3, 'created': '2023-04-12 05:07:45.000000000', 'files': ['config/release/tripleo-ci/CentOS-9/zed.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-9/wallaby.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-master.yml', 'config/release/tripleo-ci/CentOS-9/master.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-zed.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5b587a7f65a3537157dd8b0df2415176aec447cd', 'message': 'Revert ""Exclude latest gnupg2 & Pin to last good version""\n\nThis reverts commit 7467dd032d3873c1e0c1153713298c6b1f56793b.\n\nReason for revert: https://mirror.stream.centos.org/9-stream/BaseOS/source/tree/Packages/gnupg2-2.3.3-3.el9.src.rpm infected rpm is removed from the mirror.\n\nCloses-Bug: #2015309\n\nChange-Id: I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af\n'}]",2,879863,5b587a7f65a3537157dd8b0df2415176aec447cd,13,4,3,12393,,,0,"Revert ""Exclude latest gnupg2 & Pin to last good version""

This reverts commit 7467dd032d3873c1e0c1153713298c6b1f56793b.

Reason for revert: https://mirror.stream.centos.org/9-stream/BaseOS/source/tree/Packages/gnupg2-2.3.3-3.el9.src.rpm infected rpm is removed from the mirror.

Closes-Bug: #2015309

Change-Id: I6f36ab0a68a1824f3e0b317a9f859c06d73cd7af
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/63/879863/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/release/tripleo-ci/CentOS-9/zed.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-9/wallaby.yml', 'config/release/tripleo-ci/CentOS-9/master.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-master.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-zed.yml']",6,0c7584cf6977ab13313bb8aeecfd1e7c1ef9bb3d,,," exclude: - gnupg2-2.3.3-3.el9.x86_64 # TODO(marios) https://bugs.launchpad.net/tripleo/+bug/2015309 # Note(Marios): Downgrade gnupg2 version # due to https://bugs.launchpad.net/tripleo/+bug/2015309 if [ -n ""$(rpm -qa gnupg2)"" ];then sudo dnf -y downgrade gnupg2.x86_64 2.3.3-2.el9; fi",0,30
openstack%2Ftripleo-ansible~stable%2Fwallaby~I14e718683074b96314e8d4823f044eda508f3b9d,openstack/tripleo-ansible,stable/wallaby,I14e718683074b96314e8d4823f044eda508f3b9d,"Revert ""Exclude latest gnupg2 & Pin to last good version""",MERGED,2023-04-17 06:58:53.000000000,2023-04-17 18:59:58.000000000,2023-04-17 18:59:58.000000000,"[{'_account_id': 8449}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 29775}]","[{'number': 1, 'created': '2023-04-17 06:58:53.000000000', 'files': ['zuul.d/playbooks/pre.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/41c8484e813da2e9f7702561353f187bc30098bc', 'message': 'Revert ""Exclude latest gnupg2 & Pin to last good version""\n\nThis reverts commit 9ea5b8874a0c6cbaff1f30539fbc671afd013252.\n\nReason for revert: Package was fixed\n\nChange-Id: I14e718683074b96314e8d4823f044eda508f3b9d\n'}]",0,880591,41c8484e813da2e9f7702561353f187bc30098bc,8,5,1,8367,,,0,"Revert ""Exclude latest gnupg2 & Pin to last good version""

This reverts commit 9ea5b8874a0c6cbaff1f30539fbc671afd013252.

Reason for revert: Package was fixed

Change-Id: I14e718683074b96314e8d4823f044eda508f3b9d
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/91/880591/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/pre.yml'],1,41c8484e813da2e9f7702561353f187bc30098bc,bug/2015309,, # FIXME(Chandan): https://bugs.launchpad.net/tripleo/+bug/2015309 - name: Downgrade gnupg2 to 2.3.3-2.el9.x86_64 become: true ansible.builtin.shell: | sudo dnf -y downgrade gnupg2-2.3.3-2.el9.x86_64 failed_when: false ,0,7
openstack%2Fpuppet-openstack-integration~master~I2947d21ee75b53c3916b50151a401d26180590c9,openstack/puppet-openstack-integration,master,I2947d21ee75b53c3916b50151a401d26180590c9,Exclude system packages from tempest virtualenv,MERGED,2023-04-03 08:02:58.000000000,2023-04-17 18:48:52.000000000,2023-04-17 18:48:52.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-03 08:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/5698cb5bea3071a8eab3b69e4da1ee57c6887a77', 'message': 'Exclude system packages from tempest virtualenv\n\nIn Debian/Ubuntu we install tempest from source, thus all system\npackages should be excluded to avoid conflicts between system packages\nand packages installed by pip.\n\nChange-Id: I2947d21ee75b53c3916b50151a401d26180590c9\n'}, {'number': 2, 'created': '2023-04-03 08:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/ec84531eb44d109ba201130741487300117af501', 'message': 'Exclude system packages from tempest virtualenv\n\nIn Debian/Ubuntu we install tempest from source, thus all system\npackages should be excluded to avoid conflicts between system packages\nand packages installed by pip.\n\nChange-Id: I2947d21ee75b53c3916b50151a401d26180590c9\n'}, {'number': 3, 'created': '2023-04-03 08:09:35.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/1fa65898cfaabe366b4b7910fe147aee28e613ad', 'message': 'Exclude system packages from tempest virtualenv\n\nIn Debian/Ubuntu we install tempest from source, thus all system\npackages should be excluded to avoid conflicts between system packages\nand packages installed by pip.\n\nChange-Id: I2947d21ee75b53c3916b50151a401d26180590c9\n'}]",4,879271,1fa65898cfaabe366b4b7910fe147aee28e613ad,20,3,3,9816,,,0,"Exclude system packages from tempest virtualenv

In Debian/Ubuntu we install tempest from source, thus all system
packages should be excluded to avoid conflicts between system packages
and packages installed by pip.

Change-Id: I2947d21ee75b53c3916b50151a401d26180590c9
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/71/879271/3 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,5698cb5bea3071a8eab3b69e4da1ee57c6887a77,, python3 -m virtualenv run_tempest, python3 -m virtualenv --system-site-packages run_tempest,1,1
openstack%2Foctavia~stable%2Fxena~I30b81866989c22b94fb77e62e7abd180f0f0af50,openstack/octavia,stable/xena,I30b81866989c22b94fb77e62e7abd180f0f0af50,Pass config to castellan,NEW,2023-04-14 05:46:11.000000000,2023-04-17 18:35:50.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 05:46:11.000000000', 'files': ['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/006e0c5ff0b1dc106e3585491e56bb307a8f908e', 'message': ""Pass config to castellan\n\nCurrently castellan can't be configured through octavia.conf as\nconf is not passed while initializing backend.\n\nAlso document castellan configuration options in reference.\n\nBackports on stable branches also include [0] which adds a release note.\n\n[0] Iacc796737bad8881873da7db5273338c2cff9e68\n\nConflicts:\n    etc/config/octavia-config-generator.conf (doesn't exist on stable\n    branches)\n\nChange-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50\n(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)\n(cherry picked from commit e8ada397f9a7acc3d25d5557e7ecf6a7742ff319)\n(cherry picked from commit 8fbe035cd13920f174beb8f528cc93a52a96570f)\n""}]",0,880437,006e0c5ff0b1dc106e3585491e56bb307a8f908e,2,1,1,29244,,,0,"Pass config to castellan

Currently castellan can't be configured through octavia.conf as
conf is not passed while initializing backend.

Also document castellan configuration options in reference.

Backports on stable branches also include [0] which adds a release note.

[0] Iacc796737bad8881873da7db5273338c2cff9e68

Conflicts:
    etc/config/octavia-config-generator.conf (doesn't exist on stable
    branches)

Change-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50
(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)
(cherry picked from commit e8ada397f9a7acc3d25d5557e7ecf6a7742ff319)
(cherry picked from commit 8fbe035cd13920f174beb8f528cc93a52a96570f)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/37/880437/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml']",2,006e0c5ff0b1dc106e3585491e56bb307a8f908e,,--- fixes: - | Usage of ``castellan_cert_manager`` as cert_manager has been significantly improved. Now you can define configuration options for castellan in octavia.conf and they will be passed properly to castellan beckend. This allows to use allowed castellan backends as for certificate storage. ,,11,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c,openstack/tripleo-heat-templates,stable/train,I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c,Set the correct path for pacemaker logs in rsyslog,MERGED,2023-04-13 04:01:03.000000000,2023-04-17 18:08:14.000000000,2023-04-17 18:08:14.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 04:01:03.000000000', 'files': ['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6534d55f8825456ec731cc64eef0c4151112e5c5', 'message': 'Set the correct path for pacemaker logs in rsyslog\n\nPacemaker logs are mounted inside rsyslog container under\n""/var/log/host/pacemaker/"" and not ""/var/log/pacemaker/"".\n\nResolves: rhbz#2179284\nChange-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c\n'}]",0,880183,6534d55f8825456ec731cc64eef0c4151112e5c5,8,2,1,32240,,,0,"Set the correct path for pacemaker logs in rsyslog

Pacemaker logs are mounted inside rsyslog container under
""/var/log/host/pacemaker/"" and not ""/var/log/pacemaker/"".

Resolves: rhbz#2179284
Change-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/880183/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'],1,6534d55f8825456ec731cc64eef0c4151112e5c5,rsyslog_host_logs-stable/train, file: /var/log/host/pacemaker/pacemaker.log, file: /var/log/pacemaker/pacemaker.log,1,1
openstack%2Ftripleo-ansible~stable%2Fwallaby~I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2,openstack/tripleo-ansible,stable/wallaby,I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2,Use short_hostnames when tls-everywhere is enabled,MERGED,2023-04-05 07:41:45.000000000,2023-04-17 18:08:11.000000000,2023-04-17 18:08:11.000000000,"[{'_account_id': 6796}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 33080}, {'_account_id': 34598}, {'_account_id': 35491}]","[{'number': 1, 'created': '2023-04-05 07:41:45.000000000', 'files': ['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1b0836ddf1a0d6820bf9a6ef65457cf8c1b176f4', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}]",3,879486,1b0836ddf1a0d6820bf9a6ef65457cf8c1b176f4,12,6,1,25402,,,0,"Use short_hostnames when tls-everywhere is enabled

Nodes are enrolled and configured during the overcloud deployment, but
deployed ceph needs to work with short_hostnames to properly have ssh
access and distribute, later in the process, both private and public
keys.

Signed-off-by: Francesco Pantano <fpantano@redhat.com>
Change-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/86/879486/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'],1,1b0836ddf1a0d6820bf9a6ef65457cf8c1b176f4,fix_short_hostnames-stable/wallaby," cephadm_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname.split('.')[0] ] }}"" cephadm_non_admin_hosts: ""{{ cephadm_non_admin_hosts + [ item.hostname.split('.')[0] ] }}"""," cephadm_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname ] }}"" cephadm_non_admin_hosts: ""{{ cephadm_non_admin_hosts + [ item.hostname ] }}""",2,2
openstack%2Foctavia~stable%2Fxena~Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82,openstack/octavia,stable/xena,Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82,Rename Context to RequestContext,NEW,2023-04-14 06:01:42.000000000,2023-04-17 18:04:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 06:01:42.000000000', 'files': ['octavia/tests/functional/api/v2/test_health_monitor.py', 'octavia/common/context.py', 'octavia/tests/functional/api/v2/test_quotas.py', 'octavia/tests/functional/api/v2/test_amphora.py', 'octavia/tests/functional/api/v2/test_flavors.py', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/test_flavor_profiles.py', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/tests/functional/api/v2/test_availability_zones.py', 'octavia/tests/unit/common/test_policy.py', 'octavia/tests/functional/api/v2/test_l7rule.py', 'octavia/tests/functional/api/v2/test_member.py', 'octavia/api/common/hooks.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/tests/functional/api/v2/test_provider.py', 'octavia/tests/functional/api/v2/test_availability_zone_profiles.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/15b01f4c3d94d00017bab87035dc90d42922b900', 'message': 'Rename Context to RequestContext\n\nIf castellan is used, it requires one of the following context types to\nbe provided during init: KeystonePassword, KeystoneToken or\nRequestContext [1]\n\nAlso it makes sense to be consistent across projects and with\noslo_context regarding context class naming.\n\n[1] https://opendev.org/openstack/castellan/src/commit/86712360f345866e108e12eda1075101635dd1ec/castellan/key_manager/barbican_key_manager.py#L208-L210\n\nConflicts:\n\toctavia/controller/worker/v2/tasks/notification_tasks.py\n\toctavia/tests/unit/controller/worker/v2/tasks/test_notification_tasks.py\n\toctavia/tests/unit/common/test_policy.py\n\nChange-Id: Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82\n(cherry picked from commit 62e1d871cbbbeefc4919c0c12a3cfff606c53557)\n(cherry picked from commit 48b9d42a571659240dfa737d99781c9713edaf0b)\n(cherry picked from commit 111194847f0c0bc2fe672513485ba9ce70767db4)\n'}]",0,880445,15b01f4c3d94d00017bab87035dc90d42922b900,2,1,1,29244,,,0,"Rename Context to RequestContext

If castellan is used, it requires one of the following context types to
be provided during init: KeystonePassword, KeystoneToken or
RequestContext [1]

Also it makes sense to be consistent across projects and with
oslo_context regarding context class naming.

[1] https://opendev.org/openstack/castellan/src/commit/86712360f345866e108e12eda1075101635dd1ec/castellan/key_manager/barbican_key_manager.py#L208-L210

Conflicts:
	octavia/controller/worker/v2/tasks/notification_tasks.py
	octavia/tests/unit/controller/worker/v2/tasks/test_notification_tasks.py
	octavia/tests/unit/common/test_policy.py

Change-Id: Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82
(cherry picked from commit 62e1d871cbbbeefc4919c0c12a3cfff606c53557)
(cherry picked from commit 48b9d42a571659240dfa737d99781c9713edaf0b)
(cherry picked from commit 111194847f0c0bc2fe672513485ba9ce70767db4)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/45/880445/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/functional/api/v2/test_health_monitor.py', 'octavia/common/context.py', 'octavia/tests/functional/api/v2/test_quotas.py', 'octavia/tests/functional/api/v2/test_amphora.py', 'octavia/tests/functional/api/v2/test_flavors.py', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/test_flavor_profiles.py', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/tests/functional/api/v2/test_availability_zones.py', 'octavia/tests/unit/common/test_policy.py', 'octavia/tests/functional/api/v2/test_l7rule.py', 'octavia/tests/functional/api/v2/test_member.py', 'octavia/api/common/hooks.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/tests/functional/api/v2/test_provider.py', 'octavia/tests/functional/api/v2/test_availability_zone_profiles.py']",17,15b01f4c3d94d00017bab87035dc90d42922b900,," with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id',"," with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id',",303,154
openstack%2Fcinder~master~Id87876543df825f9d84938c615c5976abdebd8f4,openstack/cinder,master,Id87876543df825f9d84938c615c5976abdebd8f4,Make paramiko import optional,MERGED,2023-04-11 15:19:13.000000000,2023-04-17 17:32:19.000000000,2023-04-17 17:30:55.000000000,"[{'_account_id': 597}, {'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-04-11 15:19:13.000000000', 'files': ['cinder/exception.py', 'cinder/ssh_utils.py', 'cinder/tests/unit/test_ssh_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/69497b151ee35aa626be6ddccb40742528241d45', 'message': 'Make paramiko import optional\n\nSince paramiko does not support FIPS, some deployments\nmay run without paramiko installed.  Handle this in\nssh_utils.\n\n(This does not handle the paramiko requirement for\ndrivers that import it directly.)\n\nChange-Id: Id87876543df825f9d84938c615c5976abdebd8f4\n'}]",8,880062,69497b151ee35aa626be6ddccb40742528241d45,32,4,1,4523,,,0,"Make paramiko import optional

Since paramiko does not support FIPS, some deployments
may run without paramiko installed.  Handle this in
ssh_utils.

(This does not handle the paramiko requirement for
drivers that import it directly.)

Change-Id: Id87876543df825f9d84938c615c5976abdebd8f4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/880062/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/exception.py', 'cinder/ssh_utils.py', 'cinder/tests/unit/test_ssh_utils.py']",3,69497b151ee35aa626be6ddccb40742528241d45,," @mock.patch('cinder.ssh_utils.paramiko', new=None) def test_missing_paramiko(self): self.assertRaises(exception.RequirementMissing, ssh_utils.SSHPool, '192.0.2.1', 22, 10, 'test', password='hello')",,20,1
openstack%2Fnetworking-odl~master~Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43,openstack/networking-odl,master,Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43,CI: Add periodic weekly job with sqlalchemy main,MERGED,2023-02-01 15:00:23.000000000,2023-04-17 17:23:13.000000000,2023-04-17 17:20:56.000000000,"[{'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-01 15:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/b63ac0faa4857a24179dca5719913845c4feb6ef', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 2, 'created': '2023-02-02 10:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/932fee8a2ff0b795c5eafa8b5175af8cb9325634', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 3, 'created': '2023-02-03 05:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/f56ea545bfabd3a470c89aa0e6f8508eb72736f4', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 4, 'created': '2023-02-03 05:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/52726f651b86e6589975ddccd078b73f4ea7e6a5', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 5, 'created': '2023-02-03 15:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/3933b1dd75e1b5c64291ba551474279ca55295a4', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/872644\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 6, 'created': '2023-02-03 15:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/79caeab5cc4104078981521efad08c61b900595c', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 7, 'created': '2023-02-15 09:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/1464d1a665dcf7dfb2be30c951baacd32c1f7a10', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 8, 'created': '2023-02-21 13:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/c9e9fd89a0d02d30aaf3522dea1ca7e1c8d112c1', 'message': 'CI: Add periodic weekly job with sqlalchemy main\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-main, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}, {'number': 9, 'created': '2023-04-14 06:52:08.000000000', 'files': ['.zuul.d/project.yaml', '.zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/84733c7a23b2f8ee3cb96c091348738f635cc578', 'message': 'CI: Add periodic weekly job with sqlalchemy main\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-main, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43\nRelated-Bug: #2004265\n'}]",12,872416,84733c7a23b2f8ee3cb96c091348738f635cc578,43,3,9,8313,,,0,"CI: Add periodic weekly job with sqlalchemy main

Add new job to periodic weekly
openstack-tox-py310-with-sqlalchemy-main, and change previous
jobs in the periodic to py310

Depends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641
Change-Id: Ib8e7cb764ab4943cb8e0f01dd3b04c7595ee2c43
Related-Bug: #2004265
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/16/872416/3 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,b63ac0faa4857a24179dca5719913845c4feb6ef,bug/2004265, - openstack-tox-py310 - openstack-tox-py310-with-oslo-master: required-projects: *odl_required_projects - openstack-tox-py310-with-sqlalchemy-master: parent: openstack-tox-py310-with-oslo-master required-projects: - github.com/sqlalchemy/sqlalchemy, - openstack-tox-py39,7,1
openstack%2Fkolla-ansible~master~I5ae1d911c5df423e0b70dab306709320083b7b69,openstack/kolla-ansible,master,I5ae1d911c5df423e0b70dab306709320083b7b69,opensearch: default dashboards tag to opensearch_tag,MERGED,2023-04-17 12:31:18.000000000,2023-04-17 17:08:48.000000000,2023-04-17 17:07:39.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 27339}, {'_account_id': 35345}]","[{'number': 1, 'created': '2023-04-17 12:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2dc3f8c3f4717e9043d7812bfe2468ecb37e4b60', 'message': 'opensearch: default dashboards tag to opensearch_tag\n\nChange-Id: I5ae1d911c5df423e0b70dab306709320083b7b69\n'}, {'number': 2, 'created': '2023-04-17 12:37:33.000000000', 'files': ['ansible/roles/opensearch/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c0a45c7eb74224557c1e86883eed4e1cd33f8c61', 'message': 'opensearch: default dashboards tag to opensearch_tag\n\nCloses-Bug: #2016627\n\nChange-Id: I5ae1d911c5df423e0b70dab306709320083b7b69\n'}]",1,880626,c0a45c7eb74224557c1e86883eed4e1cd33f8c61,13,5,2,22629,,,0,"opensearch: default dashboards tag to opensearch_tag

Closes-Bug: #2016627

Change-Id: I5ae1d911c5df423e0b70dab306709320083b7b69
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/26/880626/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/opensearch/defaults/main.yml'],1,2dc3f8c3f4717e9043d7812bfe2468ecb37e4b60,,"opensearch_dashboards_tag: ""{{ opensearch_tag }}""","opensearch_dashboards_tag: ""{{ openstack_tag }}""",1,1
openstack%2Fplacement~master~I9c807c2bad39fed288314b1fb291d2a286aa09c3,openstack/placement,master,I9c807c2bad39fed288314b1fb291d2a286aa09c3,Update python testing as per zed cycle testing runtime,MERGED,2022-05-13 08:42:19.000000000,2023-04-17 16:43:23.000000000,2023-04-17 16:41:10.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-05-13 08:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/eab50f2a363ed36a70d0c9d2218cceb8f784f358', 'message': 'Update python testing as per zed cycle testing runtime\n\nIn Zed cycle, we have dropped the python 3.6/3.7[1] testing\nand its support. Removing the py36 centos8 job as well as\nupdating the python classifier also to reflect the same.\n\n[1] https://governance.openstack.org/tc/reference/runtimes/zed.html\n\nChange-Id: I9c807c2bad39fed288314b1fb291d2a286aa09c3\n'}, {'number': 2, 'created': '2022-05-13 08:42:39.000000000', 'files': ['releasenotes/notes/drop-python-3-6-and-3-7-9db9b12a73106e26.yaml', '.zuul.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/placement/commit/fcd9e88da29d62f71492ffa749b7d08ef128caab', 'message': 'Update python testing as per zed cycle testing runtime\n\nIn Zed cycle, we have dropped the python 3.6/3.7[1] testing\nand its support. Removing the py36 centos8 job as well as\nupdating the python classifier also to reflect the same.\n\n[1] https://governance.openstack.org/tc/reference/runtimes/zed.html\n\nChange-Id: I9c807c2bad39fed288314b1fb291d2a286aa09c3\n'}]",0,841690,fcd9e88da29d62f71492ffa749b7d08ef128caab,8,2,2,31412,,,0,"Update python testing as per zed cycle testing runtime

In Zed cycle, we have dropped the python 3.6/3.7[1] testing
and its support. Removing the py36 centos8 job as well as
updating the python classifier also to reflect the same.

[1] https://governance.openstack.org/tc/reference/runtimes/zed.html

Change-Id: I9c807c2bad39fed288314b1fb291d2a286aa09c3
",git fetch https://review.opendev.org/openstack/placement refs/changes/90/841690/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-python-3-6-and-3-7-9db9b12a73106e26.yaml', '.zuul.yaml', 'setup.cfg']",3,eab50f2a363ed36a70d0c9d2218cceb8f784f358,,python_requires = >=3.8,python_requires = >=3.6 Programming Language :: Python :: 3.6 Programming Language :: Python :: 3.7,6,7
openstack%2Foctavia~stable%2Fxena~I1a9a9177cafb8c52f13a646b12cff1c35afd8679,openstack/octavia,stable/xena,I1a9a9177cafb8c52f13a646b12cff1c35afd8679,Fix SQLAlchemy warning about conflict relationship with Tags,NEW,2023-04-14 06:18:55.000000000,2023-04-17 16:41:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 06:18:55.000000000', 'files': ['octavia/db/models.py', 'releasenotes/notes/remove-tags-relationship-warnings-a3c0175135f6cd84.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/218d667892332e0d548d36eb563dcfac482087c2', 'message': ""Fix SQLAlchemy warning about conflict relationship with Tags\n\nSQLAlchemy shows a warning about a conflict with a relationship with the\nTags object:\n\n  SAWarning: relationship '<Obj1>._tags' will copy column <obj1>.id to\n  column tags.resource_id, which conflicts with relationship(s):\n  '<Obj2>._tags'\n\nRemove this warning by using the overlaps [0] keyword in the definition\nof the relationship.\n\n[0] https://docs.sqlalchemy.org/en/20/orm/relationship_api.html#\\\n    sqlalchemy.orm.relationship.params.overlaps\n\nChange-Id: I1a9a9177cafb8c52f13a646b12cff1c35afd8679\n(cherry picked from commit 8409c06cda0bb3e3c0795b14ec3917ca2b5afe7b)\n(cherry picked from commit 6ae577279fee13b80e3b8e50252d15c70668d388)\n(cherry picked from commit 64b8846eda6ffed48a5964a8c285028dc0fcd99c)\n""}]",0,880449,218d667892332e0d548d36eb563dcfac482087c2,2,1,1,29244,,,0,"Fix SQLAlchemy warning about conflict relationship with Tags

SQLAlchemy shows a warning about a conflict with a relationship with the
Tags object:

  SAWarning: relationship '<Obj1>._tags' will copy column <obj1>.id to
  column tags.resource_id, which conflicts with relationship(s):
  '<Obj2>._tags'

Remove this warning by using the overlaps [0] keyword in the definition
of the relationship.

[0] https://docs.sqlalchemy.org/en/20/orm/relationship_api.html#\
    sqlalchemy.orm.relationship.params.overlaps

Change-Id: I1a9a9177cafb8c52f13a646b12cff1c35afd8679
(cherry picked from commit 8409c06cda0bb3e3c0795b14ec3917ca2b5afe7b)
(cherry picked from commit 6ae577279fee13b80e3b8e50252d15c70668d388)
(cherry picked from commit 64b8846eda6ffed48a5964a8c285028dc0fcd99c)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/49/880449/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/db/models.py', 'releasenotes/notes/remove-tags-relationship-warnings-a3c0175135f6cd84.yaml']",2,218d667892332e0d548d36eb563dcfac482087c2,,--- fixes: - | Fixed SQLAlchemy warnings about the relationship between the Tags object and the other Octavia resources. ,,19,7
openstack%2Foctavia~stable%2Fzed~Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82,openstack/octavia,stable/zed,Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82,Rename Context to RequestContext,NEW,2023-04-14 05:48:09.000000000,2023-04-17 16:38:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 05:48:09.000000000', 'files': ['octavia/tests/functional/api/v2/test_health_monitor.py', 'octavia/common/context.py', 'octavia/tests/functional/api/v2/test_quotas.py', 'octavia/tests/functional/api/v2/test_amphora.py', 'octavia/tests/functional/api/v2/test_flavors.py', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/test_flavor_profiles.py', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/controller/worker/v2/tasks/notification_tasks.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_notification_tasks.py', 'octavia/tests/functional/api/v2/test_availability_zones.py', 'octavia/tests/unit/common/test_policy.py', 'octavia/tests/functional/api/v2/test_l7rule.py', 'octavia/tests/functional/api/v2/test_member.py', 'octavia/api/common/hooks.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/tests/functional/api/v2/test_provider.py', 'octavia/tests/functional/api/v2/test_availability_zone_profiles.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/48b9d42a571659240dfa737d99781c9713edaf0b', 'message': 'Rename Context to RequestContext\n\nIf castellan is used, it requires one of the following context types to\nbe provided during init: KeystonePassword, KeystoneToken or\nRequestContext [1]\n\nAlso it makes sense to be consistent across projects and with\noslo_context regarding context class naming.\n\n[1] https://opendev.org/openstack/castellan/src/commit/86712360f345866e108e12eda1075101635dd1ec/castellan/key_manager/barbican_key_manager.py#L208-L210\n\nChange-Id: Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82\n(cherry picked from commit 62e1d871cbbbeefc4919c0c12a3cfff606c53557)\n'}]",0,880439,48b9d42a571659240dfa737d99781c9713edaf0b,2,1,1,29244,,,0,"Rename Context to RequestContext

If castellan is used, it requires one of the following context types to
be provided during init: KeystonePassword, KeystoneToken or
RequestContext [1]

Also it makes sense to be consistent across projects and with
oslo_context regarding context class naming.

[1] https://opendev.org/openstack/castellan/src/commit/86712360f345866e108e12eda1075101635dd1ec/castellan/key_manager/barbican_key_manager.py#L208-L210

Change-Id: Ic08ad89b4e07e0fe8a80b3e5db6d50276aafff82
(cherry picked from commit 62e1d871cbbbeefc4919c0c12a3cfff606c53557)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/39/880439/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/functional/api/v2/test_health_monitor.py', 'octavia/common/context.py', 'octavia/tests/functional/api/v2/test_quotas.py', 'octavia/tests/functional/api/v2/test_amphora.py', 'octavia/tests/functional/api/v2/test_flavors.py', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/test_flavor_profiles.py', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/controller/worker/v2/tasks/notification_tasks.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_notification_tasks.py', 'octavia/tests/functional/api/v2/test_availability_zones.py', 'octavia/tests/unit/common/test_policy.py', 'octavia/tests/functional/api/v2/test_l7rule.py', 'octavia/tests/functional/api/v2/test_member.py', 'octavia/api/common/hooks.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/tests/functional/api/v2/test_provider.py', 'octavia/tests/functional/api/v2/test_availability_zone_profiles.py']",19,48b9d42a571659240dfa737d99781c9713edaf0b,," with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id', with mock.patch.object(octavia.common.context.RequestContext, 'project_id',"," with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id', with mock.patch.object(octavia.common.context.Context, 'project_id',",310,163
openstack%2Foctavia~stable%2Fyoga~I30b81866989c22b94fb77e62e7abd180f0f0af50,openstack/octavia,stable/yoga,I30b81866989c22b94fb77e62e7abd180f0f0af50,Pass config to castellan,NEW,2023-04-14 05:45:58.000000000,2023-04-17 16:38:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 05:45:58.000000000', 'files': ['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/8fbe035cd13920f174beb8f528cc93a52a96570f', 'message': ""Pass config to castellan\n\nCurrently castellan can't be configured through octavia.conf as\nconf is not passed while initializing backend.\n\nAlso document castellan configuration options in reference.\n\nBackports on stable branches also include [0] which adds a release note.\n\n[0] Iacc796737bad8881873da7db5273338c2cff9e68\n\nConflicts:\n    etc/config/octavia-config-generator.conf (doesn't exist on stable\n    branches)\n\nChange-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50\n(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)\n(cherry picked from commit e8ada397f9a7acc3d25d5557e7ecf6a7742ff319)\n""}]",0,880436,8fbe035cd13920f174beb8f528cc93a52a96570f,2,1,1,29244,,,0,"Pass config to castellan

Currently castellan can't be configured through octavia.conf as
conf is not passed while initializing backend.

Also document castellan configuration options in reference.

Backports on stable branches also include [0] which adds a release note.

[0] Iacc796737bad8881873da7db5273338c2cff9e68

Conflicts:
    etc/config/octavia-config-generator.conf (doesn't exist on stable
    branches)

Change-Id: I30b81866989c22b94fb77e62e7abd180f0f0af50
(cherry picked from commit f5ac714a7b22687fbb5b12db7f41c283cee12aee)
(cherry picked from commit e8ada397f9a7acc3d25d5557e7ecf6a7742ff319)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/36/880436/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/certificates/manager/castellan_mgr.py', 'releasenotes/notes/octavia_castellan_config-995e65f129e3e983.yaml']",2,8fbe035cd13920f174beb8f528cc93a52a96570f,,--- fixes: - | Usage of ``castellan_cert_manager`` as cert_manager has been significantly improved. Now you can define configuration options for castellan in octavia.conf and they will be passed properly to castellan beckend. This allows to use allowed castellan backends as for certificate storage. ,,11,1
openstack%2Fkayobe~stable%2Fzed~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kayobe,stable/zed,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 08:44:03.000000000,2023-04-17 16:19:06.000000000,2023-04-17 16:17:57.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 08:44:03.000000000', 'files': ['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/4fb98861d1195e1540d17af21ac0f47b9856df25', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)\n""}]",0,880462,4fb98861d1195e1540d17af21ac0f47b9856df25,8,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/62/880462/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py']",2,4fb98861d1195e1540d17af21ac0f47b9856df25,fix-merge-action-plugins," copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)", result.update(copy_action.run(task_vars=task_vars)),12,4
openstack%2Fkayobe~stable%2Fyoga~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kayobe,stable/yoga,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 08:44:28.000000000,2023-04-17 16:19:04.000000000,2023-04-17 16:17:55.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 08:44:28.000000000', 'files': ['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/c0dbca2fcdfad11be9866721947fe959dd822083', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)\n""}]",0,880463,c0dbca2fcdfad11be9866721947fe959dd822083,8,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/63/880463/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py']",2,c0dbca2fcdfad11be9866721947fe959dd822083,fix-merge-action-plugins," copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)", result.update(copy_action.run(task_vars=task_vars)),12,4
openstack%2Fnova~master~I681b81a035f900addd18563dfd563a8e488b7ad7,openstack/nova,master,I681b81a035f900addd18563dfd563a8e488b7ad7,fixup! db: Remove unnecessary 'insert()' argument,ABANDONED,2023-04-17 16:07:07.000000000,2023-04-17 16:08:14.000000000,,[],"[{'number': 1, 'created': '2023-04-17 16:07:07.000000000', 'files': ['nova/tests/unit/db/main/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d8de7789be8fc7d29c7f78ae72a6bc0f598863d', 'message': ""fixup! db: Remove unnecessary 'insert()' argument\n\nChange-Id: I681b81a035f900addd18563dfd563a8e488b7ad7\n""}]",0,880666,3d8de7789be8fc7d29c7f78ae72a6bc0f598863d,2,0,1,15334,,,0,"fixup! db: Remove unnecessary 'insert()' argument

Change-Id: I681b81a035f900addd18563dfd563a8e488b7ad7
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/880666/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/db/main/test_api.py'],1,3d8de7789be8fc7d29c7f78ae72a6bc0f598863d,sqlalchemy-20, mock_insert.assert_called_once_with(), mock_insert.assert_called_once_with(None),1,1
openstack%2Fkayobe~stable%2Fxena~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kayobe,stable/xena,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 08:44:49.000000000,2023-04-17 16:06:46.000000000,2023-04-17 16:05:46.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 08:44:49.000000000', 'files': ['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e8b9b8c0edb8e1482f3e4a0cde23dd735668d5d1', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)\n""}]",0,880464,e8b9b8c0edb8e1482f3e4a0cde23dd735668d5d1,8,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 46000d4e05b6b7fc133114e8100da6fc64afb70e)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/64/880464/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/plugins/action/merge_configs.py', 'kayobe/plugins/action/merge_yaml.py']",2,e8b9b8c0edb8e1482f3e4a0cde23dd735668d5d1,fix-merge-action-plugins," copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)", result.update(copy_action.run(task_vars=task_vars)),12,4
openstack%2Fnetworking-sfc~master~I16a823d9274f4ec5290c1e2d5d009d02f35623c0,openstack/networking-sfc,master,I16a823d9274f4ec5290c1e2d5d009d02f35623c0,Add neutron and neutron-lib projects to SQLAlchemy main branch job,MERGED,2023-04-03 12:27:46.000000000,2023-04-17 16:01:12.000000000,2023-04-17 15:58:57.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-03 12:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/d4b77393e2b7f84779fb7c9cb98f3f00b0492caa', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: I16a823d9274f4ec5290c1e2d5d009d02f35623c0\nRelated-Bug: #2004265\n'}, {'number': 2, 'created': '2023-04-03 12:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/3b6c5f67110bc0569baffd39a3574941634ed27a', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: I16a823d9274f4ec5290c1e2d5d009d02f35623c0\nRelated-Bug: #2004265\n'}, {'number': 3, 'created': '2023-04-12 12:24:55.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/887bed68c7ab52eacf1da99cafea17059a232ac1', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: I16a823d9274f4ec5290c1e2d5d009d02f35623c0\nRelated-Bug: #2004265\n'}]",4,879336,887bed68c7ab52eacf1da99cafea17059a232ac1,16,3,3,8313,,,0,"Add neutron and neutron-lib projects to SQLAlchemy main branch job

Change-Id: I16a823d9274f4ec5290c1e2d5d009d02f35623c0
Related-Bug: #2004265
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/36/879336/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,d4b77393e2b7f84779fb7c9cb98f3f00b0492caa,bug/2004265, - openstack/neutron-lib - openstack/neutron,,2,1
openstack%2Fnetworking-bagpipe~master~I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c,openstack/networking-bagpipe,master,I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c,CI: Add periodic weekly job with sqlalchemy main,MERGED,2023-02-01 13:32:13.000000000,2023-04-17 15:43:51.000000000,2023-04-17 15:41:42.000000000,"[{'_account_id': 8313}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-01 13:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/ec4555c570b9ac2d9635031b3cf861f5cf68d240', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 2, 'created': '2023-02-02 10:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/df8c0af1226dcb0b3934b69cbefe6ce120cf7d29', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 3, 'created': '2023-02-03 05:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/fe43107bf9a382617c07c4fc6c979ff8f8705ce9', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 4, 'created': '2023-02-03 05:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/bcfdfbe553cadc854443b746a7c6fd6601f6c99b', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 5, 'created': '2023-02-03 15:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/c4836a597b86627798625b07a93918ae48be01c5', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/872644\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 6, 'created': '2023-02-03 15:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/814f2ba781b3abcee48613b5a1eb10d1e8660a64', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 7, 'created': '2023-02-14 16:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/6fd15a9c3d481fb19bd3437867b679b48e3fcaf4', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 8, 'created': '2023-02-21 12:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/3b73d8af6eabf69aa34160f38738e1a31d317929', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 9, 'created': '2023-02-21 12:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/39bca18c52aec09ed20494570b1d39bb685d3a32', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 10, 'created': '2023-02-21 12:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/4e681eb9d1de4e99b5709743534ac63750e0fd92', 'message': 'CI: Add periodic weekly job with sqlalchemy master\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-master, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 11, 'created': '2023-02-21 13:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/3c87658291acd9dfd7531ab14e7bd7dc5c1079e4', 'message': 'CI: Add periodic weekly job with sqlalchemy main\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-main, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 12, 'created': '2023-04-03 13:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/88f39103210c702aa00c7069b5d67a8a5b005b41', 'message': 'CI: Add periodic weekly job with sqlalchemy main\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-main, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}, {'number': 13, 'created': '2023-04-12 12:15:03.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/7eecbc11f3f77ade3dc6176b66f6a36b502c0b6a', 'message': 'CI: Add periodic weekly job with sqlalchemy main\n\nAdd new job to periodic weekly\nopenstack-tox-py310-with-sqlalchemy-main, and change previous\njobs in the periodic to py310\n\nDepends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641\nChange-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c\nRelated-Bug: #2004265\n'}]",15,872408,7eecbc11f3f77ade3dc6176b66f6a36b502c0b6a,48,4,13,8313,,,0,"CI: Add periodic weekly job with sqlalchemy main

Add new job to periodic weekly
openstack-tox-py310-with-sqlalchemy-main, and change previous
jobs in the periodic to py310

Depends-On: https://review.opendev.org/c/openstack/networking-sfc/+/872641
Change-Id: I32a0b6c21ecbac9e05dbdc2c30d55e18650c993c
Related-Bug: #2004265
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/08/872408/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,ec4555c570b9ac2d9635031b3cf861f5cf68d240,bug/2004265, - openstack-tox-py310: - openstack-tox-py310-with-oslo-master: - openstack-tox-py310-with-sqlalchemy-master: parent: openstack-tox-py310-with-oslo-master required-projects: - github.com/sqlalchemy/sqlalchemy, - openstack-tox-py39: - openstack-tox-py39-with-oslo-master:,6,2
openstack%2Foslo.db~master~I4d66f0308b89a187143ef6c8495383fe60043c14,openstack/oslo.db,master,I4d66f0308b89a187143ef6c8495383fe60043c14,Add release note for base test class removal,MERGED,2021-06-25 17:07:43.000000000,2023-04-17 15:39:37.000000000,2023-04-17 15:38:16.000000000,"[{'_account_id': 9816}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-06-25 17:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0a604f9cd5a44dc50c6f7fa1cf77468038a6c7fe', 'message': ""tests: Remove 'oslo_db.sqlalchemy.test_base'\n\nWell, mostly. This has been deprecated since 4.15.0 (2015) in favour of\nfixtures, allowing us to avoid the 'oslo.test' runtime dependency and\nensuring people create base classes that actually fit their purposes.\nRemove these now. I suspect there will be a bit of fallout from this but\nit's trivial to resolve.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2021-07-28 14:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/831376b90ae355518f46499a4e423690982442f2', 'message': ""tests: Remove 'oslo_db.sqlalchemy.test_base'\n\nWell, mostly. This has been deprecated since 4.15.0 (2015) in favour of\nfixtures, allowing us to avoid the 'oslo.test' runtime dependency and\nensuring people create base classes that actually fit their purposes.\nRemove these now. I suspect there will be a bit of fallout from this but\nit's trivial to resolve.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2022-02-11 18:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/536a03349efef5197604714931a5a81a137760cf', 'message': ""tests: Remove 'oslo_db.sqlalchemy.test_base'\n\nWell, mostly. This has been deprecated since 4.15.0 (2015) in favour of\nfixtures, allowing us to avoid the 'oslo.test' runtime dependency and\nensuring people create base classes that actually fit their purposes.\nRemove these now. I suspect there will be a bit of fallout from this but\nit's trivial to resolve.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2022-02-11 18:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/043209237fd2ebe8473fed7de1ac0ed03969d4a7', 'message': ""tests: Remove 'oslo_db.sqlalchemy.test_base'\n\nWell, mostly. This has been deprecated since 4.15.0 (2015) in favour of\nfixtures, allowing us to avoid the 'oslo.test' runtime dependency and\nensuring people create base classes that actually fit their purposes.\nRemove these now. I suspect there will be a bit of fallout from this but\nit's trivial to resolve.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2022-07-20 14:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c9236d836f3fccc1ea82a19cbc8deb0a028d963b', 'message': ""tests: Remove 'oslo_db.sqlalchemy.test_base'\n\nWell, mostly. This has been deprecated since 4.15.0 (2015) in favour of\nfixtures, allowing us to avoid the 'oslo.test' runtime dependency and\nensuring people create base classes that actually fit their purposes.\nRemove these now. I suspect there will be a bit of fallout from this but\nit's trivial to resolve.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2023-04-17 12:39:19.000000000', 'files': ['oslo_db/sqlalchemy/test_fixtures.py', 'oslo_db/sqlalchemy/enginefacade.py', 'releasenotes/notes/remove-base-test-classes-557889ec4f072781.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/af5392bf3fcf032ed376e5e49dff485f875c0a57', 'message': 'Add release note for base test class removal\n\nIn change I1e71150ba6daeba464b6ed8d46163f1f34959db3 we removed the\nlegacy base test classes, first deprecated in 2015. We forgot to include\na release note, however. Address this now.\n\nChange-Id: I4d66f0308b89a187143ef6c8495383fe60043c14\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",6,798136,af5392bf3fcf032ed376e5e49dff485f875c0a57,24,4,6,15334,,,0,"Add release note for base test class removal

In change I1e71150ba6daeba464b6ed8d46163f1f34959db3 we removed the
legacy base test classes, first deprecated in 2015. We forgot to include
a release note, however. Address this now.

Change-Id: I4d66f0308b89a187143ef6c8495383fe60043c14
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/36/798136/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/test_base.py', 'oslo_db/sqlalchemy/test_fixtures.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/tests/sqlalchemy/test_fixtures.py', 'oslo_db/tests/sqlalchemy/base.py']",6,0a604f9cd5a44dc50c6f7fa1cf77468038a6c7fe,cleanup,,"import debtcollector @debtcollector.removals.removed_class( ""DbTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class DbTestCase(db_fixtures.OpportunisticDBTestMixin, test_base.BaseTestCase): def setUp(self): super(DbTestCase, self).setUp() self.engine = enginefacade.writer.get_engine() self.sessionmaker = enginefacade.writer.get_sessionmaker() @debtcollector.removals.removed_class( ""MySQLOpportunisticTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class MySQLOpportunisticTestCase(DbTestCase): FIXTURE = db_fixtures.MySQLOpportunisticFixture @debtcollector.removals.removed_class( ""PostgreSQLOpportunisticTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class PostgreSQLOpportunisticTestCase(DbTestCase): FIXTURE = db_fixtures.PostgresqlOpportunisticFixture ",6,337
openstack%2Fkolla~stable%2Fwallaby~I14af40078508b06e46866b77ab200228ec827a0d,openstack/kolla,stable/wallaby,I14af40078508b06e46866b77ab200228ec827a0d,Add multipath to cinder-volume,MERGED,2023-04-03 10:54:26.000000000,2023-04-17 15:36:54.000000000,2023-04-17 15:35:49.000000000,"[{'_account_id': 13671}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-03 10:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6143e4cd3ab862c0e486af5fea783f1c9562eb73', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 2, 'created': '2023-04-04 13:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9b2b1b6eb30467064ef13328dd518b07a6cf5a88', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 3, 'created': '2023-04-04 13:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f77b60b387dbce708b4205ff86ecda463fdad508', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 4, 'created': '2023-04-04 13:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/29d9187903f2d39af5b078033b48de123e825d79', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nThis change also contains partial fix from\nI650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 until tox jobs\nfixed in it.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 5, 'created': '2023-04-12 20:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0c954dde32853ef1df1e47d496fd12548d58904c', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 6, 'created': '2023-04-12 20:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/83cb14a287383e918fb76a65632416267780fdb5', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 7, 'created': '2023-04-12 20:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4746fab68f935080b0037bf5e9b1e944828ff478', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}, {'number': 8, 'created': '2023-04-13 10:46:50.000000000', 'files': ['docker/cinder/cinder-volume/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/50868ec65aa8a3c62cf0e57214066228bf35d326', 'message': 'Add multipath to cinder-volume\n\nCinder-volume container can operate on multipath devices but\nfails to do so due to absent multipath package for several images.\nThis fix explicitely adds multipath to the image.\n\nCloses-Bug: #1970541\nChange-Id: I14af40078508b06e46866b77ab200228ec827a0d\n(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)\n'}]",1,879182,50868ec65aa8a3c62cf0e57214066228bf35d326,28,5,8,22629,,,0,"Add multipath to cinder-volume

Cinder-volume container can operate on multipath devices but
fails to do so due to absent multipath package for several images.
This fix explicitely adds multipath to the image.

Closes-Bug: #1970541
Change-Id: I14af40078508b06e46866b77ab200228ec827a0d
(cherry picked from commit b9aa91381391c8aaabc7c76de39e5ee258562f4c)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/82/879182/6 && git format-patch -1 --stdout FETCH_HEAD,['docker/cinder/cinder-volume/Dockerfile.j2'],1,6143e4cd3ab862c0e486af5fea783f1c9562eb73,bug/1970541-stable/wallaby," 'device-mapper-multipath', 'multipath-tools',",,2,0
openstack%2Fkolla~master~Ifa095a4a5a4a2476b356b082b9b57b491c9e29db,openstack/kolla,master,Ifa095a4a5a4a2476b356b082b9b57b491c9e29db,Glance-api fails due to absent multipath tools,MERGED,2023-04-13 11:08:27.000000000,2023-04-17 15:36:23.000000000,2023-04-17 15:35:16.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23871}]","[{'number': 1, 'created': '2023-04-13 11:08:27.000000000', 'files': ['docker/glance/glance-api/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d23ace3fa6197d32fc6a883f9f06e54293d2089b', 'message': 'Glance-api fails due to absent multipath tools\n\nCloses-Bug: #2015500\nChange-Id: Ifa095a4a5a4a2476b356b082b9b57b491c9e29db\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}]",0,880281,d23ace3fa6197d32fc6a883f9f06e54293d2089b,11,5,1,14200,,,0,"Glance-api fails due to absent multipath tools

Closes-Bug: #2015500
Change-Id: Ifa095a4a5a4a2476b356b082b9b57b491c9e29db
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/81/880281/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/glance/glance-api/Dockerfile.j2'],1,d23ace3fa6197d32fc6a883f9f06e54293d2089b,glance-api-multipath," {% set glance_api_packages = [ 'device-mapper-multipath', 'qemu-img' ] %} 'multipath-tools',", {% set glance_api_packages = ['qemu-img'] %},5,1
openstack%2Ftap-as-a-service~master~Id22e20efbf30dddbdbcb986186e02f056f3ed21d,openstack/tap-as-a-service,master,Id22e20efbf30dddbdbcb986186e02f056f3ed21d,OSC: Remove calls to neutronclient,MERGED,2022-12-15 12:23:05.000000000,2023-04-17 15:28:11.000000000,2023-04-17 15:28:11.000000000,"[{'_account_id': 7730}, {'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-15 12:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/c343aed8965c3d1021f46a395124915ff5a16829', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\nTODO: fix remaining unit tests\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371?forceReload=true\n\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 2, 'created': '2022-12-15 12:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/c1668b6a36ae37731dfd560e6a0d1e23b9357209', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\nTODO: fix remaining unit tests\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371?forceReload=true\n\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 3, 'created': '2022-12-15 14:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/bc0a74da3536fe06adc2274c97384580a00e5aa5', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371?forceReload=true\n\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 4, 'created': '2023-01-20 15:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/e58f0ead9c08f4ae28b1aa3ad9c314349d903d25', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371\n\nDepends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 5, 'created': '2023-01-25 08:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/003b443f0fc5fb36fdcc30bb0751fd6a88c31fbc', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371\n\nDepends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 6, 'created': '2023-02-24 08:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/f47942cff3c50f7b8ecf01cf5907cbea4d649093', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371\n\nDepends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 7, 'created': '2023-02-24 08:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/0726b706fa4238883f6ba068023bd03186422ccb', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371\n\nDepends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}, {'number': 8, 'created': '2023-03-03 14:58:40.000000000', 'files': ['requirements.txt', 'neutron_taas/tests/unit/taas_client/osc/fakes.py', 'neutron_taas/tests/unit/taas_client/osc/test_osc_tap_service.py', 'neutron_taas/taas_client/osc/tap_service.py', 'neutron_taas/tests/unit/taas_client/osc/test_osc_tap_flow.py', 'neutron_taas/taas_client/osc/tap_flow.py'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/def943f447615df692bb8853a3905f0ec2299a1a', 'message': 'OSC: Remove calls to neutronclient\n\nWith [1] the python binding code in Neutronclient prints warning\nabout future deprecation, change taas osc client code to use\ntotally OpenstackSDK.\n\n[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371\n\nDepends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287\nRelated-Bug: #1999774\nChange-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d\n'}]",5,867786,def943f447615df692bb8853a3905f0ec2299a1a,23,4,8,8313,,,0,"OSC: Remove calls to neutronclient

With [1] the python binding code in Neutronclient prints warning
about future deprecation, change taas osc client code to use
totally OpenstackSDK.

[1]: https://review.opendev.org/c/openstack/python-neutronclient/+/862371

Depends-On: https://review.opendev.org/c/openstack/openstacksdk/+/871287
Related-Bug: #1999774
Change-Id: Id22e20efbf30dddbdbcb986186e02f056f3ed21d
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/86/867786/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_taas/tests/unit/taas_client/osc/fakes.py', 'neutron_taas/tests/unit/taas_client/osc/test_osc_tap_service.py', 'neutron_taas/taas_client/osc/tap_service.py', 'neutron_taas/taas_client/osc/tap_flow.py']",4,c343aed8965c3d1021f46a395124915ff5a16829,bug/1999774,"from openstack import resourcefrom osc_lib.cli import identity as identity_utilsfrom neutron_taas._i18n import _ from neutron_taas.taas_client.osc import tap_serviceclass TapFlow(resource.Resource): """"""Tap Flow"""""" resource_key = 'tap_flow' resources_key = 'tap_flows' base_path = '/taas/tap_flows' # capabilities allow_create = True allow_fetch = True allow_commit = True allow_delete = True allow_list = True _allow_unknown_attrs_in_body = True _query_mapping = resource.QueryParameters( ""sort_key"", ""sort_dir"", 'name', 'project_id' ) # Properties #: The ID of the tap flow. id = resource.Body('id') #: The tap flow's name. name = resource.Body('name') #: The tap flow's description. description = resource.Body('description') #: The ID of the project that owns the tap flow. project_id = resource.Body('project_id', alias='tenant_id') #: Tenant_id (deprecated attribute). tenant_id = resource.Body('tenant_id', deprecated=True) #: The id of the tap_service with which the tap flow is associated tap_service_id = resource.Body('tap_service_id') #: The direction of the tap flow. direction = resource.Body('direction') #: The status for the tap flow. status = resource.Body('status') #: The id of the port the tap flow is associated with source_port = resource.Body('source_port') identity_utils.add_project_owner_option_to_parser(parser) type=lambda s: s.lower(), client = self.app.client_manager.network source_port = client.find_port(parsed_args.port)['id'] tap_service_id = client._find(tap_service.TapService, parsed_args.tap_service)['id'] project_id = identity_utils.find_project( obj = client._create(TapFlow, **attrs) identity_utils.add_project_owner_option_to_parser(parser) client = self.app.client_manager.network project_id = identity_utils.find_project( objs = client._list(TapFlow, retrieve_all=True, params=params) client = self.app.client_manager.network id = client._find(TapFlow, parsed_args.tap_flow) obj = client._get(TapFlow, id) client = self.app.client_manager.network id = client._find(TapFlow, id_or_name)['id'] client._delete(TapFlow, id) client = self.app.client_manager.network original_t_f = client._find(TapFlow, parsed_args.tap_flow) obj = client._update(TapFlow, original_t_f, **attrs)","from neutronclient._i18n import _ from neutronclient.common import utils from neutronclient.osc import utils as nc_osc_utilspath = 'taas' object_path = '/%s/' % path resource_path = '/%s/%%s/%%s' % path nc_osc_utils.add_project_owner_option_to_parser(parser) type=utils.convert_to_uppercase, client = self.app.client_manager.neutronclient source_port = client.find_resource('port', parsed_args.port)['id'] tap_service_id = client.find_resource( 'tap_service', parsed_args.tap_service)['id'] project_id = nc_osc_utils.find_project( body = {TAP_FLOW: attrs} obj = client.post('%s%s' % (object_path, TAP_FLOWS), body=body)[TAP_FLOW] nc_osc_utils.add_project_owner_option_to_parser(parser) client = self.app.client_manager.neutronclient project_id = nc_osc_utils.find_project( objs = client.list(TAP_FLOWS, '%s%s' % (object_path, TAP_FLOWS), retrieve_all=True, params=params)[TAP_FLOWS] client = self.app.client_manager.neutronclient id = client.find_resource(TAP_FLOW, parsed_args.tap_flow)['id'] obj = client.get(resource_path % (TAP_FLOWS, id))[TAP_FLOW] client = self.app.client_manager.neutronclient id = client.find_resource(TAP_FLOW, id_or_name)['id'] client.delete(resource_path % (TAP_FLOWS, id)) client = self.app.client_manager.neutronclient id = client.find_resource(TAP_FLOW, parsed_args.tap_flow)['id'] body = {TAP_FLOW: attrs} obj = client.put(resource_path % (TAP_FLOWS, id), body)[TAP_FLOW]",171,102
openstack%2Fcloudkitty~master~I0dfef93c603524b732e6b2694d9c8877826b5ddc,openstack/cloudkitty,master,I0dfef93c603524b732e6b2694d9c8877826b5ddc,Remove `state` field from API,MERGED,2023-03-15 17:39:48.000000000,2023-04-17 15:26:07.000000000,2023-04-17 15:25:03.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25277}]","[{'number': 1, 'created': '2023-03-15 17:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ae56df57b7bd0a85fed85ab792564a4b45fd6de6', 'message': 'Remove `state` field from API\n\nFollowing the patch [1], this patchset executes the removal of the state field from the API.\n\n[1] https://review.opendev.org/c/openstack/cloudkitty/+/774634\n\nChange-Id: I0dfef93c603524b732e6b2694d9c8877826b5ddc\n'}, {'number': 2, 'created': '2023-04-03 13:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/c0d237c4d7cad83531cc331dd1be917a8e048bcc', 'message': 'Remove `state` field from API\n\nFollowing the patch [1], this patchset executes the removal of the state\nfield from the API.\n\n[1] https://review.opendev.org/c/openstack/cloudkitty/+/774634\n\nChange-Id: I0dfef93c603524b732e6b2694d9c8877826b5ddc\n'}, {'number': 3, 'created': '2023-04-03 13:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/c7611ee009f4f68ca3d3bcf5cbe2edc1e4c4be72', 'message': 'Remove `state` field from API\n\nFollowing the patch [1], this patchset executes the removal of the state\nfield from the API.\n\n[1] https://review.opendev.org/c/openstack/cloudkitty/+/774634\n\nChange-Id: I0dfef93c603524b732e6b2694d9c8877826b5ddc\n'}, {'number': 4, 'created': '2023-04-03 14:36:30.000000000', 'files': ['cloudkitty/tests/gabbi/gabbits/v2-scope-state.yaml', 'cloudkitty/api/v2/scope/state.py', 'releasenotes/notes/remove-state-attribute-scope-28e48ae4ada5208d.yaml'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/980d7871c12fefd6229ddba1843b2d037d46c6f9', 'message': 'Remove `state` field from API\n\nFollowing the patch [1], this patchset executes the removal of the state\nfield from the API.\n\n[1] https://review.opendev.org/c/openstack/cloudkitty/+/774634\n\nChange-Id: I0dfef93c603524b732e6b2694d9c8877826b5ddc\n'}]",12,877537,980d7871c12fefd6229ddba1843b2d037d46c6f9,23,3,4,28356,,,0,"Remove `state` field from API

Following the patch [1], this patchset executes the removal of the state
field from the API.

[1] https://review.opendev.org/c/openstack/cloudkitty/+/774634

Change-Id: I0dfef93c603524b732e6b2694d9c8877826b5ddc
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/37/877537/3 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/tests/gabbi/gabbits/v2-scope-state.yaml', 'cloudkitty/api/v2/scope/state.py']",2,ae56df57b7bd0a85fed85ab792564a4b45fd6de6,remove_state_field_storage_scope," last_processed_timestamp=None): if not last_processed_timestamp: ""Variables 'last_processed_timestamp' cannot be empty/None."") if update_storage_scope.last_processed_timestamp:"," # This ""state"" property should be removed in the next release. voluptuous.Optional('state'): vutils.get_string_type(), 'state': r.last_processed_timestamp.isoformat(), # This ""state"" property should be removed in the next release. voluptuous.Optional('state'): voluptuous.Coerce(tzutils.dt_from_iso), last_processed_timestamp=None, state=None): if not state and not last_processed_timestamp: ""Variables 'state' and 'last_processed_timestamp' cannot be "" ""empty/None. We expect at least one of them."") if state: LOG.warning(""The use of 'state' variable is deprecated, and will "" ""be removed in the next upcomming release. You should "" ""consider using 'last_processed_timestamp' variable."") if not last_processed_timestamp: last_processed_timestamp = state # This ""state"" property should be removed in the next release. voluptuous.Required('state'): vutils.get_string_type(), 'state': update_storage_scope.state.isoformat(), # This ""state"" property should be removed in the next release. voluptuous.Required('state'): vutils.get_string_type(), if update_storage_scope.last_processed_timestamp.isoformat(): 'state': last_processed_timestamp,",9,29
openstack%2Fkayobe~stable%2Fyoga~I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,openstack/kayobe,stable/yoga,I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,Fix kayobe_config_path description in globals.yml,MERGED,2023-04-13 21:00:41.000000000,2023-04-17 15:16:40.000000000,2023-04-17 15:15:33.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 21:00:41.000000000', 'files': ['etc/kayobe/globals.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/eb30965c676e8ee821db8749b504f88515298979', 'message': ""Fix kayobe_config_path description in globals.yml\n\nThis change fixes the description accidently copied from the\n'kayobe_env_config_path' description.\n\nTrivialFix\n\nChange-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)\n""}]",0,880366,eb30965c676e8ee821db8749b504f88515298979,7,2,1,14200,,,0,"Fix kayobe_config_path description in globals.yml

This change fixes the description accidently copied from the
'kayobe_env_config_path' description.

TrivialFix

Change-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/66/880366/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/globals.yml'],1,eb30965c676e8ee821db8749b504f88515298979,fix-globals-description,# Path to Kayobe configuration directory on Ansible control host.,"# Path to Kayobe configuration directory on Ansible control host, with an # environment path appended if kayobe_environment is set.",1,2
openstack%2Fnetworking-bagpipe~master~I21e1d5f1e446afffaba6002f277a2990f934de29,openstack/networking-bagpipe,master,I21e1d5f1e446afffaba6002f277a2990f934de29,"Implement ""brctl"" and ""bridge"" using oslo.privsep",MERGED,2020-07-01 15:44:06.000000000,2023-04-17 15:14:08.000000000,2023-04-17 15:13:06.000000000,"[{'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-07-01 15:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/2c7ab9f5ae45935e05e739e41adda2d479f1c548', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 2, 'created': '2020-10-12 09:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/b8a89c99f71237ec85e2eed7b5e31b8a58c5cebd', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 3, 'created': '2020-10-13 09:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/b8af628bb1d7809b3ab9ecfbf0d62fb3115296f5', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 4, 'created': '2020-12-01 18:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/f5d05bd17f10660148f122eafd8fe68f0b7e7a26', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 5, 'created': '2021-03-10 07:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/3e0811c97d186c848aea532ed0e22d7dbd5e6c14', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 6, 'created': '2021-03-10 07:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/88235621757157e38cf7a2bad654e6ecfdf2ef01', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}, {'number': 7, 'created': '2023-03-29 16:25:57.000000000', 'files': ['etc/bagpipe-bgp/rootwrap.d/linux-vxlan.filters', 'networking_bagpipe/tests/unit/privileged/test_privileged_utils.py', 'networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/privileged/privileged_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/1e571c14ea6a9e03e6ed91af7594022457a2c2cb', 'message': 'Implement ""brctl"" and ""bridge"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""\ncommands and replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40260\nChange-Id: I21e1d5f1e446afffaba6002f277a2990f934de29\n'}]",10,738872,1e571c14ea6a9e03e6ed91af7594022457a2c2cb,24,4,7,8313,,,0,"Implement ""brctl"" and ""bridge"" using oslo.privsep

Remove the use of oslo.rootwrap when executing ""brctl"" and ""bridge""
commands and replace them with oslo.privsep.

Story: #2007686
Task: #40260
Change-Id: I21e1d5f1e446afffaba6002f277a2990f934de29
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/72/738872/5 && git format-patch -1 --stdout FETCH_HEAD,"['etc/bagpipe-bgp/rootwrap.d/linux-vxlan.filters', 'networking_bagpipe/tests/unit/privileged/test_privileged_utils.py', 'networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/privileged/privileged_utils.py']",4,2c7ab9f5ae45935e05e739e41adda2d479f1c548,privsep," @privileged.default_cmd.entrypoint def brctl(params, check_exit=True): """"""run brctl command :param params: parameters for brctl :param check_exit: boolean or list of allowed exit codes, see https://opendev.org/openstack/oslo.concurrency/src/ branch/master/oslo_concurrency/processutils.py#L207 :return: tupple of stdout, stderr """""" cmd = ['brctl'] + params.split() res = processutils.execute(*cmd, check_exit_code=check_exit, run_as_root=True) return res @privileged.default_cmd.entrypoint def bridge(params): """"""Run bridge command :param params: parameters for bridge """""" cmd = ['bridge'] + params.split() processutils.execute(*cmd, run_as_root=True)",,101,59
openstack%2Fplacement~master~Ia916e050f8aa790a787efea5f9c9f295c8d7558f,openstack/placement,master,Ia916e050f8aa790a787efea5f9c9f295c8d7558f,Move implemented specs for Xena and Yoga release,MERGED,2022-08-19 00:08:50.000000000,2023-04-17 15:12:32.000000000,2023-04-17 15:11:30.000000000,"[{'_account_id': 7166}, {'_account_id': 15334}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-08-19 00:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/722fd72b09826c9f30b00f9ef0b172b1878fda71', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}, {'number': 2, 'created': '2022-09-19 01:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/9a307b34a2fec3acbc5c0ac0248a57d30017a359', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}, {'number': 3, 'created': '2022-10-09 00:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/75a7285b58e12391b6c92f2cdf7f4fe5617202c0', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}, {'number': 4, 'created': '2022-12-03 01:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/4f1ba6d9cbe80c53f66b2f049b75f70380a2ad95', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}, {'number': 5, 'created': '2023-02-21 18:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/cd9b48b62425c21c4b02a4cfd181cc24554a13bb', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}, {'number': 6, 'created': '2023-03-26 09:43:24.000000000', 'files': ['doc/source/specs/xena/implemented/support-consumer-types.rst', 'doc/source/specs/index.rst', 'doc/source/specs/yoga/implemented/2005346-any-traits-in-allocation_candidates-query.rst', 'doc/source/specs/yoga/implemented/2005345-placement-mixing-required-traits-with-any-traits.rst', 'doc/source/specs/xena/implemented/allow-provider-re-parenting.rst'], 'web_link': 'https://opendev.org/openstack/placement/commit/ed6e84aad71650cb764fdeb1dcc1b3bd59c1aa54', 'message': ""Move implemented specs for Xena and Yoga release\n\nMove implemented specs from 'in progress' to 'implemented'.\n\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\nChange-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f\n""}]",0,853730,ed6e84aad71650cb764fdeb1dcc1b3bd59c1aa54,20,5,6,7634,,,0,"Move implemented specs for Xena and Yoga release

Move implemented specs from 'in progress' to 'implemented'.

Signed-off-by: Takashi Natsume <takanattie@gmail.com>
Change-Id: Ia916e050f8aa790a787efea5f9c9f295c8d7558f
",git fetch https://review.opendev.org/openstack/placement refs/changes/30/853730/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/xena/implemented/support-consumer-types.rst', 'doc/source/specs/index.rst', 'doc/source/specs/yoga/implemented/2005346-any-traits-in-allocation_candidates-query.rst', 'doc/source/specs/yoga/implemented/2005345-placement-mixing-required-traits-with-any-traits.rst', 'doc/source/specs/xena/implemented/allow-provider-re-parenting.rst']",5,722fd72b09826c9f30b00f9ef0b172b1878fda71,move_implemented_specs,,,8,10
openstack%2Fkayobe~stable%2Fzed~I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,openstack/kayobe,stable/zed,I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e,Fix kayobe_config_path description in globals.yml,MERGED,2023-04-13 21:00:22.000000000,2023-04-17 15:11:48.000000000,2023-04-17 15:10:33.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 21:00:22.000000000', 'files': ['etc/kayobe/globals.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/dc142067cb89efb7a653389ef64e66ee41da5c35', 'message': ""Fix kayobe_config_path description in globals.yml\n\nThis change fixes the description accidently copied from the\n'kayobe_env_config_path' description.\n\nTrivialFix\n\nChange-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)\n""}]",0,880365,dc142067cb89efb7a653389ef64e66ee41da5c35,7,2,1,14200,,,0,"Fix kayobe_config_path description in globals.yml

This change fixes the description accidently copied from the
'kayobe_env_config_path' description.

TrivialFix

Change-Id: I7b9ced54ad886b3f92f7c757adc2efafa4cbfa4e
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 2ab498f955c87f0f92651600be45d7dda9264af4)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/65/880365/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/globals.yml'],1,dc142067cb89efb7a653389ef64e66ee41da5c35,fix-globals-description,# Path to Kayobe configuration directory on Ansible control host.,"# Path to Kayobe configuration directory on Ansible control host, with an # environment path appended if kayobe_environment is set.",1,2
openstack%2Fkayobe~master~Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3,openstack/kayobe,master,Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3,Build Ubuntu images with IPA when on Ubuntu,MERGED,2023-01-16 10:19:55.000000000,2023-04-17 15:11:31.000000000,2023-04-17 15:10:29.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-01-16 10:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2724171765ea800944b19f22c3cf95125675813b', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release``by default. This allows for Ubuntu images to be built when\nrunning on Ubuntu.\n\nRocky will still build CentOS images.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 2, 'created': '2023-01-16 10:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/8f9fc0ad0854aa60a932e5c34abcd6d0c060f526', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release``by default. This allows for Ubuntu images to be built when\nrunning on Ubuntu.\n\nRocky will still build CentOS images, as they still need to be tested\nbeing built with IPA.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 3, 'created': '2023-01-16 11:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/940d984be7e6bb8f4fde9cd39e41cd3fe2c56925', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 4, 'created': '2023-01-16 12:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/be007c42afe0d40a006c56715292af34f8c51221', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 5, 'created': '2023-01-16 13:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/fb92b7bc396217cdeab3bfac9c08490cf1f99845', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 6, 'created': '2023-03-30 14:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/ca7e215cc0ef99fd906c28c2f9c90a91bac97d07', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 7, 'created': '2023-03-30 19:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/de9f7eb80b7f6056e7fe8ba7299a824616698dd2', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 8, 'created': '2023-03-31 08:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/2ada117d7ced8d6d53328ed003748a056f3c3aec', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 9, 'created': '2023-04-03 08:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/38fcd8b058dccabf79a46c9bb3afe9168d541395', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 10, 'created': '2023-04-03 08:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/9b46dba5ef06c9c041beec0ca042a09321cdddec', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 11, 'created': '2023-04-03 09:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/373d4e01dab598cdfd3b268fc4bbc1a80b4bd155', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 12, 'created': '2023-04-17 04:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/50487d5d11ddc904d057be7e5c3e3e3f7d393295', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 13, 'created': '2023-04-17 07:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/41f87b29a461f4e615752f94b7d0f29858c6b6cd', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}, {'number': 14, 'created': '2023-04-17 10:21:18.000000000', 'files': ['releasenotes/notes/build-ubuntu-ipa-images-when-on-ubuntu-5dfcdfdb673343ea.yaml', 'ansible/inventory/group_vars/all/ipa', 'playbooks/kayobe-seed-base/overrides.yml.j2'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bdaeed184bf41163b9b410995ad021cee93fb39b', 'message': 'Build Ubuntu images with IPA when on Ubuntu\n\nChange ``ipa_build_dib_elements_default`` and\n``ipa_build_dib_env_default`` to use ``os_distribution`` and\n``os_release`` by default. This allows for Ubuntu images to be built\nwhen running on Ubuntu.\n\nRocky will still build CentOS images, as Rocky IPA images have not been\ntested yet.\n\nChange-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3\n'}]",26,870522,bdaeed184bf41163b9b410995ad021cee93fb39b,60,4,14,35263,,,0,"Build Ubuntu images with IPA when on Ubuntu

Change ``ipa_build_dib_elements_default`` and
``ipa_build_dib_env_default`` to use ``os_distribution`` and
``os_release`` by default. This allows for Ubuntu images to be built
when running on Ubuntu.

Rocky will still build CentOS images, as Rocky IPA images have not been
tested yet.

Change-Id: Iefd2d0b7a3a3e07f5c112d58e2ec0b3da0a747d3
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/22/870522/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/inventory/group_vars/all/ipa'],1,2724171765ea800944b19f22c3cf95125675813b,," - ""{{ 'centos' if os_distribution == 'rocky' else os_distribution }}"" DIB_RELEASE: ""{{ '9-stream' if os_distribution == 'rocky' else os_release }}"""," # TODO(mgoddard): Use {{ os_distribution }} here when Ubuntu IPA builds work. - centos # TODO(mgoddard): Use {{ os_release }} here when we use os_distribution # above. DIB_RELEASE: ""9-stream""",2,5
openstack%2Fkolla~stable%2Fwallaby~If0f9b4dd058a257d0653332d1b663e150c717304,openstack/kolla,stable/wallaby,If0f9b4dd058a257d0653332d1b663e150c717304,Fix test malicious tarball fail,MERGED,2023-04-13 06:43:56.000000000,2023-04-17 15:09:02.000000000,2023-04-17 15:08:06.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-13 06:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cdd3aa4b6c2b922b3b6fbcc6f156c7bbfe53136a', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 2, 'created': '2023-04-13 06:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/15b5148cb61df94d24d794081ca66b107b6597bf', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 3, 'created': '2023-04-13 06:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/247ab30a077d139c943d2ef191b4bbde0d2599cb', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 4, 'created': '2023-04-13 06:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/25157b1bca39f55b0d0ea73c51e83e4e751a5995', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 5, 'created': '2023-04-13 06:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c84aff1c83de6ed0408b06821e1b03b30e54bd0c', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 6, 'created': '2023-04-13 08:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/38981b8240eaef9ea9ef10337664aaf98b34f44b', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 7, 'created': '2023-04-13 09:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/15765402700cdb6fd99b7954c9c040f408e313a0', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}, {'number': 8, 'created': '2023-04-13 10:43:02.000000000', 'files': ['kolla/image/build.py', 'kolla/tests/test_build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/779aa83f4448df2ad4db7309cca496301b777ff8', 'message': ""Fix test malicious tarball fail\n\nSince I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails\non plugins with an exception: 'tarfile.ReadError: not a gzip file'\nbecause the test checks only gzip compressed archives but plugins\ncreated as plain tar files. This change fixes the issue using\ntransparent compression support and also adds some debug info.\n\nCloses-Bug: #1990432\nChange-Id: If0f9b4dd058a257d0653332d1b663e150c717304\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\nCo-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>\n(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)\n(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)\n""}]",6,880186,779aa83f4448df2ad4db7309cca496301b777ff8,22,4,8,22629,,,0,"Fix test malicious tarball fail

Since I650fcbc8f773fad8116338f6fb0cf7b4f4f17b33 builds from git fails
on plugins with an exception: 'tarfile.ReadError: not a gzip file'
because the test checks only gzip compressed archives but plugins
created as plain tar files. This change fixes the issue using
transparent compression support and also adds some debug info.

Closes-Bug: #1990432
Change-Id: If0f9b4dd058a257d0653332d1b663e150c717304
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
Co-Authored-by: Michal Nasiadka <mnasiadka@gmail.com>
(cherry picked from commit 143765fb67221cc51f1dc56a41ac2b67dddc453f)
(cherry picked from commit 5da2ff0828c7376a2f16a2673cd03420da038bca)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/86/880186/8 && git format-patch -1 --stdout FETCH_HEAD,"['kolla/image/build.py', 'kolla/tests/test_build.py']",2,cdd3aa4b6c2b922b3b6fbcc6f156c7bbfe53136a,test-malicious-tarball-stable/wallaby,"<<<<<<< HEAD (e9f0a9 Merge ""CI: Retry docker push on publish jobs"" into stable/wa) ======= @mock.patch.dict(os.environ, clear=True) @mock.patch('docker.APIClient') def test_local_directory(self, mock_client): tmpdir = tempfile.mkdtemp() file_name = 'test.txt' file_path = os.path.join(tmpdir, file_name) saved_umask = os.umask(0o077) try: with open(file_path, 'w') as f: f.write('Hello') self.dc = mock_client self.image.plugins = [{ 'name': 'fake-image-base-plugin-test', 'type': 'local', 'enabled': True, 'source': tmpdir} ] push_queue = mock.Mock() builder = build.BuildTask(self.conf, self.image, push_queue) builder.run() self.assertTrue(builder.success) except IOError: print('IOError') else: os.remove(file_path) finally: os.umask(saved_umask) os.rmdir(tmpdir) @mock.patch.dict(os.environ, clear=True) @mock.patch('docker.APIClient') def test_malicious_tar(self, mock_client): tmpdir = tempfile.mkdtemp() file_name = 'test.txt' archive_name = 'my_archive.tar' file_path = os.path.join(tmpdir, file_name) archive_path = os.path.join(tmpdir, archive_name) # Ensure the file is read/write by the creator only saved_umask = os.umask(0o077) try: with open(file_path, 'w') as f: f.write('Hello') with tarfile.open(archive_path, 'w') as tar: tar.add(file_path, arcname='../test.txt') self.dc = mock_client self.image.plugins = [{ 'name': 'fake-image-base-plugin-test', 'type': 'local', 'enabled': True, 'source': archive_path} ] push_queue = mock.Mock() builder = build.BuildTask(self.conf, self.image, push_queue) builder.run() self.assertFalse(builder.success) except IOError: print('IOError') else: os.remove(file_path) os.remove(archive_path) finally: os.umask(saved_umask) os.rmdir(tmpdir) @mock.patch.dict(os.environ, clear=True) @mock.patch('docker.APIClient') def test_malicious_tar_gz(self, mock_client): tmpdir = tempfile.mkdtemp() file_name = 'test.txt' archive_name = 'my_archive.tar.gz' file_path = os.path.join(tmpdir, file_name) archive_path = os.path.join(tmpdir, archive_name) # Ensure the file is read/write by the creator only saved_umask = os.umask(0o077) try: with open(file_path, 'w') as f: f.write('Hello') with tarfile.open(archive_path, 'w:gz') as tar: tar.add(file_path, arcname='../test.txt') self.dc = mock_client self.image.plugins = [{ 'name': 'fake-image-base-plugin-test', 'type': 'local', 'enabled': True, 'source': archive_path} ] push_queue = mock.Mock() builder = build.BuildTask(self.conf, self.image, push_queue) builder.run() self.assertFalse(builder.success) except IOError: print('IOError') else: os.remove(file_path) os.remove(archive_path) finally: os.umask(saved_umask) os.rmdir(tmpdir) >>>>>>> CHANGE (5da2ff Fix test malicious tarball fail)",,126,0
openstack%2Fcloudkitty~master~I51e50d1b4f7d5fbe7dcbda7ddcc8b8453eb5c439,openstack/cloudkitty,master,I51e50d1b4f7d5fbe7dcbda7ddcc8b8453eb5c439,Improve reprocessing task documentation,MERGED,2023-03-15 16:32:46.000000000,2023-04-17 15:08:14.000000000,2023-04-17 15:07:11.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25277}]","[{'number': 1, 'created': '2023-03-15 16:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/fc28dfab5aa6437f62a03a5552344204916e8fd5', 'message': 'Improve reprocessing task documentation\n\nChange-Id: I51e50d1b4f7d5fbe7dcbda7ddcc8b8453eb5c439\n'}, {'number': 2, 'created': '2023-04-03 13:29:10.000000000', 'files': ['api-ref/source/v2/task/reprocessing_parameters.yml', 'api-ref/source/v2/task/reprocessing.inc'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/60d91d8ce4b24bc06d9ff05cdfdd86b15df7a884', 'message': 'Improve reprocessing task documentation\n\nChange-Id: I51e50d1b4f7d5fbe7dcbda7ddcc8b8453eb5c439\n'}]",2,877525,60d91d8ce4b24bc06d9ff05cdfdd86b15df7a884,14,3,2,28356,,,0,"Improve reprocessing task documentation

Change-Id: I51e50d1b4f7d5fbe7dcbda7ddcc8b8453eb5c439
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/25/877525/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v2/task/reprocessing_parameters.yml', 'api-ref/source/v2/task/reprocessing.inc']",2,fc28dfab5aa6437f62a03a5552344204916e8fd5,fix_cloudkitty_documentation_reprocessing_api, - order: scope_ids_order_query,,10,0
openstack%2Fnetworking-bgpvpn~master~I043c657052c9fa43fcef4636362477d16551c337,openstack/networking-bgpvpn,master,I043c657052c9fa43fcef4636362477d16551c337,CI: add oslo_master and sqlalchemy to periodic weekly,MERGED,2022-10-20 09:50:20.000000000,2023-04-17 15:06:38.000000000,2023-04-17 15:04:30.000000000,"[{'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2022-10-20 09:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/f1aee99c5ebfc842849f97b38c57d0ab63154ca7', 'message': 'CI: add oslo_master to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\n\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 2, 'created': '2023-01-30 13:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/66cfc03c75e2fb35dee822ba7cebaaa396cd32f9', 'message': 'CI: add oslo_master to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\n\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 3, 'created': '2023-02-01 13:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/fcb819db1e1f01db71b5b80ca46861b7b4c74561', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 4, 'created': '2023-02-02 10:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/417edfc97251e058a5f8ddfb8a5d67af909fc9f3', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 5, 'created': '2023-02-02 10:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/db4b226f14897f4cfa471d512f6c4c7cc1746f72', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 6, 'created': '2023-02-03 05:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/ee31b62f9c648eb1c74ab0deee83dde30993f387', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 7, 'created': '2023-02-03 05:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/af7f1df7f5d5e3e06c6224b892e63a9c46b23eba', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 8, 'created': '2023-02-14 16:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/5f958ac634140df5d1f2be9d9da4467111d18bf2', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 9, 'created': '2023-02-21 13:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/5ba90e349fb8da6af7b3b027b4c5624ece747e3d', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 10, 'created': '2023-04-03 13:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/9d25d66739c38fd355b05258d19f60cb291c4ca1', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}, {'number': 11, 'created': '2023-04-12 12:12:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/ce690c88031232f21a558142183b17d2ef8fa509', 'message': 'CI: add oslo_master and sqlalchemy to periodic weekly\n\nAdd openstack-tox-py39-with-oslo-master to periodic weekly and as an\nextra simplify the required projects with anchor.\nAdd openstack-tox-py310-with-sqlalchemy-master job to weekly queue.\nChange previous jobs in the periodic to py310\n\nRelated-Bug: #2004265\nChange-Id: I043c657052c9fa43fcef4636362477d16551c337\n'}]",14,861960,ce690c88031232f21a558142183b17d2ef8fa509,47,4,11,8313,,,0,"CI: add oslo_master and sqlalchemy to periodic weekly

Add openstack-tox-py39-with-oslo-master to periodic weekly and as an
extra simplify the required projects with anchor.
Add openstack-tox-py310-with-sqlalchemy-master job to weekly queue.
Change previous jobs in the periodic to py310

Related-Bug: #2004265
Change-Id: I043c657052c9fa43fcef4636362477d16551c337
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/60/861960/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f1aee99c5ebfc842849f97b38c57d0ab63154ca7,oslo_master_periodic, required-projects: &bgpvpn_required_projects required-projects: *bgpvpn_required_projects required-projects: *bgpvpn_required_projects - horizon-tox-python3-django32: required-projects: *bgpvpn_required_projects required-projects: *bgpvpn_required_projects - openstack-tox-py39: required-projects: *bgpvpn_required_projects required-projects: *bgpvpn_required_projects - openstack-tox-py39-with-oslo-master: required-projects: *bgpvpn_required_projects, required-projects: required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon - horizon-tox-python3-django32: required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon - openstack-tox-py39: required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon required-projects: - openstack/neutron - openstack/networking-bagpipe - openstack/horizon,9,25
openstack%2Fcharm-horizon-k8s~main~I85220ebd6b60676c6f6f22cf6ee72fbcac2b965e,openstack/charm-horizon-k8s,main,I85220ebd6b60676c6f6f22cf6ee72fbcac2b965e,Fix rust crypto build failure,ABANDONED,2023-04-13 17:41:52.000000000,2023-04-17 15:06:30.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 17:41:52.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/0d53d3e613bfa24df6be2972a64a2b6cc2323d28', 'message': 'Fix rust crypto build failure\n\nBuild fails because the Rust compiler cannot find the libssl-dev package\nlocation, fixed by adding pkg-config.\n\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I85220ebd6b60676c6f6f22cf6ee72fbcac2b965e\n'}]",0,880352,0d53d3e613bfa24df6be2972a64a2b6cc2323d28,4,2,1,35761,,,0,"Fix rust crypto build failure

Build fails because the Rust compiler cannot find the libssl-dev package
location, fixed by adding pkg-config.

Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
Change-Id: I85220ebd6b60676c6f6f22cf6ee72fbcac2b965e
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/52/880352/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,0d53d3e613bfa24df6be2972a64a2b6cc2323d28,build-rust-crypto, - pkg-config,,1,0
openstack%2Fcharm-glance-k8s~main~Id53ee16ccd5dd61e5a5a55f10b6c182ce12fb39d,openstack/charm-glance-k8s,main,Id53ee16ccd5dd61e5a5a55f10b6c182ce12fb39d,Fix rust crypto build failure,ABANDONED,2023-04-13 17:35:53.000000000,2023-04-17 15:06:24.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 17:35:53.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/98bd24c599822a77cc8433d543f6d55e35d027f5', 'message': 'Fix rust crypto build failure\n\nBuild fails because the Rust compiler cannot find the libssl-dev package\nlocation, fixed by adding pkg-config.\n\nChange-Id: Id53ee16ccd5dd61e5a5a55f10b6c182ce12fb39d\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880348,98bd24c599822a77cc8433d543f6d55e35d027f5,3,1,1,35761,,,0,"Fix rust crypto build failure

Build fails because the Rust compiler cannot find the libssl-dev package
location, fixed by adding pkg-config.

Change-Id: Id53ee16ccd5dd61e5a5a55f10b6c182ce12fb39d
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-glance-k8s refs/changes/48/880348/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,98bd24c599822a77cc8433d543f6d55e35d027f5,build-rust-crypto, - pkg-config,,1,0
openstack%2Fcharm-placement-k8s~main~I353538353353863b3561ab2cf82426dae8cac09c,openstack/charm-placement-k8s,main,I353538353353863b3561ab2cf82426dae8cac09c,Fix rust crypto build failure,ABANDONED,2023-04-13 17:40:08.000000000,2023-04-17 15:06:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 17:40:08.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-placement-k8s/commit/e8c2729f3662d3737847e4e1ec9b980ed95411d1', 'message': 'Fix rust crypto build failure\n\nBuild fails because the Rust compiler cannot find the libssl-dev package\nlocation, fixed by adding pkg-config.\n\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I353538353353863b3561ab2cf82426dae8cac09c\n'}]",0,880351,e8c2729f3662d3737847e4e1ec9b980ed95411d1,3,1,1,35761,,,0,"Fix rust crypto build failure

Build fails because the Rust compiler cannot find the libssl-dev package
location, fixed by adding pkg-config.

Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
Change-Id: I353538353353863b3561ab2cf82426dae8cac09c
",git fetch https://review.opendev.org/openstack/charm-placement-k8s refs/changes/51/880351/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,e8c2729f3662d3737847e4e1ec9b980ed95411d1,build-rust-crypto, - pkg-config,parts:,1,1
openstack%2Fcharm-neutron-k8s~main~I77bf31023d82ae0131872cf94b9286ba3eccba97,openstack/charm-neutron-k8s,main,I77bf31023d82ae0131872cf94b9286ba3eccba97,Fix rust crypto build failure,ABANDONED,2023-04-13 17:37:27.000000000,2023-04-17 15:06:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 17:37:27.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/e89252e4831657dae0b4356b449d50e98f3d51a3', 'message': 'Fix rust crypto build failure\n\nBuild fails because the Rust compiler cannot find the libssl-dev package\nlocation, fixed by adding pkg-config.\n\nChange-Id: I77bf31023d82ae0131872cf94b9286ba3eccba97\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880349,e89252e4831657dae0b4356b449d50e98f3d51a3,3,1,1,35761,,,0,"Fix rust crypto build failure

Build fails because the Rust compiler cannot find the libssl-dev package
location, fixed by adding pkg-config.

Change-Id: I77bf31023d82ae0131872cf94b9286ba3eccba97
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-neutron-k8s refs/changes/49/880349/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,e89252e4831657dae0b4356b449d50e98f3d51a3,build-rust-crypto, - pkg-config,,1,0
openstack%2Fcharm-cinder-k8s~main~I8e51d65544de946ff166909f0a7d8788d3424a8a,openstack/charm-cinder-k8s,main,I8e51d65544de946ff166909f0a7d8788d3424a8a,Fix rust crypto build failure,ABANDONED,2023-04-13 17:39:10.000000000,2023-04-17 15:05:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 17:39:10.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-k8s/commit/15e2f2ce82c4fc1ca4af554227ce61ef32f6d784', 'message': 'Fix rust crypto build failure\n\nBuild fails because the Rust compiler cannot find the libssl-dev package\nlocation, fixed by adding pkg-config.\n\nChange-Id: I8e51d65544de946ff166909f0a7d8788d3424a8a\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880350,15e2f2ce82c4fc1ca4af554227ce61ef32f6d784,3,1,1,35761,,,0,"Fix rust crypto build failure

Build fails because the Rust compiler cannot find the libssl-dev package
location, fixed by adding pkg-config.

Change-Id: I8e51d65544de946ff166909f0a7d8788d3424a8a
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-cinder-k8s refs/changes/50/880350/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,15e2f2ce82c4fc1ca4af554227ce61ef32f6d784,build-rust-crypto, - pkg-config,,1,0
openstack%2Fkayobe~stable%2Fyoga~I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,openstack/kayobe,stable/yoga,I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,Fix passwords.yml generation when parent directory doesn't exist,MERGED,2023-04-14 07:39:05.000000000,2023-04-17 15:03:48.000000000,2023-04-17 15:02:36.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 07:39:05.000000000', 'files': ['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bbcd462dffebab377363f0f8b5ed00651a94517b', 'message': ""Fix passwords.yml generation when parent directory doesn't exist\n\nFixes an issue where generation of passwords.yml for Kolla Ansible\ncould fail if the directory containing the file does not exist. This is\ntypical in a multiple environment setup, when creating a new\nenvironment.\n\nStory: 2010293\nTask: 46275\nCloses-Bug: #2015093\nChange-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d\n(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)\n""}]",0,880388,bbcd462dffebab377363f0f8b5ed00651a94517b,9,4,1,22629,,,0,"Fix passwords.yml generation when parent directory doesn't exist

Fixes an issue where generation of passwords.yml for Kolla Ansible
could fail if the directory containing the file does not exist. This is
typical in a multiple environment setup, when creating a new
environment.

Story: 2010293
Task: 46275
Closes-Bug: #2015093
Change-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d
(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/88/880388/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml']",2,bbcd462dffebab377363f0f8b5ed00651a94517b,,"--- fixes: - | Fixes an issue where generation of ``passwords.yml`` for Kolla Ansible could fail if the directory containing the file does not exist. This is typical in a multiple environment setup, when creating a new environment. See `story 2010293 <https://storyboard.openstack.org/#!/story/2010293>`_ for details. ",,11,0
openstack%2Fkayobe~stable%2Fxena~I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,openstack/kayobe,stable/xena,I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,Fix passwords.yml generation when parent directory doesn't exist,MERGED,2023-04-14 07:39:21.000000000,2023-04-17 15:03:44.000000000,2023-04-17 15:02:42.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 07:39:21.000000000', 'files': ['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/608795e912a29931aa3056bb64b142b5aa05d416', 'message': ""Fix passwords.yml generation when parent directory doesn't exist\n\nFixes an issue where generation of passwords.yml for Kolla Ansible\ncould fail if the directory containing the file does not exist. This is\ntypical in a multiple environment setup, when creating a new\nenvironment.\n\nStory: 2010293\nTask: 46275\nCloses-Bug: #2015093\nChange-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d\n(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)\n""}]",0,880389,608795e912a29931aa3056bb64b142b5aa05d416,9,4,1,22629,,,0,"Fix passwords.yml generation when parent directory doesn't exist

Fixes an issue where generation of passwords.yml for Kolla Ansible
could fail if the directory containing the file does not exist. This is
typical in a multiple environment setup, when creating a new
environment.

Story: 2010293
Task: 46275
Closes-Bug: #2015093
Change-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d
(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/89/880389/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml']",2,608795e912a29931aa3056bb64b142b5aa05d416,,"--- fixes: - | Fixes an issue where generation of ``passwords.yml`` for Kolla Ansible could fail if the directory containing the file does not exist. This is typical in a multiple environment setup, when creating a new environment. See `story 2010293 <https://storyboard.openstack.org/#!/story/2010293>`_ for details. ",,11,0
openstack%2Fplacement~stable%2Fyoga~I5af1b65c1f47ca3c36e19905a9a5417faf8739a1,openstack/placement,stable/yoga,I5af1b65c1f47ca3c36e19905a9a5417faf8739a1,chore: back-merge os-traits version update to placement in stable/yoga to support owner traits,ABANDONED,2023-04-12 23:14:03.000000000,2023-04-17 14:59:49.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 33330}]","[{'number': 1, 'created': '2023-04-12 23:14:03.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/placement/commit/36b6211e93c62e25d17718dc986d04ba229a3f06', 'message': 'chore: back-merge os-traits version update to placement in stable/yoga to support owner traits\n\nChange-Id: I5af1b65c1f47ca3c36e19905a9a5417faf8739a1\n'}]",2,880249,36b6211e93c62e25d17718dc986d04ba229a3f06,5,3,1,33330,,,0,"chore: back-merge os-traits version update to placement in stable/yoga to support owner traits

Change-Id: I5af1b65c1f47ca3c36e19905a9a5417faf8739a1
",git fetch https://review.opendev.org/openstack/placement refs/changes/49/880249/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,36b6211e93c62e25d17718dc986d04ba229a3f06,,os-traits>=2.10.0 # Apache-2.0,os-traits>=2.7.0 # Apache-2.0,1,1
openstack%2Fplacement~stable%2Fzed~Ia81f535a6eb577adc5aac4e3f62eb66f91e41ad6,openstack/placement,stable/zed,Ia81f535a6eb577adc5aac4e3f62eb66f91e41ad6,chore: update stable/zed OS-TRAITS version to 2.10.0,ABANDONED,2023-04-12 23:21:17.000000000,2023-04-17 14:59:40.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 23:21:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/placement/commit/3364fa207788b431f3f97f8c49a557d6c24cd644', 'message': 'chore: update stable/zed OS-TRAITS version to 2.10.0\n\nChange-Id: Ia81f535a6eb577adc5aac4e3f62eb66f91e41ad6\n'}]",1,880250,3364fa207788b431f3f97f8c49a557d6c24cd644,4,2,1,33330,,,0,"chore: update stable/zed OS-TRAITS version to 2.10.0

Change-Id: Ia81f535a6eb577adc5aac4e3f62eb66f91e41ad6
",git fetch https://review.opendev.org/openstack/placement refs/changes/50/880250/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3364fa207788b431f3f97f8c49a557d6c24cd644,,os-traits>=2.10.0 # Apache-2.0,os-traits>=2.8.0 # Apache-2.0,1,1
openstack%2Fvalidations-libs~master~I137fc2c668027895b38c76eaa8f1db90b2d12272,openstack/validations-libs,master,I137fc2c668027895b38c76eaa8f1db90b2d12272,VF container security and stability adjustment,ABANDONED,2022-08-26 13:38:29.000000000,2023-04-17 14:59:06.000000000,,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 35059}]","[{'number': 1, 'created': '2022-08-26 13:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/087781f7405b841993e0f3bfee3c4a4ce80634c6', 'message': 'Changing default base image to UBI\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 2, 'created': '2022-08-29 06:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/85ffe66a7fef6e766119bc046a074ac54a35ae48', 'message': 'Changing default base image to UBI\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 3, 'created': '2022-09-02 13:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/3ae3e8c4e95897b5a57b0e745c290be6a1eda833', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 4, 'created': '2022-09-21 07:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/d15fdb47a910428973d9fbb728605f6db4940dc7', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 5, 'created': '2022-09-21 12:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/406465fddbe30bf790e0f3d061a0cf538106af7f', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 6, 'created': '2022-09-21 13:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/024cb4d4d6e7182449942897eaa21680b2f41034', 'message': 'xVF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 7, 'created': '2022-09-21 15:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/39994e2b77a2d5712c16108c0f7fbdeb304972e4', 'message': 'xVF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 8, 'created': '2022-09-21 15:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/ddc91c3a95047d37720fc0a7ca98c0007180f98c', 'message': 'xVF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 9, 'created': '2022-09-22 07:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/066b7fa0c6cc7bb177fae75b2127fb95455b2987', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 10, 'created': '2022-09-26 09:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/832814dc07c676c9251caf75f88d4d7a15bac9d1', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 11, 'created': '2022-09-26 11:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/bf9a8e1404ef4460e927874ceeaa98489c0946cc', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 12, 'created': '2022-09-26 13:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/dc59fc49411b539cb9619404bc78993fa3d17d76', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 13, 'created': '2022-09-26 14:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/b5fc9c1404703ad4e4851d0fb8d339adb61264c2', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 14, 'created': '2022-09-26 15:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/e73093f349470b7f06250d0dcf80a38b7df66d02', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 15, 'created': '2022-09-27 11:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/7359a949905862b6f0b9c6179a778965bc4ab028', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 16, 'created': '2022-09-29 10:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/65055222dc913213d7758a42115eb3d70fcfb92b', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 17, 'created': '2022-09-29 10:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/5728bfd59f5d8b9855a163b9c61db1986f1941a8', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 18, 'created': '2022-09-29 11:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/a5184896ea9f40acd3bb4fd30cf65e288b29b5a4', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 19, 'created': '2022-09-29 12:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/ac3e8d4e54bc79d26cfb31c1b639cb93bb1cc520', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 20, 'created': '2022-09-29 14:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/67d8c50f9e52290e693bee8f1f9000a9d06d4ac3', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\nFurther changes:\n  * Renaming the container file to more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blogs and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nDepends-On: https://review.opendev.org/c/openstack/validations-libs/+/855647\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 21, 'created': '2022-09-29 15:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/cd5a86e20ac02ba611469727f9bc514854332034', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n  * Execution location of the build command in CI changed to decrease context size\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 22, 'created': '2022-09-30 06:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/f485fede93ad1a8f96f11862a66be51b99603527', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n  * Execution location of the build command in CI changed to decrease context size\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 23, 'created': '2022-09-30 11:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/ee4c9ce8b169ca2d69e27e3b0a5fbbcab5ed2096', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 24, 'created': '2022-09-30 12:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/22f7e89f3d03520abe1ad2103bb678f1560d6b59', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 25, 'created': '2022-09-30 14:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/267d345f969714e09082be0ec36562c5157848fb', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 26, 'created': '2022-10-03 11:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/fa93546f0b8fff1ddebc41e64cf5d10a27644798', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 27, 'created': '2022-10-24 09:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/48c939c223d64d20458848173ec9e5b5b62b8554', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 28, 'created': '2022-12-12 09:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/1a4032d25d87514452dd0ef2b98cbf35a0c15dcb', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 29, 'created': '2022-12-12 10:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/c76e9f903699f055856769be26b1005323cd3e70', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 30, 'created': '2023-01-02 07:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/79007f50e93a2602837cd1dc9cee320316e5a71c', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}, {'number': 31, 'created': '2023-01-06 10:49:13.000000000', 'files': ['.gitignore', 'container/validation', 'playbooks/validations-libs-podified.yaml'], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/2f73b3942e2ceaf2a1aa2f0661a6c7854576589b', 'message': 'VF container security and stability adjustment\n\nContainer will be rootless, if executed and built with default\npodman runtime which allows necessary functionality.\nThe permissions will be set on the log directory, limiting filesystem\naccess to a minimum. Attempting execution under docker will notify user about\nthe impeding privilidge escalation and the reasons behind it.\n\nContainer is now build with one less intermediate layer,\nkeeping down the storage footprint and build runtime.\n\nThe CLI remains unchanged.\n\nFurther changes:\n  * Renaming the container file to a more obvious alternative\n  * Setting default workdir for the container\n  * Improving logging facility of the script\n  * Propagating CLI __init__ args\n  * Setting _print function to send logs to debug by default\n  * Eliminating unused _print function arg\n  * Replacing deprecated distutils import with shutils\n  * Replacing error printouts with catch blocks and exceptions\n  * Extending log verbosity\n  * Changing base image to more stable ubi9\n  * Additional info is requested from the container runtime\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272\n'}]",11,854782,2f73b3942e2ceaf2a1aa2f0661a6c7854576589b,73,4,31,32926,,,0,"VF container security and stability adjustment

Container will be rootless, if executed and built with default
podman runtime which allows necessary functionality.
The permissions will be set on the log directory, limiting filesystem
access to a minimum. Attempting execution under docker will notify user about
the impeding privilidge escalation and the reasons behind it.

Container is now build with one less intermediate layer,
keeping down the storage footprint and build runtime.

The CLI remains unchanged.

Further changes:
  * Renaming the container file to a more obvious alternative
  * Setting default workdir for the container
  * Improving logging facility of the script
  * Propagating CLI __init__ args
  * Setting _print function to send logs to debug by default
  * Eliminating unused _print function arg
  * Replacing deprecated distutils import with shutils
  * Replacing error printouts with catch blocks and exceptions
  * Extending log verbosity
  * Changing base image to more stable ubi9
  * Additional info is requested from the container runtime

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: I137fc2c668027895b38c76eaa8f1db90b2d12272
",git fetch https://review.opendev.org/openstack/validations-libs refs/changes/82/854782/27 && git format-patch -1 --stdout FETCH_HEAD,['container/validation'],1,087781f7405b841993e0f3bfee3c4a4ce80634c6,container/ubi,"LABEL name=""VF containerfile"" RUN groupadd -g %(gid)s -o %(user)s &&\ useradd -m -u %(uid)s -g %(gid)s -o -s /bin/bash %(user)s RUN dnf install -y python3-pip gcc python3-devel jq %(extra_pkgs)s openssh-clients opensshRUN ln -s /usr/local/share/ansible /usr/share/ansible &&\ mkdir -m 755 /home/%(user)s/validations &&\ mkdir -m 755 /home/%(user)s/community-validations &&\ chown -R %(uid)s:%(gid)s /home/%(user)sWORKDIR /home/%(user)s self.log = logging.getLogger(__name__ + "".Validation"") super(Validation, self).__init__(description=description, epilog=epilog) parser.add_argument('--image', type=str, default='ubi9/ubi', help='Container base image. Defaults to ubi9/ubi') def _print(self, string): self.log.debug(string) with open('./.VFContainerfile', 'w+') as containerfile: '.VFContainerfile', if self.engine == 'docker' and os.getuid() != 0: self.log.warning( ""Build with Docker requires privilege escalation in order"" "" to mount volumes. https://github.com/moby/moby/issues/2259"" ""Requesting privilege escalation."") except subprocess.CalledProcessError as e: self.log.fatal( ""Error encountered during image build %s"", e) self.log.error( ""Error encountered during volume mounting %s"", e) cmd.append('-v%s:/home/validation/containerhost_private_key:z' % if not os.path.isdir(os.path.abspath(self.validation_log_dir)): self._create_volume(self.validation_log_dir) cmd.append('-v%s:/home/validation/validations:z' % self.validation_log_dir) if not os.path.isdir(os.path.abspath(COMMUNITY_VALIDATION_PATH)): self._create_volume(COMMUNITY_VALIDATION_PATH) cmd.append('-v%s:/home/validation/community-validations:z' % COMMUNITY_VALIDATION_PATH) self._print('Adding volumes: {}'.format(','.join(self.volumes))) for volume in self.volumes: self._print(""Run command {}"".format(cmd)) def _set_volume_permissions(self): cmd = [ 'podman', 'unshare', 'chown', '-R', str(self.uid) + ':' + str(self.uid), self.validation_log_dir] self._print(""Permissions change command {}"".format(cmd)) try: subprocess.check_call(cmd) except subprocess.CalledProcessError as e: self.log.fatal( ""Error encountered during volume mounting %s"", e) sys.exit(1) self._set_volume_permissions() self._print('Running {}'.format(' '.join(cmd))) except subprocess.CalledProcessError as e: self.log.fatal( ""Error encountered during container execution %s"", e)","LABEL name=""VF dockerfile"" RUN groupadd -g %(gid)s -o %(user)s RUN useradd -m -u %(uid)s -g %(gid)s -o -s /bin/bash %(user)s RUN dnf install -y python3-pip gcc python3-devel jq %(extra_pkgs)sRUN ln -s /usr/local/share/ansible /usr/share/ansible log = logging.getLogger(__name__ + "".Validation"") super(Validation, self).__init__(description=DESCRIPTION, epilog=EPILOG) parser.add_argument('--image', type=str, default='fedora:30', help='Container base image. Defaults to fedora:30') def _print(self, string, debug=True): with open('./Containerfile', 'w+') as containerfile: 'Containerfile', if os.getuid() != 0: except subprocess.CalledProcessError: print('An error occurred!') self._print(e) cmd.append('-v%s:/root/containerhost_private_key:z' % self._create_volume(self.validation_log_dir) if os.path.isdir(os.path.abspath(self.validation_log_dir)): cmd.append('-v%s:/root/validations:z' % self.validation_log_dir) self._create_volume(COMMUNITY_VALIDATION_PATH) if os.path.isdir(os.path.abspath(COMMUNITY_VALIDATION_PATH)): cmd.append('-v%s:/root/community-validations:z' % COMMUNITY_VALIDATION_PATH) self._print('Adding volumes:') for volume in self.volumes: self._print(volume) self._print('Running %s' % ' '.join(cmd)) except subprocess.CalledProcessError: print('An error occurred!')",68,32
openstack%2Fplacement~master~I1e0c8e173a1197e54ba4f8a3eacdc2dcd567dfc9,openstack/placement,master,I1e0c8e173a1197e54ba4f8a3eacdc2dcd567dfc9,Dropping lower constraints testing,ABANDONED,2021-04-25 03:00:46.000000000,2023-04-17 14:58:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-04-25 03:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/4f59cf06dd9f4b1e18d81df6f7fb6f663001a70c', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints [1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I1e0c8e173a1197e54ba4f8a3eacdc2dcd567dfc9\n'}, {'number': 2, 'created': '2021-09-07 07:57:49.000000000', 'files': ['.zuul.yaml', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/placement/commit/def8fe0af0bae20c4eaf563344cb52e351c1369e', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints [1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I1e0c8e173a1197e54ba4f8a3eacdc2dcd567dfc9\n'}]",0,787863,def8fe0af0bae20c4eaf563344cb52e351c1369e,5,1,2,31412,,,0,"Dropping lower constraints testing

We facing errors related to the new pip resolver, this
topic was discussed on the ML and QA team proposed to
to test lower-constraints [1].

I propose to drop this test because the complexity and recurring pain needed
to maintain that now exceeds the benefits provided by this mechanismes.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html

Change-Id: I1e0c8e173a1197e54ba4f8a3eacdc2dcd567dfc9
",git fetch https://review.opendev.org/openstack/placement refs/changes/63/787863/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'lower-constraints.txt', 'tox.ini']",3,4f59cf06dd9f4b1e18d81df6f7fb6f663001a70c,,," [testenv:lower-constraints] # When using pbr and in a git repo, 'setup.py install' does not install # packages. 'setup.py develop', used when usedevelop is True, does. usedevelop = False # Use our own install_command to turn off upper constraints, which conflicts # with lower constraints. install_command = pip install {opts} {packages} deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt # Test with both functional and unit tests. commands = {[testenv]commands} stestr --test-path=./placement/tests run {posargs}",0,106
openstack%2Fneutron~master~I943f2fb4db9dc33dc372f844d6133faff415befe,openstack/neutron,master,I943f2fb4db9dc33dc372f844d6133faff415befe,OVN: Always try and create a metadata port on subnets,MERGED,2023-04-07 21:15:35.000000000,2023-04-17 14:52:47.000000000,2023-04-17 14:51:19.000000000,"[{'_account_id': 1131}, {'_account_id': 6737}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-07 21:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/127cde027084431cbde55b34e8442c0bf975238b', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 2, 'created': '2023-04-12 01:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc69ca0ba2415a6f6f8e55a62a66f229723d50ba', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 3, 'created': '2023-04-12 01:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58dc988ca7c53ea704d6e1fea09920812da8f2c7', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 4, 'created': '2023-04-12 13:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/151c6c3b69edd42da9e47e47444847e9b8d17aa7', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 5, 'created': '2023-04-12 14:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/61fce0a2fbcac4e674499bbcb14c8f6cab8465cd', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 6, 'created': '2023-04-12 15:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4304845d0d7cb036f46a05b6e1461dd4f919f0a', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 7, 'created': '2023-04-12 17:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76ae6a97fb982417a66aec2149f092899fa0e3eb', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 8, 'created': '2023-04-12 19:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00342c3d7c4d0cba0f76639ebb11d2b27114509d', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 9, 'created': '2023-04-12 20:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d721d5aaa064beeedcffac84eec969accf9628d', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 10, 'created': '2023-04-12 22:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37a2ead37ad52b0c1f4a1dab42cfd4f8791b68d7', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nI am only marking this a partial fix since it is\nunclear if there is another issue lurking in this code.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nPartial-bug: #2015377\n'}, {'number': 11, 'created': '2023-04-13 16:33:01.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py', 'releasenotes/notes/ovn-recreate-metadata-port-76e2c0e651267aa0.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/267efd298479d66c64d55a76bd21c9664080f76a', 'message': 'OVN: Always try and create a metadata port on subnets\n\nWhen a subnet is updated, for example, to disable then\nre-enable DHCP on it, if there is no metadata port it\nwill just return without trying to allocate an IP,\nleaving DHCP unusable on the subnet.  This could happen\nif an admin, even accidentally, deletes the DHCP port\non a subnet while DHCP is disabled.\n\nThis also makes OVN behave like ML2/OVS, which will\nre-create the DHCP port when the enable_dhcp flag is\nchanged to false and back to true.\n\nChange-Id: I943f2fb4db9dc33dc372f844d6133faff415befe\nCloses-bug: #2015377\n'}]",10,879913,267efd298479d66c64d55a76bd21c9664080f76a,52,7,11,1131,,,0,"OVN: Always try and create a metadata port on subnets

When a subnet is updated, for example, to disable then
re-enable DHCP on it, if there is no metadata port it
will just return without trying to allocate an IP,
leaving DHCP unusable on the subnet.  This could happen
if an admin, even accidentally, deletes the DHCP port
on a subnet while DHCP is disabled.

This also makes OVN behave like ML2/OVS, which will
re-create the DHCP port when the enable_dhcp flag is
changed to false and back to true.

Change-Id: I943f2fb4db9dc33dc372f844d6133faff415befe
Closes-bug: #2015377
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/879913/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py']",3,127cde027084431cbde55b34e8442c0bf975238b,bug/2015377," self._ovn_client.update_metadata_port(ctx, net)"," self._ovn_client.update_metadata_port(ctx, net['id'])",69,21
openstack%2Fironic~master~I9aad5f3845f8abc64b1b2abc78b829929f73aafd,openstack/ironic,master,I9aad5f3845f8abc64b1b2abc78b829929f73aafd,tests: Comment out prints,ABANDONED,2022-09-07 23:09:34.000000000,2023-04-17 14:52:47.000000000,,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-07 23:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e9ae06acb0179042632857f5f82d9f2adf98332d', 'message': 'tests: Comment out prints\n\nThese were polluting the output of the test runs and making it really\ndifficult to identify failures. Silence them. People can always\nuncomment the prints if they need them.\n\nChange-Id: I9aad5f3845f8abc64b1b2abc78b829929f73aafd\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2022-09-08 10:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de46b3661b4875fa75cc3a98c59457612dd1cb33', 'message': 'tests: Comment out prints\n\nThese were polluting the output of the test runs and making it really\ndifficult to identify failures. Silence them. People can always\nuncomment the prints if they need them.\n\nChange-Id: I9aad5f3845f8abc64b1b2abc78b829929f73aafd\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2023-04-17 09:34:20.000000000', 'files': ['ironic/tests/unit/api/test_acl.py', 'ironic/tests/unit/api/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5a644361b025cb5bcdcb7288c40e5553500b4f33', 'message': 'tests: Comment out prints\n\nThese were polluting the output of the test runs and making it really\ndifficult to identify failures. Silence them. People can always\nuncomment the prints if they need them.\n\nChange-Id: I9aad5f3845f8abc64b1b2abc78b829929f73aafd\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",6,856348,5a644361b025cb5bcdcb7288c40e5553500b4f33,14,2,3,15334,,,0,"tests: Comment out prints

These were polluting the output of the test runs and making it really
difficult to identify failures. Silence them. People can always
uncomment the prints if they need them.

Change-Id: I9aad5f3845f8abc64b1b2abc78b829929f73aafd
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/ironic refs/changes/48/856348/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/test_acl.py', 'ironic/tests/unit/api/base.py']",2,e9ae06acb0179042632857f5f82d9f2adf98332d,sqlalchemy-20," # print('%s: %s %s' % (method.upper(), full_path, params)) # print('GOT:%s' % response) # print('DELETE: %s' % (full_path)) # print('GOT:%s' % response) # print('GET: %s %r' % (full_path, all_params)) # print('GOT:%s' % response)"," print('%s: %s %s' % (method.upper(), full_path, params)) print('GOT:%s' % response) print('DELETE: %s' % (full_path)) print('GOT:%s' % response) print('GET: %s %r' % (full_path, all_params)) print('GOT:%s' % response)",10,10
openstack%2Fkayobe~stable%2Fzed~I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,openstack/kayobe,stable/zed,I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d,Fix passwords.yml generation when parent directory doesn't exist,MERGED,2023-04-14 07:38:51.000000000,2023-04-17 14:47:38.000000000,2023-04-17 14:46:04.000000000,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 07:38:51.000000000', 'files': ['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/6b6dede9fc3eb300b0fc9a6f5c903c6f4db955e1', 'message': ""Fix passwords.yml generation when parent directory doesn't exist\n\nFixes an issue where generation of passwords.yml for Kolla Ansible\ncould fail if the directory containing the file does not exist. This is\ntypical in a multiple environment setup, when creating a new\nenvironment.\n\nStory: 2010293\nTask: 46275\nCloses-Bug: #2015093\nChange-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d\n(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)\n""}]",0,880387,6b6dede9fc3eb300b0fc9a6f5c903c6f4db955e1,9,4,1,22629,,,0,"Fix passwords.yml generation when parent directory doesn't exist

Fixes an issue where generation of passwords.yml for Kolla Ansible
could fail if the directory containing the file does not exist. This is
typical in a multiple environment setup, when creating a new
environment.

Story: 2010293
Task: 46275
Closes-Bug: #2015093
Change-Id: I9dce73a8a205c0c0ad02eba3a10e02b82f5b191d
(cherry picked from commit 5287083116da2512b887529e67af4c4919e1e296)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/87/880387/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-ansible/library/kolla_passwords.py', 'releasenotes/notes/fix-kolla-passwords-f1b5d051c494b4d8.yaml']",2,6b6dede9fc3eb300b0fc9a6f5c903c6f4db955e1,,"--- fixes: - | Fixes an issue where generation of ``passwords.yml`` for Kolla Ansible could fail if the directory containing the file does not exist. This is typical in a multiple environment setup, when creating a new environment. See `story 2010293 <https://storyboard.openstack.org/#!/story/2010293>`_ for details. ",,11,0
openstack%2Fcharm-rabbitmq-server~master~I8a4f42249a8607c5d0baf3b9f19d8edd663ec1ca,openstack/charm-rabbitmq-server,master,I8a4f42249a8607c5d0baf3b9f19d8edd663ec1ca,"Add lunar, drop kinetic, and sync charm-helpers",MERGED,2023-04-12 19:27:39.000000000,2023-04-17 14:36:17.000000000,2023-04-17 14:36:17.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 19:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/6db383b52f9321297711c048132db0439bb8b199', 'message': 'Add lunar and drop kinetic\n\nAdd 23.04 run-on base and add lunar to metadata.yaml.\nDrop 22.10 run-on base and drop kinetic from metadata.yaml.\n\nChange-Id: I8a4f42249a8607c5d0baf3b9f19d8edd663ec1ca\n'}, {'number': 2, 'created': '2023-04-14 15:11:33.000000000', 'files': ['charmhelpers/contrib/openstack/deferred_events.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'charmcraft.yaml', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/core/host_factory/ubuntu.py', 'metadata.yaml'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/09c507dd21de5ce5e6203d648bd0c47256258d5b', 'message': 'Add lunar, drop kinetic, and sync charm-helpers\n\nAdd 23.04 run-on base and add lunar to metadata.yaml.\nDrop 22.10 run-on base and drop kinetic from metadata.yaml.\nCharm-helper sync to pick up Antelope support.\n\nChange-Id: I8a4f42249a8607c5d0baf3b9f19d8edd663ec1ca\n'}]",0,880234,09c507dd21de5ce5e6203d648bd0c47256258d5b,11,3,2,11805,,,0,"Add lunar, drop kinetic, and sync charm-helpers

Add 23.04 run-on base and add lunar to metadata.yaml.
Drop 22.10 run-on base and drop kinetic from metadata.yaml.
Charm-helper sync to pick up Antelope support.

Change-Id: I8a4f42249a8607c5d0baf3b9f19d8edd663ec1ca
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/34/880234/2 && git format-patch -1 --stdout FETCH_HEAD,"['charmcraft.yaml', 'metadata.yaml']",2,6db383b52f9321297711c048132db0439bb8b199,lunar-support,- lunar,- kinetic,2,2
openstack%2Fkolla-ansible~stable%2Fyoga~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kolla-ansible,stable/yoga,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 09:57:25.000000000,2023-04-17 14:34:19.000000000,2023-04-17 14:32:54.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 09:57:25.000000000', 'files': ['ansible/action_plugins/merge_yaml.py', 'ansible/action_plugins/merge_configs.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c8f11df802dd221cc36f5b79c6faec073b6a5f1a', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nAlso, this change contains fixes already applied in the Kayobe\nproject to improve and synchronize the code of the plugins between\nprojects.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)\n""}]",0,880476,c8f11df802dd221cc36f5b79c6faec073b6a5f1a,9,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Also, this change contains fixes already applied in the Kayobe
project to improve and synchronize the code of the plugins between
projects.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/880476/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/action_plugins/merge_configs.py', 'ansible/action_plugins/merge_yaml.py']",2,c8f11df802dd221cc36f5b79c6faec073b6a5f1a,fix-merge-action-plugins,"import yaml if source and os.access(source, os.R_OK): result = yaml.safe_load(template_data) f.write(yaml.dump(output, default_flow_style=False)) copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)","from yaml import dump from yaml import safe_load if os.access(source, os.R_OK): result = safe_load(template_data) f.write(dump(output, default_flow_style=False)) result.update(copy_action.run(task_vars=task_vars))",16,9
openstack%2Fkolla-ansible~stable%2Fzed~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kolla-ansible,stable/zed,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-14 09:57:03.000000000,2023-04-17 14:34:05.000000000,2023-04-17 14:32:56.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-14 09:57:03.000000000', 'files': ['ansible/action_plugins/merge_yaml.py', 'ansible/action_plugins/merge_configs.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/89d9a0c43412f63a97a80ae7aab7af14bc589917', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nAlso, this change contains fixes already applied in the Kayobe\nproject to improve and synchronize the code of the plugins between\nprojects.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)\n""}]",0,880475,89d9a0c43412f63a97a80ae7aab7af14bc589917,9,3,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Also, this change contains fixes already applied in the Kayobe
project to improve and synchronize the code of the plugins between
projects.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
(cherry picked from commit 8972241dc9736109f9d98552035e7557c366bf94)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/75/880475/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/action_plugins/merge_configs.py', 'ansible/action_plugins/merge_yaml.py']",2,89d9a0c43412f63a97a80ae7aab7af14bc589917,fix-merge-action-plugins,"import yaml if source and os.access(source, os.R_OK): result = yaml.safe_load(template_data) f.write(yaml.dump(output, default_flow_style=False)) copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)","from yaml import dump from yaml import safe_load if os.access(source, os.R_OK): result = safe_load(template_data) f.write(dump(output, default_flow_style=False)) result.update(copy_action.run(task_vars=task_vars))",16,9
openstack%2Fnova~master~If3210c0659ac0d81586731f948db7a3a899b0b3e,openstack/nova,master,If3210c0659ac0d81586731f948db7a3a899b0b3e,Fix duplicate cell creation with same name,NEW,2023-03-09 07:08:38.000000000,2023-04-17 14:22:45.000000000,,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-09 07:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/522a06c3d31aa2487ba2c97d32712b3958ad45d6', 'message': ""Fix duplicate cell creation with same name\n\nAs of now, if user tries to create a cell using templated\nurls and execute the same command (nova-manage cell_v2 create_cell)\ntwice, then two different db entries are created in CellMappings\ntable having same cell name (eg. cell1).\n\nThis change adds unique constraint on 'name' field in\nCellMappings table in nova_api db.\n\nCloses-Bug: #1923899\nCloses-Bug: #1736731\nChange-Id: If3210c0659ac0d81586731f948db7a3a899b0b3e\n""}, {'number': 2, 'created': '2023-03-13 10:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e385646a6512a17d5d292034761a9104998d220', 'message': ""Fix duplicate cell creation with same name\n\nAs of now, if user tries to create a cell using templated\nurls and execute the same command (nova-manage cell_v2 create_cell)\ntwice, then two different db entries are created in CellMappings\ntable having same cell name (eg. cell1).\n\nThis change adds unique constraint on 'name' field in\nCellMappings table in nova_api db.\n\nCloses-Bug: #1923899\nCloses-Bug: #1736731\nChange-Id: If3210c0659ac0d81586731f948db7a3a899b0b3e\n""}, {'number': 3, 'created': '2023-03-14 13:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cdd2fd815ece2cf9abe05c228b38b3a8d73df54', 'message': ""Fix duplicate cell creation with same name\n\nAs of now, if user tries to create a cell using templated\nurls and execute the same command (nova-manage cell_v2 create_cell)\ntwice, then two different db entries are created in CellMappings\ntable having same cell name (eg. cell1).\n\nThis change adds unique constraint on 'name' field in\nCellMappings table in nova_api db.\n\nCloses-Bug: #1923899\nCloses-Bug: #1736731\nChange-Id: If3210c0659ac0d81586731f948db7a3a899b0b3e\n""}, {'number': 4, 'created': '2023-03-15 05:57:44.000000000', 'files': ['nova/tests/functional/db/test_cell_mapping.py', 'nova/cmd/status.py', 'nova/tests/unit/db/api/test_migrations.py', 'nova/db/api/migrations/versions/88ef7b0ca805_add_uniq_cell_mappings_name.py', 'nova/db/api/models.py', 'releasenotes/notes/fix-duplicate-cell-names-84427a36f7e38f7c.yaml', 'nova/tests/functional/db/test_host_mapping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c928fbdcc10eddc0e4be605181c061d3e42de46e', 'message': ""Fix duplicate cell creation with same name\n\nAs of now, if user tries to create a cell using templated\nurls and execute the same command (nova-manage cell_v2 create_cell)\ntwice, then two different db entries are created in CellMappings\ntable having same cell name (eg. cell1).\n\nThis change adds unique constraint on 'name' field in\nCellMappings table in nova_api db.\n\nCloses-Bug: #1923899\nCloses-Bug: #1736731\nChange-Id: If3210c0659ac0d81586731f948db7a3a899b0b3e\n""}]",18,876940,c928fbdcc10eddc0e4be605181c061d3e42de46e,27,6,4,20733,,,0,"Fix duplicate cell creation with same name

As of now, if user tries to create a cell using templated
urls and execute the same command (nova-manage cell_v2 create_cell)
twice, then two different db entries are created in CellMappings
table having same cell name (eg. cell1).

This change adds unique constraint on 'name' field in
CellMappings table in nova_api db.

Closes-Bug: #1923899
Closes-Bug: #1736731
Change-Id: If3210c0659ac0d81586731f948db7a3a899b0b3e
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/876940/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/api/test_migrations.py', 'nova/db/api/migrations/versions/88ef7b0ca805_add_uniq_cell_mappings_name.py', 'nova/db/api/models.py']",3,522a06c3d31aa2487ba2c97d32712b3958ad45d6,bug/1923899," schema.UniqueConstraint('name', name='uniq_cell_mappings0name'),",,47,0
openstack%2Foslo.db~master~I4d4a58e15e840ecfa63e15c709617a65642c8323,openstack/oslo.db,master,I4d4a58e15e840ecfa63e15c709617a65642c8323,Remove logic for SQLAlchemy < 1.4,MERGED,2023-03-22 12:26:09.000000000,2023-04-17 14:14:39.000000000,2023-04-17 14:13:42.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-22 12:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/f058d86ee96f59690be5133a8f6d5668f25cf62e', 'message': 'Remove logic for SQLAlchemy < 1.4\n\nChange I8629225eeb51d95264d8a3e4b719268bb1597f4f bumped the minimum\nversion for SQLAlchemy to 1.4, meaning this logic is now dead. Remove\nit.\n\nChange-Id: I4d4a58e15e840ecfa63e15c709617a65642c8323\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-04-05 12:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c4058ec9c3ac734a6b391c25e3a26b5694f0a602', 'message': 'Remove logic for SQLAlchemy < 1.4\n\nChange I8629225eeb51d95264d8a3e4b719268bb1597f4f bumped the minimum\nversion for SQLAlchemy to 1.4, meaning this logic is now dead. Remove\nit.\n\nChange-Id: I4d4a58e15e840ecfa63e15c709617a65642c8323\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2023-04-17 09:19:18.000000000', 'files': ['oslo_db/sqlalchemy/provision.py', 'oslo_db/sqlalchemy/engines.py', 'oslo_db/tests/sqlalchemy/test_exc_filters.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/56d79bf3784bacf4fa17cee31a1ba1a8b3680dba', 'message': 'Remove logic for SQLAlchemy < 1.4\n\nChange I8629225eeb51d95264d8a3e4b719268bb1597f4f bumped the minimum\nversion for SQLAlchemy to 1.4, meaning this logic is now dead. Remove\nit.\n\nChange-Id: I4d4a58e15e840ecfa63e15c709617a65642c8323\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,878215,56d79bf3784bacf4fa17cee31a1ba1a8b3680dba,13,3,3,15334,,,0,"Remove logic for SQLAlchemy < 1.4

Change I8629225eeb51d95264d8a3e4b719268bb1597f4f bumped the minimum
version for SQLAlchemy to 1.4, meaning this logic is now dead. Remove
it.

Change-Id: I4d4a58e15e840ecfa63e15c709617a65642c8323
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/15/878215/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/provision.py', 'oslo_db/sqlalchemy/engines.py', 'oslo_db/tests/sqlalchemy/test_exc_filters.py']",3,f058d86ee96f59690be5133a8f6d5668f25cf62e,sqlalchemy-20," self.url = url.set(database=""non_existent_database"")"," # TODO(zzzeek): remove hasattr() conditional in favor of ""url.set()"" # when SQLAlchemy 1.4 is the minimum version in requirements if hasattr(url, ""set""): self.url = url.set(database=""non_existent_database"") else: # TODO(zzzeek): remove when SQLAlchemy 1.4 # is the minimum version in requirements url.database = 'non_existent_database' self.url = url",3,46
openstack%2Foslo.db~master~I5396a5a3272e6984954d819cfc71507283c775db,openstack/oslo.db,master,I5396a5a3272e6984954d819cfc71507283c775db,Match exceptions with multiple lines,MERGED,2023-03-22 12:26:09.000000000,2023-04-17 14:06:54.000000000,2023-04-17 14:05:43.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-22 12:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0d6241b5914188cc455716e4b09f0485001ebf88', 'message': 'Match exceptions with multiple lines\n\nWe were creating regexes without the DOTALL flag, which meant \'.\' wasn\'t\nmatching newlines. This meant exceptions that contained multiple lines\nwould not be caught. For example, in my environment where Kerberos is\nused, I see the following otherwise harmless message:\n\n  (psycopg2.OperationalError) connection to server at ""localhost"" (::1),\n  port 5432 failed: could not initiate GSSAPI security context: No\n  credentials were supplied, or the credentials were unavailable or\n  inaccessible: Configuration file does not specify default realm\n\n  connection to server at ""localhost"" (::1), port 5432 failed: FATAL:\n  database ""non_existent_database"" does not exist\n\nThe presence of that newline causes our matchers to fail and the\nexception is not wrapped. Correct this.\n\nIn the meanwhile, we reformat the function that does the wrapping to\nmake it a little flatter. This was difficult to modify (for debugging\npurposes) due to the level of indentation.\n\nChange-Id: I5396a5a3272e6984954d819cfc71507283c775db\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-04-05 12:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/1b70dd14dbfafa12cb3b39360cb35296e0a7d2c6', 'message': 'Match exceptions with multiple lines\n\nWe were creating regexes without the DOTALL flag, which meant \'.\' wasn\'t\nmatching newlines. This meant exceptions that contained multiple lines\nwould not be caught. For example, in my environment where Kerberos is\nused, I see the following otherwise harmless message:\n\n  (psycopg2.OperationalError) connection to server at ""localhost"" (::1),\n  port 5432 failed: could not initiate GSSAPI security context: No\n  credentials were supplied, or the credentials were unavailable or\n  inaccessible: Configuration file does not specify default realm\n\n  connection to server at ""localhost"" (::1), port 5432 failed: FATAL:\n  database ""non_existent_database"" does not exist\n\nThe presence of that newline causes our matchers to fail and the\nexception is not wrapped. Correct this.\n\nIn the meanwhile, we reformat the function that does the wrapping to\nmake it a little flatter. This was difficult to modify (for debugging\npurposes) due to the level of indentation.\n\nChange-Id: I5396a5a3272e6984954d819cfc71507283c775db\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2023-04-17 09:19:18.000000000', 'files': ['oslo_db/sqlalchemy/exc_filters.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7d62b3664e4acad9161d849a111bdb8b4d707f61', 'message': 'Match exceptions with multiple lines\n\nWe were creating regexes without the DOTALL flag, which meant \'.\' wasn\'t\nmatching newlines. This meant exceptions that contained multiple lines\nwould not be caught. For example, in my environment where Kerberos is\nused, I see the following otherwise harmless message:\n\n  (psycopg2.OperationalError) connection to server at ""localhost"" (::1),\n  port 5432 failed: could not initiate GSSAPI security context: No\n  credentials were supplied, or the credentials were unavailable or\n  inaccessible: Configuration file does not specify default realm\n\n  connection to server at ""localhost"" (::1), port 5432 failed: FATAL:\n  database ""non_existent_database"" does not exist\n\nThe presence of that newline causes our matchers to fail and the\nexception is not wrapped. Correct this.\n\nIn the meanwhile, we reformat the function that does the wrapping to\nmake it a little flatter. This was difficult to modify (for debugging\npurposes) due to the level of indentation.\n\nChange-Id: I5396a5a3272e6984954d819cfc71507283c775db\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,878214,7d62b3664e4acad9161d849a111bdb8b4d707f61,13,3,3,15334,,,0,"Match exceptions with multiple lines

We were creating regexes without the DOTALL flag, which meant '.' wasn't
matching newlines. This meant exceptions that contained multiple lines
would not be caught. For example, in my environment where Kerberos is
used, I see the following otherwise harmless message:

  (psycopg2.OperationalError) connection to server at ""localhost"" (::1),
  port 5432 failed: could not initiate GSSAPI security context: No
  credentials were supplied, or the credentials were unavailable or
  inaccessible: Configuration file does not specify default realm

  connection to server at ""localhost"" (::1), port 5432 failed: FATAL:
  database ""non_existent_database"" does not exist

The presence of that newline causes our matchers to fail and the
exception is not wrapped. Correct this.

In the meanwhile, we reformat the function that does the wrapping to
make it a little flatter. This was difficult to modify (for debugging
purposes) due to the level of indentation.

Change-Id: I5396a5a3272e6984954d819cfc71507283c775db
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/14/878214/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_db/sqlalchemy/exc_filters.py'],1,0d6241b5914188cc455716e4b09f0485001ebf88,sqlalchemy-20," (fn, re.compile(reg, re.DOTALL)) for exc in (context.sqlalchemy_exception, context.original_exception): for super_ in exc.__class__.__mro__: if super_ not in per_dialect: continue regexp_reg = per_dialect[super_] for fn, regexp in regexp_reg: match = regexp.match(exc.args[0]) if not match: continue try: fn( exc, match, context.engine.dialect.name, context.is_disconnect, ) except exception.DBError as dbe: if ( context.connection is not None and not context.connection.closed and not context.connection.invalidated and ROLLBACK_CAUSE_KEY in context.connection.info ): dbe.cause = context.connection.info.pop( ROLLBACK_CAUSE_KEY, ) if isinstance(dbe, exception.DBConnectionError): context.is_disconnect = True return dbe"," (fn, re.compile(reg)) for exc in ( context.sqlalchemy_exception, context.original_exception): for super_ in exc.__class__.__mro__: if super_ in per_dialect: regexp_reg = per_dialect[super_] for fn, regexp in regexp_reg: match = regexp.match(exc.args[0]) if match: try: fn( exc, match, context.engine.dialect.name, context.is_disconnect) except exception.DBError as dbe: if ( context.connection is not None and not context.connection.closed and not context.connection.invalidated and ROLLBACK_CAUSE_KEY in context.connection.info ): dbe.cause = \ context.connection.info.pop( ROLLBACK_CAUSE_KEY) if isinstance( dbe, exception.DBConnectionError): context.is_disconnect = True return dbe",32,30
openstack%2Foslo.db~master~Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e,openstack/oslo.db,master,Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e,Don't sleep in tests,MERGED,2023-03-22 12:26:09.000000000,2023-04-17 14:06:06.000000000,2023-04-17 14:04:52.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-22 12:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/05a4a065be6e335580972be1ea3584907656f1f8', 'message': ""Don't sleep in tests\n\nMock it out, reducing test run of ~3 and ~15 seconds to milliseconds.\n\nChange-Id: Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-04-05 12:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/69c90d8cee615be987ef1c949ee12ae39eaa4407', 'message': ""Don't sleep in tests\n\nMock it out, reducing test run of ~3 and ~15 seconds to milliseconds.\n\nChange-Id: Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2023-04-17 09:19:18.000000000', 'files': ['oslo_db/tests/test_api.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/672dd056aa66645648c0d71af5eae3da9f424e48', 'message': ""Don't sleep in tests\n\nMock it out, reducing test run of ~3 and ~15 seconds to milliseconds.\n\nChange-Id: Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,878216,672dd056aa66645648c0d71af5eae3da9f424e48,14,3,3,15334,,,0,"Don't sleep in tests

Mock it out, reducing test run of ~3 and ~15 seconds to milliseconds.

Change-Id: Ice3a0c0d0a5b8c2920c7f775ff8ce974b572c66e
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/16/878216/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_db/tests/test_api.py'],1,05a4a065be6e335580972be1ea3584907656f1f8,sqlalchemy-20," @mock.patch('oslo_db.api.time.sleep', return_value=None) @mock.patch('oslo_db.api.time.sleep', return_value=None) def test_retry_wrapper_exception_checker(self, mock_sleep):", def test_retry_wrapper_exception_checker(self):,3,1
openstack%2Foslo.db~master~I4e1faa2c617ac19e7c9766e99ee9012ad9298d31,openstack/oslo.db,master,I4e1faa2c617ac19e7c9766e99ee9012ad9298d31,Remove dead code,MERGED,2023-03-22 12:26:09.000000000,2023-04-17 14:04:54.000000000,2023-04-17 14:04:54.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-22 12:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ea051f4d5a8dd7594d5b6d4a0707c0b798b811e8', 'message': 'Remove dead code\n\nThis should have been removed in change\nIc3d6bd318038d723b0d50d39e45f8e26289e9a57 but was missed.\n\nChange-Id: I4e1faa2c617ac19e7c9766e99ee9012ad9298d31\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-04-05 12:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9942934185650664441ea848cdcf6b564c278254', 'message': 'Remove dead code\n\nThis should have been removed in change\nIc3d6bd318038d723b0d50d39e45f8e26289e9a57 but was missed.\n\nChange-Id: I4e1faa2c617ac19e7c9766e99ee9012ad9298d31\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2023-04-17 09:19:18.000000000', 'files': ['oslo_db/sqlalchemy/utils.py', 'oslo_db/tests/sqlalchemy/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/04acea8cbbf7a989e07dad66fd40ac1d3ba4e0d2', 'message': 'Remove dead code\n\nThis should have been removed in change\nIc3d6bd318038d723b0d50d39e45f8e26289e9a57 but was missed.\n\nChange-Id: I4e1faa2c617ac19e7c9766e99ee9012ad9298d31\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,878213,04acea8cbbf7a989e07dad66fd40ac1d3ba4e0d2,12,3,3,15334,,,0,"Remove dead code

This should have been removed in change
Ic3d6bd318038d723b0d50d39e45f8e26289e9a57 but was missed.

Change-Id: I4e1faa2c617ac19e7c9766e99ee9012ad9298d31
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/13/878213/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/utils.py', 'oslo_db/tests/sqlalchemy/test_utils.py']",2,ea051f4d5a8dd7594d5b6d4a0707c0b798b811e8,sqlalchemy-20,,"from sqlalchemy import CheckConstraint def test_detect_boolean_deleted_constraint_detection(self): table_name = 'abc' table = Table(table_name, self.meta, Column('id', Integer, primary_key=True), Column('deleted', Boolean(create_constraint=True))) ck = [ const for const in table.constraints if isinstance(const, CheckConstraint)][0] self.assertTrue(utils._is_deleted_column_constraint(ck)) self.assertFalse( utils._is_deleted_column_constraint( CheckConstraint(""deleted > 5"") ) ) ",0,81
openstack%2Fnova~master~I8352b13ffe048901d295424856e632abece49c07,openstack/nova,master,I8352b13ffe048901d295424856e632abece49c07,libvirt: Check if VIF MTU matches network MTU,NEW,2022-08-09 03:06:59.000000000,2023-04-17 14:01:55.000000000,,"[{'_account_id': 8864}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-09 03:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/118d524574717a25f141539d7dd732b38134c5f2', 'message': 'libvirt: Check VIF MTU matches network MTU\n\nNot camera ready, just an early cut.\n\nChange-Id: I8352b13ffe048901d295424856e632abece49c07\n'}, {'number': 2, 'created': '2022-08-09 03:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61403c7bbcfdf779615ebdb1b50037e1199cc350', 'message': 'libvirt: Check if VIF MTU matches network MTU\n\nlibvirt does not allow the MTU to be modified on a running\nVM. At the same time, Neutron will assume the current MTU\nof the network is how the VIF should be configured. So, in\norder for migration to not break, the current host\nconfigured MTU must match that of the network.\n\nFormerly, this check was deferred until the actual live-\nmigration was already in flight. The error message also\nmade it seem that the MTU changing is the problem, whereas\nthere are really two possible problems.\n\nChange-Id: I8352b13ffe048901d295424856e632abece49c07\n'}, {'number': 3, 'created': '2023-03-28 13:15:14.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8a016af9e06a93dd090eec2a3d5fef32a05b5432', 'message': 'libvirt: Check if VIF MTU matches network MTU\n\nlibvirt does not allow the MTU to be modified on a running\nVM. At the same time, Neutron will assume the current MTU\nof the network is how the VIF should be configured. So, in\norder for migration to not break, the current host\nconfigured MTU must match that of the network.\n\nFormerly, this check was deferred until the actual live-\nmigration was already in flight. The error message also\nmade it seem that the MTU changing is the problem, whereas\nthere are really two possible problems.\n\nChange-Id: I8352b13ffe048901d295424856e632abece49c07\n'}]",22,852367,8a016af9e06a93dd090eec2a3d5fef32a05b5432,34,3,3,33910,,,0,"libvirt: Check if VIF MTU matches network MTU

libvirt does not allow the MTU to be modified on a running
VM. At the same time, Neutron will assume the current MTU
of the network is how the VIF should be configured. So, in
order for migration to not break, the current host
configured MTU must match that of the network.

Formerly, this check was deferred until the actual live-
migration was already in flight. The error message also
made it seem that the MTU changing is the problem, whereas
there are really two possible problems.

Change-Id: I8352b13ffe048901d295424856e632abece49c07
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/852367/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py']",2,118d524574717a25f141539d7dd732b38134c5f2,," def check_can_live_migrate_vif(self, instance, vif, host): # libvirt does not allow the MTU to be modified on a running VM. At the # same time, Neutron will assume the current MTU of the network is how # the VIF should be configured. So, in order for migration to not # break the current host configured MTU must match that of the network. network = vif.get('network') mtu = network.get_meta('mtu') if network else None cfg = self.get_config(instance, vif, instance.image_meta, instance.flavor, CONF.libvirt.virt_type, host) iface = host.get_guest(instance).get_interface_by_cfg(cfg) if mtu is not None and iface.mtu != mtu: reason = _(""Instance must be hard rebooted after a Neutron network "" ""MTU change before live-migrating it."") raise exception.MigrationPreCheckError(reason=reason)",,20,0
openstack%2Fneutron~master~I551a5095429ca949e6886a98020c4ddd072de862,openstack/neutron,master,I551a5095429ca949e6886a98020c4ddd072de862,Run periodic jobs in experimental queue too,MERGED,2023-04-14 16:02:05.000000000,2023-04-17 14:00:08.000000000,2023-04-17 13:57:32.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 16:02:05.000000000', 'files': ['zuul.d/job-templates.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2364327bd1e4d26214e11c2f3f4627959a6a3e88', 'message': 'Run periodic jobs in experimental queue too\n\nIt was done in past with [1] but since then\nlist diverged again.\n\nTo avoid same happening again used yaml\naliases for periodic jobs. So from now\nany job added to periodic queue will\nalso be added in experimental queue\nautomatically.\n\nneutron-experimental-jobs template will\nbe used for experimental only jobs.\n\n[1] https://review.opendev.org/c/openstack/neutron/+/833172\n\nChange-Id: I551a5095429ca949e6886a98020c4ddd072de862\n'}]",5,880539,2364327bd1e4d26214e11c2f3f4627959a6a3e88,13,4,1,13861,,,0,"Run periodic jobs in experimental queue too

It was done in past with [1] but since then
list diverged again.

To avoid same happening again used yaml
aliases for periodic jobs. So from now
any job added to periodic queue will
also be added in experimental queue
automatically.

neutron-experimental-jobs template will
be used for experimental only jobs.

[1] https://review.opendev.org/c/openstack/neutron/+/833172

Change-Id: I551a5095429ca949e6886a98020c4ddd072de862
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/880539/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/job-templates.yaml'],1,2364327bd1e4d26214e11c2f3f4627959a6a3e88,neutron-ci-improvements, - neutron-ovn-grenade-multinode - neutron-ovs-tempest-with-neutron-lib-master - neutron-ovn-tempest-with-uwsgi-loki jobs: &neutron-periodic-jobs experimental: jobs: *neutron-periodic-jobs, - neutron-functional - neutron-functional-with-uwsgi-fips - neutron-functional-with-pyroute2-master - neutron-functional-with-sqlalchemy-master - neutron-fullstack - neutron-fullstack-with-uwsgi-fips - neutron-fullstack-with-pyroute2-master - neutron-ovn-grenade-multinode - neutron-ovn-tempest-with-uwsgi-loki - neutron-ovn-tempest-with-neutron-lib-master - neutron-ovs-tempest-with-neutron-lib-master - neutron-ovs-tempest-slow - neutron-ovn-tempest-slow - neutron-ovs-tempest-with-os-ken-master - neutron-ovn-tempest-postgres-full - neutron-ovn-tempest-mariadb-full - neutron-ovn-tempest-ipv6-only-ovs-master - neutron-ovn-tempest-ovs-master-centos-9-stream - neutron-ovn-tempest-with-sqlalchemy-master - neutron-ovs-tempest-with-sqlalchemy-master - neutron-ovs-tempest-fips - neutron-ovn-tempest-ovs-release-fips - devstack-tobiko-neutron: voting: true - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa - openstacksdk-functional-devstack-networking - neutron-linuxbridge-tempest-plugin-scenario-nftables - neutron-ovs-tempest-plugin-scenario-iptables_hybrid-nftables - devstack-enforce-scope - openstack-tox-py39-with-oslo-master: timeout: 3600 irrelevant-files: *irrelevant-files - neutron-functional-with-oslo-master - neutron-ovs-tempest-with-oslo-master - neutron-ovn-tempest-ovs-release-with-oslo-master jobs:,6,36
openstack%2Fneutron~master~I5ef00b1150ebc4bbf03e1c9f192cf0cb884d0c08,openstack/neutron,master,I5ef00b1150ebc4bbf03e1c9f192cf0cb884d0c08,[grenade] Collect ovn services logs,MERGED,2023-04-17 06:57:45.000000000,2023-04-17 13:51:58.000000000,2023-04-17 13:49:20.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 06:57:45.000000000', 'files': ['zuul.d/grenade.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/73ac4510c7c76fed8ec0cd0a00be50d29549c902', 'message': '[grenade] Collect ovn services logs\n\nWould be useful investigating issues.\n\nRelated-Bug: #2015364\nChange-Id: I5ef00b1150ebc4bbf03e1c9f192cf0cb884d0c08\n'}]",3,880582,73ac4510c7c76fed8ec0cd0a00be50d29549c902,11,4,1,13861,,,0,"[grenade] Collect ovn services logs

Would be useful investigating issues.

Related-Bug: #2015364
Change-Id: I5ef00b1150ebc4bbf03e1c9f192cf0cb884d0c08
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/880582/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/grenade.yaml'],1,73ac4510c7c76fed8ec0cd0a00be50d29549c902,bug/2015364, '/opt/stack/old/logs': 'logs' '/opt/stack/new/logs': 'logs',,2,0
openstack%2Fansible-collections-openstack~master~I29f9a8712ec0446cf530def6af7e9113ce15a896,openstack/ansible-collections-openstack,master,I29f9a8712ec0446cf530def6af7e9113ce15a896,Vpn endpoint group module,NEW,2023-04-17 13:14:41.000000000,2023-04-17 13:29:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-17 13:14:41.000000000', 'files': ['plugins/modules/endpoint_group.py', 'ci/roles/vpn_service/tasks/main.yml', 'ci/roles/vpn_service/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c907cb8d066daca0f3fc7232099140b7a0cf529a', 'message': 'Vpn endpoint group module\n\nChange-Id: I29f9a8712ec0446cf530def6af7e9113ce15a896\n'}]",0,880628,c907cb8d066daca0f3fc7232099140b7a0cf529a,2,1,1,32787,,,0,"Vpn endpoint group module

Change-Id: I29f9a8712ec0446cf530def6af7e9113ce15a896
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/28/880628/1 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/endpoint_group.py', 'ci/roles/vpn_service/tasks/main.yml', 'ci/roles/vpn_service/defaults/main.yml']",3,c907cb8d066daca0f3fc7232099140b7a0cf529a,endpointgroup,,,213,0
openstack%2Foslo.db~master~I169aaf279f6abd675154bba6b16d040ae7b61028,openstack/oslo.db,master,I169aaf279f6abd675154bba6b16d040ae7b61028,Remove LegacyEngineFacade,NEW,2021-06-25 17:07:43.000000000,2023-04-17 13:20:41.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-06-25 17:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0822f93392292041b5c222d1fbddaaf7905453d6', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2021-07-28 14:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/40421a59aec1b427c200060623cbdf38adca9186', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2022-02-11 18:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/780b92d4293ccc7ed2233cb83f93eba3211bad15', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2022-02-11 18:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9f96343eba0807194399a0db1ce91f5381e6ac4a', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2022-07-20 14:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/57ba1c817c4eadea7e33e2ab4065b6edaddfe6ff', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2023-04-17 12:39:19.000000000', 'files': ['oslo_db/warning.py', 'oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/tests/sqlalchemy/test_utils.py', 'oslo_db/sqlalchemy/session.py', 'releasenotes/notes/remove-LegacyEngineFacade-cd1f4d8390be0d34.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c1309f0cdccfcc1b6710ecdbfaa049882642a6fe', 'message': ""Remove LegacyEngineFacade\n\nWe need to do this rather invasive change at some point. The\nLegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.\nIt's time to finally remove it, along with the helpers that generate\nsuch an object.\n\nThe 'OsloDBDeprecationWarning' exception is also removed. This could\npossibly do with a deprecation cycle, but a quick check of\ncodesearch.o.o suggests this was only ever used internally and can\ntherefore be removed with a minimum amount of noise.\n\nChange-Id: I169aaf279f6abd675154bba6b16d040ae7b61028\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",4,798135,c1309f0cdccfcc1b6710ecdbfaa049882642a6fe,18,2,6,15334,,,0,"Remove LegacyEngineFacade

We need to do this rather invasive change at some point. The
LegacyEngineFacade has been deprecated since 1.12.0 way back in 2015.
It's time to finally remove it, along with the helpers that generate
such an object.

The 'OsloDBDeprecationWarning' exception is also removed. This could
possibly do with a deprecation cycle, but a quick check of
codesearch.o.o suggests this was only ever used internally and can
therefore be removed with a minimum amount of noise.

Change-Id: I169aaf279f6abd675154bba6b16d040ae7b61028
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/35/798135/6 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/warning.py', 'oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/exception.py', 'oslo_db/tests/sqlalchemy/test_utils.py', 'oslo_db/sqlalchemy/session.py', 'releasenotes/notes/remove-LegacyEngineFacade-cd1f4d8390be0d34.yaml']",8,0822f93392292041b5c222d1fbddaaf7905453d6,cleanup,"--- upgrade: - | The ``oslo_db.sqlalchemy.enginefacade.LegacyEngineFacade`` class and related helpers, namely ``_TransactionFactory.get_legacy_facade``, ``_TransactionContextManager.get_legacy_facade`` and ``get_legacy_facade`` from the same module, have all been removed. The ``LegacyEngineFacade`` class has been deprecated since 1.12.0 in favour of using the ``oslo_db.sqlalchemy.enginefacade`` module directly. ",,15,424
openstack%2Fbarbican-ui~master~Ie29eb7779f8491dd5d47af9a1f205ccb793a216c,openstack/barbican-ui,master,Ie29eb7779f8491dd5d47af9a1f205ccb793a216c,Remove testing/support of Python 2,NEW,2022-05-22 13:37:17.000000000,2023-04-17 13:15:44.000000000,,"[{'_account_id': 22348}, {'_account_id': 32102}]","[{'number': 1, 'created': '2022-05-22 13:37:17.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican-ui/commit/7edf50eb0d8eddde2814bb661fc0f28e358098c0', 'message': 'Remove testing/support of Python 2\n\n... because Python 2 support was globally removed during Ussuri cycle.\n\nChange-Id: Ie29eb7779f8491dd5d47af9a1f205ccb793a216c\n'}]",0,842881,7edf50eb0d8eddde2814bb661fc0f28e358098c0,3,2,1,9816,,,0,"Remove testing/support of Python 2

... because Python 2 support was globally removed during Ussuri cycle.

Change-Id: Ie29eb7779f8491dd5d47af9a1f205ccb793a216c
",git fetch https://review.opendev.org/openstack/barbican-ui refs/changes/81/842881/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,7edf50eb0d8eddde2814bb661fc0f28e358098c0,,"envlist = pep8,py36-local,py3-dj111-local,eslint,karma-local,docs-local,releasenotes","envlist = pep8,py27-local,py36-local,py3-dj111-local,eslint,karma-local,docs-local,releasenotes# NOTE(shu-mutow): On CI infra, horizon will be installed # according to job setting. but on local, we need to install # horizon from master branch. [testenv:py27-local] basepython = python2.7 commands = {[testenv:hz-local]commands} {[testenv]commands} ",3,12
openstack%2Fheat-tempest-plugin~master~I1a44b65768cb862e10d013801dd47cb0510b2d07,openstack/heat-tempest-plugin,master,I1a44b65768cb862e10d013801dd47cb0510b2d07,Remove six,NEW,2022-05-09 15:51:40.000000000,2023-04-17 13:12:06.000000000,,"[{'_account_id': 22348}, {'_account_id': 32102}]","[{'number': 1, 'created': '2022-05-09 15:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/1bb471c10a5da50d90c044f61dae40bcb5632d35', 'message': 'Remove six\n\nThis library no longer supports Python 2, thus usage of six can be\nremoved.\n\nChange-Id: I1a44b65768cb862e10d013801dd47cb0510b2d07\n'}, {'number': 2, 'created': '2022-05-09 15:53:40.000000000', 'files': ['heat_tempest_plugin/tests/scenario/test_remote_deeply_nested.py', 'heat_tempest_plugin/tests/api/test_heat_api.py', 'heat_tempest_plugin/common/test.py', 'heat_tempest_plugin/tests/functional/test_template_validate.py', 'heat_tempest_plugin/tests/scenario/test_server_software_config.py', 'heat_tempest_plugin/common/remote_client.py', 'heat_tempest_plugin/tests/functional/test_remote_stack.py', 'heat_tempest_plugin/tests/scenario/test_volumes.py', 'heat_tempest_plugin/tests/functional/test_preview.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/dfb9739a8d9d87ea52ba97345cee093c9d0db0b8', 'message': 'Remove six\n\nPython 2 is no longer supported, thus usage of six can be removed.\n\nChange-Id: I1a44b65768cb862e10d013801dd47cb0510b2d07\n'}]",0,841136,dfb9739a8d9d87ea52ba97345cee093c9d0db0b8,4,2,2,9816,,,0,"Remove six

Python 2 is no longer supported, thus usage of six can be removed.

Change-Id: I1a44b65768cb862e10d013801dd47cb0510b2d07
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/36/841136/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat_tempest_plugin/tests/scenario/test_remote_deeply_nested.py', 'heat_tempest_plugin/tests/api/test_heat_api.py', 'heat_tempest_plugin/common/test.py', 'heat_tempest_plugin/tests/functional/test_template_validate.py', 'heat_tempest_plugin/tests/scenario/test_server_software_config.py', 'heat_tempest_plugin/common/remote_client.py', 'heat_tempest_plugin/tests/functional/test_remote_stack.py', 'heat_tempest_plugin/tests/functional/test_preview.py', 'heat_tempest_plugin/tests/scenario/test_volumes.py']",9,1bb471c10a5da50d90c044f61dae40bcb5632d35,remove-six," self.assertEqual(str(self.volume_size),","import six self.assertEqual(six.text_type(self.volume_size),",15,24
openstack%2Fkolla-ansible~master~I325523edc4f7e37db55a2e21fe52e76138e6d114,openstack/kolla-ansible,master,I325523edc4f7e37db55a2e21fe52e76138e6d114,Add support for ceilometer custom pipeline.yaml,MERGED,2019-05-22 09:39:47.000000000,2023-04-17 13:09:56.000000000,2019-06-03 19:35:55.000000000,"[{'_account_id': 1179}, {'_account_id': 4264}, {'_account_id': 6159}, {'_account_id': 12385}, {'_account_id': 14826}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22406}, {'_account_id': 22629}, {'_account_id': 23942}, {'_account_id': 24072}, {'_account_id': 24849}, {'_account_id': 27994}, {'_account_id': 28356}, {'_account_id': 28367}, {'_account_id': 29064}, {'_account_id': 33708}, {'_account_id': 35105}, {'_account_id': 35263}]","[{'number': 1, 'created': '2019-05-22 09:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c4b539a2e3587d1b6be695aa4ee94e12dafef06b', 'message': ""Add support for ceilometer custom pipeline.yaml\n\nThis file can be modified to adjust polling intervals or other configurations.\nWe can add a custom 'pipeline.yaml' file to override it.\n\nChange-Id: I325523edc4f7e37db55a2e21fe52e76138e6d114\nSigned-off-by: ZijianGuo <guozijn@gmail.com>\n""}, {'number': 2, 'created': '2019-05-22 09:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8c35a7b9265e92cbafb5d46c2ffe67ff3380ea44', 'message': ""Add support for ceilometer custom pipeline.yaml\n\nThis file can be modified to adjust polling intervals or other configurations.\nWe can add a custom 'pipeline.yaml' file to override it.\n\nChange-Id: I325523edc4f7e37db55a2e21fe52e76138e6d114\nSigned-off-by: ZijianGuo <guozijn@gmail.com>\n""}, {'number': 3, 'created': '2019-05-22 11:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/23ab48bdb38bf4bc5e6e0fad3d12f98722f84ce9', 'message': ""Add support for ceilometer custom pipeline.yaml\n\nThis file can be modified to adjust polling intervals or other configurations.\nWe can add a custom 'pipeline.yaml' file to override it.\n\nChange-Id: I325523edc4f7e37db55a2e21fe52e76138e6d114\nSigned-off-by: ZijianGuo <guozijn@gmail.com>\n""}, {'number': 4, 'created': '2019-05-23 09:58:36.000000000', 'files': ['ansible/roles/ceilometer/handlers/main.yml', 'ansible/roles/ceilometer/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c89b901524a7494180de1614a7b5e255589ecbb8', 'message': ""Add support for ceilometer custom pipeline.yaml\n\nThis file can be modified to adjust polling intervals or other configurations.\nWe can add a custom 'pipeline.yaml' file to override it.\n\nChange-Id: I325523edc4f7e37db55a2e21fe52e76138e6d114\nSigned-off-by: ZijianGuo <guozijn@gmail.com>\n""}]",6,660617,c89b901524a7494180de1614a7b5e255589ecbb8,28,19,4,28367,,,0,"Add support for ceilometer custom pipeline.yaml

This file can be modified to adjust polling intervals or other configurations.
We can add a custom 'pipeline.yaml' file to override it.

Change-Id: I325523edc4f7e37db55a2e21fe52e76138e6d114
Signed-off-by: ZijianGuo <guozijn@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/17/660617/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceilometer/handlers/main.yml', 'ansible/roles/ceilometer/tasks/config.yml']",2,c4b539a2e3587d1b6be695aa4ee94e12dafef06b,ceilometer-custom-pipeline,"- name: Check custom pipeline.yaml exists local_action: stat path=""{{ node_custom_config }}/ceilometer/pipeline.yaml"" register: ceilometer_pipeline_file - name: Copying over pipeline.yaml copy: src: ""{{ node_custom_config }}/ceilometer/pipeline.yaml"" dest: ""{{ node_config_directory }}/{{ item.key }}/pipeline.yaml"" force: True mode: ""0660"" become: true register: ceilometer_pipeline_overwriting when: - ceilometer_pipeline_file.stat.exists - inventory_hostname in groups[item.value.group] - item.value.enabled | bool with_dict: ""{{ ceilometer_services }}"" notify: - ""Restart {{ item.key }} container"" ",,28,0
openstack%2Fcharm-keystone-saml-mellon~master~Ib27d8d5cd14493a619c784a348cf14e424992053,openstack/charm-keystone-saml-mellon,master,Ib27d8d5cd14493a619c784a348cf14e424992053,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:52.000000000,2023-04-17 13:06:55.000000000,2023-04-17 13:06:55.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/51feacde272fa1dfd3ea81aa86fe90e87c8c2e81', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Ib27d8d5cd14493a619c784a348cf14e424992053\n'}, {'number': 2, 'created': '2023-04-14 15:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/f51892f383ebbfd6017c20eb95b446ed64ec4e9a', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: Ib27d8d5cd14493a619c784a348cf14e424992053\n'}, {'number': 3, 'created': '2023-04-14 18:54:36.000000000', 'files': ['charmcraft.yaml', 'src/tests/bundles/overlays/kinetic-zed.yaml.j2', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/579aaade7dbee1c57e6bb5da987a78f5a50e1781', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n* Add pkg-config to the charmcraft.yaml for builds. This\n  is required by rust to build cryptography.\n\nChange-Id: Ib27d8d5cd14493a619c784a348cf14e424992053\n'}]",4,878977,579aaade7dbee1c57e6bb5da987a78f5a50e1781,19,3,3,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython
* Add pkg-config to the charmcraft.yaml for builds. This
  is required by rust to build cryptography.

Change-Id: Ib27d8d5cd14493a619c784a348cf14e424992053
",git fetch https://review.opendev.org/openstack/charm-keystone-saml-mellon refs/changes/77/878977/3 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/overlays/kinetic-zed.yaml.j2', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",3,51feacde272fa1dfd3ea81aa86fe90e87c8c2e81,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': '11': '12': '13': '14': '15': '16': '17': '18': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge openstack-dashboard-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge cinder-mysql-router: charm: ch:mysql-router channel: latest/edge vault-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge cinder: num_units: 1 charm: ch:cinder options: openstack-origin: *openstack-origin glance-api-version: 2 block-device: None to: - '3' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin to: - '4' channel: latest/edge keystone: charm: ch:keystone num_units: 3 options: openstack-origin: *openstack-origin token-provider: 'fernet' to: - '5' - '6' - '7' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: openstack-origin: *openstack-origin manage-neutron-plugin-legacy-mode: true flat-network-providers: physnet1 neutron-security-groups: true to: - '8' channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: openstack-origin: *openstack-origin bridge-mappings: physnet1:br-ex to: - '9' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch num_units: 0 channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: openstack-origin: *openstack-origin network-manager: Neutron to: - '10' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 2 options: openstack-origin: *openstack-origin config-flags: default_ephemeral_format=ext4 enable-live-migration: true enable-resize: true migration-auth-type: ssh to: - '11' - '12' channel: latest/edge openstack-dashboard: charm: ch:openstack-dashboard num_units: 3 options: openstack-origin: *openstack-origin to: - '13' - '14' - '15' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '16' channel: latest/edge vault: num_units: 1 charm: ch:vault to: - '17' channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin to: - '18' channel: latest/edge keystone-saml-mellon1: charm: ../../../keystone-saml-mellon_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm num_units: 0 options: idp-name: 'test-saml-idp1' protocol-name: 'mapped' user-facing-name: ""Test SAML IDP #1"" subject-confirmation-data-address-check: False nameid-formats: ""urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"" test-saml-idp1: charm: ch:ionutbalutoiu-test-saml-idp num_units: 1 series: focal options: idp-name: 'test-saml-idp1' protocol-name: 'mapped' auth-user-name: 'user1' auth-user-password: 'userpass1' keystone-saml-mellon2: charm: ../../../keystone-saml-mellon_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm num_units: 0 options: idp-name: 'test-saml-idp2' protocol-name: 'mapped' user-facing-name: ""Test SAML IDP #2"" subject-confirmation-data-address-check: False nameid-formats: ""urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress"" test-saml-idp2: charm: ch:ionutbalutoiu-test-saml-idp num_units: 1 series: focal options: idp-name: 'test-saml-idp2' protocol-name: 'mapped' auth-user-name: 'user2' auth-user-password: 'userpass2' keystone-hacluster: charm: ch:hacluster num_units: 0 options: corosync_transport: unicast cluster_count: 3 channel: latest/edge openstack-dashboard-hacluster: charm: ch:hacluster num_units: 0 options: corosync_transport: unicast cluster_count: 3 channel: latest/edge relations: - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'glance:identity-service' - 'keystone:identity-service' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'neutron-openvswitch:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'openstack-dashboard:identity-service' - 'keystone:identity-service' - - 'openstack-dashboard:shared-db' - 'openstack-dashboard-mysql-router:shared-db' - - 'openstack-dashboard-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:neutron-api' - 'neutron-api:neutron-api' - - 'cinder:image-service' - 'glance:image-service' - - 'cinder:amqp' - 'rabbitmq-server:amqp' - - 'cinder:identity-service' - 'keystone:identity-service' - - 'cinder:cinder-volume-service' - 'nova-cloud-controller:cinder-volume-service' - - 'cinder:shared-db' - 'cinder-mysql-router:shared-db' - - 'cinder-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'keystone' - 'keystone-saml-mellon1' - - 'keystone' - 'keystone-saml-mellon2' - - 'vault:shared-db' - 'vault-mysql-router:shared-db' - - 'vault-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'vault:certificates' - 'keystone:certificates' - - 'vault:certificates' - 'glance:certificates' - - 'vault:certificates' - 'openstack-dashboard:certificates' - - 'openstack-dashboard' - 'keystone-saml-mellon1' - - 'openstack-dashboard' - 'keystone-saml-mellon2' - - 'keystone:websso-trusted-dashboard' - 'openstack-dashboard:websso-trusted-dashboard' - - 'vault:certificates' - 'cinder:certificates' - - 'vault:certificates' - 'neutron-api:certificates' - - 'vault:certificates' - 'nova-cloud-controller:certificates' - - 'placement:identity-service' - 'keystone:identity-service' - - 'placement:placement' - 'nova-cloud-controller:placement' - - 'vault:certificates' - 'placement:certificates' - - ""placement:shared-db"" - ""placement-mysql-router:shared-db"" - - ""placement-mysql-router:db-router"" - ""mysql-innodb-cluster:db-router"" - - ""keystone:ha"" - ""keystone-hacluster:ha"" - - ""openstack-dashboard:ha"" - ""openstack-dashboard-hacluster:ha"" ",0,399
openstack%2Fcharm-nova-cell-controller~master~I83b97c35b6e64050feaa94a2eee2b80fa49c2555,openstack/charm-nova-cell-controller,master,I83b97c35b6e64050feaa94a2eee2b80fa49c2555,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:10:52.000000000,2023-04-17 13:05:06.000000000,2023-04-17 13:05:06.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cell-controller/commit/7ae0b13acad179e3023cd8ebb390b3a1daf2cc0e', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I83b97c35b6e64050feaa94a2eee2b80fa49c2555\n'}, {'number': 2, 'created': '2023-04-14 14:59:26.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cell-controller/commit/ea96987f114be44d5d0fac2fb80692245b601ee7', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: I83b97c35b6e64050feaa94a2eee2b80fa49c2555\n'}]",4,878993,ea96987f114be44d5d0fac2fb80692245b601ee7,16,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: I83b97c35b6e64050feaa94a2eee2b80fa49c2555
",git fetch https://review.opendev.org/openstack/charm-nova-cell-controller refs/changes/93/878993/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,7ae0b13acad179e3023cd8ebb390b3a1daf2cc0e,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: virt-type=kvm mem=3072M '1': constraints: virt-type=kvm mem=3072M '2': constraints: virt-type=kvm mem=3072M '3': constraints: virt-type=kvm mem=3072M '4': constraints: virt-type=kvm mem=3072M '5': constraints: virt-type=kvm mem=3072M '6': '7': '8': '9': '10': '11': '12': constraints: mem=4096M '13': '14': '15': '16': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cell-controller-cell2-mysql-router: charm: ch:mysql-router options: base-port: 3316 channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge mysql-innodb-cluster-cell2: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '3' - '4' - '5' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '6' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: admin-password: openstack openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '7' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs flat-network-providers: physnet1 neutron-security-groups: true openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '8' channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: bridge-mappings: physnet1:br-ex openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '9' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch num_units: 0 channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: *openstack-origin worker-multiplier: 0.25 debug: true to: - '10' channel: latest/edge nova-cell-controller-cell2: charm: ../../../nova-cell-controller.charm num_units: 1 options: openstack-origin: *openstack-origin worker-multiplier: 0.25 debug: true cell-name: ""cell2"" to: - '11' nova-compute-cell2: charm: ch:nova-compute num_units: 1 storage: ephemeral-device: '40G' options: enable-live-migration: true enable-resize: true migration-auth-type: ssh openstack-origin: *openstack-origin debug: true to: - '12' channel: latest/edge rabbitmq-server-nova: charm: ch:rabbitmq-server num_units: 1 to: - '13' channel: latest/edge rabbitmq-server-nova-cell2: charm: ch:rabbitmq-server num_units: 1 to: - '14' channel: latest/edge rabbitmq-server-neutron: charm: ch:rabbitmq-server num_units: 1 to: - '15' channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin debug: true to: - '16' channel: latest/edge relations: - - 'nova-cloud-controller:nova-cell-api' - 'nova-cell-controller-cell2:nova-cell-compute' - - 'nova-cloud-controller:shared-db-cell' - 'nova-cell-controller-cell2-mysql-router:shared-db' - - 'nova-cloud-controller:amqp-cell' - 'rabbitmq-server-nova-cell2:amqp' - - 'nova-compute-cell2:amqp' - 'rabbitmq-server-nova-cell2:amqp' - - 'neutron-gateway:amqp' - 'rabbitmq-server-neutron:amqp' - - 'neutron-gateway:amqp-nova' - 'rabbitmq-server-nova:amqp' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'glance:identity-service' - 'keystone:identity-service' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'neutron-openvswitch:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server-neutron:amqp' - - 'neutron-gateway:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server-neutron:amqp' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-compute-cell2:image-service' - 'glance:image-service' - - 'nova-cell-controller-cell2:cloud-compute' - 'nova-compute-cell2:cloud-compute' - - 'nova-cell-controller-cell2:identity-credentials' - 'keystone:identity-credentials' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server-nova:amqp' - - 'nova-cell-controller-cell2:amqp' - 'rabbitmq-server-nova-cell2:amqp' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'nova-compute-cell2:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server-neutron:amqp' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cell-controller-cell2:shared-db' - 'nova-cell-controller-cell2-mysql-router:shared-db' - - 'nova-cell-controller-cell2-mysql-router:db-router' - 'mysql-innodb-cluster-cell2:db-router' - - 'nova-cloud-controller:neutron-api' - 'neutron-api:neutron-api' - - 'nova-compute-cell2:cloud-credentials' - 'keystone:identity-credentials' - - 'placement:identity-service' - 'keystone:identity-service' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:placement' - 'placement:placement' ",0,312
openstack%2Foslo.db~master~I470df5fa3adf43bb17a036f8f791aa529b8aa1f5,openstack/oslo.db,master,I470df5fa3adf43bb17a036f8f791aa529b8aa1f5,Implement connection_pre_ping option,ABANDONED,2022-03-14 13:01:52.000000000,2023-04-17 12:57:54.000000000,,"[{'_account_id': 11816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-03-14 13:01:52.000000000', 'files': ['oslo_db/options.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/sqlalchemy/engines.py', 'releasenotes/notes/connection_pre_ping-92d05f896c070efd.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7d50883e998f89fe75aee95127d8e858b8295093', 'message': ""Implement connection_pre_ping option\n\nIn order to control pool_pre_ping in SQLAlchemy that has been introduced\nin SQLAlchemy 1.2, we add option  connection_pre_ping since it's applied\nduring connection to engine.\n\nChange-Id: I470df5fa3adf43bb17a036f8f791aa529b8aa1f5\n""}]",5,833623,7d50883e998f89fe75aee95127d8e858b8295093,7,3,1,28619,,,0,"Implement connection_pre_ping option

In order to control pool_pre_ping in SQLAlchemy that has been introduced
in SQLAlchemy 1.2, we add option  connection_pre_ping since it's applied
during connection to engine.

Change-Id: I470df5fa3adf43bb17a036f8f791aa529b8aa1f5
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/23/833623/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/options.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/sqlalchemy/engines.py', 'releasenotes/notes/connection_pre_ping-92d05f896c070efd.yaml']",5,7d50883e998f89fe75aee95127d8e858b8295093,,--- features: - | Adds new option ``connection_pre_ping`` that controls SQLAlchemy pool_pre_ping. This is useful to enable to ensure that stale connection won't be used for running request. Please reffer to `SQLAlchemy doc <https://docs.sqlalchemy.org/en/14/core/pooling.html#disconnect-handling-pessimistic>` for more details on this option. ,,25,1
openstack%2Ftripleo-heat-templates~stable%2Fzed~If72ee0c1615efa7107a334e44ddd19d638178ce7,openstack/tripleo-heat-templates,stable/zed,If72ee0c1615efa7107a334e44ddd19d638178ce7,Remove external from KeystoneAuthMethods,NEW,2023-03-23 13:23:49.000000000,2023-04-17 12:51:15.000000000,,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-03-23 13:23:49.000000000', 'files': ['environments/enable-federation-openidc.yaml', 'sample-env-generator/openidc.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7498f1e2d8f0cf736392dab21101c463b436faf5', 'message': 'Remove external from KeystoneAuthMethods\n\nExternal is not compatable with federated authentication\n\nChange-Id: If72ee0c1615efa7107a334e44ddd19d638178ce7\n(cherry picked from commit 67f47c0d79ceb57a2a60c500a5dd3f8dd4316555)\n'}]",0,878342,7498f1e2d8f0cf736392dab21101c463b436faf5,2,4,1,7414,,,0,"Remove external from KeystoneAuthMethods

External is not compatable with federated authentication

Change-Id: If72ee0c1615efa7107a334e44ddd19d638178ce7
(cherry picked from commit 67f47c0d79ceb57a2a60c500a5dd3f8dd4316555)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/878342/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/enable-federation-openidc.yaml', 'sample-env-generator/openidc.yaml']",2,7498f1e2d8f0cf736392dab21101c463b436faf5,add_oidc_parameters-stable/zed," KeystoneAuthMethods: password,token,oauth1,mapped,application_credential,openid"," KeystoneAuthMethods: external,password,token,oauth1,mapped,application_credential,openid",2,2
openstack%2Foctavia~stable%2Fxena~I02804b7075edac72776b0377b7b283d0c7bfd8a2,openstack/octavia,stable/xena,I02804b7075edac72776b0377b7b283d0c7bfd8a2,Fix failover when the last listener is deleted,NEW,2023-04-14 06:48:58.000000000,2023-04-17 12:16:40.000000000,,"[{'_account_id': 22348}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-04-14 06:48:58.000000000', 'files': ['octavia/amphorae/backends/health_daemon/health_daemon.py', 'releasenotes/notes/Fix-listener-delete-causing-failover-251efdb79af24c0a.yaml', 'octavia/tests/unit/amphorae/backends/health_daemon/test_health_daemon.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/c58f2cb591055f5968f92d762abcd5005e68e324', 'message': 'Fix failover when the last listener is deleted\n\nThis patch fixes an issue when deleting the last listener from a load balancer\nmay trigger a failover.\n\nStory: 2010652\nTask: 47683\nChange-Id: I02804b7075edac72776b0377b7b283d0c7bfd8a2\n(cherry picked from commit ba92aeb946343c045e8363a2aae78e0a17a6cb82)\n(cherry picked from commit e7f4b1b4c21d0a2b12022032caa38602f5341a20)\n(cherry picked from commit 658173e5b7f5dcbe5e309801b7d8488442f858e4)\n(cherry picked from commit 4e15e81208e198553163ff01e90a47ae0d481ced)\n'}]",0,880454,c58f2cb591055f5968f92d762abcd5005e68e324,3,2,1,29244,,,0,"Fix failover when the last listener is deleted

This patch fixes an issue when deleting the last listener from a load balancer
may trigger a failover.

Story: 2010652
Task: 47683
Change-Id: I02804b7075edac72776b0377b7b283d0c7bfd8a2
(cherry picked from commit ba92aeb946343c045e8363a2aae78e0a17a6cb82)
(cherry picked from commit e7f4b1b4c21d0a2b12022032caa38602f5341a20)
(cherry picked from commit 658173e5b7f5dcbe5e309801b7d8488442f858e4)
(cherry picked from commit 4e15e81208e198553163ff01e90a47ae0d481ced)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/54/880454/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/health_daemon/health_daemon.py', 'releasenotes/notes/Fix-listener-delete-causing-failover-251efdb79af24c0a.yaml', 'octavia/tests/unit/amphorae/backends/health_daemon/test_health_daemon.py']",3,c58f2cb591055f5968f92d762abcd5005e68e324,," @mock.patch('octavia.amphorae.backends.utils.haproxy_query.HAProxyQuery') def test_get_stats_exception(self, mock_query): mock_query.side_effect = Exception('Boom') stats, pool_status = health_daemon.get_stats('TEST') self.assertEqual([], stats) self.assertEqual({}, pool_status) ",,22,3
openstack%2Fvalidations-libs~master~Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003,openstack/validations-libs,master,Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003,DNM Expanding validation discovery mechanism to other locations,ABANDONED,2023-01-27 15:47:26.000000000,2023-04-17 12:03:34.000000000,,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 35199}]","[{'number': 1, 'created': '2023-01-27 15:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/f1e1cd357d6a878e88920d7b3b3f395c062000eb', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 2, 'created': '2023-01-31 09:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/bb579a1c63f66d7f214a30fef7e633601ad9458f', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 3, 'created': '2023-01-31 11:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/7667413dc4fffba4808357791826a05caa5f802a', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 4, 'created': '2023-01-31 15:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/b357f50eba7d7b36bab069d8b2c64b80d30a33f6', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 5, 'created': '2023-01-31 15:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/e6dcd3f49475b40597868516681af68d58999b26', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 6, 'created': '2023-01-31 15:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/ec9156e7f43264d18dc8685756cfa30657d98d39', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 7, 'created': '2023-02-01 15:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/f49b52e346def9fda8943bfae44d3eef5601c078', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 8, 'created': '2023-02-02 09:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/e44d222ea3a0cfc00d674fe202f2efa0da305b99', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 9, 'created': '2023-02-02 10:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/30d9797046f7b5b8f29b803e77550ee4cf57039c', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 10, 'created': '2023-02-02 12:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/60d808402c070af1a48b00b765c70df65e967a1b', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 11, 'created': '2023-02-02 15:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/3c9537075d90c488e9fb18809c496147bc3c368e', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 12, 'created': '2023-02-07 10:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/b0b668347ed54b628315f4b00ffededad184d4c7', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 13, 'created': '2023-02-07 15:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/0f037eafe6565d3bfc4046d036043bb7aaf2fd4c', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 14, 'created': '2023-02-08 09:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/b347b915ae82b4be0b8f6250146416658814da58', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 15, 'created': '2023-02-08 10:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/172a79e0fc283bbda6ec6606289b8b49e10b3039', 'message': 'DNM First steps towards new validations\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n'}, {'number': 16, 'created': '2023-02-09 12:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/c5dea573089ab92f6f5427196ee2b4932251d36f', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}, {'number': 17, 'created': '2023-02-09 12:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/637ff06fad68d8925f08c835e118fddb680d2fbf', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}, {'number': 18, 'created': '2023-02-09 12:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/4289c671cd128eb44191616e2f0920415aa3eb2e', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}, {'number': 19, 'created': '2023-02-09 12:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/0f27663a89d7988ea538a915e96d9502c7648e0d', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}, {'number': 20, 'created': '2023-02-09 15:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/2f99f8391feb5da03ea1f0176ba2a74239112431', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nUnit tests now have additional mocks to cover IO, pathlib mocks in `test_utils`\nand `test_init_validation` modules were simplified as they no longer need to consider\nrestrictions of older library versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}, {'number': 21, 'created': '2023-02-20 09:27:11.000000000', 'files': ['validations_libs/tests/cli/test_list.py', 'validations_libs/tests/cli/test_show.py', 'validations_libs/ansible.py', 'validations_libs/cli/lister.py', 'validations_libs/community/init_validation.py', 'validations_libs/tests/community/test_init_validation.py', 'validations_libs/exceptions.py', 'validations_libs/validation.py', 'validations_libs/cli/community.py', 'validations_libs/tests/test_utils.py', 'validations_libs/constants.py', 'validations_libs/validation_actions.py', 'validations_libs/tests/cli/test_file.py', 'validations_libs/tests/test_validation.py', 'validations_libs/cli/run.py', 'validations_libs/tests/cli/test_community.py', 'validations_libs/cli/show.py', 'validations_libs/tests/fakes.py', 'validations_libs/utils.py', 'validations_libs/tests/test_validation_actions.py'], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/42c5e7c04f252e3917cbdd8dd889566bfd015ce8', 'message': ""DNM Expanding validation discovery mechanism to other locations\n\nRuntime will now search additional locations for validation playbooks,\nincluding standard ansible system paths for collections.\n\nValidation playbooks will now only be accepted by the runtime\nif they contain a valid metadata dictionary. All other playbooks will be ignored.\nRedundant playbook parsing calls were eliminated.\n\nPlaybook existence check during community validation init has been simplified.\n\nNew `ValidationParsingException` has been introduced to provide more accurate\ninformation about failures during parsing of validation playbooks.\n\nChecks for Python<3.0 in `test_utils.py` were removed, as the package isn't\nmeant to be compatible with these versions.\n\nUnit tests now have additional mocks to cover IO, pathlib mocks in `test_utils`\nand `test_init_validation` modules were simplified as they no longer need to consider\nrestrictions of older library versions.\n\nWarning:\n  This patch makes substantial changes to the API of validations-libs,\n  posssibly of the breaking kind.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003\n""}]",1,872025,42c5e7c04f252e3917cbdd8dd889566bfd015ce8,37,4,21,32926,,,0,"DNM Expanding validation discovery mechanism to other locations

Runtime will now search additional locations for validation playbooks,
including standard ansible system paths for collections.

Validation playbooks will now only be accepted by the runtime
if they contain a valid metadata dictionary. All other playbooks will be ignored.
Redundant playbook parsing calls were eliminated.

Playbook existence check during community validation init has been simplified.

New `ValidationParsingException` has been introduced to provide more accurate
information about failures during parsing of validation playbooks.

Checks for Python<3.0 in `test_utils.py` were removed, as the package isn't
meant to be compatible with these versions.

Unit tests now have additional mocks to cover IO, pathlib mocks in `test_utils`
and `test_init_validation` modules were simplified as they no longer need to consider
restrictions of older library versions.

Warning:
  This patch makes substantial changes to the API of validations-libs,
  posssibly of the breaking kind.

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: Id7eaebc7bd9a4a80d09f9c98ca6fb58173488003
",git fetch https://review.opendev.org/openstack/validations-libs refs/changes/25/872025/14 && git format-patch -1 --stdout FETCH_HEAD,"['validations_libs/tests/test_utils.py', 'validations_libs/constants.py', 'validations_libs/tests/test_validation.py', 'validations_libs/utils.py', 'validations_libs/exceptions.py', 'validations_libs/validation.py']",6,f1e1cd357d6a878e88920d7b3b3f395c062000eb,context-aware-playbook-discovery-patch3,"import validations_libs.exceptions as exceptions if not self.has_metadata_dict: raise exceptions.ValidationParsingException( ""No metadata found in validation {}"".format(validation_path)) :rtype: `list` return self.dict['vars']['metadata'].get('groups', []) :rtype: `list` return self.dict['vars']['metadata'].get('categories', []) :rtype: `list` return self.dict['vars']['metadata'].get('products', [])"," :rtype: `list` or `None` if no metadata has been found :raise: A `NameError` exception if no metadata has been found in the playbook if self.has_metadata_dict: return self.dict['vars']['metadata'].get('groups', []) else: raise NameError( ""No metadata found in validation {}"".format(self.id) ) :rtype: `list` or `None` if no metadata has been found :raise: A `NameError` exception if no metadata has been found in the playbook if self.has_metadata_dict: return self.dict['vars']['metadata'].get('categories', []) else: raise NameError( ""No metadata found in validation {}"".format(self.id) ) :rtype: `list` or `None` if no metadata has been found :raise: A `NameError` exception if no metadata has been found in the playbook if self.has_metadata_dict: return self.dict['vars']['metadata'].get('products', []) else: raise NameError( ""No metadata found in validation {}"".format(self.id) ) :raise: A `NameError` exception if no metadata has been found in the playbook",50,80
openstack%2Fneutron~master~I0250062d22ac9729497d11832e3d67ac3b2a86df,openstack/neutron,master,I0250062d22ac9729497d11832e3d67ac3b2a86df,Fix network_segment_range unit tests module,MERGED,2023-04-17 09:39:01.000000000,2023-04-17 11:57:31.000000000,2023-04-17 11:56:15.000000000,"[{'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-17 09:39:01.000000000', 'files': ['neutron/tests/unit/extensions/test_network_segment_range.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/28961c8b76a4b09412825231a3f69374b183aefd', 'message': ""Fix network_segment_range unit tests module\n\nThis module needs to ensure that common config options (service_plugins\noption especially) is registered. Otherwise this test module can't be\nsuccessfully run without other tests as it was then failing due to\nunregistered config option.\n\nTrivial-fix\n\nChange-Id: I0250062d22ac9729497d11832e3d67ac3b2a86df\n""}]",0,880616,28961c8b76a4b09412825231a3f69374b183aefd,10,4,1,11975,,,0,"Fix network_segment_range unit tests module

This module needs to ensure that common config options (service_plugins
option especially) is registered. Otherwise this test module can't be
successfully run without other tests as it was then failing due to
unregistered config option.

Trivial-fix

Change-Id: I0250062d22ac9729497d11832e3d67ac3b2a86df
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/880616/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/extensions/test_network_segment_range.py'],1,28961c8b76a4b09412825231a3f69374b183aefd,secure-rbac,from neutron.common import config config.register_common_config_options(),,2,0
openstack%2Fpuppet-nova~master~I562d19299e0377e02f2587f5ef36d35069b5a5cd,openstack/puppet-nova,master,I562d19299e0377e02f2587f5ef36d35069b5a5cd,Add native resource type for qemu.conf,MERGED,2023-04-03 15:51:15.000000000,2023-04-17 11:36:40.000000000,2023-04-17 11:35:46.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-03 15:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/fc170d484958855b18ed6b19d94c4d07d91012e8', 'message': 'WIP: Add native resource type for qemu.conf\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 2, 'created': '2023-04-03 16:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ebdc72214046dcb861a6e65aed86f820ec943618', 'message': 'WIP: Add native resource type for qemu.conf\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 3, 'created': '2023-04-03 16:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/280c21099f0cb3b41165261838a6fb4a30e1ae1a', 'message': 'WIP: Add native resource type for qemu.conf\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 4, 'created': '2023-04-03 16:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/162f30920c02437535bd95b570880f8f0bab4bd2', 'message': 'WIP: Add native resource type for qemu.conf\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 5, 'created': '2023-04-03 17:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1d587a91c6d7ee0c14fd1f5eeb7c16ad6427e99f', 'message': 'Add native resource type for qemu.conf\n\nThis introduces the native resource type to manipulate qemu.conf, so\nthat we can define the resources in the same way for all libvirt\nconfig files.\n\nThis also updates all libvirt config resource types to convert boolean\nvalues automatically, because libvirt does not support raw boolean\nvalues and the values should be converted to 1/0.\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 6, 'created': '2023-04-03 18:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a6b65b5905dac5904cb61a6a6b973db820cfcc9e', 'message': 'Add native resource type for qemu.conf\n\nThis introduces the native resource type to manipulate qemu.conf, so\nthat we can define the resources in the same way for all libvirt\nconfig files.\n\nThis also updates all libvirt config resource types to convert boolean\nvalues automatically, because libvirt does not support raw boolean\nvalues and the values should be converted to 1/0.\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 7, 'created': '2023-04-03 18:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/66c559a36aa71f5760a99b8161d13b09ed0cdcf8', 'message': 'Add native resource type for qemu.conf\n\nThis introduces the native resource type to manipulate qemu.conf, so\nthat we can define the resources in the same way for all libvirt\nconfig files.\n\nThis also updates all libvirt config resource types to convert boolean\nvalues automatically, because libvirt does not support raw boolean\nvalues and the values should be converted to 1/0.\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}, {'number': 8, 'created': '2023-04-04 01:27:42.000000000', 'files': ['lib/puppet/type/virtstoraged_config.rb', 'spec/unit/type/libvirtd_config_spec.rb', 'lib/puppet/type/qemu_config.rb', 'releasenotes/notes/qemu_config-9c7a99cf69972152.yaml', 'lib/puppet/provider/qemu_config/ini_setting.rb', 'spec/unit/type/virtlogd_config_spec.rb', 'lib/puppet/type/virtproxyd_config.rb', 'manifests/migration/qemu.pp', 'manifests/compute/libvirt/config.pp', 'manifests/deps.pp', 'lib/puppet/type/virtnodedevd_config.rb', 'spec/unit/type/virtsecretd_config_spec.rb', 'lib/puppet/type/virtsecretd_config.rb', 'spec/unit/type/virtlockd_config_spec.rb', 'spec/unit/type/qemu_config_spec.rb', 'lib/puppet/type/virtlogd_config.rb', 'lib/puppet/type/libvirtd_config.rb', 'spec/unit/type/virtnodedevd_config_spec.rb', 'spec/unit/type/virtproxyd_config_spec.rb', 'lib/puppet/type/virtqemud_config.rb', 'spec/classes/nova_migration_qemu_spec.rb', 'lib/puppet/type/virtlockd_config.rb', 'manifests/compute/libvirt/qemu.pp', 'spec/classes/nova_compute_libvirt_qemu_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/06875a6c739738fe70cd072f3078ea2dc6ec8b86', 'message': 'Add native resource type for qemu.conf\n\nThis introduces the native resource type to manipulate qemu.conf, so\nthat we can define the resources in the same way for all libvirt\nconfig files.\n\nThis also updates all libvirt config resource types to convert boolean\nvalues automatically, because libvirt does not support raw boolean\nvalues and the values should be converted to 1/0.\n\nChange-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd\n'}]",2,879360,06875a6c739738fe70cd072f3078ea2dc6ec8b86,26,4,8,9816,,,0,"Add native resource type for qemu.conf

This introduces the native resource type to manipulate qemu.conf, so
that we can define the resources in the same way for all libvirt
config files.

This also updates all libvirt config resource types to convert boolean
values automatically, because libvirt does not support raw boolean
values and the values should be converted to 1/0.

Change-Id: I562d19299e0377e02f2587f5ef36d35069b5a5cd
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/60/879360/8 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/migration/qemu.pp', 'spec/unit/type/qemu_config_spec.rb', 'manifests/compute/libvirt/config.pp', 'lib/puppet/type/qemu_config.rb', 'manifests/deps.pp', 'spec/classes/nova_migration_qemu_spec.rb', 'manifests/compute/libvirt/qemu.pp', 'spec/classes/nova_compute_libvirt_qemu_spec.rb', 'lib/puppet/provider/qemu_config/ini_setting.rb']",9,fc170d484958855b18ed6b19d94c4d07d91012e8,qemu-conf,"Puppet::Type.type(:qemu_config).provide( :ini_setting, :parent => Puppet::Type.type(:libvirtd_config).provider(:ini_setting) ) do def self.file_path '/etc/libvirt/qemu.conf' end end ",,199,248
openstack%2Ftooz~master~I01aaff4af34b89fe82d985276ba356ce85a910de,openstack/tooz,master,I01aaff4af34b89fe82d985276ba356ce85a910de,Fix mysql timeout,MERGED,2022-11-23 00:02:23.000000000,2023-04-17 11:36:08.000000000,2023-04-17 11:35:08.000000000,"[{'_account_id': 15334}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-23 00:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/10a429eb91fe5263f2cb5eb42fec43c066e5b6bb', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 2, 'created': '2022-11-23 14:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/7171437cdc79988a06117333e883db2053852ad1', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 3, 'created': '2023-01-04 17:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/7640634b654b1c8f5b98bf670eaf4b973a6c9714', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 4, 'created': '2023-01-18 09:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/69c2a057b8b44db6fc2ee59ec2151cf2fefd9b1e', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 5, 'created': '2023-03-29 06:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/b18715e44ad849220ecb8a058fd007c502058889', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hours.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 6, 'created': '2023-03-29 07:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/f3d7c26938b4549f749d24d873e80563a1978958', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}, {'number': 7, 'created': '2023-04-14 06:04:08.000000000', 'files': ['tooz/drivers/mysql.py', 'tooz/tests/test_mysql.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/db64c2175c01f896f40ee2aa420cbb58ce30e4dd', 'message': 'Fix mysql timeout\n\nmysql should support customize timeout when acquire lock.\nCurently we only put 0, which will lead to in crush cases,\nlock might releases after mysql socket timeout, which is long hrs.\n\nChange-Id: I01aaff4af34b89fe82d985276ba356ce85a910de\n'}]",6,865352,db64c2175c01f896f40ee2aa420cbb58ce30e4dd,25,4,7,12404,,,0,"Fix mysql timeout

mysql should support customize timeout when acquire lock.
Curently we only put 0, which will lead to in crush cases,
lock might releases after mysql socket timeout, which is long hrs.

Change-Id: I01aaff4af34b89fe82d985276ba356ce85a910de
",git fetch https://review.opendev.org/openstack/tooz refs/changes/52/865352/7 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/mysql.py'],1,10a429eb91fe5263f2cb5eb42fec43c066e5b6bb,support-mysql-timeout," blocking, timeout = utils.convert_blocking(blocking) cur.execute( ""SELECT GET_LOCK(%s, %s);"", self.name, timeout if timeout is not None else 0 )"," cur.execute(""SELECT GET_LOCK(%s, 0);"", self.name)",6,1
openstack%2Foslo.utils~master~I1f88bdadc68bfa726eac1da1c5824c1ed352ad98,openstack/oslo.utils,master,I1f88bdadc68bfa726eac1da1c5824c1ed352ad98,Implement zoneinfo support to drop dependency to pytz,MERGED,2023-02-07 09:43:34.000000000,2023-04-17 11:27:44.000000000,2023-04-17 11:26:34.000000000,"[{'_account_id': 9816}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-02-07 09:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f9666daf0e3b8a788ebf368d3a5f6482c859cbed', 'message': 'Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n'}, {'number': 2, 'created': '2023-02-08 09:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/7cd30edc9166301636ca11de73b5739949a0da6f', 'message': 'Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required by our gates.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n'}, {'number': 3, 'created': '2023-02-08 09:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/39308cd049e71da68bec69b4d85a9471b9d8cffc', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required by our gates because by default, zoneinfo uses the\nsystem’s time zone data if available; if no system time zone data is\navailable, the library will fall back to using the first-party tzdata\npackage available on PyPI.. Apparently our gates have no time zone\ndata available because we get the following error without tzdata\ninstalled [3]:\n\n`ModuleNotFoundError: No module named 'tzdata'\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n""}, {'number': 4, 'created': '2023-02-08 13:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/bea402e074c65974a0bb18bb451593cefb718558', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n""}, {'number': 5, 'created': '2023-02-28 12:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/41e1c1afa25040b1dc5aacaed57b7f736480c79b', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n""}, {'number': 6, 'created': '2023-03-01 11:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/df1f4d42ea1723093770b9401cd3efb9e6906f54', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nDepends-on: https://review.opendev.org/c/openstack/requirements/+/875854\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n""}, {'number': 7, 'created': '2023-03-23 16:13:52.000000000', 'files': ['requirements.txt', 'oslo_utils/timeutils.py', 'releasenotes/notes/implement-zoneinfo-to-remove-pytz-fba6f70db09ecdb8.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/7d9fda625fd5e16c91a9b95920c477f857193389', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nDepends-on: https://review.opendev.org/c/openstack/requirements/+/875854\nChange-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98\n""}]",6,872862,7d9fda625fd5e16c91a9b95920c477f857193389,29,4,7,28522,,,0,"Implement zoneinfo support to drop dependency to pytz

Zoneinfo was introduced within python 3.9.

The support of pytz will be removed within RHEL 10 [1].

2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10
so we want to see pytz removed within this series.

tzdata is required at runtime in our gates, because, by default,
zoneinfo uses the system’s time zone data if available; if no system
time zone data is available, the library will fall back to using the
first-party tzdata package available on PyPI. Apparently our gates have no
time zone data available nor tzdata installed by default because we get the
following error without tzdata installed [3]:
`ModuleNotFoundError: No module named 'tzdata'

So I prefer to add tzdata in our requirements to avoid runtime failure
related to time zone and ensure that time zone are always available.

[1] https://issues.redhat.com/browse/RHEL-219
[2] https://review.opendev.org/c/openstack/governance/+/872232
[3] https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`

Depends-on: https://review.opendev.org/c/openstack/requirements/+/875854
Change-Id: I1f88bdadc68bfa726eac1da1c5824c1ed352ad98
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/62/872862/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_utils/timeutils.py', 'releasenotes/notes/implement-zoneinfo-to-remove-pytz-fba6f70db09ecdb8.yaml']",3,f9666daf0e3b8a788ebf368d3a5f6482c859cbed,remove-pytz,"--- other: - | Implement zoneinfo to allow us to remove pytz's dependency. zoneinfo was introduced by python 3.9, and the series 2023.2 (bobcat) set py39 as the minimal supported runtime, so we are able to remove pytz. ",,9,4
openstack%2Foslo.serialization~master~I8d87d54f6f5ded8caee6cb780bacb39afea0fea1,openstack/oslo.serialization,master,I8d87d54f6f5ded8caee6cb780bacb39afea0fea1,Implement zoneinfo support to drop dependency to pytz,MERGED,2023-02-07 13:43:25.000000000,2023-04-17 11:27:05.000000000,2023-04-17 11:26:01.000000000,"[{'_account_id': 9816}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-02-07 13:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/e37c24b549a627d675b095eab088163082d50c89', 'message': 'Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n'}, {'number': 2, 'created': '2023-02-08 13:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/859c924d95d7f1944ff4b40bca651534e7025b80', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required by our gates because by default, zoneinfo uses the\nsystem’s time zone data if available; if no system time zone data is\navailable, the library will fall back to using the first-party tzdata\npackage available on PyPI.. Apparently our gates have no time zone\ndata available because we get the following error without tzdata\ninstalled [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3]\nhttps://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n""}, {'number': 3, 'created': '2023-02-08 13:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/587a4426798f6609523f6f50c8c6b8ddc89b25c2', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3]\nhttps://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n""}, {'number': 4, 'created': '2023-02-28 12:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/b838d169e1906d70136078bc5f020f50ba9981ab', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3]\nhttps://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n""}, {'number': 5, 'created': '2023-03-01 11:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/725bda81e049225ac842acdade2ba6f2ce1586f7', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3]\nhttps://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nDepends-on: https://review.opendev.org/c/openstack/requirements/+/875854\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n""}, {'number': 6, 'created': '2023-03-23 16:18:07.000000000', 'files': ['requirements.txt', 'oslo_serialization/tests/test_msgpackutils.py', 'releasenotes/notes/implement-zoneinfo-to-remove-pytz-c136b33bbfbfe59f.yaml', 'oslo_serialization/msgpackutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/a326ec5eea86d7458953a229b4dbd887595f68f1', 'message': ""Implement zoneinfo support to drop dependency to pytz\n\nZoneinfo was introduced within python 3.9.\n\nThe support of pytz will be removed within RHEL 10 [1].\n\n2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10\nso we want to see pytz removed within this series.\n\ntzdata is required at runtime in our gates, because, by default,\nzoneinfo uses the system’s time zone data if available; if no system\ntime zone data is available, the library will fall back to using the\nfirst-party tzdata package available on PyPI. Apparently our gates have no\ntime zone data available nor tzdata installed by default because we get the\nfollowing error without tzdata installed [3]:\n`ModuleNotFoundError: No module named 'tzdata'\n\nSo I prefer to add tzdata in our requirements to avoid runtime failure\nrelated to time zone and ensure that time zone are always available.\n\n[1] https://issues.redhat.com/browse/RHEL-219\n[2] https://review.opendev.org/c/openstack/governance/+/872232\n[3]\nhttps://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`\n\nDepends-on: https://review.opendev.org/c/openstack/requirements/+/875854\nChange-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1\n""}]",7,872915,a326ec5eea86d7458953a229b4dbd887595f68f1,27,4,6,28522,,,0,"Implement zoneinfo support to drop dependency to pytz

Zoneinfo was introduced within python 3.9.

The support of pytz will be removed within RHEL 10 [1].

2023.2 (bobcat) will move our testing runtime to py3.9 and py3.10
so we want to see pytz removed within this series.

tzdata is required at runtime in our gates, because, by default,
zoneinfo uses the system’s time zone data if available; if no system
time zone data is available, the library will fall back to using the
first-party tzdata package available on PyPI. Apparently our gates have no
time zone data available nor tzdata installed by default because we get the
following error without tzdata installed [3]:
`ModuleNotFoundError: No module named 'tzdata'

So I prefer to add tzdata in our requirements to avoid runtime failure
related to time zone and ensure that time zone are always available.

[1] https://issues.redhat.com/browse/RHEL-219
[2] https://review.opendev.org/c/openstack/governance/+/872232
[3]
https://zuul.opendev.org/t/openstack/build/0a1576775e894b09bc31269fea00ba03/log/job-output.txt#1445`

Depends-on: https://review.opendev.org/c/openstack/requirements/+/875854
Change-Id: I8d87d54f6f5ded8caee6cb780bacb39afea0fea1
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/15/872915/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_serialization/tests/test_msgpackutils.py', 'releasenotes/notes/implement-zoneinfo-to-remove-pytz-c136b33bbfbfe59f.yaml', 'oslo_serialization/msgpackutils.py']",4,e37c24b549a627d675b095eab088163082d50c89,remove-pytz,import zoneinfo tz = str(dt.tzinfo) if 'tz' in dct and dct['tz']: tzinfo = zoneinfo.ZoneInfo(dct['tz']) dt = dt.replace(tzinfo=tzinfo),from pytz import timezone tz = dt.tzinfo.tzname(None) if 'tz' in dct: tzinfo = timezone(dct['tz']) dt = tzinfo.localize(dt),20,13
openstack%2Foslo.db~master~I1e71150ba6daeba464b6ed8d46163f1f34959db3,openstack/oslo.db,master,I1e71150ba6daeba464b6ed8d46163f1f34959db3,Remove legacy base test classes,MERGED,2023-02-17 12:56:46.000000000,2023-04-17 11:12:36.000000000,2023-04-17 11:11:39.000000000,"[{'_account_id': 11816}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-17 12:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5c795561118d5cae2ed0413ec5b233114b9c7bb5', 'message': 'Remove legacy base test classes\n\nThe fixtures have been available for a very long time now. We can drop\nthese.\n\nChange-Id: I1e71150ba6daeba464b6ed8d46163f1f34959db3\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-02-17 15:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e99749dbfe8e631809b320ab88f1c20fc473bbf1', 'message': 'Remove legacy base test classes\n\nThe fixtures have been available for a very long time now. We can drop\nthese.\n\nChange-Id: I1e71150ba6daeba464b6ed8d46163f1f34959db3\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2023-02-27 15:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6af0ef5a2bb62cda697048bfbe5b92129105d477', 'message': 'Remove legacy base test classes\n\nThe fixtures have been available for a very long time now. We can drop\nthese.\n\nChange-Id: I1e71150ba6daeba464b6ed8d46163f1f34959db3\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 4, 'created': '2023-03-22 15:05:24.000000000', 'files': ['oslo_db/sqlalchemy/test_base.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/exception.py', 'oslo_db/tests/sqlalchemy/test_fixtures.py', 'oslo_db/tests/sqlalchemy/base.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/a609333c5482228ee69baab91858e1812909cd55', 'message': 'Remove legacy base test classes\n\nThe fixtures have been available for a very long time now. We can drop\nthese.\n\nChange-Id: I1e71150ba6daeba464b6ed8d46163f1f34959db3\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",4,874239,a609333c5482228ee69baab91858e1812909cd55,17,3,4,15334,,,0,"Remove legacy base test classes

The fixtures have been available for a very long time now. We can drop
these.

Change-Id: I1e71150ba6daeba464b6ed8d46163f1f34959db3
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/39/874239/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/test_base.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/exception.py', 'oslo_db/tests/sqlalchemy/test_fixtures.py', 'oslo_db/tests/sqlalchemy/base.py']",5,5c795561118d5cae2ed0413ec5b233114b9c7bb5,sqlalchemy-20,,"import debtcollector @debtcollector.removals.removed_class( ""DbTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class DbTestCase(db_fixtures.OpportunisticDBTestMixin, test_base.BaseTestCase): def setUp(self): super(DbTestCase, self).setUp() self.engine = enginefacade.writer.get_engine() self.sessionmaker = enginefacade.writer.get_sessionmaker() @debtcollector.removals.removed_class( ""MySQLOpportunisticTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class MySQLOpportunisticTestCase(DbTestCase): FIXTURE = db_fixtures.MySQLOpportunisticFixture @debtcollector.removals.removed_class( ""PostgreSQLOpportunisticTestCase"", message=""Do not import from oslo_db.tests! "" ""Please use oslo_db.sqlalchemy.test_fixtures directly"") class PostgreSQLOpportunisticTestCase(DbTestCase): FIXTURE = db_fixtures.PostgresqlOpportunisticFixture ",1,340
openstack%2Fkayobe~stable%2Fyoga~Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751,openstack/kayobe,stable/yoga,Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751,Bump mrlesmithjr.lvm to skip swap resizes,MERGED,2023-04-17 06:34:07.000000000,2023-04-17 11:04:15.000000000,2023-04-17 11:03:13.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 32657}]","[{'number': 1, 'created': '2023-04-17 06:34:07.000000000', 'files': ['requirements.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/c851c6ba408f5ed1e5c520371aee264d87686c5e', 'message': 'Bump mrlesmithjr.lvm to skip swap resizes\n\nSee https://github.com/mrlesmithjr/ansible-manage-lvm/releases/tag/v0.2.7\n\nChange-Id: Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751\n(cherry picked from commit b3797d66502e60830ac76b87995195a46821cf37)\n'}]",0,880509,c851c6ba408f5ed1e5c520371aee264d87686c5e,9,4,1,22629,,,0,"Bump mrlesmithjr.lvm to skip swap resizes

See https://github.com/mrlesmithjr/ansible-manage-lvm/releases/tag/v0.2.7

Change-Id: Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751
(cherry picked from commit b3797d66502e60830ac76b87995195a46821cf37)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/09/880509/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.yml'],1,c851c6ba408f5ed1e5c520371aee264d87686c5e,, version: v0.2.8, version: v0.2.6,1,1
openstack%2Ftripleo-quickstart-extras~master~I9b23d6842cd518971b325ffd29b51d171c353b4f,openstack/tripleo-quickstart-extras,master,I9b23d6842cd518971b325ffd29b51d171c353b4f,Fix neutron_bridge_mappings default for standalone,MERGED,2023-03-28 08:37:41.000000000,2023-04-17 10:31:55.000000000,2023-04-17 10:31:55.000000000,"[{'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2023-03-28 08:37:41.000000000', 'files': ['roles/standalone-upgrade/defaults/main.yml', 'roles/standalone-upgrade/README.md', 'roles/standalone/README.md', 'roles/standalone/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6887104038ba5d0152c77abe4a38e98d72693b89', 'message': ""Fix neutron_bridge_mappings default for standalone\n\nbr-tenant is not created as part of standalone\ndeployments but bridge_mapping was refererring\nit. This results into unnecessary Warning[1] in\novn-controller logs, this patch fixes it.\n\n[1] Bridge 'br-tenant' not found for network 'tenant'\n\nRelated-Bug: #1895822\nChange-Id: I9b23d6842cd518971b325ffd29b51d171c353b4f\n""}]",4,878747,6887104038ba5d0152c77abe4a38e98d72693b89,15,6,1,13861,,,0,"Fix neutron_bridge_mappings default for standalone

br-tenant is not created as part of standalone
deployments but bridge_mapping was refererring
it. This results into unnecessary Warning[1] in
ovn-controller logs, this patch fixes it.

[1] Bridge 'br-tenant' not found for network 'tenant'

Related-Bug: #1895822
Change-Id: I9b23d6842cd518971b325ffd29b51d171c353b4f
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/47/878747/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/standalone-upgrade/defaults/main.yml', 'roles/standalone-upgrade/README.md', 'roles/standalone/README.md', 'roles/standalone/defaults/main.yml']",4,6887104038ba5d0152c77abe4a38e98d72693b89,bug/1895822,"standalone_neutron_bridge_mappings: ""datacentre:br-ctlplane""","standalone_neutron_bridge_mappings: ""datacentre:br-ctlplane,tenant:br-tenant""",4,4
openstack%2Fansible-collections-openstack~master~Ieaf77efde24431eddc550c688d8c341c12ddbbaa,openstack/ansible-collections-openstack,master,Ieaf77efde24431eddc550c688d8c341c12ddbbaa,"vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules",ABANDONED,2023-04-11 14:01:55.000000000,2023-04-17 10:01:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-11 14:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b1264e616e46a496fbfa19250f4ce3fb8019279f', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 2, 'created': '2023-04-12 12:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/34f26b43ababfe49667d22c7ce9f3e7301c94c91', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 3, 'created': '2023-04-12 13:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5d54d3abf9bbecab83635e3a320878d283cc266e', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 4, 'created': '2023-04-12 14:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7f3789b1b6fce61596f84c946674dc28ed7d5009', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 5, 'created': '2023-04-12 14:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/93648c9dc6f847e663b2db853efc7178439eef4b', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 6, 'created': '2023-04-12 15:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cdf67d455ea02c6dfc861e66506159c813d89133', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 7, 'created': '2023-04-12 19:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/49a6e02e2a57789e194c519087224ef1aba00d6d', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 8, 'created': '2023-04-12 20:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/37916ff17f21e88b7795cb277683b141b272d68f', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 9, 'created': '2023-04-12 20:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a8a4a5d6ee7f9b9b8b41eea8c912ac5a889a3635', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 10, 'created': '2023-04-12 20:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/53bb3a54b76e54d0f69e0378ec1e6d554e784829', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 11, 'created': '2023-04-12 21:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/02f8e52736c906a4ff10decc864e8d9af61c952f', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 12, 'created': '2023-04-12 23:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7d2a906c38030cec3e78df45e4b714352586018d', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 13, 'created': '2023-04-12 23:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ce3f16621226fffb641600d52a2bb017326ecf13', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 14, 'created': '2023-04-12 23:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0d3e8717ca78e49eda9d85b92c78fd864eec6187', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 15, 'created': '2023-04-13 08:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/335310f1f0166a538f07d5c41379223cd14ab1df', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}, {'number': 16, 'created': '2023-04-13 08:30:00.000000000', 'files': ['plugins/modules/endpoint_group.py', 'plugins/modules/ipsec_connection.py', 'plugins/modules/ipsec_policy.py', 'meta/runtime.yml', 'plugins/modules/vpn_service.py', 'plugins/modules/ike_policy.py', 'ci/roles/vpn_service/tasks/main.yml', 'ci/run-collection.yml', 'ci/roles/vpn_service/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c21e74264f2ae0bf7c8f110bb8201ddfe0843713', 'message': 'vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules\n\nChange-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa\n'}]",0,880054,c21e74264f2ae0bf7c8f110bb8201ddfe0843713,32,1,16,32787,,,0,"vpn service, ike policy, ipsec policy, endpoint group, ipsec connection modules

Change-Id: Ieaf77efde24431eddc550c688d8c341c12ddbbaa
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/54/880054/16 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/endpoint_group.py', 'plugins/modules/ipsec_connection.py', 'plugins/modules/ipsec_policy.py', 'meta/runtime.yml', 'plugins/modules/vpn_service.py', 'plugins/modules/ike_policy.py', 'ci/roles/vpn_service/tasks/main.yml', 'ci/run-collection.yml', 'ci/roles/vpn_service/defaults/main.yml']",9,b1264e616e46a496fbfa19250f4ce3fb8019279f,ipsec-policy,,,1302,0
openstack%2Foslo.db~master~Ia4f3dcf410b2983ca0aca12f497739303d98112e,openstack/oslo.db,master,Ia4f3dcf410b2983ca0aca12f497739303d98112e,Removes option bindings deprecated since 2014,ABANDONED,2022-06-08 09:27:14.000000000,2023-04-17 09:45:19.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-06-08 09:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6eb348e734fcc1e8c63deaf4b0725567e7b5cd3c', 'message': 'Remove option bindings deprecated since 2014\n\nThose bindings are deprecated since 2014, I think\nwe can remove them safely.\n\nChange-Id: Ia4f3dcf410b2983ca0aca12f497739303d98112e\n'}, {'number': 2, 'created': '2022-06-08 09:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d2bfa1ffa5ce8676523934f5d6579b4c4b03c0cf', 'message': 'Remove option bindings deprecated since 2014\n\nThose bindings are deprecated since 2014, I think\nwe can remove them safely.\n\nChange-Id: Ia4f3dcf410b2983ca0aca12f497739303d98112e\n'}, {'number': 3, 'created': '2022-06-08 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0c0073a953be72e08f1aa69ca86617318717cb6b', 'message': 'Remove option bindings deprecated since 2014\n\nThose bindings are deprecated since 2014, I think\nwe can remove them safely.\n\nChange-Id: Ia4f3dcf410b2983ca0aca12f497739303d98112e\n'}, {'number': 4, 'created': '2022-06-08 09:38:22.000000000', 'files': ['oslo_db/options.py', 'releasenotes/notes/remove-deprecated-parameters-d738dbbeaa4e3ed3.yaml', 'oslo_db/tests/sqlalchemy/test_options.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/bd39da02ba09278c06aa524ee4608570f5cdb767', 'message': 'Removes option bindings deprecated since 2014\n\nThose bindings are deprecated since 2014, I think\nwe can remove them safely.\n\nChange-Id: Ia4f3dcf410b2983ca0aca12f497739303d98112e\n'}]",1,845110,bd39da02ba09278c06aa524ee4608570f5cdb767,7,2,4,28522,,,0,"Removes option bindings deprecated since 2014

Those bindings are deprecated since 2014, I think
we can remove them safely.

Change-Id: Ia4f3dcf410b2983ca0aca12f497739303d98112e
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/10/845110/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_db/options.py'],1,6eb348e734fcc1e8c63deaf4b0725567e7b5cd3c,," secret=True),"," deprecated_group='DEFAULT', deprecated_name='db_backend', deprecated_group='DEFAULT', secret=True, deprecated_opts=[cfg.DeprecatedOpt('sql_connection', group='DEFAULT'), cfg.DeprecatedOpt('sql_connection', group='DATABASE'), cfg.DeprecatedOpt('connection', group='sql'), ]), deprecated_opts=[cfg.DeprecatedOpt('sql_max_retries', group='DEFAULT'), cfg.DeprecatedOpt('sql_max_retries', group='DATABASE')], deprecated_opts=[cfg.DeprecatedOpt('sql_retry_interval', group='DEFAULT'), cfg.DeprecatedOpt('reconnect_interval', group='DATABASE')], deprecated_opts=[cfg.DeprecatedOpt('sql_max_overflow', group='DEFAULT'), cfg.DeprecatedOpt('sqlalchemy_max_overflow', group='DATABASE')], deprecated_opts=[cfg.DeprecatedOpt('sql_connection_debug', group='DEFAULT')], deprecated_opts=[cfg.DeprecatedOpt('sql_connection_trace', group='DEFAULT')], deprecated_opts=[cfg.DeprecatedOpt('sqlalchemy_pool_timeout', group='DATABASE')],",1,28
openstack%2Foslo.db~master~If537934713986997fa531946551c8a408d83c925,openstack/oslo.db,master,If537934713986997fa531946551c8a408d83c925,[WIP] Make SQLAlchemy session thread-safe,ABANDONED,2021-07-02 15:48:37.000000000,2023-04-17 09:41:30.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-07-02 15:48:37.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/tests/sqlalchemy/test_update_match.py', 'oslo_db/sqlalchemy/orm.py', 'oslo_db/tests/sqlalchemy/base.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7fccc3a8bfac19fc2b6f433b5a4ef9feb0aeb92e', 'message': '[WIP] Make SQLAlchemy session thread-safe\n\nUsed scoped session instead of the regular one. Tests are totally broken\nfor now\n\nChange-Id: If537934713986997fa531946551c8a408d83c925\n'}]",0,799224,7fccc3a8bfac19fc2b6f433b5a4ef9feb0aeb92e,3,1,1,27838,,,0,"[WIP] Make SQLAlchemy session thread-safe

Used scoped session instead of the regular one. Tests are totally broken
for now

Change-Id: If537934713986997fa531946551c8a408d83c925
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/24/799224/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py', 'oslo_db/sqlalchemy/orm.py', 'oslo_db/tests/sqlalchemy/test_update_match.py', 'oslo_db/tests/sqlalchemy/base.py']",5,7fccc3a8bfac19fc2b6f433b5a4ef9feb0aeb92e,session_thread_master," def tearDown(self): super(_DbTestCase, self).tearDown() if hasattr(self, 'sessionmaker'): self.sessionmaker.remove() ",,23,5
openstack%2Fironic~master~If8fc919d4a04325ca48a037c02481d9efe54279f,openstack/ironic,master,If8fc919d4a04325ca48a037c02481d9efe54279f,tests: Enable SQLAlchemy 2.0 deprecation warnings,ABANDONED,2022-09-07 23:09:34.000000000,2023-04-17 09:34:09.000000000,,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-09-07 23:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/42edff6cd90f2c2a8253bbb20415e0b993d56e75', 'message': 'tests: Enable SQLAlchemy 2.0 deprecation warnings\n\nWell, sort of. We enable them but immediately filter out the ones we\'re\nactually seeing, the rationale being that we can address these in a\npiecemeal fashion without the risk of introducing new issues.\n\nThere\'s a lot more to be done here. However, the work done in oslo.db\n[1] should provide a guide for how to resolve the outstanding issues.\n\n[1] https://review.opendev.org/q/topic:""sqlalchemy-20""+project:openstack/oslo.db\n\nChange-Id: If8fc919d4a04325ca48a037c02481d9efe54279f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2022-09-08 10:00:21.000000000', 'files': ['ironic/tests/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4d0a18d34c07bde81530460fee52626a897e7bb1', 'message': 'tests: Enable SQLAlchemy 2.0 deprecation warnings\n\nWell, sort of. We enable them but immediately filter out the ones we\'re\nactually seeing, the rationale being that we can address these in a\npiecemeal fashion without the risk of introducing new issues.\n\nThere\'s a lot more to be done here. However, the work done in oslo.db\n[1] should provide a guide for how to resolve the outstanding issues.\n\n[1] https://review.opendev.org/q/topic:""sqlalchemy-20""+project:openstack/oslo.db\n\nChange-Id: If8fc919d4a04325ca48a037c02481d9efe54279f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",2,856346,4d0a18d34c07bde81530460fee52626a897e7bb1,11,3,2,15334,,,0,"tests: Enable SQLAlchemy 2.0 deprecation warnings

Well, sort of. We enable them but immediately filter out the ones we're
actually seeing, the rationale being that we can address these in a
piecemeal fashion without the risk of introducing new issues.

There's a lot more to be done here. However, the work done in oslo.db
[1] should provide a guide for how to resolve the outstanding issues.

[1] https://review.opendev.org/q/topic:""sqlalchemy-20""+project:openstack/oslo.db

Change-Id: If8fc919d4a04325ca48a037c02481d9efe54279f
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/ironic refs/changes/46/856346/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/base.py', 'tox.ini']",2,42edff6cd90f2c2a8253bbb20415e0b993d56e75,sqlalchemy-20,setenv = VIRTUAL_ENV={envdir} PYTHONDONTWRITEBYTECODE = 1 LANGUAGE=en_US LC_ALL=en_US.UTF-8 # TODO(stephenfin): Remove once we bump our upper-constraint to SQLAlchemy 2.0 SQLALCHEMY_WARN_20=1setenv = {[testenv]setenv} PYTHON=coverage run --source nova --parallel-mode,setenv = VIRTUAL_ENV={envdir} PYTHONDONTWRITEBYTECODE = 1 LANGUAGE=en_US LC_ALL=en_US.UTF-8setenv = VIRTUAL_ENV={envdir} LANGUAGE=en_US PYTHON=coverage run --source ironic --omit='*tests*' --parallel-mode,20,7
openstack%2Fnova~master~I7756e393b78296fb8dbf3ca69c759d75b816376d,openstack/nova,master,I7756e393b78296fb8dbf3ca69c759d75b816376d,db: Remove legacy migrations,MERGED,2023-02-01 17:08:29.000000000,2023-04-17 09:09:43.000000000,2023-04-17 01:08:26.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-02-01 17:08:29.000000000', 'files': ['nova/db/main/legacy_migrations/versions/416_placeholder.py', 'nova/db/api/legacy_migrations/versions/069_placeholder.py', 'nova/db/api/legacy_migrations/migrate.cfg', 'nova/db/api/legacy_migrations/versions/085_placeholder.py', 'nova/db/main/legacy_migrations/versions/420_placeholder.py', 'nova/db/api/legacy_migrations/versions/078_placeholder.py', 'nova/db/main/legacy_migrations/versions/407_placeholder.py', 'nova/tests/unit/db/test_migration.py', 'nova/db/api/legacy_migrations/versions/__init__.py', 'nova/db/main/legacy_migrations/versions/411_placeholder.py', 'nova/db/main/legacy_migrations/versions/409_placeholder.py', 'nova/db/api/legacy_migrations/versions/082_placeholder.py', 'nova/db/api/legacy_migrations/versions/073_placeholder.py', 'nova/db/main/legacy_migrations/versions/414_placeholder.py', 'nova/db/main/legacy_migrations/versions/__init__.py', 'nova/db/api/legacy_migrations/versions/075_placeholder.py', 'nova/db/main/legacy_migrations/versions/419_placeholder.py', 'nova/db/main/legacy_migrations/versions/413_placeholder.py', 'nova/db/api/legacy_migrations/README', 'nova/db/api/legacy_migrations/versions/074_placeholder.py', 'nova/db/api/legacy_migrations/versions/087_placeholder.py', 'nova/db/main/legacy_migrations/README', 'nova/db/api/legacy_migrations/versions/076_placeholder.py', 'nova/tests/unit/db/main/test_migrations.py', 'nova/db/api/legacy_migrations/versions/067_train.py', 'nova/db/migration.py', 'nova/db/api/legacy_migrations/versions/080_placeholder.py', 'nova/db/main/legacy_migrations/manage.py', 'nova/db/main/legacy_migrations/migrate.cfg', 'nova/db/main/legacy_migrations/versions/412_placeholder.py', 'nova/db/main/legacy_migrations/versions/408_placeholder.py', 'nova/db/main/legacy_migrations/versions/402_train.py', 'nova/db/api/legacy_migrations/versions/081_placeholder.py', 'nova/db/api/legacy_migrations/versions/077_placeholder.py', 'nova/db/main/legacy_migrations/__init__.py', 'nova/tests/unit/db/api/test_migrations.py', 'nova/db/main/legacy_migrations/versions/403_placeholder.py', 'nova/db/api/legacy_migrations/__init__.py', 'nova/db/api/legacy_migrations/versions/072_placeholder.py', 'nova/db/main/legacy_migrations/versions/410_placeholder.py', 'nova/db/main/legacy_migrations/versions/415_placeholder.py', 'requirements.txt', 'nova/db/api/legacy_migrations/versions/068_placeholder.py', 'releasenotes/notes/remove-sqlalchemy-migrate-907c200314884d81.yaml', 'nova/db/main/legacy_migrations/versions/406_placeholder.py', 'nova/db/api/legacy_migrations/versions/086_placeholder.py', 'nova/db/api/legacy_migrations/versions/083_placeholder.py', 'nova/db/main/legacy_migrations/versions/422_placeholder.py', 'nova/db/main/legacy_migrations/versions/405_placeholder.py', 'nova/db/api/legacy_migrations/manage.py', 'nova/db/main/legacy_migrations/versions/418_placeholder.py', 'nova/db/api/legacy_migrations/versions/070_placeholder.py', 'nova/db/main/legacy_migrations/versions/417_placeholder.py', 'nova/db/api/legacy_migrations/versions/079_placeholder.py', 'nova/db/main/legacy_migrations/versions/404_placeholder.py', 'nova/db/main/legacy_migrations/versions/421_placeholder.py', 'doc/source/reference/database-migrations.rst', 'nova/db/api/legacy_migrations/versions/084_placeholder.py', 'nova/db/api/legacy_migrations/versions/071_placeholder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd39e4b4be9ddb18b96d5f8086955b91232f25e9', 'message': 'db: Remove legacy migrations\n\nsqlalchemy-migrate does not (and will not) support sqlalchemy 2.0. We\nneed to drop these migrations to ensure we can upgrade our sqlalchemy\nversion.\n\nChange-Id: I7756e393b78296fb8dbf3ca69c759d75b816376d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",14,872428,fd39e4b4be9ddb18b96d5f8086955b91232f25e9,49,7,1,15334,,,0,"db: Remove legacy migrations

sqlalchemy-migrate does not (and will not) support sqlalchemy 2.0. We
need to drop these migrations to ensure we can upgrade our sqlalchemy
version.

Change-Id: I7756e393b78296fb8dbf3ca69c759d75b816376d
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/872428/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/main/legacy_migrations/versions/416_placeholder.py', 'nova/db/api/legacy_migrations/versions/069_placeholder.py', 'nova/db/api/legacy_migrations/migrate.cfg', 'nova/db/api/legacy_migrations/versions/085_placeholder.py', 'nova/db/main/legacy_migrations/versions/420_placeholder.py', 'nova/db/api/legacy_migrations/versions/078_placeholder.py', 'nova/db/main/legacy_migrations/versions/407_placeholder.py', 'nova/tests/unit/db/test_migration.py', 'nova/db/api/legacy_migrations/versions/__init__.py', 'nova/db/main/legacy_migrations/versions/411_placeholder.py', 'nova/db/main/legacy_migrations/versions/409_placeholder.py', 'nova/db/api/legacy_migrations/versions/082_placeholder.py', 'nova/db/api/legacy_migrations/versions/073_placeholder.py', 'nova/db/main/legacy_migrations/versions/414_placeholder.py', 'nova/db/main/legacy_migrations/versions/__init__.py', 'nova/db/api/legacy_migrations/versions/075_placeholder.py', 'nova/db/main/legacy_migrations/versions/419_placeholder.py', 'nova/db/main/legacy_migrations/versions/413_placeholder.py', 'nova/db/api/legacy_migrations/README', 'nova/db/api/legacy_migrations/versions/074_placeholder.py', 'nova/db/api/legacy_migrations/versions/087_placeholder.py', 'nova/db/main/legacy_migrations/README', 'nova/db/api/legacy_migrations/versions/076_placeholder.py', 'nova/tests/unit/db/main/test_migrations.py', 'nova/db/api/legacy_migrations/versions/067_train.py', 'nova/db/migration.py', 'nova/db/api/legacy_migrations/versions/080_placeholder.py', 'nova/db/main/legacy_migrations/manage.py', 'nova/db/main/legacy_migrations/migrate.cfg', 'nova/db/main/legacy_migrations/versions/412_placeholder.py', 'nova/db/main/legacy_migrations/versions/408_placeholder.py', 'nova/db/main/legacy_migrations/versions/402_train.py', 'nova/db/api/legacy_migrations/versions/081_placeholder.py', 'nova/db/api/legacy_migrations/versions/077_placeholder.py', 'nova/db/main/legacy_migrations/__init__.py', 'nova/tests/unit/db/api/test_migrations.py', 'nova/db/main/legacy_migrations/versions/403_placeholder.py', 'nova/db/api/legacy_migrations/__init__.py', 'nova/db/api/legacy_migrations/versions/072_placeholder.py', 'nova/db/main/legacy_migrations/versions/410_placeholder.py', 'nova/db/main/legacy_migrations/versions/415_placeholder.py', 'requirements.txt', 'nova/db/api/legacy_migrations/versions/068_placeholder.py', 'releasenotes/notes/remove-sqlalchemy-migrate-907c200314884d81.yaml', 'nova/db/main/legacy_migrations/versions/406_placeholder.py', 'nova/db/api/legacy_migrations/versions/086_placeholder.py', 'nova/db/api/legacy_migrations/versions/083_placeholder.py', 'nova/db/main/legacy_migrations/versions/422_placeholder.py', 'nova/db/main/legacy_migrations/versions/405_placeholder.py', 'nova/db/api/legacy_migrations/manage.py', 'nova/db/main/legacy_migrations/versions/418_placeholder.py', 'nova/db/api/legacy_migrations/versions/070_placeholder.py', 'nova/db/main/legacy_migrations/versions/417_placeholder.py', 'nova/db/api/legacy_migrations/versions/079_placeholder.py', 'nova/db/main/legacy_migrations/versions/404_placeholder.py', 'nova/db/main/legacy_migrations/versions/421_placeholder.py', 'doc/source/reference/database-migrations.rst', 'nova/db/api/legacy_migrations/versions/084_placeholder.py', 'nova/db/api/legacy_migrations/versions/071_placeholder.py']",59,fd39e4b4be9ddb18b96d5f8086955b91232f25e9,sqlalchemy-20,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # This is a placeholder for backports. # Do not use this number for new work. New work starts after # all the placeholders. # # See this for more information: # http://lists.openstack.org/pipermail/openstack-dev/2013-March/006827.html def upgrade(migrate_engine): pass ",24,3537
openstack%2Fskyline-console~master~Ib4008fa1e1d00921040320e2d1b44d35bd38cef9,openstack/skyline-console,master,Ib4008fa1e1d00921040320e2d1b44d35bd38cef9,Add admin state up switch,MERGED,2023-02-16 11:18:47.000000000,2023-04-17 09:08:33.000000000,2023-04-17 09:07:31.000000000,"[{'_account_id': 22348}, {'_account_id': 30434}, {'_account_id': 33689}, {'_account_id': 34589}]","[{'number': 1, 'created': '2023-02-16 11:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/9acd992f61f4c1e51b1b49153a3bcc8fb886c195', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 2, 'created': '2023-02-16 11:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/e300b808ecaf25b8f692a6d528599ffb84aa2dc9', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 3, 'created': '2023-02-16 11:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/0ca65c8a2baec6dcf0c3dbe624c7f351146446f0', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 4, 'created': '2023-02-16 11:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/fa4338e30429706329eef847b9666230b624c7d7', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 5, 'created': '2023-02-16 16:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/8716063512d52195fc1508bb3a831e7f8710c413', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 6, 'created': '2023-02-20 11:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/633d489128929065ffada2f9b819e79d3ca2daf6', 'message': 'WIP Add admin state up switch\n\nTODO tests update?\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 7, 'created': '2023-02-20 11:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/019cd7181fbb18c928d05b6a71fd9ee4a9fe5e9d', 'message': 'WIP Add admin state up switch\n\nTODO tests update?\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 8, 'created': '2023-02-20 14:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/467e5b5b6060b1786bd757399e17680cad79605e', 'message': 'WIP Add admin state up switch\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 9, 'created': '2023-02-22 09:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/95fea11d4ec497dd1e633a3c0626f5cc87d44178', 'message': 'Add admin state up switch\n\nAdd admin state up switches to various steps of load balancer creation.\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 10, 'created': '2023-04-06 09:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/5d6210a3f89e1c0bd28d3725f0dd05f2831cd65a', 'message': 'Add admin state up switch\n\nAdd admin state up switches to various steps of load balancer creation.\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 11, 'created': '2023-04-14 13:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/6bbc6ccb512f000242465f73fa3db51fcc8b89dd', 'message': 'Add admin state up switch\n\nAdd admin state up switches to various steps of load balancer creation.\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}, {'number': 12, 'created': '2023-04-17 06:42:56.000000000', 'files': ['releasenotes/notes/add-admin-state-loadbalancer-switches-721264bd7d7bcf75.yaml', 'src/locales/en.json', 'src/pages/network/containers/LoadBalancers/StepCreateComponents/HealthMonitorStep/index.jsx', 'src/pages/network/containers/LoadBalancers/LoadBalancerInstance/actions/StepCreate/BaseStep/index.jsx', 'src/pages/network/containers/LoadBalancers/StepCreateComponents/PoolStep/index.jsx', 'src/pages/network/containers/LoadBalancers/LoadBalancerInstance/actions/StepCreate/index.jsx', 'src/pages/network/containers/LoadBalancers/StepCreateComponents/ListenerStep/index.jsx'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/f6535f71d8197ba5e6357097ed93840f9d721a8a', 'message': 'Add admin state up switch\n\nAdd admin state up switches to various steps of load balancer creation.\n\nChange-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9\n'}]",2,874086,f6535f71d8197ba5e6357097ed93840f9d721a8a,28,4,12,34429,,,0,"Add admin state up switch

Add admin state up switches to various steps of load balancer creation.

Change-Id: Ib4008fa1e1d00921040320e2d1b44d35bd38cef9
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/86/874086/12 && git format-patch -1 --stdout FETCH_HEAD,"['src/pages/network/containers/LoadBalancers/LoadBalancerInstance/actions/StepCreate/BaseStep/index.jsx', 'config/webpack.dev.js', 'src/components/FormItem/Switch/index.jsx', 'src/components/FormItem/index.jsx']",4,9acd992f61f4c1e51b1b49153a3bcc8fb886c195,clean-static,"import { QuestionCircleOutlined } from '@ant-design/icons'; import { DatePicker, Divider, Tooltip,import MemberAllocator from 'components/FormItem/MemberAllocator'; import { isEmpty } from 'lodash'; import PropTypes from 'prop-types'; import React from 'react'; import AceEditor from 'react-ace';import Descriptions from './Descriptions';import InstanceVolume from './InstanceVolume';import IPDistributor from './IPDistributor'; import IpInputSimple from './IpInputSimple'; import Label from './Label'; import MacAddressInput from './MacAddressInput'; import MetadataTransfer from './MetadataTransfer'; import More from './More'; import NameInput from './NameInput'; import NetworkSelect from './NetworkSelect'; import NetworkSelectTable from './NetworkSelectTable'; import NUMAInput from './NUMAInput'; import PortRange from './PortRange'; import Radio from './Radio'; import Select from './Select'; import SelectTable from './SelectTable'; import SelectWithInput from './SelectWithInput'; import SliderInput from './SliderInput'; import Switch from './Switch'; import TabSelectTable from './TabSelectTable'; import TextareaFromFile from './TextareaFromFile'; import Title from './Title'; import Transfer from './Transfer'; import TreeSelect from './TreeSelect'; import Upload from './Upload'; import VolumeSelectTable from './VolumeSelectTable';","import React from 'react'; import PropTypes from 'prop-types'; import { isEmpty } from 'lodash'; import { Divider, Tooltip, DatePicker,import { QuestionCircleOutlined } from '@ant-design/icons'; import AceEditor from 'react-ace'; import MemberAllocator from 'components/FormItem/MemberAllocator';import Select from './Select'; import Label from './Label'; import SelectTable from './SelectTable'; import InstanceVolume from './InstanceVolume'; import More from './More'; import Upload from './Upload';import IpInputSimple from './IpInputSimple'; import NetworkSelect from './NetworkSelect'; import Radio from './Radio'; import Descriptions from './Descriptions'; import NameInput from './NameInput'; import PortRange from './PortRange'; import SliderInput from './SliderInput'; import Title from './Title'; import Switch from './Switch';import Transfer from './Transfer'; import NUMAInput from './NUMAInput';import TextareaFromFile from './TextareaFromFile'; import IPDistributor from './IPDistributor'; import MacAddressInput from './MacAddressInput';import MetadataTransfer from './MetadataTransfer'; import NetworkSelectTable from './NetworkSelectTable'; import VolumeSelectTable from './VolumeSelectTable'; import TabSelectTable from './TabSelectTable'; import TreeSelect from './TreeSelect'; import SelectWithInput from './SelectWithInput';",69,42
openstack%2Fpuppet-openstack-integration~stable%2Fzed~I2de028ddac3bd8683b092f9b59f0b7bc13be87a3,openstack/puppet-openstack-integration,stable/zed,I2de028ddac3bd8683b092f9b59f0b7bc13be87a3,Restore bgpvpn tests,MERGED,2023-04-12 05:59:52.000000000,2023-04-17 08:47:50.000000000,2023-04-17 08:47:50.000000000,"[{'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 05:59:52.000000000', 'files': ['manifests/tempest.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/553dfc86e5a2fe7356c1dd11630bfac8b9eed3e0', 'message': 'Restore bgpvpn tests\n\nThis fixes the skipped bgpvpn tempest tests so that the functionality\nis tested in the integration jobs.\n\nChange-Id: I2de028ddac3bd8683b092f9b59f0b7bc13be87a3\n(cherry picked from commit 58042b00f36ea5bed17a1701b4681ff24c96aaa4)\n(cherry picked from commit 424fc512afc1e7cb99732e2d012e59557728d927)\n'}]",4,880096,553dfc86e5a2fe7356c1dd11630bfac8b9eed3e0,21,3,1,9816,,,0,"Restore bgpvpn tests

This fixes the skipped bgpvpn tempest tests so that the functionality
is tested in the integration jobs.

Change-Id: I2de028ddac3bd8683b092f9b59f0b7bc13be87a3
(cherry picked from commit 58042b00f36ea5bed17a1701b4681ff24c96aaa4)
(cherry picked from commit 424fc512afc1e7cb99732e2d012e59557728d927)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/96/880096/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/tempest.pp'],1,553dfc86e5a2fe7356c1dd11630bfac8b9eed3e0,," $neutron_bgpvpn_extensions = $bgpvpn ? { true => ['bgpvpn'], default => [], } $neutron_l2gw_extensions + $neutron_bgpvpn_extensions", $neutron_l2gw_extensions,6,1
openstack%2Freleases~master~I54b28b54fce49c6f09efbc487010713e30e2f0a9,openstack/releases,master,I54b28b54fce49c6f09efbc487010713e30e2f0a9,Retire patrol,MERGED,2023-04-12 19:19:09.000000000,2023-04-17 08:37:35.000000000,2023-04-17 08:37:35.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-12 19:19:09.000000000', 'files': ['doc/source/reference/using.rst', 'deliverables/bobcat/patrole.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/56d321ccebdca75bf88b89981a8887d9ebb00861', 'message': 'Retire patrol\n\npatrole project is not maintained and in QA\nPTG, we decided to retire it.\n\n- https://etherpad.opendev.org/p/qa-bobcat-ptg\n\nBecause patrole is branchless deliverables, removing\nits deliverable file itself for bobcat.\n\nDepends-On: https://review.opendev.org/c/openstack/governance/+/880014\nChange-Id: I54b28b54fce49c6f09efbc487010713e30e2f0a9\n'}]",5,880229,56d321ccebdca75bf88b89981a8887d9ebb00861,11,4,1,8556,,,0,"Retire patrol

patrole project is not maintained and in QA
PTG, we decided to retire it.

- https://etherpad.opendev.org/p/qa-bobcat-ptg

Because patrole is branchless deliverables, removing
its deliverable file itself for bobcat.

Depends-On: https://review.opendev.org/c/openstack/governance/+/880014
Change-Id: I54b28b54fce49c6f09efbc487010713e30e2f0a9
",git fetch https://review.opendev.org/openstack/releases refs/changes/29/880229/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/using.rst', 'deliverables/bobcat/patrole.yaml']",2,56d321ccebdca75bf88b89981a8887d9ebb00861,retire-patrole,,--- launchpad: patrole release-model: cycle-with-intermediary team: Quality Assurance type: other stable-branch-type: none repository-settings: openstack/patrole: pypi-name: Patrole ,1,11
openstack%2Fneutron~master~I18d227d5a4bf87febe36c04f12dab07d210a0f95,openstack/neutron,master,I18d227d5a4bf87febe36c04f12dab07d210a0f95,[WIP][POC] NFTables,ABANDONED,2020-10-27 14:05:39.000000000,2023-04-17 08:21:14.000000000,,"[{'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 15752}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-27 14:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/792b3f56c8a1f8bf1b5003e65a86ddb060a29a89', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 2, 'created': '2020-11-02 16:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4610411c8ad39aa311b340cbb075313c7772c228', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 3, 'created': '2020-11-12 08:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2363dccd590603b413688480225f20797b7b6e8d', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 4, 'created': '2020-11-12 16:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69f7ae6272065603448bb2a3600df428ad1fdf20', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 5, 'created': '2022-10-26 10:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23a817e81638c28ad3bc9c21be7801a53edd34b5', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 6, 'created': '2022-10-26 14:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a9961c353fe4ccf8a09f6f7844d841860e9ed89', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 7, 'created': '2022-11-02 11:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e338b4d3d689aea7e7b17cc60f1df6f8086fa7d', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 8, 'created': '2022-11-04 12:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9bca3519bf0915a804a5234cdc0e91b14a02476', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 9, 'created': '2022-11-04 14:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14fac0c5f57f713020a50a142c2c29a9109bfbe7', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 10, 'created': '2022-11-04 16:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4fa0cd547ea91559df293109b6eb033c107c81c', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 11, 'created': '2022-11-04 16:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aeb09c6b5c2b9c575dd1904009ddb128394095ad', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 12, 'created': '2022-11-04 16:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f198b09d6288af2fbbe4953e26a06003cc590dac', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 13, 'created': '2022-11-07 09:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/502b881a823dcb453495066ef883b6fb506013ca', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 14, 'created': '2022-11-07 12:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5236fccdad3381de81d0c06cf0b14069ae77cfca', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 15, 'created': '2022-11-07 13:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6f58fe03a66ab99fcea6c4b7b2601822a1980a1', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 16, 'created': '2022-11-07 17:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb4479522590de6482f886efe1fe369b0a10b532', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 17, 'created': '2022-11-08 12:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28b1f383bc86737c4a0911ee14910b45e6dce9e7', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}, {'number': 18, 'created': '2022-11-22 16:33:08.000000000', 'files': ['neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/privileged/agent/linux/test_nftables.py', 'neutron/agent/l3/extensions/ndp_proxy.py', 'neutron/agent/l3/router_info.py', 'neutron/agent/linux/iptables_manager_l3.py', 'neutron/tests/unit/agent/linux/test_nftables_manager.py', 'zuul.d/project.yaml', 'neutron/agent/linux/nftables_manager.py', 'neutron/agent/l3/dvr_edge_router.py', 'neutron/privileged/agent/linux/nftables.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3f1c1a4ee95d3abe05e46a3977fea6223b6ec37', 'message': ""[WIP][POC] NFTables\n\nPlease, don't review this patch now (well, you can but this is just\na POC, nothing else)\n\nImplements: bluepring nftables-migration\nCloses-Bug: #----\n\nChange-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95\n""}]",236,759874,b3f1c1a4ee95d3abe05e46a3977fea6223b6ec37,74,6,18,16688,,,0,"[WIP][POC] NFTables

Please, don't review this patch now (well, you can but this is just
a POC, nothing else)

Implements: bluepring nftables-migration
Closes-Bug: #----

Change-Id: I18d227d5a4bf87febe36c04f12dab07d210a0f95
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/759874/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_nftables_manager.py', 'neutron/agent/linux/nftables_manager.py']",2,792b3f56c8a1f8bf1b5003e65a86ddb060a29a89,nft_migration,"# Copyright 2020 Red Hat Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import abc import collections import contextlib import difflib import os import re import sys from neutron_lib import constants from neutron_lib import exceptions from neutron_lib.exceptions import l3 as l3_exc from neutron_lib.utils import runtime from oslo_concurrency import lockutils from oslo_config import cfg from oslo_log import log as logging from oslo_serialization import jsonutils from oslo_utils import excutils from neutron._i18n import _ from neutron.agent.linux import ip_lib from neutron.agent.linux import iptables_comments as ic from neutron.agent.linux import utils as linux_utils from neutron.common import _constants as n_const from neutron.common import utils from neutron.conf.agent import common as config LOG = logging.getLogger(__name__) OPERATOR_BINARY_AND = '&' OPERATOR_BINARY_OR = '|' OPERATOR_BINARY_XOR = '^' OPERATOR_LEFT_SHIFT = '<<' OPERATOR_RIGHT_SHIFT = '>>' OPERATOR_EQUAL = '==' OPERATOR_NOT_EQUAL = '!=' OPERATOR_LESS_THAN = '<' OPERATOR_GREATER_THAN = '>' OPERATOR_LESS_OR_EQUAL = '<=' OPERATOR_GREATER_OR_EQUAL = '>=' OPERATOR_IN = 'in' OPERATORS = (OPERATOR_BINARY_AND, OPERATOR_BINARY_OR, OPERATOR_BINARY_XOR, OPERATOR_LEFT_SHIFT, OPERATOR_RIGHT_SHIFT, OPERATOR_EQUAL, OPERATOR_NOT_EQUAL, OPERATOR_LESS_THAN, OPERATOR_GREATER_THAN, OPERATOR_LESS_OR_EQUAL, OPERATOR_GREATER_OR_EQUAL, OPERATOR_IN) BINARY_OPERATORS = (OPERATOR_BINARY_AND, OPERATOR_BINARY_OR, OPERATOR_BINARY_XOR) # Payload protocols PROTOCOL_IP = 'ip' PROTOCOL_IP6 = 'ip6' PROTOCOL_TCP = 'tcp' PROTOCOL_UDP = 'udp' PROTOCOL_UDPLITE = 'udplite' PROTOCOL_SCTP = 'sctp' PROTOCOL_AH = 'ah' PROTOCOL_ESP = 'esp' PROTOCOL_COMP = 'comp' PROTOCOL_ICMP = 'icmp' PROTOCOL_ICMPV6 = 'icmpv6' PROTOCOL_ETHER = 'ether' PROTOCOL_DST = 'dst' PROTOCOL_FRAG = 'frag' PROTOCOL_HBH = 'hbh' PROTOCOL_MH = 'mh' PROTOCOL_RT = 'rt' # (TODO) PROTOCOL_VLAN: ""&"": [{""payload"": {""base"": ""ll"", ""offset"": 0, # ""len"": 16}}, # 4095] PROTOCOL_ARP = 'arp' PAYLOAD_PROTOCOLS = (PROTOCOL_IP, PROTOCOL_IP6, PROTOCOL_TCP, PROTOCOL_UDP, PROTOCOL_UDPLITE, PROTOCOL_SCTP, PROTOCOL_AH, PROTOCOL_ESP, PROTOCOL_COMP, PROTOCOL_ICMP, PROTOCOL_ICMPV6, PROTOCOL_ETHER, PROTOCOL_DST, PROTOCOL_FRAG, PROTOCOL_HBH, PROTOCOL_MH, PROTOCOL_RT, PROTOCOL_ARP) CT_STATE_NEW = 'new' CT_STATE_ESTABLISHED = 'established' CT_STATE_RELATED = 'related' CT_STATE_UNTRACKED = 'untracked' CT_STATES = (CT_STATE_NEW, CT_STATE_ESTABLISHED, CT_STATE_RELATED, CT_STATE_UNTRACKED) CT_STATUS_EXPECTED = 'expected' CT_STATUS_SEENREPLY = 'seen-reply' CT_STATUS_ASSURED = 'assured' CT_STATUS_CONFIRMED = 'confirmed' CT_STATUS_SNAT = 'snat' CT_STATUS_DNAT = 'dnat' CT_STATUS_DYING = 'dying' CT_STATUSES = (CT_STATUS_EXPECTED, CT_STATUS_SEENREPLY, CT_STATUS_ASSURED, CT_STATUS_CONFIRMED, CT_STATUS_SNAT, CT_STATUS_DNAT, CT_STATUS_DYING) STATEMENT_ACCEPT = 'accept' STATEMENT_DROP = 'drop' STATEMENT_QUEUE = 'queue' STATEMENT_CONTINUE = 'continue' STATEMENT_RETURN = 'return' STATEMENT_JUMP = 'jump' STATEMENT_REJECT = 'reject' STATEMENT_DNAT = 'dnat' STATEMENT_SNAT = 'snat' STATEMENT_MASQUERADE = 'masquerade' STATEMENT_REDIRECT = 'redirect' STATEMENTS = (STATEMENT_ACCEPT, STATEMENT_DROP, STATEMENT_QUEUE, STATEMENT_CONTINUE, STATEMENT_RETURN, STATEMENT_JUMP, STATEMENT_REJECT, STATEMENT_DNAT, STATEMENT_SNAT, STATEMENT_MASQUERADE, STATEMENT_REDIRECT) def get_binary_name(): """"""Grab the name of the binary we're running in."""""" return os.path.basename(sys.argv[0])[:16].replace(' ', '_') bin_name = get_binary_name() def get_chain_name(chain_name, wrap=True): if wrap: return chain_name[:constants.MAX_IPTABLES_CHAIN_LEN_WRAP] else: return chain_name[:constants.MAX_IPTABLES_CHAIN_LEN_NOWRAP] # TODO(ralonsoh): maybe remove this. class _Compare(object, metaclass=abc.ABCMeta): pass class _JsonDump(object, metaclass=abc.ABCMeta): def _name(self): return (getattr(self, 'JSON_NAME', None) or self.__class__.__name__.lower()) def to_json(self): return {self._name(): {k: v for k, v in self.__dict__.items() if v is not None}} class NFTablesJsonParser(_JsonDump): def __init__(self, metainfo, tables, chains, rules): self.metainfo = metainfo self.tables = tables self.chains = chains self.rules = rules @classmethod def from_json(cls, _json): if not 'nftables' in _json: raise Exception('JSON object is not a NFTables save file') metainfo = None tables = [] chains = [] rules = [] for register in _json['nftables']: if 'metainfo' in register: metainfo = Metainfo.from_json(register['metainfo']) elif 'table' in register: tables.append(Table.from_json(register['table'])) elif 'chain' in register: chains.append(Chain.from_json(register['chain'])) elif 'rule' in register: rules.append(Rule.from_json(register['rule'])) else: LOG.warning('Parameter not recognized in the NFTables JSON ' 'saved file: %s', next(iter(register))) return cls(metainfo, tables, chains, rules) def to_json(self): nftables = [self.metainfo.to_json()] for table in self.tables: nftables.append(table.to_json()) for chain in self.chains: nftables.append(chain.to_json()) for rule in self.rules: nftables.append(rule.to_json()) return {'nftables': nftables} class Metainfo(_JsonDump): def __init__(self, version, release_name, json_schema_version): self.version = version self.release_name = release_name self.json_schema_version = json_schema_version @classmethod def from_json(cls, _json): return cls(_json['version'], _json['release_name'], _json['json_schema_version']) class Rule(_JsonDump): def __init__(self, family, table, chain, handle, expr, comment=None, wrap=True, top=False, binary_name=bin_name, tag=None): self.family = family self.table = table self.chain = chain self.handle = handle self.expr = expr self.comment = comment self.wrap = wrap self.wrap_name = binary_name[:16] self.top = top self.tag = tag def __eq__(self, other): return ((self.chain == other.chain) and (self.table == other.table) and (self.expr == other.expr) and (self.top == other.top) and (self.wrap == other.wrap)) def __ne__(self, other): return not self == other @classmethod def from_json(cls, _json): return cls(_json['family'], _json['table'], _json['chain'], _json['handle'], [cls.parse_expr(expr) for expr in _json['expr']], comment=_json.get('comment'), wrap=False) @staticmethod def parse_expr(expr): command = next(iter(expr)) value = expr[command] if 'counter' == command: return RuleCounter.from_json(value) if 'match' == command: return RuleMatch.from_json(value) if command in STATEMENTS: return RuleStatement.from_json(command, value) if 'mangle' == command: return RuleMangle.from_json(value) raise Exception('Rule invalid command %s' % command) def to_json(self): chain = ('%s-%s' % (self.wrap_name, self.chain) if self.wrap else self.chain) rule = {'rule': {'family': self.family, 'table': self.table, 'chain': chain, 'handle': self.handle, 'expr': [expr.to_json() for expr in self.expr]}} if self.comment: rule['rule']['comment'] = self.comment return rule def is_jump_to_chain(self, chain): for _ in (expr for expr in self.expr if type(expr, RuleStatement) and expr.type == STATEMENT_JUMP and expr.target == chain): return True return False def is_jump_conditional(self): for _ in (expr for expr in self.expr if type(expr, RuleStatement) and expr.type == STATEMENT_JUMP and expr.wrapped_jump): return True return False class RuleCounter(_JsonDump): JSON_NAME = 'counter' def __init__(self, packets, bytes): self.packets = packets self.bytes = bytes @classmethod def from_json(cls, _json): return cls(_json['packets'], _json['bytes']) class RuleMatch(_JsonDump): def __init__(self, op, left, right): if op not in OPERATORS: raise Exception('Operator %(op)s not supported' % {'op': op}) self.op = op self.left = left self.right = right @classmethod def from_json(cls, _json): return cls(_json['op'], RuleMatchValue.from_json(_json['left']), RuleMatchValue.from_json(_json['right'])) def to_json(self): return {'match': {'op': self.op, 'left': self.left.to_json(), 'right': self.right.to_json()}} class RuleMatchBinaryOperator(_JsonDump): def __init__(self, op, first, second): if op not in BINARY_OPERATORS: raise Exception('Binary operator %(op)s not supported' % {'op': op}) self.op = op self.first = first self.second = second @classmethod def from_json(cls, _json): return cls(_json['op'], RuleMatchValue.from_json(_json['left']), RuleMatchValue.from_json(_json['right'])) def to_json(self): return {self.op: [self.first.to_json(), self.second.to_json()]} class RuleMatchValue(_JsonDump): def __init__(self, _type, raw_value=None, payload_protocol=None, payload_field=None, meta=None, ct=None, bool_operator=None, prefix_addr=None, prefix_len=None, _set=None, map_key=None, map_data=None): self.type = _type self.raw_value = raw_value self.payload_protocol = payload_protocol self.payload_field = payload_field self.meta = meta self.ct = ct self.bool_operator = bool_operator self.prefix_addr = prefix_addr self.prefix_len = prefix_len self.set = _set self.map_key = map_key self.map_data = map_data @classmethod def from_json(cls, _json): # Check if dictionary first if isinstance(_json, (str, int)): return cls('raw_value', raw_value=_json) if not isinstance(_json, dict): raise Exception('A rule match value should be a raw value ' '(int, str) or a dictionary; type: %s' % type(_json)) command = next(iter(_json)) value = _json[command] if 'payload' == command: payload = _json['payload'] return cls('payload', payload_protocol=payload['protocol'], payload_field=payload['field']) if 'ct' == command: payload = _json['ct'] return cls('ct', ct=payload['key']) if 'meta' == command: payload = _json['meta'] return cls('meta', meta=payload['key']) if 'prefix' == command: return cls(command, prefix_addr=value.get('addr'), prefix_len=value.get('len')) if command in BINARY_OPERATORS: first = RuleMatchValue.from_json(_json[command][0]) second = RuleMatchValue.from_json(_json[command][1]) return RuleMatchBinaryOperator(command, first, second) raise Exception('Command parameter %s not recognized as a rule match ' 'operator', command) def to_json(self): if 'raw_value' == self.type: return self.raw_value if 'payload' == self.type: return {self.type: {'protocol': self.payload_protocol, 'field': self.payload_field}} if 'ct' == self.type: return {self.type: {'key': self.ct}} if 'meta' == self.type: return {self.type: {'key': self.meta}} if 'prefix' == self.type: return {self.type: {'addr': self.prefix_addr, 'len': self.prefix_len}} class RuleStatement(_JsonDump): """""" -j <> """""" def __init__(self, _type, addr=None, port=None, target=None, flags=None): self.type = _type self.addr = addr self.flags = flags self.port = port if target and target.startswith('$'): self.wrapped_target = True self.target = target[1:] else: self.wrapped_target = False self.target = target @classmethod def from_json(cls, _type, _json): if not _json: return cls(_type) addr = _json.get('addr') # Could be str, range or # map (TODO) {key, data}. flags = _json.get('flags') # Could be str or list. port = _json.get('port') # Could be int target = _json.get('target') # Could be str (another chain) return cls(_type, addr=addr, port=port, target=target, flags=flags) def to_json(self): _json = {} for parameter in ('addr', 'flags', 'port', 'target'): if getattr(self, parameter, None): _json[parameter] = getattr(self, parameter) return {self.type: _json if _json else None} class RuleMangle(_JsonDump): """""" key, value: pueden ser cualquier match_value """""" def __init__(self, key, value): self.key = key self.value = value @classmethod def from_json(cls, _json): return cls(RuleMatchValue.from_json(_json['key']), RuleMatchValue.from_json(_json['value'])) def to_json(self): return {'mangle': {'key': self.key.to_json(), 'value': self.value.to_json()}} class Chain(_JsonDump): def __init__(self, family, table, name, handle, _type=None, hook=None, prio=None, policy=None, comment=None): self.family = family self.table = table self.name = name self.handle = handle self.type = _type self.hook = hook self.prio = prio self.policy = policy self.comment = comment @classmethod def from_json(cls, _json): return cls(_json['family'], _json['table'], _json['name'], _json['handle'], _type=_json.get('type'), hook=_json.get('hook'), prio=_json.get('prio'), policy=_json.get('policy'), comment=_json.get('comment')) class Table(_JsonDump): def __init__(self, family, name, handle, comment=None, binary_name=bin_name): self.family = family self.name = name self.handle = handle self.comment = comment self.rules = [] self.remove_rules = [] self.chains = set([]) self.unwrapped_chains = set() self.remove_chains = set() self.wrap_name = binary_name[:16] @classmethod def from_json(cls, _json): return cls(_json['family'], _json['name'], _json['handle'], comment=_json.get('comment')) def to_json(self): table = {'table': {'family': self.family, 'name': self.name, 'handle': self.handle}} if self.comment: table['table']['comment'] = self.comment return table def add_chain(self, name, wrap=True): """"""Adds a named chain to the table. The chain name is wrapped to be unique for the component creating it, so different components of Nova can safely create identically named chains without interfering with one another. At the moment, its wrapped name is <binary name>-<chain name>, so if neutron-openvswitch-agent creates a chain named 'OUTPUT', it'll actually end up being named 'neutron-openvswi-OUTPUT'. """""" name = get_chain_name(name, wrap) if wrap: self.chains.add(name) else: self.unwrapped_chains.add(name) def _select_chain_set(self, wrap): if wrap: return self.chains else: return self.unwrapped_chains def remove_chain(self, chain_name, wrap=True): """"""Remove named chain. This removal ""cascades"". All rule in the chain are removed, as are all rules in other chains that jump to it. If the chain is not found, this is merely logged. """""" chain_name = get_chain_name(chain_name, wrap) chain_set = self._select_chain_set(wrap) if chain_name not in chain_set: LOG.debug('Attempted to remove chain %s which does not exist', chain_name) return chain_set.remove(chain_name) if not wrap: jump_to_chain = chain_name # non-wrapped chains and rules need to be dealt with specially, # so we keep a list of them to be iterated over in apply() self.remove_chains.add(chain_name) self.remove_rules += [r for r in self.rules if r.chain == chain_name or r.is_jump_to_chain(jump_to_chain)] else: jump_to_chain = '%s-%s' % (self.wrap_name, chain_name) # Remove rules from list that have a matching chain name or # a matching jump chain self.rules = [r for r in self.rules if r.chain != chain_name and jump_to_chain not in r.rule] def add_rule(self, chain, rule, wrap=True, top=False, tag=None, comment=None): """"""Add a rule to the table. This is just like what you'd feed to iptables, just without the '-A <chain name>' bit at the start. However, if you need to jump to one of your wrapped chains, prepend its name with a '$' which will ensure the wrapping is applied correctly. """""" chain = get_chain_name(chain, wrap) if wrap and chain not in self.chains: raise LookupError(_('Unknown chain: %r') % chain) if '$' in rule: rule = ' '.join( self._wrap_target_chain(e, wrap) for e in rule.split(' ')) # self.rules.append(IptablesRule(chain, rule, wrap, top, self.wrap_name, # tag, comment)) self.rules.append(Rule(chain, rule, wrap, top, self.wrap_name, tag, comment)) def _wrap_target_chain(self, s, wrap): if s.startswith('$'): s = ('%s-%s' % (self.wrap_name, get_chain_name(s[1:], wrap))) return s # # TODO: refactor everything!!! # class NFTablesRule(object): # # def __init__(self, chain, rule, wrap=True, top=False, # binary_name=bin_name, tag=None, comment=None): # self.chain = get_chain_name(chain, wrap) # self.rule = rule # self.wrap = wrap # self.top = top # self.wrap_name = binary_name[:16] # self.tag = tag # self.comment = comment # # def __eq__(self, other): # return ((self.chain == other.chain) and # (self.rule == other.rule) and # (self.top == other.top) and # (self.wrap == other.wrap)) # # def __ne__(self, other): # return not self == other # # def __str__(self): # if self.wrap: # chain = '%s-%s' % (self.wrap_name, self.chain) # else: # chain = self.chain # rule = '-A %s %s' % (chain, self.rule) # # If self.rule is '' the above will cause a trailing space, which # # could cause us to not match on save/restore, so strip it now. # #return comment_rule(rule.strip(), self.comment) # # # # TODO: refactor everything!!! # class NFTablesTable(object): # # def __init__(self, binary_name=bin_name): # self.rules = [] # self.remove_rules = [] # self.chains = set() # self.unwrapped_chains = set() # self.remove_chains = set() # self.wrap_name = binary_name[:16] # # def add_chain(self, name, wrap=True): # """"""Adds a named chain to the table. # # The chain name is wrapped to be unique for the component creating # it, so different components of Nova can safely create identically # named chains without interfering with one another. # # At the moment, its wrapped name is <binary name>-<chain name>, # so if neutron-openvswitch-agent creates a chain named 'OUTPUT', # it'll actually end up being named 'neutron-openvswi-OUTPUT'. # # """""" # name = get_chain_name(name, wrap) # if wrap: # self.chains.add(name) # else: # self.unwrapped_chains.add(name) # # def _select_chain_set(self, wrap): # if wrap: # return self.chains # else: # return self.unwrapped_chains # # def remove_chain(self, name, wrap=True): # """"""Remove named chain. # # This removal ""cascades"". All rule in the chain are removed, as are # all rules in other chains that jump to it. # # If the chain is not found, this is merely logged. # # """""" # name = get_chain_name(name, wrap) # chain_set = self._select_chain_set(wrap) # # if name not in chain_set: # LOG.debug('Attempted to remove chain %s which does not exist', # name) # return # # chain_set.remove(name) # # if not wrap: # # non-wrapped chains and rules need to be dealt with specially, # # so we keep a list of them to be iterated over in apply() # self.remove_chains.add(name) # # # Add rules to remove that have a matching chain name or # # a matching jump chain # jump_snippet = '-j %s' % name # self.remove_rules += [str(r) for r in self.rules # if r.chain == name or jump_snippet in r.rule] # else: # jump_snippet = '-j %s-%s' % (self.wrap_name, name) # # # Remove rules from list that have a matching chain name or # # a matching jump chain # self.rules = [r for r in self.rules # if r.chain != name and jump_snippet not in r.rule] # # def add_rule(self, chain, rule, wrap=True, top=False, tag=None, # comment=None): # """"""Add a rule to the table. # # This is just like what you'd feed to iptables, just without # the '-A <chain name>' bit at the start. # # However, if you need to jump to one of your wrapped chains, # prepend its name with a '$' which will ensure the wrapping # is applied correctly. # # """""" # chain = get_chain_name(chain, wrap) # if wrap and chain not in self.chains: # raise LookupError(_('Unknown chain: %r') % chain) # # if '$' in rule: # rule = ' '.join( # self._wrap_target_chain(e, wrap) for e in rule.split(' ')) # # self.rules.append(NFTablesRule(chain, rule, wrap, top, self.wrap_name, # tag, comment)) # # def _wrap_target_chain(self, s, wrap): # if s.startswith('$'): # s = ('%s-%s' % (self.wrap_name, get_chain_name(s[1:], wrap))) # # return s # # def remove_rule(self, chain, rule, wrap=True, top=False, comment=None): # """"""Remove a rule from a chain. # # Note: The rule must be exactly identical to the one that was added. # You cannot switch arguments around like you can with the iptables # CLI tool. # # """""" # chain = get_chain_name(chain, wrap) # try: # if '$' in rule: # rule = ' '.join( # self._wrap_target_chain(e, wrap) for e in rule.split(' ')) # # self.rules.remove(NFTablesRule(chain, rule, wrap, top, # self.wrap_name, # comment=comment)) # if not wrap: # self.remove_rules.append(str(NFTablesRule(chain, rule, wrap, # top, self.wrap_name, # comment=comment))) # except ValueError: # LOG.warning('Tried to remove rule that was not there:' # ' %(chain)r %(rule)r %(wrap)r %(top)r', # {'chain': chain, 'rule': rule, # 'top': top, 'wrap': wrap}) # # def _get_chain_rules(self, chain, wrap): # chain = get_chain_name(chain, wrap) # return [rule for rule in self.rules # if rule.chain == chain and rule.wrap == wrap] # # def empty_chain(self, chain, wrap=True): # """"""Remove all rules from a chain."""""" # chained_rules = self._get_chain_rules(chain, wrap) # for rule in chained_rules: # self.rules.remove(rule) # # def clear_rules_by_tag(self, tag): # if not tag: # return # rules = [rule for rule in self.rules if rule.tag == tag] # for rule in rules: # self.rules.remove(rule) # # class NFTablesManager(object): # # def __init__(self, _execute=None, state_less=False, use_ipv6=False, # nat=True, namespace=None, binary_name=bin_name): # if _execute: # self.execute = _execute # else: # self.execute = linux_utils.execute # # self.use_ipv6 = use_ipv6 # self.namespace = namespace # self.nftables_apply_deferred = False # self.wrap_name = binary_name[:16] # # self.ipv4 = {'filter': NFTablesTable(binary_name=self.wrap_name)} # self.ipv6 = {'filter': NFTablesTable(binary_name=self.wrap_name)} # # TODO: configure default ""filter"" tables (ipv4, ipv6) # # TODO: configure default ""raw"" tables (ipv4, ipv6) # # TODO: configure default ""mangle"" tables (ipv4, ipv6), if needed # # TODO: configure default ""nat"" tables (ipv4, ipv6), if needed # # def get_tables(self, ip_version): # return {4: self.ipv4, 6: self.ipv6}[ip_version] # # def apply(self): # if self.nftables_apply_deferred: # return # return self._apply() # # def _apply(self): # pass ",,2523,0
openstack%2Fneutron~master~I688f5a19fbf44acaa26176679800f4b13bc827bb,openstack/neutron,master,I688f5a19fbf44acaa26176679800f4b13bc827bb,[DNM] Testing OVN default_acl_drop option,ABANDONED,2022-11-29 23:46:27.000000000,2023-04-17 08:21:09.000000000,,"[{'_account_id': 4694}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-29 23:46:27.000000000', 'files': ['neutron/common/ovn/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/72547cb453a61fca238ccec80d5451314fe86fc2', 'message': '[DNM] Testing OVN default_acl_drop option\n\nTesting OVN default_acl_drop option\n\nDepends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/848198\nChange-Id: I688f5a19fbf44acaa26176679800f4b13bc827bb\n'}]",1,866095,72547cb453a61fca238ccec80d5451314fe86fc2,7,3,1,4694,,,0,"[DNM] Testing OVN default_acl_drop option

Testing OVN default_acl_drop option

Depends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/848198
Change-Id: I688f5a19fbf44acaa26176679800f4b13bc827bb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/866095/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/common/ovn/constants.py'],1,72547cb453a61fca238ccec80d5451314fe86fc2,test_ovn_default_acl_drop,# Force a change OVN_DEFAULT_ACL_DROP = 'default_acl_drop',,2,0
openstack%2Fneutron~master~Ib614fd5fcb4159642695ab0b380fbc8ae49c0776,openstack/neutron,master,Ib614fd5fcb4159642695ab0b380fbc8ae49c0776,[OVN] Update fip while fixed_ip of internal port has changed,ABANDONED,2022-12-16 10:14:32.000000000,2023-04-17 08:21:05.000000000,,"[{'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-16 10:14:32.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4c29187c90cdeefb3c046e19127456a6d785a43', 'message': '[OVN] Update fip while fixed_ip of internal port has changed\n\nIf we updated fixed_ips of one internal port which associated\na floatingip, but the dnat_adn_snat entry in ovn will not change.\n\nWe fix it by that it always query nat entries related the internal\nlogical port from ovn-nb when update_port, then update fip if nat\nentries are not empty and logical_ip is not change.\n\nCloses-Bug: #1999209\nChange-Id: Ib614fd5fcb4159642695ab0b380fbc8ae49c0776\n'}]",4,867964,e4c29187c90cdeefb3c046e19127456a6d785a43,7,3,1,28056,,,0,"[OVN] Update fip while fixed_ip of internal port has changed

If we updated fixed_ips of one internal port which associated
a floatingip, but the dnat_adn_snat entry in ovn will not change.

We fix it by that it always query nat entries related the internal
logical port from ovn-nb when update_port, then update fip if nat
entries are not empty and logical_ip is not change.

Closes-Bug: #1999209
Change-Id: Ib614fd5fcb4159642695ab0b380fbc8ae49c0776
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/867964/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'],1,e4c29187c90cdeefb3c046e19127456a6d785a43,bug/1999209," # Query dnat_and_snat entries related this logical_port nats = self._nb_idl.db_find_rows( 'NAT', ('logical_port', '=', port['id']), ('type', '=', 'dnat_and_snat') ).execute(check_error=True) for nat in nats: fip_id = nat.external_ids.get(ovn_const.OVN_FIP_EXT_ID_KEY) if fip_id: fixed_ip_v4 = None for fixed_ip in port['fixed_ips']: subnet_id = fixed_ip['subnet_id'] subnet = self._plugin.get_subnet(context, subnet_id) # Only consider ipv4 address if subnet['ip_version'] == const.IP_VERSION_4: fixed_ip_v4 = fixed_ip['ip_address'] break if fixed_ip_v4 and fixed_ip_v4 != nat.logical_ip: fip_body = {'floatingip': { 'fixed_ip_address': fixed_ip_v4, 'port_id': port['id']}} self._l3_plugin.update_floatingip(context, fip_id, fip_body) break ",,25,0
openstack%2Fovn-bgp-agent~master~I84bb648eaad0f43aae6a17470ef1e7754e2f59f5,openstack/ovn-bgp-agent,master,I84bb648eaad0f43aae6a17470ef1e7754e2f59f5,[WIP] Add support for distributed routers,NEW,2022-12-12 11:19:53.000000000,2023-04-17 08:03:45.000000000,,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2022-12-12 11:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/841cca32b4948c2efcbb7919cfb041c0d86874a8', 'message': '[WIP] Add support for distributed routers\n\nWith this patch we add support for distributed routers. In that\ncase there is no need to go through a centralized node, as there\nis no cr-lrp created for it. Thus the traffic can be directly\nsent/received on the node where the VM is (the same as with FIPs\nwith DVR) but for tenant networks IPs.\n\nStil missing in this patch:\n- Unittesting coverage\n- Testing\n\nTO DO in follow up patch sets:\n- Add proper support for ovn-lb\n- Ensure FIPs are supported and recovered properly\n- Documentation and current limitations\n- Release note\n\nChange-Id: I84bb648eaad0f43aae6a17470ef1e7754e2f59f5\n'}, {'number': 2, 'created': '2022-12-19 13:13:25.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/config.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/a9b07a6fcdc685dfd0cdaf2ae995c20402fc4035', 'message': '[WIP] Add support for distributed routers\n\nWith this patch we add support for distributed routers. In that\ncase there is no need to go through a centralized node, as there\nis no cr-lrp created for it. Thus the traffic can be directly\nsent/received on the node where the VM is (the same as with FIPs\nwith DVR) but for tenant networks IPs.\n\nStil missing in this patch:\n- Unittesting coverage\n- Testing\n\nTO DO in follow up patch sets:\n- Add proper support for ovn-lb\n- Ensure FIPs are supported and recovered properly\n- Documentation and current limitations\n- Release note\n\nChange-Id: I84bb648eaad0f43aae6a17470ef1e7754e2f59f5\n'}]",0,866527,a9b07a6fcdc685dfd0cdaf2ae995c20402fc4035,4,3,2,23567,,,0,"[WIP] Add support for distributed routers

With this patch we add support for distributed routers. In that
case there is no need to go through a centralized node, as there
is no cr-lrp created for it. Thus the traffic can be directly
sent/received on the node where the VM is (the same as with FIPs
with DVR) but for tenant networks IPs.

Stil missing in this patch:
- Unittesting coverage
- Testing

TO DO in follow up patch sets:
- Add proper support for ovn-lb
- Ensure FIPs are supported and recovered properly
- Documentation and current limitations
- Release note

Change-Id: I84bb648eaad0f43aae6a17470ef1e7754e2f59f5
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/27/866527/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/config.py']",2,841cca32b4948c2efcbb7919cfb041c0d86874a8,," cfg.BoolOpt('distributed_routing', default=False, help='Enable if OVN routers are fully distributed, i.e., ' 'without centralized gateway chassis port (cr-lrp).'),",,88,36
openstack%2Fneutron-tempest-plugin~master~I65681721ebdda011672862f729023961aecba047,openstack/neutron-tempest-plugin,master,I65681721ebdda011672862f729023961aecba047,[DNM] Test with default tb-cache,ABANDONED,2023-01-01 13:54:27.000000000,2023-04-17 08:03:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-01 13:54:27.000000000', 'files': ['zuul.d/base-nested-switch.yaml', 'zuul.d/wallaby_jobs.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/xena_jobs.yaml', 'zuul.d/yoga_jobs.yaml', 'zuul.d/project.yaml', 'zuul.d/zed_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/2901d55d614cf73c43a4bb6666759e49745853c5', 'message': '[DNM] Test with default tb-cache\n\nChange-Id: I65681721ebdda011672862f729023961aecba047\n'}]",0,868948,2901d55d614cf73c43a4bb6666759e49745853c5,3,1,1,13861,,,0,"[DNM] Test with default tb-cache

Change-Id: I65681721ebdda011672862f729023961aecba047
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/48/868948/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base-nested-switch.yaml', 'zuul.d/wallaby_jobs.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/xena_jobs.yaml', 'zuul.d/yoga_jobs.yaml', 'zuul.d/project.yaml', 'zuul.d/zed_jobs.yaml']",7,2901d55d614cf73c43a4bb6666759e49745853c5,dnm, nodeset: neutron-nested-virt-ubuntu-focal nodeset: neutron-nested-virt-ubuntu-focal nodeset: neutron-nested-virt-ubuntu-focal nodeset: neutron-nested-virt-ubuntu-focal nodeset: neutron-nested-virt-ubuntu-focal,,154,46
openstack%2Fneutron-tempest-plugin~master~Ib242dfeca4f348a30f31729a7c7584af0c50edf8,openstack/neutron-tempest-plugin,master,Ib242dfeca4f348a30f31729a7c7584af0c50edf8,[DNM] Test tb-cache workaround for jammy,ABANDONED,2022-12-16 06:38:15.000000000,2023-04-17 08:03:32.000000000,,"[{'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-16 06:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/7bbeffe102e2e63c553f09ca7d78a45f59b52e86', 'message': '[DNM] Test lower concurrency on non nested provider\n\nworkaround https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/867320\n\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 2, 'created': '2022-12-16 10:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/39b26e9a16e0df763de733ee189ca2cfe26e9d29', 'message': '[DNM] Test lower concurrency on non nested provider\n\nCheck if zram helps, it will create half the\nswap of total memory.\n\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 3, 'created': '2022-12-16 15:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/a82c8fa7a874006550b680399f61d6a217b2568a', 'message': '[DNM] Test lower concurrency on non nested provider\n\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 4, 'created': '2022-12-22 15:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/5aa7a97deec0c83cc56ecc2c204a40f541ecd75d', 'message': '[DNM] Test tb-cache workaround for jammy\n\nDepends-On: https://review.opendev.org/c/openstack/nova/+/868419\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 5, 'created': '2022-12-29 17:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/ce4ba0f0ce1918de1a551fcf2a6ff30069607ab2', 'message': '[DNM] Test tb-cache workaround for jammy\n\nDepends-On: https://review.opendev.org/c/openstack/nova/+/868419\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 6, 'created': '2022-12-30 14:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/b65e2ed75b40739b8d1cc345256b61d60c1d40c2', 'message': '[DNM] Test tb-cache workaround for jammy\n\nDepends-On: https://review.opendev.org/c/openstack/nova/+/868419\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 7, 'created': '2023-01-01 13:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/44b2a739b2bc9bfa776fe55f66f6e471c6d392f0', 'message': '[DNM] Test tb-cache workaround for jammy\n\nDepends-On: https://review.opendev.org/c/openstack/nova/+/868419\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}, {'number': 8, 'created': '2023-01-03 15:52:15.000000000', 'files': ['zuul.d/base-nested-switch.yaml', 'zuul.d/wallaby_jobs.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/xena_jobs.yaml', 'zuul.d/yoga_jobs.yaml', 'zuul.d/project.yaml', 'zuul.d/zed_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/a13e9d35cc0590029a7871ab6541cd54649b6110', 'message': '[DNM] Test tb-cache workaround for jammy\n\nDepends-On: https://review.opendev.org/c/openstack/nova/+/868419\nChange-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8\n'}]",0,867934,a13e9d35cc0590029a7871ab6541cd54649b6110,17,2,8,13861,,,0,"[DNM] Test tb-cache workaround for jammy

Depends-On: https://review.opendev.org/c/openstack/nova/+/868419
Change-Id: Ib242dfeca4f348a30f31729a7c7584af0c50edf8
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/34/867934/7 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base-nested-switch.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/project.yaml']",3,7bbeffe102e2e63c553f09ca7d78a45f59b52e86,dnm,- job: name: neutron-tempest-plugin-linuxbridge-1 parent: neutron-tempest-plugin-linuxbridge - job: name: neutron-tempest-plugin-linuxbridge-2 parent: neutron-tempest-plugin-linuxbridge - job: name: neutron-tempest-plugin-linuxbridge-3 parent: neutron-tempest-plugin-linuxbridge - job: name: neutron-tempest-plugin-linuxbridge-4 parent: neutron-tempest-plugin-linuxbridge - job: name: neutron-tempest-plugin-linuxbridge-5 parent: neutron-tempest-plugin-linuxbridge - job: name: neutron-tempest-plugin-openvswitch-1 parent: neutron-tempest-plugin-openvswitch - job: name: neutron-tempest-plugin-openvswitch-2 parent: neutron-tempest-plugin-openvswitch - job: name: neutron-tempest-plugin-openvswitch-3 parent: neutron-tempest-plugin-openvswitch - job: name: neutron-tempest-plugin-openvswitch-4 parent: neutron-tempest-plugin-openvswitch - job: name: neutron-tempest-plugin-openvswitch-5 parent: neutron-tempest-plugin-openvswitch - job: name: neutron-tempest-plugin-ovn-1 parent: neutron-tempest-plugin-ovn - job: name: neutron-tempest-plugin-ovn-2 parent: neutron-tempest-plugin-ovn - job: name: neutron-tempest-plugin-ovn-3 parent: neutron-tempest-plugin-ovn - job: name: neutron-tempest-plugin-ovn-4 parent: neutron-tempest-plugin-ovn - job: name: neutron-tempest-plugin-ovn-5 parent: neutron-tempest-plugin-ovn - neutron-tempest-plugin-ovn-1 - neutron-tempest-plugin-ovn-2 - neutron-tempest-plugin-ovn-3 - neutron-tempest-plugin-ovn-4 - neutron-tempest-plugin-ovn-5 - neutron-tempest-plugin-openvswitch-1 - neutron-tempest-plugin-openvswitch-2 - neutron-tempest-plugin-openvswitch-3 - neutron-tempest-plugin-openvswitch-4 - neutron-tempest-plugin-openvswitch-5 - neutron-tempest-plugin-linuxbridge-1 - neutron-tempest-plugin-linuxbridge-2 - neutron-tempest-plugin-linuxbridge-3 - neutron-tempest-plugin-linuxbridge-4 - neutron-tempest-plugin-linuxbridge-5, templates: - build-openstack-docs-pti - neutron-tempest-plugin-jobs - neutron-tempest-plugin-jobs-wallaby - neutron-tempest-plugin-jobs-xena - neutron-tempest-plugin-jobs-yoga - neutron-tempest-plugin-jobs-zed - check-requirements - tempest-plugin-jobs - release-notes-jobs-python3 - neutron-tempest-plugin-sfc - neutron-tempest-plugin-sfc-wallaby - neutron-tempest-plugin-sfc-xena - neutron-tempest-plugin-sfc-yoga - neutron-tempest-plugin-sfc-zed - neutron-tempest-plugin-bgpvpn-bagpipe - neutron-tempest-plugin-bgpvpn-bagpipe-wallaby - neutron-tempest-plugin-bgpvpn-bagpipe-xena - neutron-tempest-plugin-bgpvpn-bagpipe-yoga - neutron-tempest-plugin-bgpvpn-bagpipe-zed - neutron-tempest-plugin-dynamic-routing - neutron-tempest-plugin-dynamic-routing-wallaby - neutron-tempest-plugin-dynamic-routing-xena - neutron-tempest-plugin-dynamic-routing-yoga - neutron-tempest-plugin-dynamic-routing-zed - neutron-tempest-plugin-fwaas - neutron-tempest-plugin-fwaas-zed - neutron-tempest-plugin-vpnaas - neutron-tempest-plugin-vpnaas-wallaby - neutron-tempest-plugin-vpnaas-xena - neutron-tempest-plugin-vpnaas-yoga - neutron-tempest-plugin-vpnaas-zed - neutron-tempest-plugin-tap-as-a-service - neutron-tempest-plugin-tap-as-a-service-xena - neutron-tempest-plugin-tap-as-a-service-yoga - neutron-tempest-plugin-tap-as-a-service-zed,88,46
openstack%2Ftap-as-a-service~master~Ibdcb930d177160b81dbd540a662c52bba2cfb862,openstack/tap-as-a-service,master,Ibdcb930d177160b81dbd540a662c52bba2cfb862,Support cross-node traffic in the vlan network,ABANDONED,2022-12-31 03:02:17.000000000,2023-04-17 08:03:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-12-31 03:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/0e030235afc7ea6be86c364b7bd12368123ec58d', 'message': 'Support cross-node traffic in the vlan network\n\nIn an inter-node vlan network, the vlan ID is converted to the actual vlan ID when traffic is sent out of the node\n\nWhen a br-ex bridge is sent from a physical switch, the external vlan id must be converted to the internal vlan id. Otherwise, traffic cannot be sent to VMS due to broadcast domain errors\n\nChange-Id: Ibdcb930d177160b81dbd540a662c52bba2cfb862\n'}, {'number': 2, 'created': '2022-12-31 06:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/1b65a1a6fdfb1d5c5ef16f5cec34960c045c9d7e', 'message': 'Support cross-node traffic in the vlan network\n\nIn an inter-node vlan network, the vlan ID is converted to the actual vlan ID when traffic is sent out of the node\n\nWhen a br-ex bridge is sent from a physical switch, the external vlan id must be converted to the internal vlan id. Otherwise, traffic cannot be sent to VMS due to broadcast domain errors\n\nChange-Id: Ibdcb930d177160b81dbd540a662c52bba2cfb862\n'}, {'number': 3, 'created': '2022-12-31 07:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/69a3cf0a2b3e1f132b07bfa13adad92485f85b1b', 'message': 'Support cross-node traffic in the vlan network\n\nIn an inter-node vlan network, the vlan ID is converted to the actual vlan ID when traffic is sent out of the node\n\nWhen a br-ex bridge is sent from a physical switch, the external vlan id must be converted to the internal vlan id. Otherwise, traffic cannot be sent to VMS due to broadcast domain errors\n\nChange-Id: Ibdcb930d177160b81dbd540a662c52bba2cfb862\n'}, {'number': 4, 'created': '2022-12-31 08:23:50.000000000', 'files': ['neutron_taas/services/taas/drivers/linux/ovs_taas.py'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/4533b8805ebcd7ba17a879f0a3a7d87cefb5ece4', 'message': 'Support cross-node traffic in the vlan network\n\nIn an inter-node vlan network, the vlan ID is converted to the actual vlan ID when traffic is sent out of the node\n\nWhen a br-ex bridge is sent from a physical switch, the external vlan id must be converted to the internal vlan id. Otherwise, traffic cannot be sent to VMS due to broadcast domain errors\n\nChange-Id: Ibdcb930d177160b81dbd540a662c52bba2cfb862\n'}]",10,868953,4533b8805ebcd7ba17a879f0a3a7d87cefb5ece4,11,1,4,32921,,,0,"Support cross-node traffic in the vlan network

In an inter-node vlan network, the vlan ID is converted to the actual vlan ID when traffic is sent out of the node

When a br-ex bridge is sent from a physical switch, the external vlan id must be converted to the internal vlan id. Otherwise, traffic cannot be sent to VMS due to broadcast domain errors

Change-Id: Ibdcb930d177160b81dbd540a662c52bba2cfb862
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/53/868953/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_taas/services/taas/drivers/linux/ovs_taas.py'],1,0e030235afc7ea6be86c364b7bd12368123ec58d,," # Get in_br_ex port ID in_br_ex_id = self.int_br.get_port_ofport('int-br-ex') # Get VLAN tag for tap flow port port_dict = self.int_br.get_port_tag_dict() port_vlan_id = port_dict[ovs_port.port_name] self.int_br.add_flow(table=0, priority=30, # dl_vlan=port_vlan_id, in_port=in_br_ex_id, dl_dst=port_mac, actions=( ""mod_vlan_id:%s,normal,"" ""mod_vlan_vid:%s,output:%s"" % (str(port_vlan_id), str(taas_id), str(patch_int_tap_id))))",,17,0
openstack%2Fneutron~master~Ib8c930c8f4bb59795cd80d56fdf35d6b90454e8e,openstack/neutron,master,Ib8c930c8f4bb59795cd80d56fdf35d6b90454e8e,ovn-migration: Ping backup node only in start-migration,ABANDONED,2023-01-05 19:45:29.000000000,2023-04-17 08:03:15.000000000,,"[{'_account_id': 22348}, {'_account_id': 34271}]","[{'number': 1, 'created': '2023-01-05 19:45:29.000000000', 'files': ['tools/ovn_migration/tripleo_environment/ovn_migration.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d437f4f91fed96c98c506c9b499f3463c80b8997', 'message': ""ovn-migration: Ping backup node only in start-migration\n\nPreviously, the backup node was pinged when modifying MTU settings. At\nthat time the backup node doesn't need to be accessible because it's\nunused. The patch moves the check just when start-migration is issued.\n\nChange-Id: Ib8c930c8f4bb59795cd80d56fdf35d6b90454e8e\n""}]",1,869398,d437f4f91fed96c98c506c9b499f3463c80b8997,6,2,1,8655,,,0,"ovn-migration: Ping backup node only in start-migration

Previously, the backup node was pinged when modifying MTU settings. At
that time the backup node doesn't need to be accessible because it's
unused. The patch moves the check just when start-migration is issued.

Change-Id: Ib8c930c8f4bb59795cd80d56fdf35d6b90454e8e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/869398/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/ovn_migration/tripleo_environment/ovn_migration.sh'],1,d437f4f91fed96c98c506c9b499f3463c80b8997,ovn-migration,} check_backup_node() { check_backup_node, # Check if backup is enabled,4,1
openstack%2Fneutron~master~I91180b602182adddf74075109293e73b21c00b47,openstack/neutron,master,I91180b602182adddf74075109293e73b21c00b47,ovn-migration: Exit if backup node doesn't respond to ping,ABANDONED,2023-01-05 19:45:29.000000000,2023-04-17 08:03:11.000000000,,"[{'_account_id': 22348}, {'_account_id': 34271}]","[{'number': 1, 'created': '2023-01-05 19:45:29.000000000', 'files': ['tools/ovn_migration/tripleo_environment/ovn_migration.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b14b3e964b9c631fd56639b4ccf01790b3fcd4eb', 'message': ""ovn-migration: Exit if backup node doesn't respond to ping\n\nPreviously the migration continued even if backup feature was enabled\nbut the backup node was not accesible. This patch doesn't start the\nmigration if backup node doesn't respond.\n\nChange-Id: I91180b602182adddf74075109293e73b21c00b47\n""}]",1,869399,b14b3e964b9c631fd56639b4ccf01790b3fcd4eb,6,2,1,8655,,,0,"ovn-migration: Exit if backup node doesn't respond to ping

Previously the migration continued even if backup feature was enabled
but the backup node was not accesible. This patch doesn't start the
migration if backup node doesn't respond.

Change-Id: I91180b602182adddf74075109293e73b21c00b47
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/869399/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/ovn_migration/tripleo_environment/ovn_migration.sh'],1,b14b3e964b9c631fd56639b4ccf01790b3fcd4eb,ovn-migration, exit 1,,1,0
openstack%2Fneutron~master~I7482ee3f91c99d5f586381b8c1a45653d65aee8a,openstack/neutron,master,I7482ee3f91c99d5f586381b8c1a45653d65aee8a,DNM Trying to get fullstack logs with tox4,ABANDONED,2022-12-22 10:13:22.000000000,2023-04-17 08:03:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-12-22 10:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45041e6c2cfc352d1f6794175558172cf9ea7a25', 'message': 'DNM Trying to get fullstack logs with tox4\n\nChange-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a\n'}, {'number': 2, 'created': '2022-12-22 14:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d209da268271f5e918e11052ca4b4d54987b5b79', 'message': 'DNM Trying to get fullstack logs with tox4\n\nChange-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a\n'}, {'number': 3, 'created': '2023-01-23 11:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db561a3ba053865b4510d32abcf3f5bfb2d532b0', 'message': 'DNM Trying to get fullstack logs with tox4\n\nChange-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a\n'}, {'number': 4, 'created': '2023-01-25 18:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/458971353b18afaf4a4920dab2c71e04a00b033e', 'message': 'DNM Trying to get fullstack logs with tox4\n\nChange-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a\n'}, {'number': 5, 'created': '2023-02-06 11:28:02.000000000', 'files': ['playbooks/run_functional_job.yaml', 'playbooks/configure_functional_job.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c9207a5caff9db350416205a52797fcbb20a257', 'message': 'DNM Trying to get fullstack logs with tox4\n\nChange-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a\n'}]",0,868380,4c9207a5caff9db350416205a52797fcbb20a257,16,1,5,11975,,,0,"DNM Trying to get fullstack logs with tox4

Change-Id: I7482ee3f91c99d5f586381b8c1a45653d65aee8a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/868380/4 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,45041e6c2cfc352d1f6794175558172cf9ea7a25,bug/1999558, OS_LOG_PATH={env:OS_LOG_PATH:/opt/stack/logs},,1,0
openstack%2Fneutron-lib~master~Ifddfa9646bedf84cf5199efa864cecb08b89071f,openstack/neutron-lib,master,Ifddfa9646bedf84cf5199efa864cecb08b89071f,Update status code for ExternalGatewayForFloatingIPNotFound,ABANDONED,2023-02-06 12:23:33.000000000,2023-04-17 08:03:03.000000000,,"[{'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 29074}]","[{'number': 1, 'created': '2023-02-06 12:23:33.000000000', 'files': ['releasenotes/notes/http-status-floating-ip-no-ext-gtw-e8b99d72ea36e8e1.yaml', 'neutron_lib/exceptions/l3.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/345064c62e2bfb1186addf4be20b7c385e6b9a7e', 'message': 'Update status code for ExternalGatewayForFloatingIPNotFound\n\nWhen trying to associate a floating ip with a port that does not have access\nto the floating ip network (e.g. there is no router connected) a\nExternalGatewayForFloatingIPNotFound exception is raised. This exception is\ntranslated to the client as a http status code 404.\n\nThis is missleading as we can be sure that the requested resource has\nbeen found. However the client is in error to assume the resource can be\nused this way.\n\nTherefor the more appropriate status code is ""Bad Request"" (400).\n\nCloses-Bug: #2006122\nChange-Id: Ifddfa9646bedf84cf5199efa864cecb08b89071f\n'}]",2,872748,345064c62e2bfb1186addf4be20b7c385e6b9a7e,6,3,1,29074,,,0,"Update status code for ExternalGatewayForFloatingIPNotFound

When trying to associate a floating ip with a port that does not have access
to the floating ip network (e.g. there is no router connected) a
ExternalGatewayForFloatingIPNotFound exception is raised. This exception is
translated to the client as a http status code 404.

This is missleading as we can be sure that the requested resource has
been found. However the client is in error to assume the resource can be
used this way.

Therefor the more appropriate status code is ""Bad Request"" (400).

Closes-Bug: #2006122
Change-Id: Ifddfa9646bedf84cf5199efa864cecb08b89071f
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/48/872748/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/http-status-floating-ip-no-ext-gtw-e8b99d72ea36e8e1.yaml', 'neutron_lib/exceptions/l3.py']",2,345064c62e2bfb1186addf4be20b7c385e6b9a7e,status_floating_ip_missing_router,class ExternalGatewayForFloatingIPNotFound(exceptions.BadRequest):,class ExternalGatewayForFloatingIPNotFound(exceptions.NotFound):,7,1
openstack%2Fneutron~stable%2Fvictoria~Idf522a20f9735829ee568020bfed46345a95e294,openstack/neutron,stable/victoria,Idf522a20f9735829ee568020bfed46345a95e294,[ovn]neutron agent show real heartbeat_timestamp,ABANDONED,2023-02-06 10:32:35.000000000,2023-04-17 08:02:58.000000000,,"[{'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-06 10:32:35.000000000', 'files': ['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9372ca93a9c67890151e7e50a2d573aa3d83d327', 'message': ""[ovn]neutron agent show real heartbeat_timestamp\n\nagent's heartbeat_timestamp returns the current time, not\nconducive to agent status troubleshooting.\nthis patch use agent's updated_at as heartbeat_timestamp.\n\nCloses-bug: #1977629\n\nChange-Id: Idf522a20f9735829ee568020bfed46345a95e294\n(cherry picked from commit 411ecc4865198e2bed5e3d0ab498e3a42408c17d)\n""}]",1,872683,9372ca93a9c67890151e7e50a2d573aa3d83d327,5,2,1,30463,,,0,"[ovn]neutron agent show real heartbeat_timestamp

agent's heartbeat_timestamp returns the current time, not
conducive to agent status troubleshooting.
this patch use agent's updated_at as heartbeat_timestamp.

Closes-bug: #1977629

Change-Id: Idf522a20f9735829ee568020bfed46345a95e294
(cherry picked from commit 411ecc4865198e2bed5e3d0ab498e3a42408c17d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/872683/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py']",2,9372ca93a9c67890151e7e50a2d573aa3d83d327,," 'heartbeat_timestamp': self.updated_at,"," 'heartbeat_timestamp': timeutils.utcnow(),",22,1
openstack%2Fneutron-lib~master~Ia117189294c06dfc859e6a23cd9d20aca4d7c95f,openstack/neutron-lib,master,Ia117189294c06dfc859e6a23cd9d20aca4d7c95f,model_query: Improve perf with large # of RBAC,ABANDONED,2021-11-10 16:57:41.000000000,2023-04-17 08:02:54.000000000,,"[{'_account_id': 5948}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-11-10 16:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/ae770f46925479b51fff9557265fc629a8d0edac', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\n'}, {'number': 2, 'created': '2021-11-10 17:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/0079ce3525e90096ffa0eb897b7ceb0d5b48be26', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\n'}, {'number': 3, 'created': '2021-11-10 17:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/d7892389232b8224807b40fa1f50a08ed3be0139', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\n'}, {'number': 4, 'created': '2021-11-10 17:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/bf873cb0eaa19ca73ce75981575980597eceafc1', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\n'}, {'number': 5, 'created': '2021-11-10 19:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/117c76af8925655e1c831625651c45fadbcdd540', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\n'}, {'number': 6, 'created': '2022-06-12 02:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/99db97ff1973fb30215337a99d03f576950aa2b7', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: Id5a256757758c26ae73e33a7311f3a94acea52e9\n'}, {'number': 7, 'created': '2022-06-13 01:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/35b53a6fd54e95c71e431816cb1ab47731df9120', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}, {'number': 8, 'created': '2022-06-29 19:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/9c1d1298794e53a3b58c996470f115ee0e7f5664', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}, {'number': 9, 'created': '2022-07-05 18:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/da7483c5c98baa927ccf377e6147dbd157c68087', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}, {'number': 10, 'created': '2022-07-11 02:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/f1b53ce4d47551250bb1968df053021128f2aee3', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}, {'number': 11, 'created': '2023-01-16 09:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/0b58e0b9038d2400e3171cf993b301044f23a445', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}, {'number': 12, 'created': '2023-02-06 12:31:31.000000000', 'files': ['neutron_lib/db/model_query.py', 'neutron_lib/tests/unit/db/test_model_query.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/71640b424cbf46301306298eda7fd33c0ca2bc42', 'message': 'model_query: Improve perf with large # of RBAC\n\nThis commit refactors a good deal of the model query class\nin order to restructure the generated queries in such a way\nthat the MySQL optimizer is able to leverage indexes in\ncases where it formerly could not.\n\nMore specifically, the commit replaces an outer join (used\nto cover both tenant-owned RBACs and RBACs which are shared\nwith the tenant) with a late union of the both of these\nsame result sets. Unioning the result sets at the very last\nminute allows the MySQL optimizer to leverage indexes on\nthe intermediate results.\n\nThis commit necssitates changes to `neutron`[1] due to the\ninterface change within.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/817462\n\nChange-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f\nCloses-Bug: 1918145\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/817462\nSigned-off-by: Tyler Stachecki <tstachecki@bloomberg.net>\n'}]",53,817459,71640b424cbf46301306298eda7fd33c0ca2bc42,58,3,12,33910,,,0,"model_query: Improve perf with large # of RBAC

This commit refactors a good deal of the model query class
in order to restructure the generated queries in such a way
that the MySQL optimizer is able to leverage indexes in
cases where it formerly could not.

More specifically, the commit replaces an outer join (used
to cover both tenant-owned RBACs and RBACs which are shared
with the tenant) with a late union of the both of these
same result sets. Unioning the result sets at the very last
minute allows the MySQL optimizer to leverage indexes on
the intermediate results.

This commit necssitates changes to `neutron`[1] due to the
interface change within.

[1]https://review.opendev.org/c/openstack/neutron/+/817462

Change-Id: Ia117189294c06dfc859e6a23cd9d20aca4d7c95f
Closes-Bug: 1918145
Depends-On: https://review.opendev.org/c/openstack/neutron/+/817462
Signed-off-by: Tyler Stachecki <tstachecki@bloomberg.net>
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/59/817459/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/db/model_query.py', 'neutron_lib/tests/unit/db/test_model_query.py']",2,ae770f46925479b51fff9557265fc629a8d0edac,model-query-perf," self._mock_hook, result_filters=self._mock_hook, rbac_filter_hook=self._mock_hook) mock_model, 'hook1', self._mock_hook, {}, result_filters={}, rbac_filter_hook={}) mock_context, mock_model, field='fake_field', hoisted_filters=None)"," self._mock_hook, result_filters=self._mock_hook) mock_model, 'hook1', self._mock_hook, {}, result_filters={}) mock_context, mock_model, field='fake_field')",107,53
openstack%2Fneutron-vpnaas~master~I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140,openstack/neutron-vpnaas,master,I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140,Do not spawn strongswan ipsec for admin down connections,ABANDONED,2022-12-23 16:40:24.000000000,2023-04-17 08:02:50.000000000,,"[{'_account_id': 14525}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-23 16:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/6e2e924fed249a9ad77c1a566e5a737ae0607aeb', 'message': 'Do not spawn strongswan ipsec for admin down connections\n\nRelated-Prod: PRODX-3456\nChange-Id: I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140\n'}, {'number': 2, 'created': '2022-12-23 16:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/37ed6f844793c1988079ffa187bbc916c65fe2da', 'message': 'Do not spawn strongswan ipsec for admin down connections\n\nHonor admin_state_up flag when handling vpn connection.\n\nChange-Id: I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140\n'}, {'number': 3, 'created': '2023-02-08 14:25:37.000000000', 'files': ['neutron_vpnaas/services/vpn/device_drivers/strongswan_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/14b76f228e6977c87bc69d67780101ed1e7268d1', 'message': 'Do not spawn strongswan ipsec for admin down connections\n\nHonor admin_state_up flag when handling vpn connection.\n\nChange-Id: I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140\n'}]",1,868501,14b76f228e6977c87bc69d67780101ed1e7268d1,8,2,3,14525,,,0,"Do not spawn strongswan ipsec for admin down connections

Honor admin_state_up flag when handling vpn connection.

Change-Id: I9b053aa11ed03cdb8d441ca05c7e8faabe1fc140
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/01/868501/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/services/vpn/device_drivers/strongswan_ipsec.py'],1,6e2e924fed249a9ad77c1a566e5a737ae0607aeb,m4, if not ipsec_site_conn['admin_state_up']: continue,,2,0
openstack%2Fneutron~master~Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e,openstack/neutron,master,Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e,Remove FIPAddDeleteEvent event,ABANDONED,2022-11-08 12:46:32.000000000,2023-04-17 08:02:32.000000000,,"[{'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 12:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fef3ebc18f35fd065be9a135f24bffbe56e95d8c', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 2, 'created': '2022-11-09 07:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfec32c230919861c9117366a9ff1b589b1b36a2', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 3, 'created': '2022-11-09 10:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9338cee1dec711b5c75a7f5b491b423a35b56ebc', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 4, 'created': '2022-11-10 12:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a2112d679566bca3f6c8b564740c8b3b1fce0ae', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 5, 'created': '2022-12-16 09:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7695cbe35a2c55a402b6e0a7519667ad5c678c0', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 6, 'created': '2023-02-13 03:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40da1e89a4f1cf0d4914e539dc5395bbe0e27c7d', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 7, 'created': '2023-02-13 07:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c0e09e307ec4778cee5bdc6c66ea874be0c9992', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 8, 'created': '2023-02-20 02:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8c3f79bb078aa3b5577537e337771a02f85360a8', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 9, 'created': '2023-02-20 02:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5173919b672de792fec07382b3e67d5cbdf5f63', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}, {'number': 10, 'created': '2023-02-21 01:45:25.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/614dc74333eb88bf170597d1f966e67027ac43ae', 'message': 'Remove FIPAddDeleteEvent event\n\nIn OVN 20.03.0 issue with event handler workarounds has been solved [1]\nFIPAddDeleteEvent can be removed. Workaround was added in networking-ovn\nproject [2]\n\n1)\nhttps://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8\n2) https://review.opendev.org/c/openstack/networking-ovn/+/613584\n\nCloses-Bug: #1985096\nChange-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e\n'}]",6,864000,614dc74333eb88bf170597d1f966e67027ac43ae,51,3,10,32667,,,0,"Remove FIPAddDeleteEvent event

In OVN 20.03.0 issue with event handler workarounds has been solved [1]
FIPAddDeleteEvent can be removed. Workaround was added in networking-ovn
project [2]

1)
https://github.com/ovn-org/ovn/commit/069a32cbf443c937feff44078e8828d7a2702da8
2) https://review.opendev.org/c/openstack/networking-ovn/+/613584

Closes-Bug: #1985096
Change-Id: Ia59d5c8811ebd4f8f610aec4610d98ad00f0381e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/864000/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,fef3ebc18f35fd065be9a135f24bffbe56e95d8c,remove_event,," def delete_mac_binding_entries(self, external_ip): """"""Delete all MAC_Binding entries associated to this IP address"""""" cmd = [ ""OVN_Southbound"", { ""op"": ""delete"", ""table"": ""MAC_Binding"", ""where"": [ [""ip"", ""=="", external_ip] ] } ] return ovn_utils.OvsdbClientTransactCommand.run(cmd) ",1,131
openstack%2Fneutron~master~Ib8ffb47bebd08a58f6583f1ea873000b33db5e42,openstack/neutron,master,Ib8ffb47bebd08a58f6583f1ea873000b33db5e42,Routed provider nets: Fix subnet allocation logic,ABANDONED,2021-02-24 17:51:32.000000000,2023-04-17 08:02:24.000000000,,"[{'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-24 17:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efd946d537d82e487d6f92c95ec53122c3f8f3b2', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}, {'number': 2, 'created': '2021-04-19 14:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a5138e830a525a907372671a660627367141ebd', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}, {'number': 3, 'created': '2021-10-14 15:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7a3e0a370fb7d78887cbdb6a1d0d6c6c3413f95', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}, {'number': 4, 'created': '2021-10-22 09:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eab825732a55d999dd6d45ccf04d96950c044a77', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}, {'number': 5, 'created': '2021-10-22 11:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a574159c4fc0909697c7f8b3c8d240ae3f6bf467', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}, {'number': 6, 'created': '2022-11-24 13:09:44.000000000', 'files': ['neutron/services/segments/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3749c57d53d2266c84f71f1b999e35a4d0fb0c66', 'message': 'Routed provider nets: Fix subnet allocation logic\n\nTempest Test: https://review.opendev.org/c/openstack/tempest/+/665155\nCloses-Bug: #1916276\nChange-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42\n'}]",8,777443,3749c57d53d2266c84f71f1b999e35a4d0fb0c66,51,6,6,8313,,,0,"Routed provider nets: Fix subnet allocation logic

Tempest Test: https://review.opendev.org/c/openstack/tempest/+/665155
Closes-Bug: #1916276
Change-Id: Ib8ffb47bebd08a58f6583f1ea873000b33db5e42
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/777443/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/segments/plugin.py'],1,efd946d537d82e487d6f92c95ec53122c3f8f3b2,bug/1916276," original_port_ipv4_subnets_number, orig_segment_id = ( port_ipv4_subnets_number, segment_id = ( self._get_ipv4_subnets_number_and_segment_id(port, context)) if not orig_segment_id and not segment_id: if (not does_original_port_require_nova_inventory_update and not orig_segment_id): if not does_port_require_nova_inventory_update and not segment_id:"," original_port_ipv4_subnets_number, segment_id = ( if not segment_id: if not does_original_port_require_nova_inventory_update: if not does_port_require_nova_inventory_update:",7,4
openstack%2Fneutron~master~I68f79af5b02ff271d5e82052940368de23da54dc,openstack/neutron,master,I68f79af5b02ff271d5e82052940368de23da54dc,DNM - TESTING PATCH: functional and fullstack CI jobs,ABANDONED,2023-01-18 17:14:37.000000000,2023-04-17 08:02:08.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-18 17:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc4cb3c8a504ba34b86b863cc7ee2779d0897c65', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested: https://review.opendev.org/c/openstack/neutron/+/870967/\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 2, 'created': '2023-01-19 16:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/575684ac57683ca414857b36ad92586d0e9c86d8', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested: https://review.opendev.org/c/openstack/neutron/+/870967/\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 3, 'created': '2023-01-25 18:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ecf69217f12ac2f4f9787efce1cebec93ee354e', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested: https://review.opendev.org/c/openstack/neutron/+/870967/\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 4, 'created': '2023-02-08 14:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb33d27ed2c3c180f33583e4f04480f5d0fd8fc7', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/873118\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 5, 'created': '2023-02-09 15:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abb424b1fea848fe2fa1f0bdb0d2f3b9876acc6a', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/873118\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 6, 'created': '2023-02-09 17:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d64f1a937cacbb4a6ccc59f7ff1028d9e98b0c3e', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/873118\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 7, 'created': '2023-02-13 11:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a761d79c6ffe7130a0dc50379a63a118f09aa95', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/873118\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 8, 'created': '2023-02-13 16:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e236dce834612267cf396a0ea8783d1313713338', 'message': 'DNM - TESTING PATCH: neutron-functional-with-uwsgi\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/873118\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 9, 'created': '2023-03-09 10:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/edadd286342e823209b8bfe6a3e6c39400d2c820', 'message': 'DNM - TESTING PATCH: functional and fullstack CI jobs\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/876556\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}, {'number': 10, 'created': '2023-03-09 14:08:33.000000000', 'files': ['zuul.d/base.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1bd92f7169b60938bbd33b51fd5330d091a7ca3', 'message': 'DNM - TESTING PATCH: functional and fullstack CI jobs\n\nPatch tested:\n  https://review.opendev.org/c/openstack/neutron/+/876556\n\nChange-Id: I68f79af5b02ff271d5e82052940368de23da54dc\n'}]",1,870979,f1bd92f7169b60938bbd33b51fd5330d091a7ca3,25,1,10,16688,,,0,"DNM - TESTING PATCH: functional and fullstack CI jobs

Patch tested:
  https://review.opendev.org/c/openstack/neutron/+/876556

Change-Id: I68f79af5b02ff271d5e82052940368de23da54dc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/870979/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base.yaml', 'zuul.d/project.yaml']",2,fc4cb3c8a504ba34b86b863cc7ee2779d0897c65,improve-ci, - neutron-functional-with-uwsgi-1 - neutron-functional-with-uwsgi-2 - neutron-functional-with-uwsgi-3 - neutron-functional-with-uwsgi-4 - neutron-functional-with-uwsgi-5 - neutron-functional-with-uwsgi-6 - neutron-functional-with-uwsgi-7 - neutron-functional-with-uwsgi-8 - neutron-functional-with-uwsgi-9 - neutron-functional-with-uwsgi-10 - neutron-functional-with-uwsgi-11 - neutron-functional-with-uwsgi-12 - neutron-functional-with-uwsgi-13 - neutron-functional-with-uwsgi-14 - neutron-functional-with-uwsgi-15 - neutron-functional-with-uwsgi-16 - neutron-functional-with-uwsgi-17 - neutron-functional-with-uwsgi-18 - neutron-functional-with-uwsgi-19 - neutron-functional-with-uwsgi-20, - neutron-functional-with-uwsgi - neutron-fullstack-with-uwsgi - neutron-ovs-grenade-multinode - neutron-ovs-grenade-multinode-skip-level: voting: false - neutron-ovn-grenade-multinode-skip-level: voting: false - neutron-ovs-grenade-dvr-multinode - neutron-ovs-tempest-multinode-full - neutron-ovs-tempest-dvr-ha-multinode-full - neutron-ovn-tempest-ipv6-only-ovs-release - neutron-ovs-rally-task - neutron-ovn-rally-task - tempest-integrated-networking: irrelevant-files: &ovn-irrelevant-files - ^\.pylintrc$ - ^test-requirements.txt$ - ^releasenotes/.*$ - ^doc/.*$ - ^setup.cfg$ - ^.*\.conf\.sample$ - ^.*\.rst$ - ^neutron/locale/.*$ - ^neutron/tests/.*$ - ^tools/.*$ - ^tox.ini$ - ^neutron/agent/dhcp/.*$ - ^neutron/agent/l2/.*$ - ^neutron/agent/l3/.*$ - ^neutron/agent/metadata/.*$ - ^neutron/agent/windows/.*$ - ^neutron/agent/dhcp_agent.py - ^neutron/agent/l3_agent.py - ^neutron/agent/metadata_agent.py - ^neutron/agent/resource_cache.py - ^neutron/agent/rpc.py - ^neutron/agent/securitygroup_rpc.py - ^neutron/plugins/ml2/drivers/linuxbridge/.*$ - ^neutron/plugins/ml2/drivers/openvswitch/.*$ - ^neutron/plugins/ml2/drivers/macvtap/.*$ - ^neutron/plugins/ml2/drivers/mech_sriov/.*$ - ^neutron/services/qos/drivers/linuxbridge/.*$ - ^neutron/services/qos/drivers/openvswitch/.*$ - ^neutron/services/trunk/drivers/linuxbridge/.*$ - ^neutron/services/trunk/drivers/openvswitch/.*$ - ^neutron/scheduler/.*$ - ^roles/.*functional.*$ - ^playbooks/.*functional.*$ - ^zuul.d/(?!(project)).*\.yaml - neutron-ovn-tempest-ovs-release-ubuntu-old: irrelevant-files: *ovn-irrelevant-files gate: jobs: - neutron-functional-with-uwsgi - neutron-fullstack-with-uwsgi - neutron-ovs-tempest-multinode-full - neutron-ovs-grenade-multinode - neutron-ovs-grenade-dvr-multinode - neutron-ovn-tempest-ipv6-only-ovs-release - tempest-integrated-networking: irrelevant-files: *ovn-irrelevant-files - neutron-ovn-tempest-ovs-release-ubuntu-old: irrelevant-files: *ovn-irrelevant-files,100,64
openstack%2Fneutron~master~I695a81b22e7e4006094458d6238b814bd98b6d5d,openstack/neutron,master,I695a81b22e7e4006094458d6238b814bd98b6d5d,Use sqlalchemy baked query,ABANDONED,2017-02-08 14:47:31.000000000,2023-04-17 08:01:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10267}, {'_account_id': 10385}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2017-02-08 14:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78ded941d0c1807755f8919ee630e2a970262905', 'message': 'DEMO: illustrate how to integrate sqlalchemy ""baked"" query\n\nThe ""baked"" query system in SQLAlchemy caches the string\nSQL statement for a particular Query-construction path.   As\nsome profiling in Neutron have observed 30-40% time spent in\nconstructing Query objects due to the many small ""fetch-one-object""\nstyle of query, the ""baked"" system may potentially be able to\ngreatly reduce this.\n\nIn Neutron, most queries come from _model_query(), so in order to\nmake this possible, all the hooks that feed into _model_query() would\nneed to provide ""baked"" versions of their processors.  In order to\nallow the ""baked"" system to integrate gracefully without forcing\nthose external points to support it, this patch illustrates a system\nby which each plugin point is tested for ""baked"" compatibility\nand if not present we fall back to the regular _model_query.\n\nBaked queries: http://docs.sqlalchemy.org/en/latest/orm/extensions/baked.html\n\nChange-Id: I695a81b22e7e4006094458d6238b814bd98b6d5d\n'}, {'number': 2, 'created': '2018-08-08 11:24:30.000000000', 'files': ['neutron/services/timestamp/timestamp_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/services/tag/tag_plugin.py', 'neutron/db/_model_query.py', 'neutron/db/external_net_db.py', 'neutron/db/portbindings_db.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fafd9923dd6c82d4ff02508fa53ae68c54b385ca', 'message': 'Use sqlalchemy baked query\n\nThe ""baked"" query system in SQLAlchemy caches the string\nSQL statement for a particular Query-construction path.   As\nsome profiling in Neutron have observed 30-40% time spent in\nconstructing Query objects due to the many small ""fetch-one-object""\nstyle of query, the ""baked"" system may potentially be able to\ngreatly reduce this.\n\nIn Neutron, most queries come from _model_query(), so in order to\nmake this possible, all the hooks that feed into _model_query() would\nneed to provide ""baked"" versions of their processors.  In order to\nallow the ""baked"" system to integrate gracefully without forcing\nthose external points to support it, this patch illustrates a system\nby which each plugin point is tested for ""baked"" compatibility\nand if not present we fall back to the regular _model_query.\n\nBaked queries: http://docs.sqlalchemy.org/en/latest/orm/extensions/baked.html\n\nChange-Id: I695a81b22e7e4006094458d6238b814bd98b6d5d\n'}]",3,430973,fafd9923dd6c82d4ff02508fa53ae68c54b385ca,36,15,2,11816,,,0,"Use sqlalchemy baked query

The ""baked"" query system in SQLAlchemy caches the string
SQL statement for a particular Query-construction path.   As
some profiling in Neutron have observed 30-40% time spent in
constructing Query objects due to the many small ""fetch-one-object""
style of query, the ""baked"" system may potentially be able to
greatly reduce this.

In Neutron, most queries come from _model_query(), so in order to
make this possible, all the hooks that feed into _model_query() would
need to provide ""baked"" versions of their processors.  In order to
allow the ""baked"" system to integrate gracefully without forcing
those external points to support it, this patch illustrates a system
by which each plugin point is tested for ""baked"" compatibility
and if not present we fall back to the regular _model_query.

Baked queries: http://docs.sqlalchemy.org/en/latest/orm/extensions/baked.html

Change-Id: I695a81b22e7e4006094458d6238b814bd98b6d5d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/430973/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/common_db_mixin.py'],1,78ded941d0c1807755f8919ee630e2a970262905,demo_baked_query,"from sqlalchemy.ext import bakedquery_bakery = baked.bakery() def _baked_model_query(self, context, model): """"""Generate a model query using the ""baked"" system. The ""baked"" system caches the string SQL from a Query object. In order for this to work, we need to ensure that everything we do to the Query can also compose a cache key that will refer to the correct cached SQL statement. """""" assert isinstance(model, type) # model is a mapped class # the bakery is ""keyed"" off the code location of the # callable, as well string name of the model which can vary baked_query = bakery( lambda session: session.query(model), str(model) ) # below, we assume all decisions made on behalf of str(model) # will *always* be identical given that same model. If this is not # the case, this won't work. params = {} # define basic filter condition for model query query_filter = None if ndb_utils.model_query_scope_is_project(context, model): if hasattr(model, 'rbac_entries'): baked_query += lambda q: q.outerjoin(model.rbac_entries) rbac_model = model.rbac_entries.property.mapper.class_ query_filter = ( (model.tenant_id == bindparam('tenant_id')) | ((rbac_model.action == 'access_as_shared') & ((rbac_model.target_tenant == bindparam('tenant_id') | (rbac_model.target_tenant == '*')))) params['tenant_id'] = context.tenant_id elif hasattr(model, 'shared'): query_filter = ((model.tenant_id == bindparam('tenant_id')) | (model.shared == sql.true())) params['tenant_id'] = context.tenant_id else: query_filter = (model.tenant_id == bindparam('tenant_id')) params['tenant_id'] = context.tenant_id # Execute query hooks registered from mixins and plugins for _name, hooks in six.iteritems(self._model_query_hooks.get(model, {})): # if the hook provides query or filter, but not a ""baked"" version, # give up, return non-baked query if ( hooks.get('query') and not hooks.get('baked_query') ) or ( hooks.get('filter') and not hooks.get('baked_filter') ): return _model_query(context, model), None, False baked_query_hook = self._resolve_ref(hooks.get('baked_query')) if baked_query_hook: query = baked_query_hook(context, model, baked_query, params) baked_filter_hook = self._resolve_ref(hooks.get('baked_filter')) if baked_filter_hook: baked_query_filter = baked_filter_hook( context, model, query_filter, params) # NOTE(salvatore-orlando): 'if query_filter' will try to evaluate the # condition, raising an exception if query_filter is not None: baked_query += lambda q: q.filter(query_filter) return baked_query, params, True query, params, is_baked = self._baked_model_query(context, model) if is_baked: query.add_criteria( lambda q: q.filter(model.id == bindparam('model_id'), str(model) ) params['model_id'] = id return query.for_session(context.session).one() else: return query.filter(model.id == id).one()"," query = self._model_query(context, model) return query.filter(model.id == id).one()",84,2
openstack%2Fovsdbapp~master~Iec4bceba42fe3addbe439a522a005416912c84a4,openstack/ovsdbapp,master,Iec4bceba42fe3addbe439a522a005416912c84a4,ovs_idl: provide 'update_timeout',ABANDONED,2022-11-23 17:35:31.000000000,2023-04-17 08:01:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 27623}, {'_account_id': 33896}]","[{'number': 1, 'created': '2022-11-23 17:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/3abe5fa19b49947bf7002374a4cb644eb4cd4d8d', 'message': ""ovs_idl: provide 'update_timeout'\n\nProvide ability to set timeout for updating in-memory database after a successful transaction.\n\nChange-Id: Iec4bceba42fe3addbe439a522a005416912c84a4\n""}, {'number': 2, 'created': '2022-11-23 17:44:12.000000000', 'files': ['ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/__init__.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/318e7d6da5c8f9212b6bdfca1981a0c5cd27c397', 'message': ""ovs_idl: provide 'update_timeout'\n\nProvide ability to set timeout for updating in-memory database after a successful transaction.\n\nCloses-Bug: 1997585\nChange-Id: Iec4bceba42fe3addbe439a522a005416912c84a4\n""}]",10,865454,318e7d6da5c8f9212b6bdfca1981a0c5cd27c397,11,3,2,33871,,,0,"ovs_idl: provide 'update_timeout'

Provide ability to set timeout for updating in-memory database after a successful transaction.

Closes-Bug: 1997585
Change-Id: Iec4bceba42fe3addbe439a522a005416912c84a4
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/54/865454/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovsdbapp/backend/ovs_idl/command.py', 'ovsdbapp/backend/ovs_idl/__init__.py']",2,3abe5fa19b49947bf7002374a4cb644eb4cd4d8d,fix-post-commit," self.update_timeout = kwargs.pop(""update_timeout"", None)",,21,1
openstack%2Fneutron-dynamic-routing~master~Iec4be7776ee13c02eb746539bc2add4b9989596e,openstack/neutron-dynamic-routing,master,Iec4be7776ee13c02eb746539bc2add4b9989596e,Add neutron and neutron-lib projects to SQLAlchemy main branch job,MERGED,2023-04-03 12:36:16.000000000,2023-04-17 07:35:42.000000000,2023-04-17 07:33:37.000000000,"[{'_account_id': 16137}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-03 12:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/1e90f88a3ab65c37dc9bba2d0acf71b6a06e2bc9', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: Iec4be7776ee13c02eb746539bc2add4b9989596e\nRelated-Bug: #2004265\n'}, {'number': 2, 'created': '2023-04-03 12:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/e965df421b4169bbd643637b27c4f42fda916555', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: Iec4be7776ee13c02eb746539bc2add4b9989596e\nRelated-Bug: #2004265\n'}, {'number': 3, 'created': '2023-04-12 11:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/86936efa8896c45752987122e53653a046934be3', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: Iec4be7776ee13c02eb746539bc2add4b9989596e\nRelated-Bug: #2004265\n'}, {'number': 4, 'created': '2023-04-12 11:57:47.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/46d83cfe5c0172ad46bcba92010d149883de23fb', 'message': 'Add neutron and neutron-lib projects to SQLAlchemy main branch job\n\nChange-Id: Iec4be7776ee13c02eb746539bc2add4b9989596e\nRelated-Bug: #2004265\n'}]",8,879337,46d83cfe5c0172ad46bcba92010d149883de23fb,19,3,4,8313,,,0,"Add neutron and neutron-lib projects to SQLAlchemy main branch job

Change-Id: Iec4be7776ee13c02eb746539bc2add4b9989596e
Related-Bug: #2004265
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/37/879337/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1e90f88a3ab65c37dc9bba2d0acf71b6a06e2bc9,bug/2004265, - neutron-lib - neutron - neutron-dynamic-routing-openstack-tox-py310-with-sqlalchemy-main,,3,0
openstack%2Frequirements~master~I463ddc26cc1566234834877bb926e7d919fe26a5,openstack/requirements,master,I463ddc26cc1566234834877bb926e7d919fe26a5,Add more typing packages,ABANDONED,2023-04-14 09:30:45.000000000,2023-04-17 07:23:52.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 09:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/8bfb20474b3f1157e51ea2bf1ffa4c4983372a12', 'message': 'Add more typing packages to g-r.txt\n\nChange-Id: I463ddc26cc1566234834877bb926e7d919fe26a5\n'}, {'number': 2, 'created': '2023-04-14 12:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fdec99c89a72c97f4429d118045ea8b7ce9e33f0', 'message': 'Add more typing packages\n\nThese two packages help mypy type check Octavia code.\n\nChange-Id: I463ddc26cc1566234834877bb926e7d919fe26a5\n'}, {'number': 3, 'created': '2023-04-14 12:04:52.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8a1a92593a4b9371c3f6508b3cf286d54ce4b0ff', 'message': 'Add more typing packages\n\nThese two packages help mypy type check Octavia code.\n\nOctavia mypy integration:\nId8b1c2109abd199b13374094ea64a4cacb34085b\n\nChange-Id: I463ddc26cc1566234834877bb926e7d919fe26a5\n'}]",0,880472,8a1a92593a4b9371c3f6508b3cf286d54ce4b0ff,8,2,3,34429,,,0,"Add more typing packages

These two packages help mypy type check Octavia code.

Octavia mypy integration:
Id8b1c2109abd199b13374094ea64a4cacb34085b

Change-Id: I463ddc26cc1566234834877bb926e7d919fe26a5
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/880472/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,8bfb20474b3f1157e51ea2bf1ffa4c4983372a12,octavia-mypy, # Types packages types-requests types-simplejson,,4,0
openstack%2Fpuppet-ceph~master~I341889a47d157197be6210e863bf9f0d513b677d,openstack/puppet-ceph,master,I341889a47d157197be6210e863bf9f0d513b677d,Prepare a new puppet-ceph release,MERGED,2023-04-13 10:17:41.000000000,2023-04-17 07:03:40.000000000,2023-04-17 07:03:40.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 10:17:41.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/0d9a5556a9649fe6c8da2eae81bd00ac2fcc129c', 'message': ""Prepare a new puppet-ceph release\n\nWe introduced a few new features recently. Let's create a release.\n\nChange-Id: I341889a47d157197be6210e863bf9f0d513b677d\n""}]",0,880276,0d9a5556a9649fe6c8da2eae81bd00ac2fcc129c,7,3,1,9816,,,0,"Prepare a new puppet-ceph release

We introduced a few new features recently. Let's create a release.

Change-Id: I341889a47d157197be6210e863bf9f0d513b677d
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/76/880276/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,0d9a5556a9649fe6c8da2eae81bd00ac2fcc129c,," ""version"": ""5.0.0"","," ""version"": ""4.0.0"",",1,1
openstack%2Faodh~stable%2Fussuri~Ic021b9d7f9c2494dd90dd76725be746aef9f2865,openstack/aodh,stable/ussuri,Ic021b9d7f9c2494dd90dd76725be746aef9f2865,[DNM] testing CI,ABANDONED,2023-01-27 12:47:43.000000000,2023-04-17 07:02:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 12:47:43.000000000', 'files': ['.dnm'], 'web_link': 'https://opendev.org/openstack/aodh/commit/7f84a6d14dfdd13feff7981ecac946b27434c6d3', 'message': '[DNM] testing CI\n\nChange-Id: Ic021b9d7f9c2494dd90dd76725be746aef9f2865\n'}]",0,872014,7f84a6d14dfdd13feff7981ecac946b27434c6d3,3,1,1,32240,,,0,"[DNM] testing CI

Change-Id: Ic021b9d7f9c2494dd90dd76725be746aef9f2865
",git fetch https://review.opendev.org/openstack/aodh refs/changes/14/872014/1 && git format-patch -1 --stdout FETCH_HEAD,['.dnm'],1,7f84a6d14dfdd13feff7981ecac946b27434c6d3,,,,0,0
openstack%2Faodh~stable%2Ftrain~Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca,openstack/aodh,stable/train,Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca,[DNM] Testing CI,ABANDONED,2023-01-27 13:26:33.000000000,2023-04-17 07:02:33.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 13:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/b817a07edbfa74baf47946315901af9b44bf4901', 'message': '[DNM] Testing CI\n\nChange-Id: Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca\n'}, {'number': 2, 'created': '2023-01-30 06:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/2a8f72a107942b4341b6719b32a39cbf3593f67b', 'message': '[DNM] Testing CI\n\nChange-Id: Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca\n'}, {'number': 3, 'created': '2023-01-30 11:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/1fd8d67a3348336774e8a3f585f4eebf4824b40c', 'message': '[DNM] Testing CI\n\nChange-Id: Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca\n'}, {'number': 4, 'created': '2023-01-30 11:52:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/aodh/commit/b620bcfe7ff255b3b0c1d8618aed8efda11d670f', 'message': '[DNM] Testing CI\n\nChange-Id: Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca\n'}]",1,872016,b620bcfe7ff255b3b0c1d8618aed8efda11d670f,11,1,4,32240,,,0,"[DNM] Testing CI

Change-Id: Ic1393d3568e8b46e55f47acd6d8c8879bea4bfca
",git fetch https://review.opendev.org/openstack/aodh refs/changes/16/872016/4 && git format-patch -1 --stdout FETCH_HEAD,['.dnm'],1,b817a07edbfa74baf47946315901af9b44bf4901,,,,0,0
openstack%2Fpuppet-nova~master~Ib3b914b83bb61de1592553f7b43d0eace7c26903,openstack/puppet-nova,master,Ib3b914b83bb61de1592553f7b43d0eace7c26903,Support [os_brick] options,NEW,2022-11-26 17:04:08.000000000,2023-04-17 07:00:06.000000000,,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-26 17:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/4d331d6bbaaffb411e373d66386a5dd05ba23125', 'message': 'Support [os_brick] options\n\nNova now supports configuration os-brick specific lock_path. This\nadds the new class to manage the [os_brick] option.\n\nDepends-on: https://review.opendev.org/849328\nDepends-on: https://review.opendev.org/865771\nChange-Id: Ib3b914b83bb61de1592553f7b43d0eace7c26903\n'}, {'number': 2, 'created': '2022-11-28 00:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/9f5d96ac1c9a87cfa9601a236eeee5f1f5952581', 'message': 'Support [os_brick] options\n\nNova now supports configuration os-brick specific lock_path. This\nadds the new class to manage the [os_brick] option.\n\nDepends-on: https://review.opendev.org/849328\nDepends-on: https://review.opendev.org/865771\nChange-Id: Ib3b914b83bb61de1592553f7b43d0eace7c26903\n'}, {'number': 3, 'created': '2022-11-28 01:56:31.000000000', 'files': ['spec/classes/nova_os_brick_spec.rb', 'manifests/os_brick.pp', 'releasenotes/notes/os_brick-d7164dfcb0319654.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/75169174327113591808440214c8899435f6b2ea', 'message': 'Support [os_brick] options\n\nNova now supports configuration os-brick specific lock_path. This\nadds the new class to manage the [os_brick] option.\n\nDepends-on: https://review.opendev.org/849328\nDepends-on: https://review.opendev.org/865771\nChange-Id: Ib3b914b83bb61de1592553f7b43d0eace7c26903\n'}]",3,865773,75169174327113591808440214c8899435f6b2ea,12,3,3,9816,,,0,"Support [os_brick] options

Nova now supports configuration os-brick specific lock_path. This
adds the new class to manage the [os_brick] option.

Depends-on: https://review.opendev.org/849328
Depends-on: https://review.opendev.org/865771
Change-Id: Ib3b914b83bb61de1592553f7b43d0eace7c26903
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/73/865773/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_os_brick_spec.rb', 'manifests/os_brick.pp', 'releasenotes/notes/os_brick-d7164dfcb0319654.yaml']",3,4d331d6bbaaffb411e373d66386a5dd05ba23125,os-brick-lock_path,--- features: - | The new ``nova::os_brick`` class has been added. This class manages the ``[os_brick]`` options. ,,64,0
openstack%2Ftripleo-ansible~stable%2Fwallaby~I6dd684e65aeaa7d61127f51e97846bc2c65ff62a,openstack/tripleo-ansible,stable/wallaby,I6dd684e65aeaa7d61127f51e97846bc2c65ff62a,Exclude latest gnupg2 & Pin to last good version,MERGED,2023-04-11 14:12:25.000000000,2023-04-17 06:58:53.000000000,2023-04-13 20:05:26.000000000,"[{'_account_id': 8449}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2023-04-11 14:12:25.000000000', 'files': ['zuul.d/playbooks/pre.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9ea5b8874a0c6cbaff1f30539fbc671afd013252', 'message': 'Exclude latest gnupg2 & Pin to last good version\n\nThis adds exclude for gnupg2-2.3.3-3.el9 and downgrade to last good\nversion gnupg2.x86_64 2.3.3-2.el9 in centos9 branches for the related\nbug hitting check/gate and periodics. This is a workaround to unblock\nthe gates.\n\nRelated-Bug: 2015309\n\nChange-Id: I6dd684e65aeaa7d61127f51e97846bc2c65ff62a\nSigned-off-by: Chandan Kumar <chkumar@redhat.com>\n'}]",5,880055,9ea5b8874a0c6cbaff1f30539fbc671afd013252,18,4,1,12393,,,0,"Exclude latest gnupg2 & Pin to last good version

This adds exclude for gnupg2-2.3.3-3.el9 and downgrade to last good
version gnupg2.x86_64 2.3.3-2.el9 in centos9 branches for the related
bug hitting check/gate and periodics. This is a workaround to unblock
the gates.

Related-Bug: 2015309

Change-Id: I6dd684e65aeaa7d61127f51e97846bc2c65ff62a
Signed-off-by: Chandan Kumar <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/55/880055/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/pre.yml'],1,9ea5b8874a0c6cbaff1f30539fbc671afd013252,bug/2015309, # FIXME(Chandan): https://bugs.launchpad.net/tripleo/+bug/2015309 - name: Downgrade gnupg2 to 2.3.3-2.el9.x86_64 become: true ansible.builtin.shell: | sudo dnf -y downgrade gnupg2-2.3.3-2.el9.x86_64 failed_when: false ,,7,0
openstack%2Ftripleo-ci~master~I3919a8422cc07799a258c8da1162a1c945c0bc4c,openstack/tripleo-ci,master,I3919a8422cc07799a258c8da1162a1c945c0bc4c,Updating CentOS-8 stream default build image,MERGED,2023-04-16 15:58:57.000000000,2023-04-17 06:49:53.000000000,2023-04-17 06:49:53.000000000,"[{'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-16 15:58:57.000000000', 'files': ['roles/oooci-build-images/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/20fc32bf4236ec60ca3d70d48563ca0e0ed54e5a', 'message': 'Updating CentOS-8 stream default build image\n\nPrevious image is no longer available at\nhttps://cloud.centos.org/centos/8-stream/x86_64/images/.\n\nUpdating to reference the latest image.\n\nCloses-Bug: #2016422\nChange-Id: I3919a8422cc07799a258c8da1162a1c945c0bc4c\n'}]",2,880569,20fc32bf4236ec60ca3d70d48563ca0e0ed54e5a,7,3,1,9976,,,0,"Updating CentOS-8 stream default build image

Previous image is no longer available at
https://cloud.centos.org/centos/8-stream/x86_64/images/.

Updating to reference the latest image.

Closes-Bug: #2016422
Change-Id: I3919a8422cc07799a258c8da1162a1c945c0bc4c
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/69/880569/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/oooci-build-images/defaults/main.yaml'],1,20fc32bf4236ec60ca3d70d48563ca0e0ed54e5a,LP2016422,tripleo_image_source: https://cloud.centos.org/centos/8-stream/x86_64/images/CentOS-Stream-GenericCloud-8-20230404.0.x86_64.qcow2,tripleo_image_source: https://cloud.centos.org/centos/8-stream/x86_64/images/CentOS-Stream-GenericCloud-8-20220125.1.x86_64.qcow2,1,1
openstack%2Fkayobe~master~Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751,openstack/kayobe,master,Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751,Bump mrlesmithjr.lvm to skip swap resizes,MERGED,2022-10-13 11:38:40.000000000,2023-04-17 06:13:22.000000000,2022-12-07 12:53:44.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28048}, {'_account_id': 32657}]","[{'number': 1, 'created': '2022-10-13 11:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e1747a5b38390b576b5ffe29c8403a7da65eba9d', 'message': 'Bump mrlesmithjr.lvm to skip swap resizes\n\nSee https://github.com/mrlesmithjr/ansible-manage-lvm/releases/tag/v0.2.7\n\nChange-Id: Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751\n'}, {'number': 2, 'created': '2022-10-20 15:03:47.000000000', 'files': ['requirements.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/b3797d66502e60830ac76b87995195a46821cf37', 'message': 'Bump mrlesmithjr.lvm to skip swap resizes\n\nSee https://github.com/mrlesmithjr/ansible-manage-lvm/releases/tag/v0.2.7\n\nChange-Id: Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751\n'}]",1,861166,b3797d66502e60830ac76b87995195a46821cf37,11,6,2,22629,,,0,"Bump mrlesmithjr.lvm to skip swap resizes

See https://github.com/mrlesmithjr/ansible-manage-lvm/releases/tag/v0.2.7

Change-Id: Id48a63ba5a85d4745b7e0a905a9195ad0dc7a751
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/66/861166/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.yml'],1,e1747a5b38390b576b5ffe29c8403a7da65eba9d,, version: v0.2.7, version: v0.2.6,1,1
openstack%2Fneutron~master~Ia5627a1be3d5b9a1298ee4db7d9703509ef61290,openstack/neutron,master,Ia5627a1be3d5b9a1298ee4db7d9703509ef61290,[DNM] Check custom playbook,ABANDONED,2023-04-13 07:15:44.000000000,2023-04-17 06:03:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-13 07:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98315df5b30971a0b85087493215b294d65695ea', 'message': '[DNM] ovn skip level packages\n\nChange-Id: Ia5627a1be3d5b9a1298ee4db7d9703509ef61290\n'}, {'number': 2, 'created': '2023-04-14 15:29:42.000000000', 'files': ['playbooks/multinode-grenade-custom.yaml', 'zuul.d/project.yaml', 'zuul.d/job-templates.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a292ae57dc5703f300573ccf7c14dac6b0c11ee', 'message': '[DNM] Check custom playbook\n\nTo validate neutron-ovn-tempest-full-multinode-ovs-master\nfor #2015364\n\nChange-Id: Ia5627a1be3d5b9a1298ee4db7d9703509ef61290\n'}]",0,880269,5a292ae57dc5703f300573ccf7c14dac6b0c11ee,5,1,2,13861,,,0,"[DNM] Check custom playbook

To validate neutron-ovn-tempest-full-multinode-ovs-master
for #2015364

Change-Id: Ia5627a1be3d5b9a1298ee4db7d9703509ef61290
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/880269/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/grenade.yaml'],1,98315df5b30971a0b85087493215b294d65695ea,dnm,," old: Q_BUILD_OVS_FROM_GIT: true OVN_BUILD_MODULES: true OVN_BUILD_FROM_SOURCE: True OVN_BRANCH: ""v21.06.0"" OVS_BRANCH: ""a4b04276ab5934d087669ff2d191a23931335c87"" new: Q_BUILD_OVS_FROM_GIT: false OVN_BUILD_MODULES: false old: Q_BUILD_OVS_FROM_GIT: true OVN_BUILD_MODULES: true OVN_BUILD_FROM_SOURCE: True OVN_BRANCH: ""v21.06.0"" OVS_BRANCH: ""a4b04276ab5934d087669ff2d191a23931335c87"" new: Q_BUILD_OVS_FROM_GIT: false OVN_BUILD_MODULES: false",0,18
openstack%2Fpuppet-openstack-integration~master~Ic13252e9adb58de3485375bb17a65c355d322afe,openstack/puppet-openstack-integration,master,Ic13252e9adb58de3485375bb17a65c355d322afe,Tempest: Extend http_timeout,MERGED,2023-04-12 03:19:04.000000000,2023-04-17 05:59:31.000000000,2023-04-17 05:59:31.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 03:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b48526a0e54582bdaa4527e51bdb6bb6a9412426', 'message': 'Tempest: Extend http_timeout\n\nWe have occasionally seen tempest failures caused by http timeout in\nCI. This extends the timeout to lower down the failure late.\n\nDepends-on: https://review.opendev.org/880120\nChange-Id: Ic13252e9adb58de3485375bb17a65c355d322afe\n'}, {'number': 2, 'created': '2023-04-12 04:40:38.000000000', 'files': ['manifests/tempest.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/07675c83da26473ebc98c8990322a078c7a891cf', 'message': 'Tempest: Extend http_timeout\n\nWe have occasionally seen tempest failures caused by http timeout in\nCI. This extends the timeout to lower down the failure late.\n\nDepends-on: https://review.opendev.org/880120\nChange-Id: Ic13252e9adb58de3485375bb17a65c355d322afe\n'}]",1,880121,07675c83da26473ebc98c8990322a078c7a891cf,12,3,2,9816,,,0,"Tempest: Extend http_timeout

We have occasionally seen tempest failures caused by http timeout in
CI. This extends the timeout to lower down the failure late.

Depends-on: https://review.opendev.org/880120
Change-Id: Ic13252e9adb58de3485375bb17a65c355d322afe
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/21/880121/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/tempest.pp'],1,b48526a0e54582bdaa4527e51bdb6bb6a9412426,," http_timeout => 120,",,1,0
openstack%2Fpuppet-tempest~master~I3b82cc711b0baa18e4836d4f9dbd11c29bc5cff4,openstack/puppet-tempest,master,I3b82cc711b0baa18e4836d4f9dbd11c29bc5cff4,Support [service-clients] http_timeout,MERGED,2023-04-12 03:17:46.000000000,2023-04-17 03:41:55.000000000,2023-04-17 03:40:59.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 03:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/543b231e35aa8ff6421803e7fce31f9807740200', 'message': 'Support [service_clients] http_timeout\n\nWe have occasionally seen tempest failures caused by http timeout in\nCI. This introduces the parameter to tune the timeout option to lower\ndown the failure late (hopefully).\n\nChange-Id: I3b82cc711b0baa18e4836d4f9dbd11c29bc5cff4\n'}, {'number': 2, 'created': '2023-04-12 04:40:25.000000000', 'files': ['manifests/init.pp', 'releasenotes/notes/http_timeout-a0d7c667102fa106.yaml', 'spec/classes/tempest_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/df2d370a526565973455b0041c5ea132bf2bb0e1', 'message': 'Support [service-clients] http_timeout\n\nWe have occasionally seen tempest failures caused by http timeout in\nCI. This introduces the parameter to tune the timeout option to lower\ndown the failure late (hopefully).\n\nChange-Id: I3b82cc711b0baa18e4836d4f9dbd11c29bc5cff4\n'}]",8,880120,df2d370a526565973455b0041c5ea132bf2bb0e1,22,3,2,9816,,,0,"Support [service-clients] http_timeout

We have occasionally seen tempest failures caused by http timeout in
CI. This introduces the parameter to tune the timeout option to lower
down the failure late (hopefully).

Change-Id: I3b82cc711b0baa18e4836d4f9dbd11c29bc5cff4
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/20/880120/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'releasenotes/notes/http_timeout-a0d7c667102fa106.yaml', 'spec/classes/tempest_init_spec.rb']",3,543b231e35aa8ff6421803e7fce31f9807740200,, is_expected.to contain_tempest_config('service_clients/http_timeout').with(:value => '<SERVICE DEFAULT>'),,9,0
openstack%2Fcinder~stable%2Fxena~I0ece6e279048abcc04b3674108290a80eca6bd62,openstack/cinder,stable/xena,I0ece6e279048abcc04b3674108290a80eca6bd62,Remove multiatttach request parameter,MERGED,2023-04-13 23:12:36.000000000,2023-04-16 23:48:49.000000000,2023-04-14 14:54:42.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-04-13 23:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/02ea211113dd809e550667f1f37f7b0f13065197', 'message': 'Remove multiatttach request parameter\n\nThe initial cinder design[1][2][3] allowed users to create mutliattach\nvolumes by spcifying the ``multiattach`` parameter in the request\nbody of volume create operation (``--allow-multiattach`` option in\ncinderclient).\n\nThis functionality changed in Queens with the introduction of\nmicroversion 3.50[4] where we used volume types to store\nthe multiattach capabilities. Any volume created with a multiattach\nvolume type will be a multiattach volume[5].\n\nWhile implementing the new functionality, we had to keep backward\ncompatibility with the *old way* of creating multiattach volumes.\nWe deprecated the ``multiattach`` (``--allow-multiattach`` on cinderclient\nside) parameter in the queens release[6][7].\nWe also removed the support of the ``--allow-multiattach`` optional\nparameter from cinderclient in the train release[8] but the API\nside never removed the compatibility code to disallow functionality\nof creating multiattach volumes by using the ``multiattach``\nparameter (instead of a multiattach volume type).\n\nThis patch removes the support of providing the ``multiattach``\nparameter in the request body of a volume create operation and will\nfail with a BadRequest exception stating the reason of failure\nand how it can be fixed.\n\n[1] https://blueprints.launchpad.net/cinder/+spec/multi-attach-volume\n[2] https://review.opendev.org/c/openstack/cinder/+/85847/\n[3] https://review.opendev.org/c/openstack/python-cinderclient/+/85856\n[4] https://github.com/openstack/cinder/commit/f1bfd9790d2a7cac9a3e66417b11dc8e3edd8109\n[5] https://docs.openstack.org/cinder/latest/admin/volume-multiattach.html#how-to-create-a-multiattach-volume\n[6] https://github.com/openstack/cinder/commit/94dbf5cce2caff484460a1330feb6cbf7f3dd56a\n[7] https://github.com/openstack/python-cinderclient/commit/adb141a2626192e8f45a911291895716d7c1c8a4\n[8] https://github.com/openstack/python-cinderclient/commit/3c1b417959689c85a2f54505057ca995fedca075\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/875372\nCloses-Bug: 2008259\n\nChange-Id: I0ece6e279048abcc04b3674108290a80eca6bd62\n(cherry picked from commit 32f1145b7ddf9a9a359e2359e7db63dbdd00b899)\n(cherry picked from commit e2c3bcc6e380921bbe283b4a1b173216193c753d)\nConflicts: api-ref/source/v3/parameters.yaml\n(cherry picked from commit a8a4cdcb2e099456d435028c924e51dcbdee33e9)\nConflicts: cinder/volume/flows/api/create_volume.py\n(cherry picked from commit d4535c77493a7b362091b962f42f2613dea65dbe)\n'}, {'number': 2, 'created': '2023-04-13 23:50:25.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/tests/unit/api/v3/test_volumes.py', 'cinder/api/v3/volumes.py', 'cinder/volume/flows/api/create_volume.py', 'api-ref/source/v3/volumes-v3-volumes.inc', 'api-ref/source/v3/parameters.yaml', 'api-ref/source/v2/volumes-v2-volumes.inc', 'cinder/tests/unit/volume/test_volume.py', 'cinder/api/v2/volumes.py', 'api-ref/source/v2/parameters.yaml', 'cinder/api/schemas/volumes.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/volume/api.py', 'releasenotes/notes/remove-multiattach-request-param-4444e02533f919da.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/75d778244d298961da3ff73fc23058c0b6958f5c', 'message': 'Remove multiatttach request parameter\n\nThe initial cinder design[1][2][3] allowed users to create mutliattach\nvolumes by spcifying the ``multiattach`` parameter in the request\nbody of volume create operation (``--allow-multiattach`` option in\ncinderclient).\n\nThis functionality changed in Queens with the introduction of\nmicroversion 3.50[4] where we used volume types to store\nthe multiattach capabilities. Any volume created with a multiattach\nvolume type will be a multiattach volume[5].\n\nWhile implementing the new functionality, we had to keep backward\ncompatibility with the *old way* of creating multiattach volumes.\nWe deprecated the ``multiattach`` (``--allow-multiattach`` on cinderclient\nside) parameter in the queens release[6][7].\nWe also removed the support of the ``--allow-multiattach`` optional\nparameter from cinderclient in the train release[8] but the API\nside never removed the compatibility code to disallow functionality\nof creating multiattach volumes by using the ``multiattach``\nparameter (instead of a multiattach volume type).\n\nThis patch removes the support of providing the ``multiattach``\nparameter in the request body of a volume create operation and will\nfail with a BadRequest exception stating the reason of failure\nand how it can be fixed.\n\n[1] https://blueprints.launchpad.net/cinder/+spec/multi-attach-volume\n[2] https://review.opendev.org/c/openstack/cinder/+/85847/\n[3] https://review.opendev.org/c/openstack/python-cinderclient/+/85856\n[4] https://github.com/openstack/cinder/commit/f1bfd9790d2a7cac9a3e66417b11dc8e3edd8109\n[5] https://docs.openstack.org/cinder/latest/admin/volume-multiattach.html#how-to-create-a-multiattach-volume\n[6] https://github.com/openstack/cinder/commit/94dbf5cce2caff484460a1330feb6cbf7f3dd56a\n[7] https://github.com/openstack/python-cinderclient/commit/adb141a2626192e8f45a911291895716d7c1c8a4\n[8] https://github.com/openstack/python-cinderclient/commit/3c1b417959689c85a2f54505057ca995fedca075\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/875372\nCloses-Bug: 2008259\n\nChange-Id: I0ece6e279048abcc04b3674108290a80eca6bd62\n(cherry picked from commit 32f1145b7ddf9a9a359e2359e7db63dbdd00b899)\n(cherry picked from commit e2c3bcc6e380921bbe283b4a1b173216193c753d)\nConflicts: api-ref/source/v3/parameters.yaml\n(cherry picked from commit a8a4cdcb2e099456d435028c924e51dcbdee33e9)\nConflicts: cinder/volume/flows/api/create_volume.py\n(cherry picked from commit d4535c77493a7b362091b962f42f2613dea65dbe)\nConflicts: cinder/tests/unit/api/v2/test_volumes.py\n        cinder/volume/api.py\n'}]",9,880375,75d778244d298961da3ff73fc23058c0b6958f5c,22,3,2,5689,,,0,"Remove multiatttach request parameter

The initial cinder design[1][2][3] allowed users to create mutliattach
volumes by spcifying the ``multiattach`` parameter in the request
body of volume create operation (``--allow-multiattach`` option in
cinderclient).

This functionality changed in Queens with the introduction of
microversion 3.50[4] where we used volume types to store
the multiattach capabilities. Any volume created with a multiattach
volume type will be a multiattach volume[5].

While implementing the new functionality, we had to keep backward
compatibility with the *old way* of creating multiattach volumes.
We deprecated the ``multiattach`` (``--allow-multiattach`` on cinderclient
side) parameter in the queens release[6][7].
We also removed the support of the ``--allow-multiattach`` optional
parameter from cinderclient in the train release[8] but the API
side never removed the compatibility code to disallow functionality
of creating multiattach volumes by using the ``multiattach``
parameter (instead of a multiattach volume type).

This patch removes the support of providing the ``multiattach``
parameter in the request body of a volume create operation and will
fail with a BadRequest exception stating the reason of failure
and how it can be fixed.

[1] https://blueprints.launchpad.net/cinder/+spec/multi-attach-volume
[2] https://review.opendev.org/c/openstack/cinder/+/85847/
[3] https://review.opendev.org/c/openstack/python-cinderclient/+/85856
[4] https://github.com/openstack/cinder/commit/f1bfd9790d2a7cac9a3e66417b11dc8e3edd8109
[5] https://docs.openstack.org/cinder/latest/admin/volume-multiattach.html#how-to-create-a-multiattach-volume
[6] https://github.com/openstack/cinder/commit/94dbf5cce2caff484460a1330feb6cbf7f3dd56a
[7] https://github.com/openstack/python-cinderclient/commit/adb141a2626192e8f45a911291895716d7c1c8a4
[8] https://github.com/openstack/python-cinderclient/commit/3c1b417959689c85a2f54505057ca995fedca075

Depends-On: https://review.opendev.org/c/openstack/tempest/+/875372
Closes-Bug: 2008259

Change-Id: I0ece6e279048abcc04b3674108290a80eca6bd62
(cherry picked from commit 32f1145b7ddf9a9a359e2359e7db63dbdd00b899)
(cherry picked from commit e2c3bcc6e380921bbe283b4a1b173216193c753d)
Conflicts: api-ref/source/v3/parameters.yaml
(cherry picked from commit a8a4cdcb2e099456d435028c924e51dcbdee33e9)
Conflicts: cinder/volume/flows/api/create_volume.py
(cherry picked from commit d4535c77493a7b362091b962f42f2613dea65dbe)
Conflicts: cinder/tests/unit/api/v2/test_volumes.py
        cinder/volume/api.py
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/880375/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/tests/unit/api/v3/test_volumes.py', 'cinder/api/v3/volumes.py', 'cinder/volume/flows/api/create_volume.py', 'api-ref/source/v3/volumes-v3-volumes.inc', 'api-ref/source/v3/parameters.yaml', 'api-ref/source/v2/volumes-v2-volumes.inc', 'cinder/tests/unit/volume/test_volume.py', 'cinder/api/v2/volumes.py', 'api-ref/source/v2/parameters.yaml', 'cinder/api/schemas/volumes.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/volume/api.py', 'releasenotes/notes/remove-multiattach-request-param-4444e02533f919da.yaml']",14,02ea211113dd809e550667f1f37f7b0f13065197,874865-stable/zed-stable/yoga-stable/xena,"--- fixes: - | `Bug #2008259 <https://bugs.launchpad.net/cinder/+bug/2008259>`_: Fixed the volume create functionality where non-admin users were able to create multiattach volumes by providing the `multiattach` parameter in the request body. Now we can only create multiattach volumes using a multiattach volume type, which is also the recommended way. other: - | Removed the ability to create multiattach volumes by specifying `multiattach` parameter in the request body of a volume create operation. This functionality is unsafe, can lead to data loss, and has been deprecated since the Queens release. The recommended method for creating a multiattach volume is to use a volume type that supports multiattach. By default, volume types can only be created by the operator. Users who have a need for multiattach volumes should contact their operator if a suitable volume type is not available. ",,73,89
openstack%2Fkuryr-kubernetes~master~I1eb9c2f51fd792405cbb87742645518a00fdc890,openstack/kuryr-kubernetes,master,I1eb9c2f51fd792405cbb87742645518a00fdc890,Fix value ValueError when Pod has no IP address,MERGED,2023-04-14 11:57:38.000000000,2023-04-16 21:35:44.000000000,2023-04-16 21:34:38.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 11:57:38.000000000', 'files': ['kuryr_kubernetes/controller/drivers/network_policy.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2b69e039a8002c24e50e2ff1a947573951e9c1e2', 'message': ""Fix value ValueError when Pod has no IP address\n\nIn case the Pod has no IP address we shouldn't attempt to\nconvert it to a Python address. Instead, we should skip that\noperation and expect it to be retried later.\n\nChange-Id: I1eb9c2f51fd792405cbb87742645518a00fdc890\n""}]",3,880511,2b69e039a8002c24e50e2ff1a947573951e9c1e2,15,3,1,27032,,,0,"Fix value ValueError when Pod has no IP address

In case the Pod has no IP address we shouldn't attempt to
convert it to a Python address. Instead, we should skip that
operation and expect it to be retried later.

Change-Id: I1eb9c2f51fd792405cbb87742645518a00fdc890
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/11/880511/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/network_policy.py'],1,2b69e039a8002c24e50e2ff1a947573951e9c1e2,fix-value-error, if pod_ip is None: continue,,2,0
openstack%2Fkeystone~master~I8c45131b298ceae7b43b42e2c5df167607d18c48,openstack/keystone,master,I8c45131b298ceae7b43b42e2c5df167607d18c48,Improve application credential validation speed,NEW,2023-04-14 07:31:22.000000000,2023-04-16 07:13:43.000000000,,"[{'_account_id': 21107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 07:31:22.000000000', 'files': ['keystone/models/revoke_model.py', 'keystone/assignment/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/013f8a2bb20b409ea2fece74dde392765b6d49a0', 'message': 'Improve application credential validation speed\n\nValidating an application credential token is very slow, taking at least\n400ms+ in a simple devstack environment, 5-10x longer than validating a\nuser/password project token.\n\nThe primary bottleneck during a token validation request\n(/v3/auth/tokens) is that token.roles is evaluated at least 5 times.\nvalidate_token is called twice, first during RBAC to populate the\nsubject token context and again to actually validate the token. Each\ncall to validate_token then called token.roles twice because it first\nchecks if it is None, before calling it again to use the result. Lastly\ntoken.roles is evaluated a fifth time during\nrender_token_response_from_model.\n\nEach evaluation of token.roles calls through\n_get_application_credential_roles into list_role_assignments which then\nmakes multiple round-trip SQL queries to the database.\n\nUnlike the related get_roles_for_user_and_project function, none of\nthese calls are currently cached/memoized. We memoize\nlist_role_assignments to get the same-speedup.\n\nReduce the number of token.roles calls to only 3 by storing and re-using\nthe token.roles result in validate_token, then memoize\nlist_role_assignments so the 2nd and 3rd call fetch from the cache\ninstead of repeating many SQL queries.\n\nThis provides a substantial performance improvement bringing validation\ntime in-line with user/password tokens.\n\nne\n\nChange-Id: I8c45131b298ceae7b43b42e2c5df167607d18c48\n'}]",1,880456,013f8a2bb20b409ea2fece74dde392765b6d49a0,5,2,1,21107,,,0,"Improve application credential validation speed

Validating an application credential token is very slow, taking at least
400ms+ in a simple devstack environment, 5-10x longer than validating a
user/password project token.

The primary bottleneck during a token validation request
(/v3/auth/tokens) is that token.roles is evaluated at least 5 times.
validate_token is called twice, first during RBAC to populate the
subject token context and again to actually validate the token. Each
call to validate_token then called token.roles twice because it first
checks if it is None, before calling it again to use the result. Lastly
token.roles is evaluated a fifth time during
render_token_response_from_model.

Each evaluation of token.roles calls through
_get_application_credential_roles into list_role_assignments which then
makes multiple round-trip SQL queries to the database.

Unlike the related get_roles_for_user_and_project function, none of
these calls are currently cached/memoized. We memoize
list_role_assignments to get the same-speedup.

Reduce the number of token.roles calls to only 3 by storing and re-using
the token.roles result in validate_token, then memoize
list_role_assignments so the 2nd and 3rd call fetch from the cache
instead of repeating many SQL queries.

This provides a substantial performance improvement bringing validation
time in-line with user/password tokens.

ne

Change-Id: I8c45131b298ceae7b43b42e2c5df167607d18c48
",git fetch https://review.opendev.org/openstack/keystone refs/changes/56/880456/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/models/revoke_model.py', 'keystone/assignment/core.py']",2,013f8a2bb20b409ea2fece74dde392765b6d49a0,appcred-validation-speed, @MEMOIZE_COMPUTED_ASSIGNMENTS,,4,2
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c,openstack/tripleo-heat-templates,stable/wallaby,I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c,Set the correct path for pacemaker logs in rsyslog,MERGED,2023-04-05 05:58:49.000000000,2023-04-15 22:43:25.000000000,2023-04-15 22:43:25.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-05 05:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1330d4e70a0838083bbce62ca3ea53c639af718e', 'message': 'Set the correct path for pacemaker logs in rsyslog\n\nLog path for pacemaker is set to ""PacemakerLoggingSource""\nwhich exists on the host, not inside the container.\n\nThis change introduces a new variable `PacemakerRsyslogLoggingSource`\nwhich hold the correct path for pacemaker logs mounted inside\nrsyslog container under ""/var/log/host/pacemaker/"".\n\nLikewise, similar variables can be configured for log files of\nother host services which are mounted under ""/var/log/host/"".\n\nResolves: rhbz#2180933\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/879393\nChange-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c\n'}, {'number': 2, 'created': '2023-04-05 05:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/52d547b62b98a4779a558f186e7eaefacd5f69bc', 'message': 'Set the correct path for pacemaker logs in rsyslog\n\nLog path for pacemaker is set to ""PacemakerLoggingSource""\nwhich exists on the host, not inside the container.\n\nThis change introduces a new variable `PacemakerRsyslogLoggingSource`\nwhich hold the correct path for pacemaker logs mounted inside\nrsyslog container under ""/var/log/host/pacemaker/"".\n\nLikewise, similar variables can be configured for log files of\nother host services which are mounted under ""/var/log/host/"".\n\nResolves: rhbz#2180933\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/879525\nChange-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c\n'}, {'number': 3, 'created': '2023-04-12 07:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f760e9c462fcef419423521dc200a35a09967ed', 'message': 'Set the correct path for pacemaker logs in rsyslog\n\nPacemaker logs are mounted inside rsyslog container under\n""/var/log/host/pacemaker/"" and not ""/var/log/pacemaker/"".\n\nResolves: rhbz#2180933\nChange-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c\n'}, {'number': 4, 'created': '2023-04-12 07:01:29.000000000', 'files': ['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/404713a9202744d485e843844c3b80f70ff5e68f', 'message': 'Set the correct path for pacemaker logs in rsyslog\n\nPacemaker logs are mounted inside rsyslog container under\n""/var/log/host/pacemaker/"" and not ""/var/log/pacemaker/"".\n\nResolves: rhbz#2180933\nChange-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c\n'}]",7,879485,404713a9202744d485e843844c3b80f70ff5e68f,26,2,4,32240,,,0,"Set the correct path for pacemaker logs in rsyslog

Pacemaker logs are mounted inside rsyslog container under
""/var/log/host/pacemaker/"" and not ""/var/log/pacemaker/"".

Resolves: rhbz#2180933
Change-Id: I1953db2faff367cd5f06ef3ce530ccd00cc7dc6c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/879485/3 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/pacemaker/pacemaker-baremetal-puppet.yaml', 'releasenotes/notes/pacemaker-rsyslog-logging-afc3b9ac8a905c46.yaml']",2,1330d4e70a0838083bbce62ca3ea53c639af718e,rsyslog_host_logs-stable/wallaby,--- features: - | Add new paramater 'PacemakerRsyslogLoggingSource' which holds the absolute path of pacemaker logs mounted inside rsyslog container. ,,13,0
openstack%2Fopenstack-ansible-os_sahara~master~I5561693e490700bc572e196e36e8ef0fa4df1ec5,openstack/openstack-ansible-os_sahara,master,I5561693e490700bc572e196e36e8ef0fa4df1ec5,Ensure service is restarted on unit file changes,MERGED,2023-04-11 10:46:06.000000000,2023-04-15 16:08:59.000000000,2023-04-15 16:07:59.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-11 10:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/afa4e51df5ae0e29fef3a59326bc6c051a90442c', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nChange-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5\n""}, {'number': 2, 'created': '2023-04-12 07:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/c16d29724dac542daabff6296c105e044658a403', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nChange-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5\n""}, {'number': 3, 'created': '2023-04-12 17:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/0b2108082974d75da4fcda51ded430b82315b187', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nChange-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5\n""}, {'number': 4, 'created': '2023-04-14 09:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/8176cda73439f1ed08f7b1b50f7f2e39809c3866', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nChange-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5\n""}, {'number': 5, 'created': '2023-04-14 09:19:23.000000000', 'files': ['handlers/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/5025cd3ea16ef8677255b656fefdaa042150d4b5', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/880470\nChange-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5\n""}]",1,880038,5025cd3ea16ef8677255b656fefdaa042150d4b5,18,3,5,28619,,,0,"Ensure service is restarted on unit file changes

At the moment we don't restart services if systemd unit file is changed.

We knowingly prevent systemd_service role handlers to execute
by providing `state: started` as otherwise service will be restarted twice.
With that now  we ensure that role handlers will also listen for systemd
unit changes.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963
Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/880470
Change-Id: I5561693e490700bc572e196e36e8ef0fa4df1ec5
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/38/880038/1 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'vars/main.yml']",2,afa4e51df5ae0e29fef3a59326bc6c051a90442c,osa/systemd_restart_on_unit_change," 'enabled': value['enabled'] | default(True), 'state': value['state'] | default('started'),"," 'enabled': 'yes', 'state': 'started',",3,2
openstack%2Fopenstack-ansible-os_murano~master~I3ecb1d9892145906d2f384d53ec47e722ab2649b,openstack/openstack-ansible-os_murano,master,I3ecb1d9892145906d2f384d53ec47e722ab2649b,Ensure service is restarted on unit file changes,MERGED,2023-04-10 14:38:00.000000000,2023-04-15 10:20:12.000000000,2023-04-15 10:19:13.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-10 14:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_murano/commit/d7a20c07b791eee89c483b81045d51a3850d9e77', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nChange-Id: I3ecb1d9892145906d2f384d53ec47e722ab2649b\n""}, {'number': 2, 'created': '2023-04-12 07:56:42.000000000', 'files': ['handlers/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_murano/commit/80bda1bd2f0a50296deb85f8d6e0325a2481caad', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nChange-Id: I3ecb1d9892145906d2f384d53ec47e722ab2649b\n""}]",0,879974,80bda1bd2f0a50296deb85f8d6e0325a2481caad,10,3,2,28619,,,0,"Ensure service is restarted on unit file changes

At the moment we don't restart services if systemd unit file is changed.

We knowingly prevent systemd_service role handlers to execute
by providing `state: started` as otherwise service will be restarted twice.
With that now  we ensure that role handlers will also listen for systemd
unit changes.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963
Change-Id: I3ecb1d9892145906d2f384d53ec47e722ab2649b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_murano refs/changes/74/879974/2 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'vars/main.yml']",2,d7a20c07b791eee89c483b81045d51a3850d9e77,osa/systemd_restart_on_unit_change," {% set _ = value.update( { 'service_key': key, 'enabled': value['enabled'] | default(True), 'state': value['state'] | default('started'), } ) %}", {% set _ = value.update({'service_key': key}) %},9,1
openstack%2Fopenstack-ansible~master~I403e932b7b94bae4c4618df7fd36ad645356589d,openstack/openstack-ansible,master,I403e932b7b94bae4c4618df7fd36ad645356589d,Revert using healtcheck for sahara,MERGED,2023-04-14 09:18:55.000000000,2023-04-15 09:49:48.000000000,2023-04-15 09:48:26.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-14 09:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fd363438e6a4782d448a64d669b373ccd9e211d1', 'message': ""Revert using healtcheck for sahara\n\nSahara has healtcheck URI broken despite it's contained in api-paste.\nURI claims on failed auth, which is not supposed to happen with properly\nworking /healthcheck.\n\nChange-Id: I403e932b7b94bae4c4618df7fd36ad645356589d\n""}, {'number': 2, 'created': '2023-04-14 18:33:16.000000000', 'files': ['inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/33e4be050b3e1d7a9b697ca7c3722c6356d3bd49', 'message': ""Revert using healtcheck for sahara\n\nSahara has healtcheck URI broken despite it's contained in api-paste.\nURI claims on failed auth, which is not supposed to happen with properly\nworking /healthcheck.\n\nChange-Id: I403e932b7b94bae4c4618df7fd36ad645356589d\n""}]",1,880470,33e4be050b3e1d7a9b697ca7c3722c6356d3bd49,12,4,2,28619,,,0,"Revert using healtcheck for sahara

Sahara has healtcheck URI broken despite it's contained in api-paste.
URI claims on failed auth, which is not supposed to happen with properly
working /healthcheck.

Change-Id: I403e932b7b94bae4c4618df7fd36ad645356589d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/70/880470/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/haproxy/haproxy.yml'],1,fd363438e6a4782d448a64d669b373ccd9e211d1,," - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"""," - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck""",1,1
openstack%2Frequirements~master~Ie2cf3e05b65dcc27b26c99bd994c4c7b4516920c,openstack/requirements,master,Ie2cf3e05b65dcc27b26c99bd994c4c7b4516920c,Remove the Patrole deliverables from req,MERGED,2023-04-12 18:31:28.000000000,2023-04-15 07:39:59.000000000,2023-04-15 07:39:00.000000000,"[{'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-12 18:31:28.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fbc45b75fd3bfd2db4915db4530f170c4fa8d4fe', 'message': ""Remove the Patrole deliverables from req\n\nPatrole is going to be retired (depends-on), so let's\ndelete the patrole deveilerbales from project.txt\n\nDepends-On: https://review.opendev.org/c/openstack/governance/+/880014\nChange-Id: Ie2cf3e05b65dcc27b26c99bd994c4c7b4516920c\n""}]",2,880218,fbc45b75fd3bfd2db4915db4530f170c4fa8d4fe,11,4,1,8556,,,0,"Remove the Patrole deliverables from req

Patrole is going to be retired (depends-on), so let's
delete the patrole deveilerbales from project.txt

Depends-On: https://review.opendev.org/c/openstack/governance/+/880014
Change-Id: Ie2cf3e05b65dcc27b26c99bd994c4c7b4516920c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/18/880218/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,fbc45b75fd3bfd2db4915db4530f170c4fa8d4fe,retire-patrole,,openstack/patrole,0,1
openstack%2Fproject-config~master~I98785ee1873d30bdbf362e27c71d965935c5b947,openstack/project-config,master,I98785ee1873d30bdbf362e27c71d965935c5b947,Normalize projects.yaml,MERGED,2023-04-15 02:19:35.000000000,2023-04-15 07:14:34.000000000,2023-04-15 06:42:30.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-15 02:19:35.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8a463864a63d4d2a24ab9363f18ebc2b22b54307', 'message': 'Normalize projects.yaml\n\nChange-Id: I98785ee1873d30bdbf362e27c71d965935c5b947\n'}]",0,880561,8a463864a63d4d2a24ab9363f18ebc2b22b54307,7,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I98785ee1873d30bdbf362e27c71d965935c5b947
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/880561/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,8a463864a63d4d2a24ab9363f18ebc2b22b54307,project-yaml-normalization,, upstream: https://github.com/openstack-charmers/charm-openstack-hypervisor.git,0,1
openstack%2Fdevstack~master~I11ff825f743d13270037eebeb92b7169a037ed64,openstack/devstack,master,I11ff825f743d13270037eebeb92b7169a037ed64,Remove patrole projects ref,ABANDONED,2023-04-12 19:06:29.000000000,2023-04-15 06:40:53.000000000,,"[{'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-12 19:06:29.000000000', 'files': ['doc/source/plugin-registry.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2fefdc025029e968aca92b45f2bf4206f6e55e7a', 'message': 'Remove patrole projects ref\n\npatrole project is not maintained and in QA\nPTG, we decided to retire it.\n\n- https://etherpad.opendev.org/p/qa-bobcat-ptg\n\nDepends-On: https://review.opendev.org/c/openstack/governance/+/880014\nChange-Id: I11ff825f743d13270037eebeb92b7169a037ed64\n'}]",1,880227,2fefdc025029e968aca92b45f2bf4206f6e55e7a,5,2,1,8556,,,0,"Remove patrole projects ref

patrole project is not maintained and in QA
PTG, we decided to retire it.

- https://etherpad.opendev.org/p/qa-bobcat-ptg

Depends-On: https://review.opendev.org/c/openstack/governance/+/880014
Change-Id: I11ff825f743d13270037eebeb92b7169a037ed64
",git fetch https://review.opendev.org/openstack/devstack refs/changes/27/880227/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugin-registry.rst'],1,2fefdc025029e968aca92b45f2bf4206f6e55e7a,retire-patrole,,openstack/patrole `https://opendev.org/openstack/patrole <https://opendev.org/openstack/patrole>`__,0,1
openstack%2Ftripleo-ci~master~I0d26f2e2b337d230d26d619f03d762a71efde2c2,openstack/tripleo-ci,master,I0d26f2e2b337d230d26d619f03d762a71efde2c2,Updating CentOS image,MERGED,2023-04-14 09:29:03.000000000,2023-04-15 02:12:40.000000000,2023-04-15 02:12:40.000000000,"[{'_account_id': 8449}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 29775}]","[{'number': 1, 'created': '2023-04-14 09:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/59ac667ea5439f71dfa62030df0ef72a19325f15', 'message': 'Updating CentOS image\n\nPrevious image was old and it is no longer available, updating to latest\nimage.\n\nChange-Id: I0d26f2e2b337d230d26d619f03d762a71efde2c2\n'}, {'number': 2, 'created': '2023-04-14 09:52:15.000000000', 'files': ['roles/oooci-build-images/vars/centos-9.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d5a73f5f560d649361064225233ff73d4264b7c4', 'message': 'Updating CentOS image\n\nPrevious image was old and it is no longer available, updating to latest\nimage.\n\nCloses-Bug: #2016284\n\nChange-Id: I0d26f2e2b337d230d26d619f03d762a71efde2c2\n'}]",2,880471,d5a73f5f560d649361064225233ff73d4264b7c4,10,5,2,8367,,,0,"Updating CentOS image

Previous image was old and it is no longer available, updating to latest
image.

Closes-Bug: #2016284

Change-Id: I0d26f2e2b337d230d26d619f03d762a71efde2c2
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/71/880471/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/oooci-build-images/vars/centos-9.yaml'],1,59ac667ea5439f71dfa62030df0ef72a19325f15,update-c9-image,tripleo_image_source: http://cloud.centos.org/centos/9-stream/x86_64/images/CentOS-Stream-GenericCloud-9-20230410.0.x86_64.qcow2,tripleo_image_source: http://cloud.centos.org/centos/9-stream/x86_64/images/CentOS-Stream-GenericCloud-9-20220425.0.x86_64.qcow2,1,1
openstack%2Fmanila~master~I8ff25174626385b8d1d0b11d6846e345e2d9b125,openstack/manila,master,I8ff25174626385b8d1d0b11d6846e345e2d9b125,"db: Migrate ""share group"", ""share group type"" APIs to enginefacade",MERGED,2022-09-08 10:50:44.000000000,2023-04-15 01:39:09.000000000,2023-04-15 01:38:02.000000000,"[{'_account_id': 15334}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-09-08 10:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/68c1c853cf2f17d2fd8820d042f90c633fe9380a', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}, {'number': 2, 'created': '2022-12-21 12:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2f930618111e32dbc06ead49245a153621ef5254', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}, {'number': 3, 'created': '2022-12-21 15:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c36ecdbfb29d53574931bcf4f2087e73325a08e9', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}, {'number': 4, 'created': '2023-01-30 11:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2477c75300721cdc1e962dad75962f590caa7d10', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}, {'number': 5, 'created': '2023-03-31 15:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ae21a1fbd78cdf4f58e1ac35ca0e6f0c588290d2', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}, {'number': 6, 'created': '2023-04-14 16:02:29.000000000', 'files': ['manila/db/api.py', 'manila/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/15b4b39eb5ad6dbc77c430fb8c6500ef22f89bd1', 'message': 'db: Migrate ""share group"", ""share group type"" APIs to enginefacade\n\nThis one is beefier than usual, since we\'re migrating not only share\ngroup and share group type-related APIs, but also things like share\ngroup type members, share group type snapshots, etc.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125\n'}]",6,856467,15b4b39eb5ad6dbc77c430fb8c6500ef22f89bd1,43,4,6,15334,,,0,"db: Migrate ""share group"", ""share group type"" APIs to enginefacade

This one is beefier than usual, since we're migrating not only share
group and share group type-related APIs, but also things like share
group type members, share group type snapshots, etc.

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: I8ff25174626385b8d1d0b11d6846e345e2d9b125
",git fetch https://review.opendev.org/openstack/manila refs/changes/67/856467/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/db/sqlalchemy/api.py'],1,68c1c853cf2f17d2fd8820d042f90c633fe9380a,sqlalchemy-20,"def _share_group_get(context, share_group_id):@context_manager.reader def share_group_get(context, share_group_id): return _share_group_get(context, share_group_id) sort_key=None, sort_dir=None): context, models.ShareGroup, read_deleted='no')@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.writer share_group.update(values) context.session.add(share_group) return _share_group_get(context, values['id'])@context_manager.writer def share_group_update(context, share_group_id, values): share_group_ref = _share_group_get( context, share_group_id) share_group_ref.update(values) share_group_ref.save(session=context.session) return share_group_ref@context_manager.writer def share_group_destroy(context, share_group_id): share_group_ref = _share_group_get(context, share_group_id) share_group_ref.soft_delete(context.session) context.session.query(models.ShareGroupShareTypeMapping).filter_by( share_group_id=share_group_ref['id']).soft_delete()@context_manager.reader def count_shares_in_share_group(context, share_group_id): return (model_query(context, models.Share,@context_manager.reader def get_all_shares_by_share_group(context, share_group_id): context, models.Share,@context_manager.reader share_type_id=None): ).filter_by(project_id=project_id)@context_manager.reader share_type_id=None): ).filter_by(project_id=project_id)@context_manager.reader share_type_id=None): ).join( models.ShareInstance.share_id == models.Share.id ).filter( models.Share.project_id == project_id ).filter( models.ShareInstance.replica_state.isnot(None) )@context_manager.reader def count_share_group_snapshots_in_share_group(context, share_group_id): context, models.ShareGroupSnapshot,@context_manager.reader def count_share_groups_in_share_network(context, share_network_id): context, models.ShareGroup,@context_manager.reader def count_share_group_snapshot_members_in_share(context, share_id): context, models.ShareSnapshotInstance,#################### def _share_group_snapshot_get(context, share_group_snapshot_id): context, models.ShareGroupSnapshot, project_only=True, read_deleted='no', context, project_id=None, detailed=True, filters=None, sort_key=None, sort_dir=None, ): query = model_query(context, models.ShareGroupSnapshot, read_deleted='no')@context_manager.reader def share_group_snapshot_get(context, share_group_snapshot_id): return _share_group_snapshot_get(context, share_group_snapshot_id)@context_manager.reader@context_manager.reader@context_manager.writer share_group_snapshot.update(values) context.session.add(share_group_snapshot) return _share_group_snapshot_get(context, values['id'])@context_manager.writer def share_group_snapshot_update(context, share_group_snapshot_id, values): share_group_ref = _share_group_snapshot_get( context, share_group_snapshot_id, ) share_group_ref.update(values) share_group_ref.save(session=context.session) return share_group_ref@context_manager.writer def share_group_snapshot_destroy(context, share_group_snapshot_id): share_group_snap_ref = _share_group_snapshot_get( context, share_group_snapshot_id, ) share_group_snap_ref.soft_delete(context.session) context.session.query( models.ShareSnapshotInstance ).filter_by( share_group_snapshot_id=share_group_snapshot_id ).soft_delete() ####################@context_manager.reader def share_group_snapshot_members_get_all(context, share_group_snapshot_id): context, models.ShareSnapshotInstance,@context_manager.reader def share_group_snapshot_member_get(context, member_id): context, models.ShareSnapshotInstance, project_only=True, read_deleted='no',@context_manager.writer def share_group_snapshot_member_create(context, values): member = models.ShareSnapshotInstance() member.update(values) context.session.add(member) return share_group_snapshot_member_get(context, values['id'])@context_manager.writer def share_group_snapshot_member_update(context, member_id, values): member = share_group_snapshot_member_get(context, member_id) member.update(values) context.session.add(member) return share_group_snapshot_member_get(context, member_id)@context_manager.writer try: values['group_specs'] = _metadata_refs( values.get('group_specs'), models.ShareGroupTypeSpecs) mappings = [] for item in values.get('share_types', []): share_type = share_type_get_by_name_or_id(context, item) if not share_type: raise exception.ShareTypeDoesNotExist(share_type=item) mapping = models.ShareGroupTypeShareTypeMapping() mapping['id'] = uuidutils.generate_uuid() mapping['share_type_id'] = share_type['id'] mapping['share_group_type_id'] = values['id'] mappings.append(mapping) values['share_types'] = mappings share_group_type_ref = models.ShareGroupTypes() share_group_type_ref.update(values) share_group_type_ref.save(session=context.session) except db_exception.DBDuplicateEntry: raise exception.ShareGroupTypeExists(type_id=values['name']) except exception.ShareTypeDoesNotExist: raise except Exception as e: raise db_exception.DBError(e) for project in set(projects): access_ref = models.ShareGroupTypeProjects() access_ref.update({""share_group_type_id"": share_group_type_ref.id, ""project_id"": project}) access_ref.save(session=context.session) return share_group_type_ref def _share_group_type_get_query( context, read_deleted=None, expected_fields=None, ): context, models.ShareGroupTypes,@context_manager.readerdef _share_group_type_get_id_from_share_group_type_query(context, type_id): context, models.ShareGroupTypes, read_deleted=""no"",def _share_group_type_get_id_from_share_group_type(context, type_id): context, type_id, ).first()def _share_group_type_get( context, type_id, inactive=False, expected_fields=None, ): context, read_deleted, expected_fields,@context_manager.reader context, type_id, inactive=inactive, expected_fields=expected_fields, )def _share_group_type_get_by_name(context, name): context, models.ShareGroupTypes,@context_manager.reader@context_manager.writer def share_group_type_destroy(context, type_id): _share_group_type_get(context, type_id) results = model_query( context, models.ShareGroup, read_deleted=""no"", ).filter_by( share_group_type_id=type_id, ).count() if results: LOG.error('Share group type %s deletion failed, it in use.', type_id) raise exception.ShareGroupTypeInUse(type_id=type_id) model_query( context, models.ShareGroupTypeSpecs, ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypeShareTypeMapping, ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypeProjects, ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypes, ).filter_by( id=type_id, ).soft_delete() ############################### def _share_group_type_access_query(context,): return model_query( context, models.ShareGroupTypeProjects, read_deleted=""no"", )@context_manager.reader@context_manager.reader try: access_ref.save(session=context.session) except db_exception.DBDuplicateEntry: raise exception.ShareGroupTypeAccessExists( type_id=share_group_type_id, project_id=project_id) return access_ref@context_manager.reader############################### def _share_group_type_specs_query(context, type_id): context, models.ShareGroupTypeSpecs, read_deleted=""no""@context_manager.reader@context_manager.writer def share_group_type_specs_delete(context, type_id, key): _share_group_type_specs_get_item(context, type_id, key) _share_group_type_specs_query( context, type_id, ).filter_by( key=key, ).soft_delete()def _share_group_type_specs_get_item(context, type_id, key): context, type_id,@context_manager.writer def share_group_type_specs_update_or_create(context, type_id, specs): spec_ref = None for key, value in specs.items(): try: spec_ref = _share_group_type_specs_get_item( context, type_id, key, ) except exception.ShareGroupTypeSpecsNotFound: spec_ref = models.ShareGroupTypeSpecs() spec_ref.update({""key"": key, ""value"": value, ""share_group_type_id"": type_id, ""deleted"": 0}) spec_ref.save(session=context.session) return specs","def _share_group_get(context, share_group_id, session=None): session = session or get_session() session=session,def share_group_get(context, share_group_id, session=None): return _share_group_get(context, share_group_id, session=session) sort_key=None, sort_dir=None, session=None): session = session or get_session() context, models.ShareGroup, session=session, read_deleted='no') session = get_session() with session.begin(): share_group.update(values) session.add(share_group) return _share_group_get(context, values['id'], session=session)def share_group_update(context, share_group_id, values): session = get_session() with session.begin(): share_group_ref = _share_group_get( context, share_group_id, session=session) share_group_ref.update(values) share_group_ref.save(session=session) return share_group_refdef share_group_destroy(context, share_group_id): session = get_session() with session.begin(): share_group_ref = _share_group_get( context, share_group_id, session=session) share_group_ref.soft_delete(session) session.query(models.ShareGroupShareTypeMapping).filter_by( share_group_id=share_group_ref['id']).soft_delete()def count_shares_in_share_group(context, share_group_id, session=None): session = session or get_session() return (model_query(context, models.Share, session=session,def get_all_shares_by_share_group(context, share_group_id, session=None): session = session or get_session() context, models.Share, session=session, share_type_id=None, session=None): session=session).filter_by(project_id=project_id) share_type_id=None, session=None): session=session).filter_by(project_id=project_id) session=None, share_type_id=None): session = session or get_session() session=session).join( models.ShareInstance.share_id == models.Share.id).filter( models.Share.project_id == project_id).filter( models.ShareInstance.replica_state.isnot(None))def count_share_group_snapshots_in_share_group(context, share_group_id, session=None): session = session or get_session() context, models.ShareGroupSnapshot, session=session,def count_share_groups_in_share_network(context, share_network_id, session=None): session = session or get_session() context, models.ShareGroup, session=session,def count_share_group_snapshot_members_in_share(context, share_id, session=None): session = session or get_session() context, models.ShareSnapshotInstance, session=session,def _share_group_snapshot_get(context, share_group_snapshot_id, session=None): session = session or get_session() context, models.ShareGroupSnapshot, session=session, project_only=True, read_deleted='no', context, project_id=None, detailed=True, filters=None, sort_key=None, sort_dir=None, session=None): session = session or get_session() query = model_query( context, models.ShareGroupSnapshot, session=session, read_deleted='no')def share_group_snapshot_get(context, share_group_snapshot_id, session=None): session = session or get_session() return _share_group_snapshot_get( context, share_group_snapshot_id, session=session) session = get_session() with session.begin(): share_group_snapshot.update(values) session.add(share_group_snapshot) return _share_group_snapshot_get( context, values['id'], session=session)def share_group_snapshot_update(context, share_group_snapshot_id, values): session = get_session() with session.begin(): share_group_ref = _share_group_snapshot_get( context, share_group_snapshot_id, session=session) share_group_ref.update(values) share_group_ref.save(session=session) return share_group_refdef share_group_snapshot_destroy(context, share_group_snapshot_id): session = get_session() with session.begin(): share_group_snap_ref = _share_group_snapshot_get( context, share_group_snapshot_id, session=session) share_group_snap_ref.soft_delete(session) session.query(models.ShareSnapshotInstance).filter_by( share_group_snapshot_id=share_group_snapshot_id).soft_delete()def share_group_snapshot_members_get_all(context, share_group_snapshot_id, session=None): session = session or get_session() context, models.ShareSnapshotInstance, session=session,def share_group_snapshot_member_get(context, member_id, session=None): context, models.ShareSnapshotInstance, session=session, project_only=True, read_deleted='no',def share_group_snapshot_member_create(context, values): member = models.ShareSnapshotInstance() session = get_session() with session.begin(): member.update(values) session.add(member) return share_group_snapshot_member_get( context, values['id'], session=session)def share_group_snapshot_member_update(context, member_id, values): session = get_session() with session.begin(): member = share_group_snapshot_member_get( context, member_id, session=session) member.update(values) session.add(member) return share_group_snapshot_member_get( context, member_id, session=session) session = get_session() with session.begin(): try: values['group_specs'] = _metadata_refs( values.get('group_specs'), models.ShareGroupTypeSpecs) mappings = [] for item in values.get('share_types', []): share_type = share_type_get_by_name_or_id(context, item) if not share_type: raise exception.ShareTypeDoesNotExist(share_type=item) mapping = models.ShareGroupTypeShareTypeMapping() mapping['id'] = uuidutils.generate_uuid() mapping['share_type_id'] = share_type['id'] mapping['share_group_type_id'] = values['id'] mappings.append(mapping) values['share_types'] = mappings share_group_type_ref = models.ShareGroupTypes() share_group_type_ref.update(values) share_group_type_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareGroupTypeExists(type_id=values['name']) except exception.ShareTypeDoesNotExist: raise except Exception as e: raise db_exception.DBError(e) for project in set(projects): access_ref = models.ShareGroupTypeProjects() access_ref.update({""share_group_type_id"": share_group_type_ref.id, ""project_id"": project}) access_ref.save(session=session) return share_group_type_ref def _share_group_type_get_query(context, session=None, read_deleted=None, expected_fields=None): context, models.ShareGroupTypes, session=session,def _share_group_type_get_id_from_share_group_type_query(context, type_id, session=None): context, models.ShareGroupTypes, read_deleted=""no"", session=session,def _share_group_type_get_id_from_share_group_type(context, type_id, session=None): context, type_id, session=session).first()def _share_group_type_get(context, type_id, session=None, inactive=False, expected_fields=None): context, session, read_deleted, expected_fields, context, type_id, session=None, inactive=inactive, expected_fields=expected_fields)def _share_group_type_get_by_name(context, name, session=None): context, models.ShareGroupTypes, session=session,def share_group_type_destroy(context, type_id): session = get_session() with session.begin(): _share_group_type_get(context, type_id, session) results = model_query( context, models.ShareGroup, session=session, read_deleted=""no"", ).filter_by( share_group_type_id=type_id, ).count() if results: LOG.error('Share group type %s deletion failed, it in use.', type_id) raise exception.ShareGroupTypeInUse(type_id=type_id) model_query( context, models.ShareGroupTypeSpecs, session=session, ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypeShareTypeMapping, session=session ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypeProjects, session=session ).filter_by( share_group_type_id=type_id, ).soft_delete() model_query( context, models.ShareGroupTypes, session=session ).filter_by( id=type_id, ).soft_delete() def _share_group_type_access_query(context, session=None): return model_query(context, models.ShareGroupTypeProjects, session=session, read_deleted=""no"") session = get_session() with session.begin(): try: access_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareGroupTypeAccessExists( type_id=share_group_type_id, project_id=project_id) return access_refdef _share_group_type_specs_query(context, type_id, session=None): context, models.ShareGroupTypeSpecs, session=session, read_deleted=""no""def share_group_type_specs_delete(context, type_id, key): session = get_session() with session.begin(): _share_group_type_specs_get_item(context, type_id, key, session) _share_group_type_specs_query( context, type_id, session, ).filter_by( key=key, ).soft_delete()def _share_group_type_specs_get_item(context, type_id, key, session=None): context, type_id, session=session,def share_group_type_specs_update_or_create(context, type_id, specs): session = get_session() with session.begin(): spec_ref = None for key, value in specs.items(): try: spec_ref = _share_group_type_specs_get_item( context, type_id, key, session) except exception.ShareGroupTypeSpecsNotFound: spec_ref = models.ShareGroupTypeSpecs() spec_ref.update({""key"": key, ""value"": value, ""share_group_type_id"": type_id, ""deleted"": 0}) spec_ref.save(session=session) return specs",281,225
openstack%2Fnova~master~I3391993322af9b53cfb3b230d1d6c1537db8db5e,openstack/nova,master,I3391993322af9b53cfb3b230d1d6c1537db8db5e,WIP: Use network's dns_domain in metadata hostname,ABANDONED,2022-05-06 13:34:14.000000000,2023-04-15 01:10:41.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-05-06 13:34:14.000000000', 'files': ['nova/tests/fixtures/neutron.py', 'nova/network/neutron.py', 'nova/network/model.py', 'nova/api/metadata/base.py', 'nova/tests/functional/test_metadata.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/45c4e6042a47a4ab50b3a8c7120ac442909f6b40', 'message': ""WIP: Use network's dns_domain in metadata hostname\n\nChange-Id: I3391993322af9b53cfb3b230d1d6c1537db8db5e\nImplements: bp/fqdn-in-metadata\n""}]",1,840899,45c4e6042a47a4ab50b3a8c7120ac442909f6b40,7,2,1,8864,,,0,"WIP: Use network's dns_domain in metadata hostname

Change-Id: I3391993322af9b53cfb3b230d1d6c1537db8db5e
Implements: bp/fqdn-in-metadata
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/840899/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutron.py', 'nova/tests/fixtures/neutron.py', 'nova/network/model.py', 'nova/api/metadata/base.py', 'nova/tests/functional/test_metadata.py']",5,45c4e6042a47a4ab50b3a8c7120ac442909f6b40,," self.neutron = self.useFixture(nova_fixtures.NeutronFixture(self)) networks = [{'port': self.neutron.port_1['id']}] server = self._build_server(name='test', networks=networks) self.assertEqual('test.network_1.example.com', j['hostname']) def test_lookup_ec2_hostname(self): url = '%slatest/meta-data/hostname' % self.md_url res = requests.request('GET', url, timeout=5) self.assertEqual(200, res.status_code) self.assertEqual('test.network_1.example.com', res.text)"," self.useFixture(nova_fixtures.NeutronFixture(self)) server = self._build_server(name='test') self.assertEqual('test.novalocal', j['hostname'])",38,12
openstack%2Fcharm-octavia-dashboard~master~I6e549bd4611517f363d7df905e3af0ccdf0727ba,openstack/charm-octavia-dashboard,master,I6e549bd4611517f363d7df905e3af0ccdf0727ba,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:11:00.000000000,2023-04-14 23:03:11.000000000,2023-04-14 23:03:11.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:11:00.000000000', 'files': ['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-octavia-dashboard/commit/8287e5a0c50bdf281ce5c3c233f967f2e8f7a7c7', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I6e549bd4611517f363d7df905e3af0ccdf0727ba\n'}]",2,878997,8287e5a0c50bdf281ce5c3c233f967f2e8f7a7c7,9,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I6e549bd4611517f363d7df905e3af0ccdf0727ba
",git fetch https://review.opendev.org/openstack/charm-octavia-dashboard refs/changes/97/878997/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,8287e5a0c50bdf281ce5c3c233f967f2e8f7a7c7,antelope-voting,,variables: openstack-origin: &openstack-origin distro series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge octavia-mysql-router: charm: ch:mysql-router channel: latest/edge openstack-dashboard-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '3' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '4' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs neutron-security-groups: True openstack-origin: *openstack-origin to: - '5' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch num_units: 0 channel: latest/edge octavia: charm: ch:octavia num_units: 1 options: openstack-origin: *openstack-origin to: - '6' channel: latest/edge openstack-dashboard: charm: ch:openstack-dashboard num_units: 1 options: openstack-origin: *openstack-origin to: - '7' channel: latest/edge octavia-dashboard: charm: ../../../octavia-dashboard_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm relations: - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'octavia:shared-db' - 'octavia-mysql-router:shared-db' - - 'octavia-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'openstack-dashboard:shared-db' - 'openstack-dashboard-mysql-router:shared-db' - - 'openstack-dashboard-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'keystone:identity-service' - 'neutron-api:identity-service' - - 'keystone:identity-service' - 'octavia:identity-service' - - 'keystone:identity-service' - 'openstack-dashboard:identity-service' - - 'rabbitmq-server:amqp' - 'neutron-api:amqp' - - 'rabbitmq-server:amqp' - 'octavia:amqp' - - 'rabbitmq-server:amqp' - 'neutron-openvswitch:amqp' - - 'neutron-openvswitch:neutron-plugin' - 'octavia:neutron-openvswitch' - - 'openstack-dashboard:dashboard-plugin' - 'octavia-dashboard:dashboard' ,0,147
openstack%2Fcharm-glance-simplestreams-sync~master~I37c5aff2d71eae71015d1a1986fb73f64b864a94,openstack/charm-glance-simplestreams-sync,master,I37c5aff2d71eae71015d1a1986fb73f64b864a94,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:34.000000000,2023-04-14 23:02:18.000000000,2023-04-14 23:02:18.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:34.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance-simplestreams-sync/commit/6faf284248fe998c2404912945722a286a30a773', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I37c5aff2d71eae71015d1a1986fb73f64b864a94\n'}]",2,878968,6faf284248fe998c2404912945722a286a30a773,9,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I37c5aff2d71eae71015d1a1986fb73f64b864a94
",git fetch https://review.opendev.org/openstack/charm-glance-simplestreams-sync refs/changes/68/878968/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,6faf284248fe998c2404912945722a286a30a773,antelope-voting,, - kinetic-zed - kinetic-zed,0,136
openstack%2Fcharm-nova-compute~master~Ic290801451f6537e25dfb0330a81598bbafa7135,openstack/charm-nova-compute,master,Ic290801451f6537e25dfb0330a81598bbafa7135,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:16:43.000000000,2023-04-14 22:59:19.000000000,2023-04-14 22:59:19.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:16:43.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/d9fc4b69c11464525c38e5f2f6a5e9003d0d4b4e', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Ic290801451f6537e25dfb0330a81598bbafa7135\n'}]",4,879006,d9fc4b69c11464525c38e5f2f6a5e9003d0d4b4e,15,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: Ic290801451f6537e25dfb0330a81598bbafa7135
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/06/879006/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,d9fc4b69c11464525c38e5f2f6a5e9003d0d4b4e,antelope-voting,,- kinetic-zed - kinetic-zed,0,314
openstack%2Fcharm-manila-ganesha~master~I0236382ca3078c0434ad67fc33ba759baf066c93,openstack/charm-manila-ganesha,master,I0236382ca3078c0434ad67fc33ba759baf066c93,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:12:02.000000000,2023-04-14 22:59:09.000000000,2023-04-14 22:59:09.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:12:02.000000000', 'files': ['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-manila-ganesha/commit/eb42d7a6843012b32d57bbefd951f9e6ca208a31', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I0236382ca3078c0434ad67fc33ba759baf066c93\n'}]",5,878982,eb42d7a6843012b32d57bbefd951f9e6ca208a31,14,4,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I0236382ca3078c0434ad67fc33ba759baf066c93
",git fetch https://review.opendev.org/openstack/charm-manila-ganesha refs/changes/82/878982/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,eb42d7a6843012b32d57bbefd951f9e6ca208a31,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: True series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': '11': '12': '13': '14': '15': '16': '17': constraints: mem=8G '18': constraints: mem=8G '19': '20': '21': '22': '23': services: manila-mysql-router: charm: ch:mysql-router channel: latest/edge manila-ganesha-mysql-router: charm: ch:mysql-router channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge manila-ganesha-az1: num_units: 3 charm: ../../../manila-ganesha_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm options: openstack-origin: *openstack-origin to: - '3' - '4' - '5' ceph-mon: charm: ch:ceph-mon num_units: 3 options: source: *openstack-origin to: - '6' - '7' - '8' channel: latest/edge ceph-osd: charm: ch:ceph-osd num_units: 3 options: source: *openstack-origin storage: osd-devices: 'cinder,10G' to: - '9' - '10' - '11' channel: latest/edge ceph-fs: charm: ch:ceph-fs num_units: 2 options: source: *openstack-origin to: - '12' - '13' channel: latest/edge manila: charm: ch:manila num_units: 1 options: default-share-backend: cephfsnfs1 share-protocols: NFS openstack-origin: *openstack-origin to: - '14' channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: *openstack-origin to: - '15' channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin to: - '16' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 2 options: config-flags: default_ephemeral_format=ext4 enable-live-migration: true enable-resize: true migration-auth-type: ssh openstack-origin: *openstack-origin to: - '17' - '18' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin to: - '19' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs flat-network-providers: physnet1 neutron-security-groups: true openstack-origin: *openstack-origin to: - '20' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: bridge-mappings: physnet1:br-ex openstack-origin: *openstack-origin to: - '21' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '22' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '23' channel: latest/edge nrpe: charm: ch:nrpe channel: latest/edge relations: - - 'ceph-mon' - 'ceph-osd' - - 'ceph-mon' - 'ceph-fs' - - 'ceph-mon' - 'manila-ganesha-az1' - - 'manila:shared-db' - 'manila-mysql-router:shared-db' - - 'manila-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'manila-ganesha-az1' - 'rabbitmq-server' - - 'manila-ganesha-az1' - 'keystone' - - 'manila' - 'manila-ganesha-az1' - - 'manila-ganesha-az1:shared-db' - 'manila-ganesha-mysql-router:shared-db' - - 'manila-ganesha-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'manila' - 'rabbitmq-server' - - 'manila' - 'keystone' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-api:neutron-api' - 'nova-cloud-controller:neutron-api' - - 'placement:placement' - 'nova-cloud-controller:placement' - - 'placement:amqp' - 'rabbitmq-server:amqp' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'placement:identity-service' - 'keystone:identity-service' - - 'neutron-api:neutron-plugin-api' - 'neutron-gateway:neutron-plugin-api' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'glance:identity-service' - 'keystone:identity-service' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'manila-ganesha-az1:nrpe-external-master' - 'nrpe:nrpe-external-master' ",0,341
openstack%2Fcharm-heat~master~I4e2f6e5d763b6fe216082b063d5dcc12e1aa3f62,openstack/charm-heat,master,I4e2f6e5d763b6fe216082b063d5dcc12e1aa3f62,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:38.000000000,2023-04-14 22:58:57.000000000,2023-04-14 22:58:57.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:38.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/c09949a4df5966e0c1e831d3ba9a12a09d54e6e9', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I4e2f6e5d763b6fe216082b063d5dcc12e1aa3f62\n'}]",3,878970,c09949a4df5966e0c1e831d3ba9a12a09d54e6e9,11,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I4e2f6e5d763b6fe216082b063d5dcc12e1aa3f62
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/70/878970/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,c09949a4df5966e0c1e831d3ba9a12a09d54e6e9,antelope-voting,, - kinetic-zed - kinetic-zed,0,242
openstack%2Fcharm-nova-cloud-controller~master~I367b12d6919747d987f30020575a467f1c473fef,openstack/charm-nova-cloud-controller,master,I367b12d6919747d987f30020575a467f1c473fef,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:10:53.000000000,2023-04-14 22:58:54.000000000,2023-04-14 22:58:54.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:10:53.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/0d34b8725dfd70d8bd140cdd7c8891eedb516da9', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I367b12d6919747d987f30020575a467f1c473fef\n'}]",3,878994,0d34b8725dfd70d8bd140cdd7c8891eedb516da9,11,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I367b12d6919747d987f30020575a467f1c473fef
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/94/878994/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,0d34b8725dfd70d8bd140cdd7c8891eedb516da9,antelope-voting,,- kinetic-zed - kinetic-zed,0,259
openstack%2Fcharm-neutron-gateway~master~I73f8f0d538701779ad570bc7565982a6b7e4f7af,openstack/charm-neutron-gateway,master,I73f8f0d538701779ad570bc7565982a6b7e4f7af,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:12:19.000000000,2023-04-14 22:58:33.000000000,2023-04-14 22:58:33.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:12:19.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/cf83220246c2613c943da17902ff219317a15672', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I73f8f0d538701779ad570bc7565982a6b7e4f7af\n'}]",3,878991,cf83220246c2613c943da17902ff219317a15672,11,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I73f8f0d538701779ad570bc7565982a6b7e4f7af
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/91/878991/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,cf83220246c2613c943da17902ff219317a15672,antelope-voting,, - migrate-ovn: kinetic-zed - kinetic-zed,0,289
openstack%2Fcharm-ceilometer-agent~master~I45bf4ef2d0fc1323132804c7a89cc42a768d18a8,openstack/charm-ceilometer-agent,master,I45bf4ef2d0fc1323132804c7a89cc42a768d18a8,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:06.000000000,2023-04-14 22:58:05.000000000,2023-04-14 22:58:05.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:06.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/b92515f4b192c6b9bc0d2866079c759a4aef9ab1', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I45bf4ef2d0fc1323132804c7a89cc42a768d18a8\n'}]",3,878954,b92515f4b192c6b9bc0d2866079c759a4aef9ab1,13,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I45bf4ef2d0fc1323132804c7a89cc42a768d18a8
",git fetch https://review.opendev.org/openstack/charm-ceilometer-agent refs/changes/54/878954/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,b92515f4b192c6b9bc0d2866079c759a4aef9ab1,antelope-voting,, - kinetic-zed - kinetic-zed,0,326
openstack%2Fcharm-placement~master~I90a8235e29b42d6cd445ead387ae531988b578e6,openstack/charm-placement,master,I90a8235e29b42d6cd445ead387ae531988b578e6,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:11:10.000000000,2023-04-14 22:56:31.000000000,2023-04-14 22:56:31.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/8b10a7dbd73afdba338b1d127551fe2e31a12300', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I90a8235e29b42d6cd445ead387ae531988b578e6\n'}, {'number': 2, 'created': '2023-04-14 15:02:42.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/09503a4d34e8b980bef3696c63fc0482d2b3e70e', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: I90a8235e29b42d6cd445ead387ae531988b578e6\n'}]",2,879001,09503a4d34e8b980bef3696c63fc0482d2b3e70e,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: I90a8235e29b42d6cd445ead387ae531988b578e6
",git fetch https://review.opendev.org/openstack/charm-placement refs/changes/01/879001/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,8b10a7dbd73afdba338b1d127551fe2e31a12300,antelope-voting,,variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': '11': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge vault-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 constraints: mem=1G to: - '3' channel: latest/edge glance: charm: ch:glance num_units: 1 constraints: mem=1G options: openstack-origin: *openstack-origin to: - '4' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin admin-password: openstack to: - '5' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: openstack-origin: *openstack-origin manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs flat-network-providers: physnet1 neutron-security-groups: true to: - '6' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: openstack-origin: *openstack-origin bridge-mappings: physnet1:br-ex to: - '7' channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: openstack-origin: *openstack-origin network-manager: Neutron debug: true to: - '8' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 1 constraints: mem=4G options: openstack-origin: *openstack-origin enable-live-migration: true enable-resize: true migration-auth-type: ssh debug: true to: - '9' channel: latest/edge placement: charm: ../../../placement.charm num_units: 1 constraints: mem=1G options: openstack-origin: *openstack-origin debug: true to: - '10' vault: num_units: 1 charm: ch:vault to: - '11' channel: latest/edge relations: - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller' - 'glance' - - 'nova-cloud-controller' - 'keystone' - - 'nova-compute' - 'nova-cloud-controller' - - 'nova-compute' - 'rabbitmq-server:amqp' - - 'nova-compute' - 'glance' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance' - 'keystone' - - 'glance' - 'rabbitmq-server' - - 'neutron-gateway' - 'nova-cloud-controller' - - 'neutron-gateway:amqp' - 'rabbitmq-server' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api' - 'rabbitmq-server' - - 'neutron-api' - 'nova-cloud-controller' - - 'neutron-api' - 'neutron-openvswitch' - - 'neutron-api' - 'keystone' - - 'neutron-api' - 'neutron-gateway' - - 'neutron-openvswitch' - 'nova-compute' - - 'neutron-openvswitch' - 'rabbitmq-server' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'placement' - 'keystone' - - 'placement' - 'nova-cloud-controller' - - 'vault:shared-db' - 'vault-mysql-router:shared-db' - - 'vault-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'vault:certificates' - 'keystone:certificates' - - 'vault:certificates' - 'placement:certificates' - - 'vault:certificates' - 'neutron-api:certificates' - - 'vault:certificates' - 'glance:certificates' - - 'vault:certificates' - 'nova-cloud-controller:certificates' ,0,257
openstack%2Fcharm-magnum~master~Id8e23d885d2bed9a7ace4b6e71fad890fce5b425,openstack/charm-magnum,master,Id8e23d885d2bed9a7ace4b6e71fad890fce5b425,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:54.000000000,2023-04-14 22:55:35.000000000,2023-04-14 22:55:35.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum/commit/521529d523d1edd71862b539e54ff5cee13e0b0d', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Id8e23d885d2bed9a7ace4b6e71fad890fce5b425\n'}, {'number': 2, 'created': '2023-04-14 15:03:02.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-magnum/commit/82b425c9dd457df3e2bf45024a8a4c96c6f68ff6', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: Id8e23d885d2bed9a7ace4b6e71fad890fce5b425\n'}]",2,878978,82b425c9dd457df3e2bf45024a8a4c96c6f68ff6,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: Id8e23d885d2bed9a7ace4b6e71fad890fce5b425
",git fetch https://review.opendev.org/openstack/charm-magnum refs/changes/78/878978/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,521529d523d1edd71862b539e54ff5cee13e0b0d,antelope-voting,,variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': # the following machines are for nova-compute which needs more memory # for the instances. '10': constraints: mem=4096M cores=4 '11': constraints: mem=4096M cores=4 '12': '13': '14': '15': '16': '17': applications: nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge vault-mysql-router: charm: ch:mysql-router channel: latest/edge magnum-mysql-router: charm: ch:mysql-router channel: latest/edge heat-mysql-router: charm: ch:mysql-router channel: latest/edge barbican-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '3' channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: openstack-origin: *openstack-origin network-manager: Neutron to: - '4' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs openstack-origin: *openstack-origin flat-network-providers: physnet1 neutron-security-groups: true to: - '5' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '6' channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: openstack-origin: *openstack-origin bridge-mappings: physnet1:br-ex to: - '7' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin to: - '8' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin to: - '9' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 2 storage: ephemeral-device: '40G' options: openstack-origin: *openstack-origin to: - '10' - '11' channel: latest/edge vault: charm: ch:vault num_units: 1 to: - '12' channel: latest/edge magnum: charm: ../../../magnum.charm num_units: 3 options: openstack-origin: *openstack-origin to: - '13' - '14' - '15' magnum-hacluster: charm: ch:hacluster num_units: 0 options: corosync_transport: unicast cluster_count: 3 channel: latest/edge heat: charm: ch:heat num_units: 1 options: openstack-origin: *openstack-origin to: - '16' channel: latest/edge barbican: charm: ch:barbican num_units: 1 options: openstack-origin: *openstack-origin to: - '17' channel: latest/edge relations: - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:identity-service' - 'keystone:identity-service' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-api:neutron-api' - 'nova-cloud-controller:neutron-api' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'rabbitmq-server:amqp' - 'neutron-openvswitch:amqp' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'placement:identity-service' - 'keystone:identity-service' - - 'placement:placement' - 'nova-cloud-controller:placement' - - 'vault:shared-db' - 'vault-mysql-router:shared-db' - - 'vault-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'vault:certificates' - 'neutron-api:certificates' - - 'vault:certificates' - 'glance:certificates' - - 'vault:certificates' - 'keystone:certificates' - - 'vault:certificates' - 'nova-cloud-controller:certificates' - - 'vault:certificates' - 'placement:certificates' - - 'magnum:shared-db' - 'magnum-mysql-router:shared-db' - - 'magnum-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'magnum:amqp' - 'rabbitmq-server:amqp' - - 'magnum:identity-service' - 'keystone:identity-service' - - 'magnum:certificates' - 'vault:certificates' - - 'magnum:ha' - 'magnum-hacluster:ha' - - 'heat:amqp' - 'rabbitmq-server:amqp' - - 'heat:identity-service' - 'keystone:identity-service' - - 'heat:shared-db' - 'heat-mysql-router:shared-db' - - 'heat-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'heat:certificates' - 'vault:certificates' - - 'barbican:amqp' - 'rabbitmq-server:amqp' - - 'barbican:identity-service' - 'keystone:identity-service' - - 'barbican:shared-db' - 'barbican-mysql-router:shared-db' - - 'barbican-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'barbican:certificates' - 'vault:certificates' ,0,346
openstack%2Fcharm-manila-generic~master~I102ee0648ffbbed87df5b3de6cb964ee6fb90744,openstack/charm-manila-generic,master,I102ee0648ffbbed87df5b3de6cb964ee6fb90744,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:12:04.000000000,2023-04-14 22:55:33.000000000,2023-04-14 22:55:33.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/321e8e59b93397ac860dd22dc3171627057222c3', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I102ee0648ffbbed87df5b3de6cb964ee6fb90744\n'}, {'number': 2, 'created': '2023-04-14 15:01:30.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/6f7411162638b1cecedc045c2efc4b5f466bc56b', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: I102ee0648ffbbed87df5b3de6cb964ee6fb90744\n'}]",3,878983,6f7411162638b1cecedc045c2efc4b5f466bc56b,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: I102ee0648ffbbed87df5b3de6cb964ee6fb90744
",git fetch https://review.opendev.org/openstack/charm-manila-generic refs/changes/83/878983/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,321e8e59b93397ac860dd22dc3171627057222c3,antelope-voting,,variables: openstack-origin: &openstack-origin distro series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': services: manila-mysql-router: charm: ch:mysql-router channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge manila: charm: ch:manila num_units: 1 options: default-share-backend: generic openstack-origin: *openstack-origin to: - '3' channel: latest/edge manila-generic: charm: ../../../manila-generic.charm options: driver-handles-share-servers: False rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '4' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '5' channel: latest/edge nrpe: charm: ch:nrpe channel: latest/edge relations: - - 'manila:shared-db' - 'manila-mysql-router:shared-db' - - 'manila-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'manila:manila-plugin' - 'manila-generic' - - 'manila' - 'rabbitmq-server' - - 'manila' - 'keystone' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nrpe:nrpe-external-master' - 'manila:nrpe-external-master' ,0,97
openstack%2Fcharm-manila~master~I57df3d1f01049a9b4b12c970cf83abffb7b4ed64,openstack/charm-manila,master,I57df3d1f01049a9b4b12c970cf83abffb7b4ed64,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:58.000000000,2023-04-14 22:54:58.000000000,2023-04-14 22:54:58.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:58.000000000', 'files': ['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/7bd535068d7489816092ca8afc92d343bc326883', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I57df3d1f01049a9b4b12c970cf83abffb7b4ed64\n'}]",6,878980,7bd535068d7489816092ca8afc92d343bc326883,15,4,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I57df3d1f01049a9b4b12c970cf83abffb7b4ed64
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/80/878980/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,7bd535068d7489816092ca8afc92d343bc326883,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': '11': '12': '13': '14': '15': # 16 and 17 are nova compute units '16': constraints: mem=8G '17': constraints: mem=8G '18': '19': '20': '21': '22': '23': services: manila-mysql-router: charm: ch:mysql-router channel: latest/edge manila-ganesha-mysql-router: charm: ch:mysql-router channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge # manila backends manila-ganesha: num_units: 1 charm: ch:manila-ganesha options: openstack-origin: *openstack-origin to: - '3' channel: latest/edge manila-generic: charm: ch:manila-generic channel: latest/edge options: driver-handles-share-servers: False ceph-mon: charm: ch:ceph-mon num_units: 3 options: source: *openstack-origin to: - '4' - '5' - '6' channel: latest/edge ceph-osd: charm: ch:ceph-osd num_units: 3 options: source: *openstack-origin storage: osd-devices: 'cinder,10G' to: - '7' - '8' - '9' channel: latest/edge ceph-fs: charm: ch:ceph-fs num_units: 2 options: source: *openstack-origin to: - '10' - '11' channel: latest/edge manila: charm: ../../../manila_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm num_units: 3 options: default-share-backend: cephfsnfs1 share-protocols: NFS openstack-origin: *openstack-origin to: - '12' - '13' - '14' nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: *openstack-origin to: - '15' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 2 storage: ephemeral-device: '40G' options: config-flags: default_ephemeral_format=ext4 enable-live-migration: true enable-resize: true migration-auth-type: ssh openstack-origin: *openstack-origin to: - '16' - '17' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin to: - '18' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true neutron-plugin: ovs flat-network-providers: physnet1 neutron-security-groups: true openstack-origin: *openstack-origin to: - '19' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: bridge-mappings: physnet1:br-ex openstack-origin: *openstack-origin to: - '20' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '21' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '22' channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin to: - '23' channel: latest/edge nrpe: charm: ch:nrpe channel: latest/edge relations: - - 'ceph-mon' - 'ceph-osd' - - 'ceph-mon' - 'ceph-fs' - - 'ceph-mon' - 'manila-ganesha' - - 'manila:shared-db' - 'manila-mysql-router:shared-db' - - 'manila-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'manila-ganesha' - 'rabbitmq-server' - - 'manila-ganesha' - 'keystone' - - 'manila' - 'manila-ganesha' - - 'manila:manila-plugin' - 'manila-generic:manila-plugin' - - 'manila-ganesha:shared-db' - 'manila-ganesha-mysql-router:shared-db' - - 'manila-ganesha-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'manila' - 'rabbitmq-server' - - 'manila' - 'keystone' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-api:neutron-api' - 'nova-cloud-controller:neutron-api' - - 'neutron-api:neutron-plugin-api' - 'neutron-gateway:neutron-plugin-api' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'glance:identity-service' - 'keystone:identity-service' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'placement:placement' - 'nova-cloud-controller:placement' - - 'placement:amqp' - 'rabbitmq-server:amqp' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'placement:identity-service' - 'keystone:identity-service' - - 'nrpe:nrpe-external-master' - 'manila:nrpe-external-master' ",0,351
openstack%2Fcharm-gnocchi~master~I463ac3b04112941489a5211f75e8e24db0aa82e0,openstack/charm-gnocchi,master,I463ac3b04112941489a5211f75e8e24db0aa82e0,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:36.000000000,2023-04-14 22:53:34.000000000,2023-04-14 22:53:34.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/a8d229d753cd1a8ee2466968de42a30107e1ba06', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I463ac3b04112941489a5211f75e8e24db0aa82e0\n'}, {'number': 2, 'created': '2023-04-14 14:49:25.000000000', 'files': ['osci.yaml', 'src/tests/bundles/jammy-antelope-s3.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/4c6cef4b700d83201b82e1935c8d29be5ba1438f', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I463ac3b04112941489a5211f75e8e24db0aa82e0\n'}]",2,878969,4c6cef4b700d83201b82e1935c8d29be5ba1438f,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I463ac3b04112941489a5211f75e8e24db0aa82e0
",git fetch https://review.opendev.org/openstack/charm-gnocchi refs/changes/69/878969/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/kinetic-zed-s3.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",4,a8d229d753cd1a8ee2466968de42a30107e1ba06,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: &series kinetic machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': '11': '12': '13': series: focal # We specify machine placements for these to improve iteration # time, given that machine ""0"" comes up way before machine ""6"" applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge gnocchi-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 options: source: *openstack-origin to: - '3' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '4' channel: latest/edge ceilometer: charm: ch:ceilometer num_units: 1 options: openstack-origin: *openstack-origin to: - '5' channel: latest/edge ceph-osd: charm: ch:ceph-osd num_units: 3 storage: osd-devices: 'cinder,10G' options: source: *openstack-origin to: - '6' - '7' - '8' channel: latest/edge ceph-mon: charm: ch:ceph-mon num_units: 3 options: expected-osd-count: 3 monitor-count: '3' source: *openstack-origin to: - '9' - '10' - '11' channel: latest/edge gnocchi: series: *series charm: ../../../gnocchi_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm num_units: 1 options: openstack-origin: *openstack-origin to: - '12' memcached: charm: ch:memcached num_units: 1 # Note that holding memcached at focal as it's not available at kinetic yet. series: focal to: - '13' relations: - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'ceph-osd:mon' - 'ceph-mon:osd' - - 'ceilometer:amqp' - 'rabbitmq-server:amqp' - - 'ceilometer:identity-credentials' - 'keystone:identity-credentials' - - 'ceilometer:identity-notifications' - 'keystone:identity-notifications' - - 'ceilometer:metric-service' - 'gnocchi:metric-service' - - 'gnocchi:identity-service' - 'keystone:identity-service' - - 'gnocchi:shared-db' - 'gnocchi-mysql-router:shared-db' - - 'gnocchi-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'gnocchi:storage-ceph' - 'ceph-mon:client' - - 'gnocchi:coordinator-memcached' - 'memcached:cache' ",1,324
openstack%2Fcharm-ironic-api~master~I25762c5e6b0ca4447d5f5b50ea77b8ff2048454f,openstack/charm-ironic-api,master,I25762c5e6b0ca4447d5f5b50ea77b8ff2048454f,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:40.000000000,2023-04-14 22:51:19.000000000,2023-04-14 22:51:19.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/0fd3a9757cfd2d0cc89f562a5e64e47422cd6d43', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I25762c5e6b0ca4447d5f5b50ea77b8ff2048454f\n'}, {'number': 2, 'created': '2023-04-14 15:00:59.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/8ae8945d0282731264d4c0ebcad5ea976f3bd9a2', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: I25762c5e6b0ca4447d5f5b50ea77b8ff2048454f\n'}]",2,878971,8ae8945d0282731264d4c0ebcad5ea976f3bd9a2,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: I25762c5e6b0ca4447d5f5b50ea77b8ff2048454f
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/71/878971/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,0fd3a9757cfd2d0cc89f562a5e64e47422cd6d43,antelope-voting,,"local_overlay_enabled: False options: source: &source distro series: kinetic relations: - - nova-ironic - ironic-api - - ironic-conductor - ironic-api - - neutron-ironic-agent:identity-credentials - keystone - - neutron-ironic-agent - neutron-api - - neutron-openvswitch - neutron-api - - neutron-openvswitch - nova-ironic - - neutron-openvswitch:amqp - rabbitmq-server:amqp - - ironic-api:amqp - rabbitmq-server:amqp - - ironic-api - keystone - - ironic-api:shared-db - ironic-api-mysql-router:shared-db - - ironic-conductor:amqp - rabbitmq-server:amqp - - ironic-conductor - keystone - - ironic-conductor:shared-db - ironic-conductor-mysql-router:shared-db - - nova-ironic:amqp - rabbitmq-server:amqp - - nova-ironic - glance - - nova-ironic - keystone - - nova-ironic - nova-cloud-controller - - neutron-gateway:amqp - rabbitmq-server:amqp - - keystone:shared-db - keystone-mysql-router:shared-db - - nova-cloud-controller:identity-service - keystone:identity-service - - glance:identity-service - keystone:identity-service - - neutron-api:identity-service - keystone:identity-service - - neutron-api:shared-db - neutron-api-mysql-router:shared-db - - neutron-api:amqp - rabbitmq-server:amqp - - neutron-gateway:neutron-plugin-api - neutron-api:neutron-plugin-api - - glance:shared-db - glance-mysql-router:shared-db - - glance:amqp - rabbitmq-server:amqp - - nova-cloud-controller:image-service - glance:image-service - - nova-cloud-controller:amqp - rabbitmq-server:amqp - - nova-cloud-controller:quantum-network-service - neutron-gateway:quantum-network-service - - nova-cloud-controller:shared-db - nova-cloud-controller-mysql-router:shared-db - - nova-cloud-controller:neutron-api - neutron-api:neutron-api - - cinder:image-service - glance:image-service - - cinder:amqp - rabbitmq-server:amqp - - cinder:identity-service - keystone:identity-service - - cinder:cinder-volume-service - nova-cloud-controller:cinder-volume-service - - cinder:shared-db - cinder-mysql-router:shared-db - - placement:shared-db - placement-mysql-router:shared-db - - placement - keystone - - placement - nova-cloud-controller - - ceph-mon:client - nova-ironic:ceph - - ceph-mon:client - glance:ceph - - ceph-radosgw:mon - ceph-mon:radosgw - - ceph-radosgw:identity-service - keystone:identity-service - - ceph-osd:mon - ceph-mon:osd - - ceph-radosgw:object-store - glance - - mysql-innodb-cluster:db-router - nova-cloud-controller-mysql-router:db-router - - mysql-innodb-cluster:db-router - keystone-mysql-router:db-router - - mysql-innodb-cluster:db-router - glance-mysql-router:db-router - - mysql-innodb-cluster:db-router - neutron-api-mysql-router:db-router - - mysql-innodb-cluster:db-router - placement-mysql-router:db-router - - mysql-innodb-cluster:db-router - cinder-mysql-router:db-router - - mysql-innodb-cluster:db-router - ironic-api-mysql-router:db-router - - mysql-innodb-cluster:db-router - ironic-conductor-mysql-router:db-router - - vault-mysql-router:db-router - mysql-innodb-cluster:db-router - - vault:shared-db - vault-mysql-router:shared-db - - vault:certificates - ceph-radosgw - - vault:certificates - cinder - - vault:certificates - glance:certificates - - vault:certificates - keystone:certificates - - vault:certificates - neutron-api:certificates - - vault:certificates - nova-cloud-controller:certificates - - vault:certificates - placement:certificates - - vault - ironic-conductor - - vault:certificates - ironic-api:certificates - - ironic-api - hacluster-ironic services: nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge vault-mysql-router: charm: ch:mysql-router channel: latest/edge cinder-mysql-router: charm: ch:mysql-router channel: latest/edge ironic-api-mysql-router: charm: ch:mysql-router channel: latest/edge ironic-conductor-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 constraints: mem=4G options: source: *source channel: latest/edge cinder: charm: ch:cinder num_units: 1 constraints: mem=2G options: block-device: vdb glance-api-version: 2 openstack-origin: *source worker-multiplier: 0.25 storage: block-devices: cinder,50G channel: latest/edge ceph-radosgw: charm: ch:ceph-radosgw num_units: 1 constraints: mem=2G options: source: *source namespace-tenants: True channel: latest/edge ceph-mon: charm: ch:ceph-mon num_units: 3 constraints: mem=2G options: expected-osd-count: 3 source: *source channel: latest/edge ceph-osd: charm: ch:ceph-osd num_units: 3 constraints: mem=2G options: source: *source storage: osd-devices: 'cinder,30G' channel: latest/edge glance: charm: ch:glance num_units: 1 constraints: mem=2G options: openstack-origin: *source worker-multiplier: 0.25 channel: latest/edge keystone: charm: ch:keystone num_units: 1 constraints: mem=2G options: openstack-origin: *source worker-multiplier: 0.25 channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 constraints: mem=2G options: flat-network-providers: ""physnet1"" neutron-security-groups: true openstack-origin: *source manage-neutron-plugin-legacy-mode: false worker-multiplier: 0.25 channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 constraints: mem=2G options: openstack-origin: *source enable-isolated-metadata: true enable-metadata-network: true bridge-mappings: physnet1:br-ex channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 constraints: mem=2G options: network-manager: Neutron openstack-origin: *source worker-multiplier: 0.25 channel: latest/edge nova-ironic: charm: ch:nova-compute num_units: 1 constraints: mem=2G options: enable-live-migration: false enable-resize: false openstack-origin: *source virt-type: ironic channel: latest/edge placement: charm: ch:placement num_units: 1 constraints: mem=2G options: openstack-origin: *source worker-multiplier: 0.25 channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 constraints: mem=2G channel: latest/edge hacluster-ironic: charm: ch:hacluster num_units: 0 channel: latest/edge ironic-api: charm: ../../../ironic-api.charm num_units: 3 constraints: mem=2G options: openstack-origin: *source ironic-conductor: charm: ch:ironic-conductor num_units: 1 constraints: mem=2G options: openstack-origin: *source max-tftp-block-size: 1418 disable-secure-erase: true use-ipxe: true enabled-network-interfaces: ""flat, noop"" channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch num_units: 0 options: bridge-mappings: physnet1:br-ex channel: latest/edge neutron-ironic-agent: charm: ch:neutron-api-plugin-ironic num_units: 0 options: openstack-origin: *source channel: latest/edge vault: charm: ch:vault num_units: 1 channel: latest/edge ",0,318
openstack%2Fcharm-masakari~master~If0beacfe04b08ea7460dd241d2247f2afa002652,openstack/charm-masakari,master,If0beacfe04b08ea7460dd241d2247f2afa002652,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:12:08.000000000,2023-04-14 22:50:21.000000000,2023-04-14 22:50:21.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/8171911d1d5700cf8f04dbf3f3509bec3ec27b84', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: If0beacfe04b08ea7460dd241d2247f2afa002652\n'}, {'number': 2, 'created': '2023-04-14 15:03:27.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/a3c11baa54952bb89b5ca6551fc961061feff61b', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: If0beacfe04b08ea7460dd241d2247f2afa002652\n'}]",3,878985,a3c11baa54952bb89b5ca6551fc961061feff61b,14,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython

Change-Id: If0beacfe04b08ea7460dd241d2247f2afa002652
",git fetch https://review.opendev.org/openstack/charm-masakari refs/changes/85/878985/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,8171911d1d5700cf8f04dbf3f3509bec3ec27b84,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: True series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': constraints: mem=4096M '9': constraints: mem=4096M '10': constraints: mem=4096M '11': '12': '13': '14': '15': '16': '17': '18': '19': '20': '21': '22': '23': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge cinder-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge nova-cloud-controller-mysql-router: charm: ch:mysql-router channel: latest/edge masakari-mysql-router: charm: ch:mysql-router channel: latest/edge vault-mysql-router: charm: ch:mysql-router channel: latest/edge placement-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 to: - '0' - '1' - '2' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '3' channel: latest/edge cinder: charm: ch:cinder num_units: 1 options: openstack-origin: *openstack-origin block-device: ""None"" glance-api-version: 2 to: - '4' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: admin-password: openstack openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '5' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true flat-network-providers: physnet1 neutron-security-groups: true openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '6' channel: latest/edge neutron-gateway: charm: ch:neutron-gateway num_units: 1 options: bridge-mappings: physnet1:br-ex openstack-origin: *openstack-origin worker-multiplier: 0.25 to: - '7' channel: latest/edge neutron-openvswitch: charm: ch:neutron-openvswitch num_units: 0 channel: latest/edge nova-cloud-controller: charm: ch:nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: *openstack-origin worker-multiplier: 0.25 debug: true to: - '23' channel: latest/edge nova-compute: charm: ch:nova-compute num_units: 3 constraints: mem=4G options: config-flags: default_ephemeral_format=ext4 enable-live-migration: true enable-resize: true migration-auth-type: ssh openstack-origin: *openstack-origin debug: true cpu-model: kvm64 cpu-mode: custom # Allow for more retries when testing ontop of openstack config-flags: block_device_allocate_retries=120 to: - '8' - '9' - '10' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '11' channel: latest/edge masakari: charm: ../../../masakari.charm num_units: 3 options: openstack-origin: *openstack-origin to: - '12' - '13' - '14' ceph-mon: charm: ch:ceph-mon num_units: 3 options: source: *openstack-origin expected-osd-count: 3 to: - '15' - '16' - '17' channel: latest/edge ceph-osd: charm: ch:ceph-osd constraints: mem=1G num_units: 3 options: source: *openstack-origin storage: osd-devices: cinder,40G to: - '18' - '19' - '20' channel: latest/edge cinder-ceph: charm: ch:cinder-ceph channel: latest/edge masakari-monitors: charm: ch:masakari-monitors channel: latest/edge hacluster: charm: ch:hacluster options: corosync_transport: unicast cluster_count: 3 channel: latest/edge pacemaker-remote: charm: ch:pacemaker-remote options: enable-stonith: False enable-resources: False channel: latest/edge vault: num_units: 1 charm: ch:vault to: - '21' channel: latest/edge placement: charm: ch:placement num_units: 1 options: openstack-origin: *openstack-origin to: - '22' channel: latest/edge relations: - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:amqp-nova' - 'rabbitmq-server:amqp' - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'cinder:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'glance:identity-service' - 'keystone:identity-service' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'neutron-openvswitch:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'cinder:shared-db' - 'cinder-mysql-router:shared-db' - - 'cinder-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'cinder:amqp' - 'rabbitmq-server:amqp' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-gateway:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'glance:shared-db' - 'glance-mysql-router:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:shared-db' - 'nova-cloud-controller-mysql-router:shared-db' - - 'nova-cloud-controller-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'nova-cloud-controller:neutron-api' - 'neutron-api:neutron-api' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'masakari:shared-db' - 'masakari-mysql-router:shared-db' - - 'masakari-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'masakari:amqp' - 'rabbitmq-server:amqp' - - 'masakari:identity-service' - 'keystone:identity-service' - - 'glance:ceph' - 'ceph-mon:client' - - 'ceph-mon:osd' - 'ceph-osd:mon' - - 'cinder:storage-backend' - 'cinder-ceph:storage-backend' - - 'cinder-ceph:ceph' - 'ceph-mon:client' - - 'cinder-ceph:ceph-access' - 'nova-compute:ceph-access' - - 'nova-compute:juju-info' - 'masakari-monitors:container' - - 'masakari:ha' - 'hacluster:ha' - - 'keystone:identity-credentials' - 'masakari-monitors:identity-credentials' - - 'nova-compute:juju-info' - 'pacemaker-remote:juju-info' - - 'hacluster:pacemaker-remote' - 'pacemaker-remote:pacemaker-remote' - - 'vault:shared-db' - 'vault-mysql-router:shared-db' - - 'vault-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'vault:certificates' - 'keystone:certificates' - - 'vault:certificates' - 'neutron-api:certificates' - - 'vault:certificates' - 'cinder:certificates' - - 'vault:certificates' - 'glance:certificates' - - 'vault:certificates' - 'nova-cloud-controller:certificates' - - 'vault:certificates' - 'masakari:certificates' - - 'placement:shared-db' - 'placement-mysql-router:shared-db' - - 'placement-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'placement:identity-service' - 'keystone:identity-service' - - 'placement:placement' - 'nova-cloud-controller:placement' - - 'vault:certificates' - 'placement:certificates' ",0,418
openstack%2Fcharm-octavia-diskimage-retrofit~master~Icdba21a8865f3cdfd977d08a94386050b6c5a8c4,openstack/charm-octavia-diskimage-retrofit,master,Icdba21a8865f3cdfd977d08a94386050b6c5a8c4,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 22:11:02.000000000,2023-04-14 22:49:29.000000000,2023-04-14 22:49:29.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 22:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia-diskimage-retrofit/commit/a2802401b79e54acd2877a2841a60b7a4b6151fc', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Icdba21a8865f3cdfd977d08a94386050b6c5a8c4\n'}, {'number': 2, 'created': '2023-04-14 15:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia-diskimage-retrofit/commit/8316c06fd1a7e293fbe9b16d3892700d2e2d6be2', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython\n\nChange-Id: Icdba21a8865f3cdfd977d08a94386050b6c5a8c4\n'}, {'number': 3, 'created': '2023-04-14 17:59:14.000000000', 'files': ['charmcraft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-octavia-diskimage-retrofit/commit/598826bac8d2d4d0f9bfbfd0b5a187d6e03c706a', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Add libpython3-dev to allow the charm to be built. This\n  fixes a missing dependency with Cython.\n* Add pkg-config to the charmcraft.yaml for builds. This\n  is required by rust to build cryptography.\n\nChange-Id: Icdba21a8865f3cdfd977d08a94386050b6c5a8c4\n'}]",3,878998,598826bac8d2d4d0f9bfbfd0b5a187d6e03c706a,17,3,3,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Add libpython3-dev to allow the charm to be built. This
  fixes a missing dependency with Cython.
* Add pkg-config to the charmcraft.yaml for builds. This
  is required by rust to build cryptography.

Change-Id: Icdba21a8865f3cdfd977d08a94386050b6c5a8c4
",git fetch https://review.opendev.org/openstack/charm-octavia-diskimage-retrofit refs/changes/98/878998/3 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,a2802401b79e54acd2877a2841a60b7a4b6151fc,antelope-voting,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': applications: mysql-innodb-cluster: constraints: mem=3072M charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge keystone-mysql-router: charm: ch:mysql-router channel: latest/edge glance-mysql-router: charm: ch:mysql-router channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '3' channel: latest/edge glance: charm: ch:glance num_units: 1 options: openstack-origin: *openstack-origin to: - '4' channel: latest/edge glance-simplestreams-sync: charm: ch:glance-simplestreams-sync num_units: 1 options: source: ppa:simplestreams-dev/trunk use_swift: False mirror_list: ""[{url: 'http://cloud-images.ubuntu.com/daily/', name_prefix: 'ubuntu:released', path: 'streams/v1/index.sjson', max: 1, item_filters: [ 'release~(kinetic)', 'arch~(x86_64|amd64)', 'ftype~(disk1.img|disk.img)' ] }]"" # NOTE(coreycb): Drop minimal mirror until https://pad.lv/1933966 # is fixed. # # mirror_list: ""[{url: 'http://cloud-images.ubuntu.com/daily/', # name_prefix: 'ubuntu:released', # path: 'streams/v1/index.sjson', # max: 1, # item_filters: [ # 'release~(xenial|bionic|focal)', # 'arch~(x86_64|amd64)', # 'ftype~(disk1.img|disk.img)' # ] # }, # {url: 'http://cloud-images.ubuntu.com/minimal/daily/', # name_prefix: 'ubuntu:released', # path: 'streams/v1/index.sjson', # max: 1, # item_filters: [ # 'release~(xenial|bionic|focal)', # 'arch~(x86_64|amd64)', # 'ftype~(disk1.img|disk.img)' # ] # }]"" to: - '5' channel: latest/edge octavia-diskimage-retrofit: charm: ../../../octavia-diskimage-retrofit_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm options: retrofit-series: kinetic relations: - - 'glance-simplestreams-sync:juju-info' - 'octavia-diskimage-retrofit:juju-info' - - 'keystone-mysql-router:shared-db' - 'keystone:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'glance-mysql-router:shared-db' - 'glance:shared-db' - - 'glance-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'keystone:identity-service' - 'glance:identity-service' - - 'keystone:identity-service' - 'glance-simplestreams-sync:identity-service' - - 'keystone:identity-credentials' - 'octavia-diskimage-retrofit:identity-credentials' ",0,132
openstack%2Fcharm-glance~master~I9d44ab27409530e4690121e6ab7e3fdfeeda3071,openstack/charm-glance,master,I9d44ab27409530e4690121e6ab7e3fdfeeda3071,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:32.000000000,2023-04-14 22:45:51.000000000,2023-04-14 22:45:51.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/b7a61cf8cb897b37978d2c4c35fa8d6563750c66', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I9d44ab27409530e4690121e6ab7e3fdfeeda3071\n'}, {'number': 2, 'created': '2023-04-14 13:12:51.000000000', 'files': ['charmhelpers/contrib/openstack/deferred_events.py', 'tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/f6212eac8b97244827277701fb9c63b1b9347dc8', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n* Sync charm-helpers to pick up fix for os_requires_version()\n\nChange-Id: I9d44ab27409530e4690121e6ab7e3fdfeeda3071\n'}]",7,878967,f6212eac8b97244827277701fb9c63b1b9347dc8,18,3,2,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed
* Sync charm-helpers to pick up fix for os_requires_version()

Change-Id: I9d44ab27409530e4690121e6ab7e3fdfeeda3071
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/67/878967/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,b7a61cf8cb897b37978d2c4c35fa8d6563750c66,antelope-voting,, - kinetic-zed - kinetic-zed,0,191
openstack%2Fnova~master~I5b5da4748238acda98f29570fa97d09d8aa8df82,openstack/nova,master,I5b5da4748238acda98f29570fa97d09d8aa8df82,Update to the PTL guide,MERGED,2023-02-28 13:59:48.000000000,2023-04-14 21:31:24.000000000,2023-04-14 21:30:17.000000000,"[{'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-02-28 13:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cc22248f6b27be98bc2218da95938fd38e9f675', 'message': 'Update to the PTL guide\n\nWas a bit old, refreshed with more up-to-date information and links.\n\nChange-Id: I5b5da4748238acda98f29570fa97d09d8aa8df82\n'}, {'number': 2, 'created': '2023-02-28 14:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e2d4b59ad4114c275e7b7edd374235d239f9d22', 'message': 'Update to the PTL guide\n\nWas a bit old, refreshed with more up-to-date information and links.\n\nChange-Id: I5b5da4748238acda98f29570fa97d09d8aa8df82\n'}, {'number': 3, 'created': '2023-03-10 12:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccfa78e403ec27f2fb45d330ac9ad8b38f7a6dd1', 'message': 'Update to the PTL guide\n\nWas a bit old, refreshed with more up-to-date information and links.\n\nChange-Id: I5b5da4748238acda98f29570fa97d09d8aa8df82\n'}, {'number': 4, 'created': '2023-04-05 14:43:36.000000000', 'files': ['doc/source/contributor/ptl-guide.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/45b9e966ddf0757a5121a45bce7758aa1ff6cb45', 'message': 'Update to the PTL guide\n\nWas a bit old, refreshed with more up-to-date information and links.\n\nChange-Id: I5b5da4748238acda98f29570fa97d09d8aa8df82\n'}]",13,875730,45b9e966ddf0757a5121a45bce7758aa1ff6cb45,26,4,4,7166,,,0,"Update to the PTL guide

Was a bit old, refreshed with more up-to-date information and links.

Change-Id: I5b5da4748238acda98f29570fa97d09d8aa8df82
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/875730/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/ptl-guide.rst'],1,5cc22248f6b27be98bc2218da95938fd38e9f675,antelope_ptl_guide," * Example: https://releases.openstack.org/antelope/schedule.html * Example: https://etherpad.opendev.org/p/nova-antelope-ptg* Do a retro of the previous cycle * Make agreement on the agenda for this release, including but not exhaustively: * Number of review days, for either specs or implementation * Define the Spec approval and Feature freeze dates * Discuss the implications of the `SLURP or non-SLURP`__ current release .. __: https://governance.openstack.org/tc/resolutions/20220210-release-cadence-adjustment.html* Run the `count-blueprints`__ script daily to gather data for the cycle burndown chart .. __: https://opendev.org/openstack/nova-specs/src/branch/master/tools/count_blueprints.py * Example: https://blueprints.launchpad.net/nova/antelope/+setgoals* Do milestone release of nova and python-novaclient (in launchpad only, can be optional) * placement * os-traits / os-resource-classes* Prepare the operator meet-and-greet session. Enlist help of others * Spec freeze (if agreed) * Release nova and python-novaclient (if new features were merged) (can be optional) * https://etherpad.opendev.org/p/nova-antelope-blueprint-status* Final release for placement * Final release for os-traits * Final release for os-resource-classes* Client library freeze, release python-novaclient and osc-placement* Start writing the `cycle highlights * https://etherpad.opendev.org/p/nova-antelope-rc-potential* Push the cycle-highlights in marketing-friendly sentences and propose to the * Drop old RPC compat code (if there was a RPC major version bump and if agreed on at the PTG) * Bump the oldest supported compute service version (if master branch is now on a non-SLURP version)* Repeat launchpad steps ^ for python-novaclient (optional) * Repeat launchpad steps ^ for placement"," * Example: https://wiki.openstack.org/wiki/Nova/Stein_Release_Schedule * Example: https://etherpad.openstack.org/p/nova-ptg-stein* Have a priorities discussion at the PTG * Example: https://etherpad.openstack.org/p/nova-ptg-stein-priorities* Open review runways for the cycle * Example: https://etherpad.openstack.org/p/nova-runways-stein* Make sure the cycle priorities spec gets reviewed and merged * Example: https://specs.openstack.org/openstack/nova-specs/priorities/stein-priorities.html * Run the count-blueprints script daily to gather data for the cycle burndown chart * Example: https://blueprints.launchpad.net/nova/stein/+setgoals* Do milestone release of nova and python-novaclient (in launchpad only)* Periodically check the series goals others have proposed in the “Set series goals” link: * Example: https://blueprints.launchpad.net/nova/stein/+setgoals * Spec freeze * Release nova and python-novaclient * https://etherpad.openstack.org/p/nova-stein-blueprint-status* Client library freeze, release python-novaclient* Write the `cycle highlights * https://etherpad.openstack.org/p/nova-stein-rc-potential* Write the cycle-highlights in marketing-friendly sentences and propose to the * Drop old RPC compat code (if there was a RPC major version bump) * Bump the oldest supported compute service version* Repeat launchpad steps ^ for python-novaclient* Create new release wiki: * Example: https://wiki.openstack.org/wiki/Nova/Train_Release_Schedule ",39,32
openstack%2Ftempest~master~I39d1c82b03a9a16f3e143f1b5660b7a00dbec92b,openstack/tempest,master,I39d1c82b03a9a16f3e143f1b5660b7a00dbec92b,Run scenario test in parallel in tempest-full-py3 job,ABANDONED,2023-04-13 21:55:10.000000000,2023-04-14 21:17:43.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 21:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/de4bca0d0f7377d6643c4061f607da15aa60e817', 'message': ""Run scenario test in parallel in tempest-full-py3 job\n\nWe made all scenario test to run in serial because of ssh timeout\nissue. There is another job running them in parallel since long is\npassing:\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&skip=0\n\nFailing only 5 times in 3 months:\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&result=FAILURE&skip=0\n\nLet's try to run scenario in parallel in tempest-full-py3 job also and\nif we see more ssh failure due to it we can revert it back\n\nChange-Id: I39d1c82b03a9a16f3e143f1b5660b7a00dbec92b\n""}, {'number': 2, 'created': '2023-04-13 22:08:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4be8aee479fc85762797b64773e1ba0eb5b147e9', 'message': ""Run scenario test in parallel in tempest-full-py3 job\n\nWe made all scenario test to run in serial because of ssh timeout\nissue. There is another job running them in parallel since long is\npassing:\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&skip=0\n\nFailing only 5 times in 3 months:\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&result=FAILURE&skip=0\n\nLet's try to run scenario in parallel in tempest-full-py3 job also and\nif we see more ssh failure due to it we can revert it back\n\nChange-Id: I39d1c82b03a9a16f3e143f1b5660b7a00dbec92b\n""}]",3,880393,4be8aee479fc85762797b64773e1ba0eb5b147e9,9,2,2,8556,,,0,"Run scenario test in parallel in tempest-full-py3 job

We made all scenario test to run in serial because of ssh timeout
issue. There is another job running them in parallel since long is
passing:
- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&skip=0

Failing only 5 times in 3 months:
- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-full-parallel+&result=FAILURE&skip=0

Let's try to run scenario in parallel in tempest-full-py3 job also and
if we see more ssh failure due to it we can revert it back

Change-Id: I39d1c82b03a9a16f3e143f1b5660b7a00dbec92b
",git fetch https://review.opendev.org/openstack/tempest refs/changes/93/880393/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,de4bca0d0f7377d6643c4061f607da15aa60e817,,# tests mentioned in tools/tempest-extra-tests-list.txt and slow tag tests. # tempest/serial_tests run in serial and rest all tests run in parallel:regex1 = (?!.*\[.*\bslow\b.*\])' regex2 = '(?!.*\[.*\bslow\b.*\])(^tempest\.serial_tests)',# tests mentioned in tools/tempest-extra-tests-list.txt and slow tag:regex1 = '(?!.*\[.*\bslow\b.*\])(^tempest\.api)' regex2 = '(?!.*\[.*\bslow\b.*\])(^tempest\.scenario)|(^tempest\.serial_tests)',4,3
openstack%2Fopenstack-ansible-os_heat~master~Id9540fe5f7577ebbc222a1ae303b16338a1f071b,openstack/openstack-ansible-os_heat,master,Id9540fe5f7577ebbc222a1ae303b16338a1f071b,Ensure service is restarted on unit file changes,MERGED,2023-04-10 14:03:28.000000000,2023-04-14 21:17:31.000000000,2023-04-14 21:16:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-10 14:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/b95cdc1342fd9a09503c1f11d851ab2f367c0c3f', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nChange-Id: Id9540fe5f7577ebbc222a1ae303b16338a1f071b\n""}, {'number': 2, 'created': '2023-04-11 08:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/6dc4b2e647d8fc5722db052db02da69a6832ecfa', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-plugins/+/880028\nChange-Id: Id9540fe5f7577ebbc222a1ae303b16338a1f071b\n""}, {'number': 3, 'created': '2023-04-11 11:11:24.000000000', 'files': ['handlers/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/5061ec247c2fce09deb84b798858adbe53dcb488', 'message': ""Ensure service is restarted on unit file changes\n\nAt the moment we don't restart services if systemd unit file is changed.\n\nWe knowingly prevent systemd_service role handlers to execute\nby providing `state: started` as otherwise service will be restarted twice.\nWith that now  we ensure that role handlers will also listen for systemd\nunit changes.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-plugins/+/880028\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/880031\nChange-Id: Id9540fe5f7577ebbc222a1ae303b16338a1f071b\n""}]",1,879963,5061ec247c2fce09deb84b798858adbe53dcb488,14,3,3,28619,,,0,"Ensure service is restarted on unit file changes

At the moment we don't restart services if systemd unit file is changed.

We knowingly prevent systemd_service role handlers to execute
by providing `state: started` as otherwise service will be restarted twice.
With that now  we ensure that role handlers will also listen for systemd
unit changes.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-plugins/+/880028
Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/880031
Change-Id: Id9540fe5f7577ebbc222a1ae303b16338a1f071b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/63/879963/3 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'vars/main.yml']",2,b95cdc1342fd9a09503c1f11d851ab2f367c0c3f,osa/systemd_restart_on_unit_change," 'enabled': value['enabled'] | default(True), 'state': value['state'] | default('started'),"," 'enabled': 'yes', 'state': 'started',",3,3
openstack%2Fbarbican~stable%2F2023.1~I71e199d3f79a788c41b4a5f6237112bceb298491,openstack/barbican,stable/2023.1,I71e199d3f79a788c41b4a5f6237112bceb298491,Stable-only: Remove TripleO job,MERGED,2023-03-17 15:38:34.000000000,2023-04-14 21:06:04.000000000,2023-04-14 21:04:06.000000000,"[{'_account_id': 7973}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-17 15:38:34.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e2bd3b95b9b78b6a2f783700adf40015b11b002e', 'message': 'Stable-only: Remove TripleO job\n\nTripleO does not create 2023.1 (Antelope) release thus the job should\nbe removed from this branch.\n\nChange-Id: I71e199d3f79a788c41b4a5f6237112bceb298491\n'}]",1,877810,e2bd3b95b9b78b6a2f783700adf40015b11b002e,10,3,1,9816,,,0,"Stable-only: Remove TripleO job

TripleO does not create 2023.1 (Antelope) release thus the job should
be removed from this branch.

Change-Id: I71e199d3f79a788c41b4a5f6237112bceb298491
",git fetch https://review.opendev.org/openstack/barbican refs/changes/10/877810/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e2bd3b95b9b78b6a2f783700adf40015b11b002e,remove-tripleo,," # TripleO jobs that deploy Barbican. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - tripleo-ci-centos-9-scenario002-standalone: voting: false",0,7
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I795b2cd2059cd98c2ca74cd54e22ce078276a405,openstack/tripleo-heat-templates,stable/wallaby,I795b2cd2059cd98c2ca74cd54e22ce078276a405,multi-rhel-container-image-prepare.py,MERGED,2023-03-25 10:27:43.000000000,2023-04-14 20:47:51.000000000,2023-04-14 20:47:51.000000000,"[{'_account_id': 6816}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 31245}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-03-25 10:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1dc4c779275523277999cf36847c8ed0f23efa53', 'message': 'multi-rhel-container-image-prepare.py\n\nChange-Id: I795b2cd2059cd98c2ca74cd54e22ce078276a405\n'}, {'number': 2, 'created': '2023-04-05 11:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77a9febca8884bc02e3e92b2874d8dcbc3053715', 'message': 'multi-rhel-container-image-prepare.py\n\nChange-Id: I795b2cd2059cd98c2ca74cd54e22ce078276a405\n(cherry picked from commit 4e227fb89827c319f276ab16a75e158736b4fd03)\n'}, {'number': 3, 'created': '2023-04-14 11:41:26.000000000', 'files': ['tools/multi-rhel-container-image-prepare.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24b0875fe8eb2f965b1c929263e1a545ddfa82f9', 'message': 'multi-rhel-container-image-prepare.py\n\nChange-Id: I795b2cd2059cd98c2ca74cd54e22ce078276a405\n(cherry picked from commit 4e227fb89827c319f276ab16a75e158736b4fd03)\n'}]",8,878590,24b0875fe8eb2f965b1c929263e1a545ddfa82f9,25,9,3,11090,,,0,"multi-rhel-container-image-prepare.py

Change-Id: I795b2cd2059cd98c2ca74cd54e22ce078276a405
(cherry picked from commit 4e227fb89827c319f276ab16a75e158736b4fd03)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/878590/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/multi-rhel-container-image-prepare.py'],1,1dc4c779275523277999cf36847c8ed0f23efa53,multi-rhel-stable/wallaby,"#!/usr/bin/python3 # Copyright 2023 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import argparse import copy import datetime import os import shutil import sys import yaml from io import StringIO from tripleo_common.image import kolla_builder from tripleoclient import utils def parse_opts(argv): parser = argparse.ArgumentParser( description='Tool to help to create the multi-rhel container image file') parser.add_argument( ""--output-env-file"", dest=""output_env_file"", metavar='<file path>', required=True, help=""File to write environment file containing default "" ""ContainerImagePrepare value."", ) parser.add_argument( '--local-push-destination', dest='push_destination', action='store_true', default=False, help='Include a push_destination to trigger upload to a local ' 'registry.' ) parser.add_argument( '--enable-registry-login', dest='registry_login', action='store_true', default=False, help='Use this flag to enable the flag to have systems attempt ' 'to login to a remote registry prior to pulling their ' 'containers. This flag should be used when ' '--local-push-destination is *NOT* used and the target ' 'systems will have network connectivity to the remote ' 'registries. Do not use this for an overcloud that ' 'may not have network connectivity to a remote registry.' ) parser.add_argument( '--enable-multi-rhel', dest='multi_rhel', action='store_true', default=False, help='Use this flag to enable multi-rhel' ) parser.add_argument( '--excludes', dest='excludes', action='append', default=[], help='List of services to include/exclude' ) parser.add_argument( '--major-override', dest='major', action='store', default='{}', help='The override parameters for major release' ) parser.add_argument( '--minor-override', dest='minor', action='store', default='{}', help='The override parameters for minor release' ) parser.add_argument( '--role', dest='roles', action='append', default=[], help='List of roles' ) parser.add_argument( '--role-file', dest='rolefile', action='store', default='', help='role_data.yaml file' ) opts = parser.parse_args(argv[1:]) return opts def build_env_file(params): f = StringIO() f.write('# Generated with the following on %s\n#\n' % datetime.datetime.now().isoformat()) yaml.safe_dump({'parameter_defaults': params}, f, default_flow_style=False, sort_keys=False) return f.getvalue() parsed_args = parse_opts(sys.argv) auth_required = False cip = copy.deepcopy(kolla_builder.CONTAINER_IMAGE_PREPARE_PARAM) if parsed_args.push_destination: for entry in cip: entry['push_destination'] = True params = { 'ContainerImagePrepare': cip } if parsed_args.registry_login: if parsed_args.push_destination: print('[WARNING] --local-push-destination was used ' 'with --enable-registry-login. Please make ' 'sure you understand the use of these ' 'parameters together as they can cause ' 'deployment failures.') print('[NOTE] Make sure to update the paramter_defaults' ' with ContainerImageRegistryCredentials for the ' 'registries requiring authentication.') params['ContainerImageRegistryLogin'] = True if parsed_args.multi_rhel: cip_exc = copy.deepcopy(cip) cip_inc = copy.deepcopy(cip) if parsed_args.major is not None: major = yaml.safe_load(parsed_args.major) if len(parsed_args.excludes) > 0: cip_exc[0]['excludes'] = copy.deepcopy(parsed_args.excludes) cip_inc[0]['includes'] = copy.deepcopy(parsed_args.excludes) if parsed_args.minor is not None: minor = yaml.safe_load(parsed_args.minor) for key in minor.keys(): if key in cip_inc[0]['set'].keys(): cip_inc[0]['set'][key] = minor[key] if parsed_args.major is not None: major = yaml.safe_load(parsed_args.major) for key in major.keys(): if key in cip_exc[0]['set'].keys(): cip_exc[0]['set'][key] = major[key] params_set = params['ContainerImagePrepare'][0]['set'] if key in params_set.keys(): params_set[key] = major[key] base_role = [cip_exc[0], cip_inc[0]] if parsed_args.rolefile != '': read_roles = [] if os.path.exists(parsed_args.rolefile): with open(parsed_args.rolefile) as file: roles_f = yaml.safe_load(file) for role in roles_f: read_roles.append(role['name']) else: print('[ERROR] {} role file does' ' not exits'.format(parsed_args.rolefile)) roles = read_roles else: roles = parsed_args.roles params['MultiRhelRoleContainerImagePrepare'] = base_role for role in roles: params[('{}ContainerImagePrepare').format(role)] = base_role env_data = build_env_file(params) if parsed_args.output_env_file: if os.path.exists(parsed_args.output_env_file): print(""Output env file exists, "" ""moving it to backup."") shutil.move(parsed_args.output_env_file, parsed_args.output_env_file + "".backup"") utils.safe_write(parsed_args.output_env_file, env_data) ",,189,0
openstack%2Fopenstack-manuals~master~I92b31ea587d990622ef044445733b28c20a99b41,openstack/openstack-manuals,master,I92b31ea587d990622ef044445733b28c20a99b41,Retire patrole: remove doc ref,MERGED,2023-04-12 19:12:29.000000000,2023-04-14 20:35:41.000000000,2023-04-14 20:05:06.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-12 19:12:29.000000000', 'files': ['tools/www-generator.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4746e6edf7f62ca7615ef2760c51cc57a7798d90', 'message': 'Retire patrole: remove doc ref\n\npatrole project is not maintained and in QA\nPTG, we decided to retire it.\n\n- https://etherpad.opendev.org/p/qa-bobcat-ptg\n\nDepends-On: https://review.opendev.org/c/openstack/governance/+/880014\nChange-Id: I92b31ea587d990622ef044445733b28c20a99b41\n'}]",4,880228,4746e6edf7f62ca7615ef2760c51cc57a7798d90,15,2,1,8556,,,0,"Retire patrole: remove doc ref

patrole project is not maintained and in QA
PTG, we decided to retire it.

- https://etherpad.opendev.org/p/qa-bobcat-ptg

Depends-On: https://review.opendev.org/c/openstack/governance/+/880014
Change-Id: I92b31ea587d990622ef044445733b28c20a99b41
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/880228/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/www-generator.py'],1,4746e6edf7f62ca7615ef2760c51cc57a7798d90,retire-patrole," 'openstack/patrole',",,1,0
openstack%2Fopenstack-ansible~master~I0d5a92bb06b9a63c3b21b506ae319fd23c53e201,openstack/openstack-ansible,master,I0d5a92bb06b9a63c3b21b506ae319fd23c53e201,docs: Add missing link for legacy compatibility matrix,MERGED,2023-04-14 12:50:27.000000000,2023-04-14 19:24:50.000000000,2023-04-14 19:23:27.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-14 12:50:27.000000000', 'files': ['doc/source/admin/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b7db70a8719e0f2e967f182421060dd519780dc6', 'message': 'docs: Add missing link for legacy compatibility matrix\n\nChange-Id: I0d5a92bb06b9a63c3b21b506ae319fd23c53e201\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",3,880487,b7db70a8719e0f2e967f182421060dd519780dc6,10,3,1,15334,,,0,"docs: Add missing link for legacy compatibility matrix

Change-Id: I0d5a92bb06b9a63c3b21b506ae319fd23c53e201
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/87/880487/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/index.rst'],1,b7db70a8719e0f2e967f182421060dd519780dc6,docs, upgrades/compatibility-matrix-legacy.rst,,1,0
openstack%2Fcharm-rabbitmq-server~stable%2Fjammy~Ic4c2d34ff248d5429eb604824e42dbaba6ca2678,openstack/charm-rabbitmq-server,stable/jammy,Ic4c2d34ff248d5429eb604824e42dbaba6ca2678,Fix typo in configure ttl code,MERGED,2023-04-11 13:07:39.000000000,2023-04-14 18:51:40.000000000,2023-04-14 18:51:40.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-11 13:07:39.000000000', 'files': ['unit_tests/test_rabbit_utils.py', 'hooks/rabbit_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/ba80227067f2268589e0b273ef5f783369fb8c8a', 'message': 'Fix typo in configure ttl code\n\nAlso fixes tox.ini\n\nChange-Id: Ic4c2d34ff248d5429eb604824e42dbaba6ca2678\nCloses-Bug: #1939681\n(cherry picked from commit 8c9f68e8aadc3a6786bf42ca250252fed0eef381)\n'}]",2,880050,ba80227067f2268589e0b273ef5f783369fb8c8a,10,4,1,6737,,,0,"Fix typo in configure ttl code

Also fixes tox.ini

Change-Id: Ic4c2d34ff248d5429eb604824e42dbaba6ca2678
Closes-Bug: #1939681
(cherry picked from commit 8c9f68e8aadc3a6786bf42ca250252fed0eef381)
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/50/880050/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_rabbit_utils.py', 'hooks/rabbit_utils.py']",2,ba80227067f2268589e0b273ef5f783369fb8c8a,bug/1939681," '{ttlreg}'.format(ttlreg=ttlreg),"," '""{ttlreg}""'.format(ttlreg=ttlreg),",2,2
openstack%2Fneutron~master~I63bc80bc790d2caba44287b64be3e0d8722d8f6c,openstack/neutron,master,I63bc80bc790d2caba44287b64be3e0d8722d8f6c,Finish processing the Database table as soon as possible,NEW,2022-09-12 07:14:19.000000000,2023-04-14 18:42:31.000000000,,"[{'_account_id': 9845}, {'_account_id': 22348}, {'_account_id': 32586}]","[{'number': 1, 'created': '2022-09-12 07:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/641821a6a92b05a9b1e178711b210a75a3976b4b', 'message': 'Finish processing the Database table as soon as possible\n\nWhen connecting or reconnecting to the ovsdb database, if there\nis an exception in processing the database (for example, an\nexception in operating the database), it may cause the problem\nthat the data cannot be monitored correctly. see more [1]\nThis patch returns as soon as possible when processing the\nDatabase table to avoid exceptions.\n\nPartial-bug: #1988039\n\n[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039\n\nChange-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c\n'}, {'number': 2, 'created': '2022-09-13 01:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc8cc61e23d612a7ecf591224720502577ff0e79', 'message': 'Finish processing the Database table as soon as possible\n\nWhen connecting or reconnecting to the ovsdb database, if there\nis an exception in processing the database (for example, an\nexception in operating the database), it may cause the problem\nthat the data cannot be monitored correctly. see more [1]\nThis patch returns as soon as possible when processing the\nDatabase table to avoid exceptions.\n\nPartial-bug: #1988039\n\n[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039\n\nChange-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c\n'}, {'number': 3, 'created': '2022-09-13 02:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a5c186139bcd7030d6c83bc26a010d4e621cfe0', 'message': 'Finish processing the Database table as soon as possible\n\nWhen connecting or reconnecting to the ovsdb database, if there\nis an exception in processing the database (for example, an\nexception in operating the database), it may cause the problem\nthat the data cannot be monitored correctly. see more [1]\nThis patch returns as soon as possible when processing the\nDatabase table to avoid exceptions.\n\nPartial-bug: #1988039\n\n[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039\n\nChange-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c\n'}, {'number': 4, 'created': '2022-09-14 01:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d7f9e07658700470046acfa3e1217c63dca2585', 'message': 'Finish processing the Database table as soon as possible\n\nWhen connecting or reconnecting to the ovsdb database, if there\nis an exception in processing the database (for example, an\nexception in operating the database), it may cause the problem\nthat the data cannot be monitored correctly. see more [1]\nThis patch returns as soon as possible when processing the\nDatabase table to avoid exceptions.\n\nPartial-bug: #1988039\n\n[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039\n\nChange-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c\n'}, {'number': 5, 'created': '2023-04-13 14:40:49.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/edc1025a83913fcc4929f036f645826b942bdff7', 'message': 'Finish processing the Database table as soon as possible\n\nWhen connecting or reconnecting to the ovsdb database, if there\nis an exception in processing the database (for example, an\nexception in operating the database), it may cause the problem\nthat the data cannot be monitored correctly. see more [1]\nThis patch returns as soon as possible when processing the\nDatabase table to avoid exceptions.\n\nPartial-bug: #1988039\n\n[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039\n\nChange-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c\n'}]",5,857010,edc1025a83913fcc4929f036f645826b942bdff7,31,3,5,30380,,,0,"Finish processing the Database table as soon as possible

When connecting or reconnecting to the ovsdb database, if there
is an exception in processing the database (for example, an
exception in operating the database), it may cause the problem
that the data cannot be monitored correctly. see more [1]
This patch returns as soon as possible when processing the
Database table to avoid exceptions.

Partial-bug: #1988039

[1] https://bugs.launchpad.net/ovsdbapp/+bug/1988039

Change-Id: I63bc80bc790d2caba44287b64be3e0d8722d8f6c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/857010/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,641821a6a92b05a9b1e178711b210a75a3976b4b,bug/1988039, # Finish processing the database table as soon as possible # see more: https://bugs.launchpad.net/ovsdbapp/+bug/1988039 if row._table.name == 'Database': return,,4,0
openstack%2Fcharm-designate~master~I3f9c253a89906b8f1dde4f60f1fdc30119a8d31c,openstack/charm-designate,master,I3f9c253a89906b8f1dde4f60f1fdc30119a8d31c,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:27.000000000,2023-04-14 18:41:34.000000000,2023-04-14 18:41:34.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:27.000000000', 'files': ['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/b657a63abdb1990ece815805d2d3e1632f66afa4', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: I3f9c253a89906b8f1dde4f60f1fdc30119a8d31c\n'}]",5,878965,b657a63abdb1990ece815805d2d3e1632f66afa4,15,4,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: I3f9c253a89906b8f1dde4f60f1fdc30119a8d31c
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/65/878965/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,b657a63abdb1990ece815805d2d3e1632f66afa4,antelope-voting,,variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': series: focal '8': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge designate-mysql-router: charm: ch:mysql-router channel: latest/edge neutron-api-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 to: - '0' - '1' - '2' channel: latest/edge rabbitmq-server: charm: ch:rabbitmq-server num_units: 1 to: - '3' channel: latest/edge keystone: charm: ch:keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '4' channel: latest/edge neutron-api: charm: ch:neutron-api num_units: 1 options: manage-neutron-plugin-legacy-mode: true openstack-origin: *openstack-origin to: - '5' channel: latest/edge designate-bind: charm: ch:designate-bind num_units: 1 # NOTE(ajkavanagh) apparently it has no openstack origin! #options: #openstack-origin: *openstack-origin to: - '6' channel: latest/edge memcached: charm: ch:memcached num_units: 1 # Note that holding memcached at focal as it's not available at kinetic yet. series: focal to: - '7' designate: charm: ../../../designate_ubuntu-22.04-amd64_ubuntu-22.10-amd64_ubuntu-23.04-amd64.charm num_units: 1 options: nameservers: 'ns1.amuletexample.com. ns2.amuletexample.com.' openstack-origin: *openstack-origin to: - '8' nrpe: charm: ch:nrpe channel: latest/edge relations: - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'designate:shared-db' - 'designate-mysql-router:shared-db' - - 'designate-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'designate:amqp' - 'rabbitmq-server:amqp' - - 'designate:identity-service' - 'keystone:identity-service' - - 'designate:dns-backend' - 'designate-bind:dns-backend' - - 'designate:coordinator-memcached' - 'memcached:cache' - - 'designate:dnsaas' - 'neutron-api:external-dns' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'neutron-api:shared-db' - 'neutron-api-mysql-router:shared-db' - - 'neutron-api-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'designate:nrpe-external-master' - 'nrpe:nrpe-external-master' ,0,141
openstack%2Fgovernance~master~I4ed3ff970049e02f6f9f43ab03a80be9bd87d21f,openstack/governance,master,I4ed3ff970049e02f6f9f43ab03a80be9bd87d21f,Retire patrole,MERGED,2023-04-11 04:55:03.000000000,2023-04-14 18:39:21.000000000,2023-04-14 18:38:21.000000000,"[{'_account_id': 935}, {'_account_id': 5314}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-04-11 04:55:03.000000000', 'files': ['reference/legacy.yaml', 'reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/0f128cc2f63fecf397d9f5a4857786eefced0d09', 'message': 'Retire patrole\n\nPatrole project is not active anymore and its gate is broken.\nWe waited for couple of cycle to see if there is any interest\nin this project and anyone can maintain it. But we did not get any\nnew maintainers and current QA team does not have bandwidth/interest\nto continue maintaining it.\n\nThis project was for RBAc testing which is moving towards unit/functional\ntests on service side as well as tempest plugins tests.\n\nIn QA 2023.2 PTG, we decided to retire this project\n\n- https://etherpad.opendev.org/p/qa-bobcat-ptg\n\nDepends-On: https://review.opendev.org/c/openstack/patrole/+/880012\nChange-Id: I4ed3ff970049e02f6f9f43ab03a80be9bd87d21f\n'}]",1,880014,0f128cc2f63fecf397d9f5a4857786eefced0d09,15,5,1,8556,,,0,"Retire patrole

Patrole project is not active anymore and its gate is broken.
We waited for couple of cycle to see if there is any interest
in this project and anyone can maintain it. But we did not get any
new maintainers and current QA team does not have bandwidth/interest
to continue maintaining it.

This project was for RBAc testing which is moving towards unit/functional
tests on service side as well as tempest plugins tests.

In QA 2023.2 PTG, we decided to retire this project

- https://etherpad.opendev.org/p/qa-bobcat-ptg

Depends-On: https://review.opendev.org/c/openstack/patrole/+/880012
Change-Id: I4ed3ff970049e02f6f9f43ab03a80be9bd87d21f
",git fetch https://review.opendev.org/openstack/governance refs/changes/14/880014/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/legacy.yaml', 'reference/projects.yaml']",2,0f128cc2f63fecf397d9f5a4857786eefced0d09,project-update,, patrole: repos: - openstack/patrole,4,3
openstack%2Fcharm-cinder~master~Ieacd818299773e3ffee55ab3f7f052e2f57dd74a,openstack/charm-cinder,master,Ieacd818299773e3ffee55ab3f7f052e2f57dd74a,Enable jammy-antelope voting and drop kinetic-zed tests,MERGED,2023-03-29 21:11:08.000000000,2023-04-14 18:35:39.000000000,2023-04-14 18:35:39.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-29 21:11:08.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/9246a92b9834d3934e1f950cbeaaa436e8e905e9', 'message': 'Enable jammy-antelope voting and drop kinetic-zed tests\n\n* Voting was turned on for jammy-antelope in the\n  project-template for charm-functional-jobs in zosci-config\n* Voting for jammy-antelope bundles with non-standard names\n  is turned on in individual charms\n* Kinetic-zed bundles/tests are removed\n\nChange-Id: Ieacd818299773e3ffee55ab3f7f052e2f57dd74a\n'}]",5,878955,9246a92b9834d3934e1f950cbeaaa436e8e905e9,14,3,1,11805,,,0,"Enable jammy-antelope voting and drop kinetic-zed tests

* Voting was turned on for jammy-antelope in the
  project-template for charm-functional-jobs in zosci-config
* Voting for jammy-antelope bundles with non-standard names
  is turned on in individual charms
* Kinetic-zed bundles/tests are removed

Change-Id: Ieacd818299773e3ffee55ab3f7f052e2f57dd74a
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/55/878955/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/tests.yaml']",2,9246a92b9834d3934e1f950cbeaaa436e8e905e9,antelope-voting,,- kinetic-zed - kinetic-zed,0,263
openstack%2Fcharm-rabbitmq-server~stable%2Fjammy~I231f6c19a574bb3f337451c98d2f7a8c0bafd65c,openstack/charm-rabbitmq-server,stable/jammy,I231f6c19a574bb3f337451c98d2f7a8c0bafd65c,Pin tox to < 4.0.0,ABANDONED,2023-01-20 20:11:44.000000000,2023-04-14 18:28:51.000000000,,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 20:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/f62035a3a809ade735c538032b0f468485b0ee45', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}, {'number': 2, 'created': '2023-01-24 05:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/7bf18b76faf98ab97dc2fa89b3bd8b2043ffcf4d', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAlso, cherry picked from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d\nby hand.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}, {'number': 3, 'created': '2023-01-24 17:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/2bed4c02b0fe8a04da9a9d48b6c07fe19a1b7b99', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes included in this patch:\n- Cherry-pick from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d\n  by hand.\n- Add bindep.txt to install libffi-dev. This is not needed in the\n  master branch, likely because cffi is no longer in\n  test-requiremetns.txt.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}, {'number': 4, 'created': '2023-01-24 19:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/c00e9f5829738c3842c33c4013e63feac9874e67', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes included in this patch:\n- Cherry-pick from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d\n  by hand.\n- Add bindep.txt to install libffi-dev. This is not needed in the\n  master branch, likely because cffi is no longer in\n  test-requiremetns.txt.\n- Switch charm-tools to 2.8.4 to remove ruamel requirement that\n  doesn't work on Python 3.10.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}, {'number': 5, 'created': '2023-01-24 19:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/25f16e1cc377e251546e77042d4177c673849d2f', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes included in this patch:\n- Cherry-pick from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d\n  by hand.\n- Add bindep.txt to install standard binary dependencies. These\n  appear to no longer be required on master.\n- Switch charm-tools to 2.8.4 to remove ruamel requirement that\n  doesn't work on Python 3.10.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}, {'number': 6, 'created': '2023-02-13 14:28:58.000000000', 'files': ['bindep.txt', 'tests/bundles/focal-yoga.yaml', 'tests/bundles/jammy-yoga.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/c3425ec6625820f517182d1c11c86b08cf9ced1a', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes included in this patch:\n- Cherry-pick from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d\n- Cherry-pick from commit f22bb10257d7948f9222e73ff471c56809d0cd88\n- Add bindep.txt to install standard binary dependencies. These\n  appear to no longer be required on master.\n- Switch charm-tools to 2.8.4 to remove ruamel requirement that\n  doesn't work on Python 3.10.\n\nRelated-Bug: #2002788\nChange-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c\n""}]",13,871373,c3425ec6625820f517182d1c11c86b08cf9ced1a,34,4,6,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Additional changes included in this patch:
- Cherry-pick from commit 24d557ffdc96eddb48da88e6f74fa698b939d62d
- Cherry-pick from commit f22bb10257d7948f9222e73ff471c56809d0cd88
- Add bindep.txt to install standard binary dependencies. These
  appear to no longer be required on master.
- Switch charm-tools to 2.8.4 to remove ruamel requirement that
  doesn't work on Python 3.10.

Related-Bug: #2002788
Change-Id: I231f6c19a574bb3f337451c98d2f7a8c0bafd65c
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/73/871373/6 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f62035a3a809ade735c538032b0f468485b0ee45,pin-tox-jammy, tox < 4.0.0,,1,0
openstack%2Fswift~master~I74a0aac0ac29577026743f87f4b654d85e8fcc80,openstack/swift,master,I74a0aac0ac29577026743f87f4b654d85e8fcc80,ssync: fix decoding of ts_meta when ts_data has offset,MERGED,2023-02-16 18:40:32.000000000,2023-04-14 18:19:19.000000000,2023-04-14 18:18:09.000000000,"[{'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-16 18:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/83d45cd16c6ebafd784e035aa2b7d078c78df44f', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}, {'number': 2, 'created': '2023-02-17 09:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b5bc8d801d118c445141e0024b0cca048aa5a884', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nThe SsyncSender encodes object file timestamps in a compact form and\nthe SsyncReceiver decodes the timestamps and compares them to its\nobject file set.\n\nThe encoding represents the meta file timestamp as a delta from the\ndata file timestamp, NOT INCLUDING the data file timestamp offset.\n\nPreviously, the decoding was erroneously calculating the meta file\ntimestamp as the sum of the delta plus the data file timestamp\nINCLUDING the offset.\n\nFor example, if the SssyncSender has object file timestamps:\n\n  ts_data = t0_1.data\n  ts_meta = t1.data\n\nthen the receiver would erroneously perceive that the sender has:\n\n  ts_data = t0_1.data\n  ts_meta = t1_1.data\n\nAs described in the referenced bug report, this erroneous decoding\ncould cause the SsyncReceiver to request that the SsyncSender sync an\nobject that is already in sync, which results in a 409 Conflict at the\nreceiver. The 409 causes the ssync session to terminate, and the same\nprocess repeats on the next attempt.\n\nCloses-Bug: #2007643\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}, {'number': 3, 'created': '2023-02-24 10:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/412a9548b36375fd7728aea408504eaf31eb0788', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nThe SsyncSender encodes object file timestamps in a compact form and\nthe SsyncReceiver decodes the timestamps and compares them to its\nobject file set.\n\nThe encoding represents the meta file timestamp as a delta from the\ndata file timestamp, NOT INCLUDING the data file timestamp offset.\n\nPreviously, the decoding was erroneously calculating the meta file\ntimestamp as the sum of the delta plus the data file timestamp\nINCLUDING the offset.\n\nFor example, if the SssyncSender has object file timestamps:\n\n  ts_data = t0_1.data\n  ts_meta = t1.data\n\nthen the receiver would erroneously perceive that the sender has:\n\n  ts_data = t0_1.data\n  ts_meta = t1_1.data\n\nAs described in the referenced bug report, this erroneous decoding\ncould cause the SsyncReceiver to request that the SsyncSender sync an\nobject that is already in sync, which results in a 409 Conflict at the\nreceiver. The 409 causes the ssync session to terminate, and the same\nprocess repeats on the next attempt.\n\nCloses-Bug: #2007643\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}, {'number': 4, 'created': '2023-02-24 19:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/156287cc42e24344a6679a002a698e6f6df4a20a', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nThe SsyncSender encodes object file timestamps in a compact form and\nthe SsyncReceiver decodes the timestamps and compares them to its\nobject file set.\n\nThe encoding represents the meta file timestamp as a delta from the\ndata file timestamp, NOT INCLUDING the data file timestamp offset.\n\nPreviously, the decoding was erroneously calculating the meta file\ntimestamp as the sum of the delta plus the data file timestamp\nINCLUDING the offset.\n\nFor example, if the SssyncSender has object file timestamps:\n\n  ts_data = t0_1.data\n  ts_meta = t1.data\n\nthen the receiver would erroneously perceive that the sender has:\n\n  ts_data = t0_1.data\n  ts_meta = t1_1.data\n\nAs described in the referenced bug report, this erroneous decoding\ncould cause the SsyncReceiver to request that the SsyncSender sync an\nobject that is already in sync, which results in a 409 Conflict at the\nreceiver. The 409 causes the ssync session to terminate, and the same\nprocess repeats on the next attempt.\n\nCloses-Bug: #2007643\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}, {'number': 5, 'created': '2023-02-27 11:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c43d64bcb236bb70f3be345c73e9a4c53f0feac1', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nThe SsyncSender encodes object file timestamps in a compact form and\nthe SsyncReceiver decodes the timestamps and compares them to its\nobject file set.\n\nThe encoding represents the meta file timestamp as a delta from the\ndata file timestamp, NOT INCLUDING the data file timestamp offset.\n\nPreviously, the decoding was erroneously calculating the meta file\ntimestamp as the sum of the delta plus the data file timestamp\nINCLUDING the offset.\n\nFor example, if the SssyncSender has object file timestamps:\n\n  ts_data = t0_1.data\n  ts_meta = t1.data\n\nthen the receiver would erroneously perceive that the sender has:\n\n  ts_data = t0_1.data\n  ts_meta = t1_1.data\n\nAs described in the referenced bug report, this erroneous decoding\ncould cause the SsyncReceiver to request that the SsyncSender sync an\nobject that is already in sync, which results in a 409 Conflict at the\nreceiver. The 409 causes the ssync session to terminate, and the same\nprocess repeats on the next attempt.\n\nCloses-Bug: #2007643\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}, {'number': 6, 'created': '2023-02-27 13:27:39.000000000', 'files': ['test/unit/obj/test_ssync_sender.py', 'test/probe/test_object_versioning.py', 'test/unit/obj/test_ssync.py', 'swift/obj/ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2fe18b24cd7e709c8712fcda7369b0715a21fb89', 'message': 'ssync: fix decoding of ts_meta when ts_data has offset\n\nThe SsyncSender encodes object file timestamps in a compact form and\nthe SsyncReceiver decodes the timestamps and compares them to its\nobject file set.\n\nThe encoding represents the meta file timestamp as a delta from the\ndata file timestamp, NOT INCLUDING the data file timestamp offset.\n\nPreviously, the decoding was erroneously calculating the meta file\ntimestamp as the sum of the delta plus the data file timestamp\nINCLUDING the offset.\n\nFor example, if the SssyncSender has object file timestamps:\n\n  ts_data = t0_1.data\n  ts_meta = t1.data\n\nthen the receiver would erroneously perceive that the sender has:\n\n  ts_data = t0_1.data\n  ts_meta = t1_1.data\n\nAs described in the referenced bug report, this erroneous decoding\ncould cause the SsyncReceiver to request that the SsyncSender sync an\nobject that is already in sync, which results in a 409 Conflict at the\nreceiver. The 409 causes the ssync session to terminate, and the same\nprocess repeats on the next attempt.\n\nCloses-Bug: #2007643\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80\n'}]",12,874122,2fe18b24cd7e709c8712fcda7369b0715a21fb89,30,4,6,7847,,,0,"ssync: fix decoding of ts_meta when ts_data has offset

The SsyncSender encodes object file timestamps in a compact form and
the SsyncReceiver decodes the timestamps and compares them to its
object file set.

The encoding represents the meta file timestamp as a delta from the
data file timestamp, NOT INCLUDING the data file timestamp offset.

Previously, the decoding was erroneously calculating the meta file
timestamp as the sum of the delta plus the data file timestamp
INCLUDING the offset.

For example, if the SssyncSender has object file timestamps:

  ts_data = t0_1.data
  ts_meta = t1.data

then the receiver would erroneously perceive that the sender has:

  ts_data = t0_1.data
  ts_meta = t1_1.data

As described in the referenced bug report, this erroneous decoding
could cause the SsyncReceiver to request that the SsyncSender sync an
object that is already in sync, which results in a 409 Conflict at the
receiver. The 409 causes the ssync session to terminate, and the same
process repeats on the next attempt.

Closes-Bug: #2007643
Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
Change-Id: I74a0aac0ac29577026743f87f4b654d85e8fcc80
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/874122/5 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/obj/test_ssync_sender.py', 'test/unit/obj/test_ssync.py', 'swift/obj/ssync_receiver.py']",3,83d45cd16c6ebafd784e035aa2b7d078c78df44f,p-ssync-fix-meta-ts," # ignore ts_data offset when calculating ts_meta result['ts_meta'] = Timestamp(Timestamp(t_data).normal, delta=int(v, 16)) elif k == 't': # ignore ts_data offset when calculating ts_ctype result['ts_ctype'] = Timestamp(Timestamp(t_data).normal, delta=int(v, 16))"," result['ts_meta'] = Timestamp(t_data, delta=int(v, 16)) elif k == 't': result['ts_ctype'] = Timestamp(t_data, delta=int(v, 16))",16,2
openstack%2Fcharm-vault~stable%2F1.5~I18aa6c9193379ea454851b6f60a8f331ef88a980,openstack/charm-vault,stable/1.5,I18aa6c9193379ea454851b6f60a8f331ef88a980,Implement cert cache for vault units (v3),MERGED,2023-03-23 14:31:16.000000000,2023-04-14 18:06:02.000000000,2023-03-31 03:56:00.000000000,"[{'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-23 14:31:16.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/1148004e344c9f64226bfd24fcb4ad6fa63ce001', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n(cherry picked from commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c)\n(cherry picked from commit fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371)\n'}]",0,878420,1148004e344c9f64226bfd24fcb4ad6fa63ce001,9,4,1,14567,,,0,"Implement cert cache for vault units (v3)

This cache is used to store certificates and keys
issued by the leader unit. Non-leader units read
these certificates and keep data in their
""tls-certificates"" relations up to date.
This ensures that charm units that receive certs
from vault can read from relation data of any
vault unit and receive correct data.

This patch is mostly the same as
f55055b8783ca6f3f569209b4f82285377f5ac64
but improved to avoid LP#1983269 by breaking
down the cert cache into separate key-value pairs
for each remote unit and avoiding a race-condition
caused by get-csr action. Instead of using
leader-settings, this patch is now using
application data bag provided by a new vault-ha
relation implementation.

Co-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>

Change-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980
Closes-Bug: #1940549
Closes-Bug: #1983269
Closes-Bug: #1845961
(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)
(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)
(cherry picked from commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c)
(cherry picked from commit fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/20/878420/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,1148004e344c9f64226bfd24fcb4ad6fa63ce001,,"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",from unittest.mock import patch self.patches = [],922,22
openstack%2Fcharm-vault~stable%2F1.6~I18aa6c9193379ea454851b6f60a8f331ef88a980,openstack/charm-vault,stable/1.6,I18aa6c9193379ea454851b6f60a8f331ef88a980,Implement cert cache for vault units (v3),MERGED,2023-03-20 14:18:34.000000000,2023-04-14 18:05:35.000000000,2023-03-31 03:54:43.000000000,"[{'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-20 14:18:34.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n(cherry picked from commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c)\n'}]",0,877961,fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371,9,4,1,14567,,,0,"Implement cert cache for vault units (v3)

This cache is used to store certificates and keys
issued by the leader unit. Non-leader units read
these certificates and keep data in their
""tls-certificates"" relations up to date.
This ensures that charm units that receive certs
from vault can read from relation data of any
vault unit and receive correct data.

This patch is mostly the same as
f55055b8783ca6f3f569209b4f82285377f5ac64
but improved to avoid LP#1983269 by breaking
down the cert cache into separate key-value pairs
for each remote unit and avoiding a race-condition
caused by get-csr action. Instead of using
leader-settings, this patch is now using
application data bag provided by a new vault-ha
relation implementation.

Co-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>

Change-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980
Closes-Bug: #1940549
Closes-Bug: #1983269
Closes-Bug: #1845961
(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)
(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)
(cherry picked from commit acabfa31a7d6dbef20e6a3b5110141dad57cac7c)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/61/877961/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,fd4f7dc95fdf9efb9ba9213a11d0aafc392f9371,,"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",from unittest.mock import patch self.patches = [],922,22
openstack%2Fcharm-vault~stable%2F1.7~I18aa6c9193379ea454851b6f60a8f331ef88a980,openstack/charm-vault,stable/1.7,I18aa6c9193379ea454851b6f60a8f331ef88a980,Implement cert cache for vault units (v3),MERGED,2023-01-24 13:08:46.000000000,2023-04-14 18:05:08.000000000,2023-03-31 03:51:12.000000000,"[{'_account_id': 8992}, {'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 13:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/6ae678f5e072329edaaf91c065ea6a80d7313370', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 2, 'created': '2023-02-17 15:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/ad762cd8f5520f327bd1b62629d4db6b9a69a00f', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 3, 'created': '2023-02-20 13:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/2ae8d9b22962076fa01ee043525eda9dc34b49ce', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nConflicts:\n      charmcraft.yaml: made changes to fix build along with\n      charmcraft 2.1 version update.\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 4, 'created': '2023-02-20 16:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/8e23818a7abe80d0daad651172cae08483ea1b71', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 5, 'created': '2023-02-21 13:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/ab82b228bd4bf6c2b5312fb98e349af4099f9fce', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 6, 'created': '2023-02-23 13:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/e0a4bc63034d5fe226c501471557086ffa62226c', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 7, 'created': '2023-02-23 14:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/681758291ec80a408a3259d5b41cb9345b0b2809', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 8, 'created': '2023-03-13 16:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/cfc55c75750b9a214354a577e9d36cb0450f299e', 'message': '[WIP] Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 9, 'created': '2023-03-13 16:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/5ec2de6125e311e5ea6adb2283f3cf7cf6c04bfb', 'message': '[WIP] Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 10, 'created': '2023-03-13 16:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/4686f99a2b93df28322cd695b2f255cbcc9d5b80', 'message': '[WIP] Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}, {'number': 11, 'created': '2023-03-15 16:29:59.000000000', 'files': ['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/build.lock', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/acabfa31a7d6dbef20e6a3b5110141dad57cac7c', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)\n'}]",3,871601,acabfa31a7d6dbef20e6a3b5110141dad57cac7c,41,4,11,14567,,,0,"Implement cert cache for vault units (v3)

This cache is used to store certificates and keys
issued by the leader unit. Non-leader units read
these certificates and keep data in their
""tls-certificates"" relations up to date.
This ensures that charm units that receive certs
from vault can read from relation data of any
vault unit and receive correct data.

This patch is mostly the same as
f55055b8783ca6f3f569209b4f82285377f5ac64
but improved to avoid LP#1983269 by breaking
down the cert cache into separate key-value pairs
for each remote unit and avoiding a race-condition
caused by get-csr action. Instead of using
leader-settings, this patch is now using
application data bag provided by a new vault-ha
relation implementation.

Co-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>

Change-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980
Closes-Bug: #1940549
Closes-Bug: #1983269
Closes-Bug: #1845961
(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)
(cherry picked from commit 7a8a667a68bdfb1e63a9765fb39badff52ebd694)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/01/871601/8 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,6ae678f5e072329edaaf91c065ea6a80d7313370,,"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",from unittest.mock import patch self.patches = [],916,21
openstack%2Fcharm-vault~stable%2F1.8~I18aa6c9193379ea454851b6f60a8f331ef88a980,openstack/charm-vault,stable/1.8,I18aa6c9193379ea454851b6f60a8f331ef88a980,Implement cert cache for vault units (v3),MERGED,2023-01-23 13:14:32.000000000,2023-04-14 18:04:19.000000000,2023-02-20 16:28:27.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 13:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/e5ff45572adfed2b7ce4973edc1bff1d056f61ff', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n'}, {'number': 2, 'created': '2023-01-24 11:13:39.000000000', 'files': ['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/7a8a667a68bdfb1e63a9765fb39badff52ebd694', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)\n'}]",5,871248,7a8a667a68bdfb1e63a9765fb39badff52ebd694,15,4,2,14567,,,0,"Implement cert cache for vault units (v3)

This cache is used to store certificates and keys
issued by the leader unit. Non-leader units read
these certificates and keep data in their
""tls-certificates"" relations up to date.
This ensures that charm units that receive certs
from vault can read from relation data of any
vault unit and receive correct data.

This patch is mostly the same as
f55055b8783ca6f3f569209b4f82285377f5ac64
but improved to avoid LP#1983269 by breaking
down the cert cache into separate key-value pairs
for each remote unit and avoiding a race-condition
caused by get-csr action. Instead of using
leader-settings, this patch is now using
application data bag provided by a new vault-ha
relation implementation.

Co-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>

Change-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980
Closes-Bug: #1940549
Closes-Bug: #1983269
Closes-Bug: #1845961
(cherry picked from commit 04a237660b0e1aaa8d35f7c110c8f4fa2c38621d)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/48/871248/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py']",6,e5ff45572adfed2b7ce4973edc1bff1d056f61ff,bug/1983269-stable/1.8,"from unittest.mock import call, patch, MagicMock self.patches = [ 'endpoint_from_name', ] def test_get_pki_cache(self): """"""Test retrieving PKI from cache."""""" expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation cluster_relation.get_unit_pki.return_value = expected_pki pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set cluster_relation.get_unit_pki.return_value = {} cluster_relation.get_unit_pki.reset_mock() pki = vault_pki.get_pki_cache('client_unit_0') cluster_relation.get_unit_pki.assert_called_once_with( 'pki_client_unit_0') self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_err(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.side_effect = hvac.exceptions.InvalidPath cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_top_level_cert(self, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # PKI structure initial_pki = {} expected_pki = { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) @patch.object(vault_pki, 'get_pki_cache') def test_update_cert_cache_non_top_level_cert(self, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, client_name) cluster_relation.set_unit_pki.assert_called_once_with( key, expected_pki) def test_remove_unit_from_cache(self): """"""Test removing unit certificates from cache."""""" cluster_relation = MagicMock() self.endpoint_from_name.return_value = cluster_relation vault_pki.remove_unit_from_cache('client_0') key = ""{}_{}"".format(vault_pki.PKI_CACHE_KEY, 'client_0') cluster_relation.set_unit_pki.assert_called_once_with(key, None) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",from unittest.mock import patch self.patches = [],916,22
openstack%2Fcharm-vault~master~I18aa6c9193379ea454851b6f60a8f331ef88a980,openstack/charm-vault,master,I18aa6c9193379ea454851b6f60a8f331ef88a980,Implement cert cache for vault units (v3),MERGED,2022-08-25 20:11:37.000000000,2023-04-14 18:03:42.000000000,2023-01-23 11:13:22.000000000,"[{'_account_id': 935}, {'_account_id': 10058}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-25 20:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/10b751a8a49bbd5d5e8c2425fb6647ec3abe3003', 'message': '[OLD] Implement cert cache for vault units (v2)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is the same as\n1159e547dd755af97d5eab578cdfe90abad93843\nbut improved to avoid LP#1970888\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1970888\n'}, {'number': 2, 'created': '2022-08-25 20:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/1b7cde4b77e9f48a3bcb65dfb312b3db960ddff8', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 3, 'created': '2022-09-05 15:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/8bbd911bd59c582cfc423ea835823dc94b767f5b', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 4, 'created': '2022-09-06 18:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/c5c89da0a097462797aeb6fd1332744e88200901', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 5, 'created': '2022-09-19 19:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/3c690bf525b4b673aecaf2ca16ee307f79b4d2cf', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 6, 'created': '2022-10-07 21:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/d86c4fa5b3c5b331cc2bac32bbfa4a0466d43fef', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 7, 'created': '2022-10-19 17:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/10c125309fa5457610cf802b054625c3fd5c4a12', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\n'}, {'number': 8, 'created': '2022-11-29 21:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/30aec74c9049ecc8389dbe1b42c3a25f4cbd50e6', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-peer\nrelation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n'}, {'number': 9, 'created': '2023-01-11 10:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/93b5382631887b9f40a8d7020a16523b6405ac06', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-peer\nrelation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n'}, {'number': 10, 'created': '2023-01-12 14:51:29.000000000', 'files': ['osci.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'src/layer.yaml', 'unit_tests/test_lib_charm_vault_pki.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/04a237660b0e1aaa8d35f7c110c8f4fa2c38621d', 'message': 'Implement cert cache for vault units (v3)\n\nThis cache is used to store certificates and keys\nissued by the leader unit. Non-leader units read\nthese certificates and keep data in their\n""tls-certificates"" relations up to date.\nThis ensures that charm units that receive certs\nfrom vault can read from relation data of any\nvault unit and receive correct data.\n\nThis patch is mostly the same as\nf55055b8783ca6f3f569209b4f82285377f5ac64\nbut improved to avoid LP#1983269 by breaking\ndown the cert cache into separate key-value pairs\nfor each remote unit and avoiding a race-condition\ncaused by get-csr action. Instead of using\nleader-settings, this patch is now using\napplication data bag provided by a new vault-ha\nrelation implementation.\n\nCo-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>\n\nChange-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980\nCloses-Bug: #1940549\nCloses-Bug: #1983269\nCloses-Bug: #1845961\n'}]",30,854676,04a237660b0e1aaa8d35f7c110c8f4fa2c38621d,77,7,10,14567,,,0,"Implement cert cache for vault units (v3)

This cache is used to store certificates and keys
issued by the leader unit. Non-leader units read
these certificates and keep data in their
""tls-certificates"" relations up to date.
This ensures that charm units that receive certs
from vault can read from relation data of any
vault unit and receive correct data.

This patch is mostly the same as
f55055b8783ca6f3f569209b4f82285377f5ac64
but improved to avoid LP#1983269 by breaking
down the cert cache into separate key-value pairs
for each remote unit and avoiding a race-condition
caused by get-csr action. Instead of using
leader-settings, this patch is now using
application data bag provided by a new vault-ha
relation implementation.

Co-Authored-By: Rodrigo Barbieri <rodrigo.barbieri@canonical.com>

Change-Id: I18aa6c9193379ea454851b6f60a8f331ef88a980
Closes-Bug: #1940549
Closes-Bug: #1983269
Closes-Bug: #1845961
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/76/854676/3 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_reactive_vault_handlers.py', 'src/lib/charm/vault_pki.py', 'src/reactive/vault_handlers.py', 'unit_tests/test_lib_charm_vault_pki.py']",4,10b751a8a49bbd5d5e8c2425fb6647ec3abe3003,bug/1983269,"from unittest.mock import call, patch, MagicMockimport json @patch.object(vault_pki.hookenv, 'leader_get') def test_get_pki_cache(self, leader_get): """"""Test retrieving PKI from cache."""""" expected_pki = { ""client_unit_0"": { vault_pki.TOP_LEVEL_CERT_KEY: { ""client_unit_0.server.cert"": ""cert_data"", ""client_unit_0.server.key"": ""key_data"", } } } leader_get.return_value = json.dumps(expected_pki) pki = vault_pki.get_pki_cache() self.assertEqual(pki, expected_pki) # test retrieval if the PKI is not set leader_get.return_value = None pki = vault_pki.get_pki_cache() self.assertEqual(pki, {}) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_no_ca(self, get_ca, get_chain, get_pki_cache): """"""Test getting cert from cache when CA is missing."""""" get_ca.return_value = None get_chain.return_value = None cert, key = vault_pki.find_cert_in_cache(MagicMock()) # assert that CA cert or chain was retrieved get_ca.assert_called_once_with() get_chain.assert_called_once_with() # assert that function does not proceed due to the missing CA get_pki_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_missing(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test use case when searched certificate is not in cache."""""" request = MagicMock() request.unit_name = ""client_unit_0"" request._is_top_level_server_cert = True get_ca.return_value = MagicMock() get_pki_cache.return_value = {} cert, key = vault_pki.find_cert_in_cache(request) # assert that verification of cert is not attempted when # cert is not found verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) # Same scenario, but with non-top-level certificate request._is_top_level_server_cert = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_not_called() self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI cache content pki = { client_name: { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: expected_cert, key_name: expected_key } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'verify_cert') @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki, 'get_chain') @patch.object(vault_pki, 'get_ca') def test_find_cert_in_cache_not_top_level(self, get_ca, get_chain, get_pki_cache, verify_cache): """"""Test fetching non-top level cert from cache. Additional test scenario: Test that nothing is returned if cert fails CA verification. """""" ca_cert = ""CA cert data"" expected_cert = ""cert data"" expected_key = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI cache content pki = { client_name: { publish_key: { common_name: { ""cert"": expected_cert, ""key"": expected_key, } } } } get_ca.return_value = ca_cert get_chain.return_value = ca_cert get_pki_cache.return_value = pki verify_cache.return_value = True cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertEqual(cert, expected_cert) self.assertEqual(key, expected_key) # Additional test: Nothing should be returned if cert failed # CA verification. verify_cache.reset_mock() verify_cache.return_value = False cert, key = vault_pki.find_cert_in_cache(request) verify_cache.assert_called_once_with(ca_cert, expected_cert) self.assertIsNone(cert) self.assertIsNone(key) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki.hookenv, 'leader_set') def test_update_cert_cache_top_level_cert(self, leader_set, get_pki_cache): """"""Test storing top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" cert_name = ""server.cert"" key_name = ""server.key"" client_name = ""client_unit_0"" # setup cert request request = MagicMock() request.unit_name = client_name request.common_name = client_name request._is_top_level_server_cert = True request._server_cert_key = cert_name request._server_key_key = key_name # PKI structure initial_pki = {} expected_pki = { client_name: { vault_pki.TOP_LEVEL_CERT_KEY: { cert_name: cert_data, key_name: key_data } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) leader_set.assert_called_once_with( {vault_pki.PKI_CACHE_KEY: json.dumps(expected_pki)} ) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki.hookenv, 'leader_set') def test_update_cert_cache_non_top_level_cert(self, leader_set, get_pki_cache): """"""Test storing non-top-level cert in cache."""""" cert_data = ""cert data"" key_data = ""key data"" client_name = ""client_unit_0"" publish_key = client_name + "".processed_client_requests"" common_name = ""client.0"" # setup cert request request = MagicMock() request.unit_name = client_name request._is_top_level_server_cert = False request._publish_key = publish_key request.common_name = common_name # PKI structure initial_pki = {} expected_pki = { client_name: { publish_key: { common_name: { ""cert"": cert_data, ""key"": key_data, } } } } get_pki_cache.return_value = initial_pki vault_pki.update_cert_cache(request, cert_data, key_data) leader_set.assert_called_once_with( {vault_pki.PKI_CACHE_KEY: json.dumps(expected_pki)} ) @patch.object(vault_pki, 'get_pki_cache') @patch.object(vault_pki.hookenv, 'leader_set') def test_remove_unit_from_cache(self, leader_set, get_pki_cache): """"""Test removing unit certificates from cache."""""" remaining_unit = ""client/0"" removed_unit = ""client/1"" pki = { remaining_unit: ""Unit certificates"", removed_unit: ""Unit certificates"", } expected_pki = { remaining_unit: ""Unit certificates"" } get_pki_cache.return_value = pki vault_pki.remove_unit_from_cache(removed_unit) leader_set.assert_called_once_with( {vault_pki.PKI_CACHE_KEY: json.dumps(expected_pki)} ) @patch.object(vault_pki, 'update_cert_cache') def test_populate_cert_cache(self, update_cert_cache): # Define data for top level certificate and key top_level_cert_name = ""server.crt"" top_level_key_name = ""server.key"" top_level_cert_data = ""top level cert"" top_level_key_data = ""top level key"" # Define data for non-top level certificate processed_request_cn = ""juju_unit_service.crt"" processed_request_publish_key = ""juju_unit_service.processed"" processed_cert_data = ""processed cert"" processed_key_data = ""processed key"" # Mock request for top level certificate top_level_request = MagicMock() top_level_request._is_top_level_server_cert = True top_level_request._server_cert_key = top_level_cert_name top_level_request._server_key_key = top_level_key_name top_level_request._unit.relation.to_publish_raw = { top_level_cert_name: top_level_cert_data, top_level_key_name: top_level_key_data, } # Mock request for non-top level certificate processed_request = MagicMock() processed_request._is_top_level_server_cert = False processed_request.common_name = processed_request_cn processed_request._publish_key = processed_request_publish_key processed_request._unit.relation.to_publish = { processed_request_publish_key: {processed_request_cn: { ""cert"": processed_cert_data, ""key"": processed_key_data }} } tls_endpoint = MagicMock() tls_endpoint.all_requests = [top_level_request, processed_request] vault_pki.populate_cert_cache(tls_endpoint) expected_update_calls = [ call(top_level_request, top_level_cert_data, top_level_key_data), call(processed_request, processed_cert_data, processed_key_data), ] update_cert_cache.assert_has_calls(expected_update_calls)",from unittest.mock import patch,799,22
openstack%2Ftripleo-common~stable%2Fwallaby~I31ad762f264e5df2d3460d3da22a9dbc3d4ef1a8,openstack/tripleo-common,stable/wallaby,I31ad762f264e5df2d3460d3da22a9dbc3d4ef1a8,Remove container-tools module setting,MERGED,2023-04-11 13:46:49.000000000,2023-04-14 17:38:40.000000000,2023-04-14 17:37:47.000000000,"[{'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-11 13:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/67a43695890c92c5633adfde0d09f04c369a03b1', 'message': 'Remove container-tools module setting\n\nFrom stable/wallaby onwards, we use the default module\nfor container-tools (rhel). This is crucial for both\nel8 & el9 containers to work on el8 hosts.\n\n(cherry-picked from commit 4fdf01214a5d6d2fca0007ce90d760d7e72fda54)\nChange-Id: I31ad762f264e5df2d3460d3da22a9dbc3d4ef1a8\n'}, {'number': 2, 'created': '2023-04-14 05:42:49.000000000', 'files': ['container-images/tcib/base/base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4004ff6d80dfb51a3138600684f4ef93ede941db', 'message': 'Remove container-tools module setting\n\nFrom stable/wallaby onwards, we use the default module\nfor container-tools (rhel). This is crucial for both\nel8 & el9 containers to work on el8 hosts.\n\nChange-Id: I31ad762f264e5df2d3460d3da22a9dbc3d4ef1a8\n'}]",2,879865,4004ff6d80dfb51a3138600684f4ef93ede941db,11,4,2,8449,,,0,"Remove container-tools module setting

From stable/wallaby onwards, we use the default module
for container-tools (rhel). This is crucial for both
el8 & el9 containers to work on el8 hosts.

Change-Id: I31ad762f264e5df2d3460d3da22a9dbc3d4ef1a8
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/65/879865/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/base.yaml'],1,67a43695890c92c5633adfde0d09f04c369a03b1,,, - disable: container-tools:rhel8 - enable: container-tools:{{ tcib_rhel_modules['container-tools'] | default('3.0') }},0,2
openstack%2Fansible-role-collect-logs~master~I42b807b03ee79e3f3c8317dfc840cb18ff344e4b,openstack/ansible-role-collect-logs,master,I42b807b03ee79e3f3c8317dfc840cb18ff344e4b,Fix elinter isort,MERGED,2023-04-14 11:03:28.000000000,2023-04-14 17:37:50.000000000,2023-04-14 17:37:50.000000000,"[{'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 11:03:28.000000000', 'files': ['setup.cfg', '.pre-commit-config.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/61ec0ed103283c374b0d91a2411703652bb1dfee', 'message': 'Fix elinter isort\n\nPoetry got a new linter rule for pipfile,\nwhich was not followed by isort,\nisort stopped supporting old python, but\nstill released a fix for the stable branch for newer.\n\nThe black checker also show some issue,\nwhich is not visible with current fedora37,\nJust disabling it for now.\n\nChange-Id: I42b807b03ee79e3f3c8317dfc840cb18ff344e4b\n'}]",0,880480,61ec0ed103283c374b0d91a2411703652bb1dfee,6,2,1,5803,,,0,"Fix elinter isort

Poetry got a new linter rule for pipfile,
which was not followed by isort,
isort stopped supporting old python, but
still released a fix for the stable branch for newer.

The black checker also show some issue,
which is not visible with current fedora37,
Just disabling it for now.

Change-Id: I42b807b03ee79e3f3c8317dfc840cb18ff344e4b
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/80/880480/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', '.pre-commit-config.yaml']",2,61ec0ed103283c374b0d91a2411703652bb1dfee,isort, rev: 5.11.5, rev: 5.9.3,2,2
openstack%2Fswift~master~I24015b8becc7289a7d72f9a5863d201e27bcc955,openstack/swift,master,I24015b8becc7289a7d72f9a5863d201e27bcc955,InternalClient: error if allow_modify_pipeline is True,MERGED,2023-04-14 09:50:16.000000000,2023-04-14 17:32:54.000000000,2023-04-14 17:30:54.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-14 09:50:16.000000000', 'files': ['test/unit/common/test_internal_client.py', 'swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bbf9687b717be182ec90139e4fc132a58b6c0a7d', 'message': 'InternalClient: error if allow_modify_pipeline is True\n\nallow_modify_pipeline is no longer supported, but if a caller is still\nsetting it to True then raise ValueError, because the InternalClient\ninstance will no longer behave in the way the caller previously\nexpected.\n\nChange-Id: I24015b8becc7289a7d72f9a5863d201e27bcc955\n'}]",1,880474,bbf9687b717be182ec90139e4fc132a58b6c0a7d,11,2,1,7847,,,0,"InternalClient: error if allow_modify_pipeline is True

allow_modify_pipeline is no longer supported, but if a caller is still
setting it to True then raise ValueError, because the InternalClient
instance will no longer behave in the way the caller previously
expected.

Change-Id: I24015b8becc7289a7d72f9a5863d201e27bcc955
",git fetch https://review.opendev.org/openstack/swift refs/changes/74/880474/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_internal_client.py', 'swift/common/internal_client.py']",2,bbf9687b717be182ec90139e4fc132a58b6c0a7d,iter_shard_range_internal_client_2," if kwargs.get('allow_modify_pipeline'): raise ValueError(""'allow_modify_pipeline' is no longer supported"")",,23,0
openstack%2Fswift~master~Idcca7ac0796935c8883de9084d612d64159d9f92,openstack/swift,master,Idcca7ac0796935c8883de9084d612d64159d9f92,internal_client: Remove allow_modify_pipeline option,MERGED,2023-03-31 06:04:14.000000000,2023-04-14 17:31:55.000000000,2023-04-14 17:30:51.000000000,"[{'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-31 06:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/72386170d94b036117d52745a172653b27e055b7', 'message': ""ic: Remove allow_modify_pipeline option and check for gatekeeper\n\nThe internal client is suppose to be internal to the cluster, and as\nsuch we rely on it to not remove any headers we decide to send. However\nif the allow_modify_pipeline option is set the gatekeeper middleware is\nadded to the internal client's proxy pipeline.\n\nSo firstly, this patch remove the allow_modify_pipeline option from the\ninternal client constructor. And when calling loadapp\nallow_modify_pipeline is always passed with a False.\n\nFurther, an op could directly put the gatekeeper middleware into the\ninternal client config. The internal client constructor will now check\nthe pipeline and raise a ValueError if one has been placed in the\npipeline.\n\nTo do this, there is now a is_gatekeeper_loaded staticmethod that will\nwalk the pipeline which called from the InternalClient.__init__ method.\n\nChange-Id: Idcca7ac0796935c8883de9084d612d64159d9f92\n""}, {'number': 2, 'created': '2023-04-04 01:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3a55fe1b4733c9a92d2a6ea115589bfde1980fba', 'message': ""internal_client: Remove allow_modify_pipeline option\n\nThe internal client is suppose to be internal to the cluster, and as\nsuch we rely on it to not remove any headers we decide to send. However\nif the allow_modify_pipeline option is set the gatekeeper middleware is\nadded to the internal client's proxy pipeline.\n\nSo firstly, this patch remove the allow_modify_pipeline option from the\ninternal client constructor. And when calling loadapp\nallow_modify_pipeline is always passed with a False.\n\nFurther, an op could directly put the gatekeeper middleware into the\ninternal client config. The internal client constructor will now check\nthe pipeline and raise a ValueError if one has been placed in the\npipeline.\n\nTo do this, there is now a is_gatekeeper_loaded staticmethod that will\nwalk the pipeline which called from the InternalClient.__init__ method.\n\nChange-Id: Idcca7ac0796935c8883de9084d612d64159d9f92\n""}, {'number': 3, 'created': '2023-04-14 06:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1f5d3bdf615b6b2827a9031f343ca4f4486c67dd', 'message': ""internal_client: Remove allow_modify_pipeline option\n\nThe internal client is suppose to be internal to the cluster, and as\nsuch we rely on it to not remove any headers we decide to send. However\nif the allow_modify_pipeline option is set the gatekeeper middleware is\nadded to the internal client's proxy pipeline.\n\nSo firstly, this patch removes the allow_modify_pipeline option from the\ninternal client constructor. And when calling loadapp\nallow_modify_pipeline is always passed with a False.\n\nFurther, an op could directly put the gatekeeper middleware into the\ninternal client config. The internal client constructor will now check\nthe pipeline and raise a ValueError if one has been placed in the\npipeline.\n\nTo do this, there is now a check_gatekeeper_loaded staticmethod that will\nwalk the pipeline which called from the InternalClient.__init__ method.\nEnabling this walking through the pipeline, we are now stashing the wsgi\npipeline in each filter so that we don't have to rely on 'app' naming\nconventions to iterate the pipeline.\n\nChange-Id: Idcca7ac0796935c8883de9084d612d64159d9f92\n""}, {'number': 4, 'created': '2023-04-14 06:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fb37ad742b0712f47292185c235c4453b5886d61', 'message': ""internal_client: Remove allow_modify_pipeline option\n\nThe internal client is suppose to be internal to the cluster, and as\nsuch we rely on it to not remove any headers we decide to send. However\nif the allow_modify_pipeline option is set the gatekeeper middleware is\nadded to the internal client's proxy pipeline.\n\nSo firstly, this patch removes the allow_modify_pipeline option from the\ninternal client constructor. And when calling loadapp\nallow_modify_pipeline is always passed with a False.\n\nFurther, an op could directly put the gatekeeper middleware into the\ninternal client config. The internal client constructor will now check\nthe pipeline and raise a ValueError if one has been placed in the\npipeline.\n\nTo do this, there is now a check_gatekeeper_loaded staticmethod that will\nwalk the pipeline which called from the InternalClient.__init__ method.\nEnabling this walking through the pipeline, we are now stashing the wsgi\npipeline in each filter so that we don't have to rely on 'app' naming\nconventions to iterate the pipeline.\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: Idcca7ac0796935c8883de9084d612d64159d9f92\n""}, {'number': 5, 'created': '2023-04-14 09:37:49.000000000', 'files': ['test/unit/common/test_internal_client.py', 'etc/internal-client.conf-sample', 'test/unit/container/test_sharder.py', 'swift/container/sharder.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py', 'swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e5105ffa09f7919cf27fa9f70aecbc98e53536aa', 'message': ""internal_client: Remove allow_modify_pipeline option\n\nThe internal client is suppose to be internal to the cluster, and as\nsuch we rely on it to not remove any headers we decide to send. However\nif the allow_modify_pipeline option is set the gatekeeper middleware is\nadded to the internal client's proxy pipeline.\n\nSo firstly, this patch removes the allow_modify_pipeline option from the\ninternal client constructor. And when calling loadapp\nallow_modify_pipeline is always passed with a False.\n\nFurther, an op could directly put the gatekeeper middleware into the\ninternal client config. The internal client constructor will now check\nthe pipeline and raise a ValueError if one has been placed in the\npipeline.\n\nTo do this, there is now a check_gatekeeper_loaded staticmethod that will\nwalk the pipeline which called from the InternalClient.__init__ method.\nEnabling this walking through the pipeline, we are now stashing the wsgi\npipeline in each filter so that we don't have to rely on 'app' naming\nconventions to iterate the pipeline.\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: Idcca7ac0796935c8883de9084d612d64159d9f92\n""}]",22,879128,e5105ffa09f7919cf27fa9f70aecbc98e53536aa,25,3,5,7233,,,0,"internal_client: Remove allow_modify_pipeline option

The internal client is suppose to be internal to the cluster, and as
such we rely on it to not remove any headers we decide to send. However
if the allow_modify_pipeline option is set the gatekeeper middleware is
added to the internal client's proxy pipeline.

So firstly, this patch removes the allow_modify_pipeline option from the
internal client constructor. And when calling loadapp
allow_modify_pipeline is always passed with a False.

Further, an op could directly put the gatekeeper middleware into the
internal client config. The internal client constructor will now check
the pipeline and raise a ValueError if one has been placed in the
pipeline.

To do this, there is now a check_gatekeeper_loaded staticmethod that will
walk the pipeline which called from the InternalClient.__init__ method.
Enabling this walking through the pipeline, we are now stashing the wsgi
pipeline in each filter so that we don't have to rely on 'app' naming
conventions to iterate the pipeline.

Co-Authored-By: Alistair Coles <alistairncoles@gmail.com>
Change-Id: Idcca7ac0796935c8883de9084d612d64159d9f92
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/879128/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_internal_client.py', 'test/unit/container/test_sharder.py', 'swift/container/sharder.py', 'swift/common/internal_client.py']",4,72386170d94b036117d52745a172653b27e055b7,iter_shard_range_internal_client_2," :param use_replication_network: Force the client to use the replication network over the cluster. use_replication_network=False, global_conf=None, app=None): # Internal clients don't use the gatekeeper and the pipeline remains # static so we never allow anything to modify the proxy pipeline. allow_modify_pipeline=False,) if self.is_gatekeeper_loaded(self.app): raise ValueError( ""Gatekeeper middleware is not allowed in the "" ""internalclient proxy pipeline"") @staticmethod def is_gatekeeper_loaded(app): def check_app(app): if app.__class__.__name__ == 'GatekeeperMiddleware': return True elif hasattr(app, 'app'): return check_app(app.app) return False return check_app(app) "," allow_modify_pipeline=False, use_replication_network=False, global_conf=None, app=None): allow_modify_pipeline=allow_modify_pipeline,)",70,8
openstack%2Fwhitebox-tempest-plugin~master~Id24df279177b8575b68c830d9282bd8a00713aa8,openstack/whitebox-tempest-plugin,master,Id24df279177b8575b68c830d9282bd8a00713aa8,Add vdpa base movement tests,MERGED,2023-01-23 15:55:52.000000000,2023-04-14 17:26:00.000000000,2023-04-14 17:26:00.000000000,"[{'_account_id': 8864}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 15:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/f35c94c25c3190c646b50a2749da0d8c26b34483', 'message': 'Add vdpa base movement tests\n\nAdd vdpa movement tests resize and cold migration to test_vdpa test\nsutie.\n\nDepends-on: https://review.opendev.org/c/openstack/whitebox-tempest-plugin/+/822354\n\nChange-Id: Id24df279177b8575b68c830d9282bd8a00713aa8\n'}, {'number': 2, 'created': '2023-04-05 21:11:25.000000000', 'files': ['whitebox_tempest_plugin/api/compute/test_vgpu.py', 'whitebox_tempest_plugin/api/compute/test_vdpa.py', 'whitebox_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/f31b8d85b661a6b0f200511e915e3c1ada2a83e8', 'message': 'Add vdpa base movement tests\n\nAdd vdpa movement tests resize and cold migration to test_vdpa test\nsutie.\n\nDepends-on: https://review.opendev.org/c/openstack/whitebox-tempest-plugin/+/822354\n\nChange-Id: Id24df279177b8575b68c830d9282bd8a00713aa8\n'}]",15,871510,f31b8d85b661a6b0f200511e915e3c1ada2a83e8,16,3,2,31033,,,0,"Add vdpa base movement tests

Add vdpa movement tests resize and cold migration to test_vdpa test
sutie.

Depends-on: https://review.opendev.org/c/openstack/whitebox-tempest-plugin/+/822354

Change-Id: Id24df279177b8575b68c830d9282bd8a00713aa8
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/10/871510/1 && git format-patch -1 --stdout FETCH_HEAD,"['whitebox_tempest_plugin/api/compute/test_vdpa.py', 'whitebox_tempest_plugin/config.py']",2,f35c94c25c3190c646b50a2749da0d8c26b34483,add_vdpa_tests," 'CUSTOM_NVIDIA_11:nvidia-319,CUSTOM_NVIDIA_12:nvidia-320'), cfg.BoolOpt( 'vdpa_cold_migration_supported', default=False, help='Cold migration and resize supported for guest instances ' 'with vDPA ports'),"," 'CUSTOM_NVIDIA_11:nvidia-319,CUSTOM_NVIDIA_12:nvidia-320')",166,1
openstack%2Fhorizon~stable%2Ftrain~I60788061d17a5529440ec1e3d6d5c11f5259d2e8,openstack/horizon,stable/train,I60788061d17a5529440ec1e3d6d5c11f5259d2e8,Fix tooltips and popovers for flavor details on the instance list.,MERGED,2023-02-09 00:37:58.000000000,2023-04-14 16:54:38.000000000,2023-04-14 16:53:37.000000000,"[{'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-09 00:37:58.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/45d155da87cf4647924f45cc01a98a0cd703cd77', 'message': ""Fix tooltips and popovers for flavor details on the instance list.\n\nDue to some changes in bootstrap, the popup table for\nflavor details content is empty, on the instance list pages.\nThis patch adds 'sanitize:false' which fix the issue.\nFor more info. please refer[1].\n\n[1] https://github.com/twbs/bootstrap/issues/28290\n\nCloses-Bug: #1886025\n\nChange-Id: I60788061d17a5529440ec1e3d6d5c11f5259d2e8\n(cherry picked from commit 25816bd82433cae6cb9ec14a38c065cd435692ca)\n(cherry picked from commit 3e5849fbb94785b24ceb14e653645e1db4d38d40)\n""}]",2,873135,45d155da87cf4647924f45cc01a98a0cd703cd77,10,3,1,32114,,,0,"Fix tooltips and popovers for flavor details on the instance list.

Due to some changes in bootstrap, the popup table for
flavor details content is empty, on the instance list pages.
This patch adds 'sanitize:false' which fix the issue.
For more info. please refer[1].

[1] https://github.com/twbs/bootstrap/issues/28290

Closes-Bug: #1886025

Change-Id: I60788061d17a5529440ec1e3d6d5c11f5259d2e8
(cherry picked from commit 25816bd82433cae6cb9ec14a38c065cd435692ca)
(cherry picked from commit 3e5849fbb94785b24ceb14e653645e1db4d38d40)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/873135/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html'],1,45d155da87cf4647924f45cc01a98a0cd703cd77,bug/1886025-stable/ussuri-stable/train," $flavor.popover({html:true, sanitize: false, trigger: ""hover""});"," $flavor.popover({html:true, trigger: ""hover""});",1,1
openstack%2Fovsdbapp~master~I6b946ef27b38e76fd70d2b529d645f5f09ac2404,openstack/ovsdbapp,master,I6b946ef27b38e76fd70d2b529d645f5f09ac2404,Add Interface paramteres to ``OvsdbIdl.add_port`` method.,MERGED,2023-02-13 14:28:47.000000000,2023-04-14 16:51:09.000000000,2023-04-14 16:50:08.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-02-13 14:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/71208c2d5310525db1b6b2f57c59cea063730343', 'message': 'Add Interface paramteres to ``OvsdbIdl.add_port`` method.\n\nNow it is possible to define the ""Interface"" parameters when creating\na ""Port"" register (a ""Interface"" register is created along with any\nnew ""Port"").\n\nRelated-Bug: #2006603\nChange-Id: I6b946ef27b38e76fd70d2b529d645f5f09ac2404\n'}, {'number': 2, 'created': '2023-02-17 08:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/2f1591696019665a0ee6e6bb7afff18edc97e603', 'message': 'Add Interface paramteres to ``OvsdbIdl.add_port`` method.\n\nNow it is possible to define the ""Interface"" parameters when creating\na ""Port"" register (a ""Interface"" register is created along with any\nnew ""Port"").\n\nRelated-Bug: #2006603\nChange-Id: I6b946ef27b38e76fd70d2b529d645f5f09ac2404\n'}, {'number': 3, 'created': '2023-04-14 13:49:16.000000000', 'files': ['ovsdbapp/schema/open_vswitch/impl_idl.py', 'ovsdbapp/tests/functional/schema/open_vswitch/test_impl_idl.py', 'ovsdbapp/schema/open_vswitch/api.py', 'ovsdbapp/schema/open_vswitch/commands.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/ab6682e3f6bc41a630beaa828861d4ae25d55909', 'message': 'Add Interface paramteres to ``OvsdbIdl.add_port`` method.\n\nNow it is possible to define the ""Interface"" parameters when creating\na ""Port"" register (a ""Interface"" register is created along with any\nnew ""Port"").\n\nRelated-Bug: #2006603\nChange-Id: I6b946ef27b38e76fd70d2b529d645f5f09ac2404\n'}]",12,873566,ab6682e3f6bc41a630beaa828861d4ae25d55909,23,6,3,16688,,,0,"Add Interface paramteres to ``OvsdbIdl.add_port`` method.

Now it is possible to define the ""Interface"" parameters when creating
a ""Port"" register (a ""Interface"" register is created along with any
new ""Port"").

Related-Bug: #2006603
Change-Id: I6b946ef27b38e76fd70d2b529d645f5f09ac2404
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/66/873566/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovsdbapp/schema/open_vswitch/impl_idl.py', 'ovsdbapp/tests/functional/schema/open_vswitch/test_impl_idl.py', 'ovsdbapp/schema/open_vswitch/api.py', 'ovsdbapp/schema/open_vswitch/commands.py']",4,71208c2d5310525db1b6b2f57c59cea063730343,bug/2006603," def __init__(self, api, bridge, port, may_exist, **interface_attrs): self.interface_attrs = interface_attrs for k, v in self.interface_attrs.items(): setattr(iface, k, v) "," def __init__(self, api, bridge, port, may_exist):",26,7
openstack%2Fneutron~master~I164a13156f02be6a8bf4eaa53c4b670b2481bc46,openstack/neutron,master,I164a13156f02be6a8bf4eaa53c4b670b2481bc46,[DNM] Validate ovn grenade fix,NEW,2023-03-28 11:29:27.000000000,2023-04-14 16:06:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-28 11:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/926c7a765e00fca0545553b3854d4ec2eac7de4d', 'message': '[DNM] Test 878759\n\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}, {'number': 2, 'created': '2023-03-28 11:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45067e7827c9032596d73f5318f6d72a192e1266', 'message': '[DNM] Test 878759\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/878759/\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}, {'number': 3, 'created': '2023-03-28 12:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d9c0d81eb4c7d7a40f82ffe1658e04874d6d8da', 'message': '[DNM] Test 878759\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/878662/\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/878759/\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}, {'number': 4, 'created': '2023-04-12 08:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e2eaa07731b0313eea1d73842b7c14152cbcec8', 'message': '[DNM] debug ovn skip level\n\nRelated-Bug: #2015364\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}, {'number': 5, 'created': '2023-04-14 11:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9c515d7c7cdce0427cc5fc68dfb05989f0c4871', 'message': '[DNM] debug ovn skip level\n\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/880481\nRelated-Bug: #2015364\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}, {'number': 6, 'created': '2023-04-14 14:43:47.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/job-templates.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bef12b68f976f054daabc571fcc89be8fde61bea', 'message': '[DNM] Validate ovn grenade fix\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/880495\nRelated-Bug: #2015364\nChange-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46\n'}]",3,878761,bef12b68f976f054daabc571fcc89be8fde61bea,19,1,6,13861,,,0,"[DNM] Validate ovn grenade fix

Depends-On: https://review.opendev.org/c/openstack/devstack/+/880495
Related-Bug: #2015364
Change-Id: I164a13156f02be6a8bf4eaa53c4b670b2481bc46
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/878761/6 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/grenade.yaml'],1,926c7a765e00fca0545553b3854d4ec2eac7de4d,bug/2015364, grenade_from_branch: stable/zed grenade_from_branch: stable/zed, grenade_from_branch: stable/yoga grenade_from_branch: stable/yoga,2,2
openstack%2Fos-brick~master~I08440acb4582e29e4c6398be524e790957c9c6d2,openstack/os-brick,master,I08440acb4582e29e4c6398be524e790957c9c6d2,Add Lustre support in remote fs,NEW,2022-08-22 16:41:15.000000000,2023-04-14 15:51:20.000000000,,"[{'_account_id': 597}, {'_account_id': 4523}, {'_account_id': 10848}, {'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2022-08-22 16:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/be47bbd06b23dbcc3d551087cc8dc90a6032a107', 'message': 'Add Lustre support in remote fs\n\nChange-Id: I08440acb4582e29e4c6398be524e790957c9c6d2\n'}, {'number': 2, 'created': '2022-12-21 14:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/1ee4a3c5dfe555707435c50d0c6ff507b6552fd4', 'message': 'Add Lustre support in remote fs\n\nChange-Id: I08440acb4582e29e4c6398be524e790957c9c6d2\n'}, {'number': 3, 'created': '2023-02-01 14:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/c1fddacc1fb2e2f6739ad2e56eba110698540862', 'message': 'Add Lustre support in remote fs\n\nChange-Id: I08440acb4582e29e4c6398be524e790957c9c6d2\n'}, {'number': 4, 'created': '2023-02-02 06:48:41.000000000', 'files': ['os_brick/initiator/__init__.py', 'os_brick/tests/remotefs/test_remotefs.py', 'os_brick/tests/initiator/test_connector.py', 'os_brick/remotefs/remotefs.py', 'os_brick/initiator/connector.py', 'os_brick/initiator/connectors/remotefs.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a40f15da59809a58acbb3778f9a67b716f8d6fe4', 'message': 'Add Lustre support in remote fs\n\nChange-Id: I08440acb4582e29e4c6398be524e790957c9c6d2\n'}]",11,853787,a40f15da59809a58acbb3778f9a67b716f8d6fe4,50,5,4,10848,,,0,"Add Lustre support in remote fs

Change-Id: I08440acb4582e29e4c6398be524e790957c9c6d2
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/87/853787/3 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/initiator/__init__.py', 'os_brick/tests/remotefs/test_remotefs.py', 'os_brick/tests/initiator/test_connector.py', 'os_brick/remotefs/remotefs.py', 'os_brick/initiator/connector.py', 'os_brick/initiator/connectors/remotefs.py']",6,be47bbd06b23dbcc3d551087cc8dc90a6032a107,bp/add-lustre-driver," 'quobyte', 'vzstorage', 'lustre'):"," 'quobyte', 'vzstorage'):",29,3
openstack%2Fnova~master~Ib35e5028622c5eaa72dac15c7c9a6cc542187269,openstack/nova,master,Ib35e5028622c5eaa72dac15c7c9a6cc542187269,Add Lustre support to nova,NEW,2022-08-22 16:37:40.000000000,2023-04-14 15:50:59.000000000,,"[{'_account_id': 7634}, {'_account_id': 10848}, {'_account_id': 20733}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-22 16:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe3ad026c577d046437975874311ec27b0585b76', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 2, 'created': '2022-10-07 10:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f707ad62118f034c57b3d4fce97a974e17f88d6', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 3, 'created': '2022-11-04 15:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53a3a4ed1b91674dc8aa9a5139921736c304a0e3', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 4, 'created': '2022-12-21 14:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fc132da873d217ae1667047ee517d463457cf97', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 5, 'created': '2022-12-29 15:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dff612f8545486562e8439ecd07bc5e13684cdfc', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 6, 'created': '2022-12-29 17:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8e1c56affb8d2e01d2e65d0c5061f407b4d6697', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}, {'number': 7, 'created': '2023-02-01 14:12:24.000000000', 'files': ['releasenotes/notes/add-lustre-driver-9192ea8fdcf09ed0.yaml', 'nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/virt/libvirt/volume/lustre.py', 'nova/tests/unit/virt/libvirt/volume/test_lustre.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aa52e84bb710f2ab813bd98b74e3bc2384df5c9a', 'message': 'Add\xa0Lustre support to nova\n\nAdd Lustre libvirt driver and configuration support.\n\nChange-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269\n'}]",7,853786,aa52e84bb710f2ab813bd98b74e3bc2384df5c9a,35,4,7,10848,,,0,"Add Lustre support to nova

Add Lustre libvirt driver and configuration support.

Change-Id: Ib35e5028622c5eaa72dac15c7c9a6cc542187269
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/853786/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/virt/libvirt/volume/lustre.py', 'nova/tests/unit/virt/libvirt/volume/test_lustre.py']",4,fe3ad026c577d046437975874311ec27b0585b76,bp/add-lustre-driver,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import mock from oslo_utils.fixture import uuidsentinel as uuids from nova.tests.unit.virt.libvirt.volume import test_mount from nova.tests.unit.virt.libvirt.volume import test_volume from nova import utils from nova.virt.libvirt.volume import mount from nova.virt.libvirt.volume import lustre class LibvirtLustreVolumeDriverTestCase(test_volume.LibvirtVolumeBaseTestCase): """"""Tests the libvirt NFS volume driver."""""" def setUp(self): super(LibvirtLustreVolumeDriverTestCase, self).setUp() self.useFixture(test_mount.MountFixture(self)) m = mount.get_manager() m._reset_state() self.mnt_base = '/mnt' m.host_up(self.fake_host) self.flags(lustre_mount_point_base=self.mnt_base, group='libvirt') def test_libvirt_lustre_driver(self): libvirt_driver = lustre.LibvirtLustreVolumeDriver(self.fake_host) export_string = '192.168.1.1:/lustre/share1' export_mnt_base = os.path.join(self.mnt_base, utils.get_hash_str(export_string)) connection_info = {'data': {'export': export_string, 'name': self.name}} instance = mock.sentinel.instance instance.uuid = uuids.instance libvirt_driver.connect_volume(connection_info, instance) libvirt_driver.disconnect_volume(connection_info, mock.sentinel.instance) device_path = os.path.join(export_mnt_base, connection_info['data']['name']) self.assertEqual(connection_info['data']['device_path'], device_path) self.mock_ensure_tree.assert_has_calls([mock.call(export_mnt_base)]) self.mock_mount.assert_has_calls([mock.call('lustre', export_string, export_mnt_base, [])]) self.mock_umount.assert_has_calls([mock.call(export_mnt_base)]) self.mock_rmdir.assert_has_calls([mock.call(export_mnt_base)]) def test_libvirt_lustre_driver_get_config(self): libvirt_driver = lustre.LibvirtLustreVolumeDriver(self.fake_host) export_string = '192.168.1.1:/lustre/share1' export_mnt_base = os.path.join(self.mnt_base, utils.get_hash_str(export_string)) file_path = os.path.join(export_mnt_base, self.name) connection_info = {'data': {'export': export_string, 'name': self.name, 'device_path': file_path}} conf = libvirt_driver.get_config(connection_info, self.disk_info) tree = conf.format_dom() self._assertFileTypeEquals(tree, file_path) self.assertEqual('raw', tree.find('./driver').get('type')) self.assertEqual('native', tree.find('./driver').get('io')) def test_libvirt_lustre_driver_with_opts(self): libvirt_driver = lustre.LibvirtLustreVolumeDriver(self.fake_host) export_string = '192.168.1.1:/lustre/share1' options = '-o intr,lustrevers=3' export_mnt_base = os.path.join(self.mnt_base, utils.get_hash_str(export_string)) connection_info = {'data': {'export': export_string, 'name': self.name, 'options': options}} instance = mock.sentinel.instance instance.uuid = uuids.instance libvirt_driver.connect_volume(connection_info, instance) libvirt_driver.disconnect_volume(connection_info, mock.sentinel.instance) self.mock_ensure_tree.assert_has_calls([mock.call(export_mnt_base)]) self.mock_mount.assert_has_calls([mock.call('lustre', export_string, export_mnt_base, ['-o', 'intr,lustrevers=3'])]) self.mock_umount.assert_has_calls([mock.call(export_mnt_base)]) self.mock_rmdir.assert_has_calls([mock.call(export_mnt_base)]) def test_extend_volume(self): libvirt_driver = lustre.LibvirtLustreVolumeDriver(self.fake_host) export_string = '192.168.1.1:/lustre/share1' connection_info = {'data': {'export': export_string, 'name': self.name}} instance = mock.sentinel.instance requested_size = 10 new_size = libvirt_driver.extend_volume(connection_info, instance, requested_size) self.assertEqual(requested_size, new_size) ",,201,0
openstack%2Fopenstack-ansible~master~I08d0e0e5bd17fdcaa76588af4d0689bcdea3c2e1,openstack/openstack-ansible,master,I08d0e0e5bd17fdcaa76588af4d0689bcdea3c2e1,docs: Indicate how to use self-signed certs,MERGED,2023-04-14 13:41:33.000000000,2023-04-14 15:48:50.000000000,2023-04-14 15:46:47.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-14 13:41:33.000000000', 'files': ['doc/source/user/aio/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0049f17af2e555b5b07d099fe29ca203b57c1c7', 'message': 'docs: Indicate how to use self-signed certs\n\nThis is slightly nicer than simply ignoring the validation failures.\n\nChange-Id: I08d0e0e5bd17fdcaa76588af4d0689bcdea3c2e1\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,880489,c0049f17af2e555b5b07d099fe29ca203b57c1c7,8,3,1,15334,,,0,"docs: Indicate how to use self-signed certs

This is slightly nicer than simply ignoring the validation failures.

Change-Id: I08d0e0e5bd17fdcaa76588af4d0689bcdea3c2e1
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/89/880489/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/aio/quickstart.rst'],1,c0049f17af2e555b5b07d099fe29ca203b57c1c7,docs," ignore SSL issues. To use the self-signed certificate, first copy it to the other hosts. The name and location of the generated certificate are configured by the ``pki_authorities`` and ``pki_trust_store_location`` variables respectively, which are used by the ``pki`` role provided by `ansible-role-pki`__. On an Ubuntu 22.04 host, these will default to ``ExampleCorpRoot`` and ``/usr/local/share/ca-certificates``, respectively. For example: .. code-block:: shell-session $ scp aio:/usr/local/share/ca-certificates/ExampleCorpRoot.crt ~/.config/openstack/aio.crt .. __: https://opendev.org/openstack/ansible-role-pki Once this is done, configure the ``cacert`` value in the the definition for your cloud in ``clouds.yaml``. For example: .. code-block:: yaml clouds: aio: # ... cacert: /home/<username>/.config/openstack/aio.crt Alternatively, you can simply ignore SSL issues by setting ``verify: false`` in the definition for your cloud in ``clouds.yaml``. This will disable SSL verification entirely for this cloud. For example: Finally, you can also opt to disable SSL certificate configuration during initial deployment or opt to use an external certificate authority for signing, such as Lets Encrypt. Both topics are outside the scope of this document. ", ignore SSL issues. You can ignore SSL issue by setting ``verify: false`` in the definition for your cloud in ``clouds.yaml``. For example::,32,2
openstack%2Fopenstack-ansible~master~I54a78ad3fc35775a104732a544c5e1ff9c14827d,openstack/openstack-ansible,master,I54a78ad3fc35775a104732a544c5e1ff9c14827d,Fix haproxy_nova_api_metadata_service config,MERGED,2023-04-13 12:59:49.000000000,2023-04-14 15:47:52.000000000,2023-04-14 15:46:45.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-13 12:59:49.000000000', 'files': ['inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6ad9b404eed641d4ed5015d63dc79c5d53e2392a', 'message': 'Fix haproxy_nova_api_metadata_service config\n\nIn [1] we merged an incorrect haproxy config for\nhaproxy_nova_api_metadata_service[2].\n\nFirst of all, `haproxy_ssl_all_vips` is not used because `haproxy_bind`\nis defined, so this service has only one frontend(internal vip).\nIt can be dropped.\n\nOnly `haproxy_ssl` has an effect, but because it\'s an internal ip\naddress, its value should be set to `""{{ haproxy_ssl_all_vips }}""`\nwhich is generally used to define protocol for internal VIPs(yes, the\nname may be a bit misleading). We did the same for repo_server in [3].\n\nCurrently, nova metadata service listens on https and neutron tries to\nreach it over http because `openstack_service_internaluri_proto` is set\nto \'http\' by default. As the result, neutron is not able to reach\nmetadata service.\n\n[1] https://review.opendev.org/c/openstack/openstack-ansible/+/866119\n[2] https://opendev.org/openstack/openstack-ansible/blame/commit/dc1f76c82358e5efd55a3a5ee24b2c99b479a165/inventory/group_vars/haproxy/haproxy.yml#L366-L367\n[3] https://review.opendev.org/c/openstack/openstack-ansible/+/876426\n\nChange-Id: I54a78ad3fc35775a104732a544c5e1ff9c14827d\n'}]",1,880300,6ad9b404eed641d4ed5015d63dc79c5d53e2392a,10,3,1,32666,,,0,"Fix haproxy_nova_api_metadata_service config

In [1] we merged an incorrect haproxy config for
haproxy_nova_api_metadata_service[2].

First of all, `haproxy_ssl_all_vips` is not used because `haproxy_bind`
is defined, so this service has only one frontend(internal vip).
It can be dropped.

Only `haproxy_ssl` has an effect, but because it's an internal ip
address, its value should be set to `""{{ haproxy_ssl_all_vips }}""`
which is generally used to define protocol for internal VIPs(yes, the
name may be a bit misleading). We did the same for repo_server in [3].

Currently, nova metadata service listens on https and neutron tries to
reach it over http because `openstack_service_internaluri_proto` is set
to 'http' by default. As the result, neutron is not able to reach
metadata service.

[1] https://review.opendev.org/c/openstack/openstack-ansible/+/866119
[2] https://opendev.org/openstack/openstack-ansible/blame/commit/dc1f76c82358e5efd55a3a5ee24b2c99b479a165/inventory/group_vars/haproxy/haproxy.yml#L366-L367
[3] https://review.opendev.org/c/openstack/openstack-ansible/+/876426

Change-Id: I54a78ad3fc35775a104732a544c5e1ff9c14827d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/00/880300/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/haproxy/haproxy.yml'],1,6ad9b404eed641d4ed5015d63dc79c5d53e2392a,," haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"""," haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}""",1,2
openstack%2Fopenstack-ansible-os_glance~stable%2Fxena~I48feac2ea789782e55bd49196e631cd4df9778ce,openstack/openstack-ansible-os_glance,stable/xena,I48feac2ea789782e55bd49196e631cd4df9778ce,Disable uWSGI if ceph is used as a store,MERGED,2023-04-06 08:57:57.000000000,2023-04-14 15:45:19.000000000,2023-04-14 15:44:18.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-06 08:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/2b33ddc0378f599151b58f0e6163217f14fe96df', 'message': ""Disable uWSGI if ceph is used as a store\n\nAt the moment there's an issue with chunking in case uwsgi is used\nwith ceph backend.\n\nChange-Id: I48feac2ea789782e55bd49196e631cd4df9778ce\nRelated-Bug: #1916482\n(cherry picked from commit 295533132b6d143fe9d0499545fa0d396a633b49)\n""}, {'number': 2, 'created': '2023-04-13 18:29:29.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/a5fd174b2fbdf7ca9d8c0f3f8ce1788914aaa243', 'message': ""Disable uWSGI if ceph is used as a store\n\nAt the moment there's an issue with chunking in case uwsgi is used\nwith ceph backend.\n\nChange-Id: I48feac2ea789782e55bd49196e631cd4df9778ce\nRelated-Bug: #1916482\n(cherry picked from commit 295533132b6d143fe9d0499545fa0d396a633b49)\n""}]",1,879699,a5fd174b2fbdf7ca9d8c0f3f8ce1788914aaa243,12,3,2,25023,,,0,"Disable uWSGI if ceph is used as a store

At the moment there's an issue with chunking in case uwsgi is used
with ceph backend.

Change-Id: I48feac2ea789782e55bd49196e631cd4df9778ce
Related-Bug: #1916482
(cherry picked from commit 295533132b6d143fe9d0499545fa0d396a633b49)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/99/879699/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,2b33ddc0378f599151b58f0e6163217f14fe96df,,"# We don't use uwsgi if ceph is used to prevent chunking issues glance_use_uwsgi: ""{{ ('ceph' not in _glance_available_stores) }}""",glance_use_uwsgi: True,2,1
openstack%2Fneutron~master~Iba7ff50efc8f6d027fe9151fc64f547aa421b995,openstack/neutron,master,Iba7ff50efc8f6d027fe9151fc64f547aa421b995,[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``,MERGED,2023-04-13 12:49:51.000000000,2023-04-14 15:36:18.000000000,2023-04-14 15:35:12.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:49:51.000000000', 'files': ['neutron/db/dvr_mac_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/69f30c92ef595f1bfc57208f88c4c1c5a555f55c', 'message': '[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``\n\nCloses-Bug: #2016142\nChange-Id: Iba7ff50efc8f6d027fe9151fc64f547aa421b995\n'}]",1,880298,69f30c92ef595f1bfc57208f88c4c1c5a555f55c,10,6,1,16688,,,0,"[sqlalchemy-20] Add reader context to ``get_ports_on_host_by_subnet``

Closes-Bug: #2016142
Change-Id: Iba7ff50efc8f6d027fe9151fc64f547aa421b995
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/880298/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/dvr_mac_db.py'],1,69f30c92ef595f1bfc57208f88c4c1c5a555f55c,bug/2016142, @db_api.CONTEXT_READER,,1,0
openstack%2Ftripleo-quickstart~master~I71b50543bce037e0f14df8b0cd7f35d738858803,openstack/tripleo-quickstart,master,I71b50543bce037e0f14df8b0cd7f35d738858803,Remove repo_cmd_after for centos8/wallaby container-tools need rhel8,MERGED,2023-04-07 12:56:47.000000000,2023-04-14 15:31:29.000000000,2023-04-14 15:30:30.000000000,"[{'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 11166}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-07 12:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/0d044a6ff3a6c123bdcbabc333bccac252a3332c', 'message': 'Remove repo_cmd_after for centos8/wallaby container-tools need rhel8\n\nWe need to stop setting container-tools 3 and use rhel8 for c8\nwallaby. See related patch at [1] for container builds.\n\n[1] https://review.opendev.org/c/openstack/tripleo-common/+/879889\n\nChange-Id: I71b50543bce037e0f14df8b0cd7f35d738858803\n'}, {'number': 2, 'created': '2023-04-14 05:45:26.000000000', 'files': ['config/release/tripleo-ci/CentOS-8/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-8/wallaby.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c4e69f673dc4db7560a3ef297043155533947cf0', 'message': 'Remove repo_cmd_after for centos8/wallaby container-tools need rhel8\n\nWe need to stop setting container-tools 3 and use rhel8 for c8\nwallaby. See related patch at [1] for container builds.\n\n[1] https://review.opendev.org/c/openstack/tripleo-common/+/879889\n\n\nChange-Id: I71b50543bce037e0f14df8b0cd7f35d738858803\n'}]",7,879893,c4e69f673dc4db7560a3ef297043155533947cf0,17,6,2,8449,,,0,"Remove repo_cmd_after for centos8/wallaby container-tools need rhel8

We need to stop setting container-tools 3 and use rhel8 for c8
wallaby. See related patch at [1] for container builds.

[1] https://review.opendev.org/c/openstack/tripleo-common/+/879889


Change-Id: I71b50543bce037e0f14df8b0cd7f35d738858803
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/93/879893/2 && git format-patch -1 --stdout FETCH_HEAD,"['config/release/tripleo-ci/CentOS-8/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-8/wallaby.yml']",2,0d044a6ff3a6c123bdcbabc333bccac252a3332c,,, sudo dnf module disable container-tools:rhel8 -y; sudo dnf module enable container-tools:3.0 -y;,0,4
openstack%2Fopenstack-ansible-os_nova~master~Ic681f73a09bb0ac280c227f85c6e79b31fd3429a,openstack/openstack-ansible-os_nova,master,Ic681f73a09bb0ac280c227f85c6e79b31fd3429a,Move online_data_migrations to post-setup,MERGED,2023-04-12 11:50:00.000000000,2023-04-14 15:07:30.000000000,2023-04-14 15:06:26.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2023-04-12 11:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/4a9f47978f1339fa03e7b18a90373008a8bde9fa', 'message': 'Move online_data_migrations to post-setup\n\nAccording to nova rolling upgrade process [1], online_data_migrations\nshould run once all the services are running the latest version of the\ncode and were restarted. With that, we should move online migrations\nafter handlers being flushed, when all services are restarted.\n\nAt the same time, nova-status upgrade check must run before services\nare restarted to the new version, as service restart might lead to\nservice breakage if upgrade check fails [2]. It makes no sense to\nrun upgrade check when upgrade is fully finished.\n\n[1] https://docs.openstack.org/nova/latest/admin/upgrades.html#rolling-upgrade-process\n[2] https://docs.openstack.org/nova/latest/cli/nova-status.html#upgrade\n\nChange-Id: Ic681f73a09bb0ac280c227f85c6e79b31fd3429a\n'}, {'number': 2, 'created': '2023-04-12 16:22:05.000000000', 'files': ['tasks/nova_db_post_setup.yml', 'tasks/nova_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/cb62372a31da4633525977bf93cfa952a7531108', 'message': 'Move online_data_migrations to post-setup\n\nAccording to nova rolling upgrade process [1], online_data_migrations\nshould run once all the services are running the latest version of the\ncode and were restarted. With that, we should move online migrations\nafter handlers being flushed, when all services are restarted.\n\nAt the same time, nova-status upgrade check must run before services\nare restarted to the new version, as service restart might lead to\nservice breakage if upgrade check fails [2]. It makes no sense to\nrun upgrade check when upgrade is fully finished.\n\n[1] https://docs.openstack.org/nova/latest/admin/upgrades.html#rolling-upgrade-process\n[2] https://docs.openstack.org/nova/latest/cli/nova-status.html#upgrade\n\nChange-Id: Ic681f73a09bb0ac280c227f85c6e79b31fd3429a\n'}]",0,880147,cb62372a31da4633525977bf93cfa952a7531108,10,3,2,28619,,,0,"Move online_data_migrations to post-setup

According to nova rolling upgrade process [1], online_data_migrations
should run once all the services are running the latest version of the
code and were restarted. With that, we should move online migrations
after handlers being flushed, when all services are restarted.

At the same time, nova-status upgrade check must run before services
are restarted to the new version, as service restart might lead to
service breakage if upgrade check fails [2]. It makes no sense to
run upgrade check when upgrade is fully finished.

[1] https://docs.openstack.org/nova/latest/admin/upgrades.html#rolling-upgrade-process
[2] https://docs.openstack.org/nova/latest/cli/nova-status.html#upgrade

Change-Id: Ic681f73a09bb0ac280c227f85c6e79b31fd3429a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/47/880147/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/nova_db_post_setup.yml', 'tasks/nova_db_setup.yml']",2,4a9f47978f1339fa03e7b18a90373008a8bde9fa,," # The nova-status upgrade check command is typically run after upgrading the # controller services to new code, but is also OK to run for a greenfield # install to verify everything is setup correctly. This must run after cell # mapping setup and before actual service restart. # https://docs.openstack.org/nova/latest/cli/nova-status.html - name: Run nova-status upgrade check to validate a healthy configuration command: ""{{ nova_bin }}/nova-status upgrade check"" become: yes become_user: ""{{ nova_system_user_name }}"" register: nova_status_upgrade_check until: nova_status_upgrade_check is success retries: 8 delay: 15 # The nova-status upgrade check command has three standard return codes: # 0: all checks were successful # 1: warning: there might be some checks that require investigation, but # generally will not block an automated install/upgrade; digging into # warnings is useful for debugging post-install/upgrade issues # 2: at least one check failed and must stop the install/upgrade because # something was not setup properly failed_when: ""nova_status_upgrade_check.rc not in [0, 1]"" changed_when: false when: - ""ansible_local['openstack_ansible']['nova']['need_online_data_migrations'] | bool""","- name: Perform online data migrations command: ""{{ nova_bin }}/nova-manage db online_data_migrations"" become: yes become_user: ""{{ nova_system_user_name }}"" when: - ""(nova_all_software_updated | default('no')) | bool"" - ""ansible_local['openstack_ansible']['nova']['need_online_data_migrations'] | bool"" changed_when: false register: data_migrations - name: Disable the online migrations requirement ini_file: dest: ""/etc/ansible/facts.d/openstack_ansible.fact"" section: nova option: need_online_data_migrations value: False when: - data_migrations is not skipped - data_migrations is succeeded ",51,40
openstack%2Fcharm-ceph-mon~stable%2Fquincy.2~Iba5aad1d895ba8b28ce364899a1e41275dc3003b,openstack/charm-ceph-mon,stable/quincy.2,Iba5aad1d895ba8b28ce364899a1e41275dc3003b,Remove relation test,MERGED,2023-04-14 09:48:13.000000000,2023-04-14 15:05:34.000000000,2023-04-14 15:05:34.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2023-04-14 09:48:13.000000000', 'files': ['tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/b9836c88fb2a32dfb27b40199a7a7b5b5567fff9', 'message': ""Remove relation test\n\nThe CephRelationTest class wasn't of much used and the test was\nrather flaky, since it compared public IP addresses.\n\nChange-Id: Iba5aad1d895ba8b28ce364899a1e41275dc3003b\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/1034\n(cherry picked from commit f23d9e3d3eda7dda1775a3b0a600856bec42a1c4)\n""}]",0,880491,b9836c88fb2a32dfb27b40199a7a7b5b5567fff9,7,3,1,15382,,,0,"Remove relation test

The CephRelationTest class wasn't of much used and the test was
rather flaky, since it compared public IP addresses.

Change-Id: Iba5aad1d895ba8b28ce364899a1e41275dc3003b
func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/1034
(cherry picked from commit f23d9e3d3eda7dda1775a3b0a600856bec42a1c4)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/91/880491/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/tests.yaml'],1,b9836c88fb2a32dfb27b40199a7a7b5b5567fff9,remove-relation-test-stable/quincy.2,, - zaza.openstack.charm_tests.ceph.tests.CephRelationTest - zaza.openstack.charm_tests.ceph.tests.CephRelationTest - zaza.openstack.charm_tests.ceph.tests.CephRelationTest,0,3
openstack%2Fgovernance~master~I8a2e6e890b71b2a82233d869aaa8fa8f06d87792,openstack/governance,master,I8a2e6e890b71b2a82233d869aaa8fa8f06d87792,Retire puppet-tacker - Step 3: Retire Repository,MERGED,2023-02-25 06:02:06.000000000,2023-04-14 15:03:43.000000000,2023-04-14 15:02:39.000000000,"[{'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-02-25 06:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/3de6df767d9c497d19e0caf2a242604bd47b4bfd', 'message': 'Retire puppet-tacker - Step 3: Retire Repository\n\nDepends-on: https://review.opendev.org/875290\nChange-Id: I8a2e6e890b71b2a82233d869aaa8fa8f06d87792\n'}, {'number': 2, 'created': '2023-04-05 13:57:45.000000000', 'files': ['reference/legacy.yaml', 'reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/8cdf1036a1062a7924d2bf04ff30a9f2159303da', 'message': 'Retire puppet-tacker - Step 3: Retire Repository\n\nDepends-on: https://review.opendev.org/875290\nChange-Id: I8a2e6e890b71b2a82233d869aaa8fa8f06d87792\n'}]",4,875295,8cdf1036a1062a7924d2bf04ff30a9f2159303da,16,3,2,9816,,,0,"Retire puppet-tacker - Step 3: Retire Repository

Depends-on: https://review.opendev.org/875290
Change-Id: I8a2e6e890b71b2a82233d869aaa8fa8f06d87792
",git fetch https://review.opendev.org/openstack/governance refs/changes/95/875295/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,3de6df767d9c497d19e0caf2a242604bd47b4bfd,project-update,, puppet-tacker: repos: - openstack/puppet-tacker,0,3
openstack%2Ftripleo-upgrade~stable%2Fwallaby~I884d5c780685f6ea46b7b0afa34e5c4f038ae68b,openstack/tripleo-upgrade,stable/wallaby,I884d5c780685f6ea46b7b0afa34e5c4f038ae68b,[update] add validation package update during undercloud prerequisites update,MERGED,2023-03-29 01:13:41.000000000,2023-04-14 15:02:43.000000000,2023-04-14 15:02:43.000000000,"[{'_account_id': 8297}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 32926}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-03-29 01:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/453db8eccc9882f691adbfe3e9f0b4e8cb7ccbd8', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 2, 'created': '2023-03-29 01:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ea20787f22c1811768d28b0bba3c237f68530cef', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 3, 'created': '2023-03-29 18:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/0ac6c177a9101ea582b51dd5b1909796c4316eb7', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 4, 'created': '2023-03-29 20:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/2d2013908ace77554e42e0015d6b69a7bafcd372', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 5, 'created': '2023-03-29 21:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9bca9a72a54b7015651e98d43f2d6f97d2ebb62f', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 6, 'created': '2023-03-29 23:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/d52bd9b931e6d70d583fc5f1261f8382e4beed58', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 7, 'created': '2023-03-30 13:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/74d1340122bd19b02984b52523ba7c11c9731554', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 8, 'created': '2023-03-30 18:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/02116fb420e5bd4fc6826564c718d59417801492', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 9, 'created': '2023-04-04 18:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/05e9a0db73808032a409e3f42c54a24a79fb51fb', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 10, 'created': '2023-04-09 19:03:56.000000000', 'files': ['tasks/common/undercloud_prerequisites.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/96762fd5594ccbf99448d47e1d25e28a305f2ecc', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}]",16,878669,96762fd5594ccbf99448d47e1d25e28a305f2ecc,36,5,10,32432,,,0,"[update] add validation package update during undercloud prerequisites update

Update pre validation stage requires latest validation packages to reside on undercloud

This must be done after undercloud repo is updated and before undercloud is updated.

Change-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/69/878669/10 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/undercloud_prerequisites.yaml'],1,453db8eccc9882f691adbfe3e9f0b4e8cb7ccbd8,,"- name: Update validation packages prior the undercloud upgrade package: name: - ""{{ (ansible_python.version.major is version('3', '>=')) | ternary('python3-validations-libs', 'validations-common', 'openstack-tripleo-validations') }}"" state: latest tags: - update_validation_packages ",,8,0
openstack%2Fcharm-ceph-osd~stable%2Fquincy.2~I9a77f4a86412f9bf4d27c0d7e0a7fe34d5a403ff,openstack/charm-ceph-osd,stable/quincy.2,I9a77f4a86412f9bf4d27c0d7e0a7fe34d5a403ff,Remove relation test,MERGED,2023-04-14 09:45:42.000000000,2023-04-14 15:01:45.000000000,2023-04-14 15:01:45.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2023-04-14 09:45:42.000000000', 'files': ['tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/c67f8bacc3c3248a2467cf3fc6ae6e08c2b0852f', 'message': ""Remove relation test\n\nThe CephRelationTest class wasn't of much used and the test was\nrather flaky, since it compared public IP addresses.\n\nChange-Id: I9a77f4a86412f9bf4d27c0d7e0a7fe34d5a403ff\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/1034\n(cherry picked from commit f1cdc830dcfeb8cda78021fd7ecdb510f20d84d8)\n""}]",0,880490,c67f8bacc3c3248a2467cf3fc6ae6e08c2b0852f,7,3,1,15382,,,0,"Remove relation test

The CephRelationTest class wasn't of much used and the test was
rather flaky, since it compared public IP addresses.

Change-Id: I9a77f4a86412f9bf4d27c0d7e0a7fe34d5a403ff
func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/1034
(cherry picked from commit f1cdc830dcfeb8cda78021fd7ecdb510f20d84d8)
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/90/880490/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/tests.yaml'],1,c67f8bacc3c3248a2467cf3fc6ae6e08c2b0852f,remove-relation-test-stable/quincy.2,, - zaza.openstack.charm_tests.ceph.tests.CephRelationTest,0,1
openstack%2Fgovernance~master~I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71,openstack/governance,master,I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71,Add xstatic-angular-fileupload as Horizon team deliverables,MERGED,2023-02-15 07:11:23.000000000,2023-04-14 14:59:59.000000000,2023-04-14 14:58:59.000000000,"[{'_account_id': 8556}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-02-15 07:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5ba0215617fdb25bb93dbfdb0695bdcadb3df373', 'message': 'Add xstatic-angular-fileupload as Horizon team deliverables\n\nxstatic-angular-fileupload pypi is used by Horizon.\nHorizon team discussed this topic in the horizon weekly\nmeeting and decided to move it under the horizon deliverables\nand keep them under the OpenStack namespace [1].\n\n[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57\n\nDepends-On: https://review.opendev.org/c/openstack/project-config/+/873843\nChange-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71\n'}, {'number': 2, 'created': '2023-02-15 16:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/39a55ba442a088a977895c59b0b7f371a55bf4c6', 'message': 'Add xstatic-angular-fileupload as Horizon team deliverables\n\nxstatic-angular-fileupload pypi is used by Horizon.\nHorizon team discussed this topic in the horizon weekly\nmeeting and decided to move it under the horizon deliverables\nand keep them under the OpenStack namespace [1].\n\n[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57\n\nNeeded-By: https://review.opendev.org/c/openstack/project-config/+/873843\nChange-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71\n'}, {'number': 3, 'created': '2023-03-28 17:25:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e4777daae74ed1e3916c19bd5b65ae2e4f7ba81a', 'message': 'Add xstatic-angular-fileupload as Horizon team deliverables\n\nxstatic-angular-fileupload pypi is used by Horizon.\nHorizon team discussed this topic in the horizon weekly\nmeeting and decided to move it under the horizon deliverables\nand keep them under the OpenStack namespace [1]. We also check\nwith moinwiki contributor and they are not using this pypi project [2].\n\n[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57\n[2] https://github.com/moinwiki/moin/issues/1326#issuecomment-1380310586\n\nNeeded-By: https://review.opendev.org/c/openstack/project-config/+/873843\nChange-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71\n'}, {'number': 4, 'created': '2023-04-10 19:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a036ad6cb9b945854cf98d8bc2baed8beadc4679', 'message': 'Add xstatic-angular-fileupload as Horizon team deliverables\n\nxstatic-angular-fileupload pypi is used by Horizon.\nHorizon team discussed this topic in the horizon weekly\nmeeting and decided to move it under the horizon deliverables\nand keep them under the OpenStack namespace [1]. We also check\nwith moinwiki contributor and they are not using this pypi project [2].\n\n[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57\n[2] https://github.com/moinwiki/moin/issues/1326#issuecomment-1380310586\n\nNeeded-By: https://review.opendev.org/c/openstack/project-config/+/873843\nChange-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71\n'}, {'number': 5, 'created': '2023-04-10 20:44:26.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/3c252a00cb81692360a7ad8d73057497fe7f2b7e', 'message': 'Add xstatic-angular-fileupload as Horizon team deliverables\n\nxstatic-angular-fileupload pypi is used by Horizon.\nHorizon team discussed this topic in the horizon weekly\nmeeting and decided to move it under the horizon deliverables\nand keep them under the OpenStack namespace [1]. We also check\nwith moinwiki contributor and they are not using this pypi project [2].\n\n[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57\n[2] https://github.com/moinwiki/moin/issues/1326#issuecomment-1380310586\n\nNeeded-By: https://review.opendev.org/c/openstack/project-config/+/873843\nChange-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71\n'}]",7,873845,3c252a00cb81692360a7ad8d73057497fe7f2b7e,23,4,5,29313,,,0,"Add xstatic-angular-fileupload as Horizon team deliverables

xstatic-angular-fileupload pypi is used by Horizon.
Horizon team discussed this topic in the horizon weekly
meeting and decided to move it under the horizon deliverables
and keep them under the OpenStack namespace [1]. We also check
with moinwiki contributor and they are not using this pypi project [2].

[1] https://meetings.opendev.org/irclogs/%23openstack-horizon/%23openstack-horizon.2023-02-01.log.html#t2023-02-01T16:09:57
[2] https://github.com/moinwiki/moin/issues/1326#issuecomment-1380310586

Needed-By: https://review.opendev.org/c/openstack/project-config/+/873843
Change-Id: I8a1c1afdad7f2768e80c1efc5cdbcd914abc8e71
",git fetch https://review.opendev.org/openstack/governance refs/changes/45/873845/5 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,5ba0215617fdb25bb93dbfdb0695bdcadb3df373,project-update, xstatic-angular-fileupload: repos: - openstack/xstatic-angular-fileupload,,3,0
openstack%2Fansible-role-uwsgi~master~I3b11220dd30a03fd6465f7b5e041027fbd8bad1d,openstack/ansible-role-uwsgi,master,I3b11220dd30a03fd6465f7b5e041027fbd8bad1d,Replace imports with dynamic includes,MERGED,2023-04-13 16:58:39.000000000,2023-04-14 14:56:50.000000000,2023-04-14 14:55:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-13 16:58:39.000000000', 'files': ['tasks/main.yml', 'tasks/uwsgi_install.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-uwsgi/commit/3fa317e79a8f7c8102b758d22c5a08c0cfddf61b', 'message': 'Replace imports with dynamic includes\n\nA weird behaviour has been spotted in AIO, where role, that was\nimporting python_venv_build and uwsgi roles was failing, as\nvenv_build_distro_package_list definition from uwsgi role was applied\non upper level even before uwsgi runtime\n\nAs a result, previous import was failing with\nuwsgi_build_distro_package_list being undefined.\n\nReplacing any import with inlcude was solving the issue. Since we re-use\nuwsgi role a lot and using include make sense in the role, we\nstart replacing static imports from here.\n\nChange-Id: I3b11220dd30a03fd6465f7b5e041027fbd8bad1d\n'}]",0,880344,3fa317e79a8f7c8102b758d22c5a08c0cfddf61b,8,3,1,28619,,,0,"Replace imports with dynamic includes

A weird behaviour has been spotted in AIO, where role, that was
importing python_venv_build and uwsgi roles was failing, as
venv_build_distro_package_list definition from uwsgi role was applied
on upper level even before uwsgi runtime

As a result, previous import was failing with
uwsgi_build_distro_package_list being undefined.

Replacing any import with inlcude was solving the issue. Since we re-use
uwsgi role a lot and using include make sense in the role, we
start replacing static imports from here.

Change-Id: I3b11220dd30a03fd6465f7b5e041027fbd8bad1d
",git fetch https://review.opendev.org/openstack/ansible-role-uwsgi refs/changes/44/880344/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/uwsgi_install.yml']",2,3fa317e79a8f7c8102b758d22c5a08c0cfddf61b,, include_role:, import_role:,11,3
openstack%2Fgovernance~master~Ib41769b65d3f67645d4c862f7c75119b16a02311,openstack/governance,master,Ib41769b65d3f67645d4c862f7c75119b16a02311,Add ovn-bgp-agent to Neutron governed projects,MERGED,2023-04-04 13:28:47.000000000,2023-04-14 14:56:10.000000000,2023-04-14 14:55:04.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 15554}, {'_account_id': 16465}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 23804}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-04 13:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e250dd8e1150c0d53605f4ce51e978ad7df1dd14', 'message': 'Add ovn-bgp-agent to Neutron governed projects\n\nDuring the Bobcat PTG it was discussed and accepted the inclusion of\nthe ovn-bgp-agent project under the Neutron governance.\n\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: Ib41769b65d3f67645d4c862f7c75119b16a02311\n'}, {'number': 2, 'created': '2023-04-04 13:55:38.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/8edbe9389671774ba427183461d298e4c2434c7a', 'message': 'Add ovn-bgp-agent to Neutron governed projects\n\nDuring the Bobcat PTG it was discussed and accepted the inclusion of\nthe ovn-bgp-agent project under the Neutron governance.\n\nDepends-On: https://review.opendev.org/c/openstack/project-config/+/879456\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: Ib41769b65d3f67645d4c862f7c75119b16a02311\n'}]",9,879455,8edbe9389671774ba427183461d298e4c2434c7a,26,13,2,6773,,,0,"Add ovn-bgp-agent to Neutron governed projects

During the Bobcat PTG it was discussed and accepted the inclusion of
the ovn-bgp-agent project under the Neutron governance.

Depends-On: https://review.opendev.org/c/openstack/project-config/+/879456
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Change-Id: Ib41769b65d3f67645d4c862f7c75119b16a02311
",git fetch https://review.opendev.org/openstack/governance refs/changes/55/879455/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,e250dd8e1150c0d53605f4ce51e978ad7df1dd14,project-update, ovn-bgp-agent: repos: - openstack/ovn-bgp-agent,,3,0
openstack%2Ftripleo-upgrade~stable%2Fzed~I884d5c780685f6ea46b7b0afa34e5c4f038ae68b,openstack/tripleo-upgrade,stable/zed,I884d5c780685f6ea46b7b0afa34e5c4f038ae68b,[update] add validation package update during undercloud prerequisites update,MERGED,2023-03-28 22:20:57.000000000,2023-04-14 14:55:39.000000000,2023-04-14 14:55:39.000000000,"[{'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-03-28 22:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/596cbeb4eff67fcd8ebf608eb698b4592fe1cc89', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 2, 'created': '2023-03-28 22:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/c0662cfb427f329734e2bed7b94ea72a3b958db8', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 3, 'created': '2023-03-29 01:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/e3a8a2b04808bfa8e5f1bdc0da5dd077ace222fe', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 4, 'created': '2023-04-04 18:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9640e8f1fd6fa0b83a22ee45526b24c24fca2552', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}, {'number': 5, 'created': '2023-04-09 19:04:03.000000000', 'files': ['tasks/common/undercloud_prerequisites.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7be440ba9e2bbf26402d3bf3dc35db52f9e0f54f', 'message': '[update] add validation package update during undercloud prerequisites update\n\nUpdate pre validation stage requires latest validation packages to reside on undercloud\n\nThis must be done after undercloud repo is updated and before undercloud is updated.\n\nCloses: OSP-23621\n\nChange-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b\n'}]",5,878668,7be440ba9e2bbf26402d3bf3dc35db52f9e0f54f,24,3,5,32432,,,0,"[update] add validation package update during undercloud prerequisites update

Update pre validation stage requires latest validation packages to reside on undercloud

This must be done after undercloud repo is updated and before undercloud is updated.

Closes: OSP-23621

Change-Id: I884d5c780685f6ea46b7b0afa34e5c4f038ae68b
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/68/878668/5 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/undercloud_prerequisites.yaml'],1,596cbeb4eff67fcd8ebf608eb698b4592fe1cc89,," - ""{{ (ansible_python.version.major is version('3', '>=')) | ternary('python3-validations-libs', 'validations-common', 'openstack-tripleo-validations') }}""",,1,0
openstack%2Fovn-bgp-agent~master~I19c4a295eac6454d5aa465aa7b90ecf258701850,openstack/ovn-bgp-agent,master,I19c4a295eac6454d5aa465aa7b90ecf258701850,Better protect from FRR restarts,MERGED,2023-04-14 08:05:28.000000000,2023-04-14 14:13:30.000000000,2023-04-14 14:13:30.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 31291}]","[{'number': 1, 'created': '2023-04-14 08:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/3c93871974f094adcb8674162c59fbb455403558', 'message': 'Better protect from FRR restarts\n\nIt is possible that FRR gets restarted, loosing the configuration\nadded by the agent (for instance the vrf leaking). As the sync\naction is kind of heavy to run it more frequently, this patch adds\na new periodic task that is in charge of just ensuring the FRR\nconfiguration and not about the routes being exposed. That way\nit can be executed more frequently.\n\nChange-Id: I19c4a295eac6454d5aa465aa7b90ecf258701850\n'}, {'number': 2, 'created': '2023-04-14 09:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/b5b12beff33b8b6f11cfc4a4ce6a98573df0f158', 'message': 'Better protect from FRR restarts\n\nIt is possible that FRR gets restarted, loosing the configuration\nadded by the agent (for instance the vrf leaking). As the sync\naction is kind of heavy to run it more frequently, this patch adds\na new periodic task that is in charge of just ensuring the FRR\nconfiguration and not about the routes being exposed. That way\nit can be executed more frequently.\n\nChange-Id: I19c4a295eac6454d5aa465aa7b90ecf258701850\n'}, {'number': 3, 'created': '2023-04-14 12:07:41.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py', 'ovn_bgp_agent/config.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_nb_ovn_bgp_driver.py', 'ovn_bgp_agent/agent.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_ovn_bgp_driver.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/db9d9aee9f39abc68efbab00cf7745d8ecef4261', 'message': 'Better protect from FRR restarts\n\nIt is possible that FRR gets restarted, loosing the configuration\nadded by the agent (for instance the vrf leaking). As the sync\naction is kind of heavy to run it more frequently, this patch adds\na new periodic task that is in charge of just ensuring the FRR\nconfiguration and not about the routes being exposed. That way\nit can be executed more frequently.\n\nChange-Id: I19c4a295eac6454d5aa465aa7b90ecf258701850\n'}]",5,879848,db9d9aee9f39abc68efbab00cf7745d8ecef4261,15,3,3,23567,,,0,"Better protect from FRR restarts

It is possible that FRR gets restarted, loosing the configuration
added by the agent (for instance the vrf leaking). As the sync
action is kind of heavy to run it more frequently, this patch adds
a new periodic task that is in charge of just ensuring the FRR
configuration and not about the routes being exposed. That way
it can be executed more frequently.

Change-Id: I19c4a295eac6454d5aa465aa7b90ecf258701850
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/48/879848/3 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/nb_ovn_bgp_driver.py', 'ovn_bgp_agent/config.py', 'ovn_bgp_agent/agent.py']",4,3c93871974f094adcb8674162c59fbb455403558,," @periodic_task.periodic_task(spacing=CONF.frr_reconcile_interval, run_immediately=False) def frr_sync(self, context): LOG.info(""Running reconciliation loop to ensure frr configuration is "" ""in place."") try: self.agent_driver.frr_sync() except Exception as e: LOG.exception(""Unexpected exception while running the frr sync: "" ""%s"", e) ",,27,0
openstack%2Ftripleo-heat-templates~master~If042c7e9ead034d99c27b343bd7c442741c3c6dc,openstack/tripleo-heat-templates,master,If042c7e9ead034d99c27b343bd7c442741c3c6dc,Add support for Octavia failover circuit breaker,ABANDONED,2022-05-25 13:38:20.000000000,2023-04-14 13:55:49.000000000,,"[{'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-05-25 13:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3cb35022b443fee87b683f4c2dcf85de3f181361', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 2, 'created': '2022-05-27 09:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ae02f09e86d15b6403907d70ab9f2ec44655291', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 3, 'created': '2022-05-30 08:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2fd950eac3b87ea0325f3d9b633fd3cbdb91a1fd', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 4, 'created': '2022-09-15 15:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/82f42227abd5750d21cc77437b46d0be9632a05b', 'message': 'Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-octavia/+/857892\n\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 5, 'created': '2022-10-25 10:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06f6ea6f0ca9c0e48fc089b39edec2e80a1c2ec6', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 6, 'created': '2022-10-25 10:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/372325347cdd1823501287a053b75fe27c8ea107', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 7, 'created': '2022-11-08 16:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/484ceb54ff3690db1f6688c8d15316a3f902cf85', 'message': 'WIP Add support for Octavia failover circuit breaker\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}, {'number': 8, 'created': '2022-11-09 07:12:26.000000000', 'files': ['deployment/octavia/octavia-health-manager-container-puppet.yaml', 'releasenotes/notes/octavia-failover-threshold-4db80e6e26888a0d.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4f36c45b1d7b2372a7c6add2e086514cbfb0caf6', 'message': 'Add support for Octavia failover circuit breaker\n\nRespective change in puppet-octavia:\nI637e89a794203c393c50728b42666a0d2a104849\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/656811\nStory: 2005604\nTask: 30837\nChange-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc\n'}]",0,843285,4f36c45b1d7b2372a7c6add2e086514cbfb0caf6,28,3,8,34429,,,0,"Add support for Octavia failover circuit breaker

Respective change in puppet-octavia:
I637e89a794203c393c50728b42666a0d2a104849

Depends-On: https://review.opendev.org/c/openstack/octavia/+/656811
Story: 2005604
Task: 30837
Change-Id: If042c7e9ead034d99c27b343bd7c442741c3c6dc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/843285/5 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/octavia/octavia-health-manager-container-puppet.yaml', 'releasenotes/notes/octavia-failover-threshold-4db80e6e26888a0d.yaml']",2,3cb35022b443fee87b683f4c2dcf85de3f181361,task/30837,--- features: - | TODO ,,19,0
openstack%2Fopenstack-ansible-plugins~master~Iac723a4e748dc1a0c3769934e4ec73019e308aea,openstack/openstack-ansible-plugins,master,Iac723a4e748dc1a0c3769934e4ec73019e308aea,Workaround failures when project is unset,MERGED,2023-04-11 08:31:37.000000000,2023-04-14 13:40:13.000000000,2023-04-14 13:39:11.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-04-11 08:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/4171668fcd23dc0e11f48d796b08eb81d74e5dea', 'message': 'Workaround failures when project is unset\n\nIn cases, when we want to have only domain scope, we set project to\nan empty string or null.\n\nChange-Id: Iac723a4e748dc1a0c3769934e4ec73019e308aea\n'}, {'number': 2, 'created': '2023-04-11 08:32:08.000000000', 'files': ['roles/service_setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/a4357fbb9a43f44bfee72b01db219f080268fbe7', 'message': 'Workaround failures when project is unset\n\nIn cases, when we want to have only domain scope, we set project to\nan empty string or null.\n\nNeeded-By: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963\nChange-Id: Iac723a4e748dc1a0c3769934e4ec73019e308aea\n'}]",2,880028,a4357fbb9a43f44bfee72b01db219f080268fbe7,15,3,2,28619,,,0,"Workaround failures when project is unset

In cases, when we want to have only domain scope, we set project to
an empty string or null.

Needed-By: https://review.opendev.org/c/openstack/openstack-ansible-os_heat/+/879963
Change-Id: Iac723a4e748dc1a0c3769934e4ec73019e308aea
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/28/880028/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/service_setup/tasks/main.yml'],1,4171668fcd23dc0e11f48d796b08eb81d74e5dea,," vars: default_project: ""{{ item.project | default(_service_project_name) }}"" default_project: ""{{ (default_project is truthy) | ternary(default_project, omit) }}"""," default_project: ""{{ item.project | default(_service_project_name) }}""",3,1
openstack%2Fopenstack-ansible~master~Iac24eaca8cd6b3c6625933ed56d2d0608486d73f,openstack/openstack-ansible,master,Iac24eaca8cd6b3c6625933ed56d2d0608486d73f,docs: Add interaction section to AIO doc,MERGED,2023-04-14 12:50:27.000000000,2023-04-14 13:36:11.000000000,2023-04-14 13:34:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-14 12:50:27.000000000', 'files': ['doc/source/user/aio/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a83f53fecc69934682dd1da8776aed97471d12bc', 'message': 'docs: Add interaction section to AIO doc\n\nThe AIO quickstart doc provides no guidance for interacting with\ndeployment once it has been deployed. Add one, with the aim of providing\nenough tips and pointers to get OSA newbs (like myself) off the ground.\n\nChange-Id: Iac24eaca8cd6b3c6625933ed56d2d0608486d73f\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",1,880486,a83f53fecc69934682dd1da8776aed97471d12bc,8,3,1,15334,,,0,"docs: Add interaction section to AIO doc

The AIO quickstart doc provides no guidance for interacting with
deployment once it has been deployed. Add one, with the aim of providing
enough tips and pointers to get OSA newbs (like myself) off the ground.

Change-Id: Iac24eaca8cd6b3c6625933ed56d2d0608486d73f
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/880486/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/aio/quickstart.rst'],1,a83f53fecc69934682dd1da8776aed97471d12bc,docs,"Interacting with an AIO ----------------------- Once an AIO has been deployed, you most likely want to interact with it. You can do this via the web interface or one of the many clients or libraries that exist for OpenStack. Using a GUI ~~~~~~~~~~~ The horizon web interface provides a graphical interface for interacting with the AIO deployment. By default, the horizon API is available on port 443 of the host (or port 80, if SSL certificate configuration was disabled). As such, to interact with horizon, simply browse to the IP of the host. .. note:: If the AIO was deployed in a cloud VM, you may need to configure security groups or firewall rules to allow access to the HTTP(S) ports. For example, if the AIO was deployed in an OpenStack VM, you can create and apply a suitable security group for interacting with horizon like so: .. code-block:: shell-session $ openstack security group create http \ --description 'Allow HTTP and HTTPS access' $ openstack security group rule create http \ --protocol tcp --dst-port 80 --remote-ip 0.0.0.0/0 $ openstack security group rule create http \ --protocol tcp --dst-port 443 --remote-ip 0.0.0.0/0 $ openstack server add security group $SERVER http A list of service ports can be found in the `OpenStack Install Guide`__. .. __: https://docs.openstack.org/install-guide/firewalls-default-ports.html This will present a login page. By default, OpenStack-Ansible create a user called ``admin``. The password will be the value of the ``keystone_auth_admin_password`` variable. If you did not configure this variable, OpenStack-Ansible auto-generates one. You can view the configured password in the ``/etc/openstack_deploy/user_secrets.yml`` file. .. code-block:: shell-session # grep admin_pass /etc/openstack_deploy/user_secrets.yml heat_stack_domain_admin_password: <redacted> keystone_auth_admin_password: <redacted> radosgw_admin_password: <redacted> Using this username and password combination, log in to horizon. Using a client or library ~~~~~~~~~~~~~~~~~~~~~~~~~ There are a variety of clients and libraries available for interacting with an OpenStack deployment, including as `openstackclient`__, `openstacksdk`__, or `gophercloud`__. These are typically configured using either environment variables sourced from an ``openrc`` file or the newer ``clouds.yaml`` file. .. __: https://opendev.org/openstack/python-openstackclient .. __: https://opendev.org/openstack/openstacksdk .. __: https://opendev.org/openstack/gophercloud OpenStack-Ansible provides the ``openstack_openrc`` role for creating these configuration files as well as a number of utilities such as *openstackclient*. If the AIO deployment using the ``lxc`` scenario (the default), these will be availably in the utility container. .. code-block:: shell-session $ lxc-attach -n `lxc-ls -1 | grep utility` # ls /root/openrc /root/openrc # ls /root/.config/openstack/clouds.yaml /root/.config/openstack/clouds.yaml # export OS_CLOUD=default # openstack project list -c Name -f value service admin Alternatively, if the AIO was deployed using the ``metal`` scenario, these files will be available on the host itself. .. code-block:: shell-session # ls /root/openrc /root/openrc # ls /root/.config/openstack/clouds.yaml /root/.config/openstack/clouds.yaml If you wish to access the AIO deployment from another host - perhaps your local workstation - you will need either an ``openrc`` file or ``clouds.yaml`` file. You can download an ``openrc`` file from horizon: simply click the User dropdown in the top-right corner and select *⭳ OpenStack RC file*. .. important:: You may be tempted to copy the ``openrc`` or ``clouds.yaml`` files created by the ``openstack_openrc`` role. However, these files use the ``internal`` `interface`__ by default. This interface use the management network (``172.29.236.0/22``) , which is not routable from outside the host. If you wish to use these files, you will need to change the interface to ``public``. .. __: https://docs.openstack.org/keystone/latest/contributor/service-catalog.html#endpoints .. note:: If the AIO was deployed in a cloud VM, you may need to configure security groups or firewall rules to allow access to the various sevice ports. For example, if the AIO was deployed in an OpenStack VM, you can create and apply a suitable security group for interacting the core services like so: .. code-block:: shell-session $ openstack security group create openstack-apis \ --description 'Allow access to various OpenStack services' $ for port in 8774 8776 9292 9696 5000 8780; do openstack security group rule create openstack-apis \ --protocol tcp --dst-port ${port}:${port} --remote-ip 0.0.0.0/0 done $ openstack server add security group $SERVER openstack-apis A list of service ports can be found in the `OpenStack Install Guide`__. .. __: https://docs.openstack.org/install-guide/firewalls-default-ports.html .. note:: If you have enabled SSL certificate configuration (default), all services will use self-signed certificates. While the host is configured to trust these certificates, this is not the case for other hosts. This will result in HTTPS errors when attempting to interact with the cloud. To resolve this issue, you will need to manually configure certificates on other hosts or ignore SSL issues. You can ignore SSL issue by setting ``verify: false`` in the definition for your cloud in ``clouds.yaml``. For example:: .. code-block:: yaml clouds: aio: # ... verify: false More information about SSL certificate configuration can be found in the :doc:`security guide </user/security/ssl-certificates>`. Once one of these files have been created, you can use it to interact with your deployment using most standard clients and libraries. For example, to list available projects using *openstackclient*: .. code-block:: shell-session $ export OS_CLOUD=aio $ openstack project list -c Name -f value service admin ",,162,0
openstack%2Ftripleo-heat-templates~stable%2Fzed~Icef9c5cbed256d977590f2e38427a1155b503824,openstack/tripleo-heat-templates,stable/zed,Icef9c5cbed256d977590f2e38427a1155b503824,Add Redis password to designate central service,ABANDONED,2023-04-13 18:03:33.000000000,2023-04-14 13:18:09.000000000,,"[{'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 18:03:33.000000000', 'files': ['deployment/designate/designate-central-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8fd0b1c422f002fed59451c4e3330bbadb74fbe0', 'message': 'Add Redis password to designate central service\n\nMake sure that at the redis password is available for configuring\nprocess coordination in the event that the central and producer\nservices are spread out over separate servers via composable roles.\nThis was missed when the related change\nIcc23208945304913cdaeede703c486064646379a was proposed.\n\nNote: this patch should be backported through to wallaby for the\nrelated puppet-tripleo patch already merged.\n\nChange-Id: Icef9c5cbed256d977590f2e38427a1155b503824\n(cherry picked from commit 9b86cb7f60e1f65ac52393b677bd07926b92ba0a)\n'}]",0,880353,8fd0b1c422f002fed59451c4e3330bbadb74fbe0,3,3,1,6681,,,0,"Add Redis password to designate central service

Make sure that at the redis password is available for configuring
process coordination in the event that the central and producer
services are spread out over separate servers via composable roles.
This was missed when the related change
Icc23208945304913cdaeede703c486064646379a was proposed.

Note: this patch should be backported through to wallaby for the
related puppet-tripleo patch already merged.

Change-Id: Icef9c5cbed256d977590f2e38427a1155b503824
(cherry picked from commit 9b86cb7f60e1f65ac52393b677bd07926b92ba0a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/880353/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/designate/designate-central-container-puppet.yaml'],1,8fd0b1c422f002fed59451c4e3330bbadb74fbe0,zed, RedisPassword: description: The password for the redis service account. type: string hidden: true - designate_redis_password: {get_param: RedisPassword} designate::db::database_connection:, - designate::db::database_connection:,6,1
openstack%2Fopenstack-ansible-os_manila~master~I57df438cd25efd30e0e437470fc34df8fea1317c,openstack/openstack-ansible-os_manila,master,I57df438cd25efd30e0e437470fc34df8fea1317c,Remove unused variable,MERGED,2023-04-11 08:04:20.000000000,2023-04-14 13:07:01.000000000,2023-04-14 13:05:52.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-11 08:04:20.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_manila/commit/543e3170146b3164113fe427fa4838dda0afb6d7', 'message': 'Remove unused variable\n\nThis was introduced when the role was created using os_cinder as\na starting point [1], as has never been used in the manila role.\n\n[1] https://opendev.org/openstack/openstack-ansible-os_manila/commit/f9bfb7f0bcc5d1bf79b01a20743f4e68d7c5b202\n\nChange-Id: I57df438cd25efd30e0e437470fc34df8fea1317c\n'}]",0,880026,543e3170146b3164113fe427fa4838dda0afb6d7,8,3,1,25023,,,0,"Remove unused variable

This was introduced when the role was created using os_cinder as
a starting point [1], as has never been used in the manila role.

[1] https://opendev.org/openstack/openstack-ansible-os_manila/commit/f9bfb7f0bcc5d1bf79b01a20743f4e68d7c5b202

Change-Id: I57df438cd25efd30e0e437470fc34df8fea1317c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_manila refs/changes/26/880026/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,543e3170146b3164113fe427fa4838dda0afb6d7,,,"## Set default manila path in service units. The default override sets the ## execution path for the manila service. manila_environment_overrides: Service: Environment: ""PATH={{ manila_bin }}:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ",0,6
openstack%2Ftripleo-ansible~master~I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2,openstack/tripleo-ansible,master,I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2,Use short_hostnames when tls-everywhere is enabled,ABANDONED,2023-02-28 14:51:25.000000000,2023-04-14 12:19:14.000000000,,"[{'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 33080}, {'_account_id': 34598}]","[{'number': 1, 'created': '2023-02-28 14:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e90db5f95150ebd533337d6f6387f3ca50760e25', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}, {'number': 2, 'created': '2023-02-28 16:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/eb0f3d67c11538c0a8bb7807e47017491ba7008c', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}, {'number': 3, 'created': '2023-03-03 08:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/945dae4da2bc4c274aec52d5e20ffe5b28046e34', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}, {'number': 4, 'created': '2023-03-22 12:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/196a1b1db21e2333dccff45b93fa064d3fe1d86a', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}, {'number': 5, 'created': '2023-03-23 11:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4d96b007a82508337d9b7469d9f035ff129386b2', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}, {'number': 6, 'created': '2023-04-14 09:02:42.000000000', 'files': ['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/668b9d764f304a142984a9d4bf1d6e0625d1531d', 'message': 'Use short_hostnames when tls-everywhere is enabled\n\nNodes are enrolled and configured during the overcloud deployment, but\ndeployed ceph needs to work with short_hostnames to properly have ssh\naccess and distribute, later in the process, both private and public\nkeys.\n\nSigned-off-by: Francesco Pantano <fpantano@redhat.com>\nChange-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2\n'}]",7,875741,668b9d764f304a142984a9d4bf1d6e0625d1531d,20,4,6,25402,,,0,"Use short_hostnames when tls-everywhere is enabled

Nodes are enrolled and configured during the overcloud deployment, but
deployed ceph needs to work with short_hostnames to properly have ssh
access and distribute, later in the process, both private and public
keys.

Signed-off-by: Francesco Pantano <fpantano@redhat.com>
Change-Id: I3d591ebb9a7bdb3ad9b9da1d158df2de0405d4a2
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/41/875741/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-deployed-ceph.yaml'],1,e90db5f95150ebd533337d6f6387f3ca50760e25,fix_short_hostnames," cephadm_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname.split('.')[0] ] }}"" cephadm_non_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname.split('.')[0] ] }}"""," cephadm_admin_hosts: ""{{ cephadm_admin_hosts + [ item.hostname ] }}"" cephadm_non_admin_hosts: ""{{ cephadm_non_admin_hosts + [ item.hostname ] }}""",2,2
openstack%2Fneutron~stable%2Fzed~I5d7eb73606428841caa24ce1e38d1bebd5db0a9b,openstack/neutron,stable/zed,I5d7eb73606428841caa24ce1e38d1bebd5db0a9b,Do not check the context object in ``TestMeteringPlugin``,MERGED,2023-04-13 16:29:37.000000000,2023-04-14 12:03:46.000000000,2023-04-14 12:02:30.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 16:29:37.000000000', 'files': ['neutron/tests/unit/services/metering/test_metering_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b43c9a6ec053336af8bf6a4b0188cbd4ea2e7cb6', 'message': 'Do not check the context object in ``TestMeteringPlugin``\n\nSince [1], the admin context is not ``Context`` object created\nbut the new one created in ``ContextBase.elevated``. This method\ncopies the object itself (creating a new one), adds the ""admin""\nrole (if not present) and returns this new object.\n\nBecause this method always returns a new object, it is not possible\nto check the ``Context`` object used to make the function call, as\nlong as the test doesn\'t store the elevated context used in the call\n(apart from the reference stored in the mock object).\n\n[1]https://review.opendev.org/c/openstack/neutron-lib/+/880143\n\nCloses-Bug: #2016144\nChange-Id: I5d7eb73606428841caa24ce1e38d1bebd5db0a9b\n(cherry picked from commit c7ef8249419ecbefdc4a604a98d4b23554c78dae)\n'}]",1,880341,b43c9a6ec053336af8bf6a4b0188cbd4ea2e7cb6,9,3,1,16688,,,0,"Do not check the context object in ``TestMeteringPlugin``

Since [1], the admin context is not ``Context`` object created
but the new one created in ``ContextBase.elevated``. This method
copies the object itself (creating a new one), adds the ""admin""
role (if not present) and returns this new object.

Because this method always returns a new object, it is not possible
to check the ``Context`` object used to make the function call, as
long as the test doesn't store the elevated context used in the call
(apart from the reference stored in the mock object).

[1]https://review.opendev.org/c/openstack/neutron-lib/+/880143

Closes-Bug: #2016144
Change-Id: I5d7eb73606428841caa24ce1e38d1bebd5db0a9b
(cherry picked from commit c7ef8249419ecbefdc4a604a98d4b23554c78dae)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/880341/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/services/metering/test_metering_plugin.py'],1,b43c9a6ec053336af8bf6a4b0188cbd4ea2e7cb6,bug/2016144," self.mock_add.assert_called_with(mock.ANY, expected) self.mock_remove.assert_called_with(mock.ANY, expected) self.mock_add.assert_called_with(mock.ANY, expected_add) self.mock_remove.assert_called_with(mock.ANY, expected_remove) self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY,"," self.mock_add.assert_called_with(self.ctx, expected) self.mock_remove.assert_called_with(self.ctx, expected) self.mock_add.assert_called_with(self.ctx, expected_add) self.mock_remove.assert_called_with(self.ctx, expected_remove) self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx,",12,12
openstack%2Fneutron~stable%2F2023.1~I5d7eb73606428841caa24ce1e38d1bebd5db0a9b,openstack/neutron,stable/2023.1,I5d7eb73606428841caa24ce1e38d1bebd5db0a9b,Do not check the context object in ``TestMeteringPlugin``,MERGED,2023-04-13 16:28:04.000000000,2023-04-14 12:03:43.000000000,2023-04-14 12:02:26.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 16:28:04.000000000', 'files': ['neutron/tests/unit/services/metering/test_metering_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6efae0b110af0ea6ee92a9ef774cd702db3b834e', 'message': 'Do not check the context object in ``TestMeteringPlugin``\n\nSince [1], the admin context is not ``Context`` object created\nbut the new one created in ``ContextBase.elevated``. This method\ncopies the object itself (creating a new one), adds the ""admin""\nrole (if not present) and returns this new object.\n\nBecause this method always returns a new object, it is not possible\nto check the ``Context`` object used to make the function call, as\nlong as the test doesn\'t store the elevated context used in the call\n(apart from the reference stored in the mock object).\n\n[1]https://review.opendev.org/c/openstack/neutron-lib/+/880143\n\nCloses-Bug: #2016144\nChange-Id: I5d7eb73606428841caa24ce1e38d1bebd5db0a9b\n(cherry picked from commit c7ef8249419ecbefdc4a604a98d4b23554c78dae)\n'}]",1,880340,6efae0b110af0ea6ee92a9ef774cd702db3b834e,9,3,1,16688,,,0,"Do not check the context object in ``TestMeteringPlugin``

Since [1], the admin context is not ``Context`` object created
but the new one created in ``ContextBase.elevated``. This method
copies the object itself (creating a new one), adds the ""admin""
role (if not present) and returns this new object.

Because this method always returns a new object, it is not possible
to check the ``Context`` object used to make the function call, as
long as the test doesn't store the elevated context used in the call
(apart from the reference stored in the mock object).

[1]https://review.opendev.org/c/openstack/neutron-lib/+/880143

Closes-Bug: #2016144
Change-Id: I5d7eb73606428841caa24ce1e38d1bebd5db0a9b
(cherry picked from commit c7ef8249419ecbefdc4a604a98d4b23554c78dae)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/880340/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/services/metering/test_metering_plugin.py'],1,6efae0b110af0ea6ee92a9ef774cd702db3b834e,bug/2016144," self.mock_add.assert_called_with(mock.ANY, expected) self.mock_remove.assert_called_with(mock.ANY, expected) self.mock_add.assert_called_with(mock.ANY, expected_add) self.mock_remove.assert_called_with(mock.ANY, expected_remove) self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY, self.mock_add_rule.assert_called_with(mock.ANY, self.mock_remove_rule.assert_called_with(mock.ANY,"," self.mock_add.assert_called_with(self.ctx, expected) self.mock_remove.assert_called_with(self.ctx, expected) self.mock_add.assert_called_with(self.ctx, expected_add) self.mock_remove.assert_called_with(self.ctx, expected_remove) self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx, self.mock_add_rule.assert_called_with(self.ctx, self.mock_remove_rule.assert_called_with(self.ctx,",12,12
openstack%2Fneutron~master~I2560edb915f7393fcda50dd4a37a1d366bd0ce59,openstack/neutron,master,I2560edb915f7393fcda50dd4a37a1d366bd0ce59,[S-RBAC] Allow network owners to get ports from that network,MERGED,2023-04-07 11:25:01.000000000,2023-04-14 12:03:26.000000000,2023-04-14 12:02:22.000000000,"[{'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 33983}]","[{'number': 1, 'created': '2023-04-07 11:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/debf9449b36633791b0608f37c7ef748d6c64360', 'message': '[S-RBAC] Allow network owners to get ports from that network\n\nIt was somehow missed initially when we wrote new Secure RBAC policies\nbut network owner should be able to see all ports created on the\nnetwork.\n\nChange-Id: I2560edb915f7393fcda50dd4a37a1d366bd0ce59\n'}, {'number': 2, 'created': '2023-04-12 08:15:14.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/conf/policies/port.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8eecccfeae1cef3585cafa2046e85362b4e0d875', 'message': ""[S-RBAC] Allow network owners to get ports from that network\n\nIt was somehow missed initially when we wrote new Secure RBAC policies\nbut network owner should be able to see all ports created on the\nnetwork.\n\nAdditionally this patch adds mock of the neutron.policy.check function\nin TestMl2DbOperationBounds class as this class is expected to check\nDbOperators made by ML2 plugin while listing ports so there's no need to\ninclude policy checks there too.\n\nChange-Id: I2560edb915f7393fcda50dd4a37a1d366bd0ce59\n""}]",9,879891,8eecccfeae1cef3585cafa2046e85362b4e0d875,22,5,2,11975,,,0,"[S-RBAC] Allow network owners to get ports from that network

It was somehow missed initially when we wrote new Secure RBAC policies
but network owner should be able to see all ports created on the
network.

Additionally this patch adds mock of the neutron.policy.check function
in TestMl2DbOperationBounds class as this class is expected to check
DbOperators made by ML2 plugin while listing ports so there's no need to
include policy checks there too.

Change-Id: I2560edb915f7393fcda50dd4a37a1d366bd0ce59
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/879891/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/policies/port.py'],1,debf9449b36633791b0608f37c7ef748d6c64360,secure-rbac," base.RULE_NET_OWNER,",,1,0
openstack%2Fcharm-glance-k8s~main~I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7,openstack/charm-glance-k8s,main,I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7,Update kubernetes_service_patch to v1,MERGED,2023-04-13 08:20:16.000000000,2023-04-14 11:55:53.000000000,2023-04-14 11:04:56.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 08:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/a93fe85ae48a684d3f458eb8f5b6744937b1c508', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}, {'number': 2, 'created': '2023-04-13 09:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/2a1f1ea58779e396e66cc445c7aae998869c83cc', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}, {'number': 3, 'created': '2023-04-14 08:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/e104372536acdbfb7f4ac8612e6d63972d93a6f5', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}, {'number': 4, 'created': '2023-04-14 09:25:46.000000000', 'files': ['tests/unit/test_glance_charm.py', 'lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'charmcraft.yaml', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/3837495bf9b5ac40d8f37c03ae93b340b6595c71', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880272,3837495bf9b5ac40d8f37c03ae93b340b6595c71,13,2,4,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Change-Id: I3d231d12eaddb71f4f532cffc27b7ed5ab4e52e7
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-glance-k8s refs/changes/72/880272/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_glance_charm.py', 'lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'fetch-libs.sh']",3,a93fe85ae48a684d3f458eb8f5b6744937b1c508,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,charmcraft fetch-lib charms.observability_libs.v0.kubernetes_service_patch,114,52
openstack%2Fcharm-placement-k8s~main~Iaa89a9b1127a967e714b543adb428179de05e323,openstack/charm-placement-k8s,main,Iaa89a9b1127a967e714b543adb428179de05e323,Update kubernetes_service_patch to v1,MERGED,2023-04-13 12:05:07.000000000,2023-04-14 11:38:08.000000000,2023-04-14 10:37:07.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement-k8s/commit/7cbb9a1b65eaa5be28ec967bb4935af1df6d1dd7', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: Iaa89a9b1127a967e714b543adb428179de05e323\n'}, {'number': 2, 'created': '2023-04-14 08:21:37.000000000', 'files': ['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/unit/test_placement_charm.py', 'charmcraft.yaml', 'lib/charms/observability_libs/v0/kubernetes_service_patch.py', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-placement-k8s/commit/ed2bc0eec0b9b9e404dc869b46f69478e6c4c1e1', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: Iaa89a9b1127a967e714b543adb428179de05e323\n'}]",0,880289,ed2bc0eec0b9b9e404dc869b46f69478e6c4c1e1,9,2,2,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
Change-Id: Iaa89a9b1127a967e714b543adb428179de05e323
",git fetch https://review.opendev.org/openstack/charm-placement-k8s refs/changes/89/880289/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/unit/test_placement_charm.py', 'lib/charms/observability_libs/v0/kubernetes_service_patch.py', 'fetch-libs.sh']",4,7cbb9a1b65eaa5be28ec967bb4935af1df6d1dd7,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,,344,242
openstack%2Fhorizon~stable%2Ftrain~Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5,openstack/horizon,stable/train,Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5,zuul: Declare queue at top level,MERGED,2023-03-30 16:57:24.000000000,2023-04-14 11:24:13.000000000,2023-04-14 11:22:06.000000000,"[{'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-30 16:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7558c467516fd58eeabfb3a04ff23c123ee2524b', 'message': 'zuul: Declare queue at top level\n\nZuul deprecated declaring shared queues at a pipeline level with\nrelease 4.1.0[1]. This updates the job definition to use the top level\ndeclaration instead.\n\nSee [2] for details.\n\n[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n\nChange-Id: Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5\n(cherry picked from commit 4212950a4a6b036f563a236cb005604e1c096f04)\n'}, {'number': 2, 'created': '2023-03-30 17:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/168fc8fa6c6c411ccf9c955408f99644329ae2fa', 'message': 'zuul: Declare queue at top level\n\nZuul deprecated declaring shared queues at a pipeline level with\nrelease 4.1.0[1]. This updates the job definition to use the top level\ndeclaration instead.\n\nSee [2] for details.\n\n[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n\nChange-Id: Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5\n(cherry picked from commit 4212950a4a6b036f563a236cb005604e1c096f04)\n'}, {'number': 3, 'created': '2023-03-30 17:06:10.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c74d6793215e9e170afb5ad8054bbd23e637cd41', 'message': 'zuul: Declare queue at top level\n\nZuul deprecated declaring shared queues at a pipeline level with\nrelease 4.1.0[1]. This updates the job definition to use the top level\ndeclaration instead.\n\nSee [2] for details.\n\n[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n\nChange-Id: Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5\n(cherry picked from commit 4212950a4a6b036f563a236cb005604e1c096f04)\n'}]",1,878845,c74d6793215e9e170afb5ad8054bbd23e637cd41,13,3,3,29313,,,0,"zuul: Declare queue at top level

Zuul deprecated declaring shared queues at a pipeline level with
release 4.1.0[1]. This updates the job definition to use the top level
declaration instead.

See [2] for details.

[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes
[2] http://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html

Change-Id: Ie63dd3b161cb8fd9be89002027d699ce2c4a67a5
(cherry picked from commit 4212950a4a6b036f563a236cb005604e1c096f04)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/45/878845/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,7558c467516fd58eeabfb3a04ff23c123ee2524b,fix-queue-config-stable/train,"<<<<<<< HEAD (d3d3d1 Merge ""Change to a proper policy for Resume operation"" into ) ======= - project: queue: horizon templates: - check-requirements - horizon-cross-jobs - horizon-nodejs-jobs - horizon-non-primary-django-jobs - openstack-lower-constraints-jobs - openstack-python3-zed-jobs - periodic-stable-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 check: jobs: - horizon-selenium-headless - horizon-integration-tests - horizon-dsvm-tempest-plugin - horizon-tox-bandit-baseline - horizon-tempest-plugin-ipv6 gate: jobs: - horizon-dsvm-tempest-plugin - horizon-selenium-headless - horizon-integration-tests - horizon-tempest-plugin-ipv6 experimental: jobs: - horizon-integration-tests-xstatic-master - horizon-tox-py36-xstatic-master - horizon-nodejs16-run-test-xstatic-master periodic: jobs: - horizon-nodejs16-run-test - horizon-integration-tests >>>>>>> CHANGE (421295 zuul: Declare queue at top level) ",,37,0
openstack%2Fopenstacksdk~master~I9c852360b2e71f6e0a2cfd45c0a77690220379cd,openstack/openstacksdk,master,I9c852360b2e71f6e0a2cfd45c0a77690220379cd,Add resize/extend share actions.,MERGED,2023-03-29 22:14:58.000000000,2023-04-14 11:13:53.000000000,2023-04-14 11:12:31.000000000,"[{'_account_id': 15334}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 35745}]","[{'number': 1, 'created': '2023-03-29 22:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b44285c015e984cb76dc29225cd560bf7d4de79b', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 2, 'created': '2023-04-04 02:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/66e820505456cd5e6842ff31d6d46a23c06e400a', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 3, 'created': '2023-04-04 02:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f39db8a63430f0a4e4aae8e0463532e43305821a', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 4, 'created': '2023-04-04 03:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/40caeb6613c7dde05a1a09003092aecd21f1eece', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 5, 'created': '2023-04-04 04:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/aaa4a5629230580102de0522be864d5fbe45f8c6', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 6, 'created': '2023-04-04 05:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9d65ff173f4612cc2b1a30015b4a77ea5596164f', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 7, 'created': '2023-04-04 20:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6a794908b15a15a1da43ec3b158ef4a80dddf817', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API. Includes the resize_share\nmethod in the proxy.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}, {'number': 8, 'created': '2023-04-11 18:51:41.000000000', 'files': ['openstack/tests/unit/shared_file_system/v2/test_share.py', 'releasenotes/notes/add-shared-file-system-share-resize-ddd650c2e32fed34.yaml', 'openstack/tests/unit/shared_file_system/v2/test_proxy.py', 'doc/source/user/proxies/shared_file_system.rst', 'openstack/shared_file_system/v2/share.py', 'examples/shared_file_system/shares.py', 'openstack/shared_file_system/v2/_proxy.py', 'openstack/tests/functional/shared_file_system/test_share.py', 'doc/source/user/guides/shared_file_system.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c3e77fc61e8082f281ce3f37cef95b30b9180668', 'message': 'Add resize/extend share actions.\n\nAdds the resize/extend actions from the\nShare actions API. Includes the resize_share\nmethod in the proxy.\n\nChange-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd\n'}]",20,879005,c3e77fc61e8082f281ce3f37cef95b30b9180668,28,5,8,35745,,,0,"Add resize/extend share actions.

Adds the resize/extend actions from the
Share actions API. Includes the resize_share
method in the proxy.

Change-Id: I9c852360b2e71f6e0a2cfd45c0a77690220379cd
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/05/879005/7 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/shared_file_system/v2/test_share.py', 'releasenotes/notes/add-shared-file-system-share-resize-ddd650c2e32fed34.yaml', 'doc/source/user/proxies/shared_file_system.rst', 'openstack/shared_file_system/v2/share.py', 'examples/shared_file_system/shares.py', 'openstack/shared_file_system/v2/_proxy.py', 'openstack/tests/functional/shared_file_system/test_share.py', 'doc/source/user/guides/shared_file_system.rst']",8,b44285c015e984cb76dc29225cd560bf7d4de79b,manila," Resize Share ----------------------- Shared File System shares can be resized (extended or shrunk) to a given size. For details on resizing shares, refer to the `Manila docs <https://docs.openstack.org/manila/latest/admin/shared-file-systems-share-resize.html>`_. .. literalinclude:: ../examples/shared_file_system/shares.py :pyobject: shrink_share .. literalinclude:: ../examples/shared_file_system/shares.py :pyobject: extend_share ",,225,5
openstack%2Fdevstack~stable%2Fzed~I5b77a53372f4f0b7f73a87dc3666ba1c4799490f,openstack/devstack,stable/zed,I5b77a53372f4f0b7f73a87dc3666ba1c4799490f,[WIP] reload ovs modules,NEW,2023-04-14 11:10:12.000000000,2023-04-14 11:13:06.000000000,,[],"[{'number': 1, 'created': '2023-04-14 11:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/16b0d689961c35b9bb6a27b626af6e6c200c7b07', 'message': '[WIP] reload ovs modules\n\nRelated-Bug: #2015364\nChange-Id: I5b77a53372f4f0b7f73a87dc3666ba1c4799490f\n'}, {'number': 2, 'created': '2023-04-14 11:13:06.000000000', 'files': ['lib/neutron_plugins/ovs_source', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c3f1fc88795add4a93a5410426d50f7ed6361189', 'message': '[WIP] reload ovs modules\n\nRelated-Bug: #2015364\nChange-Id: I5b77a53372f4f0b7f73a87dc3666ba1c4799490f\n'}]",0,880481,c3f1fc88795add4a93a5410426d50f7ed6361189,2,0,2,13861,,,0,"[WIP] reload ovs modules

Related-Bug: #2015364
Change-Id: I5b77a53372f4f0b7f73a87dc3666ba1c4799490f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/81/880481/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/ovs_source'],1,16b0d689961c35b9bb6a27b626af6e6c200c7b07,bug/2015364, reload_ovs_kernel_modules, reload_ovs_kernel_modules else load_ovs_kernel_modules,1,3
openstack%2Fcharm-cinder-k8s~main~I966d3970947135607ed1cc83b67506dded039ef5,openstack/charm-cinder-k8s,main,I966d3970947135607ed1cc83b67506dded039ef5,Update kubernetes_service_patch to v1,MERGED,2023-04-13 12:23:55.000000000,2023-04-14 10:55:08.000000000,2023-04-14 09:54:03.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-k8s/commit/72693ea28f3c5791e140b8e4808f23b32b2b63f5', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I966d3970947135607ed1cc83b67506dded039ef5\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}, {'number': 2, 'created': '2023-04-14 08:20:52.000000000', 'files': ['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'charmcraft.yaml', 'tests/unit/test_cinder_charm.py', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-cinder-k8s/commit/ebace8dc0f12d748c0aa54544310b0448947d1ac', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I966d3970947135607ed1cc83b67506dded039ef5\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880295,ebace8dc0f12d748c0aa54544310b0448947d1ac,9,2,2,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Change-Id: I966d3970947135607ed1cc83b67506dded039ef5
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-cinder-k8s refs/changes/95/880295/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/unit/test_cinder_charm.py', 'fetch-libs.sh']",3,72693ea28f3c5791e140b8e4808f23b32b2b63f5,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,charmcraft fetch-lib charms.observability_libs.v0.kubernetes_service_patch,113,51
openstack%2Fcharm-horizon-k8s~main~I0739774a8840001e03f49d41f157dee4e18c9067,openstack/charm-horizon-k8s,main,I0739774a8840001e03f49d41f157dee4e18c9067,Update kubernetes_service_patch to v1,MERGED,2023-04-13 12:10:55.000000000,2023-04-14 10:54:42.000000000,2023-04-14 09:53:40.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/f0631217f75434a86231d8bd2d60a2f320b4c6b1', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I0739774a8840001e03f49d41f157dee4e18c9067\n'}, {'number': 2, 'created': '2023-04-14 08:22:28.000000000', 'files': ['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'charmcraft.yaml', 'tests/unit/test_dashboard_charm.py', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/af26240d033be1c1880103581adb3412708b1500', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\nChange-Id: I0739774a8840001e03f49d41f157dee4e18c9067\n'}]",0,880291,af26240d033be1c1880103581adb3412708b1500,11,3,2,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
Change-Id: I0739774a8840001e03f49d41f157dee4e18c9067
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/91/880291/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'tests/unit/test_dashboard_charm.py', 'fetch-libs.sh']",3,f0631217f75434a86231d8bd2d60a2f320b4c6b1,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,charmcraft fetch-lib charms.observability_libs.v0.kubernetes_service_patch,113,51
openstack%2Fcharm-neutron-k8s~main~I1d31310ce106d05bdce411eebe1251b2a605b15d,openstack/charm-neutron-k8s,main,I1d31310ce106d05bdce411eebe1251b2a605b15d,Update kubernetes_service_patch to v1,MERGED,2023-04-13 12:19:38.000000000,2023-04-14 10:51:33.000000000,2023-04-14 09:50:38.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 12:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/aee1dd273b157187c3a9cb75799427de3fa85cc5', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I1d31310ce106d05bdce411eebe1251b2a605b15d\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}, {'number': 2, 'created': '2023-04-14 08:20:04.000000000', 'files': ['tests/unit/test_neutron_charm.py', 'lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'charmcraft.yaml', 'fetch-libs.sh'], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/21e92120c6fd7b8bb51175478a0655508b772da0', 'message': 'Update kubernetes_service_patch to v1\n\nv1 of the kubernetes_service_patch lib will patches the service\ndefinition on `status_update` event. This helps when Juju refreshes the\npatched services to their initial state.\n\nDepends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270\nChange-Id: I1d31310ce106d05bdce411eebe1251b2a605b15d\nSigned-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>\n'}]",0,880294,21e92120c6fd7b8bb51175478a0655508b772da0,9,2,2,35761,,,0,"Update kubernetes_service_patch to v1

v1 of the kubernetes_service_patch lib will patches the service
definition on `status_update` event. This helps when Juju refreshes the
patched services to their initial state.

Depends-On: https://review.opendev.org/c/openstack/charm-ops-sunbeam/+/880270
Change-Id: I1d31310ce106d05bdce411eebe1251b2a605b15d
Signed-off-by: Guillaume Boutry <guillaume.boutry@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-neutron-k8s refs/changes/94/880294/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_neutron_charm.py', 'lib/charms/observability_libs/v1/kubernetes_service_patch.py', 'fetch-libs.sh']",3,aee1dd273b157187c3a9cb75799427de3fa85cc5,obs-kube-patcher-v1,charmcraft fetch-lib charms.observability_libs.v1.kubernetes_service_patch,charmcraft fetch-lib charms.observability_libs.v0.kubernetes_service_patch,113,51
openstack%2Fopenstack-ansible-os_neutron~stable%2Fyoga~I8bee1850e3a120f7b76f586909e6d74361696e32,openstack/openstack-ansible-os_neutron,stable/yoga,I8bee1850e3a120f7b76f586909e6d74361696e32,Workaround ovs bug that resets hostname with add command,ABANDONED,2023-03-31 14:38:03.000000000,2023-04-14 10:42:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 34411}]","[{'number': 1, 'created': '2023-03-31 14:38:03.000000000', 'files': ['tasks/providers/ovn_config.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/ef3cdab7b6e3ccda6d1d2c70ccd5b4f4680c95da', 'message': ""Workaround ovs bug that resets hostname with add command\n\nAfter RDO bumped OVS version to 3.1 from 2.17 CentOS/Rocky fails\ntempest testing due to systemd unit calling adding hostname [1]\nwhile ovs-vsctl add in 3.1 actually behaves exactly as `set` which\nsimply resets defined hostname on each service restart. To avoid that\nwe're adding `--no-record-hostname` flag that will prevent such\nbehaviour.\n\n[1] https://github.com/openvswitch/ovs/blob/branch-3.1/utilities/ovs-ctl.in#L51\n\nChange-Id: I8bee1850e3a120f7b76f586909e6d74361696e32\nRelated-Bug: #2013189\n(cherry picked from commit f1a8c358531bdf86d8aeda725bc0b1c347d325c1)\n""}]",1,879173,ef3cdab7b6e3ccda6d1d2c70ccd5b4f4680c95da,5,3,1,28619,,,0,"Workaround ovs bug that resets hostname with add command

After RDO bumped OVS version to 3.1 from 2.17 CentOS/Rocky fails
tempest testing due to systemd unit calling adding hostname [1]
while ovs-vsctl add in 3.1 actually behaves exactly as `set` which
simply resets defined hostname on each service restart. To avoid that
we're adding `--no-record-hostname` flag that will prevent such
behaviour.

[1] https://github.com/openvswitch/ovs/blob/branch-3.1/utilities/ovs-ctl.in#L51

Change-Id: I8bee1850e3a120f7b76f586909e6d74361696e32
Related-Bug: #2013189
(cherry picked from commit f1a8c358531bdf86d8aeda725bc0b1c347d325c1)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/73/879173/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/providers/ovn_config.yml'],1,ef3cdab7b6e3ccda6d1d2c70ccd5b4f4680c95da,osa/rdo_ovs_3.1-stable/yoga,"# NOTE(noonedeapdunk): ovs 3.1 installed by rdo now has a bug, where # `ovs-vsctl add` acts exactly as `set` and resets hostname # so we fully disable functionality of managing hostnames # Ubuntu in it's place don't run this vulnerable version and # passes --no-record-hostname in systemd unit file already - name: Disable seetting ovs hostname for RHEL lineinfile: path: /etc/sysconfig/openvswitch line: OPTIONS=""--no-record-hostname"" search_string: 'OPTIONS=' when: - ansible_facts['pkg_mgr'] == 'dnf' - neutron_services['neutron-ovn-controller']['group'] in group_names ",,14,0
openstack%2Foctavia~master~I6ba3e699cf35b7364f933abf5ecf12fa699d1049,openstack/octavia,master,I6ba3e699cf35b7364f933abf5ecf12fa699d1049,DNM: test new slurp job,ABANDONED,2023-02-06 08:56:27.000000000,2023-04-14 10:40:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-02-06 08:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f38c36e3697ab4bcd1dd47a9b24638da9c75c8e5', 'message': 'DNM: test new tick-tock job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}, {'number': 2, 'created': '2023-02-06 09:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ad36c4e1808895b7a8c8f30cc6bdbf51d3684b71', 'message': 'DNM: test new tick-tock job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}, {'number': 3, 'created': '2023-02-06 09:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/24d0e834f48a288c2c22552d8e411227b67dd31a', 'message': 'DNM: test new tick-tock job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}, {'number': 4, 'created': '2023-02-10 07:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/48b281deeb38ec8e35222bed5695fc765e1e18f5', 'message': 'DNM: test new tick-tock job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}, {'number': 5, 'created': '2023-02-10 08:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7960f0d9f55cbd6d24b58e5f2d88954a0fa4f936', 'message': 'DNM: test new tick-tock job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}, {'number': 6, 'created': '2023-02-10 08:34:55.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/653c59401ef9e643830ef11e84cf456d8d6f49f3', 'message': 'DNM: test new slurp job\n\nChange-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049\n'}]",2,872734,653c59401ef9e643830ef11e84cf456d8d6f49f3,16,1,6,34429,,,0,"DNM: test new slurp job

Change-Id: I6ba3e699cf35b7364f933abf5ecf12fa699d1049
",git fetch https://review.opendev.org/openstack/octavia refs/changes/34/872734/5 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,f38c36e3697ab4bcd1dd47a9b24638da9c75c8e5,grenade-skiplevel,# - openstack-tox-pip-check-reqs: # irrelevant-files: # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^etc/.*$ # - ^octavia/tests/.*$ # - ^releasenotes/.*$ # - openstack-tox-functional-py38: # irrelevant-files: # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^etc/.*$ # - ^octavia/tests/unit/.*$ # - ^releasenotes/.*$ # - openstack-tox-functional-py39: # irrelevant-files: # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^etc/.*$ # - ^octavia/tests/unit/.*$ # - ^releasenotes/.*$ # - openstack-tox-functional-py310: # irrelevant-files: # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^etc/.*$ # - ^octavia/tests/unit/.*$ # - ^releasenotes/.*$ # voting: false # - octavia-v2-dsvm-noop-api: # irrelevant-files: &irrelevant-files # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^octavia/tests/.*$ # - ^releasenotes/.*$ # - octavia-v2-dsvm-scenario: # irrelevant-files: *irrelevant-files # - octavia-v2-dsvm-tls-barbican: # irrelevant-files: *irrelevant-files # - octavia-grenade: # irrelevant-files: # - ^.*\.rst$ # - ^api-ref/.*$ # - ^doc/.*$ # - ^octavia/tests/.*$ # - ^releasenotes/.*$ # - ^setup.cfg$ # - ^tools/.*$ # - ^(test-|)requirements.txt$ # - ^tox.ini$ # - octavia-v2-dsvm-tls-barbican-fips: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-act-stdby-dsvm-scenario: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-dsvm-cinder-amphora: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-dsvm-scenario-two-node: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-dsvm-scenario-ipv6-only: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-dsvm-scenario-amphora-v2: # irrelevant-files: *irrelevant-files # voting: false # - octavia-v2-dsvm-scenario-amphora-v2-no-jobboard: # irrelevant-files: *irrelevant-files # voting: false - octavia-grenade-tick-tock:, - openstack-tox-pip-check-reqs: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^octavia/tests/.*$ - ^releasenotes/.*$ - openstack-tox-functional-py38: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^octavia/tests/unit/.*$ - ^releasenotes/.*$ - openstack-tox-functional-py39: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^octavia/tests/unit/.*$ - ^releasenotes/.*$ - openstack-tox-functional-py310: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^octavia/tests/unit/.*$ - ^releasenotes/.*$ voting: false - octavia-v2-dsvm-noop-api: irrelevant-files: &irrelevant-files - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^octavia/tests/.*$ - ^releasenotes/.*$ - octavia-v2-dsvm-scenario: irrelevant-files: *irrelevant-files - octavia-v2-dsvm-tls-barbican: irrelevant-files: *irrelevant-files - octavia-grenade: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^octavia/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^(test-|)requirements.txt$ - ^tox.ini$ - octavia-v2-dsvm-tls-barbican-fips: irrelevant-files: *irrelevant-files voting: false - octavia-v2-act-stdby-dsvm-scenario: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-cinder-amphora: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-scenario-two-node: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-scenario-ipv6-only: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-scenario-amphora-v2: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-scenario-amphora-v2-no-jobboard: irrelevant-files: *irrelevant-files voting: false - octavia-v2-dsvm-scenario-centos-9-stream:,77,77
openstack%2Foctavia~master~I8e8e67902448b31631464b06058a249c74eec3f6,openstack/octavia,master,I8e8e67902448b31631464b06058a249c74eec3f6,DNM: testing octavia jobs on Ubuntu jammy (22.04),ABANDONED,2022-10-14 12:11:38.000000000,2023-04-14 10:39:26.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-14 12:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/74dd2b7fcd463e577394d53114c83eb2e940afcb', 'message': 'DNM: testing octavia jobs on Ubuntu jammy (22.04)\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/861110\nChange-Id: I8e8e67902448b31631464b06058a249c74eec3f6\n'}, {'number': 2, 'created': '2022-10-18 09:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d91da6ba5f860405c1b8a71709a61ba6bb62dd1a', 'message': 'DNM: testing octavia jobs on Ubuntu jammy (22.04)\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/861110\nChange-Id: I8e8e67902448b31631464b06058a249c74eec3f6\n'}, {'number': 3, 'created': '2022-10-20 09:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/549deacefb4c0f946ff18ce62e44cdb4d9b886d4', 'message': 'DNM: testing octavia jobs on Ubuntu jammy (22.04)\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/861110\nChange-Id: I8e8e67902448b31631464b06058a249c74eec3f6\n'}, {'number': 4, 'created': '2022-10-20 09:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7f7686f330fe64b623c3d3fa7bea44a31a3c23c9', 'message': 'DNM: testing octavia jobs on Ubuntu jammy (22.04)\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/861110\nChange-Id: I8e8e67902448b31631464b06058a249c74eec3f6\n'}, {'number': 5, 'created': '2022-11-24 15:25:52.000000000', 'files': ['octavia/opts.py', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e785a0d0221a4a52600e14871ec97078b5913cb0', 'message': 'DNM: testing octavia jobs on Ubuntu jammy (22.04)\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/861110\nChange-Id: I8e8e67902448b31631464b06058a249c74eec3f6\n'}]",3,861366,e785a0d0221a4a52600e14871ec97078b5913cb0,14,1,5,34429,,,0,"DNM: testing octavia jobs on Ubuntu jammy (22.04)

Depends-On: https://review.opendev.org/c/openstack/tempest/+/861110
Change-Id: I8e8e67902448b31631464b06058a249c74eec3f6
",git fetch https://review.opendev.org/openstack/octavia refs/changes/66/861366/3 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,74dd2b7fcd463e577394d53114c83eb2e940afcb,migrate-to-jammy, .. _octavia-style-commandments:,.. _octavia-style-commandments:,1,1
openstack%2Fkolla-ansible~master~Ie2d9a0501fe29bfd854eb31258f282b197855948,openstack/kolla-ansible,master,Ie2d9a0501fe29bfd854eb31258f282b197855948,Fix merge action plugins verbose output,MERGED,2023-04-01 21:41:57.000000000,2023-04-14 10:37:51.000000000,2023-04-14 10:36:45.000000000,"[{'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-04-01 21:41:57.000000000', 'files': ['ansible/action_plugins/merge_yaml.py', 'ansible/action_plugins/merge_configs.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8972241dc9736109f9d98552035e7557c366bf94', 'message': ""Fix merge action plugins verbose output\n\nThis change fixes the output 'module_args' information of the plugins\n'merge_configs' and 'merge_yaml' when Ansible is executed in maximum\nverbose mode. Now all the plugin options are displayed instead of\nstandard 'copy' plugin options only.\n\nAlso, this change contains fixes already applied in the Kayobe\nproject to improve and synchronize the code of the plugins between\nprojects.\n\nChange-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}]",1,879221,8972241dc9736109f9d98552035e7557c366bf94,12,4,1,14200,,,0,"Fix merge action plugins verbose output

This change fixes the output 'module_args' information of the plugins
'merge_configs' and 'merge_yaml' when Ansible is executed in maximum
verbose mode. Now all the plugin options are displayed instead of
standard 'copy' plugin options only.

Also, this change contains fixes already applied in the Kayobe
project to improve and synchronize the code of the plugins between
projects.

Change-Id: Ie2d9a0501fe29bfd854eb31258f282b197855948
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/21/879221/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/action_plugins/merge_configs.py', 'ansible/action_plugins/merge_yaml.py']",2,8972241dc9736109f9d98552035e7557c366bf94,fix-merge-action-plugins,"import yaml if source and os.access(source, os.R_OK): result = yaml.safe_load(template_data) f.write(yaml.dump(output, default_flow_style=False)) copy_result = copy_action.run(task_vars=task_vars) copy_result['invocation']['module_args'].update({ 'src': result_file, 'sources': sources, 'extend_lists': extend_lists}) result.update(copy_result)","from yaml import dump from yaml import safe_load if os.access(source, os.R_OK): result = safe_load(template_data) f.write(dump(output, default_flow_style=False)) result.update(copy_action.run(task_vars=task_vars))",16,9
openstack%2Foctavia~master~I3706fd5e12e17be37edce974563c6806d4f09709,openstack/octavia,master,I3706fd5e12e17be37edce974563c6806d4f09709,allowed_cidr validation for additional_vips,MERGED,2023-03-02 09:09:44.000000000,2023-04-14 10:25:46.000000000,2023-04-14 10:24:35.000000000,"[{'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-03-02 09:09:44.000000000', 'files': ['octavia/tests/unit/network/drivers/neutron/test_allowed_address_pairs.py', 'octavia/network/drivers/neutron/allowed_address_pairs.py', 'releasenotes/notes/allowed_cidr-validation-for-additional_vips-175c32824cc7ee95.yaml', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/api/v2/controllers/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/60f579b64a8f603e5a67860a90cd413a0e9ca381', 'message': 'allowed_cidr validation for additional_vips\n\nThe validation for the allowed_cidr parameter did not take into account\nthe IP version of additional vIPs. The parameter was rejected if the IP\nversion did not match the IP version of the primary vIP. As additional\nvIPs can have a different IP version from the primary vIP all vIPs must\nbe checked during validation.\n\nChange-Id: I3706fd5e12e17be37edce974563c6806d4f09709\n'}]",1,876042,60f579b64a8f603e5a67860a90cd413a0e9ca381,8,3,1,11290,,,0,"allowed_cidr validation for additional_vips

The validation for the allowed_cidr parameter did not take into account
the IP version of additional vIPs. The parameter was rejected if the IP
version did not match the IP version of the primary vIP. As additional
vIPs can have a different IP version from the primary vIP all vIPs must
be checked during validation.

Change-Id: I3706fd5e12e17be37edce974563c6806d4f09709
",git fetch https://review.opendev.org/openstack/octavia refs/changes/42/876042/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/network/drivers/neutron/test_allowed_address_pairs.py', 'octavia/network/drivers/neutron/allowed_address_pairs.py', 'releasenotes/notes/allowed_cidr-validation-for-additional_vips-175c32824cc7ee95.yaml', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/api/v2/controllers/listener.py']",5,60f579b64a8f603e5a67860a90cd413a0e9ca381,multi-vip-allowed-cidr," def _validate_cidr_compatible_with_vip(self, vips, allowed_cidrs): for cidr in allowed_cidrs: for vip in vips: # Check if CIDR IP version matches VIP IP version if (common_utils.is_cidr_ipv6(cidr) == common_utils.is_ipv6(vip)): break else: msg = _(""CIDR %(cidr)s IP version incompatible with all VIPs "" ""%(vips)s IP version."") detail=msg % {'cidr': cidr, 'vips': vips}) lb_db = self.repositories.load_balancer.get( lock_session, id=lb_id) vip_addresses = [lb_db.vip.ip_address] vip_addresses.extend([vip.ip_address for vip in lb_db.additional_vips]) self._validate_cidr_compatible_with_vip(vip_addresses, allowed_cidrs) vip_addresses = [db_listener.load_balancer.vip.ip_address] vip_addresses.extend( [vip.ip_address for vip in db_listener.load_balancer.additional_vips] ) vip_addresses, listener.allowed_cidrs)"," def _validate_cidr_compatible_with_vip(self, vip, allowed_cidrs): for cidr in allowed_cidrs: # Check if CIDR IP version matches VIP IP version if common_utils.is_cidr_ipv6(cidr) != common_utils.is_ipv6(vip): msg = _(""CIDR %(cidr)s IP version incompatible with VIP "" ""%(vip)s IP version."") detail=msg % {'cidr': cidr, 'vip': vip}) vip_db = self.repositories.vip.get( lock_session, load_balancer_id=lb_id) vip_address = vip_db.ip_address self._validate_cidr_compatible_with_vip(vip_address, allowed_cidrs) vip_address = db_listener.load_balancer.vip.ip_address vip_address, listener.allowed_cidrs)",107,37
openstack%2Fglance~master~I5d398277b01a114cfb74af6458f8bee30a812cc5,openstack/glance,master,I5d398277b01a114cfb74af6458f8bee30a812cc5,Fix glance download with wrong checksum,NEW,2023-03-27 08:57:17.000000000,2023-04-14 10:23:24.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-27 08:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d4f06afa2d5e0aa2a2501d621755b55e254e9963', 'message': 'Fix glance download with wrong checksum\n\nThe glance download is broken with glance cache enabled and wrong\nchecksum because the save and reraise the exeption in glance cache.\n\nCloses-Bug: #2012898\nChange-Id: I5d398277b01a114cfb74af6458f8bee30a812cc5\n'}, {'number': 2, 'created': '2023-03-27 09:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e90ed3941fb260e7b16e986b0dd62e2d6d2fc079', 'message': 'Fix glance download with wrong checksum\n\nThe glance download is broken with glance cache enabled and wrong\nchecksum because the save and reraise the exeption in glance cache.\n\nCloses-Bug: #2012898\nChange-Id: I5d398277b01a114cfb74af6458f8bee30a812cc5\n'}, {'number': 3, 'created': '2023-03-27 12:05:20.000000000', 'files': ['glance/tests/unit/test_image_cache.py', 'glance/image_cache/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/5ea5a4f95dcf23b381d2c7fbfcac535ef8644c52', 'message': 'Fix glance download with wrong checksum\n\nThe glance download is broken with glance cache enabled and wrong\nchecksum because the save and reraise the exeption in glance cache.\n\nCloses-Bug: #2012898\nChange-Id: I5d398277b01a114cfb74af6458f8bee30a812cc5\n'}]",3,878633,5ea5a4f95dcf23b381d2c7fbfcac535ef8644c52,14,1,3,33607,,,0,"Fix glance download with wrong checksum

The glance download is broken with glance cache enabled and wrong
checksum because the save and reraise the exeption in glance cache.

Closes-Bug: #2012898
Change-Id: I5d398277b01a114cfb74af6458f8bee30a812cc5
",git fetch https://review.opendev.org/openstack/glance refs/changes/33/878633/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/image_cache/__init__.py'],1,d4f06afa2d5e0aa2a2501d621755b55e254e9963,bug-2012898," # image_iter has given us bad, (size_checked_iter has found a # bad length), or corrupt data (checksum is wrong). # NOTE(plibeau): bug #2012898 we don't want save and reraise # exception because this action broke the customer download LOG.exception(encodeutils.exception_to_unicode(e))"," with excutils.save_and_reraise_exception(): # image_iter has given us bad, (size_checked_iter has found a # bad length), or corrupt data (checksum is wrong). LOG.exception(encodeutils.exception_to_unicode(e))",5,4
openstack%2Freleases~master~Ib37f7ddfc613333238a6dbcd08871f8a5bd3aa14,openstack/releases,master,Ib37f7ddfc613333238a6dbcd08871f8a5bd3aa14,[vitrage] Transition Xena to EM,MERGED,2023-03-29 13:10:34.000000000,2023-04-14 10:03:42.000000000,2023-04-14 10:03:42.000000000,"[{'_account_id': 17685}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:10:34.000000000', 'files': ['deliverables/xena/python-vitrageclient.yaml', 'deliverables/xena/vitrage.yaml', 'deliverables/xena/vitrage-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b457edea836cdce0498f08d1f1a183d60a552acc', 'message': '[vitrage] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ib37f7ddfc613333238a6dbcd08871f8a5bd3aa14\n'}]",1,878901,b457edea836cdce0498f08d1f1a183d60a552acc,9,4,1,17685,,,0,"[vitrage] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ib37f7ddfc613333238a6dbcd08871f8a5bd3aa14
",git fetch https://review.opendev.org/openstack/releases refs/changes/01/878901/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-vitrageclient.yaml', 'deliverables/xena/vitrage.yaml', 'deliverables/xena/vitrage-dashboard.yaml']",3,b457edea836cdce0498f08d1f1a183d60a552acc,xena-em, - version: xena-em projects: - repo: openstack/vitrage-dashboard hash: 556a43ef3193a1fa5ea127c64f98c0d5e9972afa,,12,0
openstack%2Freleases~master~I31d1284479900be78d5be2bf3e1c3cdb121430a5,openstack/releases,master,I31d1284479900be78d5be2bf3e1c3cdb121430a5,[OpenStackSDK] Transition Xena to EM,MERGED,2023-03-29 13:07:31.000000000,2023-04-14 10:03:40.000000000,2023-04-14 10:03:40.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:07:31.000000000', 'files': ['deliverables/xena/python-openstackclient.yaml', 'deliverables/xena/osc-lib.yaml', 'deliverables/xena/cliff.yaml', 'deliverables/xena/openstacksdk.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1e4d6901620ed18e2f930b8dcb0720afe4a4b31c', 'message': '[OpenStackSDK] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I31d1284479900be78d5be2bf3e1c3cdb121430a5\n'}]",1,878886,1e4d6901620ed18e2f930b8dcb0720afe4a4b31c,9,4,1,17685,,,0,"[OpenStackSDK] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I31d1284479900be78d5be2bf3e1c3cdb121430a5
",git fetch https://review.opendev.org/openstack/releases refs/changes/86/878886/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-openstackclient.yaml', 'deliverables/xena/osc-lib.yaml', 'deliverables/xena/cliff.yaml', 'deliverables/xena/openstacksdk.yaml']",4,1e4d6901620ed18e2f930b8dcb0720afe4a4b31c,xena-em, - version: xena-em projects: - repo: openstack/openstacksdk hash: d0d4d8bc64da62dc8338e307b4f736cd0b1f5f49,,16,0
openstack%2Freleases~master~Ice6a6f3137332bf3358aed60c87207043abb4313,openstack/releases,master,Ice6a6f3137332bf3358aed60c87207043abb4313,[ec2-api] Transition Xena to EM,MERGED,2023-03-29 12:59:25.000000000,2023-04-14 10:03:38.000000000,2023-04-14 10:03:38.000000000,"[{'_account_id': 10234}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 12:59:25.000000000', 'files': ['deliverables/xena/ec2-api.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/83b3f532f9f4c59ac394c604c273506d58255319', 'message': '[ec2-api] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ice6a6f3137332bf3358aed60c87207043abb4313\n'}]",1,878865,83b3f532f9f4c59ac394c604c273506d58255319,9,4,1,17685,,,0,"[ec2-api] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ice6a6f3137332bf3358aed60c87207043abb4313
",git fetch https://review.opendev.org/openstack/releases refs/changes/65/878865/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/ec2-api.yaml'],1,83b3f532f9f4c59ac394c604c273506d58255319,xena-em, - version: xena-em projects: - repo: openstack/ec2-api hash: 6eaebd8672a4391b33885067a84cd4c2e204d584,,4,0
openstack%2Freleases~master~Ic6b7845f126ce417132fe3d48cffa1a9e80e6ac5,openstack/releases,master,Ic6b7845f126ce417132fe3d48cffa1a9e80e6ac5,[blazar] Transition Xena to EM,MERGED,2023-03-29 13:10:47.000000000,2023-04-14 10:01:54.000000000,2023-04-14 10:01:54.000000000,"[{'_account_id': 15197}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:10:47.000000000', 'files': ['deliverables/xena/blazar-nova.yaml', 'deliverables/xena/blazar-dashboard.yaml', 'deliverables/xena/blazar.yaml', 'deliverables/xena/python-blazarclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/edf6cb7c762122ef8ea54bbb0316d181001a44e4', 'message': '[blazar] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ic6b7845f126ce417132fe3d48cffa1a9e80e6ac5\n'}]",1,878902,edf6cb7c762122ef8ea54bbb0316d181001a44e4,9,4,1,17685,,,0,"[blazar] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ic6b7845f126ce417132fe3d48cffa1a9e80e6ac5
",git fetch https://review.opendev.org/openstack/releases refs/changes/02/878902/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/blazar-nova.yaml', 'deliverables/xena/blazar-dashboard.yaml', 'deliverables/xena/blazar.yaml', 'deliverables/xena/python-blazarclient.yaml']",4,edf6cb7c762122ef8ea54bbb0316d181001a44e4,xena-em, - version: xena-em projects: - repo: openstack/python-blazarclient hash: e653050bc27ae99dbbd59bb6c4beb8f34486c0ba,,16,0
openstack%2Freleases~master~Ia51d71dc15fbce542c549eb9319a03e936e8dc3a,openstack/releases,master,Ia51d71dc15fbce542c549eb9319a03e936e8dc3a,[mistral] Transition Xena to EM,MERGED,2023-03-29 12:59:43.000000000,2023-04-14 09:55:33.000000000,2023-04-14 09:55:33.000000000,"[{'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 35600}]","[{'number': 1, 'created': '2023-03-29 12:59:43.000000000', 'files': ['deliverables/xena/python-mistralclient.yaml', 'deliverables/xena/mistral.yaml', 'deliverables/xena/mistral-extra.yaml', 'deliverables/xena/mistral-lib.yaml', 'deliverables/xena/mistral-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/774c421d60c03df83cf90bf5ffe6ebe68417aa7d', 'message': '[mistral] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ia51d71dc15fbce542c549eb9319a03e936e8dc3a\n'}]",1,878866,774c421d60c03df83cf90bf5ffe6ebe68417aa7d,9,6,1,17685,,,0,"[mistral] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ia51d71dc15fbce542c549eb9319a03e936e8dc3a
",git fetch https://review.opendev.org/openstack/releases refs/changes/66/878866/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-mistralclient.yaml', 'deliverables/xena/mistral.yaml', 'deliverables/xena/mistral-extra.yaml', 'deliverables/xena/mistral-lib.yaml', 'deliverables/xena/mistral-dashboard.yaml']",5,774c421d60c03df83cf90bf5ffe6ebe68417aa7d,xena-em, - version: xena-em projects: - repo: openstack/mistral-dashboard hash: 2980dfc44f11400c75a1113e468f50e7c6d6396c,,20,0
openstack%2Freleases~master~Ia4d7120cc08fce9fba65333360897b524bf59b92,openstack/releases,master,Ia4d7120cc08fce9fba65333360897b524bf59b92,[storlets] Transition Xena to EM,MERGED,2023-03-29 13:00:14.000000000,2023-04-14 09:55:31.000000000,2023-04-14 09:55:31.000000000,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:00:14.000000000', 'files': ['deliverables/xena/storlets.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c35076d55cf5a51f06538ecfae5187bd4c6027b6', 'message': '[storlets] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ia4d7120cc08fce9fba65333360897b524bf59b92\n'}]",1,878868,c35076d55cf5a51f06538ecfae5187bd4c6027b6,9,5,1,17685,,,0,"[storlets] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ia4d7120cc08fce9fba65333360897b524bf59b92
",git fetch https://review.opendev.org/openstack/releases refs/changes/68/878868/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/storlets.yaml'],1,c35076d55cf5a51f06538ecfae5187bd4c6027b6,xena-em, - version: xena-em projects: - repo: openstack/storlets hash: a513114c33d414037ec80bc6c5722dae52a90410,,4,0
openstack%2Fvenus-dashboard~master~Ia0044a6a6225cd1b9893326f133a9b57746d6c28,openstack/venus-dashboard,master,Ia0044a6a6225cd1b9893326f133a9b57746d6c28,Log Analysis develop8,MERGED,2023-04-14 09:11:49.000000000,2023-04-14 09:52:56.000000000,2023-04-14 09:52:56.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2023-04-14 09:11:49.000000000', 'files': ['venus_dashboard/static/dashboard/admin/venus/logAnalysis/logAnalysis.html'], 'web_link': 'https://opendev.org/openstack/venus-dashboard/commit/c8ef4e389471bea8860985b92e76cd4c73fdcf5d', 'message': 'Log Analysis develop8\n\nChange-Id: Ia0044a6a6225cd1b9893326f133a9b57746d6c28\n'}]",0,880469,c8ef4e389471bea8860985b92e76cd4c73fdcf5d,6,2,1,29602,,,0,"Log Analysis develop8

Change-Id: Ia0044a6a6225cd1b9893326f133a9b57746d6c28
",git fetch https://review.opendev.org/openstack/venus-dashboard refs/changes/69/880469/1 && git format-patch -1 --stdout FETCH_HEAD,['venus_dashboard/static/dashboard/admin/venus/logAnalysis/logAnalysis.html'],1,c8ef4e389471bea8860985b92e76cd4c73fdcf5d,," <option value=""module_name"">模块</option> <option value=""host_name"">主机</option> <option value=""program_name"">组件</option>"," <option value=""namespace_name"">namespace</option>",3,1
openstack%2Fvenus-dashboard~master~Ic9cf4d8dd2587bd472385ec84f3e09805379f31e,openstack/venus-dashboard,master,Ic9cf4d8dd2587bd472385ec84f3e09805379f31e,Log Analusis develop7,MERGED,2023-04-14 09:09:06.000000000,2023-04-14 09:51:45.000000000,2023-04-14 09:51:45.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2023-04-14 09:09:06.000000000', 'files': ['venus_dashboard/static/dashboard/admin/venus/logAnalysis/logAnalysis.controller.js'], 'web_link': 'https://opendev.org/openstack/venus-dashboard/commit/94630cc42db1a8dc3789b275a7e41c6162455d40', 'message': 'Log Analusis develop7\n\nChange-Id: Ic9cf4d8dd2587bd472385ec84f3e09805379f31e\n'}]",0,880468,94630cc42db1a8dc3789b275a7e41c6162455d40,6,2,1,29602,,,0,"Log Analusis develop7

Change-Id: Ic9cf4d8dd2587bd472385ec84f3e09805379f31e
",git fetch https://review.opendev.org/openstack/venus-dashboard refs/changes/68/880468/1 && git format-patch -1 --stdout FETCH_HEAD,['venus_dashboard/static/dashboard/admin/venus/logAnalysis/logAnalysis.controller.js'],1,94630cc42db1a8dc3789b275a7e41c6162455d40,, condition_value: ''," condition_value: '', page_size: horizon.cookies.get('API_RESULT_PAGE_SIZE') || 20, page_num: 1 page_size: $scope.model.page_size, page_num: $scope.model.page_num,",1,5
openstack%2Fovn-bgp-agent~master~I8221457ee588cd36de08cc0976bf6a1ec377c331,openstack/ovn-bgp-agent,master,I8221457ee588cd36de08cc0976bf6a1ec377c331,Ensure permanent mac entry are deleted from the right device,MERGED,2023-04-13 16:46:57.000000000,2023-04-14 09:51:13.000000000,2023-04-14 09:51:13.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-13 16:46:57.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/utils/wire.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_ovn_bgp_driver.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/ed43b17904d71b3bc9b49b1792473ec617325db8', 'message': 'Ensure permanent mac entry are deleted from the right device\n\nFor vlan provider networks we add the mac entry for the cr-lrp\npointint to the vlan device, not the bridge itself [1].\nThis patch ensure the deletion part takes that into account too\n\n[1] https://review.opendev.org/c/openstack/ovn-bgp-agent/+/875636\n\nChange-Id: I8221457ee588cd36de08cc0976bf6a1ec377c331\n'}]",0,879845,ed43b17904d71b3bc9b49b1792473ec617325db8,6,2,1,23567,,,0,"Ensure permanent mac entry are deleted from the right device

For vlan provider networks we add the mac entry for the cr-lrp
pointint to the vlan device, not the bridge itself [1].
This patch ensure the deletion part takes that into account too

[1] https://review.opendev.org/c/openstack/ovn-bgp-agent/+/875636

Change-Id: I8221457ee588cd36de08cc0976bf6a1ec377c331
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/45/879845/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/utils/wire.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_ovn_bgp_driver.py']",2,ed43b17904d71b3bc9b49b1792473ec617325db8,," self.ipv4, 'fake-table') dev = '{}.{}'.format(self.bridge, 10) '{}/32'.format(self.ipv4), 'fake-table', dev=dev, dev = '{}.{}'.format(self.bridge, 10) '{}/128'.format(self.ipv6), 'fake-table', dev=dev, expected_calls = [mock.call(self.ipv4, 'fake-table'), mock.call(self.ipv6, 'fake-table')] expected_calls = [mock.call(self.ipv4, 'fake-table'), mock.call(self.ipv6, 'fake-table')] expected_calls = [mock.call(self.ipv4, 'fake-table'), mock.call(self.ipv6, 'fake-table')] self.fip, 'fake-table') expected_calls = [mock.call(self.ipv4, 'fake-table'), mock.call(self.ipv6, 'fake-table')] dev=self.bridge, lladdr=self.mac), dev=self.bridge, lladdr=self.mac)] '{}/32'.format(self.ipv4), 'fake-table') '{}/128'.format(self.ipv6), 'fake-table')"," self.ipv4, 'fake-table', self.bridge) '{}/32'.format(self.ipv4), 'fake-table', self.bridge, '{}/128'.format(self.ipv6), 'fake-table', self.bridge, expected_calls = [mock.call(self.ipv4, 'fake-table', self.bridge), mock.call(self.ipv6, 'fake-table', self.bridge)] expected_calls = [mock.call(self.ipv4, 'fake-table', self.bridge), mock.call(self.ipv6, 'fake-table', self.bridge)] expected_calls = [mock.call(self.ipv4, 'fake-table', self.bridge), mock.call(self.ipv6, 'fake-table', self.bridge)] self.fip, 'fake-table', self.bridge) expected_calls = [mock.call(self.ipv4, 'fake-table', self.bridge), mock.call(self.ipv6, 'fake-table', self.bridge)] self.bridge, lladdr=self.mac), self.bridge, lladdr=self.mac)] '{}/32'.format(self.ipv4), 'fake-table', self.bridge) '{}/128'.format(self.ipv6), 'fake-table', self.bridge)",24,19
openstack%2Freleases~master~I8cde79b4b3da0974e52424d669197a696b931e22,openstack/releases,master,I8cde79b4b3da0974e52424d669197a696b931e22,[watcher] Transition Xena to EM,MERGED,2023-03-29 13:07:25.000000000,2023-04-14 09:43:37.000000000,2023-04-14 09:43:37.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 28748}]","[{'number': 1, 'created': '2023-03-29 13:07:25.000000000', 'files': ['deliverables/xena/watcher-dashboard.yaml', 'deliverables/xena/watcher.yaml', 'deliverables/xena/python-watcherclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/66eb9442f4ceeeb73e9f954a2ff0840f2b30bfff', 'message': '[watcher] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I8cde79b4b3da0974e52424d669197a696b931e22\n'}]",2,878885,66eb9442f4ceeeb73e9f954a2ff0840f2b30bfff,9,4,1,17685,,,0,"[watcher] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I8cde79b4b3da0974e52424d669197a696b931e22
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/878885/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/watcher-dashboard.yaml', 'deliverables/xena/watcher.yaml', 'deliverables/xena/python-watcherclient.yaml']",3,66eb9442f4ceeeb73e9f954a2ff0840f2b30bfff,xena-em, - version: xena-em projects: - repo: openstack/python-watcherclient hash: dc9b5cb347bc50595670fa9df90c00d52734395d,,12,0
openstack%2Freleases~master~I939e5da546e67bdeac441b69f85bbe2469a2295a,openstack/releases,master,I939e5da546e67bdeac441b69f85bbe2469a2295a,[adjutant] Transition Xena to EM,MERGED,2023-03-29 13:09:18.000000000,2023-04-14 09:43:35.000000000,2023-04-14 09:43:35.000000000,"[{'_account_id': 14394}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:09:18.000000000', 'files': ['deliverables/xena/python-adjutantclient.yaml', 'deliverables/xena/adjutant-ui.yaml', 'deliverables/xena/adjutant.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8a32a53b3e0148e406b0817830505ea57df71c86', 'message': '[adjutant] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I939e5da546e67bdeac441b69f85bbe2469a2295a\n'}]",1,878894,8a32a53b3e0148e406b0817830505ea57df71c86,9,4,1,17685,,,0,"[adjutant] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I939e5da546e67bdeac441b69f85bbe2469a2295a
",git fetch https://review.opendev.org/openstack/releases refs/changes/94/878894/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-adjutantclient.yaml', 'deliverables/xena/adjutant-ui.yaml', 'deliverables/xena/adjutant.yaml']",3,8a32a53b3e0148e406b0817830505ea57df71c86,xena-em, - version: xena-em projects: - repo: openstack/adjutant hash: f8cd1d888fc2335dbc9edcd63e4aa5ff54fac8b7,,12,0
openstack%2Freleases~master~I9d640eb5e6901c32b5a7b7e1b12e23f61cd1ca50,openstack/releases,master,I9d640eb5e6901c32b5a7b7e1b12e23f61cd1ca50,[trove] Transition Xena to EM,MERGED,2023-03-29 13:03:46.000000000,2023-04-14 09:43:33.000000000,2023-04-14 09:43:33.000000000,"[{'_account_id': 6732}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:03:46.000000000', 'files': ['deliverables/xena/python-troveclient.yaml', 'deliverables/xena/trove-dashboard.yaml', 'deliverables/xena/trove.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/240a463ed5a839809802da2435da1f3e8596ebe2', 'message': '[trove] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I9d640eb5e6901c32b5a7b7e1b12e23f61cd1ca50\n'}]",1,878872,240a463ed5a839809802da2435da1f3e8596ebe2,9,5,1,17685,,,0,"[trove] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I9d640eb5e6901c32b5a7b7e1b12e23f61cd1ca50
",git fetch https://review.opendev.org/openstack/releases refs/changes/72/878872/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-troveclient.yaml', 'deliverables/xena/trove-dashboard.yaml', 'deliverables/xena/trove.yaml']",3,240a463ed5a839809802da2435da1f3e8596ebe2,xena-em, - version: xena-em projects: - repo: openstack/trove hash: 71d8400db5403e37f17340bc05b2a22324d334cd,,12,0
openstack%2Freleases~master~I14b1b1c63aa28dd439b49fda7c1bbb95a2afe748,openstack/releases,master,I14b1b1c63aa28dd439b49fda7c1bbb95a2afe748,[tacker] Transition Xena to EM,MERGED,2023-03-29 13:10:26.000000000,2023-04-14 09:43:31.000000000,2023-04-14 09:43:31.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:10:26.000000000', 'files': ['deliverables/xena/tacker-horizon.yaml', 'deliverables/xena/tacker.yaml', 'deliverables/xena/python-tackerclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8eb1d73799824ed1e56c30df9d7ca58c54db145f', 'message': '[tacker] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I14b1b1c63aa28dd439b49fda7c1bbb95a2afe748\n'}]",2,878900,8eb1d73799824ed1e56c30df9d7ca58c54db145f,9,4,1,17685,,,0,"[tacker] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I14b1b1c63aa28dd439b49fda7c1bbb95a2afe748
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/878900/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/tacker-horizon.yaml', 'deliverables/xena/tacker.yaml', 'deliverables/xena/python-tackerclient.yaml']",3,8eb1d73799824ed1e56c30df9d7ca58c54db145f,xena-em, - version: xena-em projects: - repo: openstack/python-tackerclient hash: 98789f8f9af345894cee523df254704babf80156,,12,0
openstack%2Freleases~master~Id22cf51d8e7afbccb99809b92a7c94f4d9614c97,openstack/releases,master,Id22cf51d8e7afbccb99809b92a7c94f4d9614c97,[zaqar] Transition Xena to EM,MERGED,2023-03-29 13:03:52.000000000,2023-04-14 09:42:14.000000000,2023-04-14 09:42:14.000000000,"[{'_account_id': 8846}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:03:52.000000000', 'files': ['deliverables/xena/zaqar-ui.yaml', 'deliverables/xena/python-zaqarclient.yaml', 'deliverables/xena/zaqar.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/89d77b97967288d524afe937078120073682c20e', 'message': '[zaqar] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Id22cf51d8e7afbccb99809b92a7c94f4d9614c97\n'}]",1,878873,89d77b97967288d524afe937078120073682c20e,9,4,1,17685,,,0,"[zaqar] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Id22cf51d8e7afbccb99809b92a7c94f4d9614c97
",git fetch https://review.opendev.org/openstack/releases refs/changes/73/878873/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/zaqar-ui.yaml', 'deliverables/xena/python-zaqarclient.yaml', 'deliverables/xena/zaqar.yaml']",3,89d77b97967288d524afe937078120073682c20e,xena-em, - version: xena-em projects: - repo: openstack/zaqar hash: c7d9976e1527eba5ca59a503b08e5d785d2b6101,,12,0
openstack%2Fnova~stable%2Fzed~Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,openstack/nova,stable/zed,Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,Fix rescue volume-based instance,MERGED,2023-01-30 12:46:49.000000000,2023-04-14 09:35:15.000000000,2023-04-14 09:34:00.000000000,"[{'_account_id': 4393}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-01-30 12:46:49.000000000', 'files': ['releasenotes/notes/rescue-volume-based-instance-c6e3fba236d90be7.yaml', 'nova/tests/functional/test_server_rescue.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d00a848a735f98b028f5930798ee69ef205c8e2e', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n(cherry picked from commit 6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b)\n'}]",3,872116,d00a848a735f98b028f5930798ee69ef205c8e2e,19,6,1,20733,,,0,"Fix rescue volume-based instance

As of now, when attempting to rescue a volume-based instance
using an image without the hw_rescue_device and/or hw_rescue_bus
properties set, the rescue api call fails (as non-stable rescue
for volume-based instances are not supported) leaving the instance
in error state.

This change checks for hw_rescue_device/hw_rescue_bus image
properties before attempting to rescue and if the property
is not set, then fail with proper error message, without changing
instance state.

Related-Bug: #1978958
Closes-Bug: #1926601
Change-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1
(cherry picked from commit 6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b)
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/872116/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/rescue-volume-based-instance-c6e3fba236d90be7.yaml', 'nova/tests/functional/test_server_rescue.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py']",4,d00a848a735f98b028f5930798ee69ef205c8e2e,lp_1978958," rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) @mock.patch('nova.objects.instance.Instance.image_meta') mock_get_cn, mock_image_meta): instance.image_meta = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) @mock.patch('nova.objects.image_meta.ImageMeta.from_image_ref') @mock.patch('nova.objects.compute_node.ComputeNode' '.get_by_host_and_nodename') @mock.patch('nova.compute.utils.is_volume_backed_instance', return_value=True) @mock.patch('nova.objects.block_device.BlockDeviceMappingList' '.get_by_instance_uuid') def test_rescue_bfv_with_required_image_properties( self, mock_get_bdms, mock_is_volume_backed, mock_get_cn, mock_image_meta_obj_from_ref): instance = self._create_instance_obj() bdms = objects.BlockDeviceMappingList(objects=[ objects.BlockDeviceMapping( boot_index=0, image_id=uuids.image_id, source_type='image', destination_type='volume', volume_type=None, snapshot_id=None, volume_id=uuids.volume_id, volume_size=None)]) rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {'hw_rescue_device': 'disk', 'hw_rescue_bus': 'scsi'} }) with test.nested( mock.patch.object(self.compute_api.placementclient, 'get_provider_traits'), mock.patch.object(self.compute_api.volume_api, 'get'), mock.patch.object(self.compute_api.volume_api, 'check_attached'), mock.patch.object(instance, 'save'), mock.patch.object(self.compute_api, '_record_action_start'), mock.patch.object(self.compute_api.compute_rpcapi, 'rescue_instance') ) as ( mock_get_traits, mock_get_volume, mock_check_attached, mock_instance_save, mock_record_start, mock_rpcapi_rescue ): # Mock out the returned compute node, image_meta, bdms and volume mock_image_meta_obj_from_ref.return_value = rescue_image_meta_obj mock_get_bdms.return_value = bdms mock_get_volume.return_value = mock.sentinel.volume mock_get_cn.return_value = mock.Mock(uuid=uuids.cn) # Ensure the required trait is returned, allowing BFV rescue mock_trait_info = mock.Mock(traits=[ot.COMPUTE_RESCUE_BFV]) mock_get_traits.return_value = mock_trait_info # Try to rescue the instance self.compute_api.rescue(self.context, instance, rescue_image_ref=uuids.rescue_image_id, allow_bfv_rescue=True) # Assert all of the calls made in the compute API mock_get_bdms.assert_called_once_with(self.context, instance.uuid) mock_get_volume.assert_called_once_with( self.context, uuids.volume_id) mock_check_attached.assert_called_once_with( self.context, mock.sentinel.volume) mock_is_volume_backed.assert_called_once_with( self.context, instance, bdms) mock_get_cn.assert_called_once_with( self.context, instance.host, instance.node) mock_get_traits.assert_called_once_with(self.context, uuids.cn) mock_instance_save.assert_called_once_with( expected_task_state=[None]) mock_record_start.assert_called_once_with( self.context, instance, instance_actions.RESCUE) mock_rpcapi_rescue.assert_called_once_with( self.context, instance=instance, rescue_password=None, rescue_image_ref=uuids.rescue_image_id, clean_shutdown=True) # Assert that the instance task state as set in the compute API self.assertEqual(task_states.RESCUING, instance.task_state) @mock.patch('nova.objects.image_meta.ImageMeta.from_image_ref') @mock.patch('nova.compute.utils.is_volume_backed_instance', return_value=True) @mock.patch('nova.objects.block_device.BlockDeviceMappingList' '.get_by_instance_uuid') def test_rescue_bfv_without_required_image_properties( self, mock_get_bdms, mock_is_volume_backed, mock_image_meta_obj_from_ref): instance = self._create_instance_obj() bdms = objects.BlockDeviceMappingList(objects=[ objects.BlockDeviceMapping( boot_index=0, image_id=uuids.image_id, source_type='image', destination_type='volume', volume_type=None, snapshot_id=None, volume_id=uuids.volume_id, volume_size=None)]) rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({ 'properties': {} }) with test.nested( mock.patch.object(self.compute_api.volume_api, 'get'), mock.patch.object(self.compute_api.volume_api, 'check_attached'), ) as ( mock_get_volume, mock_check_attached ): # Mock out the returned bdms, volume and image_meta mock_get_bdms.return_value = bdms mock_get_volume.return_value = mock.sentinel.volume mock_image_meta_obj_from_ref.return_value = rescue_image_meta_obj # Assert that any attempt to rescue a bfv instance on a compute # node that does not report the COMPUTE_RESCUE_BFV trait fails and # raises InstanceNotRescuable self.assertRaises(exception.InstanceNotRescuable, self.compute_api.rescue, self.context, instance, rescue_image_ref=None, allow_bfv_rescue=True) # Assert the calls made in the compute API prior to the failure mock_get_bdms.assert_called_once_with(self.context, instance.uuid) mock_get_volume.assert_called_once_with( self.context, uuids.volume_id) mock_check_attached.assert_called_once_with( self.context, mock.sentinel.volume) mock_is_volume_backed.assert_called_once_with( self.context, instance, bdms) ", rescue_image_meta_obj = image_meta_obj.ImageMeta.from_dict({}) mock_get_cn):,220,11
openstack%2Freleases~master~I5a55a4c521eed7527ded817f071c8e15c08c569b,openstack/releases,master,I5a55a4c521eed7527ded817f071c8e15c08c569b,[masakari] Transition Xena to EM,MERGED,2023-03-29 13:08:26.000000000,2023-04-14 09:29:26.000000000,2023-04-14 09:29:26.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30623}]","[{'number': 1, 'created': '2023-03-29 13:08:26.000000000', 'files': ['deliverables/xena/masakari-dashboard.yaml', 'deliverables/xena/masakari.yaml', 'deliverables/xena/python-masakariclient.yaml', 'deliverables/xena/masakari-monitors.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/17e7b17fa10865999b97fae7e62541f51530f92f', 'message': '[masakari] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I5a55a4c521eed7527ded817f071c8e15c08c569b\n'}]",1,878890,17e7b17fa10865999b97fae7e62541f51530f92f,9,4,1,17685,,,0,"[masakari] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I5a55a4c521eed7527ded817f071c8e15c08c569b
",git fetch https://review.opendev.org/openstack/releases refs/changes/90/878890/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/masakari-dashboard.yaml', 'deliverables/xena/masakari.yaml', 'deliverables/xena/python-masakariclient.yaml', 'deliverables/xena/masakari-monitors.yaml']",4,17e7b17fa10865999b97fae7e62541f51530f92f,xena-em, - version: xena-em projects: - repo: openstack/masakari-monitors hash: 98a5b71d1b0ca1de4675786d414f565bba517626,,16,0
openstack%2Fvenus-dashboard~master~Id22b87b38f99d7410b83b9d33a7c076ea892c543,openstack/venus-dashboard,master,Id22b87b38f99d7410b83b9d33a7c076ea892c543,Log Analusis develop6,MERGED,2023-04-14 09:05:51.000000000,2023-04-14 09:29:01.000000000,2023-04-14 09:29:01.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2023-04-14 09:05:51.000000000', 'files': ['venus_dashboard/static/dashboard/admin/services/venus.service.js'], 'web_link': 'https://opendev.org/openstack/venus-dashboard/commit/c7e95c2840dbb76e8e9bcc3a592dcbdeadd285de', 'message': 'Log Analusis develop6\n\nChange-Id: Id22b87b38f99d7410b83b9d33a7c076ea892c543\n'}]",0,880466,c7e95c2840dbb76e8e9bcc3a592dcbdeadd285de,6,2,1,29602,,,0,"Log Analusis develop6

Change-Id: Id22b87b38f99d7410b83b9d33a7c076ea892c543
",git fetch https://review.opendev.org/openstack/venus-dashboard refs/changes/66/880466/1 && git format-patch -1 --stdout FETCH_HEAD,['venus_dashboard/static/dashboard/admin/services/venus.service.js'],1,c7e95c2840dbb76e8e9bcc3a592dcbdeadd285de,," function getAnalysis(config) { config = {params: config}; if (venusAPI) { return venusAPI.getAnalysis(config) .then(function (data) { return data; }) .catch(function (err) { console.error(err); }); } } getLogs: getLogs, getAnalysis: getAnalysis", getLogs: getLogs,14,1
openstack%2Fmanila~master~If77a3da772c7049b5ef9431f25f99ab23fc10bdd,openstack/manila,master,If77a3da772c7049b5ef9431f25f99ab23fc10bdd,db: Replace all usage of 'get_session',NEW,2023-01-30 11:59:52.000000000,2023-04-14 09:28:53.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 11:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6882476320673334cfe9a156ac3411595ca63b31', 'message': 'db: Replace all usage of \'get_session\'\n\nWe\'re changing tack. In previous changes, we had attempted to group DB\nAPIs by theme (e.g. migrate all ""message"" APIs to enginefacade). This\nhas proven too difficult to do with shares and share-related resources,\ngiven the intertwined nature of these resources.\n\nInstead of doing this, we\'ve decorated all remaining methods with a\ncontext manager writer or reader and replaced all calls with\n\'get_session\' to use \'context.session\' instead (which should now be\nset). Future changes will be used to clean this up, removing the\nunnecessary aliasing of \'context.session\' and passing explicit \'session\'\narguments in favour of direct use of \'context.session\'. This will also\nrequire continuing the pattern of wrapped public methods (which should\nbe called directly) and unwrapped private methods (for use by wrapped\npublic methods).\n\nPro-tip: view this diff with whitespace ignored: we have removed a lot\nof \'with session.begin\' context managers since the session provided by\nthe enginefacade has already been started.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: If77a3da772c7049b5ef9431f25f99ab23fc10bdd\n'}, {'number': 2, 'created': '2023-03-31 15:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c971bcc1bcf8cb0d38226d3879ad1ca1ce6f1886', 'message': 'db: Replace all usage of \'get_session\'\n\nWe\'re changing tack. In previous changes, we had attempted to group DB\nAPIs by theme (e.g. migrate all ""message"" APIs to enginefacade). This\nhas proven too difficult to do with shares and share-related resources,\ngiven the intertwined nature of these resources.\n\nInstead of doing this, we\'re going to migrate everything in one piece.\nWhile this patch may look huge, the actual changes are trivial enough.\nWe add decorators for all public methods, and we migrate any calls to a\npublic method from another public with a call to an equivalent unwrapped\nprivate method. This prevents us created nested contexts. Where the\nprivate methods don\'t exist, we create them.\n\nPro-tip: view this diff with whitespace ignored: we have removed a lot\nof \'with session.begin\' context managers since the session provided by\nthe enginefacade has already been started.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: If77a3da772c7049b5ef9431f25f99ab23fc10bdd\n'}, {'number': 3, 'created': '2023-04-03 11:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/02539eb972ab9f17a7c55f9c252da8f0cf9f9522', 'message': 'db: Replace all usage of \'get_session\'\n\nWe\'re changing tack. In previous changes, we had attempted to group DB\nAPIs by theme (e.g. migrate all ""message"" APIs to enginefacade). This\nhas proven too difficult to do with shares and share-related resources,\ngiven the intertwined nature of these resources.\n\nInstead of doing this, we\'re going to migrate everything in one piece.\nWhile this patch may look huge, the actual changes are trivial enough.\nWe add decorators for all public methods, and we migrate any calls to a\npublic method from another public with a call to an equivalent unwrapped\nprivate method. This prevents us created nested contexts. Where the\nprivate methods don\'t exist, we create them.\n\nPro-tip: view this diff with whitespace ignored: we have removed a lot\nof \'with session.begin\' context managers since the session provided by\nthe enginefacade has already been started.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: If77a3da772c7049b5ef9431f25f99ab23fc10bdd\n'}, {'number': 4, 'created': '2023-04-03 14:29:34.000000000', 'files': ['manila/db/api.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ae1ee818bbc8905c0576a3147b65709237eb6de5', 'message': 'db: Replace all usage of \'get_session\'\n\nWe\'re changing tack. In previous changes, we had attempted to group DB\nAPIs by theme (e.g. migrate all ""message"" APIs to enginefacade). This\nhas proven too difficult to do with shares and share-related resources,\ngiven the intertwined nature of these resources.\n\nInstead of doing this, we\'re going to migrate everything in one piece.\nWhile this patch may look huge, the actual changes are trivial enough.\nWe add decorators for all public methods, and we migrate any calls to a\npublic method from another public with a call to an equivalent unwrapped\nprivate method. This prevents us created nested contexts. Where the\nprivate methods don\'t exist, we create them.\n\nPro-tip: view this diff with whitespace ignored: we have removed a lot\nof \'with session.begin\' context managers since the session provided by\nthe enginefacade has already been started.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: If77a3da772c7049b5ef9431f25f99ab23fc10bdd\n'}]",3,872158,ae1ee818bbc8905c0576a3147b65709237eb6de5,26,2,4,15334,,,0,"db: Replace all usage of 'get_session'

We're changing tack. In previous changes, we had attempted to group DB
APIs by theme (e.g. migrate all ""message"" APIs to enginefacade). This
has proven too difficult to do with shares and share-related resources,
given the intertwined nature of these resources.

Instead of doing this, we're going to migrate everything in one piece.
While this patch may look huge, the actual changes are trivial enough.
We add decorators for all public methods, and we migrate any calls to a
public method from another public with a call to an equivalent unwrapped
private method. This prevents us created nested contexts. Where the
private methods don't exist, we create them.

Pro-tip: view this diff with whitespace ignored: we have removed a lot
of 'with session.begin' context managers since the session provided by
the enginefacade has already been started.

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: If77a3da772c7049b5ef9431f25f99ab23fc10bdd
",git fetch https://review.opendev.org/openstack/manila refs/changes/58/872158/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py']",2,6882476320673334cfe9a156ac3411595ca63b31,sqlalchemy-20," # TODO(stephenfin): Remove session from all kwargs # TODO(stephenfin): Remove this assertion once we're done migrating to the # enginefacade approach assert session@context_manager.writer _reservation_rollback( session = context.session if project_id is None: project_id = context.project_id if share_type_id: user_or_st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: user_id = user_id if user_id else context.user_id user_or_st_usages = _get_user_quota_usages( context, session, project_id, user_id) # Get the current usages project_usages = _get_project_quota_usages( context, session, project_id) # Handle usage refresh work = set(deltas.keys()) while work: resource = work.pop() # Do we need to refresh the usage? refresh = False if ((resource not in PER_PROJECT_QUOTAS) and (resource not in user_or_st_usages)): user_or_st_usages[resource] = _quota_usage_create( elevated, project_id, user_id, resource, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) refresh = True elif ((resource in PER_PROJECT_QUOTAS) and (resource not in user_or_st_usages)): user_or_st_usages[resource] = _quota_usage_create( elevated, project_id, None, resource, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) refresh = True elif user_or_st_usages[resource].in_use < 0: # Negative in_use count indicates a desync, so try to # heal from that... refresh = True elif user_or_st_usages[resource].until_refresh is not None: user_or_st_usages[resource].until_refresh -= 1 if user_or_st_usages[resource].until_refresh <= 0: elif max_age and (user_or_st_usages[resource].updated_at - timeutils.utcnow()).seconds >= max_age: refresh = True # OK, refresh the usage if refresh: # Grab the sync routine sync = QUOTA_SYNC_FUNCTIONS[resources[resource].sync] updates = sync( elevated, project_id, user_id, share_type_id=share_type_id, session=session) for res, in_use in updates.items(): # Make sure we have a destination for the usage! if ((res not in PER_PROJECT_QUOTAS) and (res not in user_or_st_usages)): user_or_st_usages[res] = _quota_usage_create( elevated, project_id, user_id, res, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) if ((res in PER_PROJECT_QUOTAS) and (res not in user_or_st_usages)): user_or_st_usages[res] = _quota_usage_create( elevated, project_id, None, res, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) if user_or_st_usages[res].in_use != in_use: LOG.debug( 'quota_usages out of sync, updating. ' 'project_id: %(project_id)s, ' 'user_id: %(user_id)s, ' 'share_type_id: %(share_type_id)s, ' 'resource: %(res)s, ' 'tracked usage: %(tracked_use)s, ' 'actual usage: %(in_use)s', {'project_id': project_id, 'user_id': user_id, 'share_type_id': share_type_id, 'res': res, 'tracked_use': user_or_st_usages[res].in_use, 'in_use': in_use}) # Update the usage user_or_st_usages[res].in_use = in_use user_or_st_usages[res].until_refresh = ( until_refresh or None) # Because more than one resource may be refreshed # by the call to the sync routine, and we don't # want to double-sync, we make sure all refreshed # resources are dropped from the work set. work.discard(res) # NOTE(Vek): We make the assumption that the sync # routine actually refreshes the # resources that it is the sync routine # for. We don't check, because this is # a best-effort mechanism. # Check for deltas that would go negative unders = [res for res, delta in deltas.items() if delta < 0 and delta + user_or_st_usages[res].in_use < 0] # Now, let's check the quotas # NOTE(Vek): We're only concerned about positive increments. # If a project has gone over quota, we want them to # be able to reduce their usage without any # problems. for key, value in user_or_st_usages.items(): if key not in project_usages: project_usages[key] = value overs = [res for res, delta in deltas.items() if user_or_st_quotas[res] >= 0 and delta >= 0 and (0 <= project_quotas[res] < delta + project_usages[res]['total'] or user_or_st_quotas[res] < delta + user_or_st_usages[res].total)] # NOTE(carloss): If OverQuota is allowed, there is no problem to exceed # the quotas, so we reset the overs list and LOG it. if overs and overquota_allowed: msg = _(""The service has identified one or more exceeded "" ""quotas. Please check the quotas for project "" ""%(project_id)s, user %(user_id)s and share type "" ""%(share_type_id)s, and adjust them if "" ""necessary."") % { ""project_id"": project_id, ""user_id"": user_id, ""share_type_id"": share_type_id } LOG.warning(msg) overs = [] # NOTE(Vek): The quota check needs to be in the transaction, # but the transaction doesn't fail just because # we're over quota, so the OverQuota raise is # outside the transaction. If we did the raise # here, our usage updates would be discarded, but # they're not invalidated by being over-quota. context.session.commit() context.session.begin() # Create the reservations if not overs: reservations = [] for res, delta in deltas.items(): reservation = _reservation_create(elevated, uuidutils.generate_uuid(), user_or_st_usages[res], project_id, user_id, res, delta, expire, share_type_id=share_type_id, session=session) reservations.append(reservation.uuid) # Also update the reserved quantity # NOTE(Vek): Again, we are only concerned here about # positive increments. Here, though, we're # worried about the following scenario: # # 1) User initiates resize down. # 2) User allocates a new instance. # 3) Resize down fails or is reverted. # 4) User is now over quota. # # To prevent this, we only update the # reserved value if the delta is positive. if delta > 0: user_or_st_usages[res].reserved += delta # Apply updates to the usages table for usage_ref in user_or_st_usages.values(): session.add(usage_ref)@context_manager.writer session = context.session if share_type_id: st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: st_usages = {} user_usages = _get_user_quota_usages( context, session, project_id, user_id) reservation_query = _quota_reservations_query( session, context, reservations) for reservation in reservation_query.all(): if reservation['share_type_id']: usages = st_usages else: usages = user_usages usage = usages[reservation.resource] if reservation.delta >= 0: usage.reserved -= reservation.delta usage.in_use += reservation.delta reservation_query.soft_delete(synchronize_session=False)@context_manager.writer return _reservation_rollback( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_type_id, ) def _reservation_rollback(context, reservations, project_id=None, user_id=None, share_type_id=None): session = context.session if share_type_id: st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: st_usages = {} user_usages = _get_user_quota_usages( context, session, project_id, user_id) reservation_query = _quota_reservations_query( session, context, reservations) for reservation in reservation_query.all(): if reservation['share_type_id']: usages = st_usages else: usages = user_usages usage = usages[reservation.resource] if reservation.delta >= 0: usage.reserved -= reservation.delta reservation_query.soft_delete(synchronize_session=False)@context_manager.writer def quota_destroy_all_by_project_and_user(context, project_id, user_id): session = context.session (model_query(context, models.ProjectUserQuota, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False)) (model_query(context, models.QuotaUsage, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False)) (model_query(context, models.Reservation, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False))@context_manager.writer session = context.session share_type_quotas = model_query( context, models.ProjectShareTypeQuota, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) share_type_quota_usages = model_query( context, models.QuotaUsage, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) share_type_quota_reservations = model_query( context, models.Reservation, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) if project_id is not None: share_type_quotas = share_type_quotas.filter_by( project_id=project_id) share_type_quota_usages = share_type_quota_usages.filter_by( project_id=project_id) share_type_quota_reservations = ( share_type_quota_reservations.filter_by(project_id=project_id)) share_type_quotas.soft_delete(synchronize_session=False) share_type_quota_usages.soft_delete(synchronize_session=False) share_type_quota_reservations.soft_delete(synchronize_session=False)@context_manager.writer def quota_destroy_all_by_project(context, project_id): session = context.session (model_query(context, models.Quota, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.ProjectUserQuota, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.QuotaUsage, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.Reservation, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False))@context_manager.writer def reservation_expire(context): session = context.session current_time = timeutils.utcnow() reservation_query = (model_query( context, models.Reservation, session=session, read_deleted=""no""). filter(models.Reservation.expire < current_time)) for reservation in reservation_query.all(): if reservation.delta >= 0: quota_usage = model_query(context, models.QuotaUsage, session=session, read_deleted=""no"").filter( models.QuotaUsage.id == reservation.usage_id).first() quota_usage.reserved -= reservation.delta session.add(quota_usage) reservation_query.soft_delete(synchronize_session=False)@context_manager.writer def share_instance_create(context, share_id, values): session = context.session return _share_instance_create(context, share_id, values, session)@context_manager.writer session = context.session instance_ref = _share_instance_update( context, share_instance_id, values, session ) if with_share_data: parent_share = share_get(context, instance_ref['share_id'], session=session) instance_ref.set_share_data(parent_share) return instance_ref @require_context @context_manager.writer session = context.session if current_expected_status and share_instance_ids: filters = {'instance_ids': share_instance_ids} share_instances = share_instances_get_all( context, filters=filters, session=session) all_instances_are_compliant = all( instance['status'] == current_expected_status for instance in share_instances) if not all_instances_are_compliant: msg = _('At least one of the shares is not in the %(status)s ' 'status.') % { 'status': current_expected_status } raise exception.InvalidShareInstance(reason=msg) if current_expected_status and snapshot_instance_ids: filters = {'instance_ids': snapshot_instance_ids} snapshot_instances = share_snapshot_instance_get_all_with_filters( context, filters, session=session) all_snap_instances_are_compliant = all( snap_instance['status'] == current_expected_status for snap_instance in snapshot_instances) if not all_snap_instances_are_compliant: msg = _('At least one of the snapshots is not in the ' '%(status)s status.') % { 'status': current_expected_status } raise exception.InvalidShareSnapshotInstance(reason=msg) if share_instance_ids: updated_share_instances = share_instances_status_update( context, share_instance_ids, values, session=session) if snapshot_instance_ids: updated_snapshot_instances = ( share_snapshot_instances_status_update( context, snapshot_instance_ids, values, session=session))@context_manager.writer session = session or context.session@context_manager.reader session = context.session@context_manager.reader def share_instances_get_all(context, filters=None, session=None): session = session or context.session@context_manager.writer session = context.session share_export_locations_update(context, instance_id, [], delete=True) instance_ref = share_instance_get(context, instance_id, session=session) is_replica = instance_ref['replica_state'] is not None instance_ref.soft_delete(session=session, update_status=True) share = share_get(context, instance_ref['share_id'], session=session) if len(share.instances) == 0: share_access_delete_all_by_share(context, share['id']) session.query(models.ShareMetadata).filter_by( share_id=share['id']).soft_delete() share.soft_delete(session=session) if need_to_update_usages: _update_share_instance_usages(context, share, instance_ref, is_replica=is_replica)@context_manager.reader session = session or context.session@context_manager.reader@context_manager.reader session = context.session@context_manager.reader@context_manager.reader@context_manager.reader session = session or context.session@context_manager.reader session = session or context.session@context_manager.reader session = session or context.session@context_manager.reader session = session or context.session@context_manager.writer session = session or context.session _ensure_availability_zone_exists(context, values, session, strict=False) updated_share_replica = _share_instance_update( context, share_replica_id, values, session=session) if with_share_data: updated_share_replica = _set_instances_share_data( context, updated_share_replica, session)[0]@context_manager.writer session = session or context.session session = context.session@context_manager.writer session = context.session share_ref.save(session=session) if create_share_instance: _share_instance_create(context, share_ref['id'], share_instance_values, session=session) # NOTE(u_glide): Do so to prevent errors with relationships return share_get(context, share_ref['id'], session=session)@context_manager.reader@context_manager.writer def share_update(context, share_id, update_values): session = context.session share_ref = share_get(context, share_id, session=session) _share_instance_update(context, share_ref.instance['id'], share_instance_values, session=session) share_ref.update(share_values) share_ref.save(session=session) return share_ref@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.writer def share_delete(context, share_id): session = context.session share_ref = share_get(context, share_id, session) if len(share_ref.instances) > 0: msg = _(""Share %(id)s has %(count)s share instances."") % { 'id': share_id, 'count': len(share_ref.instances)} raise exception.InvalidShare(msg) share_ref.soft_delete(session=session) (session.query(models.ShareMetadata). filter_by(share_id=share_id).soft_delete())@context_manager.writer def share_soft_delete(context, share_id): session = context.session share_ref = share_get(context, share_id, session=session) share_ref.update(update_values) share_ref.save(session=session)@context_manager.writer def share_restore(context, share_id): session = context.session share_ref = share_get(context, share_id, session=session) share_ref.update(update_values) share_ref.save(session=session)@context_manager.writer def share_access_metadata_update(context, access_id, metadata): session = context.session # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} try: meta_ref = _share_access_metadata_get_item( context, access_id, meta_key, session=session) except exception.ShareAccessMetadataNotFound: meta_ref = models.ShareAccessRulesMetadata() item.update({""key"": meta_key, ""access_id"": access_id}) meta_ref.update(item) meta_ref.save(session=session) return metadata@context_manager.writer def share_access_metadata_delete(context, access_id, key): session = context.session metadata = _share_access_metadata_get_item( context, access_id, key, session=session) metadata.soft_delete(session)@context_manager.writer session = context.session values['share_access_rules_metadata'] = ( _metadata_refs(values.get('metadata'), models.ShareAccessRulesMetadata)) access_ref = models.ShareAccessMapping() access_ref.update(values) access_ref.save(session=session) parent_share = share_get(context, values['share_id'], session=session) for instance in parent_share.instances: vals = { 'share_instance_id': instance['id'],@context_manager.writer def share_instance_access_create(context, values, share_instance_id): values = ensure_model_dict_has_id(values) session = context.session access_list = _share_access_get_query( context, session, { 'share_id': values['share_id'], 'access_type': values['access_type'], 'access_to': values['access_to'], }).all() if len(access_list) > 0: access_ref = access_list[0] else: access_ref = models.ShareAccessMapping() access_ref.update(values) access_ref.save(session=session) vals = { 'share_instance_id': share_instance_id, 'access_id': access_ref['id'], } _share_instance_access_create(vals, session) return share_access_get(context, access_ref['id']) @require_context @context_manager.writer session = session or context.session@context_manager.reader session = session or context.session@context_manager.reader session = context.session@context_manager.reader session = session or context.session@context_manager.reader session = session or context.session@context_manager.reader session = context.session@context_manager.reader session = context.session if access_type == 'ip': rules = query_method( context, session, {'%s_id' % resource: resource_id, 'access_type': access_type}).filter( access_to_field.startswith(access_to.split('/')[0])).all() matching_rules = [ rule for rule in rules if ipaddress.ip_network(str(access_to)) == ipaddress.ip_network(str(rule['access_to'])) ] return len(matching_rules) > 0 else: return query_method( context, session, {'%s_id' % resource: resource_id, 'access_type': access_type, 'access_to': access_to}).count() > 0@context_manager.writer def share_access_delete_all_by_share(context, share_id): session = context.session (session.query(models.ShareAccessMapping). filter_by(share_id=share_id).soft_delete())@context_manager.writer def share_instance_access_delete(context, mapping_id): session = context.session mapping = (session.query(models.ShareInstanceAccessMapping). filter_by(id=mapping_id).first()) if not mapping: exception.NotFound() mapping.soft_delete(session, update_status=True, status_field_name='state') other_mappings = _share_instance_access_query( context, session, mapping['access_id']).all() # NOTE(u_glide): Remove access rule if all mappings were removed. if len(other_mappings) == 0: (session.query(models.ShareAccessRulesMetadata).filter_by( access_id=mapping['access_id']).soft_delete()) (session.query(models.ShareAccessMapping).filter_by( id=mapping['access_id']).soft_delete())@context_manager.writer def share_instance_access_update(context, access_id, instance_id, updates): session = context.session share_access = _share_access_get_query( context, session, {'id': access_id}).first() share_access.update(share_access_map_updates) share_access.save(session=session) access = _share_instance_access_query( context, session, access_id, instance_id).first() access.update(share_instance_access_map_updates) access.save(session=session) return access@context_manager.writer def share_snapshot_instance_create(context, snapshot_id, values, session=None): session = session or context.session@context_manager.writer def share_snapshot_instance_update(context, instance_id, values): session = context.session@context_manager.writer session = session or context.session snapshot_instance_ref = share_snapshot_instance_get( context, snapshot_instance_id, session=session) access_rules = share_snapshot_access_get_all_for_snapshot_instance( context, snapshot_instance_id, session=session) for rule in access_rules: share_snapshot_instance_access_delete( context, rule['access_id'], snapshot_instance_id) for el in snapshot_instance_ref.export_locations: share_snapshot_instance_export_location_delete(context, el['id']) snapshot_instance_ref.soft_delete( session=session, update_status=True) snapshot = share_snapshot_get( context, snapshot_instance_ref['snapshot_id'], session=session) if len(snapshot.instances) == 0: session.query(models.ShareSnapshotMetadata).filter_by( share_snapshot_id=snapshot['id']).soft_delete() snapshot.soft_delete(session=session)@context_manager.reader session = session or context.session@context_manager.reader session = session or context.session@context_manager.writer session = context.session snapshot_ref.save(session=session) if create_snapshot_instance: share_snapshot_instance_create( context, snapshot_ref['id'], snapshot_instance_values, session=session ) return share_snapshot_get( context, snapshot_values['id'], session=session)@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.writer def share_snapshot_update(context, snapshot_id, values): session = context.session snapshot_ref = share_snapshot_get(context, snapshot_id, session=session) instance_values, snapshot_values = ( _extract_snapshot_instance_values(values) ) if snapshot_values: snapshot_ref.update(snapshot_values) snapshot_ref.save(session=session) if instance_values: snapshot_ref.instance.update(instance_values) snapshot_ref.instance.save(session=session) return snapshot_ref@context_manager.writer session = session or context.session@context_manager.reader def share_snapshot_metadata_get(context, share_snapshot_id): session = context.session@context_manager.writer def share_snapshot_metadata_delete(context, share_snapshot_id, key): session = context.session@context_manager.writer session = context.session@context_manager.writer session = context.session@context_manager.reader session = context.session session = session or context.session session = session or context.session session = session or context.session@context_manager.writer session = session or context.session if delete: original_metadata = _share_snapshot_metadata_get( context, share_snapshot_id, session=session) for meta_key, meta_value in original_metadata.items(): if meta_key not in metadata: meta_ref = _share_snapshot_metadata_get_item( context, share_snapshot_id, meta_key, session=session) meta_ref.soft_delete(session=session) meta_ref = None # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} meta_ref = _share_snapshot_metadata_get_query( context, share_snapshot_id, session=session).filter_by( key=meta_key).first() if not meta_ref: meta_ref = models.ShareSnapshotMetadata() item.update({""key"": meta_key, ""share_snapshot_id"": share_snapshot_id}) meta_ref.update(item) meta_ref.save(session=session) return metadata@context_manager.writer session = context.session access_ref = models.ShareSnapshotAccessMapping() access_ref.update(values) access_ref.save(session=session) snapshot = share_snapshot_get(context, values['share_snapshot_id'], session=session) for instance in snapshot.instances: vals = { 'share_snapshot_instance_id': instance['id'], 'access_id': access_ref['id'], } _share_snapshot_instance_access_create(vals, session)@context_manager.reader def share_snapshot_instance_access_get_all(context, access_id, session=None):@context_manager.reader def share_snapshot_access_get(context, access_id, session=None): session = session or context.session@context_manager.reader session = context.session@context_manager.reader@context_manager.reader session = session or context.session@context_manager.writer session = context.session snapshot_access = _share_snapshot_access_get_query( context, session, {'id': access_id}).first() if not snapshot_access: raise exception.NotFound() snapshot_access.update(snapshot_access_map_updates) snapshot_access.save(session=session) access = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=instance_id).first() if not access: raise exception.NotFound() access.update(share_instance_access_map_updates) access.save(session=session) return access@context_manager.reader session = context.session access = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=share_snapshot_instance_id).first() if access is None: raise exception.NotFound() if with_snapshot_access_data: return _set_instances_snapshot_access_data( context, access, session)[0] else: return access@context_manager.writer session = context.session rule = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=snapshot_instance_id).first() if not rule: exception.NotFound() rule.soft_delete(session, update_status=True, status_field_name='state') other_mappings = share_snapshot_instance_access_get_all( context, rule['access_id'], session) if len(other_mappings) == 0: ( session.query(models.ShareSnapshotAccessMapping) .filter_by(id=rule['access_id']) .soft_delete(update_status=True, status_field_name='state') )@context_manager.writer session = context.session ssiel = models.ShareSnapshotInstanceExportLocation() ssiel.update(values) ssiel.save(session=session) return ssiel@context_manager.reader def share_snapshot_export_locations_get(context, snapshot_id): session = context.session@context_manager.reader session = context.session@context_manager.reader def share_snapshot_instance_export_location_get(context, el_id): session = context.session@context_manager.writer def share_snapshot_instance_export_location_delete(context, el_id): session = context.session el = _share_snapshot_instance_export_locations_get_query( context, session, {'id': el_id}).first() if not el: exception.NotFound() el.soft_delete(session=session)@context_manager.writer session = context.session@context_manager.reader@context_manager.reader def share_metadata_get_item(context, share_id, key, session=None): session = session or context.session@context_manager.writer@context_manager.writer@context_manager.writer session = context.session # Set existing metadata to deleted if delete argument is True delete = strutils.bool_from_string(delete) if delete: original_metadata = _share_metadata_get(context, share_id, session=session) for meta_key, meta_value in original_metadata.items(): if meta_key not in metadata: meta_ref.soft_delete(session=session) meta_ref = None # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} try: meta_ref = _share_metadata_get_item(context, share_id, meta_key, session=session) except exception.MetadataItemNotFound: meta_ref = models.ShareMetadata() item.update({""key"": meta_key, ""share_id"": share_id}) meta_ref.update(item) meta_ref.save(session=session) return metadata session = session or context.session@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader session = session or context.session@context_manager.writer session = context.session session = session or context.session@context_manager.reader@context_manager.writer def export_location_metadata_delete(context, export_location_uuid, keys=None): session = context.session@context_manager.writer session = session or context.session session = context.session@context_manager.writer session = context.session security_service_ref.save(session=session)@context_manager.writer def security_service_delete(context, id): session = context.session security_service_ref = security_service_get(context, id, session=session) security_service_ref.soft_delete(session)@context_manager.writer def security_service_update(context, id, values): session = context.session security_service_ref = security_service_get(context, id, session=session) security_service_ref.update(values) security_service_ref.save(session=session) return security_service_ref@context_manager.reader@context_manager.reader@context_manager.reader session = context.session@context_manager.reader def security_service_get_all_by_share_network(context, share_network_id): session = context.session session = context.session@context_manager.writer session = context.session network_ref.save(session=session)@context_manager.writer def share_network_delete(context, id): session = context.session network_ref = share_network_get(context, id, session=session) network_ref.soft_delete(session)@context_manager.writer def share_network_update(context, id, values): session = context.session network_ref = share_network_get(context, id, session=session) network_ref.update(values) network_ref.save(session=session) return network_ref@context_manager.reader@context_manager.reader session = context.session query = _network_get_query(context, session=session) legal_filter_keys = ('project_id', 'created_since', 'created_before') if not filters: filters = {} query = exact_filter(query, model_sn, filters, legal_filter_keys) if 'security_service_id' in filters: security_service_id = filters.get('security_service_id') query = query.join( models.ShareNetworkSecurityServiceAssociation, models.ShareNetwork.id == models. ShareNetworkSecurityServiceAssociation. share_network_id).filter_by( security_service_id=security_service_id, deleted=0) return query.all()@context_manager.reader@context_manager.reader@context_manager.reader def share_network_get_all_by_security_service(context, security_service_id): session = context.session@context_manager.writer def share_network_add_security_service(context, id, security_service_id): session = context.session assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session). filter_by(share_network_id=id). filter_by( security_service_id=security_service_id).first()) if assoc_ref: msg = ""Already associated"" raise exception.ShareNetworkSecurityServiceAssociationError( share_network_id=id, security_service_id=security_service_id, reason=msg) share_nw_ref = share_network_get(context, id, session=session) security_service_ref = security_service_get(context, security_service_id, session=session) share_nw_ref.security_services += [security_service_ref] share_nw_ref.save(session=session)@context_manager.reader session = context.session association = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session).filter_by( share_network_id=share_network_id).filter_by( security_service_id=security_service_id).first()) return association@context_manager.writer def share_network_remove_security_service(context, id, security_service_id): session = context.session share_nw_ref = share_network_get(context, id, session=session) security_service_get(context, security_service_id, session=session) assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session). filter_by(share_network_id=id). filter_by(security_service_id=security_service_id).first()) if assoc_ref: assoc_ref.soft_delete(session) else: msg = ""No association defined"" raise exception.ShareNetworkSecurityServiceDissociationError( share_network_id=id, security_service_id=security_service_id, reason=msg)@context_manager.writer session = context.session share_nw_ref = share_network_get(context, id, session=session) # Check if the old security service exists security_service_get(context, current_security_service_id, session=session) new_security_service_ref = security_service_get( context, new_security_service_id, session=session) assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session).filter_by( share_network_id=id).filter_by( security_service_id=current_security_service_id).first()) if assoc_ref: assoc_ref.soft_delete(session) else: msg = ""No association defined"" raise exception.ShareNetworkSecurityServiceDissociationError( share_network_id=id, security_service_id=current_security_service_id, reason=msg) # Add new association share_nw_ref.security_services += [new_security_service_ref] share_nw_ref.save(session=session) return share_nw_ref@context_manager.reader session = context.session@context_manager.writer session = context.session network_subnet_ref.save(session=session) return share_network_subnet_get( context, network_subnet_ref['id'], session=session)@context_manager.writer session = context.session network_subnet_ref = share_network_subnet_get(context, network_subnet_id, session=session) network_subnet_ref.soft_delete(session=session, update_status=True)@context_manager.writer def share_network_subnet_update(context, network_subnet_id, values): session = context.session network_subnet_ref = share_network_subnet_get(context, network_subnet_id, session=session) network_subnet_ref.update(values) network_subnet_ref.save(session=session) return network_subnet_ref@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader session = context.session@context_manager.writer session = context.session server_ref.save(session=session) # NOTE(u_glide): Do so to prevent errors with relationships return share_server_get(context, server_ref['id'], session=session)@context_manager.writer def share_server_delete(context, id): session = context.session server_ref = share_server_get(context, id, session=session) model_query( context, models.ShareServerShareNetworkSubnetMapping, session=session ).filter_by( share_server_id=id, ).soft_delete() share_server_backend_details_delete(context, id, session=session) server_ref.soft_delete(session=session, update_status=True)@context_manager.writer def share_server_update(context, id, values): session = context.session server_ref = share_server_get(context, id, session=session) server_ref.update(values) server_ref.save(session=session) return server_ref@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.writer session = context.session meta_ref.save(session)@context_manager.writer session = context.session@context_manager.writer session = session or context.session@context_manager.reader session = context.session@context_manager.writer session = context.session # Process existing data original_data = session.query(models.DriverPrivateData).filter_by( entity_uuid=entity_id).all() for data_ref in original_data: in_new_details = data_ref['key'] in new_details if in_new_details: new_value = str(new_details.pop(data_ref['key'])) data_ref.update({ ""value"": new_value, ""deleted"": 0, ""deleted_at"": None }) data_ref.save(session=session) elif delete_existing and data_ref['deleted'] != 1: data_ref.update({ ""deleted"": 1, ""deleted_at"": timeutils.utcnow() # Add new data for key, value in new_details.items(): data_ref = models.DriverPrivateData() data_ref.update({ ""entity_uuid"": entity_id, ""key"": key, ""value"": str(value) }) data_ref.save(session=session) return details@context_manager.writer session = context.session query = _driver_private_data_query(session, context, entity_id, key) query.update({""deleted"": 1, ""deleted_at"": timeutils.utcnow()})@context_manager.writer session = context.session alloc_ref.save(session=session)@context_manager.writer def network_allocation_delete(context, id): session = context.session alloc_ref = network_allocation_get(context, id, session=session) alloc_ref.soft_delete(session)@context_manager.reader session = context.session@context_manager.reader def network_allocations_get_by_ip_address(context, ip_address): session = context.session@context_manager.reader session = context.session@context_manager.writer def network_allocation_update(context, id, values, read_deleted=None): session = context.session alloc_ref = network_allocation_get(context, id, session=session, read_deleted=read_deleted) alloc_ref.update(values) alloc_ref.save(session=session) return alloc_ref@context_manager.writer session = context.session try: values['extra_specs'] = _metadata_refs(values.get('extra_specs'), models.ShareTypeExtraSpecs) share_type_ref = models.ShareTypes() share_type_ref.update(values) share_type_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareTypeExists(id=values['name']) except Exception as e: raise db_exception.DBError(e) for project in set(projects): access_ref = models.ShareTypeProjects() access_ref.update({""share_type_id"": share_type_ref.id, ""project_id"": project}) access_ref.save(session=session) return share_type_ref session = context.session query = model_query(context, model, session=session) try: result = query.filter_by(id=type_id).update(values) except db_exception.DBDuplicateEntry: # This exception only occurs if there's a non-deleted # share/group type which has the same name as the name being # updated. raise exists_exc(**exists_args) if not result: if is_group: raise exception.ShareGroupTypeNotFound(type_id=type_id) else: raise exception.ShareTypeNotFound(share_type_id=type_id) @context_manager.writer@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.writer def share_type_destroy(context, id): session = context.session _share_type_get(context, id, session) shares_count = model_query( context, models.ShareInstance, read_deleted=""no"", session=session, ).filter_by(share_type_id=id).count() share_group_types_count = model_query( context, models.ShareGroupTypeShareTypeMapping, read_deleted=""no"", session=session, ).filter_by(share_type_id=id).count() if shares_count or share_group_types_count: msg = (""Deletion of share type %(stype)s failed; it in use by "" ""%(shares)d shares and %(gtypes)d share group types"") msg_args = {'stype': id, 'shares': shares_count, 'gtypes': share_group_types_count} LOG.error(msg, msg_args) raise exception.ShareTypeInUse(share_type_id=id) model_query( context, models.ShareTypeExtraSpecs, session=session ).filter_by( share_type_id=id ).soft_delete() model_query( context, models.ShareTypeProjects, session=session ).filter_by( share_type_id=id, ).soft_delete() model_query( context, models.ShareTypes, session=session ).filter_by( id=id ).soft_delete()@context_manager.reader@context_manager.writer session = context.session try: access_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareTypeAccessExists(share_type_id=type_id, project_id=project_id) return access_ref@context_manager.writer@context_manager.reader@context_manager.writer def share_type_extra_specs_delete(context, share_type_id, key): session = context.session _share_type_extra_specs_get_item(context, share_type_id, key, session) (_share_type_extra_specs_query(context, share_type_id, session). filter_by(key=key).soft_delete())@context_manager.writer def share_type_extra_specs_update_or_create(context, share_type_id, specs): session = context.session spec_ref = None for key, value in specs.items(): try: spec_ref = _share_type_extra_specs_get_item( context, share_type_id, key, session) except exception.ShareTypeExtraSpecsNotFound: spec_ref = models.ShareTypeExtraSpecs() spec_ref.update({""key"": key, ""value"": value, ""share_type_id"": share_type_id, ""deleted"": 0}) spec_ref.save(session=session) return specs@context_manager.reader session = context.session az.save(session)@context_manager.reader def availability_zone_get_all(context): session = context.session@context_manager.writer session = context.session@context_manager.reader session = context.session@context_manager.writer session = context.session # Process existing data original_data = session.query( models.AsynchronousOperationData).filter_by( entity_uuid=entity_id).all() for data_ref in original_data: in_new_details = data_ref['key'] in new_details if in_new_details: new_value = str(new_details.pop(data_ref['key'])) data_ref.update({ ""value"": new_value, ""deleted"": 0, ""deleted_at"": None }) data_ref.save(session=session) elif delete_existing and data_ref['deleted'] != 1: data_ref.update({ ""deleted"": 1, ""deleted_at"": timeutils.utcnow() # Add new data for key, value in new_details.items(): data_ref = models.AsynchronousOperationData() data_ref.update({ ""entity_uuid"": entity_id, ""key"": key, ""value"": str(value) }) data_ref.save(session=session) return details@context_manager.writer session = context.session query = _async_operation_data_query(session, context, entity_id, key) query.update({""deleted"": 1, ""deleted_at"": timeutils.utcnow()})","def get_session(**kwargs): return context_manager._factory.get_legacy_facade().get_session(**kwargs) if not session: session = get_session() reservation_rollback( session = get_session() with session.begin(): if project_id is None: project_id = context.project_id if share_type_id: user_or_st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: user_id = user_id if user_id else context.user_id user_or_st_usages = _get_user_quota_usages( context, session, project_id, user_id) # Get the current usages project_usages = _get_project_quota_usages( context, session, project_id) # Handle usage refresh work = set(deltas.keys()) while work: resource = work.pop() # Do we need to refresh the usage? refresh = False if ((resource not in PER_PROJECT_QUOTAS) and (resource not in user_or_st_usages)): user_or_st_usages[resource] = _quota_usage_create( elevated, project_id, user_id, resource, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) elif ((resource in PER_PROJECT_QUOTAS) and (resource not in user_or_st_usages)): user_or_st_usages[resource] = _quota_usage_create( elevated, project_id, None, resource, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) refresh = True elif user_or_st_usages[resource].in_use < 0: # Negative in_use count indicates a desync, so try to # heal from that... refresh = True elif user_or_st_usages[resource].until_refresh is not None: user_or_st_usages[resource].until_refresh -= 1 if user_or_st_usages[resource].until_refresh <= 0: refresh = True elif max_age and (user_or_st_usages[resource].updated_at - timeutils.utcnow()).seconds >= max_age: refresh = True # OK, refresh the usage if refresh: # Grab the sync routine sync = QUOTA_SYNC_FUNCTIONS[resources[resource].sync] updates = sync( elevated, project_id, user_id, share_type_id=share_type_id, session=session) for res, in_use in updates.items(): # Make sure we have a destination for the usage! if ((res not in PER_PROJECT_QUOTAS) and (res not in user_or_st_usages)): user_or_st_usages[res] = _quota_usage_create( elevated, project_id, user_id, res, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) if ((res in PER_PROJECT_QUOTAS) and (res not in user_or_st_usages)): user_or_st_usages[res] = _quota_usage_create( elevated, project_id, None, res, 0, 0, until_refresh or None, share_type_id=share_type_id, session=session) if user_or_st_usages[res].in_use != in_use: LOG.debug( 'quota_usages out of sync, updating. ' 'project_id: %(project_id)s, ' 'user_id: %(user_id)s, ' 'share_type_id: %(share_type_id)s, ' 'resource: %(res)s, ' 'tracked usage: %(tracked_use)s, ' 'actual usage: %(in_use)s', {'project_id': project_id, 'user_id': user_id, 'share_type_id': share_type_id, 'res': res, 'tracked_use': user_or_st_usages[res].in_use, 'in_use': in_use}) # Update the usage user_or_st_usages[res].in_use = in_use user_or_st_usages[res].until_refresh = ( until_refresh or None) # Because more than one resource may be refreshed # by the call to the sync routine, and we don't # want to double-sync, we make sure all refreshed # resources are dropped from the work set. work.discard(res) # NOTE(Vek): We make the assumption that the sync # routine actually refreshes the # resources that it is the sync routine # for. We don't check, because this is # a best-effort mechanism. # Check for deltas that would go negative unders = [res for res, delta in deltas.items() if delta < 0 and delta + user_or_st_usages[res].in_use < 0] # Now, let's check the quotas # NOTE(Vek): We're only concerned about positive increments. # If a project has gone over quota, we want them to # be able to reduce their usage without any # problems. for key, value in user_or_st_usages.items(): if key not in project_usages: project_usages[key] = value overs = [res for res, delta in deltas.items() if user_or_st_quotas[res] >= 0 and delta >= 0 and (0 <= project_quotas[res] < delta + project_usages[res]['total'] or user_or_st_quotas[res] < delta + user_or_st_usages[res].total)] # NOTE(carloss): If OverQuota is allowed, there is no problem to exceed # the quotas, so we reset the overs list and LOG it. if overs and overquota_allowed: msg = _(""The service has identified one or more exceeded "" ""quotas. Please check the quotas for project "" ""%(project_id)s, user %(user_id)s and share type "" ""%(share_type_id)s, and adjust them if "" ""necessary."") % { ""project_id"": project_id, ""user_id"": user_id, ""share_type_id"": share_type_id } LOG.warning(msg) overs = [] # NOTE(Vek): The quota check needs to be in the transaction, # but the transaction doesn't fail just because # we're over quota, so the OverQuota raise is # outside the transaction. If we did the raise # here, our usage updates would be discarded, but # they're not invalidated by being over-quota. # Create the reservations if not overs: reservations = [] for res, delta in deltas.items(): reservation = _reservation_create(elevated, uuidutils.generate_uuid(), user_or_st_usages[res], project_id, user_id, res, delta, expire, share_type_id=share_type_id, session=session) reservations.append(reservation.uuid) # Also update the reserved quantity # NOTE(Vek): Again, we are only concerned here about # positive increments. Here, though, we're # worried about the following scenario: # # 1) User initiates resize down. # 2) User allocates a new instance. # 3) Resize down fails or is reverted. # 4) User is now over quota. # # To prevent this, we only update the # reserved value if the delta is positive. if delta > 0: user_or_st_usages[res].reserved += delta # Apply updates to the usages table for usage_ref in user_or_st_usages.values(): session.add(usage_ref) session = get_session() with session.begin(): if share_type_id: st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: st_usages = {} user_usages = _get_user_quota_usages( context, session, project_id, user_id) reservation_query = _quota_reservations_query( session, context, reservations) for reservation in reservation_query.all(): if reservation['share_type_id']: usages = st_usages else: usages = user_usages usage = usages[reservation.resource] if reservation.delta >= 0: usage.reserved -= reservation.delta usage.in_use += reservation.delta reservation_query.soft_delete(synchronize_session=False) session = get_session() with session.begin(): if share_type_id: st_usages = _get_share_type_quota_usages( context, session, project_id, share_type_id) else: st_usages = {} user_usages = _get_user_quota_usages( context, session, project_id, user_id) reservation_query = _quota_reservations_query( session, context, reservations) for reservation in reservation_query.all(): if reservation['share_type_id']: usages = st_usages else: usages = user_usages usage = usages[reservation.resource] if reservation.delta >= 0: usage.reserved -= reservation.delta reservation_query.soft_delete(synchronize_session=False)def quota_destroy_all_by_project_and_user(context, project_id, user_id): session = get_session() with session.begin(): (model_query(context, models.ProjectUserQuota, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False)) (model_query(context, models.QuotaUsage, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False)) (model_query(context, models.Reservation, session=session, read_deleted=""no""). filter_by(project_id=project_id). filter_by(user_id=user_id).soft_delete(synchronize_session=False)) session = get_session() with session.begin(): share_type_quotas = model_query( context, models.ProjectShareTypeQuota, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) share_type_quota_usages = model_query( context, models.QuotaUsage, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) share_type_quota_reservations = model_query( context, models.Reservation, session=session, read_deleted=""no"", ).filter_by(share_type_id=share_type_id) if project_id is not None: share_type_quotas = share_type_quotas.filter_by( project_id=project_id) share_type_quota_usages = share_type_quota_usages.filter_by( project_id=project_id) share_type_quota_reservations = ( share_type_quota_reservations.filter_by(project_id=project_id)) share_type_quotas.soft_delete(synchronize_session=False) share_type_quota_usages.soft_delete(synchronize_session=False) share_type_quota_reservations.soft_delete(synchronize_session=False)def quota_destroy_all_by_project(context, project_id): session = get_session() with session.begin(): (model_query(context, models.Quota, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.ProjectUserQuota, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.QuotaUsage, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False)) (model_query(context, models.Reservation, session=session, read_deleted=""no""). filter_by(project_id=project_id). soft_delete(synchronize_session=False))def reservation_expire(context): session = get_session() with session.begin(): current_time = timeutils.utcnow() reservation_query = (model_query( context, models.Reservation, session=session, read_deleted=""no""). filter(models.Reservation.expire < current_time)) for reservation in reservation_query.all(): if reservation.delta >= 0: quota_usage = model_query(context, models.QuotaUsage, session=session, read_deleted=""no"").filter( models.QuotaUsage.id == reservation.usage_id).first() quota_usage.reserved -= reservation.delta session.add(quota_usage) reservation_query.soft_delete(synchronize_session=False)def share_instance_create(context, share_id, values): session = get_session() with session.begin(): return _share_instance_create(context, share_id, values, session) session = get_session() with session.begin(): instance_ref = _share_instance_update( context, share_instance_id, values, session ) if with_share_data: parent_share = share_get(context, instance_ref['share_id'], session=session) instance_ref.set_share_data(parent_share) return instance_ref session = get_session() with session.begin(): if current_expected_status and share_instance_ids: filters = {'instance_ids': share_instance_ids} share_instances = share_instances_get_all( context, filters=filters, session=session) all_instances_are_compliant = all( instance['status'] == current_expected_status for instance in share_instances) if not all_instances_are_compliant: msg = _('At least one of the shares is not in the %(status)s ' 'status.') % { 'status': current_expected_status } raise exception.InvalidShareInstance(reason=msg) if current_expected_status and snapshot_instance_ids: filters = {'instance_ids': snapshot_instance_ids} snapshot_instances = share_snapshot_instance_get_all_with_filters( context, filters, session=session) all_snap_instances_are_compliant = all( snap_instance['status'] == current_expected_status for snap_instance in snapshot_instances) if not all_snap_instances_are_compliant: msg = _('At least one of the snapshots is not in the ' '%(status)s status.') % { 'status': current_expected_status } raise exception.InvalidShareSnapshotInstance(reason=msg) if share_instance_ids: updated_share_instances = share_instances_status_update( context, share_instance_ids, values, session=session) if snapshot_instance_ids: updated_snapshot_instances = ( share_snapshot_instances_status_update( context, snapshot_instance_ids, values, session=session)) session = session or get_session() session = get_session()def share_instances_get_all(context, filters=None, session=None): session = session or get_session() session = get_session() with session.begin(): share_export_locations_update(context, instance_id, [], delete=True) instance_ref = share_instance_get(context, instance_id, session=session) is_replica = instance_ref['replica_state'] is not None instance_ref.soft_delete(session=session, update_status=True) share = share_get(context, instance_ref['share_id'], session=session) if len(share.instances) == 0: share_access_delete_all_by_share(context, share['id']) session.query(models.ShareMetadata).filter_by( share_id=share['id']).soft_delete() share.soft_delete(session=session) if need_to_update_usages: _update_share_instance_usages(context, share, instance_ref, is_replica=is_replica) session = session or get_session() session = get_session() session = session or get_session() session = session or get_session() session = session or get_session() session = session or get_session() session = session or get_session() with session.begin(): _ensure_availability_zone_exists(context, values, session, strict=False) updated_share_replica = _share_instance_update( context, share_replica_id, values, session=session) if with_share_data: updated_share_replica = _set_instances_share_data( context, updated_share_replica, session)[0] session = session or get_session() session = get_session() session = get_session() with session.begin(): share_ref.save(session=session) if create_share_instance: _share_instance_create(context, share_ref['id'], share_instance_values, session=session) # NOTE(u_glide): Do so to prevent errors with relationships return share_get(context, share_ref['id'], session=session)def share_update(context, share_id, update_values): session = get_session() with session.begin(): share_ref = share_get(context, share_id, session=session) _share_instance_update(context, share_ref.instance['id'], share_instance_values, session=session) share_ref.update(share_values) share_ref.save(session=session) return share_refdef share_delete(context, share_id): session = get_session() with session.begin(): share_ref = share_get(context, share_id, session) if len(share_ref.instances) > 0: msg = _(""Share %(id)s has %(count)s share instances."") % { 'id': share_id, 'count': len(share_ref.instances)} raise exception.InvalidShare(msg) share_ref.soft_delete(session=session) (session.query(models.ShareMetadata). filter_by(share_id=share_id).soft_delete())def share_soft_delete(context, share_id): session = get_session() with session.begin(): share_ref = share_get(context, share_id, session=session) share_ref.update(update_values) share_ref.save(session=session)def share_restore(context, share_id): session = get_session() with session.begin(): share_ref = share_get(context, share_id, session=session) share_ref.update(update_values) share_ref.save(session=session)def share_access_metadata_update(context, access_id, metadata): session = get_session() with session.begin(): # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} try: meta_ref = _share_access_metadata_get_item( context, access_id, meta_key, session=session) except exception.ShareAccessMetadataNotFound: meta_ref = models.ShareAccessRulesMetadata() item.update({""key"": meta_key, ""access_id"": access_id}) meta_ref.update(item) meta_ref.save(session=session) return metadatadef share_access_metadata_delete(context, access_id, key): session = get_session() with session.begin(): metadata = _share_access_metadata_get_item( context, access_id, key, session=session) metadata.soft_delete(session) session = get_session() with session.begin(): values['share_access_rules_metadata'] = ( _metadata_refs(values.get('metadata'), models.ShareAccessRulesMetadata)) access_ref = models.ShareAccessMapping() access_ref.update(values) access_ref.save(session=session) parent_share = share_get(context, values['share_id'], session=session) for instance in parent_share.instances: vals = { 'share_instance_id': instance['id'], 'access_id': access_ref['id'], } _share_instance_access_create(vals, session) return share_access_get(context, access_ref['id']) @require_context def share_instance_access_create(context, values, share_instance_id): values = ensure_model_dict_has_id(values) session = get_session() with session.begin(): access_list = _share_access_get_query( context, session, { 'share_id': values['share_id'], 'access_type': values['access_type'], 'access_to': values['access_to'], }).all() if len(access_list) > 0: access_ref = access_list[0] else: access_ref = models.ShareAccessMapping() access_ref.update(values) access_ref.save(session=session) vals = { 'share_instance_id': share_instance_id, session = session or get_session() session = session or get_session() session = get_session() session = session or get_session() session = session or get_session() session = get_session() session = get_session() with session.begin(): if access_type == 'ip': rules = query_method( context, session, {'%s_id' % resource: resource_id, 'access_type': access_type}).filter( access_to_field.startswith(access_to.split('/')[0])).all() matching_rules = [ rule for rule in rules if ipaddress.ip_network(str(access_to)) == ipaddress.ip_network(str(rule['access_to'])) ] return len(matching_rules) > 0 else: return query_method( context, session, {'%s_id' % resource: resource_id, 'access_type': access_type, 'access_to': access_to}).count() > 0def share_access_delete_all_by_share(context, share_id): session = get_session() with session.begin(): (session.query(models.ShareAccessMapping). filter_by(share_id=share_id).soft_delete())def share_instance_access_delete(context, mapping_id): session = get_session() with session.begin(): mapping = (session.query(models.ShareInstanceAccessMapping). filter_by(id=mapping_id).first()) if not mapping: exception.NotFound() mapping.soft_delete(session, update_status=True, status_field_name='state') other_mappings = _share_instance_access_query( context, session, mapping['access_id']).all() # NOTE(u_glide): Remove access rule if all mappings were removed. if len(other_mappings) == 0: (session.query(models.ShareAccessRulesMetadata).filter_by( access_id=mapping['access_id']).soft_delete()) (session.query(models.ShareAccessMapping).filter_by( id=mapping['access_id']).soft_delete())def share_instance_access_update(context, access_id, instance_id, updates): session = get_session() with session.begin(): share_access = _share_access_get_query( context, session, {'id': access_id}).first() share_access.update(share_access_map_updates) share_access.save(session=session) access = _share_instance_access_query( context, session, access_id, instance_id).first() access.update(share_instance_access_map_updates) access.save(session=session) return accessdef share_snapshot_instance_create(context, snapshot_id, values, session=None): session = session or get_session()def share_snapshot_instance_update(context, instance_id, values): session = get_session() session = session or get_session() with session.begin(): snapshot_instance_ref = share_snapshot_instance_get( context, snapshot_instance_id, session=session) access_rules = share_snapshot_access_get_all_for_snapshot_instance( context, snapshot_instance_id, session=session) for rule in access_rules: share_snapshot_instance_access_delete( context, rule['access_id'], snapshot_instance_id) for el in snapshot_instance_ref.export_locations: share_snapshot_instance_export_location_delete(context, el['id']) snapshot_instance_ref.soft_delete( session=session, update_status=True) snapshot = share_snapshot_get( context, snapshot_instance_ref['snapshot_id'], session=session) if len(snapshot.instances) == 0: session.query(models.ShareSnapshotMetadata).filter_by( share_snapshot_id=snapshot['id']).soft_delete() snapshot.soft_delete(session=session) session = session or get_session() session = session or get_session() session = get_session() with session.begin(): snapshot_ref.save(session=session) if create_snapshot_instance: share_snapshot_instance_create( context, snapshot_ref['id'], snapshot_instance_values, session=session ) return share_snapshot_get( context, snapshot_values['id'], session=session)def share_snapshot_update(context, snapshot_id, values): session = get_session() with session.begin(): snapshot_ref = share_snapshot_get(context, snapshot_id, session=session) instance_values, snapshot_values = ( _extract_snapshot_instance_values(values) ) if snapshot_values: snapshot_ref.update(snapshot_values) snapshot_ref.save(session=session) if instance_values: snapshot_ref.instance.update(instance_values) snapshot_ref.instance.save(session=session) return snapshot_ref session = session or get_session()def share_snapshot_metadata_get(context, share_snapshot_id): session = get_session()def share_snapshot_metadata_delete(context, share_snapshot_id, key): session = get_session() session = get_session() session = get_session() session = get_session() session = session or get_session() session = session or get_session() session = session or get_session() session = session or get_session() with session.begin(): if delete: original_metadata = _share_snapshot_metadata_get( context, share_snapshot_id, session=session) for meta_key, meta_value in original_metadata.items(): if meta_key not in metadata: meta_ref = _share_snapshot_metadata_get_item( context, share_snapshot_id, meta_key, session=session) meta_ref.soft_delete(session=session) meta_ref = None # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} meta_ref = _share_snapshot_metadata_get_query( context, share_snapshot_id, session=session).filter_by( key=meta_key).first() if not meta_ref: meta_ref = models.ShareSnapshotMetadata() item.update({""key"": meta_key, ""share_snapshot_id"": share_snapshot_id}) meta_ref.update(item) meta_ref.save(session=session) return metadata session = get_session() with session.begin(): access_ref = models.ShareSnapshotAccessMapping() access_ref.update(values) access_ref.save(session=session) snapshot = share_snapshot_get(context, values['share_snapshot_id'], session=session) for instance in snapshot.instances: vals = { 'share_snapshot_instance_id': instance['id'], 'access_id': access_ref['id'], } _share_snapshot_instance_access_create(vals, session)def share_snapshot_instance_access_get_all(context, access_id, session):def share_snapshot_access_get(context, access_id, session=None): session = session or get_session() session = get_session() session = session or get_session() session = get_session() with session.begin(): snapshot_access = _share_snapshot_access_get_query( context, session, {'id': access_id}).first() if not snapshot_access: raise exception.NotFound() snapshot_access.update(snapshot_access_map_updates) snapshot_access.save(session=session) access = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=instance_id).first() if not access: raise exception.NotFound() access.update(share_instance_access_map_updates) access.save(session=session) return access session = get_session() with session.begin(): access = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=share_snapshot_instance_id).first() if access is None: raise exception.NotFound() if with_snapshot_access_data: return _set_instances_snapshot_access_data( context, access, session)[0] else: return access session = get_session() with session.begin(): rule = _share_snapshot_instance_access_get_query( context, session, access_id=access_id, share_snapshot_instance_id=snapshot_instance_id).first() if not rule: exception.NotFound() rule.soft_delete(session, update_status=True, status_field_name='state') other_mappings = share_snapshot_instance_access_get_all( context, rule['access_id'], session) if len(other_mappings) == 0: ( session.query(models.ShareSnapshotAccessMapping) .filter_by(id=rule['access_id']) .soft_delete(update_status=True, status_field_name='state') ) session = get_session() with session.begin(): ssiel = models.ShareSnapshotInstanceExportLocation() ssiel.update(values) ssiel.save(session=session) return ssieldef share_snapshot_export_locations_get(context, snapshot_id): session = get_session() session = get_session()def share_snapshot_instance_export_location_get(context, el_id): session = get_session()def share_snapshot_instance_export_location_delete(context, el_id): session = get_session() with session.begin(): el = _share_snapshot_instance_export_locations_get_query( context, session, {'id': el_id}).first() if not el: exception.NotFound() el.soft_delete(session=session) session = get_session()def share_metadata_get_item(context, share_id, key, session=None): session = session or get_session() session = get_session() with session.begin(): # Set existing metadata to deleted if delete argument is True delete = strutils.bool_from_string(delete) if delete: original_metadata = _share_metadata_get(context, share_id, session=session) for meta_key, meta_value in original_metadata.items(): if meta_key not in metadata: meta_ref = _share_metadata_get_item(context, share_id, meta_key, session=session) meta_ref.soft_delete(session=session) meta_ref = None # Now update all existing items with new values, or create new meta # objects for meta_key, meta_value in metadata.items(): # update the value whether it exists or not item = {""value"": meta_value} try: except exception.MetadataItemNotFound: meta_ref = models.ShareMetadata() item.update({""key"": meta_key, ""share_id"": share_id}) meta_ref.update(item) meta_ref.save(session=session) return metadata session = session or get_session() session = session or get_session() session = get_session() session = session or get_session()def export_location_metadata_delete(context, export_location_uuid, keys=None): session = get_session() session = session or get_session() session = get_session() session = get_session() with session.begin(): security_service_ref.save(session=session)def security_service_delete(context, id): session = get_session() with session.begin(): security_service_ref = security_service_get(context, id, session=session) security_service_ref.soft_delete(session)def security_service_update(context, id, values): session = get_session() with session.begin(): security_service_ref = security_service_get(context, id, session=session) security_service_ref.update(values) security_service_ref.save(session=session) return security_service_ref session = get_session()def security_service_get_all_by_share_network(context, share_network_id): session = get_session() session = get_session() session = get_session() with session.begin(): network_ref.save(session=session)def share_network_delete(context, id): session = get_session() with session.begin(): network_ref = share_network_get(context, id, session=session) network_ref.soft_delete(session)def share_network_update(context, id, values): session = get_session() with session.begin(): network_ref = share_network_get(context, id, session=session) network_ref.update(values) network_ref.save(session=session) return network_ref session = get_session() with session.begin(): query = _network_get_query(context, session=session) legal_filter_keys = ('project_id', 'created_since', 'created_before') if not filters: filters = {} query = exact_filter(query, model_sn, filters, legal_filter_keys) if 'security_service_id' in filters: security_service_id = filters.get('security_service_id') query = query.join( models.ShareNetworkSecurityServiceAssociation, models.ShareNetwork.id == models. ShareNetworkSecurityServiceAssociation. share_network_id).filter_by( security_service_id=security_service_id, deleted=0) return query.all()def share_network_get_all_by_security_service(context, security_service_id): session = get_session()def share_network_add_security_service(context, id, security_service_id): session = get_session() with session.begin(): assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session). filter_by(share_network_id=id). filter_by( security_service_id=security_service_id).first()) if assoc_ref: msg = ""Already associated"" raise exception.ShareNetworkSecurityServiceAssociationError( share_network_id=id, security_service_id=security_service_id, reason=msg) share_nw_ref = share_network_get(context, id, session=session) security_service_ref = security_service_get(context, security_service_id, session=session) share_nw_ref.security_services += [security_service_ref] share_nw_ref.save(session=session) session = get_session() with session.begin(): association = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session).filter_by( share_network_id=share_network_id).filter_by( security_service_id=security_service_id).first()) return associationdef share_network_remove_security_service(context, id, security_service_id): session = get_session() with session.begin(): share_nw_ref = share_network_get(context, id, session=session) security_service_get(context, security_service_id, session=session) assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session). filter_by(share_network_id=id). filter_by(security_service_id=security_service_id).first()) if assoc_ref: assoc_ref.soft_delete(session) else: msg = ""No association defined"" raise exception.ShareNetworkSecurityServiceDissociationError( share_network_id=id, security_service_id=security_service_id, reason=msg) session = get_session() with session.begin(): share_nw_ref = share_network_get(context, id, session=session) # Check if the old security service exists security_service_get(context, current_security_service_id, session=session) new_security_service_ref = security_service_get( context, new_security_service_id, session=session) assoc_ref = (model_query( context, models.ShareNetworkSecurityServiceAssociation, session=session).filter_by( share_network_id=id).filter_by( security_service_id=current_security_service_id).first()) if assoc_ref: assoc_ref.soft_delete(session) else: msg = ""No association defined"" raise exception.ShareNetworkSecurityServiceDissociationError( share_network_id=id, security_service_id=current_security_service_id, reason=msg) # Add new association share_nw_ref.security_services += [new_security_service_ref] share_nw_ref.save(session=session) return share_nw_ref session = get_session() session = get_session() with session.begin(): network_subnet_ref.save(session=session) return share_network_subnet_get( context, network_subnet_ref['id'], session=session) session = get_session() with session.begin(): network_subnet_ref = share_network_subnet_get(context, network_subnet_id, session=session) network_subnet_ref.soft_delete(session=session, update_status=True)def share_network_subnet_update(context, network_subnet_id, values): session = get_session() with session.begin(): network_subnet_ref = share_network_subnet_get(context, network_subnet_id, session=session) network_subnet_ref.update(values) network_subnet_ref.save(session=session) return network_subnet_ref session = get_session() session = get_session() with session.begin(): server_ref.save(session=session) # NOTE(u_glide): Do so to prevent errors with relationships return share_server_get(context, server_ref['id'], session=session)def share_server_delete(context, id): session = get_session() with session.begin(): server_ref = share_server_get(context, id, session=session) model_query( context, models.ShareServerShareNetworkSubnetMapping, session=session ).filter_by( share_server_id=id, ).soft_delete() share_server_backend_details_delete(context, id, session=session) server_ref.soft_delete(session=session, update_status=True)def share_server_update(context, id, values): session = get_session() with session.begin(): server_ref = share_server_get(context, id, session=session) server_ref.update(values) server_ref.save(session=session) return server_ref session = get_session() with session.begin(): meta_ref.save(session) session = get_session() session = session or get_session() session = get_session() session = get_session() with session.begin(): # Process existing data original_data = session.query(models.DriverPrivateData).filter_by( entity_uuid=entity_id).all() for data_ref in original_data: in_new_details = data_ref['key'] in new_details if in_new_details: new_value = str(new_details.pop(data_ref['key'])) data_ref.update({ ""value"": new_value, ""deleted"": 0, ""deleted_at"": None }) data_ref.save(session=session) elif delete_existing and data_ref['deleted'] != 1: data_ref.update({ ""deleted"": 1, ""deleted_at"": timeutils.utcnow() }) data_ref.save(session=session) # Add new data for key, value in new_details.items(): data_ref = models.DriverPrivateData() data_ref.update({ ""entity_uuid"": entity_id, ""key"": key, ""value"": str(value) return details session = get_session() with session.begin(): query = _driver_private_data_query(session, context, entity_id, key) query.update({""deleted"": 1, ""deleted_at"": timeutils.utcnow()}) session = get_session() with session.begin(): alloc_ref.save(session=session)def network_allocation_delete(context, id): session = get_session() with session.begin(): alloc_ref = network_allocation_get(context, id, session=session) alloc_ref.soft_delete(session) session = get_session()def network_allocations_get_by_ip_address(context, ip_address): session = get_session() session = get_session()def network_allocation_update(context, id, values, read_deleted=None): session = get_session() with session.begin(): alloc_ref = network_allocation_get(context, id, session=session, read_deleted=read_deleted) alloc_ref.update(values) alloc_ref.save(session=session) return alloc_ref session = get_session() with session.begin(): try: values['extra_specs'] = _metadata_refs(values.get('extra_specs'), models.ShareTypeExtraSpecs) share_type_ref = models.ShareTypes() share_type_ref.update(values) share_type_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareTypeExists(id=values['name']) except Exception as e: raise db_exception.DBError(e) for project in set(projects): access_ref = models.ShareTypeProjects() access_ref.update({""share_type_id"": share_type_ref.id, ""project_id"": project}) access_ref.save(session=session) return share_type_ref session = get_session() with session.begin(): query = model_query(context, model, session=session) try: result = query.filter_by(id=type_id).update(values) except db_exception.DBDuplicateEntry: # This exception only occurs if there's a non-deleted # share/group type which has the same name as the name being # updated. raise exists_exc(**exists_args) if not result: if is_group: raise exception.ShareGroupTypeNotFound(type_id=type_id) else: raise exception.ShareTypeNotFound(share_type_id=type_id) def share_type_destroy(context, id): session = get_session() with session.begin(): _share_type_get(context, id, session) shares_count = model_query( context, models.ShareInstance, read_deleted=""no"", session=session, ).filter_by(share_type_id=id).count() share_group_types_count = model_query( context, models.ShareGroupTypeShareTypeMapping, read_deleted=""no"", session=session, ).filter_by(share_type_id=id).count() if shares_count or share_group_types_count: msg = (""Deletion of share type %(stype)s failed; it in use by "" ""%(shares)d shares and %(gtypes)d share group types"") msg_args = {'stype': id, 'shares': shares_count, 'gtypes': share_group_types_count} LOG.error(msg, msg_args) raise exception.ShareTypeInUse(share_type_id=id) model_query( context, models.ShareTypeExtraSpecs, session=session ).filter_by( share_type_id=id ).soft_delete() model_query( context, models.ShareTypeProjects, session=session ).filter_by( share_type_id=id, ).soft_delete() model_query( context, models.ShareTypes, session=session ).filter_by( id=id ).soft_delete() session = get_session() with session.begin(): try: access_ref.save(session=session) except db_exception.DBDuplicateEntry: raise exception.ShareTypeAccessExists(share_type_id=type_id, project_id=project_id) return access_refdef share_type_extra_specs_delete(context, share_type_id, key): session = get_session() with session.begin(): _share_type_extra_specs_get_item(context, share_type_id, key, session) (_share_type_extra_specs_query(context, share_type_id, session). filter_by(key=key).soft_delete())def share_type_extra_specs_update_or_create(context, share_type_id, specs): session = get_session() with session.begin(): spec_ref = None for key, value in specs.items(): try: spec_ref = _share_type_extra_specs_get_item( context, share_type_id, key, session) except exception.ShareTypeExtraSpecsNotFound: spec_ref = models.ShareTypeExtraSpecs() spec_ref.update({""key"": key, ""value"": value, ""share_type_id"": share_type_id, ""deleted"": 0}) spec_ref.save(session=session) return specs session = get_session() with session.begin(): az.save(session)def availability_zone_get_all(context): session = get_session() session = get_session() session.begin() session.commit() session = get_session() session = get_session() with session.begin(): # Process existing data original_data = session.query( models.AsynchronousOperationData).filter_by( entity_uuid=entity_id).all() for data_ref in original_data: in_new_details = data_ref['key'] in new_details if in_new_details: new_value = str(new_details.pop(data_ref['key'])) data_ref.update({ ""value"": new_value, ""deleted"": 0, ""deleted_at"": None }) data_ref.save(session=session) elif delete_existing and data_ref['deleted'] != 1: data_ref.update({ ""deleted"": 1, ""deleted_at"": timeutils.utcnow() }) data_ref.save(session=session) # Add new data for key, value in new_details.items(): data_ref = models.AsynchronousOperationData() data_ref.update({ ""entity_uuid"": entity_id, ""key"": key, ""value"": str(value) return details session = get_session() with session.begin(): query = _async_operation_data_query(session, context, entity_id, key) query.update({""deleted"": 1, ""deleted_at"": timeutils.utcnow()})",1356,1231
openstack%2Freleases~master~I9ea6ae89bba99331185cd97c119034a227be2d35,openstack/releases,master,I9ea6ae89bba99331185cd97c119034a227be2d35,[cyborg] Transition Xena to EM,MERGED,2023-03-29 12:59:51.000000000,2023-04-14 09:26:46.000000000,2023-04-14 09:26:46.000000000,"[{'_account_id': 13629}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 28522}, {'_account_id': 31412}]","[{'number': 1, 'created': '2023-03-29 12:59:51.000000000', 'files': ['deliverables/xena/cyborg.yaml', 'deliverables/xena/python-cyborgclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/058644b50bbe00243fee65d9a9dba06831bc7771', 'message': '[cyborg] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I9ea6ae89bba99331185cd97c119034a227be2d35\n'}]",1,878867,058644b50bbe00243fee65d9a9dba06831bc7771,9,6,1,17685,,,0,"[cyborg] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I9ea6ae89bba99331185cd97c119034a227be2d35
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/878867/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/cyborg.yaml', 'deliverables/xena/python-cyborgclient.yaml']",2,058644b50bbe00243fee65d9a9dba06831bc7771,xena-em, - version: xena-em projects: - repo: openstack/python-cyborgclient hash: 2a8dc2449a5b6ed58aa79b10a7bf4571d8214457,,8,0
openstack%2Freleases~master~I6ef268bd0b8fa88294cb3e514fa18f51121a99c2,openstack/releases,master,I6ef268bd0b8fa88294cb3e514fa18f51121a99c2,[kuryr] Transition Xena to EM,MERGED,2023-03-29 13:00:35.000000000,2023-04-14 09:26:43.000000000,2023-04-14 09:26:43.000000000,"[{'_account_id': 13692}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:00:35.000000000', 'files': ['deliverables/xena/kuryr-libnetwork.yaml', 'deliverables/xena/kuryr-kubernetes.yaml', 'deliverables/xena/kuryr.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/07ebf80b37823178d647c8abeebe935ffd2a54cd', 'message': '[kuryr] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: I6ef268bd0b8fa88294cb3e514fa18f51121a99c2\n'}]",1,878871,07ebf80b37823178d647c8abeebe935ffd2a54cd,9,4,1,17685,,,0,"[kuryr] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: I6ef268bd0b8fa88294cb3e514fa18f51121a99c2
",git fetch https://review.opendev.org/openstack/releases refs/changes/71/878871/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/kuryr-libnetwork.yaml', 'deliverables/xena/kuryr-kubernetes.yaml', 'deliverables/xena/kuryr.yaml']",3,07ebf80b37823178d647c8abeebe935ffd2a54cd,xena-em, - version: xena-em projects: - repo: openstack/kuryr hash: 764de32607059a9a1a0bd37c46609815a1abe1ba,,12,0
openstack%2Freleases~master~Icdc5da7b9b7ec76dadd0a7ce3786ca918e4e4776,openstack/releases,master,Icdc5da7b9b7ec76dadd0a7ce3786ca918e4e4776,[senlin] Transition Xena to EM,MERGED,2023-03-29 13:10:06.000000000,2023-04-14 09:26:41.000000000,2023-04-14 09:26:41.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22998}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:10:06.000000000', 'files': ['deliverables/xena/senlin.yaml', 'deliverables/xena/senlin-dashboard.yaml', 'deliverables/xena/python-senlinclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e07c628a9e1bf994dfc7a10ffd3ef9774a78bd73', 'message': '[senlin] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Icdc5da7b9b7ec76dadd0a7ce3786ca918e4e4776\n'}]",2,878899,e07c628a9e1bf994dfc7a10ffd3ef9774a78bd73,9,4,1,17685,,,0,"[senlin] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Icdc5da7b9b7ec76dadd0a7ce3786ca918e4e4776
",git fetch https://review.opendev.org/openstack/releases refs/changes/99/878899/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/senlin.yaml', 'deliverables/xena/senlin-dashboard.yaml', 'deliverables/xena/python-senlinclient.yaml']",3,e07c628a9e1bf994dfc7a10ffd3ef9774a78bd73,xena-em, - version: xena-em projects: - repo: openstack/python-senlinclient hash: 9e21cdfd1aff56a6ab3b6a44286f7431d6cf53ad,,12,0
openstack%2Freleases~master~Ie398308289d3c77d8cb7e95eb234cd0b49f3a3d3,openstack/releases,master,Ie398308289d3c77d8cb7e95eb234cd0b49f3a3d3,[Telemetry] Transition Xena to EM,MERGED,2023-03-29 13:06:08.000000000,2023-04-14 09:25:58.000000000,2023-04-14 09:25:58.000000000,"[{'_account_id': 4264}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-03-29 13:06:08.000000000', 'files': ['deliverables/xena/python-aodhclient.yaml', 'deliverables/xena/aodh.yaml', 'deliverables/xena/ceilometer.yaml', 'deliverables/xena/ceilometermiddleware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d3069502ac4bac48b662c93d012ba7a995dcebbb', 'message': '[Telemetry] Transition Xena to EM\n\nThis transition the stable/xena branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch after the transition.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is April 20th, 2023.\n\nChange-Id: Ie398308289d3c77d8cb7e95eb234cd0b49f3a3d3\n'}]",1,878878,d3069502ac4bac48b662c93d012ba7a995dcebbb,9,4,1,17685,,,0,"[Telemetry] Transition Xena to EM

This transition the stable/xena branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch after the transition.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is April 20th, 2023.

Change-Id: Ie398308289d3c77d8cb7e95eb234cd0b49f3a3d3
",git fetch https://review.opendev.org/openstack/releases refs/changes/78/878878/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/python-aodhclient.yaml', 'deliverables/xena/aodh.yaml', 'deliverables/xena/ceilometer.yaml', 'deliverables/xena/ceilometermiddleware.yaml']",4,d3069502ac4bac48b662c93d012ba7a995dcebbb,xena-em, - version: xena-em projects: - repo: openstack/ceilometermiddleware hash: 082dabb1b7186f614664f69db32f80918b20d624,,16,0
openstack%2Fvenus-dashboard~master~Ic53916468b70d4dc36a725f4c4eae8dfb9bb730e,openstack/venus-dashboard,master,Ic53916468b70d4dc36a725f4c4eae8dfb9bb730e,log analysis develop5,MERGED,2023-04-14 09:04:06.000000000,2023-04-14 09:24:05.000000000,2023-04-14 09:24:05.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}]","[{'number': 1, 'created': '2023-04-14 09:04:06.000000000', 'files': ['venus_dashboard/log_analysis/urls.py'], 'web_link': 'https://opendev.org/openstack/venus-dashboard/commit/99d3a593ffc6e8ae225a9269147444458dea0db5', 'message': 'log analysis develop5\n\nChange-Id: Ic53916468b70d4dc36a725f4c4eae8dfb9bb730e\n'}]",0,880465,99d3a593ffc6e8ae225a9269147444458dea0db5,6,2,1,29602,,,0,"log analysis develop5

Change-Id: Ic53916468b70d4dc36a725f4c4eae8dfb9bb730e
",git fetch https://review.opendev.org/openstack/venus-dashboard refs/changes/65/880465/1 && git format-patch -1 --stdout FETCH_HEAD,['venus_dashboard/log_analysis/urls.py'],1,99d3a593ffc6e8ae225a9269147444458dea0db5,,from venus_dashboard.log_analysis import views,from venus_dashboard.log_search import views,1,1
openstack%2Fopenstack-ansible-os_sahara~master~I7707babe492dd8d348f8309e18aecba4dbf8b2a4,openstack/openstack-ansible-os_sahara,master,I7707babe492dd8d348f8309e18aecba4dbf8b2a4,Update api-paste to enable healthcheck,ABANDONED,2022-11-14 15:55:23.000000000,2023-04-14 09:19:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-14 15:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/32a06c7aa7196f880503ffef379659d66b846ee5', 'message': 'Update api-paste to enable healthcheck\n\nChange-Id: I7707babe492dd8d348f8309e18aecba4dbf8b2a4\n'}, {'number': 2, 'created': '2022-11-30 10:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/ecc258222bd3751867a25584493109b667b3ab93', 'message': 'Update api-paste to enable healthcheck\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/866124\nChange-Id: I7707babe492dd8d348f8309e18aecba4dbf8b2a4\n'}, {'number': 3, 'created': '2023-04-12 17:27:24.000000000', 'files': ['templates/api-paste.ini.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/0556b79032f77ae5e834765a2c503b81ebfdd7a2', 'message': 'Update api-paste to enable healthcheck\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/866124\nChange-Id: I7707babe492dd8d348f8309e18aecba4dbf8b2a4\n'}]",5,864422,0556b79032f77ae5e834765a2c503b81ebfdd7a2,17,1,3,28619,,,0,"Update api-paste to enable healthcheck

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/866124
Change-Id: I7707babe492dd8d348f8309e18aecba4dbf8b2a4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/22/864422/2 && git format-patch -1 --stdout FETCH_HEAD,['templates/api-paste.ini.j2'],1,32a06c7aa7196f880503ffef379659d66b846ee5,osa/healthcheck,/healthcheck: healthcheck [app:healthcheck] paste.app_factory = oslo_middleware:Healthcheck.app_factory backends = disable_by_file disable_by_file_path = /etc/sahara/healthcheck_disable,,6,0
openstack%2Foctavia~stable%2Fzed~I1a9a9177cafb8c52f13a646b12cff1c35afd8679,openstack/octavia,stable/zed,I1a9a9177cafb8c52f13a646b12cff1c35afd8679,Fix SQLAlchemy warning about conflict relationship with Tags,NEW,2023-04-14 06:18:30.000000000,2023-04-14 09:18:45.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-14 06:18:30.000000000', 'files': ['octavia/db/models.py', 'releasenotes/notes/remove-tags-relationship-warnings-a3c0175135f6cd84.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6ae577279fee13b80e3b8e50252d15c70668d388', 'message': ""Fix SQLAlchemy warning about conflict relationship with Tags\n\nSQLAlchemy shows a warning about a conflict with a relationship with the\nTags object:\n\n  SAWarning: relationship '<Obj1>._tags' will copy column <obj1>.id to\n  column tags.resource_id, which conflicts with relationship(s):\n  '<Obj2>._tags'\n\nRemove this warning by using the overlaps [0] keyword in the definition\nof the relationship.\n\n[0] https://docs.sqlalchemy.org/en/20/orm/relationship_api.html#\\\n    sqlalchemy.orm.relationship.params.overlaps\n\nChange-Id: I1a9a9177cafb8c52f13a646b12cff1c35afd8679\n(cherry picked from commit 8409c06cda0bb3e3c0795b14ec3917ca2b5afe7b)\n""}]",0,880447,6ae577279fee13b80e3b8e50252d15c70668d388,2,1,1,29244,,,0,"Fix SQLAlchemy warning about conflict relationship with Tags

SQLAlchemy shows a warning about a conflict with a relationship with the
Tags object:

  SAWarning: relationship '<Obj1>._tags' will copy column <obj1>.id to
  column tags.resource_id, which conflicts with relationship(s):
  '<Obj2>._tags'

Remove this warning by using the overlaps [0] keyword in the definition
of the relationship.

[0] https://docs.sqlalchemy.org/en/20/orm/relationship_api.html#\
    sqlalchemy.orm.relationship.params.overlaps

Change-Id: I1a9a9177cafb8c52f13a646b12cff1c35afd8679
(cherry picked from commit 8409c06cda0bb3e3c0795b14ec3917ca2b5afe7b)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/47/880447/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/db/models.py', 'releasenotes/notes/remove-tags-relationship-warnings-a3c0175135f6cd84.yaml']",2,6ae577279fee13b80e3b8e50252d15c70668d388,,--- fixes: - | Fixed SQLAlchemy warnings about the relationship between the Tags object and the other Octavia resources. ,,19,7
