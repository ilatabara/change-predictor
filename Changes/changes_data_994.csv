id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fkolla~master~Icbad4e77588f212af104efc9e6cfbd831c795a07,openstack/kolla,master,Icbad4e77588f212af104efc9e6cfbd831c795a07,Updated from global requirements,MERGED,2016-03-05 15:32:53.000000000,2016-03-07 09:12:07.000000000,2016-03-07 09:12:07.000000000,"[{'_account_id': 3}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 15:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b950e7d777797aaf68bcb7572b19dfb9c1124ca0', 'message': 'Updated from global requirements\n\nChange-Id: Icbad4e77588f212af104efc9e6cfbd831c795a07\n'}, {'number': 2, 'created': '2016-03-05 20:45:37.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f66af0c1320193755e5017d24176aa653a5ab39e', 'message': 'Updated from global requirements\n\nChange-Id: Icbad4e77588f212af104efc9e6cfbd831c795a07\n'}]",0,288890,f66af0c1320193755e5017d24176aa653a5ab39e,11,5,2,11131,,,0,"Updated from global requirements

Change-Id: Icbad4e77588f212af104efc9e6cfbd831c795a07
",git fetch https://review.opendev.org/openstack/kolla refs/changes/90/288890/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,b950e7d777797aaf68bcb7572b19dfb9c1124ca0,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Fgnocchi~stable%2F2.0~I66d01023d3fe78038aa61a5be9c93a346e3d4726,openstack/gnocchi,stable/2.0,I66d01023d3fe78038aa61a5be9c93a346e3d4726,Pass aggregation when create AggregatedTimeSerie,MERGED,2016-03-07 07:11:40.000000000,2016-03-07 09:11:55.000000000,2016-03-07 09:11:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2016-03-07 07:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5f7931b9e58b0cc028d25a1ce344cb553a74579d', 'message': 'Pass aggregation when create AggregatedTimeSerie\n\nChange-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726\nCloses-bug: #1552437\n(cherry picked from commit 23262820683421c604c8be636cfe5afa584b1356)\n'}, {'number': 2, 'created': '2016-03-07 07:51:53.000000000', 'files': ['gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1ed960afdcc286dea41edb900b20922ae89f1a16', 'message': 'Pass aggregation when create AggregatedTimeSerie\n\nChange-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726\nCloses-bug: #1552437\n(cherry picked from commit 23262820683421c604c8be636cfe5afa584b1356)\n'}]",0,289186,1ed960afdcc286dea41edb900b20922ae89f1a16,7,2,2,2813,,,0,"Pass aggregation when create AggregatedTimeSerie

Change-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726
Closes-bug: #1552437
(cherry picked from commit 23262820683421c604c8be636cfe5afa584b1356)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/86/289186/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py']",2,5f7931b9e58b0cc028d25a1ce344cb553a74579d,bug/1552437," def test_updated_measures(self): self.storage.add_measures(self.metric, [ storage.Measure(datetime.datetime(2014, 1, 1, 12, 0, 1), 69), storage.Measure(datetime.datetime(2014, 1, 1, 12, 7, 31), 42), ]) self.storage.process_background_tasks(self.index, sync=True) self.storage.add_measures(self.metric, [ storage.Measure(datetime.datetime(2014, 1, 1, 12, 9, 31), 4), storage.Measure(datetime.datetime(2014, 1, 1, 12, 12, 45), 44), ]) self.storage.process_background_tasks(self.index, sync=True) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 39.75), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 39.75), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 23.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric)) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 69), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 42.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric, aggregation='max')) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 4), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 4), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 4.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric, aggregation='min')) ",,38,0
openstack%2Fkolla~master~I8bb2398ebdf4b10fe8386f5b2b25802172e1cbd3,openstack/kolla,master,I8bb2398ebdf4b10fe8386f5b2b25802172e1cbd3,Reconfigure horizon service,MERGED,2016-03-07 03:45:17.000000000,2016-03-07 09:11:31.000000000,2016-03-07 09:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 14027}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-07 03:45:17.000000000', 'files': ['ansible/roles/horizon/tasks/reconfigure.yml', 'ansible/roles/horizon/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9a5150275bd99b350ed521e87bb1bb9c2cdfe737', 'message': 'Reconfigure horizon service\n\nImplements reconfiguring the horizon service.\n\nCloses-Bug: #1553526\n\nChange-Id: I8bb2398ebdf4b10fe8386f5b2b25802172e1cbd3\n'}]",0,289126,9a5150275bd99b350ed521e87bb1bb9c2cdfe737,7,3,1,7488,,,0,"Reconfigure horizon service

Implements reconfiguring the horizon service.

Closes-Bug: #1553526

Change-Id: I8bb2398ebdf4b10fe8386f5b2b25802172e1cbd3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/289126/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/horizon/tasks/reconfigure.yml', 'ansible/roles/horizon/tasks/do_reconfigure.yml']",2,9a5150275bd99b350ed521e87bb1bb9c2cdfe737,bug/1553526,"--- - name: Ensuring the containers up kolla_docker: name: ""{{ item.name }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false when: inventory_hostname in groups[item.group] with_items: - { name: horizon, group: horizon } - include: config.yml - name: Check the configs command: docker exec {{ item.name }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false register: check_results when: inventory_hostname in groups[item.group] with_items: - { name: horizon, group: horizon } # NOTE(jeffrey4l): when config_strategy == 'COPY_ALWAYS' # and container env['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE', # just remove the container and start again - name: Containers config strategy kolla_docker: name: ""{{ item.name }}"" action: ""get_container_env"" register: container_envs when: inventory_hostname in groups[item.group] with_items: - { name: horizon, group: horizon } - name: Remove the containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""remove_container"" register: remove_containers when: - config_strategy == ""COPY_ONCE"" or item[1]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: horizon, group: horizon }] - container_envs.results - check_results.results - include: start.yml when: remove_containers.changed - name: Restart containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""restart_container"" when: - config_strategy == 'COPY_ALWAYS' - item[1]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: horizon, group: horizon }] - container_envs.results - check_results.results ",,67,0
openstack%2Fkolla~master~Ia3e206e10b24bae12857ea13becda55bc13f33fd,openstack/kolla,master,Ia3e206e10b24bae12857ea13becda55bc13f33fd,Upgrade fails at Magnum,MERGED,2016-03-06 03:07:54.000000000,2016-03-07 09:04:03.000000000,2016-03-07 09:04:03.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-06 03:07:54.000000000', 'files': ['ansible/roles/magnum/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/355b6a459993adde7898d2d1082cce548a9ac019', 'message': 'Upgrade fails at Magnum\n\nTypo in magnum upgrade task\n\nChange-Id: Ia3e206e10b24bae12857ea13becda55bc13f33fd\nCloses-Bug: #1553643\n'}]",0,288968,355b6a459993adde7898d2d1082cce548a9ac019,9,5,1,2834,,,0,"Upgrade fails at Magnum

Typo in magnum upgrade task

Change-Id: Ia3e206e10b24bae12857ea13becda55bc13f33fd
Closes-Bug: #1553643
",git fetch https://review.opendev.org/openstack/kolla refs/changes/68/288968/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/magnum/tasks/upgrade.yml'],1,355b6a459993adde7898d2d1082cce548a9ac019,bug/1553643,- include: start.yml,- include: start.tml,1,1
openstack%2Fkolla~master~I737a71598a6a9747999cfcfbe78c70dbb6fdc608,openstack/kolla,master,I737a71598a6a9747999cfcfbe78c70dbb6fdc608,Make memcached reconfigure not block,MERGED,2016-03-06 02:22:39.000000000,2016-03-07 09:03:43.000000000,2016-03-07 09:03:43.000000000,"[{'_account_id': 3}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 16620}]","[{'number': 1, 'created': '2016-03-06 02:22:39.000000000', 'files': ['ansible/roles/memcached/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/004880397ad38d519ad05a771a21c2cf88194ca1', 'message': 'Make memcached reconfigure not block\n\nThe playbooks crash during reconfigure of memcached.\n\nChange-Id: I737a71598a6a9747999cfcfbe78c70dbb6fdc608\nCloses-Bug: #1553631\n'}]",0,288963,004880397ad38d519ad05a771a21c2cf88194ca1,9,5,1,2834,,,0,"Make memcached reconfigure not block

The playbooks crash during reconfigure of memcached.

Change-Id: I737a71598a6a9747999cfcfbe78c70dbb6fdc608
Closes-Bug: #1553631
",git fetch https://review.opendev.org/openstack/kolla refs/changes/63/288963/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/memcached/tasks/do_reconfigure.yml'],1,004880397ad38d519ad05a771a21c2cf88194ca1,bug/1553631," - [{ name: memcached, group: memcached }] - [{ name: memcached, group: memcached }]"," - { name: memcached, group: memcached } - { name: memcached, group: memcached }",2,2
openstack%2Fcharm-keystone~master~I60482a18e69998e35852982de3e1b94b34fc6ce6,openstack/charm-keystone,master,I60482a18e69998e35852982de3e1b94b34fc6ce6,Enable Xenial-Mitaka amulet test target.,MERGED,2016-03-04 14:42:34.000000000,2016-03-07 09:03:18.000000000,2016-03-07 09:03:18.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 14:42:34.000000000', 'files': ['tests/021-basic-xenial-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/cd227779f7172c5f3131e3ac9a74f24961225c3b', 'message': 'Enable Xenial-Mitaka amulet test target.\n\nChange-Id: I60482a18e69998e35852982de3e1b94b34fc6ce6\n'}]",0,288494,cd227779f7172c5f3131e3ac9a74f24961225c3b,9,3,1,20635,,,0,"Enable Xenial-Mitaka amulet test target.

Change-Id: I60482a18e69998e35852982de3e1b94b34fc6ce6
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/94/288494/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/021-basic-xenial-mitaka'],1,cd227779f7172c5f3131e3ac9a74f24961225c3b,amulet-xenial-enable,,,0,0
openstack%2Fopenstack-manuals~master~Iec118a83892512664d53463980b9974882f06b6e,openstack/openstack-manuals,master,Iec118a83892512664d53463980b9974882f06b6e,Added note about partial spec for ml2 plugin,MERGED,2016-03-07 05:23:48.000000000,2016-03-07 09:03:02.000000000,2016-03-07 09:03:02.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-07 05:23:48.000000000', 'files': ['doc/config-reference/source/networking/networking_options_reference.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a607ca3f50b5a97cb19ad7ddd2b0cab308a8b235', 'message': 'Added note about partial spec for ml2 plugin\n\nAs per bug, added information about partial spec.\n\nChange-Id: Iec118a83892512664d53463980b9974882f06b6e\nCloses-Bug: #1345948\n'}]",0,289140,a607ca3f50b5a97cb19ad7ddd2b0cab308a8b235,7,3,1,9162,,,0,"Added note about partial spec for ml2 plugin

As per bug, added information about partial spec.

Change-Id: Iec118a83892512664d53463980b9974882f06b6e
Closes-Bug: #1345948
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/289140/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/networking/networking_options_reference.rst'],1,a607ca3f50b5a97cb19ad7ddd2b0cab308a8b235,bug/1345948,"components separately. The ml2 plugin also allows administrators to perform a partial specification, where some options are specified explicitly in the configuration, and the remainder is allowed to be chosen automatically by the Compute service. This section describes the available configuration options.",components separately. This section describes these configuration options.,6,2
openstack%2Fopenstack-ansible-lxc_hosts~master~Ie135adf0e458bd964c2d43a645d65907c0a6eac6,openstack/openstack-ansible-lxc_hosts,master,Ie135adf0e458bd964c2d43a645d65907c0a6eac6,Reorder lxc networking tasks,MERGED,2016-03-06 05:25:57.000000000,2016-03-07 09:02:28.000000000,2016-03-07 09:02:28.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-06 05:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/14809b312a62e41036f66e4c9b124e1bf54fc856', 'message': 'Reorder lxc networking tasks\n\nChange the order of tasks so that dropping the lxc bridge interface\nconfiguration file occurs before checking for, and bringing up, the lxc\nbridge interface.\n\nChange-Id: Ie135adf0e458bd964c2d43a645d65907c0a6eac6\n'}, {'number': 2, 'created': '2016-03-06 06:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ef91f2ac32be23dcc16a65e7709568729a00ae0e', 'message': 'Reorder lxc networking tasks\n\nChange the order of tasks so that dropping the lxc bridge interface\nconfiguration file occurs before checking for, and bringing up, the lxc\nbridge interface.\n\nAlso put the lxc-net.override file in place prior to lxc being\ninstalled. Without this file, the lxcbr0 bridge will automatically be\ncreated and assigned an address when the lxc service is started.\n\nChange-Id: Ie135adf0e458bd964c2d43a645d65907c0a6eac6\n'}, {'number': 3, 'created': '2016-03-06 07:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/cf0ab92e8f9cba1f4a0ce37c9f395001c9b68867', 'message': ""Reorder lxc networking tasks\n\nDrop the lxc bridge interface configuration file occurs before checking\nfor, and bringing up, the lxc bridge interface. Also, put the\nlxc-net.override file in place prior to lxc being installed. Without\nthis file, the lxcbr0 bridge will automatically be created and assigned\nan address when the lxc service is started.\n\nTests has been added and updated to ensure that the lxc bridge interface\nconfiguration file looks as expected and the bridge interface itself\nhas the expected IP address when overriding the role's default\nlxc_net_address variable.\n\nChange-Id: Ie135adf0e458bd964c2d43a645d65907c0a6eac6\n""}, {'number': 4, 'created': '2016-03-06 07:06:13.000000000', 'files': ['tasks/lxc_net.yml', 'tests/files/expected-lxc-net-bridge.cfg', 'tasks/lxc_post_install.yml', 'tests/test.yml', 'tasks/lxc_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ad8908a1539712812e39a99911ee7490584807e1', 'message': ""Reorder lxc networking tasks\n\nDrop the lxc bridge interface configuration file before checking for,\nand bringing up, the lxc bridge interface. Also, put the\nlxc-net.override file in place prior to lxc being installed. Without\nthis file, the lxcbr0 bridge will automatically be created and assigned\nan address when the lxc service is started.\n\nTests has been added and updated to ensure that the lxc bridge interface\nconfiguration file looks as expected and the bridge interface itself\nhas the expected IP address when overriding the role's default\nlxc_net_address variable.\n\nChange-Id: Ie135adf0e458bd964c2d43a645d65907c0a6eac6\n""}]",0,288971,ad8908a1539712812e39a99911ee7490584807e1,14,4,4,14805,,,0,"Reorder lxc networking tasks

Drop the lxc bridge interface configuration file before checking for,
and bringing up, the lxc bridge interface. Also, put the
lxc-net.override file in place prior to lxc being installed. Without
this file, the lxcbr0 bridge will automatically be created and assigned
an address when the lxc service is started.

Tests has been added and updated to ensure that the lxc bridge interface
configuration file looks as expected and the bridge interface itself
has the expected IP address when overriding the role's default
lxc_net_address variable.

Change-Id: Ie135adf0e458bd964c2d43a645d65907c0a6eac6
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/71/288971/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_net.yml'],1,14809b312a62e41036f66e4c9b124e1bf54fc856,reorder_lxc_net_tasks,"- name: Drop lxc net bridge template: src: ""lxc-net-bridge.cfg.j2"" dest: ""/etc/network/interfaces.d/lxc-net-bridge.cfg"" owner: ""root"" group: ""root"" mode: ""0644"" tags: - lxc-files - lxc-net - lxc-bridge "," - name: Drop lxc net bridge template: src: ""lxc-net-bridge.cfg.j2"" dest: ""/etc/network/interfaces.d/lxc-net-bridge.cfg"" owner: ""root"" group: ""root"" mode: ""0644"" tags: - lxc-files - lxc-net - lxc-bridge",12,12
openstack%2Fcharm-glance~master~Iaefe423193c33ce7d83eb545fc9040c57199e451,openstack/charm-glance,master,Iaefe423193c33ce7d83eb545fc9040c57199e451,Enable Xenial-Mitaka amulet test target.,MERGED,2016-03-04 14:40:25.000000000,2016-03-07 09:00:32.000000000,2016-03-07 09:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 14:40:25.000000000', 'files': ['tests/021-basic-xenial-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/babf0a33cee33805030399b0ccd11d4fdc2f3eab', 'message': 'Enable Xenial-Mitaka amulet test target.\n\nChange-Id: Iaefe423193c33ce7d83eb545fc9040c57199e451\n'}]",0,288492,babf0a33cee33805030399b0ccd11d4fdc2f3eab,9,3,1,20635,,,0,"Enable Xenial-Mitaka amulet test target.

Change-Id: Iaefe423193c33ce7d83eb545fc9040c57199e451
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/92/288492/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/021-basic-xenial-mitaka'],1,babf0a33cee33805030399b0ccd11d4fdc2f3eab,amulet-xenial-enable,,,0,0
openstack%2Fcharm-ceph-radosgw~master~I5d45747b1c9500f8aea219a212d4bab9a7381526,openstack/charm-ceph-radosgw,master,I5d45747b1c9500f8aea219a212d4bab9a7381526,Enable Xenial-Mitaka amulet test target.,MERGED,2016-03-04 13:56:37.000000000,2016-03-07 09:00:10.000000000,2016-03-07 09:00:10.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 13:56:37.000000000', 'files': ['tests/021-basic-xenial-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/27be90e03a37c97467c724eb7935715dfd1a4a71', 'message': 'Enable Xenial-Mitaka amulet test target.\n\nChange-Id: I5d45747b1c9500f8aea219a212d4bab9a7381526\n'}]",0,288459,27be90e03a37c97467c724eb7935715dfd1a4a71,9,3,1,20635,,,0,"Enable Xenial-Mitaka amulet test target.

Change-Id: I5d45747b1c9500f8aea219a212d4bab9a7381526
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/59/288459/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/021-basic-xenial-mitaka'],1,27be90e03a37c97467c724eb7935715dfd1a4a71,amulet-xenial-enable,,,0,0
openstack%2Fcharm-cinder~master~I947e0b4cb6eecfd819155dafaa5b88e7eee0dcff,openstack/charm-cinder,master,I947e0b4cb6eecfd819155dafaa5b88e7eee0dcff,Enable Xenial-Mitaka amulet test target.,MERGED,2016-03-04 14:39:41.000000000,2016-03-07 08:58:43.000000000,2016-03-07 08:58:43.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 14:39:41.000000000', 'files': ['tests/021-basic-xenial-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/a9aac060834b8d036bd3318a4ed55a746a5c8c94', 'message': 'Enable Xenial-Mitaka amulet test target.\n\nChange-Id: I947e0b4cb6eecfd819155dafaa5b88e7eee0dcff\n'}]",0,288489,a9aac060834b8d036bd3318a4ed55a746a5c8c94,9,3,1,20635,,,0,"Enable Xenial-Mitaka amulet test target.

Change-Id: I947e0b4cb6eecfd819155dafaa5b88e7eee0dcff
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/89/288489/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/021-basic-xenial-mitaka'],1,a9aac060834b8d036bd3318a4ed55a746a5c8c94,amulet-xenial-enable,,,0,0
openstack%2Fcharm-rabbitmq-server~master~I66cb4f53586f7838e9adc2f73a551926e10b9942,openstack/charm-rabbitmq-server,master,I66cb4f53586f7838e9adc2f73a551926e10b9942,Enable Xenial-Mitaka amulet test target.,MERGED,2016-03-04 14:43:24.000000000,2016-03-07 08:58:11.000000000,2016-03-07 08:58:11.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 14:43:24.000000000', 'files': ['tests/021-basic-xenial-mitaka'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/c620121e032ed70c030b6ff30b1e193e041d5b71', 'message': 'Enable Xenial-Mitaka amulet test target.\n\nChange-Id: I66cb4f53586f7838e9adc2f73a551926e10b9942\n'}]",0,288496,c620121e032ed70c030b6ff30b1e193e041d5b71,11,3,1,20635,,,0,"Enable Xenial-Mitaka amulet test target.

Change-Id: I66cb4f53586f7838e9adc2f73a551926e10b9942
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/96/288496/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/021-basic-xenial-mitaka'],1,c620121e032ed70c030b6ff30b1e193e041d5b71,amulet-xenial-enable,,,0,0
openstack%2Fgnocchi~master~Iec84957eceee57a430655379ef4a94a20cd6a6ff,openstack/gnocchi,master,Iec84957eceee57a430655379ef4a94a20cd6a6ff,optimise timeseries,MERGED,2016-03-02 04:11:32.000000000,2016-03-07 08:54:49.000000000,2016-03-07 08:54:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-03-02 04:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0cd5198409152f556ca8dc0a6dd6c95bd81ca789', 'message': 'remove unnecessary sort_index\n\nwe don\'t need to sort_index when using set_values because the ts is\nsorted and the ts passed in is sorted (via BoundedTimeSerie). sort_index\nis redundant because combine_first maintains ordering when merging. also,\nfrom what i can tell, sort_index is the reason for random\n""cannot reindex from a duplicate axis"" errors that are thrown (see bug).\n\nthis patch also uses drop rather than overly complicated double slice\nand merging that was happening previously.\n\nChange-Id: Iec84957eceee57a430655379ef4a94a20cd6a6ff\nCloses-Bug: #1548448\n'}, {'number': 2, 'created': '2016-03-02 13:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e23dfb99e2d54074c854c7b43b7fda4e55428778', 'message': ""remove unnecessary sort_index\n\nwe don't need to sort_index when using set_values because the ts is\nsorted and the ts passed in is sorted (via BoundedTimeSerie). sort_index\nis redundant because combine_first maintains ordering when merging.\n\nthis patch also uses drop rather than overly complicated double slice\nand merging that was happening previously.\n\nChange-Id: Iec84957eceee57a430655379ef4a94a20cd6a6ff\nRelated-Bug: #1548448\n""}, {'number': 3, 'created': '2016-03-03 03:29:37.000000000', 'files': ['gnocchi/carbonara.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/37c4909a28e0252c33e193740cd4f01c1f6b3960', 'message': ""optimise timeseries\n\nwe don't need necessarily need to use to sort_index when using\nset_values because the ts is sorted and the ts passed in may be\nsorted (via BoundedTimeSerie). we should sort only when required.\n\nalso, it's much more efficient to remove duplicates by leveraging\nduplicated() vs groupby(level=0).last()[1]\n\nthis patch also uses drop rather than overly complicated double slice\nand merging that was happening previously.\n\n[1] http://paste.openstack.org/show/489078/\n\nChange-Id: Iec84957eceee57a430655379ef4a94a20cd6a6ff\nRelated-Bug: #1548448\n""}]",0,286975,37c4909a28e0252c33e193740cd4f01c1f6b3960,15,4,3,6537,,,0,"optimise timeseries

we don't need necessarily need to use to sort_index when using
set_values because the ts is sorted and the ts passed in may be
sorted (via BoundedTimeSerie). we should sort only when required.

also, it's much more efficient to remove duplicates by leveraging
duplicated() vs groupby(level=0).last()[1]

this patch also uses drop rather than overly complicated double slice
and merging that was happening previously.

[1] http://paste.openstack.org/show/489078/

Change-Id: Iec84957eceee57a430655379ef4a94a20cd6a6ff
Related-Bug: #1548448
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/75/286975/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/carbonara.py'],1,0cd5198409152f556ca8dc0a6dd6c95bd81ca789,bug/1548448, self.ts = t.combine_first(self.ts) new_ts = self.ts.drop(self.ts[first_timestamp:last_timestamp].index), self.ts = t.combine_first(self.ts).sort_index() new_ts = self.ts[:first_timestamp].combine_first( self.ts[last_timestamp:]),2,3
openstack%2Fgnocchi~master~I226a0ba317ec4412159c2afa8f68895e00535e51,openstack/gnocchi,master,I226a0ba317ec4412159c2afa8f68895e00535e51,close queues,MERGED,2016-02-29 19:48:21.000000000,2016-03-07 08:53:38.000000000,2016-03-07 08:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2016-02-29 19:48:21.000000000', 'files': ['gnocchi/cli.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f2182801a734de71a490487308460f6bb307c60f', 'message': ""close queues\n\nmetricd service catches SIGTERM and kills all children\nmultiprocessing handles. we can't detect queues at this step so\ninspect the children and kill queues as required.\n\nChange-Id: I226a0ba317ec4412159c2afa8f68895e00535e51\n""}]",0,286246,f2182801a734de71a490487308460f6bb307c60f,8,3,1,6537,,,0,"close queues

metricd service catches SIGTERM and kills all children
multiprocessing handles. we can't detect queues at this step so
inspect the children and kill queues as required.

Change-Id: I226a0ba317ec4412159c2afa8f68895e00535e51
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/46/286246/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/cli.py'],1,f2182801a734de71a490487308460f6bb307c60f,cleanup," _metricd_cleanup(workers) _metricd_cleanup(workers)def _metricd_cleanup(workers): for worker in workers: if hasattr(worker, 'queue'): worker.queue.close()"," _metricd_cleanup(workers, queues) _metricd_cleanup(workers, queues)def _metricd_cleanup(workers, queues): for queue in queues: queue.close() for worker in workers:",5,5
openstack%2Fmanila~master~I153c4ab0b4c0488f51c639029ee081a371afd640,openstack/manila,master,I153c4ab0b4c0488f51c639029ee081a371afd640,Don't require pylxd for generating the sample config,ABANDONED,2016-03-07 06:59:50.000000000,2016-03-07 08:51:45.000000000,,"[{'_account_id': 3}, {'_account_id': 12017}, {'_account_id': 15942}, {'_account_id': 17565}, {'_account_id': 18128}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-03-07 06:59:50.000000000', 'files': ['manila/share/drivers/lxd_opts.py', 'manila/opts.py', 'manila/share/drivers/lxd.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/cb5b9bca7d50ef881817e752614bdd55c382a534', 'message': ""Don't require pylxd for generating the sample config\n\nSince the introduction of the LXD/LXC first-party manila driver,\nconfig generation for manila via oslo-config-generator fails unless pylxd\nis installed on the system. This is likely an unwanted dependency as it is\nproblematic for distributions that do not include LXD and which will not\ntherefore distribute a packaged version of pylxd.\n\nCloses bug: #1553208\n\nChange-Id: I153c4ab0b4c0488f51c639029ee081a371afd640\n""}]",0,289181,cb5b9bca7d50ef881817e752614bdd55c382a534,8,6,1,7102,,,0,"Don't require pylxd for generating the sample config

Since the introduction of the LXD/LXC first-party manila driver,
config generation for manila via oslo-config-generator fails unless pylxd
is installed on the system. This is likely an unwanted dependency as it is
problematic for distributions that do not include LXD and which will not
therefore distribute a packaged version of pylxd.

Closes bug: #1553208

Change-Id: I153c4ab0b4c0488f51c639029ee081a371afd640
",git fetch https://review.opendev.org/openstack/manila refs/changes/81/289181/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/lxd_opts.py', 'manila/opts.py', 'manila/share/drivers/lxd.py']",3,cb5b9bca7d50ef881817e752614bdd55c382a534,bug/1553208,from manila.share.drivers import lv_opts from manila.share.drivers import lxd_optsCONF.register_opts(lxd_opts.lxd_opts) CONF.register_opts(lxd_opts.lv_opts),"lxd_opts = [ # (aovchinnikov): this has to stay till we can produce images which # can set up OVS correctly. cfg.StrOpt(""lxd_linux_bridge_name"", default=""lxcbr0"", required=True, help=""Linux bridge used by LXD to plug host-side veth to. "" ""It will be unplugged from here by the driver.""), cfg.StrOpt(""lxd_ovs_bridge_name"", default=""br-int"", required=True, help=""OVS bridge to use to plug a container to.""), cfg.StrOpt(""lxd_nfs_server"", default=""unfs3"", help=""User space NFS server to be used. Currently the only "" ""implementation supported is unfs3. In future ganesha "" ""is planned to be supported as well. Please note, that "" ""unfs3 is mostly an experimental driver which should "" ""be used in production with care and at the user's own "" ""risk.""), cfg.IntOpt(""lxd_build_timeout"", default=120, help=""Time to wait till container is considered being unable "" ""to start.""), cfg.IntOpt(""lxd_check_timeout"", default=1, help=""Inter-check delay for container operations.""), cfg.StrOpt(""lxd_cifs_guest_ok"", default=""yes"", help=""Determines whether to allow guest access to CIFS share "" ""or not.""), cfg.StrOpt(""lxd_image_name"", default=""manila-lxd-image"", help=""LXD image to be used for a server.""), ] lv_opts = [ cfg.StrOpt(""lxd_volume_group"", default=""manila_lxd_volumes"", help=""LVM volume group to use for volumes.""), cfg.StrOpt(""lxd_lv_size"", default=""10M"", help=""Logical volume size.""), ] CONF.register_opts(lxd_opts) CONF.register_opts(lv_opts)",69,50
openstack%2Fhorizon~master~Iea4391d93c03930b2f287c84b9c6af058ad1feb7,openstack/horizon,master,Iea4391d93c03930b2f287c84b9c6af058ad1feb7,Imported Translations from Zanata,MERGED,2016-03-06 06:15:45.000000000,2016-03-07 08:50:01.000000000,2016-03-07 08:50:01.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 12826}, {'_account_id': 19902}]","[{'number': 1, 'created': '2016-03-06 06:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ac48dfcfb25deb36992f17ba23eab0edbd35af6a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iea4391d93c03930b2f287c84b9c6af058ad1feb7\n'}, {'number': 2, 'created': '2016-03-07 06:17:30.000000000', 'files': ['horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/djangojs.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5bd01f3381348ca6513d168c3775e4af68570ce7', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iea4391d93c03930b2f287c84b9c6af058ad1feb7\n'}]",0,288975,5bd01f3381348ca6513d168c3775e4af68570ce7,10,4,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iea4391d93c03930b2f287c84b9c6af058ad1feb7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/75/288975/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/de/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/djangojs.po', 'horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'horizon/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'horizon/locale/zh_CN/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'horizon/locale/nl_NL/LC_MESSAGES/django.po', 'horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'horizon/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'horizon/locale/pt_BR/LC_MESSAGES/django.po']",25,ac48dfcfb25deb36992f17ba23eab0edbd35af6a,zanata/translations,"# Carlos Marques <marquesc@br.ibm.com>, 2016. #zanata""POT-Creation-Date: 2016-03-04 08:38+0000\n""""PO-Revision-Date: 2016-03-04 07:53+0000\n"" ""Last-Translator: Carlos Marques <marquesc@br.ibm.com>\n"""" Login as different user or go back to <a href=\""%(home_url)s"" ""\"">home page</a>\n"" "" "" msgstr """" ""\n"" "" Efetue login como um usuário diferente ou retorne para <a "" ""href=\""%(home_url)s\"">home page</a>\n"" "" "" #, python-format msgid """" ""\n"" "" Used <span> %(used)s </span>(No Limit)\n"" "" "" msgstr """" ""\n"" "" Utilizado <span> %(used)s </span>(No Limit)\n"" "" "" #, python-format msgid """" ""\n"" "" Used <span> %(used)s </span>of<span> %(available)s </span>\n"" "" "" msgstr """" ""\n"" "" Usado <span> %(used)s </span>de<span> %(available)s </span>\n"" "" "" #, python-format msgid """" ""\n""msgid ""Batch Item"" msgid_plural ""Batch Items"" msgstr[0] ""Item em Lote"" msgstr[1] ""Itens em Lote"" msgid ""Batched Item"" msgid_plural ""Batched Items"" msgstr[0] ""Item em Lote"" msgstr[1] ""Itens em Lote"" msgid ""Down Item"" msgid_plural ""Down Items"" msgstr[0] ""Item Inativo"" msgstr[1] ""Itens Inativos"" msgid ""Downed Item"" msgid_plural ""Downed Items"" msgstr[0] ""Item Desativado"" msgstr[1] ""Itens Desativados"" #, python-format msgid ""Error processing message json file '%(path)s': %(exception)s"" msgstr ""Erro ao processar o arquivo json da mensagem '%(path)s': %(exception)s"" msgid ""Log in"" msgstr ""Efetuar Log in"" #, python-format msgid ""Message json file '%(path)s' is malformed. %(exception)s"" msgstr ""O arquivo json da mensagem '%(path)s' está malformado. %(exception)s"" #, python-format msgid """" ""The value of %(resource)s is %(name)s inside the template. When launching a "" ""stack from this interface, the value must start with \""http://\"" or "" ""\""https://\"""" msgstr """" ""O valor de %(resource)s é %(name)s dentro do modelo. Ao ativar uma pilha a "" ""partir dessa interface, o valor devera iniciar com \""http://\"" ou \""https://"" ""\"""" msgid ""Up Item"" msgid_plural ""Up Items"" msgstr[0] ""Item Ativo"" msgstr[1] ""Itens Ativos"" msgid ""Update Item"" msgid_plural ""Update Items"" msgstr[0] ""Atualizar Item"" msgstr[1] ""Atualizar Itens"" msgid ""Updated Item"" msgid_plural ""Updated Items"" msgstr[0] ""Item Atualizado"" msgstr[1] ""Itens Atualizados"" msgid ""Upped Item"" msgid_plural ""Upped Items"" msgstr[0] ""Item Ativado"" msgstr[1] ""Itens Ativados"" ","""POT-Creation-Date: 2016-01-31 10:08+0000\n""""PO-Revision-Date: 2015-09-21 10:46+0000\n"" ""Last-Translator: Gabriel Wainer <gabrielcw@gmail.com>\n""",5017,332
openstack%2Fneutron-vpnaas~master~I736be6a49f919302c31fc7ebd8251cb0a0d73853,openstack/neutron-vpnaas,master,I736be6a49f919302c31fc7ebd8251cb0a0d73853,Fix tox.ini constraints for post jobs,MERGED,2016-03-05 19:00:35.000000000,2016-03-07 08:49:53.000000000,2016-03-07 08:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6659}, {'_account_id': 9656}]","[{'number': 1, 'created': '2016-03-05 19:00:35.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/cf9e80a16fbfcadd39322760969b342a8191cc96', 'message': 'Fix tox.ini constraints for post jobs\n\nPost jobs are currently failing since constraints are not available but\nrequired by this tox.ini file. Change venv environment to work without\nconstraints.\n\nChange-Id: I736be6a49f919302c31fc7ebd8251cb0a0d73853\n'}]",0,288930,cf9e80a16fbfcadd39322760969b342a8191cc96,8,4,1,6547,,,0,"Fix tox.ini constraints for post jobs

Post jobs are currently failing since constraints are not available but
required by this tox.ini file. Change venv environment to work without
constraints.

Change-Id: I736be6a49f919302c31fc7ebd8251cb0a0d73853
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/30/288930/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,cf9e80a16fbfcadd39322760969b342a8191cc96,fix-postscripts,"# TODO(pc_m): Remove install_command, once infra supports constraints for # this target. install_command = {toxinidir}/tools/tox_install.sh unconstrained {opts} {packages}",,3,0
openstack%2Fopenstack-ansible-rsyslog_server~master~Ic7b3924ade8c6243668730332fbcfd2f364605fa,openstack/openstack-ansible-rsyslog_server,master,Ic7b3924ade8c6243668730332fbcfd2f364605fa,Removing unneeded with_items usage for clarity,MERGED,2016-03-06 18:42:09.000000000,2016-03-07 08:46:17.000000000,2016-03-07 08:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-06 18:42:09.000000000', 'files': ['tasks/rsyslog_server_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/11b8ba59595195964f9c94dd35c57e786c938c69', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: Ic7b3924ade8c6243668730332fbcfd2f364605fa\n'}]",0,289061,11b8ba59595195964f9c94dd35c57e786c938c69,7,3,1,19814,,,0,"Removing unneeded with_items usage for clarity

Change-Id: Ic7b3924ade8c6243668730332fbcfd2f364605fa
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/61/289061/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rsyslog_server_post_install.yml'],1,11b8ba59595195964f9c94dd35c57e786c938c69,unneeded_with_items," src: ""50-default.conf"" dest: ""/etc/rsyslog.d/50-default.conf"""," src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" with_items: - { src: ""50-default.conf"", dest: ""/etc/rsyslog.d/50-default.conf"" }",2,4
openstack%2Fopenstack-ansible-os_aodh~master~I857315b7f4b4ed2e50d6a40d982e56b096fcfb7a,openstack/openstack-ansible-os_aodh,master,I857315b7f4b4ed2e50d6a40d982e56b096fcfb7a,Removing unneeded with_items usage for clarity,MERGED,2016-03-06 19:01:43.000000000,2016-03-07 08:46:09.000000000,2016-03-07 08:46:09.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-06 19:01:43.000000000', 'files': ['tasks/aodh_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/5673c5f51e402c930b8da9ee8b1b57e0262abbb9', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: I857315b7f4b4ed2e50d6a40d982e56b096fcfb7a\n'}]",0,289063,5673c5f51e402c930b8da9ee8b1b57e0262abbb9,7,3,1,19814,,,0,"Removing unneeded with_items usage for clarity

Change-Id: I857315b7f4b4ed2e50d6a40d982e56b096fcfb7a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/63/289063/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/aodh_pre_install.yml'],1,5673c5f51e402c930b8da9ee8b1b57e0262abbb9,unneeded_with_items," path: ""/var/log/aodh"" owner: ""{{ aodh_system_user_name }}"" group: ""{{ aodh_system_group_name }}"" mode: ""0755"""," path: ""{{ item.path }}"" owner: ""{{ item.owner|default(aodh_system_user_name) }}"" group: ""{{ item.group|default(aodh_system_group_name) }}"" mode: ""{{ item.mode|default('0755') }}"" with_items: - { path: ""/var/log/aodh"" }",4,6
openstack%2Fopenstack-ansible-pip_lock_down~master~Ia4b858210532b7e639d8f033f24e8a2e4f500449,openstack/openstack-ansible-pip_lock_down,master,Ia4b858210532b7e639d8f033f24e8a2e4f500449,Removing unneeded with_items usage for clarity,MERGED,2016-03-06 17:53:53.000000000,2016-03-07 08:45:45.000000000,2016-03-07 08:45:45.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-06 17:53:53.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/c311b994ae8473f036c5f37f1d3da54ea30c4f8c', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: Ia4b858210532b7e639d8f033f24e8a2e4f500449\n'}]",0,289056,c311b994ae8473f036c5f37f1d3da54ea30c4f8c,7,3,1,19814,,,0,"Removing unneeded with_items usage for clarity

Change-Id: Ia4b858210532b7e639d8f033f24e8a2e4f500449
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_lock_down refs/changes/56/289056/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,c311b994ae8473f036c5f37f1d3da54ea30c4f8c,unneeded_with_items," src: ""pip-link-build.py"" dest: ""{{ ansible_env.HOME }}/.pip/pip-link-build.py"" mode: ""0755"" src: ""global.conf.j2"" dest: ""{{ ansible_env.HOME }}/.pip/base/global.conf"" config_overrides: ""{{ pip_global_conf_overrides }}"" config_type: ""ini"""," src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" mode: ""{{ item.mode|default('0644') }}"" with_items: - { src: ""pip-link-build.py"", dest: ""{{ ansible_env.HOME }}/.pip/pip-link-build.py"", mode: ""0755"" } src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" config_overrides: ""{{ item.config_overrides }}"" config_type: ""{{ item.config_type }}"" with_items: - src: ""global.conf.j2"" dest: ""{{ ansible_env.HOME }}/.pip/base/global.conf"" config_overrides: ""{{ pip_global_conf_overrides }}"" config_type: ""ini""",7,14
openstack%2Fopenstack-ansible~master~I9e9ac72acb6c8174db733405f6b468ac8ced4573,openstack/openstack-ansible,master,I9e9ac72acb6c8174db733405f6b468ac8ced4573,Retry tempest cirros image creation,ABANDONED,2016-02-24 10:42:17.000000000,2016-03-07 08:43:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7219}, {'_account_id': 7307}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-02-24 10:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7f631a02c1cd3b4c9fc205e7988f484a2e3bdbd6', 'message': 'Retry tempest cirros image creation\n\nCreating the cirros image fails intermittently. To debug this I\nincreased the haproxy timeout and inserted some debug tasks into the\ntempest_resources playbook. These revealed that the cause of the failure\nis glance getting a 400 response from the cirros mirror when doing a\nhead request to ascertain the size of the image.\n\nLog excerpt:\n\n-----------------------------------------------------------------------------\nTASK: [os_tempest | Debug show cirros image url] ******************************\nok: [jrpcaioiad-624_utility_container-5180f774] => {\n    ""var"": {\n        ""cirros_img_url"": ""http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img""\n    }\n}\n\nTASK: [os_tempest | Debug download cirros image] ******************************\nchanged: [jrpcaioiad-624_utility_container-5180f774]\n\nTASK: [os_tempest | Ensure cirros image] **************************************\nfailed: [jrpcaioiad-624_utility_container-5180f774] => {""failed"": true, ""parsed"": false}\nOpenSSH_6.6.1, OpenSSL 1.0.1f 6 Jan 2014\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug1: auto-mux: Trying existing master\ndebug1: mux_client_request_session: master session id: 2\nTraceback (most recent call last):\n  File ""<stdin>"", line 1848, in <module>\n  File ""<stdin>"", line 1845, in main\n  File ""<stdin>"", line 1765, in route\n  File ""<stdin>"", line 1818, in create_image\n  File ""/usr/local/lib/python2.7/dist-packages/glanceclient/v1/images.py"", line 324, in create\n    data=image_data)\n  File ""/usr/local/lib/python2.7/dist-packages/glanceclient/common/http.py"", line 287, in post\n    return self._request(\'POST\', url, **kwargs)\n  File ""/usr/local/lib/python2.7/dist-packages/glanceclient/common/http.py"", line 276, in _request\n    resp, body_iter = self._handle_response(resp)\n  File ""/usr/local/lib/python2.7/dist-packages/glanceclient/common/http.py"", line 93, in _handle_response\n    raise exc.from_response(resp, resp.content)\nglanceclient.exc.HTTPBadRequest: 400 Bad Request: The HTTP URL is invalid. (HTTP 400)\n-----------------------------------------------------------------------------\n\nThe first two tasks show that the image url is valid and can be\ndownloaded, however the image create still fails.\n\nI cannot find fault with the OSA mechanisms and suspect the fault is an\nintermittent one with the remote server. In which case we don\'t have\nmany options apart from to retry, which is what this patch does.\n\nChange-Id: I9e9ac72acb6c8174db733405f6b468ac8ced4573\n'}, {'number': 2, 'created': '2016-02-25 10:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/820747f08b5602dd9d466cf59e66a2188bf3be0d', 'message': ""Retry tempest cirros image creation\n\nCreating the cirros image fails intermittently. To debug this I\nincreased the haproxy timeout and inserted some debug tasks into the\ntempest_resources playbook. These revealed that the cause of the failure\nis glance getting a 400 response from the cirros mirror when doing a\nhead request to ascertain the size of the image.\n\nI cannot find fault with the OSA mechanisms and suspect the fault is an\nintermittent one with the remote server. In which case we don't have\nmany options apart from to retry, which is what this patch does.\n\nChange-Id: I9e9ac72acb6c8174db733405f6b468ac8ced4573\n""}, {'number': 3, 'created': '2016-02-26 17:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3f107f01466cd803b979a607fa10e38db344318f', 'message': ""Retry tempest cirros image creation\n\nCreating the cirros image fails intermittently. To debug this I\nincreased the haproxy timeout and inserted some debug tasks into the\ntempest_resources playbook. These revealed that the cause of the failure\nis glance getting a 400 response from the cirros mirror when doing a\nhead request to ascertain the size of the image.\n\nI cannot find fault with the OSA mechanisms and suspect the fault is an\nintermittent one with the remote server. In which case we don't have\nmany options apart from to retry, which is what this patch does.\n\nChange-Id: I9e9ac72acb6c8174db733405f6b468ac8ced4573\n""}, {'number': 4, 'created': '2016-03-01 05:24:30.000000000', 'files': ['playbooks/roles/os_tempest/tasks/tempest_resources.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d8a41901520a48d5f85a986fae725e6b392eef41', 'message': ""Retry tempest cirros image creation\n\nCreating the cirros image fails intermittently. To debug this I\nincreased the haproxy timeout and inserted some debug tasks into the\ntempest_resources playbook. These revealed that the cause of the failure\nis glance getting a 400 response from the cirros mirror when doing a\nhead request to ascertain the size of the image.\n\nI cannot find fault with the OSA mechanisms and suspect the fault is an\nintermittent one with the remote server. In which case we don't have\nmany options apart from to retry, which is what this patch does.\n\nChange-Id: I9e9ac72acb6c8174db733405f6b468ac8ced4573\n""}]",1,284057,d8a41901520a48d5f85a986fae725e6b392eef41,26,6,4,7217,,,0,"Retry tempest cirros image creation

Creating the cirros image fails intermittently. To debug this I
increased the haproxy timeout and inserted some debug tasks into the
tempest_resources playbook. These revealed that the cause of the failure
is glance getting a 400 response from the cirros mirror when doing a
head request to ascertain the size of the image.

I cannot find fault with the OSA mechanisms and suspect the fault is an
intermittent one with the remote server. In which case we don't have
many options apart from to retry, which is what this patch does.

Change-Id: I9e9ac72acb6c8174db733405f6b468ac8ced4573
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/57/284057/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_tempest/tasks/tempest_resources.yml'],1,7f631a02c1cd3b4c9fc205e7988f484a2e3bdbd6,retry_cirros_dl_master, register: cirros_image_create until: cirros_image_create |success retries: 5 delay: 15,,4,0
openstack%2Faodh~master~Iccdbbfcc300f4a63fe7a58f0742eef782aff6844,openstack/aodh,master,Iccdbbfcc300f4a63fe7a58f0742eef782aff6844,Moved CORS middleware configuration into oslo-config-generator,MERGED,2016-03-03 18:30:19.000000000,2016-03-07 08:43:25.000000000,2016-03-07 08:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-03-03 18:30:19.000000000', 'files': ['etc/aodh/api_paste.ini', 'aodh/conf/defaults.py', 'aodh/service.py', 'aodh/tests/functional/gabbi/gabbi_paste.ini', 'setup.cfg', 'aodh/conf/__init__.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/7e638e07edfc33d9c58ecb17a12f56728cd9fcdb', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for aodh's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to aodh's default configuration parsing. This ensures\nthat if a value remains unset in aodh.conf, it will be set\nto use sane defaults, and that an operator modifying the\nconfiguration file will be presented with a default set of\nnecessary sane headers.\n\nChange-Id: Iccdbbfcc300f4a63fe7a58f0742eef782aff6844\nCloses-Bug: 1551836\n""}]",0,288054,7e638e07edfc33d9c58ecb17a12f56728cd9fcdb,7,3,1,9717,,,0,"Moved CORS middleware configuration into oslo-config-generator

The default values needed for aodh's implementation of cors
middleware have been moved from paste.ini into the configuration
hooks provided by oslo.config. Furthermore, these values have been
added to aodh's default configuration parsing. This ensures
that if a value remains unset in aodh.conf, it will be set
to use sane defaults, and that an operator modifying the
configuration file will be presented with a default set of
necessary sane headers.

Change-Id: Iccdbbfcc300f4a63fe7a58f0742eef782aff6844
Closes-Bug: 1551836
",git fetch https://review.opendev.org/openstack/aodh refs/changes/54/288054/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/aodh/api_paste.ini', 'aodh/conf/defaults.py', 'aodh/service.py', 'aodh/tests/functional/gabbi/gabbi_paste.ini', 'setup.cfg', 'aodh/conf/__init__.py']",6,7e638e07edfc33d9c58ecb17a12f56728cd9fcdb,bug/1551836,,,41,7
openstack%2Fvitrage~master~Ibc7eb5a369853235156829dd8bd60c4587b151a1,openstack/vitrage,master,Ibc7eb5a369853235156829dd8bd60c4587b151a1,evaluator - action executor,MERGED,2016-03-07 07:58:06.000000000,2016-03-07 08:28:46.000000000,2016-03-07 08:28:46.000000000,"[{'_account_id': 3}, {'_account_id': 19159}, {'_account_id': 19233}]","[{'number': 1, 'created': '2016-03-07 07:58:06.000000000', 'files': ['vitrage/evaluator/actions/recipes/raise_alarm.py', 'vitrage/evaluator/actions/action_executor.py', 'vitrage/tests/functional/evaluator/__init__.py', 'vitrage/evaluator/actions/base.py', 'vitrage/tests/unit/evaluator/recipes/test_set_state_recipe.py', 'vitrage/synchronizer/launcher.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/evaluator/actions/evaluator_event_transformer.py', 'vitrage/evaluator/template_fields.py', 'vitrage/evaluator/actions/__init__.py', 'vitrage/tests/functional/evaluator/test_action_executor.py', 'vitrage/synchronizer/plugins/nagios/transformer.py', 'vitrage/entity_graph/states/state_manager.py', 'vitrage/entity_graph/transformer_manager.py', 'vitrage/synchronizer/plugins/synchronizer_base.py', 'vitrage/evaluator/actions/recipes/__init__.py', 'vitrage/tests/unit/evaluator/recipes/__init__.py', 'vitrage/evaluator/actions/recipes/add_causal_relationship.py', 'vitrage/evaluator/actions/recipes/action_steps.py', 'vitrage/evaluator/actions/recipes/base.py', 'vitrage/evaluator/actions/recipes/set_state.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/9acd519a4e243f399ece04ad6b5a1865c5f22146', 'message': ' evaluator - action executor\n\nChange-Id: Ibc7eb5a369853235156829dd8bd60c4587b151a1\n'}]",0,289209,9acd519a4e243f399ece04ad6b5a1865c5f22146,7,3,1,19209,,,0," evaluator - action executor

Change-Id: Ibc7eb5a369853235156829dd8bd60c4587b151a1
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/09/289209/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/evaluator/actions/recipes/raise_alarm.py', 'vitrage/evaluator/actions/action_executor.py', 'vitrage/tests/functional/evaluator/__init__.py', 'vitrage/evaluator/actions/base.py', 'vitrage/tests/unit/evaluator/recipes/test_set_state_recipe.py', 'vitrage/synchronizer/launcher.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/evaluator/actions/evaluator_event_transformer.py', 'vitrage/evaluator/template_fields.py', 'vitrage/evaluator/actions/__init__.py', 'vitrage/tests/functional/evaluator/test_action_executor.py', 'vitrage/synchronizer/plugins/nagios/transformer.py', 'vitrage/entity_graph/states/state_manager.py', 'vitrage/entity_graph/transformer_manager.py', 'vitrage/synchronizer/plugins/synchronizer_base.py', 'vitrage/evaluator/actions/recipes/__init__.py', 'vitrage/tests/unit/evaluator/recipes/__init__.py', 'vitrage/evaluator/actions/recipes/add_causal_relationship.py', 'vitrage/evaluator/actions/recipes/action_steps.py', 'vitrage/evaluator/actions/recipes/base.py', 'vitrage/evaluator/actions/recipes/set_state.py']",21,9acd519a4e243f399ece04ad6b5a1865c5f22146,bp/vitrage_template_loader,"# Copyright 2016 - Nokia # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from vitrage.common.constants import VertexProperties as VProps from vitrage.evaluator.actions.recipes.action_steps import UPDATE_VERTEX from vitrage.evaluator.actions.recipes import base from vitrage.evaluator.actions.recipes.base import ActionStepWrapper from vitrage.evaluator.template_fields import TemplateFields as TFields class SetState(base.Recipe): @staticmethod def get_do_recipe(action_spec): update_vertex_step = SetState._get_update_vertex_step( action_spec.targets[TFields.TARGET], action_spec.properties[TFields.STATE]) # TODO(lhartal): add notify step return [update_vertex_step] @staticmethod def get_undo_recipe(action_spec): update_vertex_step = SetState._get_update_vertex_step( action_spec.targets[TFields.TARGET], None) # TODO(lhartal): add notify step return [update_vertex_step] @staticmethod def _get_update_vertex_step(target_id, vitrage_state): update_vertex_params = { VProps.VITRAGE_ID: target_id, VProps.VITRAGE_STATE: vitrage_state } update_vertex_step = ActionStepWrapper(UPDATE_VERTEX, update_vertex_params) return update_vertex_step ",,488,103
openstack%2Fgnocchi~master~I0ebf80dfa8ae0b5ca4263d5d90808e94517803cb,openstack/gnocchi,master,I0ebf80dfa8ae0b5ca4263d5d90808e94517803cb,ceph: fix help string,MERGED,2016-02-26 14:23:09.000000000,2016-03-07 08:28:13.000000000,2016-03-03 10:48:42.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7729}]","[{'number': 1, 'created': '2016-02-26 14:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9feb60931491b51c76038532b6e6f42cd96aa36e', 'message': 'ceph: fix help string\n\nChange-Id: I0ebf80dfa8ae0b5ca4263d5d90808e94517803cb\n'}, {'number': 2, 'created': '2016-03-03 09:42:47.000000000', 'files': ['gnocchi/storage/ceph.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/902758be1000b7f02b0dad87caec5021199ccb01', 'message': 'ceph: fix help string\n\nChange-Id: I0ebf80dfa8ae0b5ca4263d5d90808e94517803cb\n'}]",0,285324,902758be1000b7f02b0dad87caec5021199ccb01,17,4,2,2813,,,0,"ceph: fix help string

Change-Id: I0ebf80dfa8ae0b5ca4263d5d90808e94517803cb
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/24/285324/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/ceph.py'],1,9feb60931491b51c76038532b6e6f42cd96aa36e,bug/1548894," help='Ceph username (ie: admin without ""client."" prefix).'),"," help='Ceph username (ie: client.admin).'),",1,1
openstack%2Fgnocchi~master~I54fa13244e5416f1aace138150e9862b2c6a27b0,openstack/gnocchi,master,I54fa13244e5416f1aace138150e9862b2c6a27b0,Delete a redundant space character,ABANDONED,2016-02-21 16:09:37.000000000,2016-03-07 08:27:19.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 16237}, {'_account_id': 18137}]","[{'number': 1, 'created': '2016-02-21 16:09:37.000000000', 'files': ['gnocchi/indexer/alembic/versions/1c98ac614015_initial_base.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8b7d6d85c534e343126495c23c6d7a2448493bfd', 'message': 'Delete a redundant space character\n\nChange-Id: I54fa13244e5416f1aace138150e9862b2c6a27b0\n'}]",0,282880,8b7d6d85c534e343126495c23c6d7a2448493bfd,6,4,1,8358,,,0,"Delete a redundant space character

Change-Id: I54fa13244e5416f1aace138150e9862b2c6a27b0
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/80/282880/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/alembic/versions/1c98ac614015_initial_base.py'],1,8b7d6d85c534e343126495c23c6d7a2448493bfd,del-space,Revises:,Revises: ,1,1
openstack%2Foperations-guide~master~Ic29980b801bb5bd9d528f3879adef1cf82046313,openstack/operations-guide,master,Ic29980b801bb5bd9d528f3879adef1cf82046313,Updated from openstack-manuals,MERGED,2016-03-07 07:41:21.000000000,2016-03-07 08:20:44.000000000,2016-03-07 08:20:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 07:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/830c48acd3aeec5e266a9c0bf062de5d4e518852', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ic29980b801bb5bd9d528f3879adef1cf82046313\n'}, {'number': 2, 'created': '2016-03-07 07:51:45.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/8588c564018176f21e41f2c5f1598fcd4c18eddc', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ic29980b801bb5bd9d528f3879adef1cf82046313\n'}]",0,289200,8588c564018176f21e41f2c5f1598fcd4c18eddc,8,3,2,11131,,,0,"Updated from openstack-manuals

Change-Id: Ic29980b801bb5bd9d528f3879adef1cf82046313
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/00/289200/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,830c48acd3aeec5e266a9c0bf062de5d4e518852,openstack/openstack-manuals," <glossterm>core service</glossterm> <primary>core service</primary> <para>An official OpenStack service defined as core by DefCore Committee. Currently, consists of Block Storage service (cinder), Compute service (nova), Identity service (keystone), Image service (glance), Networking service (neutron), and Object Storage service (swift). <glossterm>optional service</glossterm> <indexterm class=""singular""> <primary>optional service</primary> </indexterm> <glossdef> <para>An official OpenStack service defined as optional by DefCore Committee. Currently, consists of Dashboard (horizon), Telemetry service (Telemetry), Orchestration service (heat), Database service (trove), Bare Metal service (ironic), and so on. </para> </glossdef> </glossentry> <glossentry>"," <glossterm>core project</glossterm> <primary>core project</primary> <para>An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"".",23,10
openstack%2Fdragonflow~master~I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29,openstack/dragonflow,master,I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29,Add option to disable multiproc publish/subscribe,MERGED,2016-02-29 15:23:34.000000000,2016-03-07 08:20:04.000000000,2016-03-07 08:20:04.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 13070}, {'_account_id': 18811}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-29 15:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1cb22125a1a5d83d00c6c546e2bbaf8ebb4e3a29', 'message': 'Add option to disable multiproc publish/subscribe\n\nAdd an option to disable multiproc publish/subscribe. When this option\nis enabled, all publishers are network publishers. This option is\nintended to be used when the system is not limited to a single publisher\n(e.g. when using multicast+egpm and not TCP). Then every publisher\nconnects to the network, and sends events directly to subscribers,\nwithout being proxied via the publisher service.\n\nChange-Id: I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29\n'}, {'number': 2, 'created': '2016-02-29 15:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b77f2c4fad90ae1712d02fbf9f7b2c5683a776a3', 'message': 'Add option to disable multiproc publish/subscribe\n\nAdd an option to disable multiproc publish/subscribe. When this option\nis enabled, all publishers are network publishers. This option is\nintended to be used when the system is not limited to a single publisher\n(e.g. when using multicast+egpm and not TCP). Then every publisher\nconnects to the network, and sends events directly to subscribers,\nwithout being proxied via the publisher service.\n\nChange-Id: I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29\n'}, {'number': 3, 'created': '2016-03-01 11:29:40.000000000', 'files': ['dragonflow/controller/df_publisher_service.py', 'devstack/plugin.sh', 'dragonflow/common/common_params.py', 'dragonflow/db/api_nb.py', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c7554f739d3b193b7f0bb572b5f75f1bd32dda23', 'message': 'Add option to disable multiproc publish/subscribe\n\nAdd an option to disable multiproc publish/subscribe. When this option\nis enabled, all publishers are network publishers. This option is\nintended to be used when the system is not limited to a single publisher\n(e.g. when using multicast+egpm and not TCP). Then every publisher\nconnects to the network, and sends events directly to subscribers,\nwithout being proxied via the publisher service.\n\nChange-Id: I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29\n'}]",5,286107,c7554f739d3b193b7f0bb572b5f75f1bd32dda23,17,5,3,20229,,,0,"Add option to disable multiproc publish/subscribe

Add an option to disable multiproc publish/subscribe. When this option
is enabled, all publishers are network publishers. This option is
intended to be used when the system is not limited to a single publisher
(e.g. when using multicast+egpm and not TCP). Then every publisher
connects to the network, and sends events directly to subscribers,
without being proxied via the publisher service.

Change-Id: I9b03fbcbdc2eeccee66a7f37dcc6b0d6d3f50b29
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/07/286107/2 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/controller/df_publisher_service.py', 'devstack/plugin.sh', 'dragonflow/common/common_params.py', 'dragonflow/db/api_nb.py', 'devstack/settings']",5,1cb22125a1a5d83d00c6c546e2bbaf8ebb4e3a29,pubsub_no_multiproc,"DF_PUB_SUB_NO_MULTIPROC=${DF_PUB_SUB_NO_MULTIPROC:-""False""}",,24,7
openstack%2Fgnocchi~master~I0be08864ee10cefa252dc89885fda5fcc89a4e8a,openstack/gnocchi,master,I0be08864ee10cefa252dc89885fda5fcc89a4e8a,Added new resource types for snmp metrics,MERGED,2016-02-18 05:10:33.000000000,2016-03-07 08:19:29.000000000,2016-03-07 08:19:29.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7729}, {'_account_id': 9526}, {'_account_id': 18137}]","[{'number': 1, 'created': '2016-02-18 05:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/aab8706f912db96579256fbc5bf19e9669e31e9e', 'message': 'Added new resource types for snmp metrics\n\nAdded new resource types for snmp related metrics: host, host_disk,\nhost_network_interface.\n\nChange-Id: I0be08864ee10cefa252dc89885fda5fcc89a4e8a\nCloses-Bug: #1518338\nCo-Authored-By: Sergio Colina <sergio@nubeliu.com>\n'}, {'number': 2, 'created': '2016-02-22 03:45:41.000000000', 'files': ['gnocchi/indexer/alembic/versions/9901e5ea4b6e_create_host.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/sqlalchemy_extension.py', 'gnocchi/indexer/sqlalchemy_base.py', 'setup.cfg', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bd5c9d72e21574163c673a9a1a483dd0ff6b91e9', 'message': 'Added new resource types for snmp metrics\n\nAdded new resource types for snmp related metrics: host, host_disk,\nhost_network_interface.\n\nChange-Id: I0be08864ee10cefa252dc89885fda5fcc89a4e8a\nCloses-Bug: #1518338\nCo-Authored-By: Sergio Colina <sergio@nubeliu.com>\n'}]",0,281630,bd5c9d72e21574163c673a9a1a483dd0ff6b91e9,15,7,2,4491,,,0,"Added new resource types for snmp metrics

Added new resource types for snmp related metrics: host, host_disk,
host_network_interface.

Change-Id: I0be08864ee10cefa252dc89885fda5fcc89a4e8a
Closes-Bug: #1518338
Co-Authored-By: Sergio Colina <sergio@nubeliu.com>
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/30/281630/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/indexer/alembic/versions/9901e5ea4b6e_create_host.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/sqlalchemy_extension.py', 'gnocchi/indexer/sqlalchemy_base.py', 'setup.cfg', 'gnocchi/tests/test_rest.py']",6,aab8706f912db96579256fbc5bf19e9669e31e9e,bug/1518338," ('host', dict( attributes={ ""started_at"": ""2014-01-03T02:02:02+00:00"", ""user_id"": str(uuid.uuid4()), ""project_id"": str(uuid.uuid4()), ""host_name"": ""test-host"", }, patchable_attributes={ ""ended_at"": ""2014-01-03T02:02:02+00:00"", }, resource_type='host')), ('host_disk', dict( attributes={ ""started_at"": ""2014-01-03T02:02:02+00:00"", ""user_id"": str(uuid.uuid4()), ""project_id"": str(uuid.uuid4()), ""host_name"": ""test-host"", ""device_name"": ""test-device"" }, patchable_attributes={ ""ended_at"": ""2014-01-03T02:02:02+00:00"", }, resource_type='host_disk')), ('host_network_interface', dict( attributes={ ""started_at"": ""2014-01-03T02:02:02+00:00"", ""user_id"": str(uuid.uuid4()), ""project_id"": str(uuid.uuid4()), ""host_name"": ""test-host"", ""device_name"": ""test-device"" }, patchable_attributes={ ""ended_at"": ""2014-01-03T02:02:02+00:00"", }, resource_type='host_network_interface')),",,206,0
openstack%2Fsahara~master~I315ef34484b177b61d6e5f595839c68081b2083a,openstack/sahara,master,I315ef34484b177b61d6e5f595839c68081b2083a,Improve exception message for wait_ambari_requests,MERGED,2016-03-02 10:29:12.000000000,2016-03-07 08:19:22.000000000,2016-03-07 08:19:22.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 12038}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-03-02 10:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f4b2619e7dbbda11e09bcc61ec239de337b0ecbc', 'message': 'Improve exception message in ambari wait request\n\nWhen ambari starts we are waiting while all sended requests will be\ncompleted. Sometimes some requests could fail and we need to know\nwhich exactly. So this patch adds such information in exception\nmessage.\n\nChange-Id: I315ef34484b177b61d6e5f595839c68081b2083a\nCloses-bug: 1549858\n'}, {'number': 2, 'created': '2016-03-02 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f9eae9827928d9c46692a62ba618850542f79773', 'message': 'Improve exception message for wait_ambari_requests\n\nWhen ambari starts we are waiting while all sended requests will be\ncompleted. Sometimes some requests could fail and we need to know\nwhich exactly. So this patch adds such information in exception\nmessage.\n\nChange-Id: I315ef34484b177b61d6e5f595839c68081b2083a\nCloses-bug: 1549858\n'}, {'number': 3, 'created': '2016-03-03 11:46:25.000000000', 'files': ['sahara/plugins/ambari/client.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2ccf65dffb6baf7cfc9d5bc3e03d87e23c7490c7', 'message': 'Improve exception message for wait_ambari_requests\n\nWhen ambari starts we are waiting while all sended requests will be\ncompleted. Sometimes some requests could fail and we need to know\nwhich exactly. So this patch adds such information in exception\nmessage.\n\nChange-Id: I315ef34484b177b61d6e5f595839c68081b2083a\nCloses-bug: 1549858\n'}]",2,287088,2ccf65dffb6baf7cfc9d5bc3e03d87e23c7490c7,20,7,3,19372,,,0,"Improve exception message for wait_ambari_requests

When ambari starts we are waiting while all sended requests will be
completed. Sometimes some requests could fail and we need to know
which exactly. So this patch adds such information in exception
message.

Change-Id: I315ef34484b177b61d6e5f595839c68081b2083a
Closes-bug: 1549858
",git fetch https://review.opendev.org/openstack/sahara refs/changes/88/287088/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/ambari/client.py'],1,f4b2619e7dbbda11e09bcc61ec239de337b0ecbc,bug/1549858," def get_request_info(self, cluster_name, request_id): return resp.get('Requests') failed = [] for req_id in requests: request = self.get_request_info(cluster_name, req_id) status = request.get(""request_status"") if status == 'COMPLETED': completed.add(req_id) elif status in ['IN_PROGRESS', 'PENDING']: not_completed.add(req_id) else: failed.append(request) if failed: msg = ""Some Ambari request(s) not in COMPLETED state: "" for req in failed: msg += (""request %d: %s - in status %s; "" % (req.get(""id""), req.get(""request_context""), req.get(""request_status""))) raise p_exc.HadoopProvisionError(msg) LOG.debug(""Waiting for %d ambari request(s) to be completed"", LOG.debug(""All ambari requests have been completed"")"," def get_request_status(self, cluster_name, request_id): return resp.get('Requests').get(""request_status"") for request in requests: status = self.get_request_status(cluster_name, request) if status == 'COMPLETED': completed.add(request) elif status in ['IN_PROGRESS', 'PENDING']: not_completed.add(request) else: raise p_exc.HadoopProvisionError( _(""Some Ambari request(s) not in COMPLETED state"")) LOG.debug(""Waiting for ambari %d requests to be completed"", LOG.debug(""Waiting for ambari requests completed"")",19,10
openstack%2Fceilometer~master~Ied6778e26ba6d70ee1407279ce0025e8bf169f22,openstack/ceilometer,master,Ied6778e26ba6d70ee1407279ce0025e8bf169f22,Add the meter example file 'lbaas-v2-meter-definitions.yaml',MERGED,2016-03-01 08:06:34.000000000,2016-03-07 08:18:59.000000000,2016-03-07 08:18:58.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 9526}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-03-01 08:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f817b4e1c7126049eacc1e990be00435e4c884f7', 'message': ""Add the meter example file 'lbaas-v2-meter-definitions.yaml'\n\nBased on the discussion result with Gordon:\n\nIn this change set, add the meter example file\n'lbaas-v2-meter-definitions.yaml' in the directory\n'etc/ceilometer/examples' to help the users to configure to\ntranslate the LbaaS v2 events to examples when they need.\n\nChange-Id: Ied6778e26ba6d70ee1407279ce0025e8bf169f22\nCo-Authored-By: Xia Linjuan <ljxiash@cn.ibm.com>\n""}, {'number': 2, 'created': '2016-03-02 07:59:31.000000000', 'files': ['etc/ceilometer/examples/loadbalancer_v2_meter_definitions.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3fafaa6fcb6ed0b296a4e9e7d7fe4f3df9a6dbc7', 'message': ""Add the meter example file 'lbaas-v2-meter-definitions.yaml'\n\nBased on the discussion result with Gordon:\n\nIn this change set, add the meter example file\n'lbaas-v2-meter-definitions.yaml' in the directory\n'etc/ceilometer/examples' to help the users to configure to\ntranslate the LbaaS v2 events to examples when they need.\n\nCo-Authored-By: Xia Linjuan <ljxiash@cn.ibm.com>\nDocImpact: Need to update the doc about the configuration\nChange-Id: Ied6778e26ba6d70ee1407279ce0025e8bf169f22\n""}]",0,286431,3fafaa6fcb6ed0b296a4e9e7d7fe4f3df9a6dbc7,16,6,2,9526,,,0,"Add the meter example file 'lbaas-v2-meter-definitions.yaml'

Based on the discussion result with Gordon:

In this change set, add the meter example file
'lbaas-v2-meter-definitions.yaml' in the directory
'etc/ceilometer/examples' to help the users to configure to
translate the LbaaS v2 events to examples when they need.

Co-Authored-By: Xia Linjuan <ljxiash@cn.ibm.com>
DocImpact: Need to update the doc about the configuration
Change-Id: Ied6778e26ba6d70ee1407279ce0025e8bf169f22
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/31/286431/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/ceilometer/examples/loadbalancer_v2_meter_definitions.yaml'],1,f817b4e1c7126049eacc1e990be00435e4c884f7,jzl/lbaas-v2-meters-example,"metric: # LBaaS V2 - name: ""loadbalancer.create"" event_type: - ""loadbalancer.create.end"" type: ""delta"" unit: ""loadbalancer"" volume: 1 resource_id: $.payload.loadbalancer.id project_id: $.payload.loadbalancer.tenant_id metadata: name: $.payload.loadbalancer.name description: $.payload.loadbalancer.description listeners: $.payload.loadbalancer.listeners operating_status: $.payload.loadbalancer.operating_status vip_address: $.payload.loadbalancer.vip_address vip_subnet_id: $.payload.loadbalancer.vip_subnet_id admin_state_up: $.payload.loadbalancer.admin_state_up - name: ""loadbalancer.update"" event_type: - ""loadbalancer.update.end"" type: ""delta"" unit: ""loadbalancer"" volume: 1 resource_id: $.payload.loadbalancer.id project_id: $.payload.loadbalancer.tenant_id metadata: name: $.payload.loadbalancer.name description: $.payload.loadbalancer.description listeners: $.payload.loadbalancer.listeners operating_status: $.payload.loadbalancer.operating_status vip_address: $.payload.loadbalancer.vip_address vip_subnet_id: $.payload.loadbalancer.vip_subnet_id admin_state_up: $.payload.loadbalancer.admin_state_up - name: ""loadbalancer.delete"" event_type: - ""loadbalancer.delete.end"" type: ""delta"" unit: ""loadbalancer"" volume: 1 resource_id: $.payload.loadbalancer.id project_id: $.payload.loadbalancer.tenant_id metadata: name: $.payload.loadbalancer.name description: $.payload.loadbalancer.description listeners: $.payload.loadbalancer.listeners operating_status: $.payload.loadbalancer.operating_status vip_address: $.payload.loadbalancer.vip_address vip_subnet_id: $.payload.loadbalancer.vip_subnet_id admin_state_up: $.payload.loadbalancer.admin_state_up - name: ""listener.create"" event_type: - ""listener.create.end"" type: ""delta"" unit: ""listener"" volume: 1 resource_id: $.payload.listener.id project_id: $.payload.listener.tenant_id metadata: name: $.payload.listener.name description: $.payload.listener.description admin_state_up: $.payload.listener.admin_state_up loadbalancers: $.payload.listener.loadbalancers default_pool_id: $.payload.listener.default_pool_id protocol: $.payload.listener.protocol connection_limit: $.payload.listener.connection_limit - name: ""listener.update"" event_type: - ""listener.update.end"" type: ""delta"" unit: ""listener"" volume: 1 resource_id: $.payload.listener.id project_id: $.payload.listener.tenant_id metadata: name: $.payload.listener.name description: $.payload.listener.description admin_state_up: $.payload.listener.admin_state_up loadbalancers: $.payload.listener.loadbalancers default_pool_id: $.payload.listener.default_pool_id protocol: $.payload.listener.protocol connection_limit: $.payload.listener.connection_limit - name: ""listener.delete"" event_type: - ""listener.delete.end"" type: ""delta"" unit: ""listener"" volume: 1 resource_id: $.payload.listener.id project_id: $.payload.listener.tenant_id metadata: name: $.payload.listener.name description: $.payload.listener.description admin_state_up: $.payload.listener.admin_state_up loadbalancers: $.payload.listener.loadbalancers default_pool_id: $.payload.listener.default_pool_id protocol: $.payload.listener.protocol connection_limit: $.payload.listener.connection_limit - name: ""healthmonitor.create"" event_type: - ""healthmonitor.create.end"" type: ""delta"" unit: ""healthmonitor"" volume: 1 resource_id: $.payload.healthmonitor.id project_id: $.payload.healthmonitor.tenant_id metadata: name: $.payload.healthmonitor.name description: $.payload.healthmonitor.description admin_state_up: $.payload.healthmonitor.admin_state_up max_retries: $.payload.healthmonitor.max_retries delay: $.payload.healthmonitor.delay timeout: $.payload.healthmonitor.timeout pools: $.payload.healthmonitor.pools type: $.payload.healthmonitor.type - name: ""healthmonitor.update"" event_type: - ""healthmonitor.update.end"" type: ""delta"" unit: ""healthmonitor"" volume: 1 resource_id: $.payload.healthmonitor.id project_id: $.payload.healthmonitor.tenant_id metadata: name: $.payload.healthmonitor.name description: $.payload.healthmonitor.description admin_state_up: $.payload.healthmonitor.admin_state_up max_retries: $.payload.healthmonitor.max_retries delay: $.payload.healthmonitor.delay timeout: $.payload.healthmonitor.timeout pools: $.payload.healthmonitor.pools type: $.payload.healthmonitor.type - name: ""healthmonitor.delete"" event_type: - ""healthmonitor.delete.end"" type: ""delta"" unit: ""healthmonitor"" volume: 1 resource_id: $.payload.healthmonitor.id project_id: $.payload.healthmonitor.tenant_id metadata: name: $.payload.healthmonitor.name description: $.payload.healthmonitor.description admin_state_up: $.payload.healthmonitor.admin_state_up max_retries: $.payload.healthmonitor.max_retries delay: $.payload.healthmonitor.delay timeout: $.payload.healthmonitor.timeout pools: $.payload.healthmonitor.pools type: $.payload.healthmonitor.type - name: ""pool.create"" event_type: - ""pool.create.end"" type: ""delta"" unit: ""pool"" volume: 1 resource_id: $.payload.pool.id project_id: $.payload.pool.tenant_id metadata: name: $.payload.pool.name description: $.payload.pool.description admin_state_up: $.payload.pool.admin_state_up lb_method: $.payload.pool.lb_method protocol: $.payload.pool.protocol subnet_id: $.payload.pool.subnet_id vip_id: $.payload.pool.vip_id status: $.payload.pool.status status_description: $.payload.pool.status_description - name: ""pool.update"" event_type: - ""pool.update.end"" type: ""delta"" unit: ""pool"" volume: 1 resource_id: $.payload.pool.id project_id: $.payload.pool.tenant_id metadata: name: $.payload.pool.name description: $.payload.pool.description admin_state_up: $.payload.pool.admin_state_up lb_method: $.payload.pool.lb_method protocol: $.payload.pool.protocol subnet_id: $.payload.pool.subnet_id vip_id: $.payload.pool.vip_id status: $.payload.pool.status status_description: $.payload.pool.status_description - name: ""pool.delete"" event_type: - ""pool.delete.end"" type: ""delta"" unit: ""pool"" volume: 1 resource_id: $.payload.pool.id project_id: $.payload.pool.tenant_id metadata: name: $.payload.pool.name description: $.payload.pool.description admin_state_up: $.payload.pool.admin_state_up lb_method: $.payload.pool.lb_method protocol: $.payload.pool.protocol subnet_id: $.payload.pool.subnet_id vip_id: $.payload.pool.vip_id status: $.payload.pool.status status_description: $.payload.pool.status_description - name: ""member.create"" event_type: - ""member.create.end"" type: ""delta"" unit: ""member"" volume: 1 resource_id: $.payload.member.id project_id: $.payload.member.tenant_id metadata: address: $.payload.member.address status: $.payload.member.status status_description: $.payload.member.status_description weight: $.payload.member.weight admin_state_up: $.payload.member.admin_state_up protocol_port: $.payload.member.protocol_port pool_id: $.payload.member.pool_id - name: ""member.update"" event_type: - ""member.update.end"" type: ""delta"" unit: ""member"" volume: 1 resource_id: $.payload.member.id project_id: $.payload.member.tenant_id metadata: address: $.payload.member.address status: $.payload.member.status status_description: $.payload.member.status_description weight: $.payload.member.weight admin_state_up: $.payload.member.admin_state_up protocol_port: $.payload.member.protocol_port pool_id: $.payload.member.pool_id - name: ""member.delete"" event_type: - ""member.delete.end"" type: ""delta"" unit: ""member"" volume: 1 resource_id: $.payload.member.id project_id: $.payload.member.tenant_id metadata: address: $.payload.member.address status: $.payload.member.status status_description: $.payload.member.status_description weight: $.payload.member.weight admin_state_up: $.payload.member.admin_state_up protocol_port: $.payload.member.protocol_port pool_id: $.payload.member.pool_id ",,265,0
openstack%2Fbarbican~master~Ice296fa9653be223e77d89ef0f1100813a8f4034,openstack/barbican,master,Ice296fa9653be223e77d89ef0f1100813a8f4034,Remove openstack-common.conf,MERGED,2016-01-12 10:46:52.000000000,2016-03-07 08:18:27.000000000,2016-03-07 08:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 780}, {'_account_id': 7136}, {'_account_id': 7789}, {'_account_id': 8623}, {'_account_id': 9796}, {'_account_id': 15274}, {'_account_id': 16046}, {'_account_id': 17579}, {'_account_id': 19136}, {'_account_id': 19673}]","[{'number': 1, 'created': '2016-01-12 10:46:52.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6a2d0132a65234a9e31d7093b3d5e7bc639aaef5', 'message': ""Remove openstack-common.conf\n\nWe don't sync from oslo-incubator, so don't\nneed this file any more.\n\nChange-Id: Ice296fa9653be223e77d89ef0f1100813a8f4034\n""}]",0,266286,6a2d0132a65234a9e31d7093b3d5e7bc639aaef5,25,11,1,19132,,,0,"Remove openstack-common.conf

We don't sync from oslo-incubator, so don't
need this file any more.

Change-Id: Ice296fa9653be223e77d89ef0f1100813a8f4034
",git fetch https://review.opendev.org/openstack/barbican refs/changes/86/266286/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,6a2d0132a65234a9e31d7093b3d5e7bc639aaef5,remove_conf,,"[DEFAULT] # The list of modules to copy from openstack-common modules=eventlet_backdoor,service,periodic_task # The base module to hold the copy of openstack.common base=barbican ",0,7
openstack%2Frpm-packaging~master~Ife244a86fece775ed903f97f1ce35b073aa260af,openstack/rpm-packaging,master,Ife244a86fece775ed903f97f1ce35b073aa260af,[openstack-macros] move __python2 macro to openstack-common,ABANDONED,2016-02-14 05:35:37.000000000,2016-03-07 08:18:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6593}, {'_account_id': 6717}, {'_account_id': 6835}, {'_account_id': 7102}, {'_account_id': 7613}, {'_account_id': 10384}, {'_account_id': 19648}]","[{'number': 1, 'created': '2016-02-14 05:35:37.000000000', 'files': ['openstack/openstack-macros/macros.openstack-suse', 'openstack/openstack-macros/macros.openstack-common'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f7b46158a557f5b36176f7eb021787aa7bf51152', 'message': '[openstack-macros] move __python2 macro to openstack-common\n\nSince __python2 is a usefule macro in following specs and it is not\nspecified in suse system. So this patch move this macro to\nopenstack-common part.\n\nChange-Id: Ife244a86fece775ed903f97f1ce35b073aa260af\n'}]",0,279921,f7b46158a557f5b36176f7eb021787aa7bf51152,7,9,1,6835,,,0,"[openstack-macros] move __python2 macro to openstack-common

Since __python2 is a usefule macro in following specs and it is not
specified in suse system. So this patch move this macro to
openstack-common part.

Change-Id: Ife244a86fece775ed903f97f1ce35b073aa260af
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/21/279921/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/openstack-macros/macros.openstack-suse', 'openstack/openstack-macros/macros.openstack-common']",2,f7b46158a557f5b36176f7eb021787aa7bf51152,python2-common,"# Copyright: (c) 2015 SUSE Linux GmbH # python specific macros to be compatible with other distros to share OpenStack # upstream packaging %__python2 /usr/bin/python2 %python2_sitelib %(%{__python2} -c ""from distutils.sysconfig import get_python_lib; print(get_python_lib())"") %python2_sitearch %(%{__python2} -c ""from distutils.sysconfig import get_python_lib; print(get_python_lib(1))"") # Make %license work like %doc for now - discussion started with openSUSE %_defaultlicensedir %_defaultdocdir",,9,8
openstack%2Fsahara~master~Ie3fd67833686c6f2fe7e6568699559484e4f4271,openstack/sahara,master,Ie3fd67833686c6f2fe7e6568699559484e4f4271,Updating quickstart guide with openstackclient usage,MERGED,2016-02-29 14:24:53.000000000,2016-03-07 08:15:08.000000000,2016-03-07 08:15:08.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 9740}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-02-29 14:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1fbe0c0654e177ac95301c79736f8d53b7540f7d', 'message': 'Updating quickstart guide with openstackclient usage\n\nChange-Id: Ie3fd67833686c6f2fe7e6568699559484e4f4271\n'}, {'number': 2, 'created': '2016-03-04 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dbce53f1304c3afc231bf73e05ca043ecd33a7ab', 'message': 'Updating quickstart guide with openstackclient usage\n\nChange-Id: Ie3fd67833686c6f2fe7e6568699559484e4f4271\n'}, {'number': 3, 'created': '2016-03-04 18:59:36.000000000', 'files': ['doc/source/devref/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/dca49a641760da4261d4222b797f36d9cefd08c3', 'message': 'Updating quickstart guide with openstackclient usage\n\nChange-Id: Ie3fd67833686c6f2fe7e6568699559484e4f4271\n'}]",32,286072,dca49a641760da4261d4222b797f36d9cefd08c3,21,8,3,12039,,,0,"Updating quickstart guide with openstackclient usage

Change-Id: Ie3fd67833686c6f2fe7e6568699559484e4f4271
",git fetch https://review.opendev.org/openstack/sahara refs/changes/72/286072/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/quickstart.rst'],1,1fbe0c0654e177ac95301c79736f8d53b7540f7d,new_cli_doc," $ export OS_PROJECT_NAME=admin $ openstack image create sahara-vanilla-latest-ubuntu --disk-format qcow2 \ --container-format bare --file sahara-vanilla-latest-ubuntu.qcow2 +------------------+--------------------------------------+ | Field | Value | +------------------+--------------------------------------+ | checksum | 3da49911332fc46db0c5fb7c197e3a77 | | container_format | bare | | created_at | 2016-02-29T10:15:04.000000 | | deleted | False | | deleted_at | None | | disk_format | qcow2 | | id | 71b9eeac-c904-4170-866a-1f833ea614f3 | | is_public | False | | min_disk | 0 | | min_ram | 0 | | name | sahara-vanilla-latest-ubuntu | | owner | 057d23cddb864759bfa61d730d444b1f | | properties | | | protected | False | | size | 1181876224 | | status | active | | updated_at | 2016-02-29T10:15:41.000000 | | virtual_size | None | +------------------+--------------------------------------+Remember the image name or save the image id, this will be used during the image registration with sahara. You can get the image ID using the ``openstack`` command line tool as follows: $ openstack image list --property name=sahara-vanilla-latest-ubuntu +--------------------------------------+------------------------------+ | ID | Name | +--------------------------------------+------------------------------+ | 71b9eeac-c904-4170-866a-1f833ea614f3 | sahara-vanilla-latest-ubuntu | +--------------------------------------+------------------------------+ $ openstack dataprocessing image register sahara-vanilla-latest-ubuntu \ --username ubuntu $ openstack dataprocessing image tags add sahara-vanilla-latest-ubuntu \ --tags vanilla <plugin_version> +-------------+--------------------------------------+ | Field | Value | +-------------+--------------------------------------+ | Description | None | | Id | 71b9eeac-c904-4170-866a-1f833ea614f3 | | Name | sahara-vanilla-latest-ubuntu | | Status | ACTIVE | | Tags | <plugin_version>, vanilla | | Username | ubuntu | +-------------+--------------------------------------+You can get information about available plugins with the following command: .. sourcecode:: console $ openstack dataprocessing plugin list Also you can get information about available services for a particular plugin with (for vanilla plugin in this example): .. sourcecode:: console $ openstack dataprocessing plugin show vanilla --version <plugin_version> +---------------------+-----------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------+-----------------------------------------------------------------------------------------------------------------------+ | Description | The Apache Vanilla plugin provides the ability to launch upstream Vanilla Apache Hadoop cluster without any | | | management consoles. It can also deploy the Oozie component. | | Name | vanilla | | Required image tags | <plugin_version>, vanilla | | Title | Vanilla Apache Hadoop | | | | | Service: | Available processes: | | | | | HDFS | datanode, namenode, secondarynamenode | | Hadoop | | | Hive | hiveserver | | JobFlow | oozie | | MapReduce | historyserver | | YARN | nodemanager, resourcemanager | +---------------------+-----------------------------------------------------------------------------------------------------------------------+ *Note, these commands assume that floating IP addresses are being used. ForCreate a master node group template with the command: .. sourcecode:: console $ openstack dataprocessing node group template create \ --name vanilla-default-master --plugin vanilla \ --version <plugin_version> --processes namenode resourcemanager --flavor 2 --auto-security-group --floating-ip-pool <pool-id> +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | Auto security group | True | | Availability zone | None | | Flavor id | 2 | | Floating ip pool | dbd8d1aa-6e8e-4a35-a77b-966c901464d5 | | Id | 0f066e14-9a73-4379-bbb4-9d9347633e31 | | Is default | False | | Is protected | False | | Is proxy gateway | False | | Is public | False | | Name | vanilla-default-master | | Node processes | namenode, resourcemanager | | Plugin name | vanilla | | Security groups | None | | Use autoconfig | False | | Version | <plugin_version> | | Volumes per node | 0 | +---------------------+--------------------------------------+ Create a worker node group template with the command: .. sourcecode:: console $ openstack dataprocessing node group template create \ --name vanilla-default-worker --plugin vanilla \ --version <plugin_version> --processes datanode nodemanager --flavor 2 --auto-security-group --floating-ip-pool <pool-id> +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | Auto security group | True | | Availability zone | None | | Flavor id | 2 | | Floating ip pool | dbd8d1aa-6e8e-4a35-a77b-966c901464d5 | | Id | 6546bf44-0590-4539-bfcb-99f8e2c11efc | | Is default | False | | Is protected | False | | Is proxy gateway | False | | Is public | False | | Name | vanilla-default-worker | | Node processes | datanode, nodemanager | | Plugin name | vanilla | | Security groups | None | | Use autoconfig | False | | Version | <plugin_version> | | Volumes per node | 0 | +---------------------+--------------------------------------+ Alternatively you can create node group templates from JSON files: ""resourcemanager"" ""floating_ip_pool"": ""<floating_ip_pool_id>"", ""floating_ip_pool"": ""<floating_ip_pool_id>"",Use the ``openstack`` client to upload the node group templates: $ openstack dataprocessing node group template create \ --json my_master_template_create.json $ openstack dataprocessing node group template create \ --json my_worker_template_create.json $ openstack dataprocessing node group template list --name vanilla-default +------------------------+--------------------------------------+-------------+--------------------+ | Name | Id | Plugin name | Version | +------------------------+--------------------------------------+-------------+--------------------+ | vanilla-default-master | 0f066e14-9a73-4379-bbb4-9d9347633e31 | vanilla | <plugin_version> | | vanilla-default-worker | 6546bf44-0590-4539-bfcb-99f8e2c11efc | vanilla | <plugin_version> | +------------------------+--------------------------------------+-------------+--------------------+ Remember the name or save the ID for the master and worker node group templates as they will be used during cluster template creation. * vanilla-default-master: ``0f066e14-9a73-4379-bbb4-9d9347633e31`` * vanilla-default-worker: ``6546bf44-0590-4539-bfcb-99f8e2c11efc``Create a cluster template with the command: .. sourcecode:: console $ openstack dataprocessing cluster template create \ --name vanilla-default-cluster --node-groups vanilla-default-master:1 vanilla-default-worker:3 +----------------+----------------------------------------------------+ | Field | Value | +----------------+----------------------------------------------------+ | Anti affinity | | | Description | None | | Id | 9d871ebd-88a9-40af-ae3e-d8c8f292401c | | Is default | False | | Is protected | False | | Is public | False | | Name | vanilla-default-cluster | | Node groups | vanilla-default-master:1, vanilla-default-worker:3 | | Plugin name | vanilla | | Use autoconfig | False | | Version | <plugin_version> | +----------------+----------------------------------------------------+ Alternatively you can create cluster templates from JSON file: ""count"": 3, ""node_group_template_id"": ""6546bf44-0590-4539-bfcb-99f8e2c11efc"" ""node_group_template_id"": ""0f066e14-9a73-4379-bbb4-9d9347633e31""Upload the Cluster template using the ``openstack`` command line tool: $ dataprocessing cluster template create --json my_cluster_template_create.json Remember the cluster template name or save the cluster template ID for use in the cluster provisioning command. The cluster ID can be found in the output of the creation command or by listing the cluster templates as follows: $ openstack dataprocessing cluster template list --name vanilla-default +-------------------------+--------------------------------------+-------------+--------------------+ | Name | Id | Plugin name | Version | +-------------------------+--------------------------------------+-------------+--------------------+ | vanilla-default-cluster | 9d871ebd-88a9-40af-ae3e-d8c8f292401c | vanilla | <plugin_version> | +-------------------------+--------------------------------------+-------------+--------------------+Create a cluster with the command: .. sourcecode:: console $ openstack dataprocessing cluster create --name my-cluster-1 \ --cluster-template vanilla-default-cluster --user-keypair my_stack --neutron-network private --image sahara-vanilla-latest-ubuntu +----------------------------+----------------------------------------------------+ | Field | Value | +----------------------------+----------------------------------------------------+ | Anti affinity | | | Cluster template id | 9d871ebd-88a9-40af-ae3e-d8c8f292401c | | Description | | | Id | 1f0dc6f7-6600-495f-8f3a-8ac08cdb3afc | | Image | 71b9eeac-c904-4170-866a-1f833ea614f3 | | Is protected | False | | Is public | False | | Is transient | False | | Name | my-cluster-1 | | Neutron management network | fabe9dae-6fbd-47ca-9eb1-1543de325efc | | Node groups | vanilla-default-master:1, vanilla-default-worker:3 | | Plugin name | vanilla | | Status | Validating | | Use autoconfig | False | | User keypair id | my_stack | | Version | <plugin_version> | +----------------------------+----------------------------------------------------+ Alternatively you can create cluster templates from JSON file: ""cluster_template_id"" : ""9d871ebd-88a9-40af-ae3e-d8c8f292401c"", ""default_image_id"": ""71b9eeac-c904-4170-866a-1f833ea614f3"", ""neutron_management_network"": ""fabe9dae-6fbd-47ca-9eb1-1543de325efc""Dashboard, or through the ``openstack`` command line client as follows: $ openstack keypair create my_stack --public-key $PATH_TO_PUBLIC_KEYinclude the ``--neoutron-network`` argument in ``cluster create`` command or ``neutron_management_network`` parameter in ``my_cluster_create.json``. If your environment does not use neutron, you can omit ``--neoutron-network`` or ``neutron_management_network`` above. You can determine the neutron network id with the following command: $ openstack network list $ openstack dataprocessing cluster create --json my_cluster_create.json Verify the cluster status by using the ``openstack`` command $ dataprocessing cluster show my-cluster-1 -c Status +--------+--------+ | Field | Value | +--------+--------+ | Status | Active | +--------+--------+other than ``Active``. Cluster also can be created with ``--wait`` flag. In that case cluster creation command will not be finished until cluster will be moved in ``Active`` state."," $ export OS_TENANT_NAME=adminWith these environment variables set you can get an authentication token using the ``keystone`` command line client as follows: .. sourcecode:: console $ keystone token-get If authentication succeeds, the output will be as follows: .. sourcecode:: console +-----------+----------------------------------+ | Property | Value | +-----------+----------------------------------+ | expires | 2015-09-03T13:37:32Z | | id | 2542c427092a4b09a07ee7612c3d99ae | | tenant_id | c82e4bce56ce4cf9b90bd15dfdef699d | | user_id | 7f5becaaa38b4c9e850ccd11672a4c96 | +-----------+----------------------------------+ The ``id`` and ``tenant_id`` values will be used for creating REST calls to sahara and should be saved. The ``id`` value is the token provided by the Identity service, and the ``tenant_id`` is the UUID for the tenant name specified earlier. These values should be exported to environment variables for ease of use later. .. sourcecode:: console $ export AUTH_TOKEN=""2542c427092a4b09a07ee7612c3d99ae"" $ export TENANT_ID=""c82e4bce56ce4cf9b90bd15dfdef699d"" Alternatively, if a devstack environment is used, these values are available through ""openrc"" file under the ""devstack_install_root"" directory and can be configured as: .. sourcecode:: console $ source <devstack_install_root>/openrc $ glance image-create --name=sahara-vanilla-latest-ubuntu \ --disk-format=qcow2 --container-format=bare < ./sahara-vanilla-latest-ubuntu.qcow2Save the image id, this will be used during the image registration with sahara. You can get the image id using the ``glance`` command line tool as follows: $ glance image-list --name sahara-vanilla-latest-ubuntu +--------------------------------------+-------------------------------------+ | ID | Name | +--------------------------------------+-------------------------------------+ | c119f99c-67f2-4404-9cff-f30e4b185036 | sahara-vanilla-latest-ubuntu | +--------------------------------------+-------------------------------------+ $ export IMAGE_ID=""c119f99c-67f2-4404-9cff-f30e4b185036"" $ sahara image-register --id $IMAGE_ID --username ubuntu $ sahara image-add-tag --id $IMAGE_ID --tag vanilla $ sahara image-add-tag --id $IMAGE_ID --tag <plugin_version> Ensure that the image is registered correctly by querying sahara. If registered successfully, the image will appear in the output as follows: .. sourcecode:: console $ sahara image-list +------------------------------+--------------------------------------+----------+---------------------------+-------------+ | name | id | username | tags | description | +------------------------------+--------------------------------------+----------+---------------------------+-------------+ | sahara-vanilla-latest-ubuntu | c119f99c-67f2-4404-9cff-f30e4b185036 | ubuntu | vanilla, <plugin_version> | None | +------------------------------+--------------------------------------+----------+---------------------------+-------------+*Note, these templates assume that floating IP addresses are being used. For ""resourcemanager"", ""hiveserver"" ""floating_ip_pool"": ""public"", ""floating_ip_pool"": ""public"",Use the ``sahara`` client to upload the node group templates: $ sahara node-group-template-create --json my_master_template_create.json $ sahara node-group-template-create --json my_worker_template_create.json $ sahara node-group-template-list +------------------------+--------------------------------------+-------------+---------------------------------------+-------------+ | name | id | plugin_name | node_processes | description | +------------------------+--------------------------------------+-------------+---------------------------------------+-------------+ | vanilla-default-master | 9d3b5b2c-d5d5-4d16-8a93-a568d29c6569 | vanilla | namenode, resourcemanager, hiveserver | None | | vanilla-default-worker | 1aa4a397-cb1e-4f38-be18-7f65fa0cc2eb | vanilla | nodemanager, datanode | None | +------------------------+--------------------------------------+-------------+---------------------------------------+-------------+ Save the id for the master and worker node group templates as they will be used during cluster template creation.* Master node group template id: ``9d3b5b2c-d5d5-4d16-8a93-a568d29c6569`` * Worker node group template id: ``1aa4a397-cb1e-4f38-be18-7f65fa0cc2eb`` ""count"": 2, ""node_group_template_id"": ""1aa4a397-cb1e-4f38-be18-7f65fa0cc2eb"" ""node_group_template_id"": ""9d3b5b2c-d5d5-4d16-8a93-a568d29c6569""Upload the Cluster template using the ``sahara`` command line tool: $ sahara cluster-template-create --json my_cluster_template_create.json Save the cluster template id for use in the cluster provisioning command. The cluster id can be found in the output of the creation command or by listing the cluster templates as follows: $ sahara cluster-template-list +-------------------------+--------------------------------------+-------------+----------------------+-------------+ | name | id | plugin_name | node_groups | description | +-------------------------+--------------------------------------+-------------+----------------------+-------------+ | vanilla-default-cluster | 74add4df-07c2-4053-931f-d5844712727f | vanilla | master: 1, worker: 2 | None | +-------------------------+--------------------------------------+-------------+----------------------+-------------+ ""cluster_template_id"" : ""74add4df-07c2-4053-931f-d5844712727f"", ""default_image_id"": ""c119f99c-67f2-4404-9cff-f30e4b185036"", ""neutron_management_network"": ""8cccf998-85e4-4c5f-8850-63d33c1c6916""Dashboard, or through the ``nova`` command line client as follows: $ nova keypair-add my_stack --pub-key $PATH_TO_PUBLIC_KEYinclude the ``neutron_management_network`` parameter in ``my_cluster_create.json``. If your environment does not use neutron, you can omit ``neutron_management_network`` above. You can determine the neutron network id with the following command: $ neutron net-list $ sahara cluster-create --json my_cluster_create.json +----------------------------+-------------------------------------------------+ | Property | Value | +----------------------------+-------------------------------------------------+ | status | Active | | neutron_management_network | None | | is_transient | False | | description | None | | user_keypair_id | my_stack | | updated_at | 2015-09-02T10:58:02 | | plugin_name | vanilla | | provision_progress | [{u'successful': True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:41:07', | | | u'step_type': u'Engine: create cluster', | | | u'updated_at': u'2015-09-02T10:41:12', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Wait for | | | instances to become active', u'total': 3, | | | u'id': u'34b4b23e- | | | dc94-4253-bb36-d343a4ec1e57'}, {u'successful': | | | True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:41:05', | | | u'step_type': u'Engine: create cluster', | | | u'updated_at': u'2015-09-02T10:41:07', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Run | | | instances', u'total': 3, u'id': u'401f6812 | | | -d92c-44f0-acfe-f22f4dc1c3fe'}, {u'successful': | | | True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:52:12', | | | u'step_type': u'Plugin: start cluster', | | | u'updated_at': u'2015-09-02T10:55:02', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Await | | | DataNodes start up', u'total': 1, u'id': u | | | '407379af-94a4-4821-9952-14a21be06ebc'}, | | | {u'successful': True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:41:13', | | | u'step_type': u'Engine: create cluster', | | | u'updated_at': u'2015-09-02T10:48:21', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Wait for | | | instance accessibility', u'total': 3, u'id': | | | u'534a3a7b-2678-44f4-9562-f859fef00b1f'}, | | | {u'successful': True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:51:43', | | | u'step_type': u'Plugin: start cluster', | | | u'updated_at': u'2015-09-02T10:52:12', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Start the | | | following process(es): DataNodes, | | | NodeManagers', u'total': 2, u'id': u'628a995c- | | | 316c-4eed-acbf-17076ffa34db'}, {u'successful': | | | True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:48:21', | | | u'step_type': u'Engine: create cluster', | | | u'updated_at': u'2015-09-02T10:48:33', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Configure | | | instances', u'total': 3, u'id': u'7fa3987a- | | | 636f-48a5-a34c-7a6ecd6b5a44'}, {u'successful': | | | True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:50:26', | | | u'step_type': u'Plugin: start cluster', | | | u'updated_at': u'2015-09-02T10:51:30', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Start the | | | following process(es): NameNode', u'total': 1, | | | u'id': u'8988c41f-9bef-484a- | | | bd93-58700f55f82b'}, {u'successful': True, | | | u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:50:14', | | | u'step_type': u'Plugin: configure cluster', | | | u'updated_at': u'2015-09-02T10:50:25', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Configure | | | topology data', u'total': 1, u'id': | | | u'bc20afb9-c44a-4825-9ac2-8bd69bf7efcc'}, | | | {u'successful': True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:48:33', | | | u'step_type': u'Plugin: configure cluster', | | | u'updated_at': u'2015-09-02T10:50:14', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Configure | | | instances', u'total': 3, u'id': u'c0a3f2ac- | | | 508f-4ef4-ac87-db82a4999795'}, {u'successful': | | | True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:55:02', | | | u'step_type': u'Plugin: start cluster', | | | u'updated_at': u'2015-09-02T10:58:01', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Start the | | | following process(es): HiveServer', u'total': | | | 1, u'id': u'd5ab5d4c-b8e7-4fe0-b36f- | | | 116861bdfcb3'}, {u'successful': True, | | | u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:41:13', | | | u'step_type': u'Engine: create cluster', | | | u'updated_at': u'2015-09-02T10:41:13', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Assign | | | IPs', u'total': 3, u'id': | | | u'd6848957-6206-4116-a310-ec458e651c12'}, | | | {u'successful': True, u'tenant_id': | | | u'c82e4bce56ce4cf9b90bd15dfdef699d', | | | u'created_at': u'2015-09-02T10:51:30', | | | u'step_type': u'Plugin: start cluster', | | | u'updated_at': u'2015-09-02T10:51:43', | | | u'cluster_id': u'9b094131-a858-4ddb- | | | 81a8-b71597417cad', u'step_name': u'Start the | | | following process(es): ResourceManager', | | | u'total': 1, u'id': u'dcd433e3-017a- | | | 430a-8217-94cae4b813c2'}] | | use_autoconfig | True | | anti_affinity | [] | | node_groups | [{u'volume_local_to_instance': False, | | | u'availability_zone': None, u'updated_at': | | | u'2015-09-02T10:41:06', u'instances': | | | [{u'instance_id': u'949da8aa-7c9e-48b3-882e- | | | 0c7a0049100e', u'created_at': | | | u'2015-09-02T10:41:06', u'updated_at': | | | u'2015-09-02T10:41:13', u'instance_name': | | | u'cluster-3-master-001', u'management_ip': | | | u'192.168.1.134', u'internal_ip': | | | u'172.24.17.2', u'id': u'e27503e8-a118-4c3e- | | | a7d7-ee64fcd4568a'}], | | | u'node_group_template_id': u'9d3b5b2c- | | | d5d5-4d16-8a93-a568d29c6569', | | | u'volumes_per_node': 0, u'id': u'6a53f95a-c2aa- | | | 48d7-b43a-62d149c656af', u'security_groups': | | | [6], u'shares': None, u'node_configs': | | | {u'MapReduce': {u'mapreduce.map.memory.mb': | | | 256, u'mapreduce.reduce.memory.mb': 512, | | | u'yarn.app.mapreduce.am.command-opts': | | | u'-Xmx204m', u'mapreduce.reduce.java.opts': | | | u'-Xmx409m', | | | u'yarn.app.mapreduce.am.resource.mb': 256, | | | u'mapreduce.map.java.opts': u'-Xmx204m', | | | u'mapreduce.task.io.sort.mb': 102}, u'YARN': | | | {u'yarn.scheduler.minimum-allocation-mb': 256, | | | u'yarn.scheduler.maximum-allocation-mb': 2048, | | | u'yarn.nodemanager.vmem-check-enabled': | | | u'false', u'yarn.nodemanager.resource.memory- | | | mb': 2048}}, u'auto_security_group': True, | | | u'volumes_availability_zone': None, | | | u'volume_mount_prefix': u'/volumes/disk', | | | u'floating_ip_pool': u'public', u'image_id': | | | None, u'volumes_size': 0, u'is_proxy_gateway': | | | False, u'count': 1, u'name': u'master', | | | u'created_at': u'2015-09-02T10:41:02', | | | u'volume_type': None, u'node_processes': | | | [u'namenode', u'resourcemanager', | | | u'hiveserver'], u'flavor_id': u'2', | | | u'use_autoconfig': True}, | | | {u'volume_local_to_instance': False, | | | u'availability_zone': None, u'updated_at': | | | u'2015-09-02T10:41:07', u'instances': | | | [{u'instance_id': u'47f97841-4a17-4e18-a8eb- | | | b4ff7dd4c3d8', u'created_at': | | | u'2015-09-02T10:41:06', u'updated_at': | | | u'2015-09-02T10:41:13', u'instance_name': | | | u'cluster-3-worker-001', u'management_ip': | | | u'192.168.1.135', u'internal_ip': | | | u'172.24.17.3', u'id': u'c4a02678-113b-432e- | | | 8f91-927b8e7cfe83'}, {u'instance_id': | | | u'a02aea39-cc1f-4a1f-8232-2470ab6e8478', | | | u'created_at': u'2015-09-02T10:41:07', | | | u'updated_at': u'2015-09-02T10:41:13', | | | u'instance_name': u'cluster-3-worker-002', | | | u'management_ip': u'192.168.1.130', | | | u'internal_ip': u'172.24.17.4', u'id': u | | | 'b7b2d6db-cd50-484b-8036-09820d2623f2'}], | | | u'node_group_template_id': u'1aa4a397-cb1e- | | | 4f38-be18-7f65fa0cc2eb', u'volumes_per_node': | | | 0, u'id': u'b666103f-a44b-4cf8-b3ae- | | | 7d2623c6cd18', u'security_groups': [7], | | | u'shares': None, u'node_configs': | | | {u'MapReduce': {u'mapreduce.map.memory.mb': | | | 256, u'mapreduce.reduce.memory.mb': 512, | | | u'yarn.app.mapreduce.am.command-opts': | | | u'-Xmx204m', u'mapreduce.reduce.java.opts': | | | u'-Xmx409m', | | | u'yarn.app.mapreduce.am.resource.mb': 256, | | | u'mapreduce.map.java.opts': u'-Xmx204m', | | | u'mapreduce.task.io.sort.mb': 102}, u'YARN': | | | {u'yarn.scheduler.minimum-allocation-mb': 256, | | | u'yarn.scheduler.maximum-allocation-mb': 2048, | | | u'yarn.nodemanager.vmem-check-enabled': | | | u'false', u'yarn.nodemanager.resource.memory- | | | mb': 2048}}, u'auto_security_group': True, | | | u'volumes_availability_zone': None, | | | u'volume_mount_prefix': u'/volumes/disk', | | | u'floating_ip_pool': u'public', u'image_id': | | | None, u'volumes_size': 0, u'is_proxy_gateway': | | | False, u'count': 2, u'name': u'worker', | | | u'created_at': u'2015-09-02T10:41:02', | | | u'volume_type': None, u'node_processes': | | | [u'nodemanager', u'datanode'], u'flavor_id': | | | u'2', u'use_autoconfig': True}] | | is_public | False | | management_public_key | ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDiFXlWNVD | | | 6gJT74wherHWtgchqpvgi2aJ4fPWXP+WgB4GEKpfD7a/dWu | | | Qg9eDBQIrWvVsKgG1i9YgRTHOQ7DdwoSKUAcpEewgw927ER | | | wdJ3IV7EDu0xENUgrUgp+CwPdk94SXPg1G4oHOCbOvJYcW6 | | | /b8Ci86vH9A7Uyu2T7tbVS4ciMKfwI0Z47lzcp2qDV6W8M7 | | | neghC1mNT4k29ghgcYOzY4SxQjxp1a5Iu6RtnJ2fvHbLeMS | | | 0hgeobSZ8heQzLImrp2dbyZy74goOcwKtk9dDPV853aZrjL | | | yOsc78EgW6n2Gugu7Ks12v9QEDr4H3yTt3DNTrB5Y8tt468 | | | k2n1 Generated-by-Sahara | | status_description | | | hadoop_version | <plugin_version> | | id | 9b094131-a858-4ddb-81a8-b71597417cad | | trust_id | None | | info | {u'HDFS': {u'NameNode': | | | u'hdfs://cluster-3-master-001:9000', u'Web UI': | | | u'http://192.168.1.134:50070'}, u'YARN': {u'Web | | | UI': u'http://192.168.1.134:8088', | | | u'ResourceManager': | | | u'http://192.168.1.134:8032'}} | | cluster_template_id | 74add4df-07c2-4053-931f-d5844712727f | | name | my-cluster-1 | | cluster_configs | {u'HDFS': {u'dfs.replication': 2}} | | created_at | 2015-09-02T10:41:02 | | default_image_id | c119f99c-67f2-4404-9cff-f30e4b185036 | | shares | None | | is_protected | False | | tenant_id | c82e4bce56ce4cf9b90bd15dfdef699d | +----------------------------+-------------------------------------------------+ Verify the cluster launched successfully by using the ``sahara`` command $ sahara cluster-list +--------------+--------------------------------------+--------+------------+ | name | id | status | node_count | +--------------+--------------------------------------+--------+------------+ | my-cluster-1 | 9b094131-a858-4ddb-81a8-b71597417cad | Active | 3 | +--------------+--------------------------------------+--------+------------+other than ""Active"".",253,358
openstack%2Fnova~master~Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3,openstack/nova,master,Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3,Clean MAC addresses for direct ports on unplug,ABANDONED,2015-08-04 14:59:00.000000000,2016-03-07 07:59:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6509}, {'_account_id': 6598}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12171}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-08-04 14:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f1973956872f5b283f5fb94583d9f757363678c', 'message': ""Clean MAC addresses for direct ports on unplug\n\nCurrently, in sriov setup VFs doesn't get cleaned up after\nport deletion. Specifically, MAC and VLAN configuration that\nwas previously assigned stays untouched and gets changed\nonly next time when this device will be allocated.\n\nThis could lead to unexpected results, for example, user could\ncreate a port with MAC address of some deleted port, but as\nthe VF of that specific deleted port wasn't cleaned up, user\ncould end up with two VFs with the same MAC address for example.\n\nChange-Id: Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3\nCloses-Bug: #1475256\n""}, {'number': 2, 'created': '2015-08-04 14:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce1672cf041141764da4513accc7c17a9a4e158c', 'message': ""Clean MAC addresses for direct ports on unplug\n\nCurrently, in sriov setup VFs doesn't get cleaned up after\nport deletion. Specifically, MAC and VLAN configuration that\nwas previously assigned stays untouched and gets changed\nonly next time when this device will be allocated.\n\nThis could lead to unexpected results, for example, user could\ncreate a port with MAC address of some deleted port, but as\nthe VF of that specific deleted port wasn't cleaned up, user\ncould end up with two VFs with the same MAC address for example.\n\nCloses-Bug: #1475256\nChange-Id: Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3\n""}, {'number': 3, 'created': '2015-08-05 04:42:17.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/virt/libvirt/vif.py', 'nova/network/linux_net.py', 'nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4dd24070b6692fb4aead0b89db4ce1ff6317a3d3', 'message': ""Clean MAC addresses for direct ports on unplug\n\nCurrently, in sriov setup VFs doesn't get cleaned up after\nport deletion. Specifically, MAC and VLAN configuration that\nwas previously assigned stays untouched and gets changed\nonly next time when this device will be allocated.\n\nThis could lead to unexpected results, for example, user could\ncreate a port with MAC address of some deleted port, but as\nthe VF of that specific deleted port wasn't cleaned up, user\ncould end up with two VFs with the same MAC address for example.\n\nTo fix that, make LibvirtGenericVIFDriver.unplug_hw_veb explictly\nreset MAC and VLAN configurtion for NIC_TYPE_DIRECT type of ports\nusing the linux_net.set_vf_interface_vlan helper.\n\nAlso, modify linux_net.set_vf_interface_vlan to accept set_state\nkeyword argument that is True by default to keep the existing\nbehaviour. When set_state is set to False, the 'ip link set $dev up/down'\ncommand will not be executed.\n\nThe reason for this is that the Neutron sriov-nic-agent already\nmanages VFs state, and, additionally, not all SRIOV drivers support\nstate control.\n\nCloses-Bug: #1475256\nChange-Id: Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3\n""}]",5,209110,4dd24070b6692fb4aead0b89db4ce1ff6317a3d3,30,13,3,6509,,,0,"Clean MAC addresses for direct ports on unplug

Currently, in sriov setup VFs doesn't get cleaned up after
port deletion. Specifically, MAC and VLAN configuration that
was previously assigned stays untouched and gets changed
only next time when this device will be allocated.

This could lead to unexpected results, for example, user could
create a port with MAC address of some deleted port, but as
the VF of that specific deleted port wasn't cleaned up, user
could end up with two VFs with the same MAC address for example.

To fix that, make LibvirtGenericVIFDriver.unplug_hw_veb explictly
reset MAC and VLAN configurtion for NIC_TYPE_DIRECT type of ports
using the linux_net.set_vf_interface_vlan helper.

Also, modify linux_net.set_vf_interface_vlan to accept set_state
keyword argument that is True by default to keep the existing
behaviour. When set_state is set to False, the 'ip link set $dev up/down'
command will not be executed.

The reason for this is that the Neutron sriov-nic-agent already
manages VFs state, and, additionally, not all SRIOV drivers support
state control.

Closes-Bug: #1475256
Change-Id: Ibdc013bbfc5a4cea62698fe686894de1b2b5e6a3
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/209110/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_linux_net.py', 'nova/virt/libvirt/vif.py', 'nova/network/linux_net.py', 'nova/tests/unit/virt/libvirt/test_vif.py']",4,5f1973956872f5b283f5fb94583d9f757363678c,," @mock.patch.object(linux_net, 'set_vf_interface_vlan') def test_unplug_hw_veb_direct(self, mock_set_vf_interface_vlan): d = vif.LibvirtGenericVIFDriver() d.unplug_hw_veb(self.instance, self.vif_hw_veb) expected_calls = [ mock.call(self.vif_hw_veb['profile']['pci_slot'], mac_addr='0', set_state=False)] self.assertEqual(expected_calls, mock_set_vf_interface_vlan.mock_calls) ",,57,6
openstack%2Fapi-site~master~Ibfb1b8376c29c56fbb97e4c1ad746b4599549418,openstack/api-site,master,Ibfb1b8376c29c56fbb97e4c1ad746b4599549418,Updated from openstack-manuals,MERGED,2016-03-07 07:41:15.000000000,2016-03-07 07:58:34.000000000,2016-03-07 07:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 07:41:15.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/1fd092d796162cffe95bbad415bf7f4217a57845', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ibfb1b8376c29c56fbb97e4c1ad746b4599549418\n'}]",0,289198,1fd092d796162cffe95bbad415bf7f4217a57845,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ibfb1b8376c29c56fbb97e4c1ad746b4599549418
",git fetch https://review.opendev.org/openstack/api-site refs/changes/98/289198/1 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,1fd092d796162cffe95bbad415bf7f4217a57845,openstack/openstack-manuals," core service An official OpenStack service defined as core by DefCore Committee. Currently, consists of Block Storage service (cinder), Compute service (nova), Identity service (keystone), Image service (glance), Networking service (neutron), and Object Storage service (swift). optional service An official OpenStack service defined as optional by DefCore Committee. Currently, consists of Dashboard (horizon), Telemetry service (Telemetry), Orchestration service (heat), Database service (trove), Bare Metal service (ironic), and so on. "," core project An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"".",14,9
openstack%2Fsecurity-doc~master~I5628b69705178ecc20cd47ddd7d3faa32cb6b0aa,openstack/security-doc,master,I5628b69705178ecc20cd47ddd7d3faa32cb6b0aa,Updated from openstack-manuals,MERGED,2016-03-07 07:41:25.000000000,2016-03-07 07:57:20.000000000,2016-03-07 07:57:20.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 07:41:25.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/2aa8277a2d3d4734ded1cfab82226e0dd098c067', 'message': 'Updated from openstack-manuals\n\nChange-Id: I5628b69705178ecc20cd47ddd7d3faa32cb6b0aa\n'}]",0,289201,2aa8277a2d3d4734ded1cfab82226e0dd098c067,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I5628b69705178ecc20cd47ddd7d3faa32cb6b0aa
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/01/289201/1 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,2aa8277a2d3d4734ded1cfab82226e0dd098c067,openstack/openstack-manuals," core service An official OpenStack service defined as core by DefCore Committee. Currently, consists of Block Storage service (cinder), Compute service (nova), Identity service (keystone), Image service (glance), Networking service (neutron), and Object Storage service (swift). optional service An official OpenStack service defined as optional by DefCore Committee. Currently, consists of Dashboard (horizon), Telemetry service (Telemetry), Orchestration service (heat), Database service (trove), Bare Metal service (ironic), and so on. "," core project An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"".",14,9
openstack%2Fha-guide~master~I36cba109e634944e589d6a2119de19d692475757,openstack/ha-guide,master,I36cba109e634944e589d6a2119de19d692475757,Updated from openstack-manuals,MERGED,2016-03-07 07:41:17.000000000,2016-03-07 07:56:58.000000000,2016-03-07 07:56:58.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 07:41:17.000000000', 'files': ['doc/common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/a306fe752306609127ef29841d4dd11651e729e6', 'message': 'Updated from openstack-manuals\n\nChange-Id: I36cba109e634944e589d6a2119de19d692475757\n'}]",0,289199,a306fe752306609127ef29841d4dd11651e729e6,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I36cba109e634944e589d6a2119de19d692475757
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/99/289199/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/glossary.rst'],1,a306fe752306609127ef29841d4dd11651e729e6,openstack/openstack-manuals," core service An official OpenStack service defined as core by DefCore Committee. Currently, consists of Block Storage service (cinder), Compute service (nova), Identity service (keystone), Image service (glance), Networking service (neutron), and Object Storage service (swift). optional service An official OpenStack service defined as optional by DefCore Committee. Currently, consists of Dashboard (horizon), Telemetry service (Telemetry), Orchestration service (heat), Database service (trove), Bare Metal service (ironic), and so on. "," core project An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"".",14,9
openstack%2Ftripleo-heat-templates~master~I20a0d4978e907111404f8108c502ab53b69a3296,openstack/tripleo-heat-templates,master,I20a0d4978e907111404f8108c502ab53b69a3296,Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades,MERGED,2016-03-02 16:58:21.000000000,2016-03-07 07:55:56.000000000,2016-03-07 07:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 9979}]","[{'number': 1, 'created': '2016-03-02 16:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f11b6f26c1f3e3dbff7bdb38fbe7e78c1cbd5644', 'message': ""Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades\n\nThis splits the upgrade script delivery out of the UpgradeWorkflow\nand into a new UpgradeScriptDeliveryWorkflow which delivers\nthe upgrade script for compute and object-storage nodes. This is\nintended to be the first part of the upgrades process, since we need\nto upgrade swift nodes before the controllers and then only one at a\ntime. So this will deliver the upgrade script which can be invoked\nby the operator using the existing script in tripleo-common\n'upgrade-non-controller.sh'\n\nChange-Id: I20a0d4978e907111404f8108c502ab53b69a3296\n""}, {'number': 2, 'created': '2016-03-02 17:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f4fbbb2dd7f00b3c63fcc664e55188bab4a6716', 'message': ""Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades\n\nThis splits the upgrade script delivery out of the UpgradeWorkflow\nand into a new UpgradeScriptDeliveryWorkflow which delivers\nthe upgrade script for compute and object-storage nodes. This is\nintended to be the first part of the upgrades process, since we need\nto upgrade swift nodes before the controllers and then only one at a\ntime. So this will deliver the upgrade script which can be invoked\nby the operator using the existing script in tripleo-common\n'upgrade-non-controller.sh'\n\nChange-Id: I20a0d4978e907111404f8108c502ab53b69a3296\n""}, {'number': 3, 'created': '2016-03-03 10:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cce573efb970859dff162a75eb94fc09a8d55678', 'message': ""Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades\n\nThis splits the upgrade script delivery out of the UpgradeWorkflow\nand into a new UpgradeScriptDeliveryWorkflow which delivers\nthe upgrade script for compute and object-storage nodes. This is\nintended to be the first part of the upgrades process, since we need\nto upgrade swift nodes before the controllers and then only one at a\ntime. So this will deliver the upgrade script which can be invoked\nby the operator using the existing script in tripleo-common\n'upgrade-non-controller.sh'\n\nChange-Id: I20a0d4978e907111404f8108c502ab53b69a3296\n""}, {'number': 4, 'created': '2016-03-03 11:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e585dbb4394063f5096701c1fd1db471eaa1c443', 'message': ""Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades\n\nThis splits the upgrade script delivery out of the UpgradeWorkflow\nand into a new task which delivers the upgrade script for\ncompute and object-storage nodes. This is intended to be the first\npart of the upgrades process, since we need to upgrade swift nodes\nbefore the controllers and then only one at a time. So this will\ndeliver the upgrade script which can be invoked by the operator\nusing the existing script in tripleo-common\n'upgrade-non-controller.sh'.\n\nThis can be invoked by passing the -e\nenvironments/major-upgrade-script-delivery.yaml (added here) to\nthe openstack overcloud deploy command.\n\nChange-Id: I20a0d4978e907111404f8108c502ab53b69a3296\n""}, {'number': 5, 'created': '2016-03-03 11:31:02.000000000', 'files': ['extraconfig/tasks/major_upgrade_object_storage.sh', 'environments/major-upgrade-script-delivery.yaml', 'extraconfig/tasks/major_upgrade_script_delivery.yaml', 'extraconfig/tasks/major_upgrade_pacemaker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c78a215ae9cd02a47e46b4d302f2a275ccce1693', 'message': ""Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades\n\nThis splits the upgrade script delivery out of the UpgradeWorkflow\nand into a new task which delivers the upgrade script for\ncompute and object-storage nodes. This is intended to be the first\npart of the upgrades process, since we need to upgrade swift nodes\nbefore the controllers and then only one at a time. So this will\ndeliver the upgrade script which can be invoked by the operator\nusing the existing script in tripleo-common\n'upgrade-non-controller.sh'.\n\nThis can be invoked by passing the -e\nenvironments/major-upgrade-script-delivery.yaml (added here) to\nthe openstack overcloud deploy command.\n\nChange-Id: I20a0d4978e907111404f8108c502ab53b69a3296\n""}]",3,287318,c78a215ae9cd02a47e46b4d302f2a275ccce1693,23,7,5,8449,,,0,"Introduce a UpgradeScriptDeliveryWorfklow as part of tripleo upgrades

This splits the upgrade script delivery out of the UpgradeWorkflow
and into a new task which delivers the upgrade script for
compute and object-storage nodes. This is intended to be the first
part of the upgrades process, since we need to upgrade swift nodes
before the controllers and then only one at a time. So this will
deliver the upgrade script which can be invoked by the operator
using the existing script in tripleo-common
'upgrade-non-controller.sh'.

This can be invoked by passing the -e
environments/major-upgrade-script-delivery.yaml (added here) to
the openstack overcloud deploy command.

Change-Id: I20a0d4978e907111404f8108c502ab53b69a3296
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/287318/3 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'extraconfig/tasks/major_upgrade_object_storage.sh', 'overcloud.yaml', 'environments/major-upgrade-script-delivery.yaml', 'extraconfig/tasks/major_upgrade_script_delivery.yaml', 'extraconfig/tasks/major_upgrade_pacemaker.yaml']",6,f11b6f26c1f3e3dbff7bdb38fbe7e78c1cbd5644,delivery_workflow,, ComputeDeliverUpgradeConfig_Step3: type: OS::Heat::SoftwareConfig properties: group: script config: list_join: - '' - - str_replace: template: | #!/bin/bash upgrade_level_nova_compute='UPGRADE_LEVEL_NOVA_COMPUTE' params: UPGRADE_LEVEL_NOVA_COMPUTE: {get_param: UpgradeLevelNovaCompute} - get_file: pacemaker_common_functions.sh - get_file: major_upgrade_compute.sh ComputeDeliverUpgradeConfigDeployment_Step3: type: OS::Heat::SoftwareDeploymentGroup depends_on: ControllerPacemakerUpgradeDeployment_Step2 properties: servers: {get_param: compute_servers} config: {get_resource: ComputeDeliverUpgradeConfig_Step3} input_values: {get_param: input_values} ,117,25
openstack%2Fopenstack-manuals~master~I94d52c1c03d5909e4c88e8aea898febe2ff222b6,openstack/openstack-manuals,master,I94d52c1c03d5909e4c88e8aea898febe2ff222b6,Do not translate Config Reference,MERGED,2016-03-07 06:47:14.000000000,2016-03-07 07:49:19.000000000,2016-03-07 07:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-07 06:47:14.000000000', 'files': ['doc-tools-check-languages.conf'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/affc689a4cb7012321269208a5eed336e348551f', 'message': 'Do not translate Config Reference\n\nThe Config Reference has no translations at all currently and contains a\nlot of generated content. Do not add it to our translation list for now,\nwe can revisit it again if there is real demand and time to translate\nit. Right now it just creates needless imports.\n\nChange-Id: I94d52c1c03d5909e4c88e8aea898febe2ff222b6\n'}]",0,289175,affc689a4cb7012321269208a5eed336e348551f,6,2,1,6547,,,0,"Do not translate Config Reference

The Config Reference has no translations at all currently and contains a
lot of generated content. Do not add it to our translation list for now,
we can revisit it again if there is real demand and time to translate
it. Right now it just creates needless imports.

Change-Id: I94d52c1c03d5909e4c88e8aea898febe2ff222b6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/75/289175/1 && git format-patch -1 --stdout FETCH_HEAD,['doc-tools-check-languages.conf'],1,affc689a4cb7012321269208a5eed336e348551f,disable-config," [""config-reference""]=""skip"""," [""config-reference""]=""RST""",1,1
openstack%2Fvitrage~master~I9c0ae7551b9bf2aeb0f3f7ff571564b916b44d5f,openstack/vitrage,master,I9c0ae7551b9bf2aeb0f3f7ff571564b916b44d5f,state normalization fixes,MERGED,2016-03-07 06:50:04.000000000,2016-03-07 07:48:38.000000000,2016-03-07 07:48:38.000000000,"[{'_account_id': 3}, {'_account_id': 19159}, {'_account_id': 19194}, {'_account_id': 19209}]","[{'number': 1, 'created': '2016-03-07 06:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/7ed5ac32996b7cc5fd43d09c00e0ac1f7a2a9a30', 'message': 'state normalization fixes\n\nChange-Id: I9c0ae7551b9bf2aeb0f3f7ff571564b916b44d5f\n'}, {'number': 2, 'created': '2016-03-07 07:10:00.000000000', 'files': ['vitrage/tests/resources/states_plugins/erroneous_states_plugins/nova.host.yaml', 'vitrage/tests/unit/entity_graph/test_state_manager.py', 'vitrage/tests/resources/states_plugins/erroneous_states_plugins/nova.instance.yaml', 'vitrage/tests/unit/synchronizer/transformers/test_transformer_manager.py', 'vitrage/entity_graph/processor/processor.py', 'etc/vitrage/states_plugins/switch.yaml', 'vitrage/tests/unit/synchronizer/nova/__init__.py', 'vitrage/tests/unit/synchronizer/nagios/__init__.py', 'vitrage/tests/unit/synchronizer/static_plugin/__init__.py', 'vitrage/tests/unit/entity_graph/base.py', 'vitrage/entity_graph/states/state_manager.py', 'vitrage/tests/resources/states_plugins/erroneous_states_plugins/nagios.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/337ccbdb93f03a881588b42b7c783d14e76c754a', 'message': 'state normalization fixes\n\nChange-Id: I9c0ae7551b9bf2aeb0f3f7ff571564b916b44d5f\n'}]",0,289176,337ccbdb93f03a881588b42b7c783d14e76c754a,10,4,2,19122,,,0,"state normalization fixes

Change-Id: I9c0ae7551b9bf2aeb0f3f7ff571564b916b44d5f
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/76/289176/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/tests/resources/states_plugins/erroneous_states_plugins/nova.host.yaml', 'vitrage/tests/unit/entity_graph/test_state_manager.py', 'vitrage/tests/resources/states_plugins/erroneous_states_plugins/nova.instance.yaml', 'vitrage/tests/unit/synchronizer/transformers/test_transformer_manager.py', 'vitrage/entity_graph/processor/processor.py', 'etc/vitrage/states_plugins/switch.yaml', 'vitrage/tests/unit/synchronizer/nova/__init__.py', 'vitrage/tests/unit/synchronizer/nagios/__init__.py', 'vitrage/tests/unit/synchronizer/static_plugin/__init__.py', 'vitrage/tests/unit/entity_graph/base.py', 'vitrage/entity_graph/states/state_manager.py', 'vitrage/tests/resources/states_plugins/erroneous_states_plugins/nagios.yaml']",12,7ed5ac32996b7cc5fd43d09c00e0ac1f7a2a9a30,bp/state-normalization-support,category: ALARM states: - normalized state: name: CRITICAL priority: 50 original states: - name: CRITITCAL - name: DOWN - normalized state: name: SEVER priority: 40 original states: - normalized state: name: WARNING priority: 30 original states: - name: WARNING - normalized state: name: UNKNOWN priority: 20 original states: - name: UNKNOWN - normalized state: name: DISABLED priority: 10 original states: - name: OK - name: UP ,,265,56
openstack%2Foperations-guide~master~I7413f07c53518bcea8fbf9c12d10f2f79b2ff795,openstack/operations-guide,master,I7413f07c53518bcea8fbf9c12d10f2f79b2ff795,Imported Translations from Zanata,MERGED,2016-03-07 06:36:48.000000000,2016-03-07 07:41:26.000000000,2016-03-07 07:41:26.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 06:36:48.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/cfd62c2cd0620e39bb0b8a8680ae73eece45e4fb', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I7413f07c53518bcea8fbf9c12d10f2f79b2ff795\n'}]",0,289171,cfd62c2cd0620e39bb0b8a8680ae73eece45e4fb,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I7413f07c53518bcea8fbf9c12d10f2f79b2ff795
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/71/289171/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po']",2,cfd62c2cd0620e39bb0b8a8680ae73eece45e4fb,zanata/translations,"""POT-Creation-Date: 2016-03-03 21:41+0000\n""""PO-Revision-Date: 2016-03-07 04:44+0000\n""msgid ""Create context"" msgstr ""コンテキストの作成"" msgid ""Generate signature of image and convert it to a base64 representation:"" msgstr ""イメージの署名を生成して、base64 形式に変換します。"" msgid ""Operate with consistency groups"" msgstr ""一貫性グループの操作"" msgid ""Signature hash method = SHA-256"" msgstr ""署名のハッシュ方法 = SHA-256"" msgid ""Signature hash methods: SHA-224, SHA-256, SHA-384, and SHA-512"" msgstr ""署名のハッシュ方法: SHA-224、SHA-256、SHA-384、SHA-512"" msgid ""Signature key type = RSA-PSS"" msgstr ""署名の鍵形式 = RSA-PSS"" msgid """" ""Signature key types: DSA, ECC_SECT571K1, ECC_SECT409K1, ECC_SECT571R1, "" ""ECC_SECT409R1, ECC_SECP521R1, ECC_SECP384R1, and RSA-PSS"" msgstr """" ""署名の鍵形式: DSA、ECC_SECT571K1、ECC_SECT409K1、ECC_SECT571R1、"" ""ECC_SECT409R1、ECC_SECP521R1、ECC_SECP384R1、RSA-PSS"" ""The following implicit values are being used to create the signature in this "" ""example: <placeholder-1/>"" msgstr """" ""以下の暗黙的な値が、この例において署名を作成するために使用されます。 "" ""<placeholder-1/>"" msgid ""The following options are currently supported: <placeholder-1/>"" msgstr ""以下のオプションが現在サポートされます。 <placeholder-1/>"" msgid """"""The maximum port number in the range that is matched by the security group "" ""rule. The <literal>port_range_min</literal> attribute constrains the "" ""<literal>port_range_max</literal> attribute. If the protocol is ICMP or "" ""ICMPv6, this value must be an ICMP or ICMPv6 type, respectively."" msgstr """" ""セキュリティグループルールに一致する、ポート番号の範囲の最大値。"" ""<literal>port_range_min</literal> 属性が <literal>port_range_max</literal> 属"" ""性を制限します。プロトコルが ICMP または ICMPv6 の場合、この値はそれぞれ "" ""ICMP コードまたは ICMPv6 コードでなければいけません。"" msgid """"msgid ""Use private key to create a signature of the image"" msgstr ""秘密鍵を使用したイメージ署名の作成"" msgid """" ""or the <link xlink:href=\""http://docs.openstack.org/cli-reference/glance.html"" ""\"">Command-Line Interface Reference </link>."" msgstr """" ""または <link xlink:href=\""http://docs.openstack.org/cli-reference/glance.html"" ""\"">Command-Line Interface Reference </link>。"" ","""POT-Creation-Date: 2016-02-16 22:13+0000\n""""PO-Revision-Date: 2016-02-21 12:46+0000\n""msgid """" ""StackTach is a tool created by Rackspace to collect and report the "" ""notifications sent by <code>nova</code>. Notifications are essentially the "" ""same as logs but can be much more detailed. A good overview of notifications "" ""can be found at <link xlink:href=\""https://wiki.openstack.org/wiki/"" ""SystemUsageData\"" xlink:title=\""System Usage Data\"">System Usage Data</link>."" ""<indexterm class=\""singular\""><primary>StackTach</primary></"" ""indexterm><indexterm class=\""singular\""><primary>logging/monitoring</"" ""primary><secondary>StackTack tool</secondary></indexterm>"" msgstr """" ""StackTachはRackspaceによって作られたツールで、<code>nova</code>から送られた通"" ""知を収集してレポートします。通知は本質的にはログと同じですが、より詳細な情報"" ""を持ちます。通知の概要のよい資料は、<link xlink:href=\""https://wiki."" ""openstack.org/wiki/SystemUsageData\"" xlink:title=\""System Usage Data"" ""\"">System Usage Data</link> にあります。<indexterm class=\""singular"" ""\""><primary>StackTach</primary></indexterm><indexterm class=\""singular"" ""\""><primary>logging/monitoring</primary><secondary>StackTack tool</"" ""secondary></indexterm>"" ",136,67
openstack%2Fsecurity-doc~master~I9bdca368b171c63235ef7782add18415fe24183b,openstack/security-doc,master,I9bdca368b171c63235ef7782add18415fe24183b,Imported Translations from Zanata,MERGED,2016-03-07 06:30:24.000000000,2016-03-07 07:41:04.000000000,2016-03-07 07:41:04.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 06:30:24.000000000', 'files': ['security-guide/source/locale/security-guide.pot', 'security-guide/source/locale/ja/LC_MESSAGES/security-guide.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/2d4b225dc1e6baad06bc7259d5e3fb4c0930ab62', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I9bdca368b171c63235ef7782add18415fe24183b\n'}]",0,289169,2d4b225dc1e6baad06bc7259d5e3fb4c0930ab62,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I9bdca368b171c63235ef7782add18415fe24183b
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/69/289169/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/source/locale/security-guide.pot', 'security-guide/source/locale/ja/LC_MESSAGES/security-guide.po']",2,2d4b225dc1e6baad06bc7259d5e3fb4c0930ab62,zanata/translations,"""POT-Creation-Date: 2016-03-05 13:15+0000\n""""PO-Revision-Date: 2016-03-07 04:38+0000\n""msgid ""Check-Block-05: Does cinder communicate with nova over TLS?""msgid ""Check-Block-06: Does cinder communicate with glance over TLS?""""The Apache Software Foundation, Welcome to Apache Hadoop!. 2016. `Apache "" ""Hadoop project <https://hadoop.apache.org>`__"" msgstr """" ""The Apache Software Foundation, Welcome to Apache Hadoop!. 2016. `Apache "" ""Hadoop project <https://hadoop.apache.org>`__"" msgid """"","""POT-Creation-Date: 2016-02-23 18:19+0000\n""""PO-Revision-Date: 2016-02-26 06:06+0000\n""msgid ""Check-Block-05: Does cinder communicates with nova over TLS?""msgid ""Check-Block-06: Does cinder communicates with glance over TLS?""msgid ""Check-Compute-05: Does Nova communicates with Glance securely?"" msgstr ""Check-Compute-05: Nova が Glance とセキュアに通信していますか?"" ",47,36
openstack%2Fvitrage~master~I163ea7a2506462d60d644bd26825055072484db8,openstack/vitrage,master,I163ea7a2506462d60d644bd26825055072484db8,fix path of vitrage dir creation,MERGED,2016-03-07 06:35:16.000000000,2016-03-07 07:40:24.000000000,2016-03-07 07:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 19122}, {'_account_id': 19134}, {'_account_id': 19159}]","[{'number': 1, 'created': '2016-03-07 06:35:16.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/54e3b084338e388b6800a927bf5e10442d4eb1a2', 'message': 'fix path of vitrage dir creation\n\nChange-Id: I163ea7a2506462d60d644bd26825055072484db8\n'}]",0,289170,54e3b084338e388b6800a927bf5e10442d4eb1a2,8,4,1,19134,,,0,"fix path of vitrage dir creation

Change-Id: I163ea7a2506462d60d644bd26825055072484db8
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/70/289170/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,54e3b084338e388b6800a927bf5e10442d4eb1a2,devstack, mkdir -p $VITRAGE_CONF_DIR/states_plugins mkdir -p $VITRAGE_CONF_DIR/static_plugins mkdir -p $VITRAGE_CONF_DIR/templates, mkdir -p /etc/states_plugins mkdir -p /etc/static_plugins mkdir -p /etc/templates,3,3
openstack%2Ftraining-guides~master~I1be590b9b35fd0eab0bf79e89011a638579d262f,openstack/training-guides,master,I1be590b9b35fd0eab0bf79e89011a638579d262f,Imported Translations from Zanata,MERGED,2016-03-07 06:18:05.000000000,2016-03-07 07:39:51.000000000,2016-03-07 07:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-07 06:18:05.000000000', 'files': ['doc/upstream-training/source/locale/ja/LC_MESSAGES/upstream-training.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d6e1b290113938b3d1841ce32e2c6cc1730f475a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1be590b9b35fd0eab0bf79e89011a638579d262f\n'}]",0,289163,d6e1b290113938b3d1841ce32e2c6cc1730f475a,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1be590b9b35fd0eab0bf79e89011a638579d262f
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/63/289163/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/locale/ja/LC_MESSAGES/upstream-training.po'],1,d6e1b290113938b3d1841ce32e2c6cc1730f475a,zanata/translations,"""PO-Revision-Date: 2016-03-07 04:32+0000\n""msgid """" ""A big thank you to everyone that has made this possible, especially Loic "" ""Dachary, Stefano Maffulli, and Tim Freund who lead the trainings."" msgstr """" ""私たちは、このイベントを実現させたすべての方々、とくにトレーニングをリードし"" ""た Loic Dachary、Stefano Maffulli、Tim Freund に感謝しています。"" msgid ""Loic Dachary (training, mentoring, assistant, french, english) - lead"" msgstr ""Loic Dachary (training, mentoring, assistant, french, english) - lead"" ""We held the first OpenStack Upstream Training in Atlanta, before OpenStack "" ""Summit Atlanta 2014. Since Atlanta, we have held the training before every "" ""OpenStack Summit. Besides this \""official\"" event, some user groups hold the "" ""local Upstream trainings."" msgstr """" ""はじめての OpenStack Upstream Training は、OpenStack Summit Atlanta 2014 の直"" ""前にアトランタで開催されました。アトランタ以降、毎回 OpenStack Summit の直前"" ""にトレーニングを開催してきました。この「公式」イベントに加えて、いくつかの"" ""ユーザーグループは、ローカルなアップストリームトレーニングを開催しています。"" msgid """"","""PO-Revision-Date: 2016-02-27 06:31+0000\n""",22,1
openstack%2Fpuppet-nova~master~I5e9566afd52f0f793924cd5b3a81679057023c86,openstack/puppet-nova,master,I5e9566afd52f0f793924cd5b3a81679057023c86,Add warning for deprecated network_device_mtu,ABANDONED,2016-01-17 15:50:13.000000000,2016-03-07 07:36:32.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}]","[{'number': 1, 'created': '2016-01-17 15:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/27d9050c2a7b529e4ed016590918d28726694a51', 'message': 'Add warning for deprecated network_device_mtu\n\nnetwork_device_mtu option is deprecated in Liberty. This value should\nbe set when creating the network.\n\nCloses-Bug: #1535095\n\nChange-Id: I5e9566afd52f0f793924cd5b3a81679057023c86\n'}, {'number': 2, 'created': '2016-01-19 07:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5a89f4dccf4cea35b5f5c3045bd1cb647cfab031', 'message': 'Add warning for deprecated network_device_mtu\n\nnetwork_device_mtu option is deprecated in Liberty. This value should\nbe set when creating the network.\n\nCloses-Bug: #1535095\n\nChange-Id: I5e9566afd52f0f793924cd5b3a81679057023c86\n'}, {'number': 3, 'created': '2016-01-22 05:25:56.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/2c1ae7bf92c84fba91adb73029e5529e1c3471dc', 'message': 'Add warning for deprecated network_device_mtu\n\nnetwork_device_mtu option is deprecated in Liberty. This value should\nbe set when creating the network.\n\nCloses-Bug: #1535095\n\nChange-Id: I5e9566afd52f0f793924cd5b3a81679057023c86\n'}]",3,268783,2c1ae7bf92c84fba91adb73029e5529e1c3471dc,15,3,3,19303,,,0,"Add warning for deprecated network_device_mtu

network_device_mtu option is deprecated in Liberty. This value should
be set when creating the network.

Closes-Bug: #1535095

Change-Id: I5e9566afd52f0f793924cd5b3a81679057023c86
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/83/268783/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/compute.pp'],1,27d9050c2a7b529e4ed016590918d28726694a51,bug/1535095,"# (optional) DEPRECATED. This value should be set when creating the network. # MTU setting for network interface. warning('network_device_mtu is deprecated, this value should be set when creating the network.')",# (optional) The MTU size for the interfaces managed by nova,3,1
openstack%2Fopenstack-manuals~master~I0b1004313bd45bf63778d82b8c84438dba1bb2fa,openstack/openstack-manuals,master,I0b1004313bd45bf63778d82b8c84438dba1bb2fa,[glossary] update core and optional service definition,MERGED,2016-03-07 01:52:08.000000000,2016-03-07 07:25:31.000000000,2016-03-07 07:25:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 01:52:08.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/27b63222c0baad93470dc890c067964f63b74c6e', 'message': '[glossary] update core and optional service definition\n\nTo reflect the current DefCore definition.\n\nChange-Id: I0b1004313bd45bf63778d82b8c84438dba1bb2fa\n'}]",0,289109,27b63222c0baad93470dc890c067964f63b74c6e,7,3,1,10497,,,0,"[glossary] update core and optional service definition

To reflect the current DefCore definition.

Change-Id: I0b1004313bd45bf63778d82b8c84438dba1bb2fa
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/09/289109/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,27b63222c0baad93470dc890c067964f63b74c6e,core-services," <glossterm>core service</glossterm> <primary>core service</primary> <para>An official OpenStack service defined as core by DefCore Committee. Currently, consists of Block Storage service (cinder), Compute service (nova), Identity service (keystone), Image service (glance), Networking service (neutron), and Object Storage service (swift). <glossterm>optional service</glossterm> <indexterm class=""singular""> <primary>optional service</primary> </indexterm> <glossdef> <para>An official OpenStack service defined as optional by DefCore Committee. Currently, consists of Dashboard (horizon), Telemetry service (Telemetry), Orchestration service (heat), Database service (trove), Bare Metal service (ironic), and so on. </para> </glossdef> </glossentry> <glossentry>"," <glossterm>core project</glossterm> <primary>core project</primary> <para>An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"".",23,10
openstack%2Fproject-config~master~Iec0bb7ae930560d6617b58859c38cde0ab11eeb9,openstack/project-config,master,Iec0bb7ae930560d6617b58859c38cde0ab11eeb9,"Set tags-only docs publishing for client jobs, not server jobs",MERGED,2016-03-04 18:55:53.000000000,2016-03-07 07:22:35.000000000,2016-03-07 07:22:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-04 18:55:53.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/aff81947dba6b9e862073200cef995b95f1a883e', 'message': 'Set tags-only docs publishing for client jobs, not server jobs\n\nRecently https://review.openstack.org/279238 merged, resulting in\ndocs for server/service repositories being published in a way that\nsuits the library/client repo publishing process (ie only the\nlatest tag is published).\n\nThis approach was meant to be implemented for the *client* jobs,\nnot the *server* jobs.\n\nThis patch corrects the behaviour to match the intent.\n\nChange-Id: Iec0bb7ae930560d6617b58859c38cde0ab11eeb9\n'}]",0,288644,aff81947dba6b9e862073200cef995b95f1a883e,7,3,1,6816,,,0,"Set tags-only docs publishing for client jobs, not server jobs

Recently https://review.openstack.org/279238 merged, resulting in
docs for server/service repositories being published in a way that
suits the library/client repo publishing process (ie only the
latest tag is published).

This approach was meant to be implemented for the *client* jobs,
not the *server* jobs.

This patch corrects the behaviour to match the intent.

Change-Id: Iec0bb7ae930560d6617b58859c38cde0ab11eeb9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/288644/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,aff81947dba6b9e862073200cef995b95f1a883e,docs-publishing-bug, - '{name}-docs' - '{name}-docs-tags-only', - '{name}-docs-tags-only' - '{name}-docs',2,2
openstack%2Fdragonflow~master~Idaa183bfc6c2358bc12a1df0220a5b2dea32ea0f,openstack/dragonflow,master,Idaa183bfc6c2358bc12a1df0220a5b2dea32ea0f,Add kazoo requirements for zookeeper,MERGED,2016-02-25 08:50:07.000000000,2016-03-07 07:18:54.000000000,2016-03-07 07:18:53.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 13070}]","[{'number': 1, 'created': '2016-02-25 08:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/86b8f1cffb9e99c213c82e6fc8fbec76ff6c7024', 'message': 'Add kazoo requirements for zookeeper\n\nChange-Id: Idaa183bfc6c2358bc12a1df0220a5b2dea32ea0f\n'}, {'number': 2, 'created': '2016-02-25 09:28:03.000000000', 'files': ['requirements.txt', 'devstack/zookeeper_driver'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d6f25092346cbc9a9eb616295a6c8338770dc64a', 'message': 'Add kazoo requirements for zookeeper\n\nThe kazoo library is in the openstack/requirements.\n\nChange-Id: Idaa183bfc6c2358bc12a1df0220a5b2dea32ea0f\n'}]",0,284594,d6f25092346cbc9a9eb616295a6c8338770dc64a,13,4,2,7805,,,0,"Add kazoo requirements for zookeeper

The kazoo library is in the openstack/requirements.

Change-Id: Idaa183bfc6c2358bc12a1df0220a5b2dea32ea0f
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/94/284594/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,86b8f1cffb9e99c213c82e6fc8fbec76ff6c7024,zookeeper-requirement,kazoo>=2.2 # Apache-2.0,,1,0
openstack%2Fsahara-dashboard~master~Ib529ce74da27243aab78bce72d57b2438c118478,openstack/sahara-dashboard,master,Ib529ce74da27243aab78bce72d57b2438c118478,Imported Translations from Zanata,MERGED,2016-03-07 06:04:40.000000000,2016-03-07 07:18:10.000000000,2016-03-07 07:18:09.000000000,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2016-03-07 06:04:40.000000000', 'files': ['sahara_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'sahara_dashboard/locale/ja/LC_MESSAGES/django.po', 'sahara_dashboard/locale/ja/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/53d7ea49bd7fb6484496578131667e7e59a63681', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ib529ce74da27243aab78bce72d57b2438c118478\n'}]",0,289159,53d7ea49bd7fb6484496578131667e7e59a63681,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ib529ce74da27243aab78bce72d57b2438c118478
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/59/289159/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'sahara_dashboard/locale/ja/LC_MESSAGES/django.po', 'sahara_dashboard/locale/ja/LC_MESSAGES/djangojs.po']",3,53d7ea49bd7fb6484496578131667e7e59a63681,zanata/translations,"""POT-Creation-Date: 2016-03-02 21:13+0000\n""""PO-Revision-Date: 2016-03-07 02:19+0000\n"" msgid ""Verification is not available."" msgstr ""検証機能が利用できません。""","""POT-Creation-Date: 2016-02-18 14:31+0000\n""""PO-Revision-Date: 2016-02-18 06:59+0000\n""",149,3
openstack%2Fha-guide~master~I353a737b89c62a53034bcb7883d1e12b7c44b036,openstack/ha-guide,master,I353a737b89c62a53034bcb7883d1e12b7c44b036,Imported Translations from Zanata,MERGED,2016-03-07 06:00:34.000000000,2016-03-07 07:04:23.000000000,2016-03-07 07:04:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-07 06:00:34.000000000', 'files': ['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/locale/ha-guide.pot'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/989d731dbac04c8dbde16bcbe08f2d7342e5b29b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I353a737b89c62a53034bcb7883d1e12b7c44b036\n'}]",0,289153,989d731dbac04c8dbde16bcbe08f2d7342e5b29b,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I353a737b89c62a53034bcb7883d1e12b7c44b036
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/53/289153/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/locale/ha-guide.pot']",2,989d731dbac04c8dbde16bcbe08f2d7342e5b29b,zanata/translations,"""POT-Creation-Date: 2016-03-07 06:00+0000\n""#: ../controller-ha-haproxy.rst:40 ../controller-ha-pacemaker.rst:574#: ../controller-ha-haproxy.rst:48 ../controller-ha-pacemaker.rst:565#: ../controller-ha-pacemaker.rst:78#: ../controller-ha-pacemaker.rst:80#: ../controller-ha-pacemaker.rst:88#: ../controller-ha-pacemaker.rst:97#: ../controller-ha-pacemaker.rst:107#: ../controller-ha-pacemaker.rst:112#: ../controller-ha-pacemaker.rst:114#: ../controller-ha-pacemaker.rst:118#: ../controller-ha-pacemaker.rst:121#: ../controller-ha-pacemaker.rst:125#: ../controller-ha-pacemaker.rst:126#: ../controller-ha-pacemaker.rst:127#: ../controller-ha-pacemaker.rst:132#: ../controller-ha-pacemaker.rst:134#: ../controller-ha-pacemaker.rst:139#: ../controller-ha-pacemaker.rst:210 ../controller-ha-pacemaker.rst:342 #: ../controller-ha-pacemaker.rst:426 ../controller-ha-pacemaker.rst:583#: ../controller-ha-pacemaker.rst:212#: ../controller-ha-pacemaker.rst:228#: ../controller-ha-pacemaker.rst:234#: ../controller-ha-pacemaker.rst:239#: ../controller-ha-pacemaker.rst:241#: ../controller-ha-pacemaker.rst:244#: ../controller-ha-pacemaker.rst:247#: ../controller-ha-pacemaker.rst:255#: ../controller-ha-pacemaker.rst:260#: ../controller-ha-pacemaker.rst:266#: ../controller-ha-pacemaker.rst:277#: ../controller-ha-pacemaker.rst:288#: ../controller-ha-pacemaker.rst:295#: ../controller-ha-pacemaker.rst:297#: ../controller-ha-pacemaker.rst:302#: ../controller-ha-pacemaker.rst:344#: ../controller-ha-pacemaker.rst:348#: ../controller-ha-pacemaker.rst:357#: ../controller-ha-pacemaker.rst:367#: ../controller-ha-pacemaker.rst:370#: ../controller-ha-pacemaker.rst:372#: ../controller-ha-pacemaker.rst:375#: ../controller-ha-pacemaker.rst:388#: ../controller-ha-pacemaker.rst:390#: ../controller-ha-pacemaker.rst:396#: ../controller-ha-pacemaker.rst:398#: ../controller-ha-pacemaker.rst:400#: ../controller-ha-pacemaker.rst:402#: ../controller-ha-pacemaker.rst:404#: ../controller-ha-pacemaker.rst:406#: ../controller-ha-pacemaker.rst:409#: ../controller-ha-pacemaker.rst:413#: ../controller-ha-pacemaker.rst:428#: ../controller-ha-pacemaker.rst:431#: ../controller-ha-pacemaker.rst:436#: ../controller-ha-pacemaker.rst:442#: ../controller-ha-pacemaker.rst:457#: ../controller-ha-pacemaker.rst:469#: ../controller-ha-pacemaker.rst:471#: ../controller-ha-pacemaker.rst:476#: ../controller-ha-pacemaker.rst:477#: ../controller-ha-pacemaker.rst:478 msgid "":command:`# start corosync` (upstart)""#: ../controller-ha-pacemaker.rst:479 msgid "":command:`# systemctl start corosync` (systemd)""#: ../controller-ha-pacemaker.rst:481#: ../controller-ha-pacemaker.rst:483#: ../controller-ha-pacemaker.rst:498#: ../controller-ha-pacemaker.rst:511#: ../controller-ha-pacemaker.rst:514#: ../controller-ha-pacemaker.rst:519#: ../controller-ha-pacemaker.rst:525#: ../controller-ha-pacemaker.rst:527#: ../controller-ha-pacemaker.rst:531#: ../controller-ha-pacemaker.rst:533#: ../controller-ha-pacemaker.rst:535#: ../controller-ha-pacemaker.rst:537#: ../controller-ha-pacemaker.rst:539#: ../controller-ha-pacemaker.rst:560#: ../controller-ha-pacemaker.rst:562#: ../controller-ha-pacemaker.rst:585#: ../controller-ha-pacemaker.rst:591#: ../controller-ha-pacemaker.rst:597msgid """" ""Start the message queue service on all nodes and configure it to start when "" ""the system boots.""#: ../controller-ha-rabbitmq.rst:182 msgid ""On Ubuntu, it is configured by default."" msgstr """" #: ../controller-ha-rabbitmq.rst:184 msgid ""On CentOS, RHEL, openSUSE, and SLES:"" msgstr """" #: ../controller-ha-rabbitmq.rst:191 msgid ""Verify that the nodes are running:"" msgstr """" #: ../controller-ha-rabbitmq.rst:202#: ../controller-ha-rabbitmq.rst:216#: ../controller-ha-rabbitmq.rst:219#: ../controller-ha-rabbitmq.rst:228#: ../controller-ha-rabbitmq.rst:231#: ../controller-ha-rabbitmq.rst:240#: ../controller-ha-rabbitmq.rst:242#: ../controller-ha-rabbitmq.rst:243#: ../controller-ha-rabbitmq.rst:247#: ../controller-ha-rabbitmq.rst:256#: ../controller-ha-rabbitmq.rst:258#: ../controller-ha-rabbitmq.rst:261#: ../controller-ha-rabbitmq.rst:263#: ../controller-ha-rabbitmq.rst:269#: ../controller-ha-rabbitmq.rst:276#: ../controller-ha-rabbitmq.rst:283#: ../controller-ha-rabbitmq.rst:289#: ../controller-ha-rabbitmq.rst:295#: ../controller-ha-rabbitmq.rst:303","""POT-Creation-Date: 2016-02-23 06:00+0000\n""#: ../controller-ha-haproxy.rst:40 ../controller-ha-pacemaker.rst:564#: ../controller-ha-haproxy.rst:48 ../controller-ha-pacemaker.rst:555#: ../controller-ha-pacemaker.rst:73 msgid "":command:`systemctl enable pcsd`"" msgstr """" #: ../controller-ha-pacemaker.rst:74 msgid "":command:`systemctl start pcsd`"" msgstr """" #: ../controller-ha-pacemaker.rst:76#: ../controller-ha-pacemaker.rst:78#: ../controller-ha-pacemaker.rst:81 msgid """" "":command:`echo my-secret-password-no-dont-use-this-one | passwd --stdin "" ""hacluster`"" msgstr """" #: ../controller-ha-pacemaker.rst:84#: ../controller-ha-pacemaker.rst:88 msgid """" "":command:`pcs cluster auth controller1 controller2 controller3 -u hacluster -"" ""p my-secret-password-no-dont-use-this-one --force`"" msgstr """" #: ../controller-ha-pacemaker.rst:91#: ../controller-ha-pacemaker.rst:93 msgid """" "":command:`pcs cluster setup --force --name my-first-openstack-cluster "" ""controller1 controller2 controller3`"" msgstr """" #: ../controller-ha-pacemaker.rst:95 msgid "":command:`pcs cluster start --all`"" msgstr """" #: ../controller-ha-pacemaker.rst:99#: ../controller-ha-pacemaker.rst:104#: ../controller-ha-pacemaker.rst:106#: ../controller-ha-pacemaker.rst:110#: ../controller-ha-pacemaker.rst:113#: ../controller-ha-pacemaker.rst:117#: ../controller-ha-pacemaker.rst:118#: ../controller-ha-pacemaker.rst:119#: ../controller-ha-pacemaker.rst:124#: ../controller-ha-pacemaker.rst:126#: ../controller-ha-pacemaker.rst:131#: ../controller-ha-pacemaker.rst:202 ../controller-ha-pacemaker.rst:329 #: ../controller-ha-pacemaker.rst:413 ../controller-ha-pacemaker.rst:573#: ../controller-ha-pacemaker.rst:204#: ../controller-ha-pacemaker.rst:220#: ../controller-ha-pacemaker.rst:226#: ../controller-ha-pacemaker.rst:231#: ../controller-ha-pacemaker.rst:233#: ../controller-ha-pacemaker.rst:236#: ../controller-ha-pacemaker.rst:239#: ../controller-ha-pacemaker.rst:247#: ../controller-ha-pacemaker.rst:252#: ../controller-ha-pacemaker.rst:258#: ../controller-ha-pacemaker.rst:269#: ../controller-ha-pacemaker.rst:280#: ../controller-ha-pacemaker.rst:287#: ../controller-ha-pacemaker.rst:289#: ../controller-ha-pacemaker.rst:294#: ../controller-ha-pacemaker.rst:331#: ../controller-ha-pacemaker.rst:335#: ../controller-ha-pacemaker.rst:344#: ../controller-ha-pacemaker.rst:354#: ../controller-ha-pacemaker.rst:357#: ../controller-ha-pacemaker.rst:359#: ../controller-ha-pacemaker.rst:362#: ../controller-ha-pacemaker.rst:375#: ../controller-ha-pacemaker.rst:377#: ../controller-ha-pacemaker.rst:383#: ../controller-ha-pacemaker.rst:385#: ../controller-ha-pacemaker.rst:387#: ../controller-ha-pacemaker.rst:389#: ../controller-ha-pacemaker.rst:391#: ../controller-ha-pacemaker.rst:393#: ../controller-ha-pacemaker.rst:396#: ../controller-ha-pacemaker.rst:400#: ../controller-ha-pacemaker.rst:415#: ../controller-ha-pacemaker.rst:418#: ../controller-ha-pacemaker.rst:423#: ../controller-ha-pacemaker.rst:429#: ../controller-ha-pacemaker.rst:444#: ../controller-ha-pacemaker.rst:456#: ../controller-ha-pacemaker.rst:458#: ../controller-ha-pacemaker.rst:463#: ../controller-ha-pacemaker.rst:465#: ../controller-ha-pacemaker.rst:467 msgid "":command:`# start corosync (upstart)`""#: ../controller-ha-pacemaker.rst:469 msgid "":command:`# systemctl start corosync (systemd)`""#: ../controller-ha-pacemaker.rst:471#: ../controller-ha-pacemaker.rst:473#: ../controller-ha-pacemaker.rst:488#: ../controller-ha-pacemaker.rst:501#: ../controller-ha-pacemaker.rst:504#: ../controller-ha-pacemaker.rst:509#: ../controller-ha-pacemaker.rst:515#: ../controller-ha-pacemaker.rst:517#: ../controller-ha-pacemaker.rst:521#: ../controller-ha-pacemaker.rst:523#: ../controller-ha-pacemaker.rst:525#: ../controller-ha-pacemaker.rst:527#: ../controller-ha-pacemaker.rst:529#: ../controller-ha-pacemaker.rst:550#: ../controller-ha-pacemaker.rst:552#: ../controller-ha-pacemaker.rst:575#: ../controller-ha-pacemaker.rst:581#: ../controller-ha-pacemaker.rst:587msgid ""Start RabbitMQ on all nodes and verify that the nodes are running:""#: ../controller-ha-rabbitmq.rst:190#: ../controller-ha-rabbitmq.rst:204#: ../controller-ha-rabbitmq.rst:207#: ../controller-ha-rabbitmq.rst:216#: ../controller-ha-rabbitmq.rst:219#: ../controller-ha-rabbitmq.rst:228#: ../controller-ha-rabbitmq.rst:230#: ../controller-ha-rabbitmq.rst:231#: ../controller-ha-rabbitmq.rst:235#: ../controller-ha-rabbitmq.rst:244#: ../controller-ha-rabbitmq.rst:246#: ../controller-ha-rabbitmq.rst:249#: ../controller-ha-rabbitmq.rst:251#: ../controller-ha-rabbitmq.rst:257#: ../controller-ha-rabbitmq.rst:264#: ../controller-ha-rabbitmq.rst:271#: ../controller-ha-rabbitmq.rst:277#: ../controller-ha-rabbitmq.rst:283#: ../controller-ha-rabbitmq.rst:291",200,174
openstack%2Fnova~master~Ib432fddc9b31fb6f906f6828d52098c9dd059aa2,openstack/nova,master,Ib432fddc9b31fb6f906f6828d52098c9dd059aa2,Dump metric exception text to logs,MERGED,2016-03-04 21:24:45.000000000,2016-03-07 07:00:25.000000000,2016-03-07 07:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7664}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 18777}]","[{'number': 1, 'created': '2016-03-04 21:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b700c349b7519a051c833a2194060bc3228c4d48', 'message': ""Dump metric exception text to logs\n\nThis patch simply adds the exception text to the logs so that we don't\nlose the troubleshooting data. Without this patch, it's much more\ndifficult to troubleshoot when something goes wrong as the root\nexception text is garbled up and lost.\n\nChange-Id: Ib432fddc9b31fb6f906f6828d52098c9dd059aa2\nCloses-Bug: 1553319\n""}, {'number': 2, 'created': '2016-03-06 04:31:07.000000000', 'files': ['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aef7a3dab112690e5172d137decb93dc28056471', 'message': ""Dump metric exception text to logs\n\nThis patch simply adds the exception text to the logs so that we don't\nlose the troubleshooting data. Without this patch, it's much more\ndifficult to troubleshoot when something goes wrong as the root\nexception text is garbled up and lost.\n\nChange-Id: Ib432fddc9b31fb6f906f6828d52098c9dd059aa2\nCloses-Bug: 1553319\n""}]",0,288750,aef7a3dab112690e5172d137decb93dc28056471,42,15,2,7664,,,0,"Dump metric exception text to logs

This patch simply adds the exception text to the logs so that we don't
lose the troubleshooting data. Without this patch, it's much more
difficult to troubleshoot when something goes wrong as the root
exception text is garbled up and lost.

Change-Id: Ib432fddc9b31fb6f906f6828d52098c9dd059aa2
Closes-Bug: 1553319
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/288750/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/resource_tracker.py'],1,b700c349b7519a051c833a2194060bc3228c4d48,bug/1553319," except Exception as exc: LOG.warning(_LW(""Cannot get the metrics from %(mon)s; "" ""error: %(exc)s""), {'mon': monitor, 'exc': exc})"," except Exception: LOG.warning(_LW(""Cannot get the metrics from %s.""), monitor)",4,2
openstack%2Ftripleo-image-elements~master~I24d1fe6707c6e8d060b146e0a64450d963e4bef3,openstack/tripleo-image-elements,master,I24d1fe6707c6e8d060b146e0a64450d963e4bef3,Add an element for cinder-backup,ABANDONED,2014-06-06 17:42:11.000000000,2016-03-07 06:48:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 7144}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-06-06 17:42:11.000000000', 'files': ['elements/cinder-backup/element-deps', 'elements/cinder-backup/README.md', 'elements/cinder-backup/os-refresh-config/post-configure.d/74-cinder-backup', 'elements/cinder-backup/install.d/cinder-source-install/74-cinder-backup'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a7d49eee59a88f9204e02269f24a85e8659b67a6', 'message': 'Add an element for cinder-backup\n\nBased on the cinder volume element\n\nChange-Id: I24d1fe6707c6e8d060b146e0a64450d963e4bef3\n'}]",10,98478,a7d49eee59a88f9204e02269f24a85e8659b67a6,17,4,1,1207,,,0,"Add an element for cinder-backup

Based on the cinder volume element

Change-Id: I24d1fe6707c6e8d060b146e0a64450d963e4bef3
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/78/98478/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/cinder-backup/element-deps', 'elements/cinder-backup/README.md', 'elements/cinder-backup/os-refresh-config/post-configure.d/74-cinder-backup', 'elements/cinder-backup/install.d/cinder-source-install/74-cinder-backup']",4,a7d49eee59a88f9204e02269f24a85e8659b67a6,cinder-backup-packaging,"#!/bin/bash set -eux os-svc-daemon -i ""$CINDER_VENV_DIR"" cinder-backup cinder cinder-backup ""--config-dir /etc/cinder"" ",,18,0
openstack%2Fmagnum-ui~master~Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c,openstack/magnum-ui,master,Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c,Add Create Bay action into BayModel item action,MERGED,2016-02-25 08:18:49.000000000,2016-03-07 06:27:29.000000000,2016-03-06 08:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-02-25 08:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/216fb6ea76410d1beb1263032b8b3091312f4ea8', 'message': '[WIP] Add Create Bay action into BayModel row-action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nrow-actions service for BayModel table.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}, {'number': 2, 'created': '2016-02-25 10:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/a9e56c55578b92d72a8891453bb38959c1dab2f3', 'message': '[WIP] Add Create Bay action into BayModel row-action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nrow-actions service for BayModel table.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}, {'number': 3, 'created': '2016-03-01 11:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/c5606719d892d65bf67e4c3e9bbad6561d1076f1', 'message': 'Add Create Bay action into BayModel row-action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nrow-actions service for BayModel table.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}, {'number': 4, 'created': '2016-03-03 05:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/a4ab40647393b867d5d37876a79985dbdf9d867d', 'message': 'Add Create Bay action into BayModel row-action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nrow-actions service for BayModel table.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}, {'number': 5, 'created': '2016-03-03 05:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/42d799b1dde19f6efc1203b2c61ae288790a6fb0', 'message': 'Add Create Bay action into BayModel item action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nitem actions for BayModel.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}, {'number': 6, 'created': '2016-03-03 11:00:02.000000000', 'files': ['magnum_ui/static/dashboard/containers/baymodels/table/table.controller.js', 'magnum_ui/static/dashboard/containers/bays/create/bay-model.js', 'magnum_ui/static/dashboard/containers/bays/create/info/bay.info.controller.js', 'magnum_ui/static/dashboard/containers/baymodels/actions.module.js', 'magnum_ui/static/dashboard/containers/bays/delete/delete.service.js', 'magnum_ui/static/dashboard/containers/baymodels/detail/detail.controller.js', 'magnum_ui/static/dashboard/containers/bays/create/create.service.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/144b3a93705e7f7db2b4cd563c6a730822a2c3b4', 'message': 'Add Create Bay action into BayModel item action\n\nTo be able to create Bay from BayModel table view and\ndetail view, this patch adds Create Bay action into\nitem actions for BayModel.\n\nAfter Bay creation, move to Bay table view.\n\nChange-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c\nImplements: blueprint create-child-resource\n'}]",0,284582,144b3a93705e7f7db2b4cd563c6a730822a2c3b4,20,5,6,16352,,,0,"Add Create Bay action into BayModel item action

To be able to create Bay from BayModel table view and
detail view, this patch adds Create Bay action into
item actions for BayModel.

After Bay creation, move to Bay table view.

Change-Id: Ib2f062f3a0994ebe0a68f31bcbf18a88672dc99c
Implements: blueprint create-child-resource
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/82/284582/6 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/containers/baymodels/table/row-actions.service.js', 'magnum_ui/static/dashboard/containers/bays/create/bay-model.js', 'magnum_ui/static/dashboard/containers/bays/create/info/bay.info.controller.js', 'magnum_ui/static/dashboard/containers/bays/create/create.service.js']",4,216fb6ea76410d1beb1263032b8b3091312f4ea8,bp/create-child-resource," 'horizon.dashboard.containers.bays.bayModel', function perform(selected) { scope.selected = selected; function allowed(selected) {"," 'bayModel', function perform() { function allowed() {",17,6
openstack%2Fnova~master~I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf,openstack/nova,master,I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf,Updated from global requirements,MERGED,2016-03-04 10:19:21.000000000,2016-03-07 06:25:16.000000000,2016-03-07 06:25:15.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16272}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 18777}]","[{'number': 1, 'created': '2016-03-04 10:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b2e32704d81bef986c4fc8197c5bbb1364479d8', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 2, 'created': '2016-03-04 14:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6553f37c9556afb68ba723713fd02f158ad882ac', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 3, 'created': '2016-03-04 14:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7aca3320d47cbbeb4df395ae6feac63cc0cdbed', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 4, 'created': '2016-03-04 17:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3d00923b60e2b51eea8a512b95e435af0ed7f83', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 5, 'created': '2016-03-04 22:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5a94c24fe9e9c36031db859c212dbfb668e708f', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 6, 'created': '2016-03-05 03:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fbb4f6ccaf5d10a38c1b142d847eb68a392f624', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 7, 'created': '2016-03-05 15:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2ce610141009baa78a65e7d6194fffcfd89cd03', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}, {'number': 8, 'created': '2016-03-05 20:48:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/a35bd323913de0d9564fdc2d47fa8472ba5deba1', 'message': 'Updated from global requirements\n\nChange-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf\n'}]",0,288357,a35bd323913de0d9564fdc2d47fa8472ba5deba1,87,16,8,11131,,,0,"Updated from global requirements

Change-Id: I7fc5fe2e1ba2f1f0e705f0b92984139e176f4daf
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/288357/8 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8b2e32704d81bef986c4fc8197c5bbb1364479d8,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Fsahara-dashboard~master~I89377ad9ab733a54e384a9b71f2c24595ba9c8cb,openstack/sahara-dashboard,master,I89377ad9ab733a54e384a9b71f2c24595ba9c8cb,implement auto refreshing health status in UI,MERGED,2016-03-04 11:03:26.000000000,2016-03-07 06:20:33.000000000,2016-03-07 06:20:33.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8090}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-04 11:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/4d69979b51df244bb4a455a91c38103d765fcdef', 'message': 'implement auto refreshing health status in UI\n\nthis implements auto refreshing of health status for clusters.\n\nChange-Id: I89377ad9ab733a54e384a9b71f2c24595ba9c8cb\n'}, {'number': 2, 'created': '2016-03-04 11:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/bc6c670a934de5ff02d28d2d405f587bd7cde6fd', 'message': 'implement auto refreshing health status in UI\n\nthis implements auto refreshing of health status for clusters.\n\nChange-Id: I89377ad9ab733a54e384a9b71f2c24595ba9c8cb\n'}, {'number': 3, 'created': '2016-03-04 17:51:14.000000000', 'files': ['sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_in_progress.html'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/2e3110aaadf5f2175fc6bde2df390526cf5258e4', 'message': 'implement auto refreshing health status in UI\n\nthis implements auto refreshing of health status for clusters.\n\nChange-Id: I89377ad9ab733a54e384a9b71f2c24595ba9c8cb\n'}]",0,288388,2e3110aaadf5f2175fc6bde2df390526cf5258e4,13,4,3,12038,,,0,"implement auto refreshing health status in UI

this implements auto refreshing of health status for clusters.

Change-Id: I89377ad9ab733a54e384a9b71f2c24595ba9c8cb
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/88/288388/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/clusters/clusters/tables.py', 'sahara_dashboard/content/data_processing/clusters/templates/clusters/_in_progress.html']",2,4d69979b51df244bb4a455a91c38103d765fcdef,auto-ref,"<div class=""horizon-pending-bar""> <div class=""progress progress-striped active""> <div class=""progress-bar"" style=""width: 100%""> {{ status }} </div> </div> </div> ",,22,9
openstack%2Fsahara-dashboard~master~I1f6bfc63d184cdc7006d7e377b22b8d1c9800749,openstack/sahara-dashboard,master,I1f6bfc63d184cdc7006d7e377b22b8d1c9800749,Fix job execution on a new cluster,MERGED,2016-03-03 10:16:48.000000000,2016-03-07 06:20:09.000000000,2016-03-07 06:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8090}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-03 10:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/3f7aac9c667d05ba69986f143a1ece2d8ed356dd', 'message': 'Fix job execution of a new cluster\n\nFollowing issues were repaired:\n\n1. wrong path was fixed to template;\n2. js code was replaced to index.html;\n3. is_public / is_protected fields moved to base class.\n\nChange-Id: I1f6bfc63d184cdc7006d7e377b22b8d1c9800749\nCloses-bug: 1550361\n'}, {'number': 2, 'created': '2016-03-03 11:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/bdf6e4ded1102570a63f46c4b1b1e95a7967dee3', 'message': 'Fix job execution on a new cluster\n\nFollowing issues were repaired:\n\n1. wrong path was fixed to template;\n2. js code was replaced to index.html;\n3. is_public / is_protected fields moved to base class.\n\nChange-Id: I1f6bfc63d184cdc7006d7e377b22b8d1c9800749\nCloses-bug: 1550361\n'}, {'number': 3, 'created': '2016-03-04 12:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/33575e148a599b73d1fd87341559b18080879e21', 'message': 'Fix job execution on a new cluster\n\nFollowing issues were repaired:\n\n1. wrong path was fixed to template;\n2. js code was replaced to index.html;\n3. is_public / is_protected fields moved to base class.\n\nChange-Id: I1f6bfc63d184cdc7006d7e377b22b8d1c9800749\nCloses-bug: 1550361\n'}, {'number': 4, 'created': '2016-03-04 14:12:36.000000000', 'files': ['sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/index.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/jobs.html'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/827795effe35fd559c34ad0b26c069443d65b09d', 'message': 'Fix job execution on a new cluster\n\nFollowing issues were repaired:\n\n1. wrong path was fixed to template;\n2. js code was replaced to index.html;\n3. is_public / is_protected fields moved to base class.\n\nChange-Id: I1f6bfc63d184cdc7006d7e377b22b8d1c9800749\nCloses-bug: 1550361\n'}]",1,287688,827795effe35fd559c34ad0b26c069443d65b09d,18,4,4,12038,,,0,"Fix job execution on a new cluster

Following issues were repaired:

1. wrong path was fixed to template;
2. js code was replaced to index.html;
3. is_public / is_protected fields moved to base class.

Change-Id: I1f6bfc63d184cdc7006d7e377b22b8d1c9800749
Closes-bug: 1550361
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/88/287688/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/index.html', 'sahara_dashboard/content/data_processing/jobs/templates/jobs/job_executions.html', 'sahara_dashboard/content/data_processing/jobs/templates/job_templates/jobs.html']",4,3f7aac9c667d05ba69986f143a1ece2d8ed356dd,bug/1550361,," <script type=""text/javascript""> addHorizonLoadEvent(function () { horizon.modals.addModalInitFunction(function (modal) { var $navbar = $(modal).find("".nav-tabs""); if ($navbar.find(""li"").size() == 1) { // hide tab bar for plugin/version modal wizard $navbar.hide(); } lower_limit = 0; $("".count-field"").change(); if ($(modal).find("".hidden_create_field"").length > 0) { var form = $("".hidden_create_field"").closest(""form""); var successful = false; form.submit(function (e) { var oldHref = $("".create_job_class"")[0].href; var plugin = $(""#id_plugin_name option:selected"").val(); var version = $(""#id_"" + plugin + ""_version option:selected"").val(); var job_id = $(""#id_job_id"").val(); form.find("".close"").click(); $("".create_job_class"")[0].href = ""launch-job-new-cluster?"" + ""plugin_name="" + encodeURIComponent(plugin) + ""&hadoop_version="" + encodeURIComponent(version) + ""&job_id="" + encodeURIComponent(job_id); $("".create_job_class"").click(); $("".create_job_class"")[0].href = oldHref; return false; }); $("".plugin_version_choice"").closest("".form-group"").hide(); } //display version for selected plugin $(document).on('change', '.plugin_name_choice', switch_versions); function switch_versions() { $("".plugin_version_choice"").closest("".form-group"").hide(); var plugin = $(this); $(""."" + plugin.val() + ""_version_choice"").closest("".form-group"").show(); } $("".plugin_name_choice"").change(); }); }); addExtraBinary = function (where_from) { var loc_type = where_from.previousSibling.name.contains(""main"") ? ""main"" : ""lib""; for(i=2; i <= $(""[name=extra_locations]"").val(); i++) { if (!$(""[name=job_"" + loc_type + ""_"" + i + ""]"").closest("".form-group"").is("":visible"")) { $(""[name=job_"" + loc_type + ""_"" + i + ""]"").closest("".form-group"").show(); break; } } }; </script> ",58,57
openstack%2Fdiskimage-builder~master~I51e7961fab7f3eeaf3ce4eeb1dd5e6981eefb154,openstack/diskimage-builder,master,I51e7961fab7f3eeaf3ce4eeb1dd5e6981eefb154,Fix spurious = in dib-python readme,MERGED,2016-03-02 05:38:17.000000000,2016-03-07 06:18:55.000000000,2016-03-07 04:59:22.000000000,"[{'_account_id': 3}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-02 05:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a5d16584de45fce9689874eb2816f2ac2ecf113a', 'message': 'Fix spurios = in dib-python readme\n\nChange-Id: I51e7961fab7f3eeaf3ce4eeb1dd5e6981eefb154\n'}, {'number': 2, 'created': '2016-03-07 04:47:56.000000000', 'files': ['elements/dib-python/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fbabe0b663e79bb352666c5d6a81d1571697c316', 'message': 'Fix spurious = in dib-python readme\n\nChange-Id: I51e7961fab7f3eeaf3ce4eeb1dd5e6981eefb154\n'}]",0,286991,fbabe0b663e79bb352666c5d6a81d1571697c316,10,2,2,10035,,,0,"Fix spurious = in dib-python readme

Change-Id: I51e7961fab7f3eeaf3ce4eeb1dd5e6981eefb154
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/91/286991/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dib-python/README.rst'],1,a5d16584de45fce9689874eb2816f2ac2ecf113a,fix/dib-python-readme,========== dib-python ==========,=========== dib=-python ===========,3,3
openstack%2Fpuppet-openstack-integration~master~I8b51fa7fa4ae255ece35643798db2357a92760b0,openstack/puppet-openstack-integration,master,I8b51fa7fa4ae255ece35643798db2357a92760b0,Switch creating cinder types to providers from define classes,MERGED,2016-02-03 12:31:20.000000000,2016-03-07 05:45:30.000000000,2016-03-07 05:45:29.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 9500}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-03 12:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/5a3b946069262b4524378bf1b96dba75e89396b6', 'message': 'Switch creating cinder types to providers from define classes\n\nChange-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0\nDepends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 2, 'created': '2016-02-04 13:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/03e571c1693de7511a894a586541a2e5d1277107', 'message': 'Switch creating cinder types to providers from define classes\n\nChange-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0\nDepends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 3, 'created': '2016-02-12 14:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/fc307dcedbc90cb6c77504b101fd9f5c56e8c9ad', 'message': 'Switch creating cinder types to providers from define classes\n\nChange-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0\nDepends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 4, 'created': '2016-02-26 13:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/428c6bbcdae4c2d1b4f2706b49ff1960ac2057da', 'message': 'Switch creating cinder types to providers from define classes\n\nChange-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0\nDepends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 5, 'created': '2016-03-04 15:02:20.000000000', 'files': ['manifests/cinder.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/dc9300061ef4cd6ce0357fcb2ef1108d718bd06e', 'message': 'Switch creating cinder types to providers from define classes\n\nChange-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0\nDepends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}]",2,275669,dc9300061ef4cd6ce0357fcb2ef1108d718bd06e,26,5,5,7745,,,0,"Switch creating cinder types to providers from define classes

Change-Id: I8b51fa7fa4ae255ece35643798db2357a92760b0
Depends-On: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/69/275669/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/cinder.pp'],1,5a3b946069262b4524378bf1b96dba75e89396b6,(detached," cinder_type { 'BACKEND_1': ensure => present, } -> cinder_type_key { 'BACKEND_1': ensure => present, properties => 'volume_backend_name=BACKEND_1',"," Cinder::Type { os_password => 'a_big_secret', os_tenant_name => 'services', os_username => 'cinder', os_auth_url => 'http://127.0.0.1:5000/v2.0', } cinder::type { 'BACKEND_1': set_key => 'volume_backend_name', set_value => 'BACKEND_1',",6,9
openstack%2Fkolla~master~I46a0bb2e413cf4d2968f956c80e10735bf7106c8,openstack/kolla,master,I46a0bb2e413cf4d2968f956c80e10735bf7106c8,Update README for Trove image,MERGED,2016-03-07 04:24:18.000000000,2016-03-07 05:30:40.000000000,2016-03-07 05:30:40.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 13642}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-07 04:24:18.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ead7752ad6b860cd510be21ba372544ddfb7b3e5', 'message': 'Update README for Trove image\n\nAdded Trove in the list of images\nprovided by kolla.\n\nChange-Id: I46a0bb2e413cf4d2968f956c80e10735bf7106c8\n'}]",0,289133,ead7752ad6b860cd510be21ba372544ddfb7b3e5,8,4,1,18009,,,0,"Update README for Trove image

Added Trove in the list of images
provided by kolla.

Change-Id: I46a0bb2e413cf4d2968f956c80e10735bf7106c8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/33/289133/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ead7752ad6b860cd510be21ba372544ddfb7b3e5,readme_update,- `Trove <http://docs.openstack.org/developer/trove/>`__,,1,0
openstack%2Fcinder~master~If6f1decf4d6244b1e04b05b8662d891fb16c6790,openstack/cinder,master,If6f1decf4d6244b1e04b05b8662d891fb16c6790,IBM Storwize with pool-aware-cinder-scheduler,MERGED,2016-02-25 09:37:56.000000000,2016-03-07 05:15:00.000000000,2016-03-01 16:38:10.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 8912}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17045}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-02-25 09:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/635c5478f3267473f1ff41526184b0f86e9f22d7', 'message': 'IBM Storwize pool aware support\n\nStorwize cinder driver only support configure one pool\nwithin one backend right now. This change adds support\nfor multi-pools aware.\n\nImplements: bp Storwize-pool-aware-support\nChange-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790\n'}, {'number': 2, 'created': '2016-02-25 10:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22a2d44a79d527549846bb1a0a803ffd0314c8a5', 'message': 'IBM Storwize with pool-aware-cinder-scheduler\n\nStorwize cinder driver only supports config one pool\nwithin one backend right now. This change adds support\nfor multi-pools aware for scheduler.\nstorwize_svc_volpool_name accepts a list of pools\nseparated by comma in cinder.conf now.\n\nImplements: bp Storwize-pool-aware-support\nChange-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790\n'}, {'number': 3, 'created': '2016-02-26 08:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7f1b5ca5b932a1d3c74663519f47cb3852916a4', 'message': 'IBM Storwize with pool-aware-cinder-scheduler\n\nStorwize cinder driver only supports config one pool\nwithin one backend right now. This change adds support\nfor multi-pools aware for scheduler.\nstorwize_svc_volpool_name accepts a list of pools\nseparated by comma in cinder.conf now.\n\nUser-Visible Change\n-------------------\nDocImpact\nThe configuration flag storwize_svc_volpool_name\nshould be updated to a ListOpt.\n\nImplements: bp Storwize-pool-aware-support\nChange-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790\n'}, {'number': 4, 'created': '2016-02-29 06:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d70db314d980233df83d178480c0cca97427318', 'message': 'IBM Storwize with pool-aware-cinder-scheduler\n\nStorwize cinder driver only supports config one pool\nwithin one backend right now. This change adds support\nfor multi-pools aware for scheduler.\nstorwize_svc_volpool_name accepts a list of pools\nseparated by comma in cinder.conf now.\n\nUser-Visible Change\n-------------------\nDocImpact\nThe configuration flag storwize_svc_volpool_name\nshould be updated to a ListOpt.\n\nImplements: bp Storwize-pool-aware-support\nChange-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790\n'}, {'number': 5, 'created': '2016-02-29 20:19:49.000000000', 'files': ['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_iscsi.py', 'releasenotes/notes/storwize-pool-aware-support-7a40c9934642b202.yaml', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_fc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/406f0eb012def6087e989f35e26c72ec4f4f747e', 'message': 'IBM Storwize with pool-aware-cinder-scheduler\n\nStorwize cinder driver only supports config one pool\nwithin one backend right now. This change adds support\nfor multi-pools aware for scheduler.\nstorwize_svc_volpool_name accepts a list of pools\nseparated by comma in cinder.conf now.\n\nUser-Visible Change\n-------------------\nDocImpact\nThe configuration flag storwize_svc_volpool_name\nshould be updated to a ListOpt.\n\nImplements: bp Storwize-pool-aware-support\nChange-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790\n'}]",26,284614,406f0eb012def6087e989f35e26c72ec4f4f747e,127,41,5,17045,,,0,"IBM Storwize with pool-aware-cinder-scheduler

Storwize cinder driver only supports config one pool
within one backend right now. This change adds support
for multi-pools aware for scheduler.
storwize_svc_volpool_name accepts a list of pools
separated by comma in cinder.conf now.

User-Visible Change
-------------------
DocImpact
The configuration flag storwize_svc_volpool_name
should be updated to a ListOpt.

Implements: bp Storwize-pool-aware-support
Change-Id: If6f1decf4d6244b1e04b05b8662d891fb16c6790
",git fetch https://review.opendev.org/openstack/cinder refs/changes/14/284614/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_iscsi.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_fc.py']",4,635c5478f3267473f1ff41526184b0f86e9f22d7,bp/Storwize-pool-aware-support," 2.0.1 - Added support for multiple pools with model update VERSION = ""2.0.1"""," VERSION = ""2.0""",245,127
openstack%2Fhorizon~master~Ide9a391c29c11df5c1b5fb009ac5aace8a521cb4,openstack/horizon,master,Ide9a391c29c11df5c1b5fb009ac5aace8a521cb4,Correct name of AngularJS Containers panel,ABANDONED,2016-03-07 03:36:05.000000000,2016-03-07 05:05:14.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 17642}]","[{'number': 1, 'created': '2016-03-07 03:36:05.000000000', 'files': ['openstack_dashboard/dashboards/project/ngcontainers/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/26227058a5696521c9b81d1c14f4933aa8b891c0', 'message': 'Correct name of AngularJS Containers panel\n\nCorrects the name of the panel to match the name presented\non the panel.\n\nChange-Id: Ide9a391c29c11df5c1b5fb009ac5aace8a521cb4\nCloses-Bug: 1553612\n'}]",0,289124,26227058a5696521c9b81d1c14f4933aa8b891c0,5,3,1,12071,,,0,"Correct name of AngularJS Containers panel

Corrects the name of the panel to match the name presented
on the panel.

Change-Id: Ide9a391c29c11df5c1b5fb009ac5aace8a521cb4
Closes-Bug: 1553612
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/289124/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/ngcontainers/panel.py'],1,26227058a5696521c9b81d1c14f4933aa8b891c0,bug/1553612," name = _(""Containers"")"," name = _(""NGContainers"")",1,1
openstack%2Fopenstack-manuals~master~Iecc870fdfe5726e6d6f4ae48845221efd6494bfc,openstack/openstack-manuals,master,Iecc870fdfe5726e6d6f4ae48845221efd6494bfc,Describe dry-run option for auto-allocate-topology,MERGED,2016-03-03 15:58:45.000000000,2016-03-07 05:00:52.000000000,2016-03-07 05:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 748}, {'_account_id': 6524}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-03-03 15:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/67f9e4398fb45125167ae082825b0763675e4960', 'message': 'Describe dry-run option for auto-allocate-topology\n\nCloses-Bug: #1552541\n\nChange-Id: Iecc870fdfe5726e6d6f4ae48845221efd6494bfc\n'}, {'number': 2, 'created': '2016-03-03 16:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fac410aac84b0a7c3c2e849b547a22298281dcc4', 'message': 'Describe dry-run option for auto-allocate-topology\n\nCloses-Bug: #1552541\n\nChange-Id: Iecc870fdfe5726e6d6f4ae48845221efd6494bfc\n'}, {'number': 3, 'created': '2016-03-03 17:32:24.000000000', 'files': ['doc/networking-guide/source/intro-os-networking-features.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b8a4166898d0f5107cab7077f322981c9309027b', 'message': 'Describe dry-run option for auto-allocate-topology\n\nCloses-Bug: #1552541\n\nChange-Id: Iecc870fdfe5726e6d6f4ae48845221efd6494bfc\n'}]",4,287937,b8a4166898d0f5107cab7077f322981c9309027b,18,7,3,6524,,,0,"Describe dry-run option for auto-allocate-topology

Closes-Bug: #1552541

Change-Id: Iecc870fdfe5726e6d6f4ae48845221efd6494bfc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/287937/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/intro-os-networking-features.rst'],1,67f9e4398fb45125167ae082825b0763675e4960,bug/1552541,"Validating the requirements for auto-allocation ----------------------------------------------- To validate that the required resources are correctly set up for auto-allocation, use the --dry-run option: .. code-block:: console $ neutron auto-allocated-topology-show --dry-run Deployment error: No default router:external network. $ neutron net-update public --is-default=True $ neutron auto-allocated-topology-show --dry-run Deployment error: No default subnetpools defined. $ neutron subnetpool-update shared-default --is-default=True $ neutron auto-allocated-topology-show --dry-run +---------+-------+ | Field | Value | +---------+-------+ | dry-run | pass | +---------+-------+ ",,26,0
openstack%2Fopenstack-manuals~master~I1738ca0afba5f7377a4c9659f727ed72c64740bf,openstack/openstack-manuals,master,I1738ca0afba5f7377a4c9659f727ed72c64740bf,Spelling mistake corrected,MERGED,2016-03-07 03:21:22.000000000,2016-03-07 04:58:28.000000000,2016-03-07 04:58:27.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}, {'_account_id': 12686}]","[{'number': 1, 'created': '2016-03-07 03:21:22.000000000', 'files': ['doc/admin-guide-cloud/source/keystone_fernet_token_faq.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cf974a5393c693661f59e0b1368b6e85365b461f', 'message': 'Spelling mistake corrected\n\nSpelling of distribe changed to distribute\n\nChange-Id: I1738ca0afba5f7377a4c9659f727ed72c64740bf\nCloses-Bug: #1553658\n'}]",0,289122,cf974a5393c693661f59e0b1368b6e85365b461f,8,4,1,20465,,,0,"Spelling mistake corrected

Spelling of distribe changed to distribute

Change-Id: I1738ca0afba5f7377a4c9659f727ed72c64740bf
Closes-Bug: #1553658
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/289122/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/source/keystone_fernet_token_faq.rst'],1,cf974a5393c693661f59e0b1368b6e85365b461f,bug/1553658," should be able to distribute keys until it is successful. If certain nodes have issues syncing, it could be permission or network issues and those should be resolved before subsequent rotations."," should be able to distribe keys until it is successful. If certain nodes have issues syncing, it could be permission or network issues and those should be resolved before subsequent rotations.",4,3
openstack%2Fdiskimage-builder~master~Idf48f70e112af1f17d398155a317872b1d569f21,openstack/diskimage-builder,master,Idf48f70e112af1f17d398155a317872b1d569f21,Fix cloud-init-disable-resizefs README title,MERGED,2016-03-02 05:49:57.000000000,2016-03-07 04:49:53.000000000,2016-03-07 04:49:52.000000000,"[{'_account_id': 3}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-02 05:49:57.000000000', 'files': ['elements/cloud-init-disable-resizefs/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6ee7da704d1a8514905bf40c117fd23466226c4f', 'message': ""Fix cloud-init-disable-resizefs README title\n\nElement readme's need to start with a title that matches the element\nname.\n\nChange-Id: Idf48f70e112af1f17d398155a317872b1d569f21\n""}]",0,286999,6ee7da704d1a8514905bf40c117fd23466226c4f,7,2,1,10035,,,0,"Fix cloud-init-disable-resizefs README title

Element readme's need to start with a title that matches the element
name.

Change-Id: Idf48f70e112af1f17d398155a317872b1d569f21
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/99/286999/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/cloud-init-disable-resizefs/README.rst'],1,6ee7da704d1a8514905bf40c117fd23466226c4f,fix/cloud-init-disable-resizefs-readme,=========================== cloud-init-disable-resizefs ===========================,Disable cloud-init's resizefs module ------------------------------------,3,2
openstack%2Fnetworking-ofagent~master~I605cc3d2051a93c36bc27d948880f11b9db70776,openstack/networking-ofagent,master,I605cc3d2051a93c36bc27d948880f11b9db70776,Updated from global requirements,MERGED,2016-02-26 01:49:20.000000000,2016-03-07 04:35:13.000000000,2016-03-07 04:35:13.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 8344}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-26 01:49:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-ofagent/commit/6b11c517d61b8beef0b8f9a7d9b9093080961af7', 'message': 'Updated from global requirements\n\nChange-Id: I605cc3d2051a93c36bc27d948880f11b9db70776\n'}]",0,285038,6b11c517d61b8beef0b8f9a7d9b9093080961af7,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I605cc3d2051a93c36bc27d948880f11b9db70776
",git fetch https://review.opendev.org/openstack/networking-ofagent refs/changes/38/285038/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6b11c517d61b8beef0b8f9a7d9b9093080961af7,openstack/requirements,oslo.config>=3.7.0 # Apache-2.0,oslo.config>=3.4.0 # Apache-2.0,1,1
openstack%2Fpuppet-keystone~master~I1e122dc34d496bc26926b6bcd0921e672e099d2e,openstack/puppet-keystone,master,I1e122dc34d496bc26926b6bcd0921e672e099d2e,Fix issue with fernet_setup exec,MERGED,2016-03-06 00:26:28.000000000,2016-03-07 03:07:10.000000000,2016-03-07 03:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-06 00:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/529110c7d9b5ab46854431c973d97f56d219e7b7', 'message': 'Fix issue with fernet_setup exec\n\nThe fernet_setup exec is requiring that the\nkeystone-user and keystone-group is passed\nin the exec call. This change exposes two\nnew parameters that default to ""keystone""\nthat are used in that exec call.\n\nChange-Id: I1e122dc34d496bc26926b6bcd0921e672e099d2e\nCloses-Bug: 1553327\n'}, {'number': 2, 'created': '2016-03-06 00:30:47.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cd4f7d86196cbe3e8acc0c17e2cfdf23424b6c40', 'message': 'Fix issue with fernet_setup exec\n\nThe fernet_setup exec is requiring that the\nkeystone-user and keystone-group is passed\nin the exec call. This change exposes two\nnew parameters that default to ""keystone""\nthat are used in that exec call.\n\nChange-Id: I1e122dc34d496bc26926b6bcd0921e672e099d2e\nCloses-Bug: 1553327\n'}]",0,288950,cd4f7d86196cbe3e8acc0c17e2cfdf23424b6c40,12,3,2,8318,,,0,"Fix issue with fernet_setup exec

The fernet_setup exec is requiring that the
keystone-user and keystone-group is passed
in the exec call. This change exposes two
new parameters that default to ""keystone""
that are used in that exec call.

Change-Id: I1e122dc34d496bc26926b6bcd0921e672e099d2e
Closes-Bug: 1553327
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/50/288950/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp', 'manifests/params.pp']",3,529110c7d9b5ab46854431c973d97f56d219e7b7,bug/1553327, $keystone_user = 'keystone' $keystone_group = 'keystone',,16,1
openstack%2Fsenlin~master~I16f19012db5a0bf0ac3271a389f84cae7473d58f,openstack/senlin,master,I16f19012db5a0bf0ac3271a389f84cae7473d58f,Move an item back to TODO list,MERGED,2016-03-07 02:24:32.000000000,2016-03-07 03:04:18.000000000,2016-03-07 03:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-03-07 02:24:32.000000000', 'files': ['TODO.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/ecb2d0071e76e3bc8ba14708c37e5fba168a815b', 'message': 'Move an item back to TODO list\n\nThis patch moves an item from etherpad to TODO list.\n\nChange-Id: I16f19012db5a0bf0ac3271a389f84cae7473d58f\n'}]",0,289116,ecb2d0071e76e3bc8ba14708c37e5fba168a815b,7,3,1,11034,,,0,"Move an item back to TODO list

This patch moves an item from etherpad to TODO list.

Change-Id: I16f19012db5a0bf0ac3271a389f84cae7473d58f
",git fetch https://review.opendev.org/openstack/senlin refs/changes/16/289116/1 && git format-patch -1 --stdout FETCH_HEAD,['TODO.rst'],1,ecb2d0071e76e3bc8ba14708c37e5fba168a815b,,PROFILE ------- - Support disk property update for os.nova.server profile ,,4,0
openstack%2Fpuppet-aodh~master~I033599af813350911c001b7dcff1a90d6008cc67,openstack/puppet-aodh,master,I033599af813350911c001b7dcff1a90d6008cc67,Add support for alarm_history_time_to_live parameter,MERGED,2016-03-04 16:44:59.000000000,2016-03-07 03:00:31.000000000,2016-03-07 03:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-04 16:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/66bc5205528d2db30c221e20fae011ffbb6a89d0', 'message': 'Add support for alarm_history_time_to_live parameter\n\nThis parameter should be configured for Aodh instead of Ceilometer.\n\nChange-Id: I033599af813350911c001b7dcff1a90d6008cc67\n'}, {'number': 2, 'created': '2016-03-04 18:23:09.000000000', 'files': ['manifests/init.pp', 'spec/classes/aodh_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/bcc2d1a9e9ec5dfc5ba501d1916c5869cd0ef628', 'message': 'Add support for alarm_history_time_to_live parameter\n\nThis parameter should be configured for Aodh instead of Ceilometer.\n\nChange-Id: I033599af813350911c001b7dcff1a90d6008cc67\n'}]",2,288581,bcc2d1a9e9ec5dfc5ba501d1916c5869cd0ef628,13,5,2,7732,,,0,"Add support for alarm_history_time_to_live parameter

This parameter should be configured for Aodh instead of Ceilometer.

Change-Id: I033599af813350911c001b7dcff1a90d6008cc67
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/81/288581/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/aodh_init_spec.rb']",2,66bc5205528d2db30c221e20fae011ffbb6a89d0,," is_expected.to contain_aodh_config('database/alarm_history_time_to_live').with_value('-1') :notification_topics => 'openstack', :alarm_history_time_to_live => '604800', } is_expected.to contain_aodh_config('database/alarm_history_time_to_live').with_value('604800')", :notification_topics => 'openstack' },15,4
openstack%2Fmagnum~master~I671bc6b4cf40d811ec8187c7c1abe99c92be0052,openstack/magnum,master,I671bc6b4cf40d811ec8187c7c1abe99c92be0052,Initial command-line interface documentation,MERGED,2016-02-25 13:48:09.000000000,2016-03-07 02:56:19.000000000,2016-03-07 02:56:19.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 18498}]","[{'number': 1, 'created': '2016-02-25 13:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/80e6de5d4cf8442511c309407aa0737987c2a33c', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 2, 'created': '2016-02-25 13:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c24e77b52601539528b5ddcea4100e2c49e31b11', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 3, 'created': '2016-02-25 13:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1098b0489d2aa9c787cabd12aaf4a10d93704eae', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 4, 'created': '2016-02-25 16:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c1c2686901af584ae091d1f281aba236af2993c3', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 5, 'created': '2016-02-25 20:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ebf69944505c8776e1d3afb7783e34aed5f851ee', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 6, 'created': '2016-02-25 20:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4d5606dce8bc77331b9d18dc07895ef5f4fcbcd3', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org. Further examples will be required in the future.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 7, 'created': '2016-02-25 21:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e839dc0c684ec04dc0c23d7d2a805aad8980bd24', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org. Further examples will be required in the future.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 8, 'created': '2016-02-27 16:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/852ecbd98c9dda76709e9ca5e183d6a1a549e891', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org. Further examples will be required in the future.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 9, 'created': '2016-02-27 21:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/012267af4a8de94e9da277d750da81b5c12ab38e', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org. Further examples will be required in the future.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}, {'number': 10, 'created': '2016-02-29 03:38:48.000000000', 'files': ['doc/source/userguide.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/311de695be60ae2e1cb009413079455f42d74521', 'message': 'Initial command-line interface documentation\n\nDocuments installation of the client and where to find more information\non the commands it supports in the CLI reference guide on\ndocs.openstack.org. Further examples will be required in the future.\n\nChange-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052\n'}]",15,284718,311de695be60ae2e1cb009413079455f42d74521,51,9,10,6772,,,0,"Initial command-line interface documentation

Documents installation of the client and where to find more information
on the commands it supports in the CLI reference guide on
docs.openstack.org. Further examples will be required in the future.

Change-Id: I671bc6b4cf40d811ec8187c7c1abe99c92be0052
",git fetch https://review.opendev.org/openstack/magnum refs/changes/18/284718/10 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userguide.rst'],1,80e6de5d4cf8442511c309407aa0737987c2a33c,," Installation ============ Using pip --------- Install `pip`:: $ curl -s https://bootstrap.pypa.io/get-pip.py | sudo python Install `python-magnumclient` from pip:: $ pip install python-magnumclient Using distribution packages --------------------------- Follow the instructions in the OpenStack Installation Guide to enable the repositories for your distribution: * `RHEL/CentOS/Fedora <http://docs.openstack.org/install-guide-rdo/>__` * `Ubuntu/Debian http://docs.openstack.org/install-guide/>__` * `openSUSE/SUSE Linux Enterprise http://docs.openstack.org/install-guide-obs/__` Install using distribution packages for RHEL/CentOS/Fedora:: $ yum install python-magnumclient Install using distribution packages for Ubuntu/Debian:: $ apt-get install python-magnumclient Install using distribution packages for OpenSuSE and SuSE Enterprise Linux:: $ zypper install python-magnumclient Verifying installation ---------------------- Execute the `magnum` command with the `--version` argument to confirm that the client is installed and in the system path:: $ magnum --version 1.1.0 Note that the version returned may differ from the above, 1.1.0 was the latest available version at the time of writing. Using the command-line client ----------------------------- Refer to the `OpenStack Command-Line Interface Reference http://docs.openstack.org/cli-reference/magnum.html`__ for a full list of the commands supported by the `magnum` command-line client.",*To be filled in*,58,1
openstack%2Fironic~master~Ib0dd722fdf35606af4cdbdd28b7a39d370046ac5,openstack/ironic,master,Ib0dd722fdf35606af4cdbdd28b7a39d370046ac5,"Revert ""API to list nodes using the same driver""",ABANDONED,2016-03-03 07:26:30.000000000,2016-03-07 02:55:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 13362}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-03 07:26:30.000000000', 'files': ['ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/controllers/v1/versions.py', 'doc/source/webapi/v1.rst', 'releasenotes/notes/list-nodes-by-driver-a1ab9f2b73f652f8.yaml', 'ironic/api/controllers/v1/utils.py', 'ironic/tests/unit/api/v1/test_utils.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6828de600a9a282f458f0d7f7902f1dcf4a8a351', 'message': 'Revert ""API to list nodes using the same driver""\n\nThis reverts commit d3859a79bafcc0e17e1fa6890b8d0f6e4d4ed0a8.\n\nReverted it due to the REF is not approved so far.\n\nChange-Id: Ib0dd722fdf35606af4cdbdd28b7a39d370046ac5\n'}]",0,287629,6828de600a9a282f458f0d7f7902f1dcf4a8a351,6,7,1,8106,,,0,"Revert ""API to list nodes using the same driver""

This reverts commit d3859a79bafcc0e17e1fa6890b8d0f6e4d4ed0a8.

Reverted it due to the REF is not approved so far.

Change-Id: Ib0dd722fdf35606af4cdbdd28b7a39d370046ac5
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/287629/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/controllers/v1/versions.py', 'doc/source/webapi/v1.rst', 'releasenotes/notes/list-nodes-by-driver-a1ab9f2b73f652f8.yaml', 'ironic/api/controllers/v1/utils.py', 'ironic/tests/unit/api/v1/test_utils.py', 'ironic/api/controllers/v1/node.py']",7,6828de600a9a282f458f0d7f7902f1dcf4a8a351,bug1530626," sort_key, sort_dir, resource_url=None, fields=None): wtypes.text, types.listtype) limit=None, sort_key='id', sort_dir='asc', fields=None): that chassis. of the resource to be returned. fields=fields) wtypes.text) limit=None, sort_key='id', sort_dir='asc'): resource_url)"," sort_key, sort_dir, driver=None, resource_url=None, fields=None): if driver: filters['driver'] = driver wtypes.text, wtypes.text, types.listtype) limit=None, sort_key='id', sort_dir='asc', driver=None, fields=None): that chassis. :param driver: Optional string value to get only nodes using that driver. of the resource to be returned. api_utils.check_allow_specify_driver(driver) driver, fields=fields) wtypes.text, wtypes.text) limit=None, sort_key='id', sort_dir='asc', driver=None): :param driver: Optional string value to get only nodes using that driver. api_utils.check_allow_specify_driver(driver) driver, resource_url)",11,85
openstack%2Fcharm-ceph-radosgw~master~I83d87c088a264ebd556e5d3285f63c60d4b799d8,openstack/charm-ceph-radosgw,master,I83d87c088a264ebd556e5d3285f63c60d4b799d8,Fix issues when using embedded webserver,MERGED,2016-03-04 21:24:58.000000000,2016-03-07 02:51:50.000000000,2016-03-07 02:51:50.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 8992}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 21:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/6cb6e2e24b64c45717ad79738c9deb0418c238f6', 'message': 'Fix issues when using embedded webserver\n\nRemove both apache configuration files from the context map\nif embedded webserver is enabled; as this is the recommended\nway of deploying radosgw, switch the amulet test to exercise\nthis option instead of apache.\n\nChange-Id: I83d87c088a264ebd556e5d3285f63c60d4b799d8\nClose-Bug: 1553357\n'}, {'number': 2, 'created': '2016-03-04 21:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/70063546d60d44599a6fc6d6f095469a0af1e464', 'message': 'Fix issues when using embedded webserver\n\nRemove both apache configuration files from the context map\nif embedded webserver is enabled; as this is the recommended\nway of deploying radosgw, switch the amulet test to exercise\nthis option instead of apache.\n\nChange-Id: I83d87c088a264ebd556e5d3285f63c60d4b799d8\nClose-Bug: 1553357\n'}, {'number': 3, 'created': '2016-03-05 08:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/0aa805339e1eb22a313536825ca32986a47f0818', 'message': 'Fix issues when using embedded webserver\n\nRemove both apache configuration files from the context map\nif embedded webserver is enabled; as this is the recommended\nway of deploying radosgw, switch the amulet test to exercise\nthis option instead of apache.\n\nChange-Id: I83d87c088a264ebd556e5d3285f63c60d4b799d8\nClose-Bug: 1553357\n'}, {'number': 4, 'created': '2016-03-05 17:58:20.000000000', 'files': ['hooks/utils.py', 'tests/basic_deployment.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/c087e0dfbef911a297c8bdc9871f8a07ef862c3b', 'message': 'Fix issues when using embedded webserver\n\nRemove apache configuration files from the context map if\nembedded webserver is enabled; as this is the recommended\nway of deploying radosgw, switch the amulet test to exercise\nthis option instead of apache.\n\nChange-Id: I83d87c088a264ebd556e5d3285f63c60d4b799d8\nClose-Bug: 1553357\n'}]",0,288751,c087e0dfbef911a297c8bdc9871f8a07ef862c3b,17,4,4,935,,,0,"Fix issues when using embedded webserver

Remove apache configuration files from the context map if
embedded webserver is enabled; as this is the recommended
way of deploying radosgw, switch the amulet test to exercise
this option instead of apache.

Change-Id: I83d87c088a264ebd556e5d3285f63c60d4b799d8
Close-Bug: 1553357
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/51/288751/4 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/utils.py', 'tests/basic_deployment.py']",2,6cb6e2e24b64c45717ad79738c9deb0418c238f6,bug/1553357," radosgw_config = {""use-embedded-webserver"": True} 'ceph': ceph_config, 'ceph-radosgw': radosgw_config} 'rgw frontends': 'civetweb port=70',", 'ceph': ceph_config},11,3
openstack%2Fcongress~master~Ifca40ceb90b976b264e36fc0cc0dd000865b96d1,openstack/congress,master,Ifca40ceb90b976b264e36fc0cc0dd000865b96d1,Updated from global requirements,MERGED,2016-03-05 15:31:15.000000000,2016-03-07 02:47:23.000000000,2016-03-07 02:47:23.000000000,"[{'_account_id': 3}, {'_account_id': 8878}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 15:31:15.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/e3c0813f9cf8d7fd071c7e084d4e42cf11c21f65', 'message': 'Updated from global requirements\n\nChange-Id: Ifca40ceb90b976b264e36fc0cc0dd000865b96d1\n'}]",0,288886,e3c0813f9cf8d7fd071c7e084d4e42cf11c21f65,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ifca40ceb90b976b264e36fc0cc0dd000865b96d1
",git fetch https://review.opendev.org/openstack/congress refs/changes/86/288886/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e3c0813f9cf8d7fd071c7e084d4e42cf11c21f65,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Fheat~master~I78626530138e76ebf43cd186bacac83f1ff48b41,openstack/heat,master,I78626530138e76ebf43cd186bacac83f1ff48b41,Fix error msg for wrong auth_url in functional,MERGED,2016-03-03 12:39:06.000000000,2016-03-07 02:36:42.000000000,2016-03-07 02:36:42.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12363}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-03-03 12:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/29a34bac0f98ba007b13020e7faa9a233c02b58d', 'message': ""Fix error msgefor wrong auth_url in functional\n\nIf auth_url config is specified without version, functional\ntests raises IndexError with message 'list out of range'. Need\nto add check for auth_url and if it's set incorrectly, raise\ncorrect error with message about wrong auth_url config.\n\nChange-Id: I78626530138e76ebf43cd186bacac83f1ff48b41\nCloses-bug: #1552325\n""}, {'number': 2, 'created': '2016-03-04 12:29:56.000000000', 'files': ['heat_integrationtests/common/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/cf49722e78474e5faeba253d88e39fe10e1edb66', 'message': ""Fix error msg for wrong auth_url in functional\n\nIf auth_url config is specified without version, functional\ntests raises IndexError with message 'list out of range'. Need\nto add check for auth_url and if it's set incorrectly, raise\ncorrect error with message about wrong auth_url config.\n\nChange-Id: I78626530138e76ebf43cd186bacac83f1ff48b41\nCloses-bug: #1552325\n""}]",4,287764,cf49722e78474e5faeba253d88e39fe10e1edb66,17,6,2,13009,,,0,"Fix error msg for wrong auth_url in functional

If auth_url config is specified without version, functional
tests raises IndexError with message 'list out of range'. Need
to add check for auth_url and if it's set incorrectly, raise
correct error with message about wrong auth_url config.

Change-Id: I78626530138e76ebf43cd186bacac83f1ff48b41
Closes-bug: #1552325
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/287764/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/common/clients.py'],1,29a34bac0f98ba007b13020e7faa9a233c02b58d,,from heat.common.i18n import _ if self.conf.auth_url.find('/v'): self.auth_version = self.conf.auth_url.split('/v')[1] else: raise ValueError(_('Incorrectly specified auth_url config: no ' 'version found.')) , self.auth_version = self.conf.auth_url.split('/v')[1],7,1
openstack%2Fbashate~master~I747ccfd87cc56e0797ec899097a6e338c720692e,openstack/bashate,master,I747ccfd87cc56e0797ec899097a6e338c720692e,Add reno & start at release notes,MERGED,2016-03-07 01:04:33.000000000,2016-03-07 02:32:13.000000000,2016-03-07 02:32:13.000000000,"[{'_account_id': 3}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-07 01:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/d01598fa0a3b70f910b2fd09cbdba047c51be9c1', 'message': 'Add reno & start at release notes\n\nAdd reno & start at having release notes\n\nChange-Id: I747ccfd87cc56e0797ec899097a6e338c720692e\n'}, {'number': 2, 'created': '2016-03-07 01:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/95d1f78ff3c59f210d00d4f72584d7d0d370d1fc', 'message': 'Add reno & start at release notes\n\nAdd reno & start at having release notes\n\nChange-Id: I747ccfd87cc56e0797ec899097a6e338c720692e\n'}, {'number': 3, 'created': '2016-03-07 01:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bashate/commit/eb7f0d6e7c1d4341ce6dfdf2c8845d065491c7b0', 'message': 'Add reno & start at release notes\n\nAdd reno & start at having release notes\n\nChange-Id: I747ccfd87cc56e0797ec899097a6e338c720692e\n'}, {'number': 4, 'created': '2016-03-07 02:09:35.000000000', 'files': ['doc/source/index.rst', 'test-requirements.txt', 'releasenotes/notes/start-using-reno-eaaafddb3fbf2010.yaml', 'doc/source/releasenotes.rst', 'doc/source/conf.py', 'releasenotes/notes/heredoc-ignore-905b29053652f90e.yaml'], 'web_link': 'https://opendev.org/openstack/bashate/commit/0661da9c91f38c71d7d6b7521ff23c3dcc8f2949', 'message': 'Add reno & start at release notes\n\nAdd reno & start at having release notes\n\nChange-Id: I747ccfd87cc56e0797ec899097a6e338c720692e\n'}]",0,289105,0661da9c91f38c71d7d6b7521ff23c3dcc8f2949,12,2,4,7118,,,0,"Add reno & start at release notes

Add reno & start at having release notes

Change-Id: I747ccfd87cc56e0797ec899097a6e338c720692e
",git fetch https://review.opendev.org/openstack/bashate refs/changes/05/289105/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'test-requirements.txt', 'releasenotes/notes/start-using-reno-eaaafddb3fbf2010.yaml', 'doc/source/conf.py', 'tox.ini']",5,d01598fa0a3b70f910b2fd09cbdba047c51be9c1,release-notes,,,8,1
openstack%2Fos-vif~master~Icf6dd39f515f5c2f8db8c1d414776eebd8e85617,openstack/os-vif,master,Icf6dd39f515f5c2f8db8c1d414776eebd8e85617,Remove vlan from hostdev and direct vif,MERGED,2016-02-23 11:54:02.000000000,2016-03-07 02:30:07.000000000,2016-03-07 02:30:07.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 7634}]","[{'number': 1, 'created': '2016-02-23 11:54:02.000000000', 'files': ['os_vif/objects/vif.py', 'os_vif/tests/test_vif.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e91941a0b841e5c4b58695d66489bbd0e9b73462', 'message': 'Remove vlan from hostdev and direct vif\n\nThis patch remove the vlan attribute from hostdev\nand direct vif. The vlan should be taken from the\nnetwork object. When the network vlan is null (for example in\nflat network) it should be zero in the libvirt xml\n\nChange-Id: Icf6dd39f515f5c2f8db8c1d414776eebd8e85617\n'}]",0,283528,e91941a0b841e5c4b58695d66489bbd0e9b73462,10,4,1,12171,,,0,"Remove vlan from hostdev and direct vif

This patch remove the vlan attribute from hostdev
and direct vif. The vlan should be taken from the
network object. When the network vlan is null (for example in
flat network) it should be zero in the libvirt xml

Change-Id: Icf6dd39f515f5c2f8db8c1d414776eebd8e85617
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/28/283528/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_vif/objects/vif.py', 'os_vif/tests/test_vif.py']",2,e91941a0b841e5c4b58695d66489bbd0e9b73462,direct_remove_vlan," dev_address=""0002:24:12.3"") 'VIFDirect': '1.0-05c939280f4025fd1f7efb921a835c57', 'VIFHostDevice': '1.0-b3516f5af46ecb9432650e4938ac2643',"," dev_address=""0002:24:12.3"", vlan=8) vlan=8, 'VIFDirect': '1.0-d07d1f26bb58b6677c5304b652cc64f1', 'VIFHostDevice': '1.0-7289a0eb0a69aeb5d821a0d006e3e444',",3,10
openstack%2Fapi-site~master~I721bb7ba19f11dd149d54dfda4e83eb8358773f8,openstack/api-site,master,I721bb7ba19f11dd149d54dfda4e83eb8358773f8,Remove duplicate error code in volume,MERGED,2016-02-11 10:39:02.000000000,2016-03-07 02:20:55.000000000,2016-03-07 02:20:55.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6062}, {'_account_id': 10497}, {'_account_id': 16237}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-02-11 10:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/5a06426dfdda6a0cc7a1687f87e9cd3ae949c059', 'message': 'Remove duplicate error code in volume\n\ncommandFault and getFault are duplicated, remove them\n\nChange-Id: I721bb7ba19f11dd149d54dfda4e83eb8358773f8\nPartial-Bug: #1515222\n'}, {'number': 2, 'created': '2016-02-16 11:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/b8f0b1d515f0447d910892b244ab50d3bfcee2f2', 'message': 'Remove duplicate error code in volume\n\ncommandFault and getFault are duplicated, remove them\n\nChange-Id: I721bb7ba19f11dd149d54dfda4e83eb8358773f8\nPartial-Bug: #1515222\n'}, {'number': 3, 'created': '2016-03-07 01:59:39.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/a6f9f07ec0598652e03887e0e1c5f0073aca7e4a', 'message': 'Remove duplicate error code in volume\n\ncommandFault and getFault are duplicated, remove them\n\nChange-Id: I721bb7ba19f11dd149d54dfda4e83eb8358773f8\nPartial-Bug: #1515222\n'}]",1,278969,a6f9f07ec0598652e03887e0e1c5f0073aca7e4a,17,6,3,6062,,,0,"Remove duplicate error code in volume

commandFault and getFault are duplicated, remove them

Change-Id: I721bb7ba19f11dd149d54dfda4e83eb8358773f8
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/69/278969/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'],1,5a06426dfdda6a0cc7a1687f87e9cd3ae949c059,fix-compute-api-ref, </response> </response> </response>, </response> &commonFaults; &getFaults; </response> &commonFaults; &getFaults; </response> &commonFaults; &getFaults;,3,3
openstack%2Fsenlin~master~I8338b2e2c9d66f36ebcc3aaa0acfc3db8c19ebe6,openstack/senlin,master,I8338b2e2c9d66f36ebcc3aaa0acfc3db8c19ebe6,Improve the text in install-guide,MERGED,2016-03-06 15:23:04.000000000,2016-03-07 02:15:25.000000000,2016-03-07 02:15:25.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-03-06 15:23:04.000000000', 'files': ['doc/source/install.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/64641783fd32a4f15bdfadaf26cd978188ff234c', 'message': 'Improve the text in install-guide\n\nUpdate the text in install-guide for better understanding.\n\nChange-Id: I8338b2e2c9d66f36ebcc3aaa0acfc3db8c19ebe6\nCloses-Bug: #1549845\n'}]",0,289030,64641783fd32a4f15bdfadaf26cd978188ff234c,7,3,1,19840,,,0,"Improve the text in install-guide

Update the text in install-guide for better understanding.

Change-Id: I8338b2e2c9d66f36ebcc3aaa0acfc3db8c19ebe6
Closes-Bug: #1549845
",git fetch https://review.opendev.org/openstack/senlin refs/changes/30/289030/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install.rst'],1,64641783fd32a4f15bdfadaf26cd978188ff234c,bug/1549845," to customize the password you will use for the ``senlin`` user. You need to update this script with the <DB PASSWORD> entered in step4. You may need two consoles for the services i.e., one for each service.", to customize the password you will use for the ``senlin`` user. You may need two consoles for the services each.,3,2
openstack%2Fpython-senlinclient~master~I8d5a7a3562487317cc37c9d437956b8aef2c8086,openstack/python-senlinclient,master,I8d5a7a3562487317cc37c9d437956b8aef2c8086,Updated from global requirements,MERGED,2016-03-03 18:06:41.000000000,2016-03-07 02:14:38.000000000,2016-03-07 02:14:38.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-03 18:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/7c5d755dd8c9862ac53c6d492686b1c3ac78e168', 'message': 'Updated from global requirements\n\nChange-Id: I8d5a7a3562487317cc37c9d437956b8aef2c8086\n'}, {'number': 2, 'created': '2016-03-04 17:48:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/b7fb9a793eff85c2cc302813f0156037ff358c0b', 'message': 'Updated from global requirements\n\nChange-Id: I8d5a7a3562487317cc37c9d437956b8aef2c8086\n'}]",0,288036,b7fb9a793eff85c2cc302813f0156037ff358c0b,12,4,2,11131,,,0,"Updated from global requirements

Change-Id: I8d5a7a3562487317cc37c9d437956b8aef2c8086
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/36/288036/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7c5d755dd8c9862ac53c6d492686b1c3ac78e168,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Ftripleo-common~master~I22c4d37ce4f489105a89d3039a0689ad1b4b8c9f,openstack/tripleo-common,master,I22c4d37ce4f489105a89d3039a0689ad1b4b8c9f,Expose TENANT_STACK_DEPLOY_ARGS,MERGED,2016-03-03 22:30:46.000000000,2016-03-07 02:13:48.000000000,2016-03-07 02:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6796}]","[{'number': 1, 'created': '2016-03-03 22:30:46.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/17f953fb1a2a66355d4355f40a8cd8a3c5cb7872', 'message': 'Expose TENANT_STACK_DEPLOY_ARGS\n\nThis environment variable can be used to set custom\nvalues for the tenant Heat stack used within the\npingtest.\n\nThis is useful if for example you are doing network\nisolation and would like to make customized settings\nto the tenant network settings, etc.\n\nChange-Id: I22c4d37ce4f489105a89d3039a0689ad1b4b8c9f\n'}]",0,288161,17f953fb1a2a66355d4355f40a8cd8a3c5cb7872,18,5,1,360,,,0,"Expose TENANT_STACK_DEPLOY_ARGS

This environment variable can be used to set custom
values for the tenant Heat stack used within the
pingtest.

This is useful if for example you are doing network
isolation and would like to make customized settings
to the tenant network settings, etc.

Change-Id: I22c4d37ce4f489105a89d3039a0689ad1b4b8c9f
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/61/288161/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,17f953fb1a2a66355d4355f40a8cd8a3c5cb7872,tenent_stack_args," TENANT_STACK_DEPLOY_ARGS=${TENANT_STACK_DEPLOY_ARGS:-""""} heat stack-create -f $TENANT_PINGTEST_TEMPLATE $TENANT_STACK_DEPLOY_ARGS tenant-stack || exitval=1", heat stack-create -f $TENANT_PINGTEST_TEMPLATE tenant-stack || exitval=1,2,1
openstack%2Fdevstack~master~I01587633625087d190e879c88c53730efa01cd16,openstack/devstack,master,I01587633625087d190e879c88c53730efa01cd16,Updated from generate-devstack-plugins-list,MERGED,2016-03-01 06:27:10.000000000,2016-03-07 02:05:08.000000000,2016-03-07 02:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 7118}, {'_account_id': 10385}, {'_account_id': 16272}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-03-01 06:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3fb0915a4a6a296b4116d4f617f36652781b7a1d', 'message': 'Updated from generate-devstack-plugins-list\n\nChange-Id: I01587633625087d190e879c88c53730efa01cd16\n'}, {'number': 2, 'created': '2016-03-02 06:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1028053bbd0440697ba3fec1d1ebf8aabe354dc8', 'message': 'Updated from generate-devstack-plugins-list\n\nChange-Id: I01587633625087d190e879c88c53730efa01cd16\n'}, {'number': 3, 'created': '2016-03-04 06:26:52.000000000', 'files': ['doc/source/plugin-registry.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/96d895d8717a476b5ad2f5278762951e1a89bdd7', 'message': 'Updated from generate-devstack-plugins-list\n\nChange-Id: I01587633625087d190e879c88c53730efa01cd16\n'}]",1,286401,96d895d8717a476b5ad2f5278762951e1a89bdd7,24,6,3,11131,,,0,"Updated from generate-devstack-plugins-list

Change-Id: I01587633625087d190e879c88c53730efa01cd16
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/286401/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugin-registry.rst'],1,3fb0915a4a6a296b4116d4f617f36652781b7a1d,openstack/devstack/plugins,"Detected Plugins ================ The following are plugins that a script has found in the openstack/ namespace, which includes but is not limited to official OpenStack projects. +------------------+-------------------------------------------------------------------------+ |Plugin Name |URL | +------------------+-------------------------------------------------------------------------+ |aodh |git://git.openstack.org/openstack/aodh | +------------------+-------------------------------------------------------------------------+ |app-catalog-ui |git://git.openstack.org/openstack/app-catalog-ui | +------------------+-------------------------------------------------------------------------+ |astara |git://git.openstack.org/openstack/astara | +------------------+-------------------------------------------------------------------------+ |barbican |git://git.openstack.org/openstack/barbican | +------------------+-------------------------------------------------------------------------+ |blazar |git://git.openstack.org/openstack/blazar | +------------------+-------------------------------------------------------------------------+ |ceilometer |git://git.openstack.org/openstack/ceilometer | +------------------+-------------------------------------------------------------------------+ |ceilometer-powervm|git://git.openstack.org/openstack/ceilometer-powervm | +------------------+-------------------------------------------------------------------------+ |cerberus |git://git.openstack.org/openstack/cerberus | +------------------+-------------------------------------------------------------------------+ |cloudkitty |git://git.openstack.org/openstack/cloudkitty | +------------------+-------------------------------------------------------------------------+ |collectd-ceilomete|git://git.openstack.org/openstack/collectd-ceilometer-plugin | +------------------+-------------------------------------------------------------------------+ |congress |git://git.openstack.org/openstack/congress | +------------------+-------------------------------------------------------------------------+ |cue |git://git.openstack.org/openstack/cue | +------------------+-------------------------------------------------------------------------+ |designate |git://git.openstack.org/openstack/designate | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-am|git://git.openstack.org/openstack/devstack-plugin-amqp1 | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-bd|git://git.openstack.org/openstack/devstack-plugin-bdd | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-ce|git://git.openstack.org/openstack/devstack-plugin-ceph | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-gl|git://git.openstack.org/openstack/devstack-plugin-glusterfs | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-hd|git://git.openstack.org/openstack/devstack-plugin-hdfs | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-pi|git://git.openstack.org/openstack/devstack-plugin-pika | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-sh|git://git.openstack.org/openstack/devstack-plugin-sheepdog | +------------------+-------------------------------------------------------------------------+ |devstack-plugin-zm|git://git.openstack.org/openstack/devstack-plugin-zmq | +------------------+-------------------------------------------------------------------------+ |dragonflow |git://git.openstack.org/openstack/dragonflow | +------------------+-------------------------------------------------------------------------+ |drbd-devstack |git://git.openstack.org/openstack/drbd-devstack | +------------------+-------------------------------------------------------------------------+ |ec2-api |git://git.openstack.org/openstack/ec2-api | +------------------+-------------------------------------------------------------------------+ |freezer |git://git.openstack.org/openstack/freezer | +------------------+-------------------------------------------------------------------------+ |freezer-api |git://git.openstack.org/openstack/freezer-api | +------------------+-------------------------------------------------------------------------+ |freezer-web-ui |git://git.openstack.org/openstack/freezer-web-ui | +------------------+-------------------------------------------------------------------------+ |gce-api |git://git.openstack.org/openstack/gce-api | +------------------+-------------------------------------------------------------------------+ |gnocchi |git://git.openstack.org/openstack/gnocchi | +------------------+-------------------------------------------------------------------------+ |ironic |git://git.openstack.org/openstack/ironic | +------------------+-------------------------------------------------------------------------+ |ironic-inspector |git://git.openstack.org/openstack/ironic-inspector | +------------------+-------------------------------------------------------------------------+ |kingbird |git://git.openstack.org/openstack/kingbird | +------------------+-------------------------------------------------------------------------+ |kuryr |git://git.openstack.org/openstack/kuryr | +------------------+-------------------------------------------------------------------------+ |magnum |git://git.openstack.org/openstack/magnum | +------------------+-------------------------------------------------------------------------+ |manila |git://git.openstack.org/openstack/manila | +------------------+-------------------------------------------------------------------------+ |mistral |git://git.openstack.org/openstack/mistral | +------------------+-------------------------------------------------------------------------+ |monasca-api |git://git.openstack.org/openstack/monasca-api | +------------------+-------------------------------------------------------------------------+ |murano |git://git.openstack.org/openstack/murano | +------------------+-------------------------------------------------------------------------+ |networking-6wind |git://git.openstack.org/openstack/networking-6wind | +------------------+-------------------------------------------------------------------------+ |networking-bagpipe|git://git.openstack.org/openstack/networking-bagpipe | +------------------+-------------------------------------------------------------------------+ |networking-bgpvpn |git://git.openstack.org/openstack/networking-bgpvpn | +------------------+-------------------------------------------------------------------------+ |networking-calico |git://git.openstack.org/openstack/networking-calico | +------------------+-------------------------------------------------------------------------+ |networking-cisco |git://git.openstack.org/openstack/networking-cisco | +------------------+-------------------------------------------------------------------------+ |networking-fortine|git://git.openstack.org/openstack/networking-fortinet | +------------------+-------------------------------------------------------------------------+ |networking-generic|git://git.openstack.org/openstack/networking-generic-switch | +------------------+-------------------------------------------------------------------------+ |networking-infoblo|git://git.openstack.org/openstack/networking-infoblox | +------------------+-------------------------------------------------------------------------+ |networking-l2gw |git://git.openstack.org/openstack/networking-l2gw | +------------------+-------------------------------------------------------------------------+ |networking-midonet|git://git.openstack.org/openstack/networking-midonet | +------------------+-------------------------------------------------------------------------+ |networking-mlnx |git://git.openstack.org/openstack/networking-mlnx | +------------------+-------------------------------------------------------------------------+ |networking-nec |git://git.openstack.org/openstack/networking-nec | +------------------+-------------------------------------------------------------------------+ |networking-odl |git://git.openstack.org/openstack/networking-odl | +------------------+-------------------------------------------------------------------------+ |networking-ofagent|git://git.openstack.org/openstack/networking-ofagent | +------------------+-------------------------------------------------------------------------+ |networking-ovn |git://git.openstack.org/openstack/networking-ovn | +------------------+-------------------------------------------------------------------------+ |networking-ovs-dpd|git://git.openstack.org/openstack/networking-ovs-dpdk | +------------------+-------------------------------------------------------------------------+ |networking-plumgri|git://git.openstack.org/openstack/networking-plumgrid | +------------------+-------------------------------------------------------------------------+ |networking-powervm|git://git.openstack.org/openstack/networking-powervm | +------------------+-------------------------------------------------------------------------+ |networking-sfc |git://git.openstack.org/openstack/networking-sfc | +------------------+-------------------------------------------------------------------------+ |networking-vsphere|git://git.openstack.org/openstack/networking-vsphere | +------------------+-------------------------------------------------------------------------+ |neutron |git://git.openstack.org/openstack/neutron | +------------------+-------------------------------------------------------------------------+ |neutron-lbaas |git://git.openstack.org/openstack/neutron-lbaas | +------------------+-------------------------------------------------------------------------+ |neutron-lbaas-dash|git://git.openstack.org/openstack/neutron-lbaas-dashboard | +------------------+-------------------------------------------------------------------------+ |neutron-vpnaas |git://git.openstack.org/openstack/neutron-vpnaas | +------------------+-------------------------------------------------------------------------+ |nova-docker |git://git.openstack.org/openstack/nova-docker | +------------------+-------------------------------------------------------------------------+ |nova-powervm |git://git.openstack.org/openstack/nova-powervm | +------------------+-------------------------------------------------------------------------+ |octavia |git://git.openstack.org/openstack/octavia | +------------------+-------------------------------------------------------------------------+ |osprofiler |git://git.openstack.org/openstack/osprofiler | +------------------+-------------------------------------------------------------------------+ |rally |git://git.openstack.org/openstack/rally | +------------------+-------------------------------------------------------------------------+ |sahara |git://git.openstack.org/openstack/sahara | +------------------+-------------------------------------------------------------------------+ |sahara-dashboard |git://git.openstack.org/openstack/sahara-dashboard | +------------------+-------------------------------------------------------------------------+ |scalpels |git://git.openstack.org/openstack/scalpels | +------------------+-------------------------------------------------------------------------+ |searchlight |git://git.openstack.org/openstack/searchlight | +------------------+-------------------------------------------------------------------------+ |senlin |git://git.openstack.org/openstack/senlin | +------------------+-------------------------------------------------------------------------+ |smaug |git://git.openstack.org/openstack/smaug | +------------------+-------------------------------------------------------------------------+ |solum |git://git.openstack.org/openstack/solum | +------------------+-------------------------------------------------------------------------+ |tacker |git://git.openstack.org/openstack/tacker | +------------------+-------------------------------------------------------------------------+ |tap-as-a-service |git://git.openstack.org/openstack/tap-as-a-service | +------------------+-------------------------------------------------------------------------+ |tricircle |git://git.openstack.org/openstack/tricircle | +------------------+-------------------------------------------------------------------------+ |trove |git://git.openstack.org/openstack/trove | +------------------+-------------------------------------------------------------------------+ |trove-dashboard |git://git.openstack.org/openstack/trove-dashboard | +------------------+-------------------------------------------------------------------------+ |vitrage |git://git.openstack.org/openstack/vitrage | +------------------+-------------------------------------------------------------------------+ |vitrage-dashboard |git://git.openstack.org/openstack/vitrage-dashboard | +------------------+-------------------------------------------------------------------------+ |vmware-nsx |git://git.openstack.org/openstack/vmware-nsx | +------------------+-------------------------------------------------------------------------+ |watcher |git://git.openstack.org/openstack/watcher | +------------------+-------------------------------------------------------------------------+ |watcher-dashboard |git://git.openstack.org/openstack/watcher-dashboard | +------------------+-------------------------------------------------------------------------+ |zaqar |git://git.openstack.org/openstack/zaqar | +------------------+-------------------------------------------------------------------------+",".. Note to reviewers: the intent of this file is to be easy for community members to update. As such fast approving (single core +2) is fine as long as you've identified that the plugin listed actually exists. Official OpenStack Projects =========================== The following are plugins that exist for official OpenStack projects. +------------------+---------------------------------------------+--------------------+ |Plugin Name |URL |Comments | +------------------+---------------------------------------------+--------------------+ |aodh |git://git.openstack.org/openstack/aodh | alarming | +------------------+---------------------------------------------+--------------------+ |barbican |git://git.openstack.org/openstack/barbican | key management | +------------------+---------------------------------------------+--------------------+ |ceilometer |git://git.openstack.org/openstack/ceilometer | metering | +------------------+---------------------------------------------+--------------------+ |congress |git://git.openstack.org/openstack/congress | governance | +------------------+---------------------------------------------+--------------------+ |cue |git://git.openstack.org/openstack/cue | message-broker | +------------------+---------------------------------------------+--------------------+ |gnocchi |git://git.openstack.org/openstack/gnocchi | metric | +------------------+---------------------------------------------+--------------------+ |ironic |git://git.openstack.org/openstack/ironic | baremetal | +------------------+---------------------------------------------+--------------------+ |magnum |git://git.openstack.org/openstack/magnum | | +------------------+---------------------------------------------+--------------------+ |manila |git://git.openstack.org/openstack/manila | file shares | +------------------+---------------------------------------------+--------------------+ |mistral |git://git.openstack.org/openstack/mistral | | +------------------+---------------------------------------------+--------------------+ |rally |git://git.openstack.org/openstack/rally | | +------------------+---------------------------------------------+--------------------+ |sahara |git://git.openstack.org/openstack/sahara | | +------------------+---------------------------------------------+--------------------+ |trove |git://git.openstack.org/openstack/trove | | +------------------+---------------------------------------------+--------------------+ |zaqar |git://git.openstack.org/openstack/zaqar | | +------------------+---------------------------------------------+--------------------+ Additional Services =================== +-----------------+------------------------------------------------------------+------------+ | Plugin Name | URL | Comments | | | | | +-----------------+------------------------------------------------------------+------------+ |amqp1 |git://git.openstack.org/openstack/devstack-plugin-amqp1 | | +-----------------+------------------------------------------------------------+------------+ |bdd |git://git.openstack.org/openstack/devstack-plugin-bdd | | +-----------------+------------------------------------------------------------+------------+ |ec2-api |git://git.openstack.org/openstack/ec2-api |[as1]_ | +-----------------+------------------------------------------------------------+------------+ |glusterfs |git://git.openstack.org/openstack/devstack-plugin-glusterfs | | +-----------------+------------------------------------------------------------+------------+ |hdfs |git://git.openstack.org/openstack/devstack-plugin-hdfs | | +-----------------+------------------------------------------------------------+------------+ |ironic-inspector |git://git.openstack.org/openstack/ironic-inspector | | +-----------------+------------------------------------------------------------+------------+ |pika |git://git.openstack.org/openstack/devstack-plugin-pika | | +-----------------+------------------------------------------------------------+------------+ |sheepdog |git://git.openstack.org/openstack/devstack-plugin-sheepdog | | +-----------------+------------------------------------------------------------+------------+ |zmq |git://git.openstack.org/openstack/devstack-plugin-zmq | | +-----------------+------------------------------------------------------------+------------+ | | | | +-----------------+------------------------------------------------------------+------------+ .. [as1] first functional devstack plugin, hence why used in most of the examples.",178,72
openstack%2Fmanila~master~I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e,openstack/manila,master,I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e,Improve exception msg when attaching/detaching volumes,MERGED,2016-02-19 08:15:45.000000000,2016-03-07 02:00:46.000000000,2016-02-27 04:38:30.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 7872}, {'_account_id': 8851}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18602}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-19 08:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1a278c850c75c3d9982f156d99dc159d40abb580', 'message': 'Improve exception msg when attaching/detaching volumes\n\nWhen something goes wrong in the generic drivers attach/detach\nvolume handing, be more verbose and also show the volume-id in the\nexception.\n\nChange-Id: I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e\n'}, {'number': 2, 'created': '2016-02-22 09:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f5c7d65ca92d98de873ec5de13bf471763d42046', 'message': 'Improve exception msg when attaching/detaching volumes\n\nWhen something goes wrong in the generic drivers attach/detach\nvolume handing, be more verbose and also show the volume-id in the\nexception.\n\nChange-Id: I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e\n'}, {'number': 3, 'created': '2016-02-22 14:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/86936c2619afbe740194097daa4323e582bc79d6', 'message': 'Improve exception msg when attaching/detaching volumes\n\nWhen something goes wrong in the generic drivers attach/detach\nvolume handing, be more verbose and also show the volume-id in the\nexception.\n\nChange-Id: I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e\n'}, {'number': 4, 'created': '2016-02-25 10:33:27.000000000', 'files': ['manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/68fd502c4d123dc57c5fdd20915446d9f4db588d', 'message': 'Improve exception msg when attaching/detaching volumes\n\nWhen something goes wrong in the generic drivers attach/detach\nvolume handing, be more verbose and also show the volume-id in the\nexception.\n\nChange-Id: I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e\n'}]",19,282220,68fd502c4d123dc57c5fdd20915446d9f4db588d,78,21,4,7102,,,0,"Improve exception msg when attaching/detaching volumes

When something goes wrong in the generic drivers attach/detach
volume handing, be more verbose and also show the volume-id in the
exception.

Change-Id: I03176801bf6f0d76a2d82b94ba6c1d5ee8f6193e
",git fetch https://review.opendev.org/openstack/manila refs/changes/20/282220/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/generic.py'],1,1a278c850c75c3d9982f156d99dc159d40abb580,282220," msg_dict = dict(volume_id=volume['id'], max_time=self.configuration.max_time_to_attach) _('Volume %(volume_id)s have not been attached in ' '%(max_time)ss. Giving up') % msg_dict) msg_dict = dict( volume_id=volume['id'], max_time=self.configuration.max_time_to_attach ) _('Volume %(volume_id)s have not been detached in ' '%(max_time)ss. Giving up') % msg_dict)", _('Volume have not been attached in %ss. Giving up') % self.configuration.max_time_to_attach) _('Volume have not been detached in %ss. Giving up') % self.configuration.max_time_to_attach),10,4
openstack%2Fproject-config~master~Ib641e0fb5458a5d3ba68038264596a22b61aedd1,openstack/project-config,master,Ib641e0fb5458a5d3ba68038264596a22b61aedd1,Remove experimental bindep infra jobs,MERGED,2016-03-05 13:39:38.000000000,2016-03-07 01:58:41.000000000,2016-03-07 01:58:40.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-05 13:39:38.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7c55b59431ae59be9950cef0e1b6e5510a1269a2', 'message': 'Remove experimental bindep infra jobs\n\nWe can safely remove these now that infra is running under\nubuntu-trusty.\n\nChange-Id: Ib641e0fb5458a5d3ba68038264596a22b61aedd1\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,288868,7c55b59431ae59be9950cef0e1b6e5510a1269a2,14,4,1,4162,,,0,"Remove experimental bindep infra jobs

We can safely remove these now that infra is running under
ubuntu-trusty.

Change-Id: Ib641e0fb5458a5d3ba68038264596a22b61aedd1
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/68/288868/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,7c55b59431ae59be9950cef0e1b6e5510a1269a2,bindep,, experimental: - gate-project-config-tox-gerrit-bindep - gate-project-config-tox-grafyaml-bindep - gate-project-config-tox-zuul-bindep - gate-project-config-tox-jenkins-project-bindep - gate-project-config-tox-nodepool-bindep - gate-project-config-tox-projects-bindep - gate-project-config-tox-irc-bindep - gate-project-config-tox-dib-bindep,0,25
openstack%2Fdragonflow~master~Id6353238d97d577a23f8038c8231a412b84f6732,openstack/dragonflow,master,Id6353238d97d577a23f8038c8231a412b84f6732,Add dev-ref for pub/sub service,MERGED,2016-02-29 12:22:40.000000000,2016-03-07 01:27:57.000000000,2016-03-07 01:27:57.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-29 12:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/407bd1c9255b9a992d775e687fb96225a7584489', 'message': 'Add dev-ref for pub/sub service\n\nAdd dev-ref for publisher/subscrive service, API, and infrastructure.\n\nChange-Id: Id6353238d97d577a23f8038c8231a412b84f6732\n'}, {'number': 2, 'created': '2016-03-02 13:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d33fa2915dc41a77c8c50df39ba948c31c11b813', 'message': 'Add dev-ref for pub/sub service\n\nAdd dev-ref for publisher/subscrive service, API, and infrastructure.\n\nChange-Id: Id6353238d97d577a23f8038c8231a412b84f6732\n'}, {'number': 3, 'created': '2016-03-03 05:23:48.000000000', 'files': ['doc/images/pubsub_neutron_API_server.graphml', 'doc/source/index.rst', 'doc/source/pluggable_pubsub.rst', 'doc/images/pubsub_topology.graphml', 'doc/images/pubsub_neutron_API_server.png', 'doc/images/pubsub_topology.png'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ca31f7660e1277f641681ba86adadb4c66f77936', 'message': 'Add dev-ref for pub/sub service\n\nAdd dev-ref for publisher/subscrive service, API, and infrastructure.\n\nChange-Id: Id6353238d97d577a23f8038c8231a412b84f6732\n'}]",5,286006,ca31f7660e1277f641681ba86adadb4c66f77936,14,4,3,20229,,,0,"Add dev-ref for pub/sub service

Add dev-ref for publisher/subscrive service, API, and infrastructure.

Change-Id: Id6353238d97d577a23f8038c8231a412b84f6732
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/06/286006/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/pluggable_pubsub.rst'],1,407bd1c9255b9a992d775e687fb96225a7584489,pubsub,"========================================== Pluggable Publish-Subscribe Infrastructure ========================================== This document described the pluggable API for publish-subscribe and publish-subscribe drivers. For the design, see the `spec publish_subscribe_abstraction`__. __ SPEC_ Instead of relying on the DB driver to support reliable publish-subscribe, we allow pub/sub mechanisms to be integrated to Dragonflow in a pluggable way. There are several Neutron API servers, and many compute nodes. Every compute node registers as a subscriber to every Neutron API server, which acts as a publisher. This can be seen in the following diagram: :: Neutron API servers +-----------+ +-----------+ | | | | | | X X X | | | | | | +-----------+ +-----------+ | | | | | +-------------------------------+ | | | +-----------------------+ | +----+ +----+ | | X X X X X X | | | | | | +----+ +----+ Compute Nodes with Dragonflow controller Additionally, the Neutron server service is forked per the number of cores on the server. Since some publishers need to bind to a TCP socket, and we will want to run monitoring services that need to run only once per server, and not once per core, we provide a *publisher service*. :: Neutron API server +-----------------------------------+ | | | | | +----+ +-------+ | | |CPU +-+Neutron| +---------+ ++-----+ | |core| |service+-----+Publisher+-+TCP | | +----+ +-------+ |service | |socket| | ++--------+ ++-----+ | X | | | | | | X | | | | | | X | | | | | | +----+ +-------+ | | | |CPU +-+Neutron+------+ | | |core| |service| | | +----+ +-------+ | | | +-----------------------------------+ Therefore the communications between the Neutron service and the publisher service requires an inter-process communications (IPC) solution. This can also be solved using a publish-subscribe mechanism. Therefore, there are two publish-subscribe implementations - a network-based implementation between Neutron server and Compute node, and an IPC-based implementation between Neutron services and the publisher service. === API === For simplicity, the API for both implementations is the same. It can be found in ``dragonflow/db/pub_sub_api.py`` (`Link`__). It is recommended to read the code to fully understand the API. __ _PUB_SUB_API For both network and IPC based communication, a driver has to implement ``dragonflow.db.pub_sub_api.PubSubApi`` (`Link`__). In both cases, ``get_publisher`` and ``get_subscriber`` return a ``dragonflow.db.pub_sub_api.PublisherApi`` and a ``dragonflow.db.pub_sub_api.SubscriberApi``, respectively. __ _PUB_SUB_API The class ``dragonflow.db.pub_sub_api.SubscriberAgentBase`` provides a starting point for implementing subscribers. Since the publisher API only requires an initialisation and event-sending method, both very implementation specific, no such base class is provided. ============= Configuration ============= The following parameters allows configuration of the publish-subscribe mechanism. Only parameters which need to be handled by the publish-subscribe drivers are listed here. For a full list, refer to ``dragonflow/common/common_params.py`` (`Link`__). __ _COMMON_PARAMS 1. pub_sub_driver - The alias to the class implementing ``PubSubApi`` for network-based pub/sub. 2. pub_sub_multiproc_driver - The alias to the class implementing ``PubSubApi`` for IPC-based pub/sub. 3. publisher_port - The port to which the network publisher should bind. It is also the port the network subscribers connect. 4. publisher_transport - The transport protocol (e.g. TCP, UDP) over which pub/sub netwrok communication is passed. 5. publisher_bind_address - The local address to which the network publisher should bind. '*' means all addresses. 6. publisher_multiproc_socket - The local socket over which the multi-proc pub/sub implementation should communicate. The actual value is implementation specific, since different implementations may use different IPC mechanisms. ======================== Reference Implementation ======================== ZeroMQ is used as a base for the reference implementation. The reference implementation can be found in ``dragonflow/db/pubsub_drivers/zmq_pubsub_driver.py`` (`Link`__). __ _ZMQ_DRIVER In it, there are two implementations of ``PubSubApi``: 1. ZMQPubSub - For the network implementation 2. ZMQPubSubMultiproc - For the IPC implementation. In both cases, extensions of ``ZMQPublisherAgentBase`` and ``ZMQSubscriberAgentBase`` are returned. In the case of subscriber, the only difference is in the implementation of ``connect``. Since the IPC implementation connects on ZMQ's *ipc* protocol, and the network implementation connects over the transport protocol provided via *publisher_transport*. In the case of the publisher, the difference is both in the implementation of ``initialize``, ``_connect``, and ``send_event``. The difference in connect is for the same reasons as the subscribers. The difference in ``initialize`` is since the multi-proc subscriber uses the lazy initialization pattern. This also accounts for the difference in ``send_event``. ========== References ========== .. _SPEC: https://raw.githubusercontent.com/openstack/dragonflow/master/doc/source/specs/publish_subscribe_abstraction.rst .. _PUB_SUB_API: https://github.com/openstack/dragonflow/tree/master/dragonflow/db/pub_sub_api.py .. _COMMON_PARAMS: https://github.com/openstack/dragonflow/tree/master/dragonflow/common/common_params.py .. _ZMQ_DRIVER: https://github.com/openstack/dragonflow/tree/master/dragonflow/db/pubsub_drivers/zmp_pubsub_driver.py [spec] https://raw.githubusercontent.com/openstack/dragonflow/master/doc/source/specs/publish_subscribe_abstraction.rst [pub_sub_api.py] https://github.com/openstack/dragonflow/tree/master/dragonflow/db/pub_sub_api.py [common_params.py] https://github.com/openstack/dragonflow/tree/master/dragonflow/common/common_params.py [zmq_pubsub_driver.py] https://github.com/openstack/dragonflow/tree/master/dragonflow/db/pubsub_drivers/zmp_pubsub_driver.py ",,175,0
openstack%2Fpython-magnumclient~master~I96be4305476ea74b4a2931fab550e8c21f1c8fad,openstack/python-magnumclient,master,I96be4305476ea74b4a2931fab550e8c21f1c8fad,Use six.u instead of u'',MERGED,2016-03-03 02:50:03.000000000,2016-03-07 01:19:55.000000000,2016-03-07 01:19:55.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-03-03 02:50:03.000000000', 'files': ['magnumclient/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/df0839349157c99d237759bf8e4871cf3c504c77', 'message': ""Use six.u instead of u''\n\nThere's no u'' in python3.4, strings are always unicode or bytes in\npython3. use six.u() to convert strings.\n\nChange-Id: I96be4305476ea74b4a2931fab550e8c21f1c8fad\n""}]",0,287567,df0839349157c99d237759bf8e4871cf3c504c77,7,3,1,19133,,,0,"Use six.u instead of u''

There's no u'' in python3.4, strings are always unicode or bytes in
python3. use six.u() to convert strings.

Change-Id: I96be4305476ea74b4a2931fab550e8c21f1c8fad
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/67/287567/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/tests/test_utils.py'],1,df0839349157c99d237759bf8e4871cf3c504c77,bug/1545957," dict_in = {six.u('a'): six.u('1'), six.u('b'): {six.u('x'): 1, 'y': six.u('2'), six.u('z'): six.u('3')}, 'c': 7}"," dict_in = {u'a': u'1', u'b': {u'x': 1, 'y': u'2', u'z': u'3'}, 'c': 7}",5,1
openstack%2Fproject-config~master~I4df78c3d542758ce6159c195c1407f1d56f565a0,openstack/project-config,master,I4df78c3d542758ce6159c195c1407f1d56f565a0,Don't cache inactive repos,MERGED,2016-03-06 02:02:05.000000000,2016-03-07 01:12:27.000000000,2016-03-07 01:12:25.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-06 02:02:05.000000000', 'files': ['nodepool/scripts/cache_git_repos.py', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list'], 'web_link': 'https://opendev.org/openstack/project-config/commit/69a073edbe60befa87ae1ed454399f6f92537bdc', 'message': ""Don't cache inactive repos\n\nWe have attic and stackforge projects all of which are now inactive.\nBecause they are inactive we don't need to be caching these repos on\nevery test slave image.\n\nChange-Id: I4df78c3d542758ce6159c195c1407f1d56f565a0\n""}]",0,288958,69a073edbe60befa87ae1ed454399f6f92537bdc,8,3,1,4146,,,0,"Don't cache inactive repos

We have attic and stackforge projects all of which are now inactive.
Because they are inactive we don't need to be caching these repos on
every test slave image.

Change-Id: I4df78c3d542758ce6159c195c1407f1d56f565a0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/58/288958/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/scripts/cache_git_repos.py', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list']",2,69a073edbe60befa87ae1ed454399f6f92537bdc,git-caching," # Skip repos that are inactive dirname = os.path.dirname(project) if not ('attic' in dirname or dirname == 'stackforge'): args = dict( name=os.path.basename(project), location=os.path.join('/opt/git', project), url='%s/%s.git' % (GIT_BASE, project)) projects_list.write(""%(name)s git %(location)s "" ""%(url)s\n"" % args)"," args = dict( name=os.path.basename(project), location=os.path.join('/opt/git', project), url='%s/%s.git' % (GIT_BASE, project)) projects_list.write(""%(name)s git %(location)s %(url)s\n"" % args)",19,11
openstack%2Fdevstack~master~Ieeed58751e5784020e04bcc2911ac74791662110,openstack/devstack,master,Ieeed58751e5784020e04bcc2911ac74791662110,Update account generator calls with correct password,MERGED,2016-03-04 15:40:23.000000000,2016-03-07 01:03:39.000000000,2016-03-07 01:03:39.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-04 15:40:23.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6cf412bb7ee2f667c38cf113440018b1ffcc7546', 'message': 'Update account generator calls with correct password\n\nChange I380dd20e5ed716a0bdf92aa02c3730359b8136e4 updated the tempest\nconfiguration to stop creating a bunch of globals. But as part of\nthat refactor it started using $admin_password as the password\nargument for tempest-account generator, which is never defined.\nThis commit rectifies the situation by using the correct variable\n$password.\n\nChange-Id: Ieeed58751e5784020e04bcc2911ac74791662110\n'}]",0,288532,6cf412bb7ee2f667c38cf113440018b1ffcc7546,12,3,1,5196,,,0,"Update account generator calls with correct password

Change I380dd20e5ed716a0bdf92aa02c3730359b8136e4 updated the tempest
configuration to stop creating a bunch of globals. But as part of
that refactor it started using $admin_password as the password
argument for tempest-account generator, which is never defined.
This commit rectifies the situation by using the correct variable
$password.

Change-Id: Ieeed58751e5784020e04bcc2911ac74791662110
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/288532/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,6cf412bb7ee2f667c38cf113440018b1ffcc7546,," tempest-account-generator -c $TEMPEST_CONFIG --os-username $admin_username --os-password ""$password"" --os-tenant-name $admin_tenant_name -r $TEMPEST_CONCURRENCY --with-admin etc/accounts.yaml tempest-account-generator -c $TEMPEST_CONFIG --os-username $admin_username --os-password ""$password"" --os-tenant-name $admin_tenant_name -r $TEMPEST_CONCURRENCY etc/accounts.yaml", tempest-account-generator -c $TEMPEST_CONFIG --os-username $admin_username --os-password $admin_password --os-tenant-name $admin_tenant_name -r $TEMPEST_CONCURRENCY --with-admin etc/accounts.yaml tempest-account-generator -c $TEMPEST_CONFIG --os-username $admin_username --os-password $admin_password --os-tenant-name $admin_tenant_name -r $TEMPEST_CONCURRENCY etc/accounts.yaml,2,2
openstack%2Fdevstack~master~I346b59705c5b0716a18087f6800f568fb1f4c9a8,openstack/devstack,master,I346b59705c5b0716a18087f6800f568fb1f4c9a8,Remove devstack plugins proposal job footer,MERGED,2016-03-01 15:37:02.000000000,2016-03-07 01:01:02.000000000,2016-03-07 01:00:59.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16272}, {'_account_id': 17377}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-03-01 15:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9dc509e8300f224b2d2b01da2dfdc2758ca091e5', 'message': 'Add ""Additional Services"" to devstack plugins proposal job footer\n\nChange I336a4c652a78e778e39652f1f16ff69be10ab065 introduced a\nsection called ""Additional Services"". This copies this over to\nthe footer so the proposal job won\'t try to delete it.\n\nChange-Id: I346b59705c5b0716a18087f6800f568fb1f4c9a8\n'}, {'number': 2, 'created': '2016-03-04 19:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1d18f76b2740bc0ad53f061d24d4281ae69433a2', 'message': ""Remove content from devstack plugins proposal job footer\n\nAside from notes, the content of the footer is entirely redundant\nwith the detected plugins list, so let's just leave the footer\nblank for now.\n\nChange-Id: I346b59705c5b0716a18087f6800f568fb1f4c9a8\n""}, {'number': 3, 'created': '2016-03-04 20:43:50.000000000', 'files': ['data/devstack-plugins-registry.footer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4b186badaadc07fc4478c77988489d31d9375de7', 'message': ""Remove devstack plugins proposal job footer\n\nAside from notes, the content of the footer is entirely redundant\nwith the detected plugins list, so let's remove it.\n\nChange-Id: I346b59705c5b0716a18087f6800f568fb1f4c9a8\n""}]",0,286662,4b186badaadc07fc4478c77988489d31d9375de7,21,8,3,16272,,,0,"Remove devstack plugins proposal job footer

Aside from notes, the content of the footer is entirely redundant
with the detected plugins list, so let's remove it.

Change-Id: I346b59705c5b0716a18087f6800f568fb1f4c9a8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/286662/2 && git format-patch -1 --stdout FETCH_HEAD,['data/devstack-plugins-registry.footer'],1,9dc509e8300f224b2d2b01da2dfdc2758ca091e5,autogen-devstack-plugins-list," Additional Services =================== +-----------------+------------------------------------------------------------+------------+ | Plugin Name | URL | Comments | | | | | +-----------------+------------------------------------------------------------+------------+ |amqp1 |git://git.openstack.org/openstack/devstack-plugin-amqp1 | | +-----------------+------------------------------------------------------------+------------+ |bdd |git://git.openstack.org/openstack/devstack-plugin-bdd | | +-----------------+------------------------------------------------------------+------------+ |ec2-api |git://git.openstack.org/openstack/ec2-api |[as1]_ | +-----------------+------------------------------------------------------------+------------+ |glusterfs |git://git.openstack.org/openstack/devstack-plugin-glusterfs | | +-----------------+------------------------------------------------------------+------------+ |hdfs |git://git.openstack.org/openstack/devstack-plugin-hdfs | | +-----------------+------------------------------------------------------------+------------+ |ironic-inspector |git://git.openstack.org/openstack/ironic-inspector | | +-----------------+------------------------------------------------------------+------------+ |pika |git://git.openstack.org/openstack/devstack-plugin-pika | | +-----------------+------------------------------------------------------------+------------+ |sheepdog |git://git.openstack.org/openstack/devstack-plugin-sheepdog | | +-----------------+------------------------------------------------------------+------------+ |zmq |git://git.openstack.org/openstack/devstack-plugin-zmq | | +-----------------+------------------------------------------------------------+------------+ | | | | +-----------------+------------------------------------------------------------+------------+ .. [as1] first functional devstack plugin, hence why used in most of the examples.",,31,0
openstack%2Fapi-site~master~I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8,openstack/api-site,master,I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8,Optimized getting_started.rb to perfect Ruby style.,MERGED,2016-02-18 17:36:46.000000000,2016-03-07 01:00:31.000000000,2016-03-07 01:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10068}, {'_account_id': 10134}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-18 17:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/7091774a66153485b5960721e6cfcc439c01dd14', 'message': 'Optimized getting_started.rb to perfect Ruby style.\n\nChange-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8\n'}, {'number': 2, 'created': '2016-02-18 21:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/3f1cadaf54ae424c9a646ee60cff924b30c2c849', 'message': 'Optimized getting_started.rb to perfect Ruby style.\n\nChange-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8\n'}, {'number': 3, 'created': '2016-02-19 10:38:50.000000000', 'files': ['firstapp/samples/fog/block_storage.rb', 'firstapp/samples/fog/getting_started.rb', 'firstapp/samples/fog/durability.rb', 'firstapp/samples/fog/scaling_out.rb', 'firstapp/samples/fog/introduction.rb'], 'web_link': 'https://opendev.org/openstack/api-site/commit/25d54b1d4506177eb9b6ab7f9daad5d899dff4dd', 'message': 'Optimized getting_started.rb to perfect Ruby style.\n\nChange-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8\n\nOptimized all samples for Ruby Fog.\n\nChange-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8\n'}]",0,281975,25d54b1d4506177eb9b6ab7f9daad5d899dff4dd,17,5,3,20636,,,0,"Optimized getting_started.rb to perfect Ruby style.

Change-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8

Optimized all samples for Ruby Fog.

Change-Id: I043a310e7b7b5c22d1ad4c8bf9b53007227f48d8
",git fetch https://review.opendev.org/openstack/api-site refs/changes/75/281975/1 && git format-patch -1 --stdout FETCH_HEAD,['firstapp/samples/fog/getting_started.rb'],1,7091774a66153485b5960721e6cfcc439c01dd14,samples/ruby-fog,"#!/usr/bin/env ruby# step-1 auth_username = ""your_auth_username"" auth_password = ""your_auth_password"" auth_url = ""http://controller:5000"" project_name = ""your_project_name_or_id"" conn = Fog::Compute::OpenStack.new({ openstack_auth_url: auth_url + ""/v3/auth/tokens"", openstack_domain_id: ""default"", openstack_username: auth_username, openstack_api_key: auth_password, openstack_project_name: project_name })p conn.images.allp conn.flavors.allimage = conn.images.get(""2cccbea0-cea9-4f86-a3ed-065c652adda5"") p imageflavor = conn.flavors.get(""2"") p flavorinstance_name = ""testing"" testing_instance = conn.servers.create({ name: instance_name, image_ref: image.id, flavor_ref: flavor.id }) testing_instance.wait_for {testing_instance.ready?} p testing_instancep conn.servers.allputs ""Checking for existing SSH key pair...""if key_pair = conn.key_pairs.get(key_pair_name) puts ""Keypair #{key_pair_name} already exists. Skipping import."" else puts ""adding keypair..."" key_pair = conn.key_pairs.create({ name: key_pair_name, public_key: File.read(File.expand_path(pub_key_file)) })p conn.key_pairs.allputs ""Checking for existing security group..."" security_group_name = ""all-in-one"" if all_in_one_security_group = conn.security_groups.find {|security_group| security_group.name == security_group_name} puts ""Security Group #{security_group_name} already exists. Skipping creation."" else all_in_one_security_group = conn.security_groups.create({ name: security_group_name, description: ""network access for all-in-one application."" }) conn.security_group_rules.create({ parent_group_id: all_in_one_security_group.id, ip_protocol: ""tcp"", from_port: 80, to_port: 80 }) conn.security_group_rules.create({ parent_group_id: all_in_one_security_group.id, ip_protocol: ""tcp"", from_port: 22, to_port: 22 })p conn.security_groups.alluser_data = <<END #!/usr/bin/env bash curl -L -s http://git.openstack.org/cgit/openstack/faafo/plain/contrib/install.sh | bash -s -- \ -i faafo -i messaging -r api -r worker -r demo ENDputs ""Checking for existing instance..."" instance_name = ""all-in-one"" if testing_instance = conn.servers.find {|instance| instance.name == instance_name} puts ""Instance #{instance_name} already exists. Skipping creation."" else testing_instance = conn.servers.create({ name: instance_name, image_ref: image.id, flavor_ref: flavor.id, key_name: key_pair.name, user_data: user_data, security_groups: all_in_one_security_group }) testing_instance.wait_for {testing_instance.ready?}p conn.servers.allputs ""Private IP found: #{private_ip_address}"" if private_ip_address ||= testing_instance.private_ip_addressputs ""Public IP found: #{floating_ip_address}"" if floating_ip_address ||= testing_instance.floating_ip_addressputs ""Checking for unused Floating IP..."" unless unused_floating_ip_address = conn.addresses.find {|address| address.instance_id.nil?} pool_name = conn.addresses.get_address_pools[0][""name""] puts ""Allocating new Floating IP from pool: #{pool_name}"" unused_floating_ip_address = conn.addresses.create({ pool: pool_name }) end # step-16 if floating_ip_address puts ""Instance #{testing_instance.name} already has a public ip. Skipping attachment."" elsif unused_floating_ip_address unused_floating_ip_address.server = testing_instance end # step-17 actual_ip_address = floating_ip_address || unused_floating_ip_address || private_ip_address puts ""The Fractals app will be deployed to http://#{actual_ip_address.ip}""","# step-1auth_username = 'your_auth_username' auth_password = 'your_auth_password' auth_url = 'http://controller:5000' project_name = 'your_project_name_or_id' region_name = 'your_region_name' conn = Fog::Compute.new({ :provider => 'openstack', :openstack_auth_url => auth_url + '/v2.0/tokens', :openstack_username => auth_username, :openstack_tenant => project_name, :openstack_api_key => auth_password, })images = conn.images.all print imagesflavors = conn.flavors.all print flavorsimage_id = '2cccbea0-cea9-4f86-a3ed-065c652adda5' image = conn.images.get image_id print imageflavor_id = '3' flavor = conn.flavors.get flavor_id print flavorinstance_name = 'testing' testing_instance = conn.servers.create(:name => instance_name, :flavor_ref => flavor.id, :image_ref => image.id)print conn.serversputs ""Checking for existing SSH keypair"" for pair in conn.key_pairs.all() if pair.name == key_pair_name key_pair = pair puts ""Key pair \"""" + key_pair.name + ""\"" exists, skipping import"" break endif not key_pair puts ""Uploading keypair from ~/.ssh/id_rsa.pub"" key_file = File.open(File.expand_path(pub_key_file)) public_key = key_file.read key_pair = conn.key_pairs.create :name => key_pair_name, :public_key => public_key endfor security_group in conn.security_groups.all if security_group.name == 'all-in-one' all_in_one_security_group = security_group break endif not all_in_one_security_group conn.create_security_group 'all-in-one', 'network access for all-in-one application.' for security_group in conn.security_groups.all if security_group.name == 'all-in-one' all_in_one_security_group = security_group break end end conn.security_group_rules.create :ip_protocol => 'TCP', :from_port => 22, :to_port => 22, :parent_group_id => all_in_one_security_group.id conn.security_group_rules.create :ip_protocol => 'TCP', :from_port => 80, :to_port => 80, :parent_group_id => all_in_one_security_group.id enduserdata = ""#!/usr/bin/env bash curl -L -s https://git.openstack.org/cgit/openstack/faafo/plain/contrib/install.sh \ | bash -s -- \ -i faafo -i messaging -r api -r worker -r demo""puts ""Checking for existing instance"" for server in conn.servers.all if server.name == instance_name instance = server break endif not instance puts ""No test instance found, creating one now"" instance = conn.servers.create :name => instance_name, :flavor_ref => flavor.id, :image_ref => image.id, :key_name => key_pair.name, :user_data => userdata, :security_groups => all_in_one_security_group end until instance.ready? for server in conn.servers if server.name == instance.name instance = server break end end endputs ""Checking for unused Floating IP..."" for address in conn.addresses.all() if not address.instance_id ip_address = address puts ""Unused IP "" + ip_address.ip + "" found, it will be used instead of creating a new IP"" break end end if not ip_address puts ""Allocating new Floating IP"" ip_address = conn.addresses.create() endif instance.public_ip_addresses.length > 0 puts ""Instance already has a floating IP address"" else instance.associate_address(ip_address.ip) endputs ""Fractals app will be deployed to http://#{ip_address.ip}""",104,116
openstack%2Fapi-site~master~I11052a5e35c0918e89308a3efdba09309ab53ecb,openstack/api-site,master,I11052a5e35c0918e89308a3efdba09309ab53ecb,Add 'admin_state_up' parameter request table,MERGED,2016-02-24 16:42:45.000000000,2016-03-07 00:57:26.000000000,2016-03-07 00:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-24 16:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/3e8d93e618f6d9f23dae361c71df02a02abd6ba2', 'message': ""Add 'admin_state_up' parameter request table\n\nAdding the 'admin_state_up' parameter in the request table for\nLBass v2 Update LoadBalancer API in networking api reference.\n\nChange-Id: I11052a5e35c0918e89308a3efdba09309ab53ecb\nCloses-Bug: #1549343\n""}, {'number': 2, 'created': '2016-03-01 21:34:07.000000000', 'files': ['api-ref/src/wadls/networking-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/81fdb40c3d6ddfd97c2d168eb983f2ae41b1e1a0', 'message': ""Add 'admin_state_up' parameter request table\n\nAdding the 'admin_state_up' parameter in the request table for\nLBaaS v2 Update LoadBalancer API in networking api reference.\n\nChange-Id: I11052a5e35c0918e89308a3efdba09309ab53ecb\nCloses-Bug: #1549343\n""}]",0,284245,81fdb40c3d6ddfd97c2d168eb983f2ae41b1e1a0,9,3,2,19840,,,0,"Add 'admin_state_up' parameter request table

Adding the 'admin_state_up' parameter in the request table for
LBaaS v2 Update LoadBalancer API in networking api reference.

Change-Id: I11052a5e35c0918e89308a3efdba09309ab53ecb
Closes-Bug: #1549343
",git fetch https://review.opendev.org/openstack/api-site refs/changes/45/284245/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/networking-api/src/common.ent'],1,3e8d93e618f6d9f23dae361c71df02a02abd6ba2,bug/1549343,"<param xmlns=""http://wadl.dev.java.net/2009/02"" required=""false"" name=""admin_state_up"" style=""plain"" type=""xsd:boolean""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The administrative state of the load balancer, which is up (<code>true</code>) or down (<code>false</code>). </para> </wadl:doc> </param>",,11,0
openstack%2Fapi-site~master~I1ada58f6bd9251afc00b63e499e15506cc4d9ed9,openstack/api-site,master,I1ada58f6bd9251afc00b63e499e15506cc4d9ed9,"Glance: Image service API v2 page, ""Download binary image data"" API",MERGED,2016-02-24 05:57:16.000000000,2016-03-07 00:56:01.000000000,2016-03-07 00:56:01.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}, {'_account_id': 19853}]","[{'number': 1, 'created': '2016-02-24 05:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/4db163078cffe372b2278a07bae9b79b1540beff', 'message': 'Glance: Image service API v2 page, ""Download binary image data"" API\n\nThis patch updates ""Error response codes"" in ""Download binary image data"" API to include ""404 Not Found"" value.\n\nChange-Id: I1ada58f6bd9251afc00b63e499e15506cc4d9ed9\nCloses-Bug: #1548723\n'}, {'number': 2, 'created': '2016-02-24 05:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/249f609a04239553e9e26ebe1584757b20149e8a', 'message': 'Glance: Image service API v2 page, ""Download binary image data"" API\n\nThis patch updates ""Error response codes"" in ""Download binary image data""\nAPI to include ""404 Not Found"" value.\n\nChange-Id: I1ada58f6bd9251afc00b63e499e15506cc4d9ed9\nCloses-Bug: #1548723\n'}, {'number': 3, 'created': '2016-03-02 23:06:02.000000000', 'files': ['api-ref/src/wadls/image-api/src/v2/wadl/images-v2.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/e2a7a513c7b65c0d2731f86a44c8c9729f8ab95a', 'message': 'Glance: Image service API v2 page, ""Download binary image data"" API\n\nThis patch updates ""Error response codes"" in ""Download binary image data""\nAPI to include ""404 Not Found"" value.\n\nChange-Id: I1ada58f6bd9251afc00b63e499e15506cc4d9ed9\nCloses-Bug: #1548723\n'}]",1,283948,e2a7a513c7b65c0d2731f86a44c8c9729f8ab95a,15,4,3,19853,,,0,"Glance: Image service API v2 page, ""Download binary image data"" API

This patch updates ""Error response codes"" in ""Download binary image data""
API to include ""404 Not Found"" value.

Change-Id: I1ada58f6bd9251afc00b63e499e15506cc4d9ed9
Closes-Bug: #1548723
",git fetch https://review.opendev.org/openstack/api-site refs/changes/48/283948/3 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/image-api/src/v2/wadl/images-v2.wadl'],1,4db163078cffe372b2278a07bae9b79b1540beff,bug/1548723, &fault404;,,1,0
openstack%2Fneutron-fwaas~master~Ida30fe7903c77851d1723d71d63f090f032bfd61,openstack/neutron-fwaas,master,Ida30fe7903c77851d1723d71d63f090f032bfd61,WIP - DO NOT MERGE - testing experimental tempest tests,ABANDONED,2016-02-23 23:56:33.000000000,2016-03-07 00:47:24.000000000,,"[{'_account_id': 3}, {'_account_id': 14556}, {'_account_id': 15330}]","[{'number': 1, 'created': '2016-02-23 23:56:33.000000000', 'files': ['DO_NOT_MERGE'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/59ca336f0045f44d8841c1aea190c3057796c079', 'message': 'WIP - DO NOT MERGE - testing experimental tempest tests\n\nChange-Id: Ida30fe7903c77851d1723d71d63f090f032bfd61\n'}]",0,283871,59ca336f0045f44d8841c1aea190c3057796c079,6,3,1,14556,,,0,"WIP - DO NOT MERGE - testing experimental tempest tests

Change-Id: Ida30fe7903c77851d1723d71d63f090f032bfd61
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/71/283871/1 && git format-patch -1 --stdout FETCH_HEAD,['DO_NOT_MERGE'],1,59ca336f0045f44d8841c1aea190c3057796c079,, ,,2,0
openstack%2Fpython-searchlightclient~master~I7257ac74f6cba8cfd38455224a2f4eb7c3897406,openstack/python-searchlightclient,master,I7257ac74f6cba8cfd38455224a2f4eb7c3897406,Updated from global requirements,MERGED,2016-03-03 18:06:39.000000000,2016-03-07 00:47:09.000000000,2016-03-07 00:47:09.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 7665}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-03 18:06:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-searchlightclient/commit/9a9b32c53f20b902b2d88864c368b67c8694f504', 'message': 'Updated from global requirements\n\nChange-Id: I7257ac74f6cba8cfd38455224a2f4eb7c3897406\n'}]",0,288035,9a9b32c53f20b902b2d88864c368b67c8694f504,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I7257ac74f6cba8cfd38455224a2f4eb7c3897406
",git fetch https://review.opendev.org/openstack/python-searchlightclient refs/changes/35/288035/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9a9b32c53f20b902b2d88864c368b67c8694f504,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Fproject-config~master~I8792ea406796e0a37451f88d6550d74090f03f41,openstack/project-config,master,I8792ea406796e0a37451f88d6550d74090f03f41,Add FIP graphs to OSIC grafyaml,MERGED,2016-03-06 02:51:05.000000000,2016-03-07 00:30:58.000000000,2016-03-07 00:30:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-06 02:51:05.000000000', 'files': ['grafana/nodepool-osic.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5636a7058fc051695a82204013ca47a18da9192b', 'message': 'Add FIP graphs to OSIC grafyaml\n\nThis was missed when adding in the initial set of graphs.\n\nChange-Id: I8792ea406796e0a37451f88d6550d74090f03f41\n'}]",0,288967,5636a7058fc051695a82204013ca47a18da9192b,8,4,1,4146,,,0,"Add FIP graphs to OSIC grafyaml

This was missed when adding in the initial set of graphs.

Change-Id: I8792ea406796e0a37451f88d6550d74090f03f41
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/288967/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/nodepool-osic.yaml'],1,5636a7058fc051695a82204013ca47a18da9192b,osic-fip-graphs," - title: Create Floating IP type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.CreateFloatingIPTask.mean, '0.001'), 'Cloud 1') - title: Get Floating IP type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.GetFloatingIPTask.mean, '0.001'), 'Cloud 1') - title: Add Floating IP type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.AddFloatingIPTask.mean, '0.001'), 'Cloud 1') - title: Delete Floating IP type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.DeleteFloatingIPTask.mean, '0.001'), 'Cloud 1') - title: List Floating IPs type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.ListFloatingIPsTask.mean, '0.001'), 'Cloud 1')",,45,0
openstack%2Fproject-config~master~Id238936fda36626784c9e343d3ac295fd3b8702b,openstack/project-config,master,Id238936fda36626784c9e343d3ac295fd3b8702b,Neutron multinode dvr - add missing PROJECTS variable,MERGED,2016-03-06 07:46:09.000000000,2016-03-07 00:30:08.000000000,2016-03-07 00:30:08.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-06 07:46:09.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3e0543f15df519770c712d3d9070756d24b38938', 'message': 'Neutron multinode dvr - add missing PROJECTS variable\n\nChange-Id: Id238936fda36626784c9e343d3ac295fd3b8702b\n'}]",0,288987,3e0543f15df519770c712d3d9070756d24b38938,7,3,1,4656,,,0,"Neutron multinode dvr - add missing PROJECTS variable

Change-Id: Id238936fda36626784c9e343d3ac295fd3b8702b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/87/288987/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,3e0543f15df519770c712d3d9070756d24b38938,," export PROJECTS=""openstack-dev/grenade $PROJECTS""",,1,0
openstack%2Fproject-config~master~Ia5ea03b10249ae776a8857ad956c22e58c8eaac2,openstack/project-config,master,Ia5ea03b10249ae776a8857ad956c22e58c8eaac2,Adding integration test support for app catalog horizon plugin,MERGED,2016-02-04 20:51:00.000000000,2016-03-07 00:29:07.000000000,2016-03-07 00:29:06.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 5545}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 7128}, {'_account_id': 9237}, {'_account_id': 9788}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-04 20:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/25134af00b1c578b5347ba1642af14f2957d1c4c', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 2, 'created': '2016-02-04 21:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eb1bff3c43591bfd69da15d4be25fc1a4f50165b', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 3, 'created': '2016-02-05 16:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1566a1744c759ba3c271eba0ccb26abfc4588d79', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 4, 'created': '2016-02-05 18:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ebed00b31c1d7e3091758a5d2ffd4d450f37f7ad', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 5, 'created': '2016-02-05 19:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4cbe505b375b634ce646b028e55a9c44ad4c550c', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 6, 'created': '2016-02-10 15:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/13f4fe323cf89fb94e0667cf5b857d9224a15310', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 7, 'created': '2016-02-10 22:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e3a0dac74cdf92c2bee70546ecde844cbeceefb6', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 8, 'created': '2016-02-17 16:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fdf27abdc91038ac61a2b5452154b2ff1011557c', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 9, 'created': '2016-02-18 15:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/650e9d6483003b0bd6ce3a38bb7a6f4ce18ad9e6', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 10, 'created': '2016-02-18 16:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0f0823f5d2d7db6cdab02c052c687edf58f69c62', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 11, 'created': '2016-02-25 19:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4f33dae24e505b76ffbdecaca3b01f02af482f47', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nBlueprint: add-integration-tests\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 12, 'created': '2016-03-04 15:36:01.000000000', 'files': ['zuul/layout.yaml', 'jenkins/jobs/app-catalog.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ae6dfa75a08af21f0a794cf9b8f3c5d57b7560a7', 'message': 'Adding integration test support for app catalog horizon plugin\n\nNew devstack gate jobs for integration tests.\nNon-voting until basic test is stabilized.\n\nChange-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\nDepends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}]",10,276440,ae6dfa75a08af21f0a794cf9b8f3c5d57b7560a7,56,10,12,7128,,,0,"Adding integration test support for app catalog horizon plugin

New devstack gate jobs for integration tests.
Non-voting until basic test is stabilized.

Change-Id: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2
Depends-On: Ie6c8ee63afbda075298fdf2043990f5e9042308d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/276440/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul/layout.yaml', 'jenkins/jobs/app-catalog.yaml']",2,25134af00b1c578b5347ba1642af14f2957d1c4c,add-app-catalog-integration," - job: name: gate-app-catalog-ui-dsvm-integration node: devstack-trusty wrappers: - build-timeout: timeout: 95 - timestamps builders: - link-logs - net-info - devstack-checkout - firefox-install - xvfb-install - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=90 export DEVSTACK_GATE_TEMPEST=0 export DEVSTACK_GATE_EXERCISES=0 export DEVSTACK_GATE_INSTALL_TESTONLY=1 export DEVSTACK_GATE_NEUTRON=1 # Enable App Catalog Horizon plugin export DEVSTACK_LOCAL_CONFIG=""enable_plugin app-catalog-ui https://git.openstack.org/openstack/app-catalog-ui"" function pre_test_hook { cd /opt/stack/new/app-catalog-ui/tools/gate/integration ./pre_test_hook.sh } export -f pre_test_hook function post_test_hook { cd /opt/stack/new/app-catalog-ui/tools/gate/integration ./post_test_hook.sh } export -f post_test_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - test-results - devstack-logs - console-log - publish-app-catalog-ui-screenshots - publisher: name: publish-app-catalog-ui-screenshots publishers: - scp: site: 'static.openstack.org' files: - target: 'logs/$LOG_PATH/screenshots' source: 'integration_tests_screenshots/**' copy-after-failure: true ",,64,1
openstack%2Fproject-config~master~I17bed59332200346906e73613d90258f8037fb6a,openstack/project-config,master,I17bed59332200346906e73613d90258f8037fb6a,Make python3 gate voting in kolla,MERGED,2016-03-06 16:15:34.000000000,2016-03-07 00:25:55.000000000,2016-03-07 00:25:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-06 16:15:34.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/86d9f5f0488266dcbb8ef8197a7c66799cc78858', 'message': 'Make python3 gate voting in kolla\n\nChange-Id: I17bed59332200346906e73613d90258f8037fb6a\n'}]",0,289045,86d9f5f0488266dcbb8ef8197a7c66799cc78858,7,3,1,14119,,,0,"Make python3 gate voting in kolla

Change-Id: I17bed59332200346906e73613d90258f8037fb6a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/289045/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,86d9f5f0488266dcbb8ef8197a7c66799cc78858,kolla, - name: python3-jobs, - name: gate-kolla-python34 voting: false - gate-kolla-python34,1,4
openstack%2Fproject-config~master~Ibf90b8c0b4d8926274790b6a260d5471f026e0a6,openstack/project-config,master,Ibf90b8c0b4d8926274790b6a260d5471f026e0a6,The bash script has moved from tests/ to tools/,MERGED,2016-03-06 16:09:56.000000000,2016-03-07 00:21:12.000000000,2016-03-07 00:21:12.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-03-06 16:09:56.000000000', 'files': ['jenkins/jobs/kolla.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9a80ca2c11f4f18a3959b3bf76418e7fb2c4ef3e', 'message': 'The bash script has moved from tests/ to tools/\n\nThe change merged a while back, this patch depends on nothing from\nKolla.\n\nChange-Id: Ibf90b8c0b4d8926274790b6a260d5471f026e0a6\n'}]",0,289043,9a80ca2c11f4f18a3959b3bf76418e7fb2c4ef3e,7,3,1,14119,,,0,"The bash script has moved from tests/ to tools/

The change merged a while back, this patch depends on nothing from
Kolla.

Change-Id: Ibf90b8c0b4d8926274790b6a260d5471f026e0a6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/289043/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/kolla.yaml'],1,9a80ca2c11f4f18a3959b3bf76418e7fb2c4ef3e,kolla, tools/setup_gate.sh, tests/setup_gate.sh,1,1
openstack%2Fnova~master~I81ec4c54437d92c4c091646c0b3f5d948b82b52b,openstack/nova,master,I81ec4c54437d92c4c091646c0b3f5d948b82b52b,Ironic: Clean up if configdrive build fails,MERGED,2016-03-03 00:08:52.000000000,2016-03-07 00:13:04.000000000,2016-03-07 00:13:03.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 13295}, {'_account_id': 13362}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 00:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adac960acd37213249d0cc790ff2859564f7fb95', 'message': ""Ironic: Clean up if configdrive build fails\n\nThe configdrive builder does a number of things; for instance, shelling\nout to mkisofs or reaching up to the top cell for SSH keys. These have\nways of failing. If they do fail, we need to cleanup what we've done in\nthe deploy so far (instance fields on the node in ironic, firewalls,\nvifs, etc).\n\nWrap the configdrive build call in a try/except to catch any errors,\nclean up, and re-raise the error.\n\nChange-Id: I81ec4c54437d92c4c091646c0b3f5d948b82b52b\nCloses-Bug: #1552466\n""}, {'number': 2, 'created': '2016-03-03 20:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3727e7a528ca48c690126390d10fc21d95eaa463', 'message': ""Ironic: Clean up if configdrive build fails\n\nThe configdrive builder does a number of things; for instance, shelling\nout to mkisofs or reaching up to the top cell for SSH keys. These have\nways of failing. If they do fail, we need to cleanup what we've done in\nthe deploy so far (instance fields on the node in ironic, firewalls,\nvifs, etc).\n\nWrap the configdrive build call in a try/except to catch any errors,\nclean up, and re-raise the error.\n\nChange-Id: I81ec4c54437d92c4c091646c0b3f5d948b82b52b\nCloses-Bug: #1552466\n""}, {'number': 3, 'created': '2016-03-03 20:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9e79350f8e9699978669df4fa6053224a24dabf', 'message': ""Ironic: Clean up if configdrive build fails\n\nThe configdrive builder does a number of things; for instance, shelling\nout to mkisofs or reaching up to the top cell for SSH keys. These have\nways of failing. If they do fail, we need to cleanup what we've done in\nthe deploy so far (instance fields on the node in ironic, firewalls,\nvifs, etc).\n\nWrap the configdrive build call in a try/except to catch any errors,\nclean up, and re-raise the error.\n\nChange-Id: I81ec4c54437d92c4c091646c0b3f5d948b82b52b\nCloses-Bug: #1552466\n""}, {'number': 4, 'created': '2016-03-03 21:48:38.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ac5e95e39707a773100fa31f5057c2ace881e4e4', 'message': ""Ironic: Clean up if configdrive build fails\n\nThe configdrive builder does a number of things; for instance, shelling\nout to mkisofs or reaching up to the top cell for SSH keys. These have\nways of failing. If they do fail, we need to cleanup what we've done in\nthe deploy so far (instance fields on the node in ironic, firewalls,\nvifs, etc).\n\nWrap the configdrive build call in a try/except to catch any errors,\nclean up, and re-raise the error.\n\nChange-Id: I81ec4c54437d92c4c091646c0b3f5d948b82b52b\nCloses-Bug: #1552466\n""}]",4,287520,ac5e95e39707a773100fa31f5057c2ace881e4e4,38,14,4,10343,,,0,"Ironic: Clean up if configdrive build fails

The configdrive builder does a number of things; for instance, shelling
out to mkisofs or reaching up to the top cell for SSH keys. These have
ways of failing. If they do fail, we need to cleanup what we've done in
the deploy so far (instance fields on the node in ironic, firewalls,
vifs, etc).

Wrap the configdrive build call in a try/except to catch any errors,
clean up, and re-raise the error.

Change-Id: I81ec4c54437d92c4c091646c0b3f5d948b82b52b
Closes-Bug: #1552466
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/287520/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py']",2,adac960acd37213249d0cc790ff2859564f7fb95,bug/1552466," @mock.patch.object(ironic_driver.IronicDriver, '_generate_configdrive') @mock.patch.object(ironic_driver.IronicDriver, '_start_firewall') @mock.patch.object(ironic_driver.IronicDriver, '_plug_vifs') @mock.patch.object(ironic_driver.IronicDriver, '_cleanup_deploy') def test_spawn_node_configdrive_fail(self, mock_cleanup_deploy, mock_pvifs, mock_sf, mock_configdrive, mock_node, mock_save, mock_required_by): mock_required_by.return_value = True node_uuid = 'aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee' node = ironic_utils.get_test_node(driver='fake', uuid=node_uuid) flavor = ironic_utils.get_test_flavor() instance = fake_instance.fake_instance_obj(self.ctx, node=node_uuid) instance.flavor = flavor mock_node.get.return_value = node mock_node.validate.return_value = ironic_utils.get_test_validation() image_meta = ironic_utils.get_test_image_meta() class TestException(Exception): pass mock_configdrive.side_effect = TestException() self.assertRaises(TestException, self.driver.spawn, self.ctx, instance, image_meta, [], None) mock_node.get.assert_called_once_with(node_uuid) mock_node.validate.assert_called_once_with(node_uuid) mock_cleanup_deploy.assert_called_with(self.ctx, node, instance, None, flavor=flavor) @mock.patch.object(configdrive, 'required_by') @mock.patch.object(objects.Instance, 'save') @mock.patch.object(FAKE_CLIENT, 'node')",,44,3
openstack%2Fpython-magnumclient~master~I19c2fc562d97ae912661df365aa48e025b53cef7,openstack/python-magnumclient,master,I19c2fc562d97ae912661df365aa48e025b53cef7,"Revert ""Completely remove openstack common modules""",MERGED,2016-03-04 15:41:07.000000000,2016-03-07 00:12:29.000000000,2016-03-07 00:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 19133}]","[{'number': 1, 'created': '2016-03-04 15:41:07.000000000', 'files': ['magnumclient/openstack/common/__init__.py', 'magnumclient/openstack/__init__.py', 'magnumclient/openstack/common/apiclient/exceptions.py', 'magnumclient/openstack/common/apiclient/utils.py', 'magnumclient/openstack/common/apiclient/fake_client.py', 'magnumclient/openstack/common/_i18n.py', 'magnumclient/openstack/common/apiclient/auth.py', 'magnumclient/openstack/common/apiclient/client.py', 'openstack-common.conf', 'magnumclient/openstack/common/apiclient/__init__.py', 'magnumclient/openstack/common/apiclient/base.py', 'magnumclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/066854363766ac430a3d70fafe1ab4c146addce7', 'message': 'Revert ""Completely remove openstack common modules""\n\nThis reverts commit d2e57d6172ea5d058c992d0b73ad44aaecc7b448.\nThat commit breaks Heat. Let\'s revert it now and merge it back after\nfixing Heat and other dependencies (if any).\n\nChange-Id: I19c2fc562d97ae912661df365aa48e025b53cef7\nPartial-Bug: #1553108\n'}]",0,288534,066854363766ac430a3d70fafe1ab4c146addce7,9,5,1,11536,,,0,"Revert ""Completely remove openstack common modules""

This reverts commit d2e57d6172ea5d058c992d0b73ad44aaecc7b448.
That commit breaks Heat. Let's revert it now and merge it back after
fixing Heat and other dependencies (if any).

Change-Id: I19c2fc562d97ae912661df365aa48e025b53cef7
Partial-Bug: #1553108
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/34/288534/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/openstack/common/__init__.py', 'magnumclient/openstack/__init__.py', 'magnumclient/openstack/common/apiclient/exceptions.py', 'magnumclient/openstack/common/apiclient/utils.py', 'magnumclient/openstack/common/apiclient/fake_client.py', 'magnumclient/openstack/common/_i18n.py', 'magnumclient/openstack/common/apiclient/auth.py', 'magnumclient/openstack/common/apiclient/client.py', 'openstack-common.conf', 'magnumclient/openstack/common/apiclient/__init__.py', 'magnumclient/openstack/common/apiclient/base.py', 'magnumclient/openstack/common/cliutils.py']",12,066854363766ac430a3d70fafe1ab4c146addce7,,"# Copyright 2012 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # W0603: Using the global statement # W0621: Redefining name %s from outer scope # pylint: disable=W0603,W0621 from __future__ import print_function import getpass import inspect import os import sys import textwrap from oslo_utils import encodeutils from oslo_utils import strutils import prettytable import six from six import moves from magnumclient.openstack.common._i18n import _ class MissingArgs(Exception): """"""Supplied arguments are not sufficient for calling a function."""""" def __init__(self, missing): self.missing = missing msg = _(""Missing arguments: %s"") % "", "".join(missing) super(MissingArgs, self).__init__(msg) def validate_args(fn, *args, **kwargs): """"""Check that the supplied args are sufficient for calling a function. >>> validate_args(lambda a: None) Traceback (most recent call last): ... MissingArgs: Missing argument(s): a >>> validate_args(lambda a, b, c, d: None, 0, c=1) Traceback (most recent call last): ... MissingArgs: Missing argument(s): b, d :param fn: the function to check :param arg: the positional arguments supplied :param kwargs: the keyword arguments supplied """""" argspec = inspect.getargspec(fn) num_defaults = len(argspec.defaults or []) required_args = argspec.args[:len(argspec.args) - num_defaults] def isbound(method): return getattr(method, '__self__', None) is not None if isbound(fn): required_args.pop(0) missing = [arg for arg in required_args if arg not in kwargs] missing = missing[len(args):] if missing: raise MissingArgs(missing) def arg(*args, **kwargs): """"""Decorator for CLI args. Example: >>> @arg(""name"", help=""Name of the new entity"") ... def entity_create(args): ... pass """""" def _decorator(func): add_arg(func, *args, **kwargs) return func return _decorator def env(*args, **kwargs): """"""Returns the first environment variable set. If all are empty, defaults to '' or keyword arg `default`. """""" for arg in args: value = os.environ.get(arg) if value: return value return kwargs.get('default', '') def add_arg(func, *args, **kwargs): """"""Bind CLI arguments to a shell.py `do_foo` function."""""" if not hasattr(func, 'arguments'): func.arguments = [] # NOTE(sirp): avoid dups that can occur when the module is shared across # tests. if (args, kwargs) not in func.arguments: # Because of the semantics of decorator composition if we just append # to the options list positional options will appear to be backwards. func.arguments.insert(0, (args, kwargs)) def unauthenticated(func): """"""Adds 'unauthenticated' attribute to decorated function. Usage: >>> @unauthenticated ... def mymethod(f): ... pass """""" func.unauthenticated = True return func def isunauthenticated(func): """"""Checks if the function does not require authentication. Mark such functions with the `@unauthenticated` decorator. :returns: bool """""" return getattr(func, 'unauthenticated', False) def print_list(objs, fields, formatters=None, sortby_index=0, mixed_case_fields=None, field_labels=None): """"""Print a list or objects as a table, one row per object. :param objs: iterable of :class:`Resource` :param fields: attributes that correspond to columns, in order :param formatters: `dict` of callables for field formatting :param sortby_index: index of the field for sorting table rows :param mixed_case_fields: fields corresponding to object attributes that have mixed case names (e.g., 'serverId') :param field_labels: Labels to use in the heading of the table, default to fields. """""" formatters = formatters or {} mixed_case_fields = mixed_case_fields or [] field_labels = field_labels or fields if len(field_labels) != len(fields): raise ValueError(_(""Field labels list %(labels)s has different number "" ""of elements than fields list %(fields)s""), {'labels': field_labels, 'fields': fields}) if sortby_index is None: kwargs = {} else: kwargs = {'sortby': field_labels[sortby_index]} pt = prettytable.PrettyTable(field_labels) pt.align = 'l' for o in objs: row = [] for field in fields: if field in formatters: row.append(formatters[field](o)) else: if field in mixed_case_fields: field_name = field.replace(' ', '_') else: field_name = field.lower().replace(' ', '_') data = getattr(o, field_name, '') row.append(data) pt.add_row(row) if six.PY3: print(encodeutils.safe_encode(pt.get_string(**kwargs)).decode()) else: print(encodeutils.safe_encode(pt.get_string(**kwargs))) def keys_and_vals_to_strs(dictionary): """"""Recursively convert a dictionary's keys and values to strings. :param dictionary: dictionary whose keys/vals are to be converted to strs """""" def to_str(k_or_v): if isinstance(k_or_v, dict): return keys_and_vals_to_strs(k_or_v) elif isinstance(k_or_v, six.text_type): return str(k_or_v) else: return k_or_v return dict((to_str(k), to_str(v)) for k, v in dictionary.items()) def print_dict(dct, dict_property=""Property"", wrap=0): """"""Print a `dict` as a table of two columns. :param dct: `dict` to print :param dict_property: name of the first column :param wrap: wrapping for the second column """""" pt = prettytable.PrettyTable([dict_property, 'Value']) pt.align = 'l' for k, v in dct.items(): # convert dict to str to check length if isinstance(v, dict): v = six.text_type(keys_and_vals_to_strs(v)) if wrap > 0: v = textwrap.fill(six.text_type(v), wrap) # if value has a newline, add in multiple rows # e.g. fault with stacktrace if v and isinstance(v, six.string_types) and r'\n' in v: lines = v.strip().split(r'\n') col1 = k for line in lines: pt.add_row([col1, line]) col1 = '' elif isinstance(v, list): val = str([str(i) for i in v]) pt.add_row([k, val]) else: pt.add_row([k, v]) if six.PY3: print(encodeutils.safe_encode(pt.get_string()).decode()) else: print(encodeutils.safe_encode(pt.get_string())) def get_password(max_password_prompts=3): """"""Read password from TTY."""""" verify = strutils.bool_from_string(env(""OS_VERIFY_PASSWORD"")) pw = None if hasattr(sys.stdin, ""isatty"") and sys.stdin.isatty(): # Check for Ctrl-D try: for __ in moves.range(max_password_prompts): pw1 = getpass.getpass(""OS Password: "") if verify: pw2 = getpass.getpass(""Please verify: "") else: pw2 = pw1 if pw1 == pw2 and pw1: pw = pw1 break except EOFError: pass return pw def service_type(stype): """"""Adds 'service_type' attribute to decorated function. Usage: .. code-block:: python @service_type('volume') def mymethod(f): ... """""" def inner(f): f.service_type = stype return f return inner def get_service_type(f): """"""Retrieves service type from function."""""" return getattr(f, 'service_type', None) def pretty_choice_list(l): return ', '.join(""'%s'"" % i for i in l) def exit(msg=''): if msg: print (msg, file=sys.stderr) sys.exit(1) ",,2264,0
openstack%2Fnova~master~I15f867d8c6ff280bc68a6abf8b0da6e970c2bb39,openstack/nova,master,I15f867d8c6ff280bc68a6abf8b0da6e970c2bb39,Enable rebuild tests in cellsv1 job,MERGED,2016-03-03 14:31:32.000000000,2016-03-07 00:04:50.000000000,2016-03-07 00:04:49.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 14:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fb1c86baf7dc7ffbb9447c9339c9c031a64bc4c', 'message': 'Enable rebuild tests in cellsv1 job\n\nThis is a test to see if the rebuild related tempest tests\nare fixed with 022802997c10fc4ed56b1e1875cd7ccb16cc0688.\n\nChange-Id: I15f867d8c6ff280bc68a6abf8b0da6e970c2bb39\nRelated-Bug: #1552046\n'}, {'number': 2, 'created': '2016-03-04 19:59:13.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/83c1fa6c03a61580212241d566b4bc04c29fe776', 'message': 'Enable rebuild tests in cellsv1 job\n\nChange 022802997c10fc4ed56b1e1875cd7ccb16cc0688 fixed evacuate/rebuild\nin the cells API so enable the rebuild-related tests we were skipping\nbefore.\n\nRelated-Bug: #1445629\nRelated-Bug: #1445631\nRelated-Bug: #1552046\n\nChange-Id: I15f867d8c6ff280bc68a6abf8b0da6e970c2bb39\n'}]",0,287830,83c1fa6c03a61580212241d566b4bc04c29fe776,27,13,2,6873,,,0,"Enable rebuild tests in cellsv1 job

Change 022802997c10fc4ed56b1e1875cd7ccb16cc0688 fixed evacuate/rebuild
in the cells API so enable the rebuild-related tests we were skipping
before.

Related-Bug: #1445629
Related-Bug: #1445631
Related-Bug: #1552046

Change-Id: I15f867d8c6ff280bc68a6abf8b0da6e970c2bb39
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/287830/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,8fb1c86baf7dc7ffbb9447c9339c9c031a64bc4c,bug/1552046,,"# https://bugs.launchpad.net/nova/+bug/1445629 r=""$r|(?:tempest\.api\.compute.servers\.test_disk_config\.ServerDiskConfigTestJSON\.test_rebuild_server_with_manual_disk_config)"" # https://bugs.launchpad.net/nova/+bug/1445631 r=""$r|(?:tempest\.api\.compute\.servers\.test_server_actions\.ServerActionsTestJSON\.test_rebuild_server_in_stop_state)""",0,4
openstack%2Fdevstack-gate~master~I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c,openstack/devstack-gate,master,I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c,[WIP] run centos7 with neutron,ABANDONED,2015-05-04 03:34:54.000000000,2016-03-06 23:11:08.000000000,,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-05-04 03:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/69cafb5077f2c8e74abb20d534e14a60647c7a37', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 2, 'created': '2015-05-05 02:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/be43dd83e29606f809085689ff21c3ae12618e0a', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 3, 'created': '2015-05-05 03:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/492523645e0c3a942f0700db092a7655cdf8b353', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 4, 'created': '2015-05-05 11:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d180e1db96a3380d81fcd736b5996f7076f73f61', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 5, 'created': '2015-05-05 11:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fdf89948fb0b8a2056e8adc69759430733827309', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 6, 'created': '2015-05-05 19:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5619273c58c7af3067066e3c831c42e4a56445b9', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 7, 'created': '2015-05-05 23:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c90f093cbe55e59ef6119c7128f8d67dfaf80b55', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 8, 'created': '2015-05-05 23:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8d01954724e3cebdf7720ede5e4dc670d34bd6f1', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 9, 'created': '2015-05-05 23:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a61fb72d578481ecbcbfa038799d57fc76bc17aa', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 10, 'created': '2015-05-06 01:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/9ceb6b5afceb71c1485a86cb28e1ef238fc2787f', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 11, 'created': '2015-05-06 03:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/832d4201ea82719ec342d014d1885d51edd764f8', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 12, 'created': '2015-05-10 21:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/98c8b9f39c2b08e2094c9d3dbb3fb31a60ea2a68', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 13, 'created': '2015-05-11 00:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fb6c485fb6b22ce45e8a3432f9f882f9129e7025', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 14, 'created': '2015-05-11 07:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2373054be96590c8f57aab4e46b1242570962272', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: If2d316eb8c422dc1e4f34b17a50b93dd72993a99\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 15, 'created': '2015-05-12 01:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/40f167ae2d59112f8ebdfad85897d521edb18291', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 16, 'created': '2015-05-12 04:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b5b250221c41ff233aae817963b1969463643485', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 17, 'created': '2015-05-12 05:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/9e371b4f164bfd57919804cc3f70ceae8a410784', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 18, 'created': '2015-05-12 09:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6c8b9a96fbc3a1e9e4ffd0457bb587c51c1d7896', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 19, 'created': '2015-05-12 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/570fd4d8fb239855f51f9ac09f2f3ecd64f2eb5b', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 20, 'created': '2015-05-12 09:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/646b7b4072fbf3662c5280d53253d9b7203db256', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 21, 'created': '2015-05-14 05:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0c5a4d694b8cfbecda8426a3e67e76900b9d197e', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 22, 'created': '2015-05-15 04:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/6e919b2c9429da2f81ec83bef3483eac1badd57c', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nDepends-On: Ief7cb33d926a9538f4eb39c74d906ee0c879de35\nDepends-On: If2d316eb8c422dc1e4f34b17a50b93dd72993a99\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 23, 'created': '2015-05-18 05:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fd637c46d2735ead8058febf17acaec57291cd1b', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nnot testing with depend If2d316eb8c422dc1e4f34b17a50b93dd72993a99 to\nsee if ipv6 failures related.\n\nDepends-On: Ief7cb33d926a9538f4eb39c74d906ee0c879de35\nDepends-On: If2d316eb8c422dc1e4f34b17a50b93dd72993a99\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 24, 'created': '2015-06-03 20:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/88ef1bc5a440f00d7b588b3eb300ec3a98b740e5', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 25, 'created': '2015-06-04 01:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/62cdff1b3c54033d729fd69b4a0605e7a7656fde', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 26, 'created': '2015-06-04 01:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5290e2c74f67674709ff0a5bf3f2be587ad5bd43', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 27, 'created': '2015-06-04 04:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d0402082a006973fe864cbf4ee11517acaa8aef2', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 28, 'created': '2015-06-05 01:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b1d2f75f1ad4ff44794eeccf2865224d9629fcf2', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 29, 'created': '2015-06-05 03:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/509c5edaddac85374b557784b737b930205301f7', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nreducing to just multi-tenant tests as that seems to be common failure\n\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 30, 'created': '2015-06-05 04:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/34b06af9a2a88b6b84d3b653712a0054fc3896f6', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 31, 'created': '2015-06-09 20:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ddb72e72edef42c102ce2ad4d1eb3aeadcd0f7eb', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 32, 'created': '2015-06-09 21:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/67ad3f33bf69e779494f7f5e0d3b14d5b4b0dd9b', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 33, 'created': '2015-06-10 01:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b876ed5116ae0cf982a08a23022894bf6ac1111c', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 34, 'created': '2015-06-10 23:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d0b4c5a25180fa6646c7e0c55777f7997d6327ba', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}, {'number': 35, 'created': '2015-06-12 22:53:25.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh', 'functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3cd7c438673587a6daabbdd6926231adaa5b3c46', 'message': '[WIP] run centos7 with neutron\n\nhard-coding this to see what happens with centos7\n\nDepends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab\nDepends-On: Ia508c552d806363f6633d0bcd357c05bf956279f\nDepends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e\n\nChange-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c\n'}]",0,179689,3cd7c438673587a6daabbdd6926231adaa5b3c46,126,3,35,7118,,,0,"[WIP] run centos7 with neutron

hard-coding this to see what happens with centos7

Depends-On: Ic46c4b9b80335c4c4ad58f9593927743cc1f4fab
Depends-On: Ia508c552d806363f6633d0bcd357c05bf956279f
Depends-On: I8b49298d27a75a864c0066896cbd3d3095982f6e

Change-Id: I1d2cdb94168ebf64765688d4ab7b2146b1e67b8c
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/89/179689/35 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,69cafb5077f2c8e74abb20d534e14a60647c7a37,centos7-neutron,export DEVSTACK_GATE_NEUTRON=${DEVSTACK_GATE_NEUTRON:-1},export DEVSTACK_GATE_NEUTRON=${DEVSTACK_GATE_NEUTRON:-0},1,1
openstack%2Fglance~master~I85e0087c530c2f1132061036fd5427368dfa2316,openstack/glance,master,I85e0087c530c2f1132061036fd5427368dfa2316,Use assertGreater/Less/Equal instead of assertTrue(A * B),MERGED,2016-02-25 14:38:23.000000000,2016-03-06 22:34:02.000000000,2016-03-06 22:34:02.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 17123}]","[{'number': 1, 'created': '2016-02-25 14:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8f3ca2f4c4f416db9cba48f349f7ac9ce239d4e3', 'message': 'Use assertGreater/Less/Equal instead of assertTrue(A * B)\n\nInstead of using assertTrue(A * B), developers should\nuse assertGreater(A, B) or assertLess(A, B) or\nassertGreaterEqual(A, B) or assertLessEqual(A, B)\nor assertEqual(A, B).\nThe * operator: >=, <=, ==\n\nChange-Id: I85e0087c530c2f1132061036fd5427368dfa2316\n'}, {'number': 2, 'created': '2016-02-26 10:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/38d946c7efcfa103c1dd83e97b2071af6067833a', 'message': 'Use assertGreater/Less/Equal instead of assertTrue(A * B)\n\nInstead of using assertTrue(A * B), developers should\nuse assertGreater(A, B) or assertLess(A, B) or\nassertGreaterEqual(A, B) or assertLessEqual(A, B)\nor assertEqual(A, B).\nThe * operator: >=, <=, ==\n\nChange-Id: I85e0087c530c2f1132061036fd5427368dfa2316\n'}, {'number': 3, 'created': '2016-03-01 09:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fa78ba158af2c3d36ef2f4f9899fc5decde2c580', 'message': 'Use assertGreater/Less/Equal instead of assertTrue(A * B)\n\nInstead of using assertTrue(A * B), developers should\nuse assertGreater(A, B) or assertLess(A, B) or\nassertGreaterEqual(A, B) or assertLessEqual(A, B)\nor assertEqual(A, B).\nThe * operator: >=, <=, ==\n\nChange-Id: I85e0087c530c2f1132061036fd5427368dfa2316\n'}, {'number': 4, 'created': '2016-03-02 07:56:51.000000000', 'files': ['glance/tests/functional/v2/test_images.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/tests/functional/db/base.py', 'glance/tests/functional/v1/test_multiprocessing.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/tests/functional/glare/test_glare.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/tests/integration/legacy_functional/test_v1_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f29e9e61384b3ae1e7b77ce9b4c11552727aa805', 'message': 'Use assertGreater/Less/Equal instead of assertTrue(A * B)\n\nInstead of using assertTrue(A * B), developers should\nuse assertGreater(A, B) or assertLess(A, B) or\nassertGreaterEqual(A, B) or assertLessEqual(A, B)\nor assertEqual(A, B).\nThe * operator: >=, <=, ==\n\nChange-Id: I85e0087c530c2f1132061036fd5427368dfa2316\n'}]",3,284739,f29e9e61384b3ae1e7b77ce9b4c11552727aa805,18,4,4,18603,,,0,"Use assertGreater/Less/Equal instead of assertTrue(A * B)

Instead of using assertTrue(A * B), developers should
use assertGreater(A, B) or assertLess(A, B) or
assertGreaterEqual(A, B) or assertLessEqual(A, B)
or assertEqual(A, B).
The * operator: >=, <=, ==

Change-Id: I85e0087c530c2f1132061036fd5427368dfa2316
",git fetch https://review.opendev.org/openstack/glance refs/changes/39/284739/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v1/test_registry_client.py', 'glance/tests/functional/v1/test_multiprocessing.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/tests/integration/legacy_functional/test_v1_api.py']",5,8f3ca2f4c4f416db9cba48f349f7ac9ce239d4e3,(detached," self.assertLessEqual(image['size'], 20) self.assertGreaterEqual(image['size'], 20) self.assertEqual('tenant1', image['is_public'] or image['owner']) self.assertEqual('admin', image['is_public'] or image['owner']) self.assertEqual('admin', image['is_public'] or image['owner'])", self.assertTrue(image['size'] <= 20) self.assertTrue(image['size'] >= 20) self.assertTrue(image['is_public'] or image['owner'] == 'tenant1') self.assertTrue(image['is_public'] or image['owner'] == 'admin') self.assertTrue(image['is_public'] or image['owner'] == 'admin'),12,12
openstack%2Fzaqar~master~I04b72580f726dbb084a26403cfdf3ca2e92756b5,openstack/zaqar,master,I04b72580f726dbb084a26403cfdf3ca2e92756b5,Updated from global requirements,MERGED,2016-03-05 03:12:33.000000000,2016-03-06 22:28:14.000000000,2016-03-06 22:28:14.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 03:12:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5a70f02cd3842e9c4f8fada81fdb620939efeab1', 'message': 'Updated from global requirements\n\nChange-Id: I04b72580f726dbb084a26403cfdf3ca2e92756b5\n'}]",0,288830,5a70f02cd3842e9c4f8fada81fdb620939efeab1,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I04b72580f726dbb084a26403cfdf3ca2e92756b5
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/30/288830/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5a70f02cd3842e9c4f8fada81fdb620939efeab1,openstack/requirements,oslo.cache>=1.5.0 # Apache-2.0,oslo.cache>=0.8.0 # Apache-2.0,1,1
openstack%2Foctavia~master~Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a,openstack/octavia,master,Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a,Add pre_test_hook to run gate jobs,MERGED,2016-02-25 21:50:10.000000000,2016-03-06 21:07:27.000000000,2016-03-06 21:03:28.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 10477}, {'_account_id': 11685}, {'_account_id': 12999}, {'_account_id': 14556}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-02-25 21:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/87259231ae0162b66d82414ef1dc3df3a9e1f3c9', 'message': 'Add pre_test_hook to run gate jobs\n\nInclude set of services with plugins to run gate jobs\nfor Octavia\n\nChange-Id: Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a\n'}, {'number': 2, 'created': '2016-02-25 22:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e47534dc1703bbbe67562f803941d2339a215547', 'message': 'Add pre_test_hook to run gate jobs\n\nTweak set of services with plugins to run gate jobs\nfor Octavia scenario tests.\n\nChange-Id: Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a\n'}, {'number': 3, 'created': '2016-02-27 00:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6df36bbeaef35e4650d08b3201df7f445189eda2', 'message': 'Add pre_test_hook to run gate jobs\n\nTweak set of services with plugins to run gate jobs\nfor Octavia scenario tests.\n\nChange-Id: Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a\n'}, {'number': 4, 'created': '2016-03-04 22:12:37.000000000', 'files': ['octavia/tests/contrib/pre_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d013927a7baa62adb6938bddc745938356522633', 'message': 'Add pre_test_hook to run gate jobs\n\nTweak set of services with plugins to run gate jobs\nfor Octavia scenario tests.\n\nChange-Id: Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a\n'}]",6,284946,d013927a7baa62adb6938bddc745938356522633,49,9,4,14556,,,0,"Add pre_test_hook to run gate jobs

Tweak set of services with plugins to run gate jobs
for Octavia scenario tests.

Change-Id: Ibaecb2e0141e3ff9a19acf4c2b63aeae60e6ed9a
",git fetch https://review.opendev.org/openstack/octavia refs/changes/46/284946/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/tests/contrib/pre_test_hook.sh'],1,87259231ae0162b66d82414ef1dc3df3a9e1f3c9,,"#!/bin/bash set -ex GATE_DEST=$BASE/new DEVSTACK_PATH=$GATE_DEST/devstack export DEVSTACK_LOCAL_CONFIG+="" enable_plugin neutron-lbaas https://git.openstack.org/openstack/neutron-lbaas enable_plugin barbican https://git.openstack.org/openstack/barbican enable_plugin octavia https://git.openstack.org/openstack/octavia"" # These are not needed for api and scenario tests ENABLED_SERVICES+=""-c-api,-c-bak,-c-sch,-c-vol,-cinder"" ENABLED_SERVICES+="",-s-account,-s-container,-s-object,-s-proxy"" # Disable lbaasv1 and enable lbaasv2 ENABLED_SERVICES+=""q-lbaasv2,-q-lbaas,octavia,o-cw,o-hk,o-hm,o-api"" export ENABLED_SERVICES $GATE_DEST/devstack-gate/devstack-vm-gate.sh ",,22,0
openstack%2Fopenstack-ansible-os_heat~master~I842367ba02241da717404cacb36c9cfbb5582474,openstack/openstack-ansible-os_heat,master,I842367ba02241da717404cacb36c9cfbb5582474,[DOCS] Cleanup the role docs for consistency and clarity,MERGED,2016-03-05 20:45:58.000000000,2016-03-06 19:54:38.000000000,2016-03-06 19:54:38.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-05 20:45:58.000000000', 'files': ['CONTRIBUTING.rst', 'doc/source/index.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/63020c841a2b8546fa5537614130ce709654b84e', 'message': '[DOCS] Cleanup the role docs for consistency and clarity\n\nRemoved duplication and wrapped lines in the Contributing guide.\n\nChange-Id: I842367ba02241da717404cacb36c9cfbb5582474\n'}]",0,288935,63020c841a2b8546fa5537614130ce709654b84e,7,3,1,19814,,,0,"[DOCS] Cleanup the role docs for consistency and clarity

Removed duplication and wrapped lines in the Contributing guide.

Change-Id: I842367ba02241da717404cacb36c9cfbb5582474
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/35/288935/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'doc/source/index.rst', 'README.rst']",3,63020c841a2b8546fa5537614130ce709654b84e,docs/cleanup,OpenStack-Ansible Heat ######################Ansible role to install OpenStack Heat. This role will install:,"OpenStack heat ##############Role to install heat api, cfn, cloudwatch, and engine. This role will install the following:",39,36
openstack%2Fneutron~master~I3e1aa21cd02c0f116cc6dee5e0577988ec37f767,openstack/neutron,master,I3e1aa21cd02c0f116cc6dee5e0577988ec37f767,Delay description association proxy construction,MERGED,2016-03-06 10:26:28.000000000,2016-03-06 19:35:55.000000000,2016-03-06 19:26:07.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7715}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 13995}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-03-06 10:26:28.000000000', 'files': ['neutron/db/model_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/284f507adaa2af7691e49327cdfc2baba9268455', 'message': ""Delay description association proxy construction\n\nAssociation proxies cannot be constructed in the mixin because they\nwill be shared between all models that inherit from it. This means\nthey all share one and it will effectively be broken for all but the\nfirst to load it.\n\nThis changes it to a declared attr like the others to make sure it's\nnot constructed until each model inherits from it.\n\nChange-Id: I3e1aa21cd02c0f116cc6dee5e0577988ec37f767\nCloses-Bug: #1553689\n""}]",0,288999,284f507adaa2af7691e49327cdfc2baba9268455,25,10,1,7787,,,0,"Delay description association proxy construction

Association proxies cannot be constructed in the mixin because they
will be shared between all models that inherit from it. This means
they all share one and it will effectively be broken for all but the
first to load it.

This changes it to a declared attr like the others to make sure it's
not constructed until each model inherits from it.

Change-Id: I3e1aa21cd02c0f116cc6dee5e0577988ec37f767
Closes-Bug: #1553689
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/288999/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/model_base.py'],1,284f507adaa2af7691e49327cdfc2baba9268455,bug/1553689," @declarative.declared_attr def description(cls): return association_proxy('standard_attr', 'description')"," description = association_proxy('standard_attr', 'description')",3,1
openstack%2Fopenstack-ansible-os_ceilometer~master~I93c281578420dc305ba9489b0a1d42628a08f246,openstack/openstack-ansible-os_ceilometer,master,I93c281578420dc305ba9489b0a1d42628a08f246,Removing unneeded with_items usage for clarity,ABANDONED,2016-03-06 19:21:24.000000000,2016-03-06 19:28:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-03-06 19:21:24.000000000', 'files': ['tasks/ceilometer_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/6e2ea30ec8393dd13913b93552b844e51ec1da68', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: I93c281578420dc305ba9489b0a1d42628a08f246\n'}]",0,289066,6e2ea30ec8393dd13913b93552b844e51ec1da68,3,1,1,19814,,,0,"Removing unneeded with_items usage for clarity

Change-Id: I93c281578420dc305ba9489b0a1d42628a08f246
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/66/289066/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ceilometer_post_install.yml'],1,6e2ea30ec8393dd13913b93552b844e51ec1da68,unneeded_with_items," src: ""rootwrap.d/ipmi.filters"" dest: ""/etc/ceilometer/rootwrap.d/ipmi.filters"""," src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" with_items: - { src: ""rootwrap.d/ipmi.filters"", dest: ""/etc/ceilometer/rootwrap.d/ipmi.filters"" }",2,4
openstack%2Ftraining-labs~master~I79fb69ec1cdbe54f122e1d2e24c10fde0eab697f,openstack/training-labs,master,I79fb69ec1cdbe54f122e1d2e24c10fde0eab697f,kvm: Download ISO if not existing.,MERGED,2016-03-06 17:01:22.000000000,2016-03-06 18:11:32.000000000,2016-03-06 18:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-06 17:01:22.000000000', 'files': ['labs/osbash/lib/osbash/kvm-install_base.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/5f965a927788ebf93645d8dc851c57a74fd61717', 'message': 'kvm: Download ISO if not existing.\n\nDownloads the ISO image if it is not existing instead of erroring out.\nWith the current changes to the way libvirt used to install the\nbase-disk, it is important to have the right ISO image.\n\nChange-Id: I79fb69ec1cdbe54f122e1d2e24c10fde0eab697f\n'}]",0,289049,5f965a927788ebf93645d8dc851c57a74fd61717,7,3,1,7007,,,0,"kvm: Download ISO if not existing.

Downloads the ISO image if it is not existing instead of erroring out.
With the current changes to the way libvirt used to install the
base-disk, it is important to have the right ISO image.

Change-Id: I79fb69ec1cdbe54f122e1d2e24c10fde0eab697f
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/49/289049/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/lib/osbash/kvm-install_base.sh'],1,5f965a927788ebf93645d8dc851c57a74fd61717,, ${OSBASH:-:} find_install-iso ,,2,0
openstack%2Fmanila~master~I9e0843b88cd1a1668fe48c6979029c012dcbaa13,openstack/manila,master,I9e0843b88cd1a1668fe48c6979029c012dcbaa13,gluster*: clean up volume option querying,MERGED,2016-02-07 04:08:07.000000000,2016-03-06 17:43:11.000000000,2016-02-27 04:15:34.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7872}, {'_account_id': 9521}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-07 04:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8115e78997e45bddf0a14e9a24e3324d76e48798', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 2, 'created': '2016-02-07 08:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3f614ab1bac1beebec06941127268fa5a56a2a18', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 3, 'created': '2016-02-11 03:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/366f4618a94e731bc30b47e0cbc1c79aa31e019a', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 4, 'created': '2016-02-14 13:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/26406d5d0f2951853c5647290a07b9f660a7b8a0', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 5, 'created': '2016-02-15 22:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4fa8d97dbcdb6cb7550086793bce87809e6b90ee', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 6, 'created': '2016-02-16 04:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d70a3f5823d281c6e79d17d20bc246d2c543d87f', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 7, 'created': '2016-02-16 21:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ad23cbc66b89a31d677f83e39a5ce201009e11ef', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volume info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nPartially implements bp gluster-code-cleanup\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 8, 'created': '2016-02-16 21:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e12d42efb84b88f0a1280546ac5df068f35d1682', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volume info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nPartially implements bp gluster-code-cleanup\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 9, 'created': '2016-02-25 09:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ff5fab2e94010c1561a38591391c970f5ad38e9f', 'message': 'gluster*: clean up volume option querying\n\n!!!  DON\'T YET MERGE\n!!! Turned out that this breaks interop with glusterfs 3.6\n!!! fix to come soon\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volue info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as  error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 10, 'created': '2016-02-25 15:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2fc6edc273ed493de9b642be8f96bbf74ebfafb8', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volume info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nPartially implements bp gluster-code-cleanup\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}, {'number': 11, 'created': '2016-02-27 01:19:42.000000000', 'files': ['manila/share/drivers/glusterfs_native.py', 'manila/tests/share/drivers/test_glusterfs_native.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/share/drivers/glusterfs/__init__.py', 'manila/tests/share/drivers/glusterfs/test_common.py', 'manila/share/drivers/glusterfs/common.py', 'manila/tests/share/drivers/glusterfs/test_layout_volume.py', 'manila/share/drivers/glusterfs/layout_volume.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/768b02bdb73b6a7ac99523f997d31b3f442413cb', 'message': 'gluster*: clean up volume option querying\n\nGlusterFS has two kind of options:\n- regular ones, which are a hardcoded set, and option names\n  are verified in ""gluster volume get""\n- user ones, whose name matches user.* -- these are\n  arbitrarily named, are ignored by ""gluster volume get"" and\n  are listed in ""gluster volume info"" output\n\nSo far we used ""gluster volume info"" universally, but that,\napart from being cumbersome for regular options, is also\nincorrect, as it can\'t distinguish an unset option name from\nan undefined one (querying the former should be treated OK,\nquerying the second should be treated as error).\n\n- implement querying of regular options with ""gluster volume\n  get"" (accepting empty response)\n- implement querying of user options with searching ""gluster vol\n  info"" data\n- verify operations on the XML tree, make tacit XML layout\n  assumptions explicit\n- implement optional Boolean coercion of values\n\nPartially implements bp gluster-code-cleanup\n\nChange-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13\n'}]",10,277141,768b02bdb73b6a7ac99523f997d31b3f442413cb,85,17,11,9521,,,0,"gluster*: clean up volume option querying

GlusterFS has two kind of options:
- regular ones, which are a hardcoded set, and option names
  are verified in ""gluster volume get""
- user ones, whose name matches user.* -- these are
  arbitrarily named, are ignored by ""gluster volume get"" and
  are listed in ""gluster volume info"" output

So far we used ""gluster volume info"" universally, but that,
apart from being cumbersome for regular options, is also
incorrect, as it can't distinguish an unset option name from
an undefined one (querying the former should be treated OK,
querying the second should be treated as error).

- implement querying of regular options with ""gluster volume
  get"" (accepting empty response)
- implement querying of user options with searching ""gluster vol
  info"" data
- verify operations on the XML tree, make tacit XML layout
  assumptions explicit
- implement optional Boolean coercion of values

Partially implements bp gluster-code-cleanup

Change-Id: I9e0843b88cd1a1668fe48c6979029c012dcbaa13
",git fetch https://review.opendev.org/openstack/manila refs/changes/41/277141/11 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/glusterfs_native.py', 'manila/tests/share/drivers/test_glusterfs_native.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/share/drivers/glusterfs/__init__.py', 'manila/tests/share/drivers/glusterfs/test_common.py', 'manila/share/drivers/glusterfs/common.py', 'manila/share/drivers/glusterfs/layout_volume.py']",7,8115e78997e45bddf0a14e9a24e3324d76e48798,bp/gluster-code-cleanup," opret = int(common.volxml_get(outxml, 'opRet')) operrno = int(common.volxml_get(outxml, 'opErrno')) operrstr = common.volxml_get(outxml, 'opErrstr', None) opret = int(common.volxml_get(outxml, 'opRet')) operrno = int(common.volxml_get(outxml, 'opErrno')) operrstr = common.volxml_get(outxml, 'opErrstr', None)", opret = int(outxml.find('opRet').text) operrno = int(outxml.find('opErrno').text) operrstr = outxml.find('opErrstr').text opret = int(outxml.find('opRet').text) operrno = int(outxml.find('opErrno').text) operrstr = outxml.find('opErrstr').text,333,47
openstack%2Ftraining-labs~master~Ic46d5cb88bf285a4bd7b0bbe7de4e55787867bbc,openstack/training-labs,master,Ic46d5cb88bf285a4bd7b0bbe7de4e55787867bbc,Fix console output in test script,MERGED,2016-03-02 18:37:48.000000000,2016-03-06 16:18:23.000000000,2016-03-06 16:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-02 18:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/2a4839439b7832e4d58eee6c13d95c10439a2480', 'message': 'Fix console output in test script\n\nA few echo commands have not been updated to the nodes used in Liberty.\nFixed.\n\nChange-Id: Ic46d5cb88bf285a4bd7b0bbe7de4e55787867bbc\n'}, {'number': 2, 'created': '2016-03-03 18:41:29.000000000', 'files': ['labs/osbash/scripts/test/launch_instance_private_net.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/4ac4ed4fa71304596935093b95600e4b0369e07f', 'message': 'Fix console output in test script\n\nA few echo commands have not been updated to the nodes used in Liberty.\nFixed.\n\nChange-Id: Ic46d5cb88bf285a4bd7b0bbe7de4e55787867bbc\n'}]",0,287378,4ac4ed4fa71304596935093b95600e4b0369e07f,9,3,2,11109,,,0,"Fix console output in test script

A few echo commands have not been updated to the nodes used in Liberty.
Fixed.

Change-Id: Ic46d5cb88bf285a4bd7b0bbe7de4e55787867bbc
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/78/287378/2 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/scripts/test/launch_instance_private_net.sh'],1,2a4839439b7832e4d58eee6c13d95c10439a2480,fix_comments_in_test,"echo ""Checking network connection to compute1 node.""echo ""Checking services on controller node.""echo ""Checking services on compute1 node.""","echo ""Checking network connection to compute node.""echo ""Checking services on network node.""echo ""Checking services on compute node.""",3,3
openstack%2Ftraining-labs~master~Ided425352d6ea97dba3f4e294140b9068f9d3efa,openstack/training-labs,master,Ided425352d6ea97dba3f4e294140b9068f9d3efa,Make heat_stack test script check for other VMs,MERGED,2016-03-06 06:49:12.000000000,2016-03-06 16:16:49.000000000,2016-03-06 16:16:49.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-06 06:49:12.000000000', 'files': ['labs/osbash/scripts/test/heat_stack.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/f54cf86b5b204a5d0e4248567ed40f40d15e9631', 'message': 'Make heat_stack test script check for other VMs\n\nOn a default osbash configuration, the test script, heat_stack.sh, does\nnot have sufficient resources to run if another VMs (e.g, one created by\nlaunch_instance_private_net.sh) is still running. In such a case, the\nscript will appear to hang forever.\n\nThis patch checks for other VMs and aborts if any are found.\n\nChange-Id: Ided425352d6ea97dba3f4e294140b9068f9d3efa\n'}]",0,288978,f54cf86b5b204a5d0e4248567ed40f40d15e9631,7,3,1,11109,,,0,"Make heat_stack test script check for other VMs

On a default osbash configuration, the test script, heat_stack.sh, does
not have sufficient resources to run if another VMs (e.g, one created by
launch_instance_private_net.sh) is still running. In such a case, the
script will appear to hang forever.

This patch checks for other VMs and aborts if any are found.

Change-Id: Ided425352d6ea97dba3f4e294140b9068f9d3efa
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/78/288978/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/scripts/test/heat_stack.sh'],1,f54cf86b5b204a5d0e4248567ed40f40d15e9631,heat_check_for_vms,"function check_for_other_vms { echo ""Verifying that no other instance VMs are left."" ( source ""$CONFIG_DIR/admin-openstackrc.sh"" if [ ""$(nova list --all-tenants --minimal | wc -l)"" -gt 4 ]; then echo ""ERROR Unexpected VMs found. There may not be enough resources"" \ ""for this test. Aborting..."" nova list --all-tenants exit 1 fi ) } check_for_other_vms ",,14,0
openstack%2Ftraining-labs~master~I8808cbfe5b0a04f90947f3ddf3e24cbbede2fcf7,openstack/training-labs,master,I8808cbfe5b0a04f90947f3ddf3e24cbbede2fcf7,Make KVM distro booting match Virtualbox version,MERGED,2016-03-02 19:19:43.000000000,2016-03-06 16:16:44.000000000,2016-03-06 16:16:43.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-02 19:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/2f9a96731de4d0dc8ccb17375a0dd677fb4cefc7', 'message': 'Make KVM distro booting match Virtualbox version\n\nOur KVM and VirtualBox code uses different methods for booting the\nLinux distribution installer. KVM boots directly from an Internet\nrepo whereas VirtualBox uses a distro ISO image.\n\nWith this patch, the KVM code uses the same method as VirtualBox. A new\nlibrary provides the keyboard scancodes (which differ from VirtualBox)\nand the function _keyboard_push_scancode is implemented for KVM, too.\n\nThis allows kvm-install_base to use distro_start_installer, and we\ncan remove the DISTRO_URL and EXTRA_ARGS which are no longer needed.\n\nChange-Id: I8808cbfe5b0a04f90947f3ddf3e24cbbede2fcf7\n'}, {'number': 2, 'created': '2016-03-03 18:42:32.000000000', 'files': ['labs/osbash/lib/osbash/kvm-keycodes.sh', 'labs/osbash/lib/osbash/kvm-install_base.sh', 'labs/osbash/lib/osbash/lib.ubuntu-14.04-server-amd64.sh', 'labs/osbash/lib/osbash/kvm-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/0df4a4dfac2f4fc706be1aaa1690ff838eaad404', 'message': 'Make KVM distro booting match Virtualbox version\n\nOur KVM and VirtualBox code uses different methods for booting the\nLinux distribution installer. KVM boots directly from an Internet\nrepo whereas VirtualBox uses a distro ISO image.\n\nWith this patch, the KVM code uses the same method as VirtualBox. A new\nlibrary provides the keyboard scancodes (which differ from VirtualBox)\nand the function _keyboard_push_scancode is implemented for KVM, too.\n\nThis allows kvm-install_base to use distro_start_installer, and we\ncan remove the DISTRO_URL and EXTRA_ARGS which are no longer needed.\n\nChange-Id: I8808cbfe5b0a04f90947f3ddf3e24cbbede2fcf7\n'}]",0,287398,0df4a4dfac2f4fc706be1aaa1690ff838eaad404,9,3,2,11109,,,0,"Make KVM distro booting match Virtualbox version

Our KVM and VirtualBox code uses different methods for booting the
Linux distribution installer. KVM boots directly from an Internet
repo whereas VirtualBox uses a distro ISO image.

With this patch, the KVM code uses the same method as VirtualBox. A new
library provides the keyboard scancodes (which differ from VirtualBox)
and the function _keyboard_push_scancode is implemented for KVM, too.

This allows kvm-install_base to use distro_start_installer, and we
can remove the DISTRO_URL and EXTRA_ARGS which are no longer needed.

Change-Id: I8808cbfe5b0a04f90947f3ddf3e24cbbede2fcf7
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/98/287398/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/lib/osbash/kvm-keycodes.sh', 'labs/osbash/lib/osbash/kvm-install_base.sh', 'labs/osbash/lib/osbash/lib.ubuntu-14.04-server-amd64.sh', 'labs/osbash/lib/osbash/kvm-functions.sh']",4,2f9a96731de4d0dc8ccb17375a0dd677fb4cefc7,reb/send-key,"# Booting a VM and passing boot parameterssource ""$OSBASH_LIB_DIR/kvm-keycodes.sh"" function _keyboard_push_scancode { local vm_name=$1 shift # Split string (e.g. '01 81') into arguments (works also if we # get each hexbyte as a separate argument) # Not quoting $@ is intentional -- we want to split on blanks local scan_code=( $@ ) $VIRSH send-key ""$vm_name"" --codeset linux ""${scan_code[@]}"" >/dev/null } ",# Booting a VM,336,25
openstack%2Ftraining-labs~master~Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83,openstack/training-labs,master,Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83,Support for i386 nodes,MERGED,2015-12-28 05:11:26.000000000,2016-03-06 16:16:01.000000000,2016-03-06 16:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2015-12-28 05:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/150860f81b3c88799ea78ddde7ca9e30a9def127', 'message': 'i386 Ubuntu ISO\n\nExperiment with i386 Ubuntu ISO image.\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 2, 'created': '2016-01-03 19:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/dad3fb717d3ab8ec371a372477a8a705adf05f73', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 3, 'created': '2016-02-04 19:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/16841681c3dd04798d268786be59000ceaa4fddd', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 4, 'created': '2016-02-08 19:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/f71e6541a15eebcad1a894c5b2625ac5123742f2', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 5, 'created': '2016-02-28 16:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/2e4ede22fb09b8c79b26d6a3804ffcf83dbc7f14', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 6, 'created': '2016-03-02 19:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/75e22bee746c34aefd9a21f6591074452d3ed324', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}, {'number': 7, 'created': '2016-03-03 18:42:29.000000000', 'files': ['labs/osbash/config/localrc', 'labs/osbash/config/openstack', 'labs/osbash/lib/osbash/lib.ubuntu-14.04-server-i386.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/88e079d84e1b7e47eb117a4027994d84902ad60f', 'message': 'Support for i386 nodes\n\nThis patch adds support for i386 nodes. It is useful on host systems\nthat don\'t have hardware virtualization extensions, such as 32-bit host\noperating systems and virtualized host environments (i.e. nested\nvirtualization).\n\nSuccessfully tested with Debian 8.2 running inside VirtualBox.\n\nWIP, main open issues:\n- only works with VM_CPUS=1\n- in some host environments, the basedisk network does not come up after\n  the initial reboot; needs the user to log in via console and ""ifup\n  eth0""\n- basedisk build takes about an hour with nested virtualization, but on\n  a public cloud instance with comparable specs, it took 14 hours\n\nChange-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83\n'}]",0,261882,88e079d84e1b7e47eb117a4027994d84902ad60f,29,3,7,11109,,,0,"Support for i386 nodes

This patch adds support for i386 nodes. It is useful on host systems
that don't have hardware virtualization extensions, such as 32-bit host
operating systems and virtualized host environments (i.e. nested
virtualization).

Successfully tested with Debian 8.2 running inside VirtualBox.

WIP, main open issues:
- only works with VM_CPUS=1
- in some host environments, the basedisk network does not come up after
  the initial reboot; needs the user to log in via console and ""ifup
  eth0""
- basedisk build takes about an hour with nested virtualization, but on
  a public cloud instance with comparable specs, it took 14 hours

Change-Id: Id6cbd42679cf24e6546a3f8ff6e82a46d8d8cf83
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/82/261882/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/osbash.sh', 'labs/osbash/lib/osbash/lib.ubuntu-14.04-server-i386.sh']",2,150860f81b3c88799ea78ddde7ca9e30a9def127,i386_04,"# Ubuntu 14.04 LTS i386 server # Default scripts for all Ubuntu installs : ${BASE_INSTALL_SCRIPTS:=scripts.ubuntu_base} #------------------------------------------------------------------------------- # Installation from ISO image #------------------------------------------------------------------------------- readonly ISO_URL_BASE=http://releases.ubuntu.com/14.04/ ISO_URL=$ISO_URL_BASE/ubuntu-14.04.3-server-i386.iso ISO_MD5=352009d5b44f0e97c9558919f0147c0c readonly _PS_ssh=http://git.openstack.org/cgit/openstack/training-labs/plain/labs/osbash/lib/osbash/netboot/preseed-ssh-v2.cfg readonly _PS_vbadd=http://git.openstack.org/cgit/openstack/training-labs/plain/labs/osbash/lib/osbash/netboot/preseed-vbadd.cfg readonly _PS_all=http://git.openstack.org/cgit/openstack/training-labs/plain/labs/osbash/lib/osbash/netboot/preseed-all-v2.cfg # Arguments for ISO image installer readonly _BOOT_ARGS=""/install/vmlinuz noapic preseed/url=%s debian-installer=en_US auto=true locale=en_US hostname=osbash fb=false debconf/frontend=noninteractive keyboard-configuration/modelcode=SKIP initrd=/install/initrd.gz console-setup/ask_detect=false"" # Fallback function to find current ISO image in case the file in ISO_URL is # neither on the disk nor at the configured URL. # This mechanism was added because old Ubuntu ISOs are removed from the server # as soon as a new ISO appears. function update_iso_variables { # Get matching line from distro repo's MD5SUMS file, e.g. # ""9e5fecc94b3925bededed0fdca1bd417 *ubuntu-14.04.3-server-i386.iso"" local distro_info=$(wget -O - $ISO_URL_BASE/MD5SUMS|grep server-i386) # First part (removing everything after first space) is the md5sum ISO_MD5=${distro_info%% *} # Second part (keeping everything after ' *') is the ISO file name local iso_file=${distro_info#* \*} ISO_URL=$ISO_URL_BASE/$iso_file echo -e >&2 ""${CStatus:-}New ISO_URL: ${CData:-}$ISO_URL${CReset:-}"" } # Boot the ISO image operating system installer function vbox_distro_start_installer { local vm_name=$1 # pick a _PS_* file local preseed=_PS_$VM_ACCESS echo ""Using $preseed ${!preseed}"" local boot_args=$(printf ""$_BOOT_ARGS"" ""${!preseed}"") vbox_kbd_escape_key ""$vm_name"" vbox_kbd_escape_key ""$vm_name"" vbox_kbd_enter_key ""$vm_name"" vbox_sleep 1 echo -e ""${CStatus:-}Pushing boot command line${CReset:-}"" vbox_kbd_string_input ""$vm_name"" ""$boot_args"" echo ""Initiating boot sequence"" vbox_kbd_enter_key ""$vm_name"" } #------------------------------------------------------------------------------- # Installation from Internet server (if ISO image cannot be used, e.g. with KVM) #------------------------------------------------------------------------------- readonly DISTRO_URL=http://archive.ubuntu.com/ubuntu/dists/trusty/main/installer-i386/ # Extra arguments for virt-install readonly EXTRA_ARGS=""locale=en_US.UTF-8 console-keymaps-at/keymap=us console-setup/ask_detect=false console-setup/layoutcode=us keyboard-configuration/layout=USA keyboard-configuration/variant=US netcfg/get_hostname=osbash netcfg/get_domainname=local mirror/country=CH mirror/http/directory=/ubuntu mirror/http/mirror=ch.archive.ubuntu.com mirror/protocol=http mirror/http/proxy= preseed/url=${_PS_ssh}"" # vim: set ai ts=4 sw=4 et ft=sh: ",,100,1
openstack%2Ftraining-labs~master~Ia5f798001431031025c47f5f01f63851f06a5fcd,openstack/training-labs,master,Ia5f798001431031025c47f5f01f63851f06a5fcd,KVM snapshot support,MERGED,2016-03-02 19:20:45.000000000,2016-03-06 16:15:50.000000000,2016-03-06 16:15:50.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-02 19:20:45.000000000', 'files': ['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/kvm-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/b7aa2d19bf2c1b423693caf6823372c29ee496e9', 'message': 'KVM snapshot support\n\nThis patch implements the functions necessary for KVM to support\nsnapshots.\n\nIt also enables vm_delete to delete snapshots and removes the warning\ndue to missing snapshot support from restore-cluster.\n\nChange-Id: Ia5f798001431031025c47f5f01f63851f06a5fcd\n'}]",0,287399,b7aa2d19bf2c1b423693caf6823372c29ee496e9,9,3,1,11109,,,0,"KVM snapshot support

This patch implements the functions necessary for KVM to support
snapshots.

It also enables vm_delete to delete snapshots and removes the warning
due to missing snapshot support from restore-cluster.

Change-Id: Ia5f798001431031025c47f5f01f63851f06a5fcd
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/99/287399/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/tools/restore-cluster.sh', 'labs/osbash/lib/osbash/kvm-functions.sh']",2,b7aa2d19bf2c1b423693caf6823372c29ee496e9,kvm_snapshots_06,"#------------------------------------------------------------------------------- # Snapshots #------------------------------------------------------------------------------- function vm_snapshot_list_tree { local vm_name=$1 $VIRSH snapshot-list --tree ""$vm_name"" } function vm_snapshot_list { local vm_name=$1 $VIRSH snapshot-list ""$vm_name"" } function vm_snapshot_exists { local vm_name=$1 local shot_name=$2 vm_snapshot_list ""$vm_name"" | grep -q ""^ $shot_name "" local vm_name=$1 local shot_name=$2 $VIRSH snapshot-create-as ""$vm_name"" ""$shot_name"" ""$vm_name: $shot_name"" } function vm_snapshot_restore { local vm_name=$1 local shot_name=$2 $VIRSH snapshot-revert ""$vm_name"" ""$shot_name"" } function vm_snapshot_restore_current { local $vm_name=$1 $VIRSH snapshot-revert ""$vm_name"" --current $VIRSH undefine --snapshots-metadata --remove-all-storage ""$vm_name""","function vm_snapshot_exists { : # Not implemented : # Not implemented $VIRSH undefine ""$vm_name""",38,10
openstack%2Ftraining-labs~master~I809e485844b343bc1a39302396ec0f68a6801371,openstack/training-labs,master,I809e485844b343bc1a39302396ec0f68a6801371,Split logs by installation phase,MERGED,2016-03-06 06:58:00.000000000,2016-03-06 16:15:45.000000000,2016-03-06 16:15:45.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-06 06:58:00.000000000', 'files': ['labs/osbash/tools/log_snapshot_split.py', 'labs/osbash/lib/functions.guest.sh', 'labs/osbash/tools/get_node_logs.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/5f94f7bd8a1743c6cbcdd18b55cf1f1a67bb320b', 'message': 'Split logs by installation phase\n\nThis patch provides a mechanism for splitting server log files from\nnodes into chunks that correspond to time periods (by default, roughly\nfrom the begin of every script start to the begin of the next script\nstart).\n\nIn order to minimize the resources used for this (compute and storage),\nthe log_point function uses ls(1) to record the size of interesting\nlog files. These ls-snapshots are retrieved at the end of a\nrepeat-test run along with the long files.\n\nA new tool, log_snapshot_split, uses that information to create a\ndirectory for each snapshot. For all observed log files, each directory\ncontain the files and lines written since the previous ls-snapshot.\n\nThe whole tool chain can be called manually but is automatically used\nby repeat-test.sh.\n\nChange-Id: I809e485844b343bc1a39302396ec0f68a6801371\n'}]",0,288981,5f94f7bd8a1743c6cbcdd18b55cf1f1a67bb320b,7,3,1,11109,,,0,"Split logs by installation phase

This patch provides a mechanism for splitting server log files from
nodes into chunks that correspond to time periods (by default, roughly
from the begin of every script start to the begin of the next script
start).

In order to minimize the resources used for this (compute and storage),
the log_point function uses ls(1) to record the size of interesting
log files. These ls-snapshots are retrieved at the end of a
repeat-test run along with the long files.

A new tool, log_snapshot_split, uses that information to create a
directory for each snapshot. For all observed log files, each directory
contain the files and lines written since the previous ls-snapshot.

The whole tool chain can be called manually but is automatically used
by repeat-test.sh.

Change-Id: I809e485844b343bc1a39302396ec0f68a6801371
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/81/288981/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/tools/log_snapshot_split.py', 'labs/osbash/lib/functions.guest.sh', 'labs/osbash/tools/get_node_logs.sh']",3,5f94f7bd8a1743c6cbcdd18b55cf1f1a67bb320b,log_logs_04," echo -e ""Splitting log files into:\n\t$node_dir/split_logs"" ""$TOP_DIR/tools/log_snapshot_split.py"" \ --logdir ""$node_dir/log"" \ --resultdir ""$node_dir/split_logs"" \ ""$node_dir/log""",,257,0
openstack%2Ftraining-labs~master~Ice78a901402078a32138250d5b767fed3f8d19d0,openstack/training-labs,master,Ice78a901402078a32138250d5b767fed3f8d19d0,While loop style change,MERGED,2016-03-06 08:54:28.000000000,2016-03-06 16:15:31.000000000,2016-03-06 16:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-06 08:54:28.000000000', 'files': ['labs/osbash/scripts/test/launch_instance_private_net.sh', 'labs/osbash/scripts/ubuntu/setup_cinder_volumes.sh', 'labs/osbash/lib/functions.sh', 'labs/osbash/lib/osbash/kvm-functions.sh', 'labs/osbash/scripts/config_private_network.sh', 'labs/osbash/lib/osbash/functions-host.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/06e403ec61cc256fb42d79b86f3ee410440f8e52', 'message': 'While loop style change\n\nInstead of using ""while [ : ] ; do"", use ""while : ; do"". This makes\nshellcheck happy.\n\nChange-Id: Ice78a901402078a32138250d5b767fed3f8d19d0\n'}]",0,288993,06e403ec61cc256fb42d79b86f3ee410440f8e52,7,3,1,11109,,,0,"While loop style change

Instead of using ""while [ : ] ; do"", use ""while : ; do"". This makes
shellcheck happy.

Change-Id: Ice78a901402078a32138250d5b767fed3f8d19d0
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/93/288993/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/scripts/test/launch_instance_private_net.sh', 'labs/osbash/scripts/ubuntu/setup_cinder_volumes.sh', 'labs/osbash/lib/functions.sh', 'labs/osbash/lib/osbash/kvm-functions.sh', 'labs/osbash/lib/osbash/functions-host.sh', 'labs/osbash/lib/osbash/virtualbox-functions.sh', 'labs/osbash/scripts/config_private_network.sh']",7,06e403ec61cc256fb42d79b86f3ee410440f8e52,loop_style, while : ; do, while [ : ]; do,12,12
openstack%2Ftraining-labs~master~I93edb4d327d37cefda55533056ffc5efd8d836ac,openstack/training-labs,master,I93edb4d327d37cefda55533056ffc5efd8d836ac,Use variable names from install-guide,MERGED,2016-03-06 06:49:37.000000000,2016-03-06 16:14:03.000000000,2016-03-06 16:14:03.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2016-03-06 06:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-labs/commit/1f7132c9b56f9d1c6918abb84d0359e64e2b3f22', 'message': 'Use variable names from install-guide\n\nUse the names for passwords from the install-guide (RABBIT_PASS,\nKEYSTONE_DBPASS, NEUTRON_PASS etc.) so they are easier to find.\n\nChange-Id: I93edb4d327d37cefda55533056ffc5efd8d836ac\n'}, {'number': 2, 'created': '2016-03-06 10:59:24.000000000', 'files': ['labs/osbash/scripts/ubuntu/setup_cinder_controller.sh', 'labs/osbash/scripts/ubuntu/setup_glance.sh', 'labs/osbash/scripts/ubuntu/setup_telemetry_compute.sh', 'labs/osbash/scripts/ubuntu/setup_telemetry_controller.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_compute.sh', 'labs/osbash/lib/functions.guest.sh', 'labs/osbash/scripts/ubuntu/install_rabbitmq.sh', 'labs/osbash/scripts/ubuntu/setup_cinder_volumes.sh', 'labs/osbash/scripts/ubuntu/setup_nova_compute.sh', 'labs/osbash/scripts/ubuntu/setup_heat_controller.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_controller.sh', 'labs/osbash/config/admin-openstackrc.sh', 'labs/osbash/config/demo-openstackrc.sh', 'labs/osbash/config/credentials', 'labs/osbash/scripts/ubuntu/setup_self-service_controller.sh', 'labs/osbash/scripts/ubuntu/setup_nova_controller.sh', 'labs/osbash/scripts/ubuntu/setup_keystone.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_compute_part_2.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_controller_part_2.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/922dd34d490119b5275cb1597ea8b334b5bb7093', 'message': 'Use variable names from install-guide\n\nUse the names for passwords from the install-guide (RABBIT_PASS,\nKEYSTONE_DBPASS, NEUTRON_PASS etc.) so they are easier to find.\n\nRemove function service_to_db_password which is no longer used.\n\nChange-Id: I93edb4d327d37cefda55533056ffc5efd8d836ac\n'}]",0,288979,922dd34d490119b5275cb1597ea8b334b5bb7093,12,3,2,11109,,,0,"Use variable names from install-guide

Use the names for passwords from the install-guide (RABBIT_PASS,
KEYSTONE_DBPASS, NEUTRON_PASS etc.) so they are easier to find.

Remove function service_to_db_password which is no longer used.

Change-Id: I93edb4d327d37cefda55533056ffc5efd8d836ac
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/79/288979/2 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/scripts/ubuntu/setup_cinder_controller.sh', 'labs/osbash/scripts/ubuntu/setup_glance.sh', 'labs/osbash/scripts/ubuntu/setup_telemetry_compute.sh', 'labs/osbash/scripts/ubuntu/setup_telemetry_controller.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_compute.sh', 'labs/osbash/lib/functions.guest.sh', 'labs/osbash/scripts/ubuntu/install_rabbitmq.sh', 'labs/osbash/scripts/ubuntu/setup_cinder_volumes.sh', 'labs/osbash/scripts/ubuntu/setup_nova_compute.sh', 'labs/osbash/scripts/ubuntu/setup_heat_controller.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_controller.sh', 'labs/osbash/config/admin-openstackrc.sh', 'labs/osbash/config/demo-openstackrc.sh', 'labs/osbash/config/credentials', 'labs/osbash/scripts/ubuntu/setup_self-service_controller.sh', 'labs/osbash/scripts/ubuntu/setup_nova_controller.sh', 'labs/osbash/scripts/ubuntu/setup_keystone.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_compute_part_2.sh', 'labs/osbash/scripts/ubuntu/setup_neutron_controller_part_2.sh']",19,1f7132c9b56f9d1c6918abb84d0359e64e2b3f22,password_vars,"iniset_sudo $conf DEFAULT password ""$NEUTRON_PASS""iniset_sudo $conf neutron password ""$NEUTRON_PASS""","neutron_admin_password=$(service_to_user_password neutron)iniset_sudo $conf DEFAULT password ""$neutron_admin_password""iniset_sudo $conf neutron password ""$neutron_admin_password""",87,90
openstack%2Fneutron~master~I4573eac9a2e04c1f126d26591d2e3207b6150337,openstack/neutron,master,I4573eac9a2e04c1f126d26591d2e3207b6150337,ovs-fw: Enhance port ranges with masks,MERGED,2016-02-23 15:54:26.000000000,2016-03-06 16:04:31.000000000,2016-02-24 14:11:02.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 13995}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-23 15:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60302cb0d4ae90c7254b6280571757d2fcbd35e7', 'message': 'ovs-fw: Enhance port ranges with masks\n\nThe algorithm for masking port range was taken from networking-ovs-dpdk.\nFuture step will be to move the algorithm to neutron-lib and reuse in\nnetworking-ovs-dpdk.\n\nChange-Id: I4573eac9a2e04c1f126d26591d2e3207b6150337\n'}, {'number': 2, 'created': '2016-02-23 16:39:51.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/rules.py', 'neutron/common/utils.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_rules.py', 'neutron/tests/unit/common/test_utils.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9af8f56d1d7d96517b6252ee1bd7c03ca1cbab72', 'message': 'ovs-fw: Enhance port ranges with masks\n\nThe algorithm for masking port range was taken from networking-ovs-dpdk.\nFuture step will be to move the algorithm to neutron-lib and reuse in\nnetworking-ovs-dpdk.\n\nChange-Id: I4573eac9a2e04c1f126d26591d2e3207b6150337\n'}]",6,283655,9af8f56d1d7d96517b6252ee1bd7c03ca1cbab72,30,16,2,8655,,,0,"ovs-fw: Enhance port ranges with masks

The algorithm for masking port range was taken from networking-ovs-dpdk.
Future step will be to move the algorithm to neutron-lib and reuse in
networking-ovs-dpdk.

Change-Id: I4573eac9a2e04c1f126d26591d2e3207b6150337
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/283655/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/openvswitch_firewall/rules.py', 'neutron/common/utils.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_rules.py', 'neutron/tests/unit/common/test_utils.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py']",5,60302cb0d4ae90c7254b6280571757d2fcbd35e7,ovsfw/portranges, tcp_dst='0x007b'), tcp_dst=123),156,23
openstack%2Ffuel-web~master~I07a823eb793e784dda99900075df01ac757f448e,openstack/fuel-web,master,I07a823eb793e784dda99900075df01ac757f448e,[Docs] Update documentation about nailgun fake mode deployment,ABANDONED,2016-02-17 20:52:49.000000000,2016-03-06 15:56:13.000000000,,"[{'_account_id': 3}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12817}, {'_account_id': 14342}, {'_account_id': 14396}, {'_account_id': 14543}, {'_account_id': 14643}, {'_account_id': 14947}, {'_account_id': 14962}, {'_account_id': 15454}, {'_account_id': 17626}, {'_account_id': 18446}, {'_account_id': 18769}]","[{'number': 1, 'created': '2016-02-17 20:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9936f2fc89acc2290465d05808964eccb42e05c', 'message': '[Docs] Update documentation about nailgun fake mode deployment\n\n* update documentation about fake mode deployment/running\n* add script which can be used for automated fake env creation\n\nChange-Id: I07a823eb793e784dda99900075df01ac757f448e\n'}, {'number': 2, 'created': '2016-02-18 07:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4b687c6d812dc67efe915e62ba20029006803b0a', 'message': '[Docs] Update documentation about nailgun fake mode deployment\n\n* update documentation about fake mode deployment/running\n* add script which can be used for automated fake env creation\n\nChange-Id: I07a823eb793e784dda99900075df01ac757f448e\n'}, {'number': 3, 'created': '2016-02-23 17:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6f46d66314304782db067f656319f692c126f15f', 'message': '[Docs] Update documentation about nailgun fake mode deployment\n\n* update documentation about fake mode deployment/running\n* add script which can be used for automated fake env creation\n\nChange-Id: I07a823eb793e784dda99900075df01ac757f448e\n'}, {'number': 4, 'created': '2016-02-23 17:39:57.000000000', 'files': ['nailgun/prepare_fake_env.sh', 'docs/develop/nailgun/development/env.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fc4343badd071f5d2bb508622ae7e104bc135460', 'message': '[Docs] Update documentation about nailgun fake mode deployment\n\n* update documentation about fake mode deployment/running\n* add script which can be used for automated fake env creation\n\nChange-Id: I07a823eb793e784dda99900075df01ac757f448e\n'}]",13,281521,fc4343badd071f5d2bb508622ae7e104bc135460,39,17,4,18446,,,0,"[Docs] Update documentation about nailgun fake mode deployment

* update documentation about fake mode deployment/running
* add script which can be used for automated fake env creation

Change-Id: I07a823eb793e784dda99900075df01ac757f448e
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/21/281521/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/develop/nailgun/development/env.rst'],1,c9936f2fc89acc2290465d05808964eccb42e05c,,#. Install and configure PostgreSQL database::#. Install dependency packages:: sudo apt-get install --yes libjpeg-dev libyaml-dev #. Install virtualenv. This step increases flexibility when dealing with environment settings and package installation:: sudo apt-get install python-virtualenv virtualenvwrapper mkvirtualenv fuel # you can use any name instead of 'fuel' workon fuel # select the particular virtual environment sudo apt-get install --yes nodejs nodejs-legacy sudo apt-get install --yes npm npm install gulp python manage.py run -p 8000 --fake-tasks | egrep --line-buffered -v '^$|HTTP' >> /var/log/nailgun/nailgun.log 2>&1 & python manage.py run -p 8000 --fake-tasks-amqp | egrep --line-buffered -v '^$|HTTP' >> /var/log/nailgun/nailgun.log 2>&1 & node_modules/.bin/gulp build node_modules/.bin/gulp build --static-dir=static_compressed node_modules/.bin/gulp build --no-uglify --no-sourcemaps node_modules/.bin/gulp build dev-server node_modules/.bin/gulp build dev-server --dev-server-host=127.0.0.1 --dev-server-port=8080 --nailgun-host=127.0.0.1 --nailgun-port=8000 node_modules/.bin/gulp build build --watch,#. Install and configure PostgreSQL database. Please note that Ubuntu 12.04 requires postgresql-server-dev-9.1 while Ubuntu 14.04 requires postgresql-server-dev-9.3::#. Install virtualenv. This step increases flexibility when dealing with environment settings and package installation: sudo pip install virtualenv virtualenvwrapper . /usr/local/bin/virtualenvwrapper.sh # you can save this to .bashrc mkvirtualenv fuel # you can use any name instead of 'fuel' workon fuel # command selects the particular environment sudo apt-get remove --yes nodejs nodejs-legacy sudo apt-get install --yes software-properties-common sudo add-apt-repository --yes ppa:chris-lea/node.js sudo apt-get update sudo apt-get install --yes nodejs sudo npm install -g gulp python manage.py run -p 8000 --fake-tasks | egrep --line-buffered -v '^$|HTTP' >> /var/log/nailgun.log 2>&1 & python manage.py run -p 8000 --fake-tasks-amqp | egrep --line-buffered -v '^$|HTTP' >> /var/log/nailgun.log 2>&1 & gulp build gulp build --static-dir=static_compressed gulp build --no-uglify --no-sourcemaps gulp dev-server gulp dev-server --dev-server-host=127.0.0.1 --dev-server-port=8080 --nailgun-host=127.0.0.1 --nailgun-port=8000 gulp build --watch,21,23
openstack%2Fi18n~master~I84ab0af9545407e7ce02028caac4738acbe24cd5,openstack/i18n,master,I84ab0af9545407e7ce02028caac4738acbe24cd5,Add unmaintained/out-of-date warning to Japanese glossary,MERGED,2016-02-27 17:37:14.000000000,2016-03-06 15:55:13.000000000,2016-03-06 15:55:13.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 3108}, {'_account_id': 10497}, {'_account_id': 14482}, {'_account_id': 16308}]","[{'number': 1, 'created': '2016-02-27 17:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/d00aeedef7d2bbf1c8ff9ce260fdcfa2b49b0dd2', 'message': 'Remove all glossary entries in Japanese\n\nThe current Zanata glossary only supports translation words\nand cannot contains contextual information which is important\nfor translations. As far as I heard, the latest Zanata supports\ncontextual information and useful glossary editors. Once OpenStack\nZanata instance is upgraded, then Japanese team considers using\nZanata glossary. Until then, we decided to maintain Japanese\nglossary on OpenStack wiki.\n\nChange-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5\n'}, {'number': 2, 'created': '2016-02-27 17:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/bfad2ddb6f95d75fed5529f508e2094b75d65f05', 'message': 'Remove all glossary entries in Japanese\n\nThe current Zanata glossary only supports translation words\nand cannot contains contextual information which is important\nfor translations. As far as I heard, the latest Zanata supports\ncontextual information and useful glossary editors. Once OpenStack\nZanata instance is upgraded, then Japanese team considers using\nZanata glossary. Until then, we decided to maintain Japanese\nglossary on OpenStack wiki.\n\nChange-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5\n'}, {'number': 3, 'created': '2016-03-05 19:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/193ed763550029f1c0a61a09e1750085ce81f019', 'message': 'Delete Japanese glossary to sync with Zanata\n\nThe current Zanata glossary only supports translation words\nand cannot contains contextual information which is important\nfor translations. As far as I heard, the latest Zanata supports\ncontextual information and useful glossary editors. Once OpenStack\nZanata instance is upgraded, then Japanese team considers using\nZanata glossary. Until then, we decided to maintain Japanese\nglossary on OpenStack wiki.\n\nJapanese glossary on Zanata has been deleted.\nThere is no meaning to have it only on the repo.\n\nChange-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5\n'}, {'number': 4, 'created': '2016-03-06 11:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/97ec4f79bfdf48d68ab04ad53412915a3e5afb0a', 'message': 'Add unmaintained/out-of-date warning to Japanese glossary\n\nThe current Zanata glossary only supports translation words\nand cannot contains contextual information which is important\nfor translations. As far as I heard, the latest Zanata supports\ncontextual information and useful glossary editors. Once OpenStack\nZanata instance is upgraded, then Japanese team considers using\nZanata glossary. Until then, we decided to maintain Japanese\nglossary on OpenStack wiki.\n\nJapanese glossary on Zanata has been deleted.\nThere is no meaning to have it only on the repo,\nbut other i18n team members prefer to keeping it,\nso this commit adds warnings.\n\nChange-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5\n'}, {'number': 5, 'created': '2016-03-06 11:52:13.000000000', 'files': ['i18n/locale/ja/LC_MESSAGES/i18n.po'], 'web_link': 'https://opendev.org/openstack/i18n/commit/1ade2661dddf8688be0d012d789b6d36e36f9ebc', 'message': 'Add unmaintained/out-of-date warning to Japanese glossary\n\nThe current Zanata glossary only supports translation words\nand cannot contains contextual information which is important\nfor translations. As far as I heard, the latest Zanata supports\ncontextual information and useful glossary editors. Once OpenStack\nZanata instance is upgraded, then Japanese team considers using\nZanata glossary. Until then, we decided to maintain Japanese\nglossary on OpenStack wiki.\n\nJapanese glossary on Zanata has been deleted.\nThere is no meaning to have it only on the repo,\nbut other i18n team members prefer to keeping it,\nso this commit adds warnings.\n\nChange-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5\n'}]",1,285725,1ade2661dddf8688be0d012d789b6d36e36f9ebc,28,6,5,841,,,0,"Add unmaintained/out-of-date warning to Japanese glossary

The current Zanata glossary only supports translation words
and cannot contains contextual information which is important
for translations. As far as I heard, the latest Zanata supports
contextual information and useful glossary editors. Once OpenStack
Zanata instance is upgraded, then Japanese team considers using
Zanata glossary. Until then, we decided to maintain Japanese
glossary on OpenStack wiki.

Japanese glossary on Zanata has been deleted.
There is no meaning to have it only on the repo,
but other i18n team members prefer to keeping it,
so this commit adds warnings.

Change-Id: I84ab0af9545407e7ce02028caac4738acbe24cd5
",git fetch https://review.opendev.org/openstack/i18n refs/changes/25/285725/1 && git format-patch -1 --stdout FETCH_HEAD,['i18n/locale/ja/LC_MESSAGES/i18n.po'],1,d00aeedef7d2bbf1c8ff9ce260fdcfa2b49b0dd2,ja-glossary,"""PO-Revision-Date: 2016-02-27 23:49+0900\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"","""PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n""msgstr ""IPの確保 (※Associate ととの調整必要あり)""msgstr ""アーキテクチャ""msgstr ""IP確保 or IP割り当て(Allocateとの区別から \""IP割り当て\"" を希望)""msgstr ""認証""msgstr ""許可(ただし文脈による)""msgstr ""バックエンド(?)""msgstr ""ブート""msgstr ""CIDR(訳さない)""msgstr ""???""msgstr ""コンテナ(Swift用?)""msgstr ""格納形式(?)""msgstr ""（資格情報）（認証情報）（認証資格）""msgstr ""宛先コンテナ""msgstr ""宛先オブジェクト名""msgstr ""IP解放""msgstr ""ディスクフォーマット""msgstr ""ディスク GB×時間(ディスク使用量(GB×時間))""msgstr ""一時ディスク""msgstr ""?""msgstr ""フィンガープリント""msgstr ""Fixed IP(訳さない)""msgstr ""インスタンスタイプ""msgstr ""Floating IP(訳さない)""msgstr ""イメージ""msgstr ""イニシエーター""msgstr ""Injected Files(?)""msgstr ""インスタンス""msgstr ""キーペア""msgstr ""起動""msgstr ""メモリー""msgstr ""オブジェクト""msgstr ""パラメーター""msgstr ""Perfect Forward Secrecy""msgstr ""プロジェクト""msgstr ""公開鍵""msgstr ""クォータ""msgstr ""リブート""msgstr ""リージョン(?)""msgstr ""ロール(?)""msgstr ""セキュリティグループ""msgstr ""サーバー""msgstr ""送信""msgstr ""システムパネル""msgstr ""プロジェクト (※テナントから変更)""msgstr ""使用状況(?)""msgstr ""ユーザー""msgstr ""ボリュームスナップショット""msgstr ""仮想CPU 時間(?)""msgstr ""パラメーター""",50,50
openstack%2Ffuel-plugins~master~If5640429a237e7cc87ac8f7b09205bd13d08eea2,openstack/fuel-plugins,master,If5640429a237e7cc87ac8f7b09205bd13d08eea2,Fix fpb 4.0.0 deployment_task.yaml validation file process,ABANDONED,2016-03-06 07:39:18.000000000,2016-03-06 15:49:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 12200}, {'_account_id': 14167}, {'_account_id': 18446}]","[{'number': 1, 'created': '2016-03-06 07:39:18.000000000', 'files': ['fuel_plugin_builder/validators/validator_v4.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/9f6316e642a9f480bea8a13825754a0cc810bbc5', 'message': 'Fix fpb 4.0.0 deployment_task.yaml validation file process\n\nThis issue is that fpb 4.0.0 validator uses tasks_path attribute\nwith deprecated ""tasks.yaml"" filename value from fpb 2.0.0 validator.\nA new ""deployment_tasks_path.yaml"" filename value that is stored\nin deployment_tasks_path attribute defined in fpb 3.0.0 validator\nmust be used instead.\n\nChange-Id: If5640429a237e7cc87ac8f7b09205bd13d08eea2\nCloses-Bug: 1552248\n'}]",0,288985,9f6316e642a9f480bea8a13825754a0cc810bbc5,6,5,1,18446,,,0,"Fix fpb 4.0.0 deployment_task.yaml validation file process

This issue is that fpb 4.0.0 validator uses tasks_path attribute
with deprecated ""tasks.yaml"" filename value from fpb 2.0.0 validator.
A new ""deployment_tasks_path.yaml"" filename value that is stored
in deployment_tasks_path attribute defined in fpb 3.0.0 validator
must be used instead.

Change-Id: If5640429a237e7cc87ac8f7b09205bd13d08eea2
Closes-Bug: 1552248
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/85/288985/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_plugin_builder/validators/validator_v4.py'],1,9f6316e642a9f480bea8a13825754a0cc810bbc5,bug/1552248," self.deployment_tasks_path, """"""Check legacy deployment_tasks.yaml."""""" logger.debug('Start tasks checking ""%s""', self.deployment_tasks_path) if utils.exists(self.deployment_tasks_path): tasks = utils.parse_yaml(self.deployment_tasks_path) self.deployment_tasks_path, logger.debug('File ""%s"" doesn\'t exist', self.deployment_tasks_path)"," self.tasks_path, """"""Check legacy tasks.yaml."""""" logger.debug('Start tasks checking ""%s""', self.tasks_path) if utils.exists(self.tasks_path): tasks = utils.parse_yaml(self.tasks_path) self.tasks_path, logger.debug('File ""%s"" doesn\'t exist', self.tasks_path)",8,7
openstack%2Fkolla~master~I6d9531ce4513ed06f1d13081418b167ad264aaff,openstack/kolla,master,I6d9531ce4513ed06f1d13081418b167ad264aaff,Add two more examples of openrc for use with public endpoints,MERGED,2016-03-03 22:50:20.000000000,2016-03-06 15:23:26.000000000,2016-03-06 15:23:26.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 11561}, {'_account_id': 13642}, {'_account_id': 14119}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-03-03 22:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2027c3c65316ca131728616a752a4a2eabcd6cd8', 'message': 'Add two more flavors of openrc to post-deploy\n\nkolla-ansible post-desploy creates an admin-openrc.sh file,\nthat when sourced primes the environment variables to make\nclient requests to the admin endpoint.\n\nThis patch adds public-openrc.sh and secure-openrc.sh which\ncan be use to make client requests to the external endpoints.\n\nPartially-implements: blueprint kolla-ssl\n\nChange-Id: I6d9531ce4513ed06f1d13081418b167ad264aaff\n'}, {'number': 2, 'created': '2016-03-05 17:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/24c4db7bbb24a7f9eee35fac37c2d35f53c6f288', 'message': 'Add two more examples of openrc for use with public endpoints\n\nRelates-to: blueprint kolla-ssl\n\nChange-Id: I6d9531ce4513ed06f1d13081418b167ad264aaff\n'}, {'number': 3, 'created': '2016-03-06 01:45:28.000000000', 'files': ['tools/openrc-example'], 'web_link': 'https://opendev.org/openstack/kolla/commit/25f99ad9303373c8692883ee9b3140e259796825', 'message': 'Add two more examples of openrc for use with public endpoints\n\nRelates-to: blueprint kolla-ssl\n\nChange-Id: I6d9531ce4513ed06f1d13081418b167ad264aaff\n'}]",6,288165,25f99ad9303373c8692883ee9b3140e259796825,23,7,3,11561,,,0,"Add two more examples of openrc for use with public endpoints

Relates-to: blueprint kolla-ssl

Change-Id: I6d9531ce4513ed06f1d13081418b167ad264aaff
",git fetch https://review.opendev.org/openstack/kolla refs/changes/65/288165/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/templates/public-openrc.sh.j2', 'ansible/post-deploy.yml', 'ansible/roles/common/templates/secure-openrc.sh.j2']",3,2027c3c65316ca131728616a752a4a2eabcd6cd8,bp/kolla-ssl,export OS_PROJECT_DOMAIN_ID=default export OS_USER_DOMAIN_ID=default export OS_PROJECT_NAME=admin export OS_TENANT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD={{ keystone_admin_password }} export OS_AUTH_URL=https://{{ kolla_external_fqdn }}:{{ keystone_public_port }}/v3 export OS_IDENTITY_API_VERSION=3 export OS_CACERT={{ kolla_external_fqdn_cacert }} ,,23,2
openstack%2Fkolla~master~I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c,openstack/kolla,master,I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c,Reconfigure for Swift,MERGED,2016-03-05 01:33:30.000000000,2016-03-06 15:19:11.000000000,2016-03-06 15:19:11.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 13642}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-05 01:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3da192295afa839588a690cd55901bcb41cfea28', 'message': 'Partially-Implements: blueprint kolla-reconfig\n\nReconfigure for Swift\n\nThis implements reconfigure for Swift service. Fixes swift-rsyncd in All-in-One deployment\n\nChange-Id: I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c\n'}, {'number': 2, 'created': '2016-03-05 02:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8db7128a5f84d3ba8f101b26e1427522b664ebe9', 'message': 'Reconfigure for Swift\n\nThis implements reconfigure for Swift service. Fixes swift-rsyncd in All-in-One deployment\n\nPartially-Implements: blueprint kolla-reconfig\n\nChange-Id: I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c\n'}, {'number': 3, 'created': '2016-03-05 15:27:49.000000000', 'files': ['ansible/roles/swift/tasks/do_reconfigure.yml', 'ansible/roles/swift/tasks/start.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/514da1760546a89faddddc274e74a7fa78650d5b', 'message': 'Reconfigure for Swift\n\nThis implements reconfigure for Swift service. Fixes swift-rsyncd in\nAll-in-One deployment\n\nPartially-Implements: blueprint kolla-reconfig\n\nChange-Id: I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c\n'}]",3,288824,514da1760546a89faddddc274e74a7fa78650d5b,17,5,3,19384,,,0,"Reconfigure for Swift

This implements reconfigure for Swift service. Fixes swift-rsyncd in
All-in-One deployment

Partially-Implements: blueprint kolla-reconfig

Change-Id: I82bfa3c73b7365bc3a0ea35d3fc102a3525ebd8c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/24/288824/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/swift/tasks/do_reconfigure.yml', 'ansible/roles/swift/tasks/start.yml']",2,3da192295afa839588a690cd55901bcb41cfea28,bp/kolla-reconfig, when: inventory_hostname in groups['swift-account-server'] or inventory_hostname in groups['swift-container-server'] or inventory_hostname in groups['swift-object-server'], when: inventory_hostname not in groups['swift-proxy-server'],20,8
openstack%2Frequirements~master~I1f784993a7c0538da99e3104a625e4920833d9e3,openstack/requirements,master,I1f784993a7c0538da99e3104a625e4920833d9e3,Fixup case sensitive names in upper-constraints,MERGED,2016-03-06 13:17:13.000000000,2016-03-06 15:10:34.000000000,2016-03-06 15:10:34.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-06 13:17:13.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/25b778138f7d7ff97f37d0a2360de2f0bdcc2794', 'message': 'Fixup case sensitive names in upper-constraints\n\nThe proposal bot picks up the right case for the names\nto update upper-constraints.txt, so we should fix it\n\napscheduler -> APScheduler:\nhttps://bitbucket.org/agronholm/apscheduler/src/ec775f9d2ce34f689fcbae28e2ab9200ddd6fa71/setup.py?fileviewer=file-view-default#setup.py-14\n\ncouchdb -> CouchDB:\nhttps://github.com/djc/couchdb-python/blob/master/setup.py#L45\n\nExample output from proposal bot:\nhttps://review.openstack.org/#/c/288849/2/upper-constraints.txt\n\nChange-Id: I1f784993a7c0538da99e3104a625e4920833d9e3\n'}]",0,289011,25b778138f7d7ff97f37d0a2360de2f0bdcc2794,6,2,1,5638,,,0,"Fixup case sensitive names in upper-constraints

The proposal bot picks up the right case for the names
to update upper-constraints.txt, so we should fix it

apscheduler -> APScheduler:
https://bitbucket.org/agronholm/apscheduler/src/ec775f9d2ce34f689fcbae28e2ab9200ddd6fa71/setup.py?fileviewer=file-view-default#setup.py-14

couchdb -> CouchDB:
https://github.com/djc/couchdb-python/blob/master/setup.py#L45

Example output from proposal bot:
https://review.openstack.org/#/c/288849/2/upper-constraints.txt

Change-Id: I1f784993a7c0538da99e3104a625e4920833d9e3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/11/289011/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,25b778138f7d7ff97f37d0a2360de2f0bdcc2794,,APScheduler===3.0.5CouchDB===1.0,apscheduler===3.0.5couchdb===1.0,2,2
openstack%2Fnetworking-ovn~master~I52ef68416ae41e7e0dbcd288e145ad50db3e17f7,openstack/networking-ovn,master,I52ef68416ae41e7e0dbcd288e145ad50db3e17f7,[WIP] - Test dont merge,ABANDONED,2016-03-06 13:14:14.000000000,2016-03-06 15:09:55.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-03-06 13:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0a4e8a3ed1d745484c3c71156f4e45f90ce5ce2d', 'message': '[WIP] - Test dont merge\n\nChange-Id: I52ef68416ae41e7e0dbcd288e145ad50db3e17f7\n'}, {'number': 2, 'created': '2016-03-06 13:39:42.000000000', 'files': ['README.rst', 'networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/94efda48b36d031da4b1bbbd288ebdb8e91f800b', 'message': '[WIP] - Test dont merge\n\nChange-Id: I52ef68416ae41e7e0dbcd288e145ad50db3e17f7\n'}]",0,289010,94efda48b36d031da4b1bbbd288ebdb8e91f800b,5,1,2,11343,,,0,"[WIP] - Test dont merge

Change-Id: I52ef68416ae41e7e0dbcd288e145ad50db3e17f7
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/10/289010/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,0a4e8a3ed1d745484c3c71156f4e45f90ce5ce2d,,.,,1,1
openstack%2Fpython-ironic-inspector-client~master~Iffe3066457db8528d1fcfced5790294e9bc128b7,openstack/python-ironic-inspector-client,master,Iffe3066457db8528d1fcfced5790294e9bc128b7,Updated from global requirements,MERGED,2016-03-03 18:06:07.000000000,2016-03-06 14:40:40.000000000,2016-03-06 14:40:40.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-03 18:06:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/9c3f4ea541092370b8f6101113e6489334d51e66', 'message': 'Updated from global requirements\n\nChange-Id: Iffe3066457db8528d1fcfced5790294e9bc128b7\n'}]",0,288029,9c3f4ea541092370b8f6101113e6489334d51e66,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: Iffe3066457db8528d1fcfced5790294e9bc128b7
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/29/288029/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9c3f4ea541092370b8f6101113e6489334d51e66,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Fapi-site~master~Idb94adf74bdb670cb406e93f0434274aabd23f7d,openstack/api-site,master,Idb94adf74bdb670cb406e93f0434274aabd23f7d,Remove the unnecessary method tag,ABANDONED,2016-02-14 04:16:44.000000000,2016-03-06 14:07:57.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 13702}, {'_account_id': 17958}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-02-14 04:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/4cc9b26e11a706c4cb8e16bc97b29aa35c4e185e', 'message': ""Remove the unnecessary method tag\n\nRemoving the unnecessary method tag '#showImageHeaders-v1' as\n'#showImageHeaders-v1' does not exist, '#showImage-v1' exists.\n\nChange-Id: Idb94adf74bdb670cb406e93f0434274aabd23f7d\nCloses-Bug: #1545234\n""}, {'number': 2, 'created': '2016-03-04 19:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d80bce24f5097f946f13c36a88280d792fa27624', 'message': ""Remove the unnecessary method tag\n\nRemoving the unnecessary method tag '#showImageHeaders-v1' as\n'#showImageHeaders-v1' does not exist, '#showImage-v1' exists.\n\nChange-Id: Idb94adf74bdb670cb406e93f0434274aabd23f7d\nCloses-Bug: #1545234\n""}]",0,279916,d80bce24f5097f946f13c36a88280d792fa27624,10,5,2,19840,,,0,"Remove the unnecessary method tag

Removing the unnecessary method tag '#showImageHeaders-v1' as
'#showImageHeaders-v1' does not exist, '#showImage-v1' exists.

Change-Id: Idb94adf74bdb670cb406e93f0434274aabd23f7d
Closes-Bug: #1545234
",git fetch https://review.opendev.org/openstack/api-site refs/changes/16/279916/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/image-api/src/v1/wadl/images-v1.wadl'],1,4cc9b26e11a706c4cb8e16bc97b29aa35c4e185e,bug/1545234,," <method href=""#showImageHeaders-v1""/>",0,1
openstack%2Ftraining-guides~master~Iabdbb9109456c9a6c72c2f2956114f5fd5841764,openstack/training-guides,master,Iabdbb9109456c9a6c72c2f2956114f5fd5841764,Imported Translations from Zanata,MERGED,2016-03-06 06:16:05.000000000,2016-03-06 13:17:13.000000000,2016-03-06 13:17:13.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-06 06:16:05.000000000', 'files': ['doc/upstream-training/source/locale/ja/LC_MESSAGES/upstream-training.po', 'doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po', 'doc/upstream-training/source/locale/upstream-training.pot'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/907e214a343a0b0e557612a361d1c8155900e70b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iabdbb9109456c9a6c72c2f2956114f5fd5841764\n'}]",0,288976,907e214a343a0b0e557612a361d1c8155900e70b,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iabdbb9109456c9a6c72c2f2956114f5fd5841764
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/76/288976/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/upstream-training/source/locale/ja/LC_MESSAGES/upstream-training.po', 'doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po', 'doc/upstream-training/source/locale/upstream-training.pot']",3,907e214a343a0b0e557612a361d1c8155900e70b,zanata/translations,"""POT-Creation-Date: 2016-03-06 06:15+0000\n""""OpenStack Summit. Besides this \""official\"" event, some user groups hold the "" ""local Upstream trainings.""#: ../../upstream-archives.rst:11""A big thank you to everyone that has made this possible, especially Loic "" ""Dachary, Stefano Maffulli, and Tim Freund who lead the trainings.""#: ../../upstream-archives.rst:15#: ../../upstream-archives.rst:20#: ../../upstream-archives.rst:21 ../../upstream-archives.rst:36 #: ../../upstream-archives.rst:57 ../../upstream-archives.rst:85#: ../../upstream-archives.rst:22#: ../../upstream-archives.rst:23#: ../../upstream-archives.rst:24#: ../../upstream-archives.rst:25#: ../../upstream-archives.rst:26 ../../upstream-archives.rst:42#: ../../upstream-archives.rst:27 ../../upstream-archives.rst:43#: ../../upstream-archives.rst:30#: ../../upstream-archives.rst:35#: ../../upstream-archives.rst:37 ../../upstream-archives.rst:64#: ../../upstream-archives.rst:38#: ../../upstream-archives.rst:39#: ../../upstream-archives.rst:40 ../../upstream-archives.rst:69#: ../../upstream-archives.rst:41 ../../upstream-archives.rst:73#: ../../upstream-archives.rst:44 ../../upstream-archives.rst:61#: ../../upstream-archives.rst:47#: ../../upstream-archives.rst:49#: ../../upstream-archives.rst:55#: ../../upstream-archives.rst:56#: ../../upstream-archives.rst:58 ../../upstream-archives.rst:86#: ../../upstream-archives.rst:59 ../../upstream-archives.rst:87#: ../../upstream-archives.rst:60#: ../../upstream-archives.rst:62 ../../upstream-archives.rst:89#: ../../upstream-archives.rst:63#: ../../upstream-archives.rst:65#: ../../upstream-archives.rst:66#: ../../upstream-archives.rst:67#: ../../upstream-archives.rst:68#: ../../upstream-archives.rst:70#: ../../upstream-archives.rst:71#: ../../upstream-archives.rst:72#: ../../upstream-archives.rst:76#: ../../upstream-archives.rst:78#: ../../upstream-archives.rst:84 msgid ""Loic Dachary (training, mentoring, assistant, french, english) - lead""#: ../../upstream-archives.rst:88#: ../../upstream-archives.rst:92#: ../../upstream-archives.rst:95#: ../../upstream-archives.rst:97#: ../../upstream-archives.rst:98#: ../../upstream-archives.rst:100#: ../../upstream-archives.rst:103#: ../../upstream-archives.rst:104#: ../../upstream-archives.rst:105#: ../../upstream-archives.rst:106#: ../../upstream-archives.rst:107#: ../../upstream-archives.rst:108#: ../../upstream-archives.rst:109#: ../../upstream-archives.rst:112#: ../../upstream-archives.rst:114#: ../../upstream-archives.rst:119#: ../../upstream-archives.rst:120#: ../../upstream-archives.rst:121#: ../../upstream-archives.rst:122#: ../../upstream-archives.rst:124#: ../../upstream-archives.rst:125#: ../../upstream-archives.rst:126#: ../../upstream-archives.rst:127","""POT-Creation-Date: 2016-02-27 06:18+0000\n""""OpenStack Summit. Also, some user groups hold the local upstream training in "" ""their country.""#: ../../upstream-archives.rst:10""We are appreciating all staffs, especially Loic Dachary, Stefano Maffulli, "" ""and Tim Freund who lead the training respectively.""#: ../../upstream-archives.rst:14#: ../../upstream-archives.rst:17 msgid ""2015 Tokyo Staff (Thank You!)"" msgstr """" #: ../../upstream-archives.rst:19#: ../../upstream-archives.rst:20 ../../upstream-archives.rst:35 #: ../../upstream-archives.rst:56 ../../upstream-archives.rst:84#: ../../upstream-archives.rst:21#: ../../upstream-archives.rst:22#: ../../upstream-archives.rst:23#: ../../upstream-archives.rst:24#: ../../upstream-archives.rst:25 ../../upstream-archives.rst:41#: ../../upstream-archives.rst:26 ../../upstream-archives.rst:42#: ../../upstream-archives.rst:29#: ../../upstream-archives.rst:32 msgid ""2015 Vancouver Staff (Thank You!)"" msgstr """" #: ../../upstream-archives.rst:34#: ../../upstream-archives.rst:36 ../../upstream-archives.rst:63#: ../../upstream-archives.rst:37#: ../../upstream-archives.rst:38#: ../../upstream-archives.rst:39 ../../upstream-archives.rst:68#: ../../upstream-archives.rst:40 ../../upstream-archives.rst:72#: ../../upstream-archives.rst:43 ../../upstream-archives.rst:60#: ../../upstream-archives.rst:46#: ../../upstream-archives.rst:48#: ../../upstream-archives.rst:52 msgid ""2014 Paris Staff (Thank You!)"" msgstr """" #: ../../upstream-archives.rst:54#: ../../upstream-archives.rst:55 ../../upstream-archives.rst:83#: ../../upstream-archives.rst:57 ../../upstream-archives.rst:85#: ../../upstream-archives.rst:58 ../../upstream-archives.rst:86#: ../../upstream-archives.rst:59#: ../../upstream-archives.rst:61 ../../upstream-archives.rst:88#: ../../upstream-archives.rst:62#: ../../upstream-archives.rst:64#: ../../upstream-archives.rst:65#: ../../upstream-archives.rst:66#: ../../upstream-archives.rst:67#: ../../upstream-archives.rst:69#: ../../upstream-archives.rst:70#: ../../upstream-archives.rst:71#: ../../upstream-archives.rst:75#: ../../upstream-archives.rst:77#: ../../upstream-archives.rst:81 msgid ""2014 Atlanta Staff (Thank You!)""#: ../../upstream-archives.rst:87#: ../../upstream-archives.rst:91#: ../../upstream-archives.rst:94#: ../../upstream-archives.rst:96#: ../../upstream-archives.rst:97#: ../../upstream-archives.rst:99#: ../../upstream-archives.rst:102#: ../../upstream-archives.rst:103#: ../../upstream-archives.rst:104#: ../../upstream-archives.rst:105#: ../../upstream-archives.rst:106#: ../../upstream-archives.rst:107#: ../../upstream-archives.rst:108#: ../../upstream-archives.rst:111#: ../../upstream-archives.rst:113#: ../../upstream-archives.rst:118#: ../../upstream-archives.rst:119#: ../../upstream-archives.rst:120#: ../../upstream-archives.rst:121#: ../../upstream-archives.rst:123#: ../../upstream-archives.rst:124#: ../../upstream-archives.rst:125#: ../../upstream-archives.rst:126",86,136
openstack%2Fi18n~master~I7296516a6083f64c30b6f417d5f32810bd2630cf,openstack/i18n,master,I7296516a6083f64c30b6f417d5f32810bd2630cf,glossary: remove meaningless whitespace,MERGED,2016-03-06 11:55:55.000000000,2016-03-06 12:47:58.000000000,2016-03-06 12:47:58.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-06 11:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/7c498220a8a71b0eea52f70cc4ae82218fb21238', 'message': 'Glossary: remove meaningless whitespace\n\nChange-Id: I7296516a6083f64c30b6f417d5f32810bd2630cf\n'}, {'number': 2, 'created': '2016-03-06 11:56:59.000000000', 'files': ['i18n/locale/i18n.pot'], 'web_link': 'https://opendev.org/openstack/i18n/commit/c10bcbfdc43f5e5c4bdcb460a49d3e406636726f', 'message': 'glossary: remove meaningless whitespace\n\nChange-Id: I7296516a6083f64c30b6f417d5f32810bd2630cf\n'}]",0,289003,c10bcbfdc43f5e5c4bdcb460a49d3e406636726f,7,2,2,841,,,0,"glossary: remove meaningless whitespace

Change-Id: I7296516a6083f64c30b6f417d5f32810bd2630cf
",git fetch https://review.opendev.org/openstack/i18n refs/changes/03/289003/1 && git format-patch -1 --stdout FETCH_HEAD,['i18n/locale/i18n.pot'],1,7c498220a8a71b0eea52f70cc4ae82218fb21238,normalize-glossary,"msgid ""authenticate""msgid ""Disassociate IP""msgid ""Disk GB Hours""msgid ""Fingerprint""msgid ""Fixed IP""msgid ""Flavor""msgid ""Floating IP""msgid ""Injected Files""msgid ""Perfect Forward Secrecy""msgid ""Public key""msgid ""Region""msgid ""Security Group""msgid ""server""msgid ""submit""msgid ""System Panel""","msgid ""authenticate ""msgid ""Disassociate IP ""msgid ""Disk GB Hours ""msgid ""Fingerprint ""msgid ""Fixed IP ""msgid ""Flavor ""msgid ""Floating IP ""msgid ""Injected Files ""msgid ""Perfect Forward Secrecy ""msgid ""Public key ""msgid ""Region ""msgid ""Security Group ""msgid ""server ""msgid ""submit ""msgid ""System Panel """,15,15
openstack%2Fstorlets~master~I9b0ddf7856c99d9e27a56f87e74d42afd63fb840,openstack/storlets,master,I9b0ddf7856c99d9e27a56f87e74d42afd63fb840,Bump up version of swift in tox testing to master,MERGED,2016-03-03 10:42:18.000000000,2016-03-06 11:56:09.000000000,2016-03-06 11:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 11317}]","[{'number': 1, 'created': '2016-03-03 10:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/2a124ff862cd636d5a8852fd712b70725bb5d153', 'message': 'Bump up version of swift in tox testing to master\n\nChange-Id: I9b0ddf7856c99d9e27a56f87e74d42afd63fb840\n'}, {'number': 2, 'created': '2016-03-03 10:45:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/storlets/commit/597932415852a44810f7eb16a8282d17633764af', 'message': 'Bump up version of swift in tox testing to master\n\nThis patch bumps up version of swift in tox testing\nfrom Liberty to master, to make sure that we can run\nstorlets with swift master.\n\nTODO:\nWe also need to update our swift installation scripts\nto run functional tests with swift master.\n\nChange-Id: I9b0ddf7856c99d9e27a56f87e74d42afd63fb840\n'}]",0,287703,597932415852a44810f7eb16a8282d17633764af,7,2,2,9816,,,0,"Bump up version of swift in tox testing to master

This patch bumps up version of swift in tox testing
from Liberty to master, to make sure that we can run
storlets with swift master.

TODO:
We also need to update our swift installation scripts
to run functional tests with swift master.

Change-Id: I9b0ddf7856c99d9e27a56f87e74d42afd63fb840
",git fetch https://review.opendev.org/openstack/storlets refs/changes/03/287703/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2a124ff862cd636d5a8852fd712b70725bb5d153,swift-bumpup, git+git://github.com/openstack/swift.git, PyECLib==1.0.7 https://launchpad.net/swift/kilo/2.3.0/+download/swift-2.3.0.tar.gz,1,2
openstack%2Fvitrage~master~I7a8e4b07f4acb206f5b4ae4fc0ec2c1d63bafbd2,openstack/vitrage,master,I7a8e4b07f4acb206f5b4ae4fc0ec2c1d63bafbd2,bug fix for evaluator,MERGED,2016-03-06 10:16:48.000000000,2016-03-06 10:47:01.000000000,2016-03-06 10:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 19134}, {'_account_id': 19209}]","[{'number': 1, 'created': '2016-03-06 10:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/1992dcbcecea90951ed7ef330ed789adc49ebb6b', 'message': 'bug fix for evaluator\n\nChange-Id: I7a8e4b07f4acb206f5b4ae4fc0ec2c1d63bafbd2\n'}, {'number': 2, 'created': '2016-03-06 10:33:13.000000000', 'files': ['vitrage/synchronizer/plugins/nova/zone/transformer.py', 'vitrage/entity_graph/processor/processor.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/357e2f5556e846b56babe0806363ec0d596a0750', 'message': 'bug fix for evaluator\n\nChange-Id: I7a8e4b07f4acb206f5b4ae4fc0ec2c1d63bafbd2\n'}]",0,288998,357e2f5556e846b56babe0806363ec0d596a0750,9,3,2,19122,,,0,"bug fix for evaluator

Change-Id: I7a8e4b07f4acb206f5b4ae4fc0ec2c1d63bafbd2
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/98/288998/2 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/synchronizer/plugins/nova/zone/transformer.py', 'vitrage/entity_graph/processor/processor.py']",2,1992dcbcecea90951ed7ef330ed789adc49ebb6b,bp/state-normalization-support, if action == EventAction.UPDATE_ENTITY or EventAction.DELETE_ENTITY or\ EventAction.CREATE_ENTITY:, if action == EventAction.UPDATE_ENTITY or \ action == EventAction.DELETE_ENTITY: elif action == EventAction.CREATE_ENTITY: graph_vertex = None,3,5
openstack%2Fvitrage~master~I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879,openstack/vitrage,master,I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879,Load transformer plugins from conf file,MERGED,2016-03-01 12:38:02.000000000,2016-03-06 10:17:48.000000000,2016-03-06 10:17:48.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 19122}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-03-01 12:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/bdb036b67e7fe5a960c09deb33c0febc5e8c5e60', 'message': 'Load transformer plugins from conf file\n\nChange-Id: I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879\n'}, {'number': 2, 'created': '2016-03-01 15:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/36d47b63aa47df76cb0c44eb08594418c59dd8a0', 'message': 'Load transformer plugins from conf file\n\nChange-Id: I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879\n'}, {'number': 3, 'created': '2016-03-06 09:00:48.000000000', 'files': ['vitrage/tests/unit/entity_graph/processor/base.py', 'vitrage/tests/unit/entity_graph/processor/test_processor.py', 'vitrage/tests/unit/synchronizer/transformers/test_transformer_manager.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/tests/functional/entity_graph/processor/test_processor.py', 'vitrage/synchronizer/plugins/nagios/synchronizer.py', 'vitrage/tests/functional/entity_graph/test_state_manager.py', 'vitrage/tests/unit/entity_graph/base.py', 'vitrage/synchronizer/plugins/__init__.py', 'vitrage/synchronizer/plugins/nagios/config.py', 'vitrage/entity_graph/transformer_manager.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/tests/unit/synchronizer/nagios/test_nagios_config.py', 'vitrage/tests/unit/synchronizer/nagios/test_nagios_synchronizer.py', 'vitrage/tests/unit/synchronizer/static_plugin/test_static_physical_synchronizer.py', 'vitrage/synchronizer/plugins/static_physical/synchronizer.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/481806cd9fbe2453f9857f8df11ec9a11eb96854', 'message': 'Load transformer plugins from conf file\n\nChange-Id: I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879\n'}]",20,286549,481806cd9fbe2453f9857f8df11ec9a11eb96854,17,4,3,20667,,,0,"Load transformer plugins from conf file

Change-Id: I5c1401ae993a4dfa87ed1f6cd80151b4b43a1879
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/49/286549/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/tests/unit/entity_graph/processor/base.py', 'vitrage/tests/functional/entity_graph/test_state_manager.py', 'vitrage/tests/unit/entity_graph/processor/test_processor.py', 'vitrage/synchronizer/plugins/__init__.py', 'vitrage/tests/unit/synchronizer/transformers/test_transformer_manager.py', 'vitrage/entity_graph/transformer_manager.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/entity_graph/processor/processor.py', 'vitrage/tests/functional/entity_graph/processor/test_processor.py']",9,bdb036b67e7fe5a960c09deb33c0febc5e8c5e60,bp/load-plugins-from-conf-file," PLUGINS_OPTS = [ cfg.ListOpt('plugin_type', default=['nagios', 'nova.host', 'nova.instance', 'nova.zone', 'switch'], help='Names of supported synchronizer plugins'), cfg.DictOpt('nagios', default={ 'synchronizer': 'vitrage.synchronizer.plugins.nagios.synchronizer', 'transformer': 'vitrage.synchronizer.plugins' '.nagios.transformer.NagiosTransformer', 'user': '', 'password': '', 'url': '', 'config_file': '/etc/vitrage/nagios_conf.yaml'},), cfg.DictOpt('nova.host', default={ 'synchronizer': 'vitrage.synchronizer.plugins.nova.host' '.synchronizer', 'transformer': 'vitrage.synchronizer.plugins.nova' '.host.transformer.HostTransformer', 'user': '', 'password': '', 'url': '', 'version': '2.0', 'project': 'admin'},), cfg.DictOpt('nova.instance', default={ 'synchronizer': 'vitrage.synchronizer.plugins.nova.instance' '.synchronizer', 'transformer': 'vitrage.synchronizer.plugins' '.nova.instance.transformer.InstanceTransformer', 'user': '', 'password': '', 'url': '', 'version': '2.0', 'project': 'admin'},), cfg.DictOpt('nova.zone', default={ 'synchronizer': 'vitrage.synchronizer.plugins.nova.zone' '.synchronizer', 'transformer': 'vitrage.synchronizer.plugins.nova' '.zone.transformer.ZoneTransformer', 'user': '', 'password': '', 'url': '', 'version': '2.0', 'project': 'admin'},), cfg.DictOpt('switch', default={ 'synchronizer': 'vitrage.synchronizer.plugins.static_physical' '.synchronizer', 'transformer': 'vitrage.synchronizer.plugins.static_physical.' 'transformer.StaticPhysicalTransformer', 'dir': '/etc/vitrage/static_plugins'},), ] self.conf.register_opts(self.PLUGINS_OPTS, group='synchronizer_plugins')",,616,40
openstack%2Fsenlin~master~I159a0b35e5f05a282b877da49bee3f816f23eb9c,openstack/senlin,master,I159a0b35e5f05a282b877da49bee3f816f23eb9c,Updated from global requirements,MERGED,2016-03-04 17:48:53.000000000,2016-03-06 09:43:35.000000000,2016-03-06 09:43:35.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 17:48:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin/commit/06b3227439c4a755d3cc3bd88d790b9841c83759', 'message': 'Updated from global requirements\n\nChange-Id: I159a0b35e5f05a282b877da49bee3f816f23eb9c\n'}]",0,288610,06b3227439c4a755d3cc3bd88d790b9841c83759,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I159a0b35e5f05a282b877da49bee3f816f23eb9c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/10/288610/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,06b3227439c4a755d3cc3bd88d790b9841c83759,openstack/requirements,openstacksdk>=0.8.1 # Apache-2.0,openstacksdk>=0.7.4 # Apache-2.0,1,1
openstack%2Fpython-openstackclient~master~I30812c3ead477267dc7e3dc774c09b3435152eb9,openstack/python-openstackclient,master,I30812c3ead477267dc7e3dc774c09b3435152eb9,Add release note for security group set refactor,MERGED,2016-03-05 16:18:51.000000000,2016-03-06 09:26:14.000000000,2016-03-06 09:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}, {'_account_id': 18658}]","[{'number': 1, 'created': '2016-03-05 16:18:51.000000000', 'files': ['releasenotes/notes/bug-1519511-74bab0e0d32db043.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/46e86e5a4a8f147b02559d6e612a57bc7ced7171', 'message': 'Add release note for security group set refactor\n\nAdd a release note for [1].\n\n[1] https://review.openstack.org/#/c/287763/\n\nChange-Id: I30812c3ead477267dc7e3dc774c09b3435152eb9\nPartial-Bug: #1519511\nImplements: blueprint neutron-client\n'}]",0,288911,46e86e5a4a8f147b02559d6e612a57bc7ced7171,12,4,1,8410,,,0,"Add release note for security group set refactor

Add a release note for [1].

[1] https://review.openstack.org/#/c/287763/

Change-Id: I30812c3ead477267dc7e3dc774c09b3435152eb9
Partial-Bug: #1519511
Implements: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/11/288911/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/bug-1519511-74bab0e0d32db043.yaml'],1,46e86e5a4a8f147b02559d6e612a57bc7ced7171,bug/1519511, - Ignore the ``security group list`` command ``--all-projects`` option - The ``security group set`` command now uses Network v2 when enabled which allows the security group name and description to be set to an empty value. [Bug `1519511 <https://bugs.launchpad.net/bugs/1519511>`_], - | Ignore the ``security group list`` command ``--all-projects`` option,5,2
openstack%2Fmanila~master~I48ea946c2b8de2ebf0e067ef4829b81cabd1464f,openstack/manila,master,I48ea946c2b8de2ebf0e067ef4829b81cabd1464f,Change sudo to run_as_root in LVM driver,MERGED,2016-02-26 04:58:30.000000000,2016-03-06 09:18:00.000000000,2016-02-27 03:39:52.000000000,"[{'_account_id': 3}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18402}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-26 04:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7fdd5b6e50adcb4899b122a3247d6b58a901d57b', 'message': ""Change sudo to run_as_root in LVM driver\n\nThe LVM driver was using sudo for one command instead\nof proper rootwrap usage. This caused failures when the\nuser running manila-share didn't have passwordless sudo\naccess.\n\nChange-Id: I48ea946c2b8de2ebf0e067ef4829b81cabd1464f\nCloses-Bug: 1550121\n""}, {'number': 2, 'created': '2016-02-26 14:25:14.000000000', 'files': ['manila/tests/share/drivers/test_lvm.py', 'manila/share/drivers/lvm.py', 'etc/manila/rootwrap.d/share.filters'], 'web_link': 'https://opendev.org/openstack/manila/commit/29020b47f775cf62cc549d2b3f53691dd4cc1f24', 'message': ""Change sudo to run_as_root in LVM driver\n\nThe LVM driver was using sudo for one command instead\nof proper rootwrap usage. This caused failures when the\nuser running manila-share didn't have passwordless sudo\naccess.\n\nDepends-On: Ib1896997f2e7a505b5bf8ec0c9e5ee35942f79a6\nChange-Id: I48ea946c2b8de2ebf0e067ef4829b81cabd1464f\nCloses-Bug: 1550121\n""}]",0,285107,29020b47f775cf62cc549d2b3f53691dd4cc1f24,50,14,2,2417,,,0,"Change sudo to run_as_root in LVM driver

The LVM driver was using sudo for one command instead
of proper rootwrap usage. This caused failures when the
user running manila-share didn't have passwordless sudo
access.

Depends-On: Ib1896997f2e7a505b5bf8ec0c9e5ee35942f79a6
Change-Id: I48ea946c2b8de2ebf0e067ef4829b81cabd1464f
Closes-Bug: 1550121
",git fetch https://review.opendev.org/openstack/manila refs/changes/07/285107/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/test_lvm.py', 'manila/share/drivers/lvm.py', 'etc/manila/rootwrap.d/share.filters']",3,7fdd5b6e50adcb4899b122a3247d6b58a901d57b,bug/1550121,"# manila/share/drivers/lvm.py: 'vgs', '--noheadings', '-o', 'name' # manila/share/drivers/lvm.py: 'vgs', %s, '--rows', '--units', 'g'","# manila/share/drivers/lvm.py: 'vgs', %s, '--rows'",11,10
openstack%2Foperations-guide~master~If91dc141717d76a78c14ee3388cec132d5f0d312,openstack/operations-guide,master,If91dc141717d76a78c14ee3388cec132d5f0d312,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 07:08:42.000000000,2016-03-06 09:04:02.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 07:08:42.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/edef7139de65079f1666f18bc33a678f1aa0c63d', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: If91dc141717d76a78c14ee3388cec132d5f0d312\n'}]",0,282981,edef7139de65079f1666f18bc33a678f1aa0c63d,5,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: If91dc141717d76a78c14ee3388cec132d5f0d312
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/81/282981/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,edef7139de65079f1666f18bc33a678f1aa0c63d,testing-bindep,,,0,0
openstack%2Fsecurity-doc~master~I6a0581f249ca21e3e79dfad6aa95a0f046d266d4,openstack/security-doc,master,I6a0581f249ca21e3e79dfad6aa95a0f046d266d4,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 07:08:22.000000000,2016-03-06 09:03:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 07:08:22.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/c03125c7f9a2ec2e96344b8389a40e91f47cc887', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: I6a0581f249ca21e3e79dfad6aa95a0f046d266d4\n'}]",0,282980,c03125c7f9a2ec2e96344b8389a40e91f47cc887,5,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: I6a0581f249ca21e3e79dfad6aa95a0f046d266d4
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/80/282980/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,c03125c7f9a2ec2e96344b8389a40e91f47cc887,testing-bindep,,,0,0
openstack%2Fapi-site~master~I2e8aee7e493e70de2dc3bb3f9e2527cbf940580f,openstack/api-site,master,I2e8aee7e493e70de2dc3bb3f9e2527cbf940580f,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 07:07:48.000000000,2016-03-06 09:03:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 07:07:48.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/api-site/commit/5d5f1ef880edc178ab5f58f8d60ba6a94c15f46e', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: I2e8aee7e493e70de2dc3bb3f9e2527cbf940580f\n'}]",0,282978,5d5f1ef880edc178ab5f58f8d60ba6a94c15f46e,11,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: I2e8aee7e493e70de2dc3bb3f9e2527cbf940580f
",git fetch https://review.opendev.org/openstack/api-site refs/changes/78/282978/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,5d5f1ef880edc178ab5f58f8d60ba6a94c15f46e,testing-bindep,,,0,0
openstack%2Fopenstack-manuals~stable%2Fkilo~I46d03304c21367ff600eabf1b72356130a92c008,openstack/openstack-manuals,stable/kilo,I46d03304c21367ff600eabf1b72356130a92c008,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 07:05:37.000000000,2016-03-06 09:03:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 07:05:37.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/568bfc9698ede29d69b2d574c6b715df9d33e540', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: I46d03304c21367ff600eabf1b72356130a92c008\n(cherry picked from commit 8ac3d612f3315108f07ec7d030ade1f162c0add4)\n'}]",0,282977,568bfc9698ede29d69b2d574c6b715df9d33e540,6,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: I46d03304c21367ff600eabf1b72356130a92c008
(cherry picked from commit 8ac3d612f3315108f07ec7d030ade1f162c0add4)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/77/282977/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,568bfc9698ede29d69b2d574c6b715df9d33e540,testing-bindep,,,0,0
openstack%2Fopenstack-manuals~stable%2Fliberty~I46d03304c21367ff600eabf1b72356130a92c008,openstack/openstack-manuals,stable/liberty,I46d03304c21367ff600eabf1b72356130a92c008,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 07:04:47.000000000,2016-03-06 09:03:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 07:04:47.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e928e45fb5b9fa9005f11639e8f175f8e5a2a901', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: I46d03304c21367ff600eabf1b72356130a92c008\n(cherry picked from commit 8ac3d612f3315108f07ec7d030ade1f162c0add4)\n'}]",0,282976,e928e45fb5b9fa9005f11639e8f175f8e5a2a901,6,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: I46d03304c21367ff600eabf1b72356130a92c008
(cherry picked from commit 8ac3d612f3315108f07ec7d030ade1f162c0add4)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/76/282976/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,e928e45fb5b9fa9005f11639e8f175f8e5a2a901,testing-bindep,,,0,0
openstack%2Fopenstack-manuals~master~I46d03304c21367ff600eabf1b72356130a92c008,openstack/openstack-manuals,master,I46d03304c21367ff600eabf1b72356130a92c008,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 04:44:10.000000000,2016-03-06 09:03:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 04:44:10.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8ac3d612f3315108f07ec7d030ade1f162c0add4', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: I46d03304c21367ff600eabf1b72356130a92c008\n'}]",0,282947,8ac3d612f3315108f07ec7d030ade1f162c0add4,7,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: I46d03304c21367ff600eabf1b72356130a92c008
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/282947/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,8ac3d612f3315108f07ec7d030ade1f162c0add4,testing-bindep,,,0,0
openstack%2Fha-guide~master~Ice1665e58843e81f935e509d0f0f4754a46cb35c,openstack/ha-guide,master,Ice1665e58843e81f935e509d0f0f4754a46cb35c,DO NOT MERGE: testing bindep-based jobs,ABANDONED,2016-02-22 04:43:32.000000000,2016-03-06 09:03:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-22 04:43:32.000000000', 'files': ['DO-NOT-MERGE'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/a4491d19d9551175001e38187b61b6bfc476f3d8', 'message': 'DO NOT MERGE: testing bindep-based jobs\n\nChange-Id: Ice1665e58843e81f935e509d0f0f4754a46cb35c\n'}]",0,282946,a4491d19d9551175001e38187b61b6bfc476f3d8,7,2,1,6547,,,0,"DO NOT MERGE: testing bindep-based jobs

Change-Id: Ice1665e58843e81f935e509d0f0f4754a46cb35c
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/46/282946/1 && git format-patch -1 --stdout FETCH_HEAD,['DO-NOT-MERGE'],1,a4491d19d9551175001e38187b61b6bfc476f3d8,testing-bindep,,,0,0
openstack%2Fvitrage~master~I17925c81af3d18b69b61a64fb4237cd92bf46082,openstack/vitrage,master,I17925c81af3d18b69b61a64fb4237cd92bf46082,move rpc transport to pecan hooks,MERGED,2016-03-06 08:49:40.000000000,2016-03-06 09:00:00.000000000,2016-03-06 09:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-03-06 08:49:40.000000000', 'files': ['vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/alarms.py', 'vitrage/api/controllers/rest.py', 'vitrage/api/controllers/v1/topology.py', 'vitrage/api/app.py', 'vitrage/api/hooks.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/99c2600259385ecb0e78075dba6537a57d278537', 'message': 'move rpc transport to pecan hooks\n\nmove command tasks to base controller\n\nChange-Id: I17925c81af3d18b69b61a64fb4237cd92bf46082\n'}]",0,288992,99c2600259385ecb0e78075dba6537a57d278537,6,2,1,19134,,,0,"move rpc transport to pecan hooks

move command tasks to base controller

Change-Id: I17925c81af3d18b69b61a64fb4237cd92bf46082
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/92/288992/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/rest.py', 'vitrage/api/controllers/v1/alarms.py', 'vitrage/api/controllers/v1/topology.py', 'vitrage/api/app.py', 'vitrage/api/hooks.py']",6,99c2600259385ecb0e78075dba6537a57d278537,hooks,"import oslo_messaging class RPCHook(hooks.PecanHook): """"""Create and attach an rpc to the request. """""" def __init__(self, conf): transport = oslo_messaging.get_transport(conf) target = oslo_messaging.Target(topic='rpcapiv1') self.client = oslo_messaging.RPCClient(transport, target) self.ctxt = {} def before(self, state): state.request.client = self.client ",,94,103
openstack%2Fpython-openstackclient~master~I4b06be959768bcdaafd9aa8df497490958bee649,openstack/python-openstackclient,master,I4b06be959768bcdaafd9aa8df497490958bee649,""" openstack server image create "" doesn't print proper info",MERGED,2016-03-01 07:21:13.000000000,2016-03-06 08:33:44.000000000,2016-03-06 08:33:44.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8276}, {'_account_id': 8410}, {'_account_id': 9301}, {'_account_id': 17211}, {'_account_id': 18466}, {'_account_id': 20453}, {'_account_id': 20466}]","[{'number': 1, 'created': '2016-03-01 07:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b8033d036779da780198ce00e9c7f34bd2615950', 'message': '"" openstack server image create "" doesn\'t print proper info\n\nAfter creating a snapshot of a running instance, a print out similar\nto server create is expected, but it prints out something like ""_info""\nwhich is nothing related to created image. _prep_image_detail method\nis added to /compute/v2/server.py to enable the priting, while running\nthe test properly.\n\nChange-Id: I4b06be959768bcdaafd9aa8df497490958bee649\nCloses-Bug:1551586\n'}, {'number': 2, 'created': '2016-03-02 05:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e4143aff059632975e42f554a8435f0a9800a7e7', 'message': '"" openstack server image create "" doesn\'t print proper info\n\nAfter creating a snapshot of a running instance, a print out similar\nto server create is expected, but it prints out something like ""_info""\nwhich is nothing related to created image. _prep_image_detail method\nis added to /compute/v2/server.py to enable the priting, while running\nthe test properly.\n\nChange-Id: I4b06be959768bcdaafd9aa8df497490958bee649\nCloses-Bug:1551586\n'}, {'number': 3, 'created': '2016-03-03 15:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b8d183ddbfd901fbd32604bf12b0e1c27d246d8b', 'message': '"" openstack server image create "" doesn\'t print proper info\n\nAfter creating a snapshot of a running instance, a print out similar\nto server create is expected, but it prints out something like ""_info""\nwhich is nothing related to created image. _prep_image_detail method\nis added to /compute/v2/server.py to enable the priting, while running\nthe test properly.\n\nChange-Id: I4b06be959768bcdaafd9aa8df497490958bee649\nCloses-Bug:1551586\n'}, {'number': 4, 'created': '2016-03-03 21:12:33.000000000', 'files': ['openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e354d17d2c7603e7f4b9e5ba4abf474dc709be9f', 'message': '"" openstack server image create "" doesn\'t print proper info\n\nAfter creating a snapshot of a running instance, a print out similar\nto server create is expected, but it prints out something like ""_info""\nwhich is nothing related to created image. _prep_image_detail method\nis added to /compute/v2/server.py to enable the priting, while running\nthe test properly.\n\nChange-Id: I4b06be959768bcdaafd9aa8df497490958bee649\nCloses-Bug:1551586\n'}]",6,286418,e354d17d2c7603e7f4b9e5ba4abf474dc709be9f,34,9,4,20453,,,0,""" openstack server image create "" doesn't print proper info

After creating a snapshot of a running instance, a print out similar
to server create is expected, but it prints out something like ""_info""
which is nothing related to created image. _prep_image_detail method
is added to /compute/v2/server.py to enable the priting, while running
the test properly.

Change-Id: I4b06be959768bcdaafd9aa8df497490958bee649
Closes-Bug:1551586
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/18/286418/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,b8033d036779da780198ce00e9c7f34bd2615950,bug/1551586,"def _prep_image_detail(image_client, image_id): """"""Prepare the detailed server dict for printing :param compute_client: a compute client instance :param server: id of image created :rtype: a dict of image details """""" info = utils.find_resource( image_client.images, image_id, ) # During testing, info value would be FakeResource # object. The following condition deals with it. try: info.id return info._info except Exception: return info image = _prep_image_detail(image_client, image_id) return zip(*sorted(six.iteritems(image)))"," image = utils.find_resource( image_client.images, image_id, ) return zip(*sorted(six.iteritems(image._info)))",23,5
openstack%2Fvitrage-dashboard~master~I28137746973edc6a539303eac17e698e3282bd24,openstack/vitrage-dashboard,master,I28137746973edc6a539303eac17e698e3282bd24,fix the test to pass tox,ABANDONED,2015-11-23 15:30:26.000000000,2016-03-06 08:13:19.000000000,,"[{'_account_id': 3}, {'_account_id': 17089}, {'_account_id': 19140}]","[{'number': 1, 'created': '2015-11-23 15:30:26.000000000', 'files': ['vitragedashboard/tests.py'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/b6acf60d3c20ac9c3df6a86b49d63f5dd1774bb0', 'message': 'fix the test to pass tox\n\nChange-Id: I28137746973edc6a539303eac17e698e3282bd24\n'}]",0,248766,b6acf60d3c20ac9c3df6a86b49d63f5dd1774bb0,4,3,1,19142,,,0,"fix the test to pass tox

Change-Id: I28137746973edc6a539303eac17e698e3282bd24
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/66/248766/1 && git format-patch -1 --stdout FETCH_HEAD,['vitragedashboard/tests.py'],1,b6acf60d3c20ac9c3df6a86b49d63f5dd1774bb0,bp/ui-system-health-sunburst, class FivecircleTests(object):,from horizon.test import helpers as test class FivecircleTests(test.TestCase):,1,2
openstack%2Fvitrage-dashboard~master~I1f520cfc756b10322cec5b97b896b0d5793a2240,openstack/vitrage-dashboard,master,I1f520cfc756b10322cec5b97b896b0d5793a2240,remove tox,ABANDONED,2015-11-23 15:20:28.000000000,2016-03-06 08:13:06.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-11-23 15:20:28.000000000', 'files': ['setup.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/e382034e9981289989ff5870282b9bd17ae165b6', 'message': 'remove tox\n\nChange-Id: I1f520cfc756b10322cec5b97b896b0d5793a2240\n'}]",0,248755,e382034e9981289989ff5870282b9bd17ae165b6,3,1,1,19142,,,0,"remove tox

Change-Id: I1f520cfc756b10322cec5b97b896b0d5793a2240
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/55/248755/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.py', 'tox.ini']",2,e382034e9981289989ff5870282b9bd17ae165b6,bp/ui-system-health-sunburst,,"[tox] minversion = 1.6 envlist = py27,pep8 skipsdist = True [testenv] usedevelop = True install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} deps = -r{toxinidir}/test-requirements.txt commands = python setup.py test --slowest --testr-args='{posargs}' [testenv:pep8] commands = flake8 [testenv:venv] commands = {posargs} [testenv:cover] commands = python setup.py test --coverage --testr-args='{posargs}' [testenv:docs] commands = python setup.py build_sphinx [testenv:debug] commands = oslo_debug_helper {posargs} [flake8] # E123, E125 skipped as they are invalid PEP-8. show-source = True ignore = E123,E125 builtins = _ exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,build ",1,36
openstack%2Fvitrage~master~Iddec366d4fe64be936afb315b6cb1a58fe64a387,openstack/vitrage,master,Iddec366d4fe64be936afb315b6cb1a58fe64a387,add get_rca call to transport,MERGED,2016-03-06 07:42:19.000000000,2016-03-06 08:13:01.000000000,2016-03-06 08:13:01.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-03-06 07:42:19.000000000', 'files': ['vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/topology.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/eaa9cfed819bbcd62deef034658682df7facdc94', 'message': 'add get_rca call to transport\n\ndont redirect to get topology\nuse a new call for the get rca\nadd mock for it also\n\nChange-Id: Iddec366d4fe64be936afb315b6cb1a58fe64a387\n'}]",0,288986,eaa9cfed819bbcd62deef034658682df7facdc94,6,2,1,19134,,,0,"add get_rca call to transport

dont redirect to get topology
use a new call for the get rca
add mock for it also

Change-Id: Iddec366d4fe64be936afb315b6cb1a58fe64a387
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/86/288986/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/topology.py']",2,eaa9cfed819bbcd62deef034658682df7facdc94,rca,," def index(self, depth=None, graph_type='graph', query=None, root=None): return self.post(depth, graph_type, query, root) @pecan.expose('json')",44,12
openstack%2Fvitrage-dashboard~master~I4128f9c9bda6aa07209f599fceea2998c7dccef4,openstack/vitrage-dashboard,master,I4128f9c9bda6aa07209f599fceea2998c7dccef4,fix the py code according to tox requirements,ABANDONED,2015-11-23 14:18:41.000000000,2016-03-06 08:12:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-11-23 14:18:41.000000000', 'files': ['setup.py', 'vitragedashboard/views.py'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/11c28cfaee3ea1958fbf7ea2e573c3a2eeb0ddb8', 'message': 'fix the py code according to tox requirements\n\nChange-Id: I4128f9c9bda6aa07209f599fceea2998c7dccef4\n'}]",0,248718,11c28cfaee3ea1958fbf7ea2e573c3a2eeb0ddb8,3,1,1,19142,,,0,"fix the py code according to tox requirements

Change-Id: I4128f9c9bda6aa07209f599fceea2998c7dccef4
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/18/248718/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.py', 'vitragedashboard/views.py']",2,11c28cfaee3ea1958fbf7ea2e573c3a2eeb0ddb8,bp/ui-system-health-sunburst,"# Copyright 2012 Alcatel-Lucent, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. topology_settings = { context['TOPOLOGY_VITRAGE_SETTINGS'] = json.dumps(topology_settings)",from horizon import Horizonfrom horizon.version import version_info as hvi from vitragedashboard.version import version_info as acvi from django.conf import settings from openstack_dashboard import api import re topology_vitrage_settings = { context['TOPOLOGY_VITRAGE_SETTINGS'] = json.dumps(topology_vitrage_settings),18,9
openstack%2Fvitrage-dashboard~master~I02dec75855e9fe8f358caa9aadcf1b5087959505,openstack/vitrage-dashboard,master,I02dec75855e9fe8f358caa9aadcf1b5087959505,first push - hello world,ABANDONED,2015-11-23 13:58:32.000000000,2016-03-06 08:12:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-11-23 13:58:32.000000000', 'files': ['vitragedashboard/static/dashboard/project/vitrage.module.js', 'README.rst', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.scss', 'vitragedashboard/tests/test_vitragedashboard.py', 'setup.py', 'vitragedashboard/tests/base.py', 'vitragedashboard/panel.py', 'MANIFEST.in', 'vitragedashboard/static/dashboard/project/topology/main_panel.html', 'vitragedashboard/templates/topology/index.html', 'vitragedashboard/urls.py', 'vitragedashboard/tests.py', 'vitragedashboard/enabled/_90_project_topology_vitrage_panel.py', 'vitragedashboard/version.py', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.controller.js', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.service.js', 'vitragedashboard/views.py', 'vitragedashboard/enabled/_80_project_vitrage_panel_group.py'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/ddffa73b33344e09ba2c87e1498e40c78f2d367c', 'message': 'first push - hello world\n\nChange-Id: I02dec75855e9fe8f358caa9aadcf1b5087959505\n'}]",0,248710,ddffa73b33344e09ba2c87e1498e40c78f2d367c,3,1,1,19142,,,0,"first push - hello world

Change-Id: I02dec75855e9fe8f358caa9aadcf1b5087959505
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/10/248710/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitragedashboard/static/dashboard/project/vitrage.module.js', 'README.rst', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.scss', 'vitragedashboard/tests/test_vitragedashboard.py', 'setup.py', 'vitragedashboard/tests/base.py', 'vitragedashboard/panel.py', 'MANIFEST.in', 'vitragedashboard/static/dashboard/project/topology/main_panel.html', 'vitragedashboard/templates/topology/index.html', 'vitragedashboard/urls.py', 'vitragedashboard/tests.py', 'vitragedashboard/enabled/_90_project_topology_vitrage_panel.py', 'vitragedashboard/version.py', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.controller.js', 'vitragedashboard/static/dashboard/project/topology/vitrage_topology.service.js', 'vitragedashboard/views.py', 'vitragedashboard/enabled/_80_project_vitrage_panel_group.py']",18,ddffa73b33344e09ba2c87e1498e40c78f2d367c,bp/ui-system-health-sunburst,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # The name of the panel group to be added to HORIZON_CONFIG. Required. PANEL_GROUP = 'vitrage_panel_group' # The display name of the PANEL_GROUP. Required. PANEL_GROUP_NAME = 'Vitrage' # The name of the dashboard the PANEL_GROUP associated with. Required. PANEL_GROUP_DASHBOARD = 'project' ",,235,53
openstack%2Fmagnum-ui~master~I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6,openstack/magnum-ui,master,I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6,Use action register service for BayModel actions,MERGED,2016-02-24 01:04:05.000000000,2016-03-06 08:05:44.000000000,2016-03-06 08:05:44.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 9576}, {'_account_id': 11536}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-02-24 01:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/31ba022d134f16ab39b0d2ef8781f759496cfc20', 'message': 'Revise module namespace in comments for baymodel\n\nThis patch revises module namespace in comments for baymodel\nbatch-actions and row-actions.\n\nChange-Id: I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6\nCloses-Bug: #1549059\n'}, {'number': 2, 'created': '2016-03-03 05:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/884c5d7c468c9f7cd5400015e4bf791fd672ddf8', 'message': 'Use action register service for BayModel actions\n\nHorizon merges action register service, so use it for\nBayModel actions in table view and detail view.\n\nAlso, fix module namespace in comments for baymodel\nbatch-actions and row-actions by remove these files.\n\nChange-Id: I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6\nCloses-Bug: #1549059\n'}, {'number': 3, 'created': '2016-03-03 09:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/7296b18e38f864c253c2106a3e71b7675d9db4c6', 'message': 'Use action register service for BayModel actions\n\nHorizon merges action register service, so use it for\nBayModel actions in table view and detail view.\n\nAlso, fix module namespace in comments for baymodel\nbatch-actions and row-actions by remove these files.\n\nChange-Id: I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6\nCloses-Bug: #1549059\n'}, {'number': 4, 'created': '2016-03-03 09:46:01.000000000', 'files': ['magnum_ui/static/dashboard/containers/baymodels/detail/detail.html', 'magnum_ui/static/dashboard/containers/baymodels/table/row-actions.service.js', 'magnum_ui/static/dashboard/containers/baymodels/table/table.controller.js', 'magnum_ui/static/dashboard/containers/baymodels/create/create.service.js', 'magnum_ui/static/dashboard/containers/baymodels/delete/delete.service.js', 'magnum_ui/static/dashboard/containers/baymodels/table/batch-actions.service.js', 'magnum_ui/static/dashboard/containers/baymodels/actions.module.js', 'magnum_ui/static/dashboard/containers/baymodels/detail/detail.controller.js', 'magnum_ui/static/dashboard/containers/baymodels/table/table.html', 'magnum_ui/static/dashboard/containers/baymodels/baymodels.module.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/5b7fc64c2db208ec13f24b9e83050c01a633ad7e', 'message': 'Use action register service for BayModel actions\n\nHorizon merges action register service, so use it for\nBayModel actions in table view and detail view.\n\nAlso, fix module namespace in comments for baymodel\nbatch-actions and row-actions by remove these files.\n\nChange-Id: I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6\nCloses-Bug: #1549059\n'}]",0,283891,5b7fc64c2db208ec13f24b9e83050c01a633ad7e,14,5,4,16352,,,0,"Use action register service for BayModel actions

Horizon merges action register service, so use it for
BayModel actions in table view and detail view.

Also, fix module namespace in comments for baymodel
batch-actions and row-actions by remove these files.

Change-Id: I2e9aa23aa6f51bb83be4a2238a4178f9ce5f6cc6
Closes-Bug: #1549059
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/91/283891/4 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/containers/baymodels/table/row-actions.service.js', 'magnum_ui/static/dashboard/containers/baymodels/table/batch-actions.service.js']",2,31ba022d134f16ab39b0d2ef8781f759496cfc20,bug/1543879-baymodel, * @name horizon.dashboard.containers.baymodels.batch-actions.service, * @name horizon.dashboard.containers.baymodels.table.batch-actions.service,2,2
openstack%2Fmagnum-ui~master~Ib5f712b83e17124217771ec79e0d255d3166da6a,openstack/magnum-ui,master,Ib5f712b83e17124217771ec79e0d255d3166da6a,Refactor actions in Container table,MERGED,2016-02-23 09:09:39.000000000,2016-03-06 08:04:22.000000000,2016-03-06 08:04:22.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-02-23 09:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/ca6a8e3b40fcf5e892533c97528c35fafba3518d', 'message': 'Refactor actions in Container table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Container table\nview.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ib5f712b83e17124217771ec79e0d255d3166da6a\nCloses-Bug: #1543879\n'}, {'number': 2, 'created': '2016-03-03 06:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/3e840d34c029663688226a6d231e40a44e570d6d', 'message': 'Refactor actions in Container table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Container table\nview.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ib5f712b83e17124217771ec79e0d255d3166da6a\nCloses-Bug: #1543879\n'}, {'number': 3, 'created': '2016-03-03 09:51:57.000000000', 'files': ['magnum_ui/static/dashboard/containers/containers/create/create.service.js', 'magnum_ui/static/dashboard/containers/magnum.service.js', 'magnum_ui/static/dashboard/containers/containers/create/create-workflow.service.js', 'magnum_ui/static/dashboard/containers/containers/table/table.controller.js', 'magnum_ui/static/dashboard/containers/containers/actions.module.js', 'magnum_ui/static/dashboard/containers/containers/containers.module.js', 'magnum_ui/static/dashboard/containers/containers/table/table.html', 'magnum_ui/static/dashboard/containers/containers/create/modal.controller.js', 'magnum_ui/static/dashboard/containers/containers/create/wizard.controller.js', 'magnum_ui/static/dashboard/containers/containers/delete/delete.service.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/c7c4750b515c5d066b886acedc753c304971a06d', 'message': 'Refactor actions in Container table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Container table\nview.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ib5f712b83e17124217771ec79e0d255d3166da6a\nCloses-Bug: #1543879\n'}]",0,283462,c7c4750b515c5d066b886acedc753c304971a06d,13,4,3,16352,,,0,"Refactor actions in Container table

According to latest Horizon framework, we should refactor
batch actions at left-top of table view and row actions in
each table rows.

This patch does refactor these actions in Container table
view.

Also, this patch shows ""confirm delete"" dialog.

Change-Id: Ib5f712b83e17124217771ec79e0d255d3166da6a
Closes-Bug: #1543879
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/62/283462/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/containers/containers/create/create.service.js', 'magnum_ui/static/dashboard/containers/magnum.service.js', 'magnum_ui/static/dashboard/containers/containers/create/create-workflow.service.js', 'magnum_ui/static/dashboard/containers/containers/table/table.controller.js', 'magnum_ui/static/dashboard/containers/containers/containers.module.js', 'magnum_ui/static/dashboard/containers/containers/table/table.html', 'magnum_ui/static/dashboard/containers/containers/create/modal.controller.js', 'magnum_ui/static/dashboard/containers/containers/create/wizard.controller.js', 'magnum_ui/static/dashboard/containers/containers/table/batch-actions.service.js', 'magnum_ui/static/dashboard/containers/containers/table/row-actions.service.js', 'magnum_ui/static/dashboard/containers/containers/delete/delete.service.js']",11,ca6a8e3b40fcf5e892533c97528c35fafba3518d,bug/1543879-container,"/** * Licensed under the Apache License, Version 2.0 (the ""License""); you may * not use self file except in compliance with the License. You may obtain * a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ (function() { 'use strict'; angular .module('horizon.dashboard.containers.containers') .factory('horizon.dashboard.containers.containers.delete.deleteService', deleteService); deleteService.$inject = [ 'horizon.app.core.openstack-service-api.magnum', 'horizon.app.core.openstack-service-api.policy', 'horizon.framework.widgets.modal.deleteModalService', 'horizon.framework.util.i18n.gettext', 'horizon.framework.util.q.extensions', 'horizon.dashboard.containers.containers.events' ]; /** * @ngDoc factory * @name horizon.dashboard.containers.containers.delete.deleteService * * @Description * Brings up the delete containers confirmation modal dialog. * On submit, delete selected resources. * On cancel, do nothing. */ function deleteService( magnum, policy, deleteModalService, gettext, $qExtensions, events ) { var scope; var singleLabels = { title: gettext('Confirm Delete Container'), /* eslint-disable max-len */ message: gettext('You have selected ""%s"". Please confirm your selection. Deleted container is not recoverable.'), /* eslint-enable max-len */ submit: gettext('Delete Container'), success: gettext('Deleted Container: %s.'), error: gettext('Unable to delete Container: %s.') }; var multiLabels = { title: gettext('Confirm Delete Containers'), /* eslint-disable max-len */ message: gettext('You have selected ""%s"". Please confirm your selection. Deleted containers are not recoverable.'), /* eslint-enable max-len */ submit: gettext('Delete Containers'), success: gettext('Deleted Containers: %s.'), error: gettext('Unable to delete Containers: %s.') }; var context = { labels: null, deleteEntity: deleteEntity, successEvent: events.DELETE_SUCCESS }; var service = { initScope: initScope, allowed: allowed, perform: perform }; return service; ////////////// // include this function in your service // if you plan to emit events to the parent controller function initScope($scope) { scope = $scope; } function allowed() { return $qExtensions.booleanAsPromise(true); } // delete selected resource objects function perform(selected) { if(!selected.hasOwnProperty('id')){ // batch (multi) context.labels = multiLabels; var items = getSelectedItems(selected); $qExtensions.allSettled(items.map(checkPermission)).then(afterCheck); }else{ // row (single) context.labels = singleLabels; deleteModalService.open(scope, [selected], context); } } // for batch delete function checkPermission(selected) { return {promise: allowed(selected), context: selected}; } // for batch delete function afterCheck(result){ if (result.fail.length > 0) { toast.add('error', getMessage(notAllowedMessage, result.fail)); } if (result.pass.length > 0) { deleteModalService.open(scope, result.pass.map(getEntity), context); } } // for batch delete function getSelectedItems(selected) { return Object.keys(selected).filter(isChecked).map(getItem); function isChecked(value) { return selected[value].checked; } function getItem(value) { return selected[value].item; } } // for batch delete function getEntity(result) { return result.context; } // call delete REST API function deleteEntity(id){ return magnum.deleteContainer(id, true); } } })(); ",,434,182
openstack%2Fmagnum-ui~master~Ia124ee756105460236d72ece51804c5ae3305432,openstack/magnum-ui,master,Ia124ee756105460236d72ece51804c5ae3305432,Refactor actions in Bay table,MERGED,2016-02-23 06:00:55.000000000,2016-03-06 08:04:16.000000000,2016-03-06 08:04:16.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 9576}, {'_account_id': 11536}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-02-23 06:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/42319695a45c28c6c20a1c9c28244736414777cf', 'message': 'Refactor actions in Bay table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Bay table view.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ia124ee756105460236d72ece51804c5ae3305432\nPartial-Bug: #1543879\n'}, {'number': 2, 'created': '2016-03-01 11:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/ad27a35053ffdd8c60d15803ee4c6ef47b70ed4e', 'message': 'Refactor actions in Bay table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Bay table view.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ia124ee756105460236d72ece51804c5ae3305432\nPartial-Bug: #1543879\n'}, {'number': 3, 'created': '2016-03-03 04:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/e12d792c74da7f589ab81d9ff3f3a191781f6573', 'message': 'Refactor actions in Bay table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Bay table view.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ia124ee756105460236d72ece51804c5ae3305432\nPartial-Bug: #1543879\n'}, {'number': 4, 'created': '2016-03-03 09:34:25.000000000', 'files': ['magnum_ui/static/dashboard/containers/bays/table/table.controller.js', 'magnum_ui/static/dashboard/containers/magnum.service.js', 'magnum_ui/static/dashboard/containers/bays/create/wizard.controller.js', 'magnum_ui/static/dashboard/containers/bays/table/table.html', 'magnum_ui/static/dashboard/containers/bays/create/create-workflow.service.js', 'magnum_ui/static/dashboard/containers/bays/delete/delete.service.js', 'magnum_ui/static/dashboard/containers/bays/create/create.service.js', 'magnum_ui/static/dashboard/containers/bays/actions.module.js', 'magnum_ui/static/dashboard/containers/bays/create/modal.controller.js', 'magnum_ui/static/dashboard/containers/bays/bays.module.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/cbc3e83180238eacaeb0d3040dc35cd11278e4e3', 'message': 'Refactor actions in Bay table\n\nAccording to latest Horizon framework, we should refactor\nbatch actions at left-top of table view and row actions in\neach table rows.\n\nThis patch does refactor these actions in Bay table view.\n\nAlso, this patch shows ""confirm delete"" dialog.\n\nChange-Id: Ia124ee756105460236d72ece51804c5ae3305432\nPartial-Bug: #1543879\n'}]",24,283396,cbc3e83180238eacaeb0d3040dc35cd11278e4e3,16,5,4,16352,,,0,"Refactor actions in Bay table

According to latest Horizon framework, we should refactor
batch actions at left-top of table view and row actions in
each table rows.

This patch does refactor these actions in Bay table view.

Also, this patch shows ""confirm delete"" dialog.

Change-Id: Ia124ee756105460236d72ece51804c5ae3305432
Partial-Bug: #1543879
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/96/283396/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/containers/bays/table/batch-actions.service.js', 'magnum_ui/static/dashboard/containers/bays/table/table.controller.js', 'magnum_ui/static/dashboard/containers/magnum.service.js', 'magnum_ui/static/dashboard/containers/bays/create/wizard.controller.js', 'magnum_ui/static/dashboard/containers/bays/table/table.html', 'magnum_ui/static/dashboard/containers/bays/create/create-workflow.service.js', 'magnum_ui/static/dashboard/containers/bays/delete/delete.service.js', 'magnum_ui/static/dashboard/containers/bays/table/row-actions.service.js', 'magnum_ui/static/dashboard/containers/bays/create/create.service.js', 'magnum_ui/static/dashboard/containers/bays/create/modal.controller.js', 'magnum_ui/static/dashboard/containers/bays/bays.module.js']",11,42319695a45c28c6c20a1c9c28244736414777cf,bug/1543879," .module('horizon.dashboard.containers.bays', []) .constant('horizon.dashboard.containers.bays.events', events()); /** * @ngdoc constant * @name horizon.dashboard.containers.bays.events * @description A list of events used by Bays */ function events() { return { CREATE_SUCCESS: 'horizon.dashboard.containers.bays.CREATE_SUCCESS', DELETE_SUCCESS: 'horizon.dashboard.containers.bays.DELETE_SUCCESS' }; }"," .module('horizon.dashboard.containers.bays', []);",432,180
openstack%2Fnetworking-ovn~master~Ie395286a049054fe9bb74e346a06ad7416a801b1,openstack/networking-ovn,master,Ie395286a049054fe9bb74e346a06ad7416a801b1,Doc: Add missing Neutron API extensions,MERGED,2016-03-04 16:20:51.000000000,2016-03-06 08:00:08.000000000,2016-03-06 08:00:08.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 11343}]","[{'number': 1, 'created': '2016-03-04 16:20:51.000000000', 'files': ['doc/source/features.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/74ed80dfbe9da20a81e5752393ac6df72735315c', 'message': 'Doc: Add missing Neutron API extensions\n\nAdd missing Neutron API extensions and include a note for\nextensions only applicable when conventional layer-3 agent\nenabled.\n\nChange-Id: Ie395286a049054fe9bb74e346a06ad7416a801b1\n'}]",0,288563,74ed80dfbe9da20a81e5752393ac6df72735315c,9,3,1,8410,,,0,"Doc: Add missing Neutron API extensions

Add missing Neutron API extensions and include a note for
extensions only applicable when conventional layer-3 agent
enabled.

Change-Id: Ie395286a049054fe9bb74e346a06ad7416a801b1
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/63/288563/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/features.rst'],1,74ed80dfbe9da20a81e5752393ac6df72735315c,doc,+----------------------------------+---------------------------+ | Extension Name | Extension Alias | +==================================+===========================+ | agent | agent | +----------------------------------+---------------------------+ | Auto Allocated Topology Services | auto-allocated-topology | +----------------------------------+---------------------------+ | Availability Zone | availability_zone | +----------------------------------+---------------------------+ | DHCP Agent Scheduler | dhcp_agent_scheduler | +----------------------------------+---------------------------+ | HA Router extension * | l3-ha | +----------------------------------+---------------------------+ | L3 Agent Scheduler * | l3_agent_scheduler | +----------------------------------+---------------------------+ | Network Availability Zone | network_availability_zone | +----------------------------------+---------------------------+ | Neutron external network | external-net | +----------------------------------+---------------------------+ | Neutron Extra DHCP opts | extra_dhcp_opt | +----------------------------------+---------------------------+ | Neutron Extra Route | extraroute | +----------------------------------+---------------------------+ | Neutron L3 Router | router | +----------------------------------+---------------------------+ | Network MTU | net-mtu | +----------------------------------+---------------------------+ | Port Binding | binding | +----------------------------------+---------------------------+ | Provider Network | provider | +----------------------------------+---------------------------+ | Quality of Service | qos | +----------------------------------+---------------------------+ | Quota management support | quotas | +----------------------------------+---------------------------+ | RBAC Policies | rbac-policies | +----------------------------------+---------------------------+ | security-group | security-group | +----------------------------------+---------------------------+ | Subnet Allocation | subnet_allocation | +----------------------------------+---------------------------+ (\*) Only applicable when conventional layer-3 agent enabled.,+---------------------------+---------------------------+ | Extension Name | Extension Alias | +===========================+===========================+ | agent | agent | +---------------------------+---------------------------+ | Availability Zone | availability_zone | +---------------------------+---------------------------+ | DHCP Agent Scheduler | dhcp_agent_scheduler | +---------------------------+---------------------------+ | Network Availability Zone | network_availability_zone | +---------------------------+---------------------------+ | Neutron external network | external-net | +---------------------------+---------------------------+ | Neutron Extra DHCP opts | extra_dhcp_opt | +---------------------------+---------------------------+ | Neutron Extra Route | extraroute | +---------------------------+---------------------------+ | Neutron L3 Router | router | +---------------------------+---------------------------+ | Network MTU | net-mtu | +---------------------------+---------------------------+ | Port Binding | binding | +---------------------------+---------------------------+ | Provider Network | provider | +---------------------------+---------------------------+ | Quality of Service | qos | +---------------------------+---------------------------+ | Quota management support | quotas | +---------------------------+---------------------------+ | RBAC Policies | rbac-policies | +---------------------------+---------------------------+ | security-group | security-group | +---------------------------+---------------------------+ | Subnet Allocation | subnet_allocation | +---------------------------+---------------------------+,43,35
openstack%2Fmagnum-ui~master~I8c00b5353e8fa40119a6979d99b75a57dfb06eae,openstack/magnum-ui,master,I8c00b5353e8fa40119a6979d99b75a57dfb06eae,Add volume_driver attribute to baymodel,MERGED,2016-02-22 08:48:34.000000000,2016-03-06 07:57:26.000000000,2016-03-06 07:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 9576}, {'_account_id': 9591}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-02-22 08:48:34.000000000', 'files': ['magnum_ui/static/dashboard/containers/baymodels/detail/detail.html', 'magnum_ui/api/magnum.py', 'magnum_ui/static/dashboard/containers/baymodels/create/info/baymodel.info.controller.js', 'magnum_ui/static/dashboard/containers/baymodels/create/baymodel-model.js', 'magnum_ui/static/dashboard/containers/baymodels/create/spec/spec.html'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/1962a39d0263c058098116db626528d18a1a901e', 'message': 'Add volume_driver attribute to baymodel\n\nThis patch adds volume_driver baymodel attribute into\nbaymodel detail view and baymodel create dialog.\n\nAlso, revise function of changing pull-down items for\nnetwork_driver and volume_driver according to COE selection.\nBecause initial items are not shown when COE selection is\nput back.\n\nChange-Id: I8c00b5353e8fa40119a6979d99b75a57dfb06eae\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}]",1,283005,1962a39d0263c058098116db626528d18a1a901e,12,5,1,16352,,,0,"Add volume_driver attribute to baymodel

This patch adds volume_driver baymodel attribute into
baymodel detail view and baymodel create dialog.

Also, revise function of changing pull-down items for
network_driver and volume_driver according to COE selection.
Because initial items are not shown when COE selection is
put back.

Change-Id: I8c00b5353e8fa40119a6979d99b75a57dfb06eae
Partially-Implements: blueprint create-trustee-user-for-each-bay
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/05/283005/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/containers/baymodels/detail/detail.html', 'magnum_ui/api/magnum.py', 'magnum_ui/static/dashboard/containers/baymodels/create/info/baymodel.info.controller.js', 'magnum_ui/static/dashboard/containers/baymodels/create/baymodel-model.js', 'magnum_ui/static/dashboard/containers/baymodels/create/spec/spec.html']",5,1962a39d0263c058098116db626528d18a1a901e,bp/create-trustee-user-for-each-bay," <div class=""form-field baymodel-volume-driver""> <label class=""on-top"" translate>Volume Driver</label> <select name=""baymodel-volume-driver"" type=""text"" class=""form-control input-sm"" ng-model=""model.newBayModelSpec.volume_driver"" placeholder=""{$ 'The volume driver name for instantiating container volume.'|translate $}"" ng-options=""driver.name as driver.label for driver in model.newBayModelSpec.volume_drivers""> </select> </div>",,50,8
openstack%2Fmagnum-ui~master~I1aba927b17e80945919931eb02b06cc6cf6a322b,openstack/magnum-ui,master,I1aba927b17e80945919931eb02b06cc6cf6a322b,Imported Translations from Zanata,MERGED,2016-03-05 06:01:24.000000000,2016-03-06 07:33:30.000000000,2016-03-06 07:33:30.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 11536}]","[{'number': 1, 'created': '2016-03-05 06:01:24.000000000', 'files': ['magnum_ui/locale/ja/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/8deca097d04914bb4a2e32c047cbf14227e7c247', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1aba927b17e80945919931eb02b06cc6cf6a322b\n'}]",0,288842,8deca097d04914bb4a2e32c047cbf14227e7c247,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1aba927b17e80945919931eb02b06cc6cf6a322b
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/42/288842/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum_ui/locale/ja/LC_MESSAGES/djangojs.po'],1,8deca097d04914bb4a2e32c047cbf14227e7c247,zanata/translations,"# Akihiro Motoki <amotoki@gmail.com>, 2016. #zanata""PO-Revision-Date: 2016-03-04 08:19+0000\n""#, fuzzy#, fuzzymsgstr ""ベイモデルを選択してください"" #, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzymsgstr ""コンテナーの名前を設定してください"" #, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy#, fuzzy, python-format","# Shu Muto <shu-mutou@rf.jp.nec.com>, 2015. #zanata""PO-Revision-Date: 2016-02-23 12:35+0000\n""msgstr ""ベイモデルを選択してください。"" msgstr ""コンテナーの名前を設定してください。"" #, python-format",28,5
openstack%2Fmagnum-ui~master~I3ea4b529025c8ac3c4092f3720124647861e6668,openstack/magnum-ui,master,I3ea4b529025c8ac3c4092f3720124647861e6668,Remove unused pngmath Sphinx extension,MERGED,2016-02-28 19:45:47.000000000,2016-03-06 07:28:35.000000000,2016-03-06 07:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 9576}, {'_account_id': 11536}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-02-28 19:45:47.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/28bf51f6c31a0918b8f7090c999fd2516d4bedcc', 'message': 'Remove unused pngmath Sphinx extension\n\nThere\'s no RST file that uses "".. math"" and thus\nthe pngmath Sphinx extension is not used and can\nget removed.\n\nChange-Id: I3ea4b529025c8ac3c4092f3720124647861e6668\n'}]",0,285835,28bf51f6c31a0918b8f7090c999fd2516d4bedcc,10,5,1,6547,,,0,"Remove unused pngmath Sphinx extension

There's no RST file that uses "".. math"" and thus
the pngmath Sphinx extension is not used and can
get removed.

Change-Id: I3ea4b529025c8ac3c4092f3720124647861e6668
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/35/285835/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,28bf51f6c31a0918b8f7090c999fd2516d4bedcc,pngmath,," 'sphinx.ext.pngmath',",0,1
openstack%2Fvitrage~master~Id1c844abd76c239ecf185a9ec93749dfae0d1ebe,openstack/vitrage,master,Id1c844abd76c239ecf185a9ec93749dfae0d1ebe,create some directories in conf directory,MERGED,2016-03-06 07:03:02.000000000,2016-03-06 07:15:21.000000000,2016-03-06 07:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-03-06 07:03:02.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/ca957f3b010b496657b5fcc3b7fa139aafc63a0f', 'message': 'create some directories in conf directory\n\ncopy the states plugins yaml file\nto the conf directory\n\nChange-Id: Id1c844abd76c239ecf185a9ec93749dfae0d1ebe\n'}]",0,288983,ca957f3b010b496657b5fcc3b7fa139aafc63a0f,6,2,1,19134,,,0,"create some directories in conf directory

copy the states plugins yaml file
to the conf directory

Change-Id: Id1c844abd76c239ecf185a9ec93749dfae0d1ebe
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/83/288983/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,ca957f3b010b496657b5fcc3b7fa139aafc63a0f,devstack, # create some folders mkdir -p /etc/states_plugins mkdir -p /etc/static_plugins mkdir -p /etc/templates # copy plugins cp $VITRAGE_DIR/etc/vitrage/states_plugins/*.yaml $VITRAGE_CONF_DIR/states_plugins ,,9,0
openstack%2Fsahara-dashboard~master~Iffba33723b3f94fc71f4fa3381580df7e17bfd1a,openstack/sahara-dashboard,master,Iffba33723b3f94fc71f4fa3381580df7e17bfd1a,Imported Translations from Zanata,MERGED,2016-03-06 06:04:48.000000000,2016-03-06 07:09:32.000000000,2016-03-06 07:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-06 06:04:48.000000000', 'files': ['sahara_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e052edfae9cf0f53c9996f1077100cdc3e04fccf', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iffba33723b3f94fc71f4fa3381580df7e17bfd1a\n'}]",0,288973,e052edfae9cf0f53c9996f1077100cdc3e04fccf,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iffba33723b3f94fc71f4fa3381580df7e17bfd1a
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/73/288973/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po'],1,e052edfae9cf0f53c9996f1077100cdc3e04fccf,zanata/translations,"""PO-Revision-Date: 2016-03-05 11:33+0000\n"" ""Last-Translator: Shengjing Zhu <zsj950618@gmail.com>\n""msgstr """" ""对于配置和参数，定义键名类型；对于参数，定义索引类型为从 0 开始的整数。"" #, fuzzymsgstr ""对于数据源，使用数据源 UUID 或者路径（根据数据源创建）。""","""PO-Revision-Date: 2016-03-04 03:09+0000\n"" ""Last-Translator: Gaoxiao Zhu <zhu.gaoxiao@h3c.com>\n""msgstr ""对于配置和参数，定义键名类型；对于参数，定义索引类型为从0开始的整数。"" msgstr ""对于数据源，使用数据源UUID或者路径（根据数据源创建。）""",6,4
openstack%2Fapi-site~master~I883631eb09f9e47b43712e5e4902da5070280ba4,openstack/api-site,master,I883631eb09f9e47b43712e5e4902da5070280ba4,Imported Translations from Zanata,MERGED,2016-03-06 06:19:13.000000000,2016-03-06 06:43:32.000000000,2016-03-06 06:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-06 06:19:13.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-quick-start/source/locale/ko_KR/LC_MESSAGES/api-quick-start.po', 'firstapp/source/locale/firstapp.pot'], 'web_link': 'https://opendev.org/openstack/api-site/commit/72f348d6511ca1d76bb9628bc0fd8ff6a495804e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I883631eb09f9e47b43712e5e4902da5070280ba4\n'}]",0,288977,72f348d6511ca1d76bb9628bc0fd8ff6a495804e,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I883631eb09f9e47b43712e5e4902da5070280ba4
",git fetch https://review.opendev.org/openstack/api-site refs/changes/77/288977/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-quick-start/source/locale/ko_KR/LC_MESSAGES/api-quick-start.po', 'firstapp/source/locale/firstapp.pot']",4,72f348d6511ca1d76bb9628bc0fd8ff6a495804e,zanata/translations,"""POT-Creation-Date: 2016-03-06 06:18+0000\n""""`a recent version of shade library installed <http://docs.openstack.org/"" ""infra/shade/installation.html>`_.""","""POT-Creation-Date: 2016-01-19 06:04+0000\n""""`a recent version of shade library installed <https://pypi.python.org/pypi/"" ""shade/0.11.0>`_.""",193,134
openstack%2Ftempest~master~I78c472f2284a8641c0c7cf0b3e0994984a04c5b0,openstack/tempest,master,I78c472f2284a8641c0c7cf0b3e0994984a04c5b0,Tokens need user domain be created correctly,MERGED,2016-02-23 20:29:39.000000000,2016-03-06 06:34:27.000000000,2016-03-03 17:07:48.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 8001}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 17123}, {'_account_id': 17254}]","[{'number': 1, 'created': '2016-02-23 20:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b94ad1fe170f57698d28f9d7c5cd21199bf7206f', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name is not specified.\nThis is okay when running tempest against devstack, since\nthere is a default domain but in productions the test user is\nrarely in the default domain.  Instead we should also pass\nuser_domain_id to get_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\n""}, {'number': 2, 'created': '2016-02-23 20:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f828ce5b6ce311dfda02123a2b12cec3b36dbe4b', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name is not specified.\nThis is okay when running tempest against devstack, since\nthere is a default domain but in productions the test user is\nrarely in the default domain.  Instead we should also pass\nuser_domain_id to get_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\nCloses-Bug: #1548987\n""}, {'number': 3, 'created': '2016-02-23 21:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7486dc8f2f7e7c7dfd099673116170d61e2a0f89', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name is not specified.\nThis is okay when running tempest against devstack, since\nthere is a default domain but in productions the test user is\nrarely in the default domain.  Instead we should also pass\nuser_domain_id to get_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\nPartial-Bug: #1548987\n""}, {'number': 4, 'created': '2016-02-23 21:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d81bfac38f911db64f711212db111a9c8fcd0188', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name are not specified.\nThis is okay when running tempest against devstack, since\nthe user is in the default domain but in productions the\ntest user is rarely in the default domain. Instead we should\nalso pass user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name to\nget_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\nCloses-Bug: #1548987\n""}, {'number': 5, 'created': '2016-02-26 17:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c37b4f10d25feb0478b14e044a2676f511aa068', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name are not specified.\nThis is okay when running tempest against devstack, since\nthe user is in the default domain but in productions the\ntest user is rarely in the default domain. Instead we should\nalso pass user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name to\nget_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\nCloses-Bug: #1548987\n""}, {'number': 6, 'created': '2016-02-29 14:35:12.000000000', 'files': ['tempest/api/identity/v3/test_tokens.py', 'tempest/api/identity/v3/test_projects.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e3cff1d493b1e091379a8cc923bc1d1878647bf', 'message': ""Tokens need user domain be created correctly\n\nWhen calling get_token() there are many assumptions on the\ndomain when user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name are not specified.\nThis is okay when running tempest against devstack, since\nthe user is in the default domain but in productions the\ntest user is rarely in the default domain. Instead we should\nalso pass user_domain_id or user_domain_name and\nproject_domain_id or project_domain_name to\nget_token to create a token.\n\nIf there is a case where user_domain_id is None when passed\nto get_token() the previous functionality still takes into effect.\nAssuming the user is in the 'Default' domain.\n\nChange-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0\nCloses-Bug: #1548987\n""}]",0,283781,5e3cff1d493b1e091379a8cc923bc1d1878647bf,30,9,6,17123,,,0,"Tokens need user domain be created correctly

When calling get_token() there are many assumptions on the
domain when user_domain_id or user_domain_name and
project_domain_id or project_domain_name are not specified.
This is okay when running tempest against devstack, since
the user is in the default domain but in productions the
test user is rarely in the default domain. Instead we should
also pass user_domain_id or user_domain_name and
project_domain_id or project_domain_name to
get_token to create a token.

If there is a case where user_domain_id is None when passed
to get_token() the previous functionality still takes into effect.
Assuming the user is in the 'Default' domain.

Change-Id: I78c472f2284a8641c0c7cf0b3e0994984a04c5b0
Closes-Bug: #1548987
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/283781/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/v3/test_tokens.py'],1,b94ad1fe170f57698d28f9d7c5cd21199bf7206f,bug/1548987," user_domain_id = creds.user_domain_id # 'user_domain_id' needs to be specified otherwise tempest_lib assumes # it to be 'default' token_id, resp = self.non_admin_token.get_token( user_id=user_id, username=username, user_domain_id=user_domain_id, password=password, auth_data=True)"," token_id, resp = self.non_admin_token.get_token(user_id=user_id, password=password, auth_data=True)",9,3
openstack%2Fmagnum~master~I269332b5736b6c5a9bc85d843f0d03f1a4d059ee,openstack/magnum,master,I269332b5736b6c5a9bc85d843f0d03f1a4d059ee,Add auth_url,MERGED,2016-02-29 11:42:20.000000000,2016-03-06 06:27:05.000000000,2016-03-06 06:27:05.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 19133}]","[{'number': 1, 'created': '2016-02-29 11:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bd9b3998d140384355d0e2c45154d7c1234a72fc', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 2, 'created': '2016-02-29 12:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cad612dd6ffa0e70fee4d96c23b34c7c3e9a5f49', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 3, 'created': '2016-02-29 12:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e582742562294abd54af667aa3cb0844a8467069', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 4, 'created': '2016-03-01 12:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3f6f81876f7b14832d37f003c296f27475b93894', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 5, 'created': '2016-03-02 02:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6ccd1e254a140de3b7f3452287fbf6889c0b48f1', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 6, 'created': '2016-03-02 12:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/93e0d5d465c08e93a1c41658af29c2fdbd155f03', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 7, 'created': '2016-03-03 06:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bca0c4d60f6aba95e44931dd3f23fd17801ac967', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 8, 'created': '2016-03-03 07:25:03.000000000', 'files': ['magnum/templates/kubernetes/kubecluster-fedora-ironic.yaml', 'magnum/templates/kubernetes/kubecluster.yaml', 'magnum/templates/kubernetes/kubecluster-coreos.yaml', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/templates/mesos/mesoscluster.yaml', 'magnum/tests/unit/conductor/handlers/test_k8s_bay_conductor.py', 'magnum/tests/unit/conductor/handlers/test_mesos_bay_conductor.py', 'magnum/conductor/template_definition.py', 'magnum/templates/kubernetes/fragments/write-kube-os-config.sh', 'magnum/tests/unit/conductor/test_template_definition.py', 'magnum/tests/unit/conductor/handlers/test_swarm_bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b79203aa9845a714ba2effa6cba588b4537b4fc1', 'message': 'Add auth_url\n\nUrl for keystone is needed by trust and other services, such as k8s\nand docker registry.\n\nChange-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}]",10,285988,b79203aa9845a714ba2effa6cba588b4537b4fc1,34,8,8,12053,,,0,"Add auth_url

Url for keystone is needed by trust and other services, such as k8s
and docker registry.

Change-Id: I269332b5736b6c5a9bc85d843f0d03f1a4d059ee
Partially-Implements: blueprint create-trustee-user-for-each-bay
",git fetch https://review.opendev.org/openstack/magnum refs/changes/88/285988/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/kubernetes/kubecluster-fedora-ironic.yaml', 'magnum/templates/kubernetes/kubecluster.yaml', 'magnum/templates/kubernetes/kubecluster-coreos.yaml', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/templates/mesos/mesoscluster.yaml', 'magnum/conductor/template_definition.py', 'magnum/templates/kubernetes/fragments/write-kube-os-config.sh']",7,bd9b3998d140384355d0e2c45154d7c1234a72fc,bp/create-trustee-user-for-each-bay,AUTH_URL=${AUTH_URL/v3/v2} ,,22,10
openstack%2Fkeystone~master~Ifde7cea02dceb280f2fb6ee7fe72316078a00606,openstack/keystone,master,Ifde7cea02dceb280f2fb6ee7fe72316078a00606,Updated from global requirements,MERGED,2016-03-05 03:05:53.000000000,2016-03-06 06:24:02.000000000,2016-03-06 06:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8871}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 03:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3398f60404a85ac150e2f11207fb8bf3370ecb3', 'message': 'Updated from global requirements\n\nChange-Id: Ifde7cea02dceb280f2fb6ee7fe72316078a00606\n'}, {'number': 2, 'created': '2016-03-05 15:16:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7c267ce4f222bb4e6d6c47af4e6864815df85a4c', 'message': 'Updated from global requirements\n\nChange-Id: Ifde7cea02dceb280f2fb6ee7fe72316078a00606\n'}]",0,288829,7c267ce4f222bb4e6d6c47af4e6864815df85a4c,12,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ifde7cea02dceb280f2fb6ee7fe72316078a00606
",git fetch https://review.opendev.org/openstack/keystone refs/changes/29/288829/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d3398f60404a85ac150e2f11207fb8bf3370ecb3,openstack/requirements,oslo.cache>=1.5.0 # Apache-2.0,oslo.cache>=0.8.0 # Apache-2.0,1,1
openstack%2Fheat~master~Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e,openstack/heat,master,Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e,Fix problems in unicode template support,MERGED,2015-12-10 04:13:33.000000000,2016-03-06 06:06:00.000000000,2016-03-06 06:06:00.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}]","[{'number': 1, 'created': '2015-12-10 04:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b7fb081deafd59be74a876df2dcea91ddd81d0fa', 'message': 'Supports unicode in template\n\nIf we use chinese character in template for\nresource name or output key, we will get an\nUnicodeDecodeError/UnicodeEncodeError while\nstack creating or deleting.\nwe should try to remove str() in codes and\nuse six.text_type() instead.\n\nCloses-Bug: #1524194\n\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 2, 'created': '2015-12-10 08:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/33309c1d9d88f0c751dbec36d58f676e6cbc74b3', 'message': 'Supports unicode in template\n\nIf we use chinese character in template for\nresource name or output key, we will get an\nUnicodeDecodeError/UnicodeEncodeError while\nstack creating or deleting.\nwe should try to remove str() in codes and\nuse six.text_type() instead.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 3, 'created': '2015-12-10 14:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/29c2c0c1e3e3a82b011506389e747e8e1a91722f', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n1. The class wrap with six.python_2_unicode_compatible, In\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n2. python_2_unicode_compatible will not handle __repr__.\n3. __repr__ should return str in all versions of python,\nso the return string in python2 should be encode.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 4, 'created': '2015-12-10 14:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9341a831403535cb2a9b8b175f03f5639f908f0a', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. The class wrap with six.python_2_unicode_compatible, In\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python,\nso the return string in python2 should be encode.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 5, 'created': '2015-12-11 03:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/270c49b4ae30d8b36999f981ec11f73985922bb5', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. The class wrap with six.python_2_unicode_compatible, In\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python,\nso the return string in python2 should be encode.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 6, 'created': '2015-12-21 03:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8914c76b5d594b45456a21a442e350e7cab88812', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. The class wrap with six.python_2_unicode_compatible, In\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python,\nso the return string in python2 should be encode.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 7, 'created': '2015-12-21 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/151f8be4d56cff77fccd87902802b1ac963040cb', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 8, 'created': '2015-12-21 11:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/07ddc0c161f48eced90e21ddd59c2444c18814b7', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 9, 'created': '2015-12-23 08:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a62dcda1721e87c8dd4884ae2ff798bef9c73f6', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 10, 'created': '2016-02-17 10:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7db156498421d8e78e02ffcb9004d78aa2bc1308', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 11, 'created': '2016-02-18 09:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e3ebd7472427e88b6422c3df23a25659a57a4201', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 12, 'created': '2016-02-29 02:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f57320beb37d3713ce95e7a383057ce2f9dc6d94', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}, {'number': 13, 'created': '2016-03-04 01:59:40.000000000', 'files': ['heat/engine/update.py', 'heat/tests/engine/test_scheduler.py', 'heat/common/i18n.py', 'heat/engine/attributes.py', 'heat/engine/rsrc_defn.py', 'heat/engine/scheduler.py', 'heat_integrationtests/functional/test_unicode_template.py', 'heat/engine/dependencies.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6cf8dc6e569842afa5f3d4a7236727f844f7ba63', 'message': 'Fix problems in unicode template support\n\nIf we use unicode as resource name or parameter,\nwe are likely to encounter unicode problems.\nThis patch aims to fix unicode problems, and\nthere are several things to be clear:\n\n1. For the class wrap with six.python_2_unicode_compatible, in\npython2 their original __str__ function will map to __unicode__,\nand new __str__ function comes from __unicode__.encode.\nSo we should always return unicode in __str__() if wrap\nwith python_2_unicode_compatible.\n\n2. python_2_unicode_compatible will not handle __repr__,\n__repr__ should return str in all versions of python.\n\nCo-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>\nCloses-Bug: #1524194\nChange-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e\n'}]",13,255663,6cf8dc6e569842afa5f3d4a7236727f844f7ba63,48,8,13,8289,,,0,"Fix problems in unicode template support

If we use unicode as resource name or parameter,
we are likely to encounter unicode problems.
This patch aims to fix unicode problems, and
there are several things to be clear:

1. For the class wrap with six.python_2_unicode_compatible, in
python2 their original __str__ function will map to __unicode__,
and new __str__ function comes from __unicode__.encode.
So we should always return unicode in __str__() if wrap
with python_2_unicode_compatible.

2. python_2_unicode_compatible will not handle __repr__,
__repr__ should return str in all versions of python.

Co-Authored-By: Ethan Lynn <xjunlin@cn.ibm.com>
Closes-Bug: #1524194
Change-Id: Ib4af43d153e0edf9d66308bf8e7b93a3be501d2e
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/255663/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/scheduler.py', 'heat/engine/dependencies.py']",2,b7fb081deafd59be74a876df2dcea91ddd81d0fa,bug/1524194," text = '{%s}' % ', '.join(six.text_type(n) for n in self) pairs = ('%s: %s' % (six.text_type(k), six.text_type(v)) for k, v in six.iteritems(self))"," text = '{%s}' % ', '.join(str(n) for n in self) pairs = ('%s: %s' % (str(k), str(v)) for k, v in six.iteritems(self))",5,3
openstack%2Frequirements~master~If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a,openstack/requirements,master,If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a,Add scapy,ABANDONED,2016-02-09 15:41:09.000000000,2016-03-06 05:51:03.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-09 15:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/61fb8370f85ad90dee27fe033c801dd6b0c951dd', 'message': 'Add scapy and python-pytun\n\nThese libraries are needed for tests in dragonflow. Scapy[2] is used to\ngenerate and parse network packets. python-pytun[1] is used to interface\n(read packets from and send packets to) TAP (and TUN) devices. For\npython3, scapy-python3[3] isused.\n\nAll packages are actively maintained. python-pytun is MIT license.\nscapy(s) are GPLv2 licenses.\n\n[1] https://pypi.python.org/pypi/python-pytun/2.2.1\n[2] https://pypi.python.org/pypi/scapy\n[3] https://github.com/phaethon/scapy\n\nChange-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a\n'}, {'number': 2, 'created': '2016-02-10 05:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/04f522890e6efaf58ce434752927c1726da5b70b', 'message': 'Add scapy and python-pytun\n\nThese libraries are needed for tests in dragonflow. Scapy[2] is used to\ngenerate and parse network packets. python-pytun[1] is used to interface\n(read packets from and send packets to) TAP (and TUN) devices. For\npython3, scapy-python3[3] isused.\n\nAll packages are actively maintained. python-pytun is MIT license.\nscapy(s) are GPLv2 licenses.\n\n[1] https://pypi.python.org/pypi/python-pytun/2.2.1\n[2] https://pypi.python.org/pypi/scapy\n[3] https://github.com/phaethon/scapy\n\nChange-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a\n'}, {'number': 3, 'created': '2016-02-10 15:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/334e7d88913e87c87ea78fca63f212ed2630cf62', 'message': 'Add scapy and python-pytun\n\nThese libraries are needed for tests in dragonflow. Scapy[2] is used to\ngenerate and parse network packets. python-pytun[1] is used to interface\n(read packets from and send packets to) TAP (and TUN) devices. For\npython3, scapy-python3[3] isused.\n\nAll packages are actively maintained. python-pytun is MIT license.\nscapy(s) are GPLv2 licenses.\n\n[1] https://pypi.python.org/pypi/python-pytun/2.2.1\n[2] https://pypi.python.org/pypi/scapy\n[3] https://github.com/phaethon/scapy\n\nChange-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a\n'}, {'number': 4, 'created': '2016-02-16 06:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1e44747b0bcc048e9cfb24ac91a699fcd0038f37', 'message': 'Add scapy and python-pytun\n\nThese libraries are needed for tests in dragonflow. Scapy[2] is used to\ngenerate and parse network packets. python-pytun[1] is used to interface\n(read packets from and send packets to) TAP (and TUN) devices. For\npython3, scapy-python3[3] isused.\n\nAll packages are actively maintained. python-pytun is MIT license.\nscapy(s) are GPLv2 licenses.\n\n[1] https://pypi.python.org/pypi/python-pytun/2.2.1\n[2] https://pypi.python.org/pypi/scapy\n[3] https://github.com/phaethon/scapy\n\nChange-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a\n'}, {'number': 5, 'created': '2016-02-24 15:33:50.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d37262bbb192a36d41ebad0fd4ce6b18d6b0ca05', 'message': 'Add scapy\n\nThese libraries are needed for tests in dragonflow. Scapy[1] is used to\ngenerate and parse network packets. For python3, scapy-python3[2] is used.\n\nBoth packages are actively maintained. The license for both packages is\nGPLv2.\n\n[1] https://pypi.python.org/pypi/scapy\n[2] https://github.com/phaethon/scapy\n\nChange-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a\n'}]",1,277893,d37262bbb192a36d41ebad0fd4ce6b18d6b0ca05,35,8,5,20229,,,0,"Add scapy

These libraries are needed for tests in dragonflow. Scapy[1] is used to
generate and parse network packets. For python3, scapy-python3[2] is used.

Both packages are actively maintained. The license for both packages is
GPLv2.

[1] https://pypi.python.org/pypi/scapy
[2] https://github.com/phaethon/scapy

Change-Id: If92ab9d473f8ea8c861584dfc6d3e6a9ff7fdb6a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/277893/4 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,61fb8370f85ad90dee27fe033c801dd6b0c951dd,scapy,python-pytun>=2.2.1 # MITscapy>=2.3.2;python_version<'3' # GNU GPL v2 scapy-python3>=0.18;python_version>='3' # GNU GPL v2,,3,0
openstack%2Fpuppet-tempest~master~I6eae378fc703e408dfecbfac222d683490c7a215,openstack/puppet-tempest,master,I6eae378fc703e408dfecbfac222d683490c7a215,Add ssl parameters,MERGED,2016-03-04 16:56:02.000000000,2016-03-06 05:15:46.000000000,2016-03-06 05:15:46.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-04 16:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/9ca44a19f942b3cbc090a6201f5d1d809f1bd383', 'message': 'Add ssl parameters\n\n* ca_certificates_file\n* disable_ssl_certificate_validation\nChange-Id: I6eae378fc703e408dfecbfac222d683490c7a215\n'}, {'number': 2, 'created': '2016-03-04 16:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/3394d335545be359ccc3b3c9e86f16587b24a5cb', 'message': 'Add ssl parameters\n\n* ca_certificates_file\n* disable_ssl_validation\nChange-Id: I6eae378fc703e408dfecbfac222d683490c7a215\n'}, {'number': 3, 'created': '2016-03-04 17:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/f09c36556ab9840479c83057b3bb54add7d8279a', 'message': 'Add ssl parameters\n\n* ca_certificates_file\n* disable_ssl_validation\nChange-Id: I6eae378fc703e408dfecbfac222d683490c7a215\n'}, {'number': 4, 'created': '2016-03-04 22:37:08.000000000', 'files': ['manifests/init.pp', 'spec/classes/tempest_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/2dcec32ad8a3db0001faa8b02809d337fb1749bf', 'message': 'Add ssl parameters\n\n* ca_certificates_file\n* disable_ssl_validation\nChange-Id: I6eae378fc703e408dfecbfac222d683490c7a215\n'}]",0,288589,2dcec32ad8a3db0001faa8b02809d337fb1749bf,11,3,4,3153,,,0,"Add ssl parameters

* ca_certificates_file
* disable_ssl_validation
Change-Id: I6eae378fc703e408dfecbfac222d683490c7a215
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/89/288589/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/tempest_spec.rb']",2,9ca44a19f942b3cbc090a6201f5d1d809f1bd383,ssl, is_expected.to contain_tempest_config('identity/ca_certificates_file').with(:value => nil) is_expected.to contain_tempest_config('identity/disable_ssl_certificate_validation').with(:value => nil),,66,56
openstack%2Fheat~master~Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf,openstack/heat,master,Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf,Do not try to save event resource if too big for db column,MERGED,2015-12-18 04:42:06.000000000,2016-03-06 05:07:27.000000000,2016-03-06 05:07:26.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 12321}, {'_account_id': 13564}, {'_account_id': 14033}]","[{'number': 1, 'created': '2015-12-18 04:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/812cc9e3c44280c444d38d616ba6e5ad867e0d35', 'message': 'Do not try to save event resource if too big for db column\n\nChange-Id: Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf\n'}, {'number': 2, 'created': '2016-01-06 06:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e825547bed1220f2587904b2d1f4a52d370d19ed', 'message': 'Do not try to save event resource if too big for db column\n\nChange-Id: Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf\n'}, {'number': 3, 'created': '2016-03-02 23:05:47.000000000', 'files': ['heat/tests/test_event.py', 'heat/engine/event.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b48452fc9acd4e4c9f8fd83ca1fc9782635cec36', 'message': 'Do not try to save event resource if too big for db column\n\nChange-Id: Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf\nCloses-Bug: #1552431\n'}]",9,259274,b48452fc9acd4e4c9f8fd83ca1fc9782635cec36,37,11,3,13564,,,0,"Do not try to save event resource if too big for db column

Change-Id: Idedcfb5bf6678cd24990d1503c223ea9a9ac41cf
Closes-Bug: #1552431
",git fetch https://review.opendev.org/openstack/heat refs/changes/74/259274/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_event.py', 'heat/engine/event.py']",2,812cc9e3c44280c444d38d616ba6e5ad867e0d35,bug/1552431,"import picklefrom oslo_log import log as loggingLOG = logging.getLogger(__name__) MAX_EVENT_RESOURCE_PROPERTIES_SIZE = (1 << 16) - 1 # Workaround: we don't want to attempt to store the # event.resource_properties column if the data is too large # (greater than permitted by BLOB). Otherwise, we end up with # an unsightly log message. rp_size = len(pickle.dumps(ev['resource_properties'])) if rp_size > MAX_EVENT_RESOURCE_PROPERTIES_SIZE: LOG.debug('event\'s resource_properties too large to store at ' '%d bytes', rp_size) # Try truncating the largest value and see if that gets us under # the db column's size constraint. max_key, max_val = max(ev['resource_properties'].items(), key=lambda i: len(repr(i[1]))) err = 'Resource properties are too large to attempt to store fully' ev['resource_properties'].update({'Error': err}) ev['resource_properties'][max_key] = '<Deleted, too large>' rp_size = len(pickle.dumps(ev['resource_properties'])) if rp_size > MAX_EVENT_RESOURCE_PROPERTIES_SIZE: LOG.debug('event\'s resource_properties STILL too large ' 'after truncating largest key at %d bytes', rp_size) err = 'Resource properties are too large to attempt to store' ev['resource_properties'] = {'Error': err} # We should have worked around the issue, but let's be extra # careful. # Give up and drop all properties.. ev['resource_properties'] = {'Error': err} new_ev = event_object.Event.create(self.context, ev) "," # Attempt do drop the largest key and re-store as we expect # This to mostly happen with one large config blob property max_key, max_val = max(ev['resource_properties'].items(), key=lambda i: len(repr(i[1]))) ev['resource_properties'].update({'Error': err}) ev['resource_properties'][max_key] = '<Deleted, too large>' try: new_ev = event_object.Event.create(self.context, ev) except oslo_db.exception.DBError: # Give up and drop all properties.. ev['resource_properties'] = {'Error': err} new_ev = event_object.Event.create(self.context, ev)",36,72
openstack%2Fpuppet-neutron~master~I85b6517dd82588eba9f234185dea11066c8c1460,openstack/puppet-neutron,master,I85b6517dd82588eba9f234185dea11066c8c1460,metadata: add nova ssl options,MERGED,2016-03-04 22:27:56.000000000,2016-03-06 05:05:36.000000000,2016-03-06 05:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-04 22:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c9e00c475c98d7a1bdf283a9698c5d1223e1be77', 'message': 'metadata: add nova ssl options\n\nAdd nova_client_cert and nova_client_priv_key - required options when we\nNova Metadata API server with SSL.\n\nChange-Id: I85b6517dd82588eba9f234185dea11066c8c1460\n'}, {'number': 2, 'created': '2016-03-05 03:42:25.000000000', 'files': ['spec/classes/neutron_agents_metadata_spec.rb', 'manifests/agents/metadata.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8101587be5a8c5e758fbcf127d9478ded53ef90b', 'message': 'metadata: add nova ssl options\n\nAdd nova_client_cert and nova_client_priv_key - required options when we\nNova Metadata API server with SSL.\n\nChange-Id: I85b6517dd82588eba9f234185dea11066c8c1460\n'}]",0,288770,8101587be5a8c5e758fbcf127d9478ded53ef90b,13,4,2,3153,,,0,"metadata: add nova ssl options

Add nova_client_cert and nova_client_priv_key - required options when we
Nova Metadata API server with SSL.

Change-Id: I85b6517dd82588eba9f234185dea11066c8c1460
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/70/288770/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_metadata_spec.rb', 'manifests/agents/metadata.pp']",2,c9e00c475c98d7a1bdf283a9698c5d1223e1be77,288770,"# [*nova_client_cert*] # Client certificate for nova metadata api server. (Defaults to $::os_service_default) # # [*nova_client_priv_key*] # Private key of client certificate. (Defaults to $::os_service_default) # $nova_client_cert = $::os_service_default, $nova_client_priv_key = $::os_service_default, 'DEFAULT/nova_client_cert': value => $nova_client_cert; 'DEFAULT/nova_client_priv_key': value => $nova_client_priv_key;",,21,5
openstack%2Fheat~master~Iff0e109a558d0185f126781369bac216da930bca,openstack/heat,master,Iff0e109a558d0185f126781369bac216da930bca,Use oslo.utils.reflection to extract class name,MERGED,2016-02-16 12:10:47.000000000,2016-03-06 05:01:48.000000000,2016-03-06 05:01:47.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 13009}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-16 12:10:47.000000000', 'files': ['heat/tests/api/openstack_v1/test_routes.py', 'heat/api/middleware/fault.py', 'heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/api/aws/exception.py', 'heat_integrationtests/scenario/scenario_base.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'heat/engine/resources/stack_resource.py', 'heat_integrationtests/functional/functional_base.py', 'heat/engine/constraints.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4136b476667845a9e564aaec6da67e10cec79035', 'message': ""Use oslo.utils.reflection to extract class name\n\nThe oslo.utils.reflection.get_class_name() handles more variations\nof where a class name may come from (on) python 2 and python 3.\nIts usage allows getting more accurate class names so we'd better use it.\n\nChange-Id: Iff0e109a558d0185f126781369bac216da930bca\n""}]",0,280639,4136b476667845a9e564aaec6da67e10cec79035,24,4,1,8686,,,0,"Use oslo.utils.reflection to extract class name

The oslo.utils.reflection.get_class_name() handles more variations
of where a class name may come from (on) python 2 and python 3.
Its usage allows getting more accurate class names so we'd better use it.

Change-Id: Iff0e109a558d0185f126781369bac216da930bca
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/280639/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/tests/api/openstack_v1/test_routes.py', 'heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/api/aws/exception.py', 'heat_integrationtests/scenario/scenario_base.py', 'contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'heat/engine/resources/stack_resource.py', 'heat_integrationtests/functional/functional_base.py', 'heat/engine/constraints.py', 'heat/engine/resource.py']",11,4136b476667845a9e564aaec6da67e10cec79035,class_name,"from oslo_utils import reflection class_name = reflection.get_class_name(self, fully_qualified=False) text = '%s ""%s"" [%s] %s' % (class_name, self.name, text = '%s ""%s"" %s' % (class_name, self.name, text = '%s ""%s""' % (class_name, self.name)"," text = '%s ""%s"" [%s] %s' % (self.__class__.__name__, self.name, text = '%s ""%s"" %s' % (self.__class__.__name__, self.name, text = '%s ""%s""' % (self.__class__.__name__, self.name)",38,18
openstack%2Fheat~master~I18df89a2b9959241ddbec2593a53c5e2aa6a4717,openstack/heat,master,I18df89a2b9959241ddbec2593a53c5e2aa6a4717,Optimize nested stack status check,MERGED,2016-02-12 12:27:27.000000000,2016-03-06 05:01:38.000000000,2016-03-06 05:01:34.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 7385}, {'_account_id': 8399}, {'_account_id': 8833}, {'_account_id': 11424}, {'_account_id': 12363}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-12 12:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/70f76b860f81e251aadbab1b56abada4e490f978', 'message': 'WIP: Optimize nested stack status check\n\nChange-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717\n'}, {'number': 2, 'created': '2016-02-12 16:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d8b004182ca0162be77848717c37c4827809dba1', 'message': 'Optimize nested stack status check\n\nCurrently, StackResource loads the whole stack when checking for status\n(in check_*_complete method), but only care about the state of the\nstack. This is a fairly expensive operation, as it retrieves the\ntemplate and reparses everything. This simplifies it with a new API that\nsimply query the stack status from the database.\n\nChange-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717\n'}, {'number': 3, 'created': '2016-02-13 21:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89a68d2522b708025b66122b8b99ee4e23ee0379', 'message': 'Optimize nested stack status check\n\nCurrently, StackResource loads the whole stack when checking for status\n(in check_*_complete method), but only care about the state of the\nstack. This is a fairly expensive operation, as it retrieves the\ntemplate and reparses everything. This simplifies it with a new API that\nsimply query the stack status from the database.\n\nChange-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717\n'}, {'number': 4, 'created': '2016-02-14 11:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/759c13569b6cac04151130091f9df04cc4dd3483', 'message': 'Optimize nested stack status check\n\nCurrently, StackResource loads the whole stack when checking for status\n(in check_*_complete method), but only care about the state of the\nstack. This is a fairly expensive operation, as it retrieves the\ntemplate and reparses everything. This simplifies it with a new API that\nsimply query the stack status from the database.\n\nChange-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717\n'}, {'number': 5, 'created': '2016-02-24 10:04:07.000000000', 'files': ['heat/db/api.py', 'heat/tests/db/test_sqlalchemy_api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/stack_resource.py', 'heat/objects/stack.py', 'heat/tests/test_stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b862908d4cdade7a15863d81900d3be6748e73d4', 'message': 'Optimize nested stack status check\n\nCurrently, StackResource loads the whole stack when checking for status\n(in check_*_complete method), but only care about the state of the\nstack. This is a fairly expensive operation, as it retrieves the\ntemplate and reparses everything. This simplifies it with a new API that\nsimply query the stack status from the database.\n\nCloses-Bug: #1549213\nChange-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717\n'}]",3,279508,b862908d4cdade7a15863d81900d3be6748e73d4,32,11,5,7385,,,0,"Optimize nested stack status check

Currently, StackResource loads the whole stack when checking for status
(in check_*_complete method), but only care about the state of the
stack. This is a fairly expensive operation, as it retrieves the
template and reparses everything. This simplifies it with a new API that
simply query the stack status from the database.

Closes-Bug: #1549213
Change-Id: I18df89a2b9959241ddbec2593a53c5e2aa6a4717
",git fetch https://review.opendev.org/openstack/heat refs/changes/08/279508/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/stack_resource.py', 'heat/objects/stack.py', 'heat/tests/test_stack_resource.py']",5,70f76b860f81e251aadbab1b56abada4e490f978,bug/1549213,"from heat.objects import stack as stack_object self.parent_resource.resource_id).AndReturn('s') self.parent_resource.resource_id).AndRaise( ('create', dict(action='create')), ('update', dict(action='update')), ('suspend', dict(action='suspend')), ('resume', dict(action='resume')), ('delete', dict(action='delete')), self.status = [self.action.upper(), None, None, None] self.mock_status = self.patchobject(stack_object.Stack, 'get_status') self.mock_status.return_value = self.status self.status[1] = 'COMPLETE' self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id) self.status[1] = 'FAILED' self.status[2] = reason self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id) self.status[1] = 'WTF' self.status[2] = 'broken on purpose' self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id) self.status[1] = 'IN_PROGRESS' self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id) self.status[1] = 'COMPLETE' self.status[3] = 'test' self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id) self.status[0] = 'COMPLETE' self.mock_status.assert_called_once_with( self.parent_resource.context, self.parent_resource.resource_id)"," self.parent_resource.resource_id, show_deleted=False, force_reload=False).AndReturn('s') def test_load_nested_force_reload(self): self.parent_resource._nested = 'write-over-me' self.parent_resource.resource_id = 319 self.m.StubOutWithMock(parser.Stack, 'load') parser.Stack.load(self.parent_resource.context, self.parent_resource.resource_id, show_deleted=False, force_reload=True).AndReturn('ok') self.m.ReplayAll() self.parent_resource.nested(force_reload=True) self.assertEqual('ok', self.parent_resource._nested) self.m.VerifyAll() self.parent_resource.resource_id, show_deleted=False, force_reload=False).AndRaise( def test_load_nested_force_reload_ok(self): self.parent_resource._nested = mock.MagicMock() self.parent_resource.resource_id = '90-8' self.m.StubOutWithMock(parser.Stack, 'load') parser.Stack.load(self.parent_resource.context, self.parent_resource.resource_id, show_deleted=False, force_reload=True).AndReturn('s') self.m.ReplayAll() st = self.parent_resource.nested(force_reload=True) self.assertEqual('s', st) self.m.VerifyAll() def test_load_nested_force_reload_none(self): self.parent_resource._nested = mock.MagicMock() self.parent_resource.resource_id = '90-8' self.m.StubOutWithMock(parser.Stack, 'load') parser.Stack.load(self.parent_resource.context, self.parent_resource.resource_id, show_deleted=False, force_reload=True).AndRaise( exception.NotFound) self.m.ReplayAll() self.assertIsNone(self.parent_resource.nested(force_reload=True)) self.m.VerifyAll() ('create', dict(action='create', show_deleted=False)), ('update', dict(action='update', show_deleted=False)), ('suspend', dict(action='suspend', show_deleted=False)), ('resume', dict(action='resume', show_deleted=False)), ('delete', dict(action='delete', show_deleted=True)), self.nested = mock.MagicMock() self.nested.name = 'nested-stack' self.parent_resource.nested = mock.MagicMock(return_value=self.nested) self.parent_resource._nested = self.nested setattr(self.nested, self.action.upper(), self.action.upper()) self.nested.action = self.action.upper() self.nested.COMPLETE = 'COMPLETE' self.nested.status = 'COMPLETE' self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True) self.nested.status = 'FAILED' self.nested.status_reason = reason self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True) self.nested.status = 'WTF' self.nested.status_reason = 'broken on purpose' self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True) self.nested.status = 'IN_PROGRESS' self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True) self.nested.status = 'COMPLETE' self.nested.state = ('UPDATE', 'COMPLETE') self.nested.updated_time = 'test' self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True) self.nested.action = 'COMPLETE' self.parent_resource.nested.assert_called_once_with( show_deleted=self.show_deleted, force_reload=True)",75,106
openstack%2Fneutron~master~I25ea71b1705d6abe5725a061cc19e553ba1b40b5,openstack/neutron,master,I25ea71b1705d6abe5725a061cc19e553ba1b40b5,Remove obsolete todo,MERGED,2016-03-04 22:18:15.000000000,2016-03-06 04:46:22.000000000,2016-03-06 04:46:21.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7715}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-03-04 22:18:15.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/13b03336973b34577fbca42eb6dfb3761d7e66fd', 'message': 'Remove obsolete todo\n\nThis TODO was fixed with Ifff57c0485e4727f352b2cc2bd1bdaabd0f1606b but\nI failed to notice that it needed to be removed.\n\nTrivialFix\n\nChange-Id: I25ea71b1705d6abe5725a061cc19e553ba1b40b5\n'}]",0,288767,13b03336973b34577fbca42eb6dfb3761d7e66fd,23,7,1,7448,,,0,"Remove obsolete todo

This TODO was fixed with Ifff57c0485e4727f352b2cc2bd1bdaabd0f1606b but
I failed to notice that it needed to be removed.

TrivialFix

Change-Id: I25ea71b1705d6abe5725a061cc19e553ba1b40b5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/67/288767/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,13b03336973b34577fbca42eb6dfb3761d7e66fd,trivial-fix,, # TODO(carl_baldwin): allow requests asking for 'default' pools,0,1
openstack%2Fneutron~master~I833e0ef58fb12f8e4c57331706f270fd83341911,openstack/neutron,master,I833e0ef58fb12f8e4c57331706f270fd83341911,Fix some inconsistency in docstrings,MERGED,2016-01-11 06:59:48.000000000,2016-03-06 04:46:03.000000000,2016-03-06 04:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 11159}, {'_account_id': 13667}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}, {'_account_id': 16707}, {'_account_id': 17130}, {'_account_id': 17211}, {'_account_id': 18573}, {'_account_id': 18785}, {'_account_id': 20246}]","[{'number': 1, 'created': '2016-01-11 06:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce15aaacd10fe3034866c472d9dde7d0f221cefe', 'message': 'Fix some inconsistency in docstrings\n\nAccording to http://docs.openstack.org/developer/hacking/#docstrings\n\nChange-Id: I833e0ef58fb12f8e4c57331706f270fd83341911\n'}, {'number': 2, 'created': '2016-01-11 07:16:04.000000000', 'files': ['neutron/api/extensions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd2aad9e0f78048afc4d719db8139cf28d8850e8', 'message': 'Fix some inconsistency in docstrings\n\nAccording to http://docs.openstack.org/developer/hacking/#docstrings\n\nChange-Id: I833e0ef58fb12f8e4c57331706f270fd83341911\n'}]",0,265700,fd2aad9e0f78048afc4d719db8139cf28d8850e8,50,21,2,19226,,,0,"Fix some inconsistency in docstrings

According to http://docs.openstack.org/developer/hacking/#docstrings

Change-Id: I833e0ef58fb12f8e4c57331706f270fd83341911
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/265700/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/extensions.py'],1,ce15aaacd10fe3034866c472d9dde7d0f221cefe,docstring123," try: resources.extend(ext.get_resources()) except AttributeError: # NOTE(dprince): Extension aren't required to have resource # extensions pass try: actions.extend(ext.get_actions()) except AttributeError: # NOTE(dprince): Extension aren't required to have action # extensions pass try: request_exts.extend(ext.get_request_extensions()) except AttributeError: # NOTE(dprince): Extension aren't required to have request # extensions pass :param attr_map: the existing mapping from resource name to update_exts = [] processed_exts = set() if not hasattr(ext, 'get_extended_resources'): del exts_to_process[ext_name] if hasattr(ext, 'update_attributes_map'): update_exts.append(ext) if hasattr(ext, 'get_required_extensions'): # Process extension only if all required extensions # have been processed already required_exts_set = set(ext.get_required_extensions()) if required_exts_set - processed_exts: continue try: extended_attrs = ext.get_extended_resources(version) for res, resource_attrs in six.iteritems(extended_attrs): attr_map.setdefault(res, {}).update(resource_attrs) except AttributeError: LOG.exception(_LE(""Error fetching extended attributes for "" ""extension '%s'""), ext.get_name()) processed_exts.add(ext_name) for ext in update_exts: return True if(not hasattr(extension, ""get_plugin_interface"") or extension.get_plugin_interface() is None):"," def get_required_extensions(self): """"""Returns a list of extensions to be processed before this one."""""" return [] resources.extend(ext.get_resources()) actions.extend(ext.get_actions()) request_exts.extend(ext.get_request_extensions()) :param: attr_map, the existing mapping from resource name to processed_exts = {} # Process extension only if all required extensions # have been processed already required_exts_set = set(ext.get_required_extensions()) if required_exts_set - set(processed_exts): extended_attrs = ext.get_extended_resources(version) for res, resource_attrs in six.iteritems(extended_attrs): attr_map.setdefault(res, {}).update(resource_attrs) processed_exts[ext_name] = ext for ext in processed_exts.values(): return isinstance(extension, ExtensionDescriptor) if extension.get_plugin_interface() is None:",43,20
openstack%2Fheat~master~If7c7360548a8d5a38cea722d198289597801789a,openstack/heat,master,If7c7360548a8d5a38cea722d198289597801789a,[DNM] Test for ceilometer issue,ABANDONED,2016-03-01 05:18:20.000000000,2016-03-06 04:30:42.000000000,,"[{'_account_id': 3}, {'_account_id': 8833}]","[{'number': 1, 'created': '2016-03-01 05:18:20.000000000', 'files': ['heat_integrationtests/scenario/test_ceilometer_alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6a31947a6d942ebe136577e91d4a275c31e13baa', 'message': '[DNM] Test for ceilometer issue\n\nChange-Id: If7c7360548a8d5a38cea722d198289597801789a\nDepends-On: I28980ff4cd82950bc713da519e0e49b62fc77a22\n'}]",0,286386,6a31947a6d942ebe136577e91d4a275c31e13baa,7,2,1,8833,,,0,"[DNM] Test for ceilometer issue

Change-Id: If7c7360548a8d5a38cea722d198289597801789a
Depends-On: I28980ff4cd82950bc713da519e0e49b62fc77a22
",git fetch https://review.opendev.org/openstack/heat refs/changes/86/286386/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/scenario/test_ceilometer_alarm.py'],1,6a31947a6d942ebe136577e91d4a275c31e13baa,, # checking for ceilometer issue,,2,0
openstack%2Fopenstack-ansible~master~I1e7a38f034cd5d6c6f6d956ba3be248784c987f0,openstack/openstack-ansible,master,I1e7a38f034cd5d6c6f6d956ba3be248784c987f0,Ensure apt-cache is updated in containers.,ABANDONED,2016-03-06 04:09:17.000000000,2016-03-06 04:26:39.000000000,,"[{'_account_id': 3}, {'_account_id': 4268}]","[{'number': 1, 'created': '2016-03-06 04:09:17.000000000', 'files': ['scripts/run-playbooks.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a69eef849a8d5b6bfaffb53cc2afa848cb47b8fa', 'message': 'Ensure apt-cache is updated in containers.\n\nChange-Id: I1e7a38f034cd5d6c6f6d956ba3be248784c987f0\n'}]",0,288970,a69eef849a8d5b6bfaffb53cc2afa848cb47b8fa,4,2,1,4268,,,0,"Ensure apt-cache is updated in containers.

Change-Id: I1e7a38f034cd5d6c6f6d956ba3be248784c987f0
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/70/288970/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/run-playbooks.sh'],1,a69eef849a8d5b6bfaffb53cc2afa848cb47b8fa,apt-get-update," # Ensure apt-cache is updated in containers ansible all_containers -m apt -a ""update_cache=yes"" ",,3,0
openstack%2Frelease-tools~master~Id5e6452c9fbc37586b2f217a348b9464329fec63,openstack/release-tools,master,Id5e6452c9fbc37586b2f217a348b9464329fec63,Remove other-requirements.txt,MERGED,2016-03-05 15:45:30.000000000,2016-03-06 04:11:38.000000000,2016-03-06 04:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-05 15:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/5c15503a69aa0a454e41e02636e05b5d1e540bf5', 'message': 'Fix other-requirements\n\nAdd missing packages so that tests pass.\n\nWith the switch from bare-trusty to ubuntu-trusty, the\nother-requirements.txt file is now used - and we setup database by\ndefault and thus need these in here.\n\nChange-Id: Id5e6452c9fbc37586b2f217a348b9464329fec63\n'}, {'number': 2, 'created': '2016-03-05 18:11:02.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/619912575dc4d8c0d5d99a236152c66d5afbe3ea', 'message': 'Remove other-requirements.txt\n\nThis file will only work on Ubuntu, it\nneeds further work to be used everywhere. Also, our CI systems are not\nready yet for full usage. Remove the file, it can be readded later once\neverything is prepared for it.\n\nChange-Id: Id5e6452c9fbc37586b2f217a348b9464329fec63\n'}]",0,288905,619912575dc4d8c0d5d99a236152c66d5afbe3ea,8,2,2,6547,,,0,"Remove other-requirements.txt

This file will only work on Ubuntu, it
needs further work to be used everywhere. Also, our CI systems are not
ready yet for full usage. Remove the file, it can be readded later once
everything is prepared for it.

Change-Id: Id5e6452c9fbc37586b2f217a348b9464329fec63
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/05/288905/2 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,5c15503a69aa0a454e41e02636e05b5d1e540bf5,bindep, # Needed with current setup of gate jobs libmysqlclient-dev mysql-client mysql-server postgresql postgresql-client,,7,0
openstack%2Foctavia~master~I342089b5e8a09e7e10fec6e935ecc1f515063d9d,openstack/octavia,master,I342089b5e8a09e7e10fec6e935ecc1f515063d9d,Updated from global requirements,MERGED,2016-03-05 15:36:03.000000000,2016-03-06 03:51:33.000000000,2016-03-06 03:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 16272}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-03-05 15:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e2664017559924f7a574b0d97e61da4513824db3', 'message': 'Updated from global requirements\n\nChange-Id: I342089b5e8a09e7e10fec6e935ecc1f515063d9d\n'}, {'number': 2, 'created': '2016-03-05 20:48:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/8cc63650fc6b5dc55b43fb4ac901d76c01c1b5d1', 'message': 'Updated from global requirements\n\nChange-Id: I342089b5e8a09e7e10fec6e935ecc1f515063d9d\n'}]",0,288897,8cc63650fc6b5dc55b43fb4ac901d76c01c1b5d1,18,5,2,11131,,,0,"Updated from global requirements

Change-Id: I342089b5e8a09e7e10fec6e935ecc1f515063d9d
",git fetch https://review.opendev.org/openstack/octavia refs/changes/97/288897/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e2664017559924f7a574b0d97e61da4513824db3,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Foctavia~master~Ie3accb5c1be455f0212fbc07d4f5c26a55529b3c,openstack/octavia,master,Ie3accb5c1be455f0212fbc07d4f5c26a55529b3c,Remove swift related content in the sample local.conf,MERGED,2016-03-04 07:52:27.000000000,2016-03-06 03:36:13.000000000,2016-03-06 03:32:18.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-04 07:52:27.000000000', 'files': ['devstack/samples/local.conf'], 'web_link': 'https://opendev.org/openstack/octavia/commit/5844f9494bbabf75cf1a4eccf35b3ee12e480e59', 'message': 'Remove swift related content in the sample local.conf\n\nSwift is not default enabled by devsatck, and it is not used\nby Octavia by default too. The content in the sample local.conf\nis useless.\n\nChange-Id: Ie3accb5c1be455f0212fbc07d4f5c26a55529b3c\n'}]",0,288287,5844f9494bbabf75cf1a4eccf35b3ee12e480e59,20,7,1,6116,,,0,"Remove swift related content in the sample local.conf

Swift is not default enabled by devsatck, and it is not used
by Octavia by default too. The content in the sample local.conf
is useless.

Change-Id: Ie3accb5c1be455f0212fbc07d4f5c26a55529b3c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/87/288287/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/samples/local.conf'],1,5844f9494bbabf75cf1a4eccf35b3ee12e480e59,remove_swift,," # Swift # ----- # Swift is now used as the back-end for the S3-like object store. If Nova's # objectstore (``n-obj`` in ``ENABLED_SERVICES``) is enabled, it will NOT # run if Swift is enabled. Setting the hash value is required and you will # be prompted for it if Swift is enabled so just set it to something already: SWIFT_HASH=66a3d6b56c1f479c8b4e70ab5c2000f5 # For development purposes the default of 3 replicas is usually not required. # Set this to 1 to save some resources: SWIFT_REPLICAS=1 # The data for Swift is stored by default in (``$DEST/data/swift``), # or (``$DATA_DIR/swift``) if ``DATA_DIR`` has been set, and can be # moved by setting ``SWIFT_DATA_DIR``. The directory will be created # if it does not exist. SWIFT_DATA_DIR=$DEST/data",0,19
openstack%2Fneutron~master~I6f7b68ec993849077f859f2e86609022cbc0bcc1,openstack/neutron,master,I6f7b68ec993849077f859f2e86609022cbc0bcc1,Mock out database access for QoS policy object interface tests,MERGED,2016-03-04 16:16:17.000000000,2016-03-06 03:21:25.000000000,2016-03-06 03:21:25.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 13995}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-03-04 16:16:17.000000000', 'files': ['neutron/tests/unit/objects/qos/test_policy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/305980a41e1475074d2d1fa286dae2994a1b8b06', 'message': 'Mock out database access for QoS policy object interface tests\n\nWhen we merged RBAC support for QoS policies, we missed mocking out\ndatabase access triggered by RBAC metaclass hooks in this test. It made\nthe test failing if executed on its own, since in that case no database\nwas created in memory for those access attempts to succeed.\n\nNow, mock out all fetches consistently for all object interface test\ncases.\n\nChange-Id: I6f7b68ec993849077f859f2e86609022cbc0bcc1\nCloses-Bug: #1553254\n'}]",0,288561,305980a41e1475074d2d1fa286dae2994a1b8b06,14,7,1,9656,,,0,"Mock out database access for QoS policy object interface tests

When we merged RBAC support for QoS policies, we missed mocking out
database access triggered by RBAC metaclass hooks in this test. It made
the test failing if executed on its own, since in that case no database
was created in memory for those access attempts to succeed.

Now, mock out all fetches consistently for all object interface test
cases.

Change-Id: I6f7b68ec993849077f859f2e86609022cbc0bcc1
Closes-Bug: #1553254
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/288561/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/objects/qos/test_policy.py'],1,305980a41e1475074d2d1fa286dae2994a1b8b06,bug/1553254," self._test_class.rbac_db_model: [], self._test_class.port_binding_model: [], self._test_class.network_binding_model: [], self.get_object = mock.patch.object( db_api, 'get_object', side_effect=self.fake_get_object).start() self.get_objects = mock.patch.object( db_api, 'get_objects', side_effect=self.fake_get_objects).start() def fake_get_object(self, context, model, **kwargs): if not objects: return None return [obj for obj in objects if obj['id'] == kwargs['id']][0] with mock.patch.object(self.context, 'elevated', return_value=admin_context) as context_mock: objs = self._test_class.get_objects(self.context) context_mock.assert_called_once_with() self.get_objects.assert_any_call( admin_context, self._test_class.db_model)"," def fake_get_object(self, context, model, id): return [obj for obj in objects if obj['id'] == id][0] with mock.patch.object( db_api, 'get_objects', side_effect=self.fake_get_objects) as get_objects_mock: with mock.patch.object( db_api, 'get_object', side_effect=self.fake_get_object): with mock.patch.object( self.context, 'elevated', return_value=admin_context) as context_mock: objs = self._test_class.get_objects(self.context) context_mock.assert_called_once_with() get_objects_mock.assert_any_call( admin_context, self._test_class.db_model)",18,19
openstack%2Fapi-site~master~I57e8dcc25f8d0637d7764f5b932d914f3e905548,openstack/api-site,master,I57e8dcc25f8d0637d7764f5b932d914f3e905548,Cleanup fixing a type 'csapi:UUID',MERGED,2016-02-15 02:13:58.000000000,2016-03-06 03:16:11.000000000,2016-03-06 03:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 10497}, {'_account_id': 10897}, {'_account_id': 13702}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-15 02:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/3b522abeeb6ca28921d8b716cd02a72927d70b47', 'message': ""Cleanup fixing a type 'csapi:UUID'\n\nThis commit fixes the type of following 'xxxx_id' and explanation:\n\n  * tenant_id\n  * stack_id\n  * snapshot_id\n  * event_id\n  * config_id\n  * server_id\n  * deployment_id\n\nChange-Id: I57e8dcc25f8d0637d7764f5b932d914f3e905548\nCloses-Bug: 1545397\n""}, {'number': 2, 'created': '2016-02-15 04:14:24.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/496a76054daa876d712edd081379ccab11111bee', 'message': ""Cleanup fixing a type 'csapi:UUID'\n\nThis commit fixes the type of following 'xxxx_id' and explanation:\n\n  * tenant_id\n  * stack_id\n  * snapshot_id\n  * event_id\n  * config_id\n  * server_id\n  * deployment_id\n\nChange-Id: I57e8dcc25f8d0637d7764f5b932d914f3e905548\nCloses-Bug: 1545397\n""}]",8,280037,496a76054daa876d712edd081379ccab11111bee,17,7,2,13702,,,0,"Cleanup fixing a type 'csapi:UUID'

This commit fixes the type of following 'xxxx_id' and explanation:

  * tenant_id
  * stack_id
  * snapshot_id
  * event_id
  * config_id
  * server_id
  * deployment_id

Change-Id: I57e8dcc25f8d0637d7764f5b932d914f3e905548
Closes-Bug: 1545397
",git fetch https://review.opendev.org/openstack/api-site refs/changes/37/280037/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,3b522abeeb6ca28921d8b716cd02a72927d70b47,bug/1545397," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tenant_id"" required=""true"" style=""template"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the tenant. A tenant is also known as an account or project. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""stack_id"" style=""template"" type=""csapi:UUID"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the <code>stack</code>. </para> </wadl:doc> <method href=""#stack_update_preview""/> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""snapshot_id"" style=""template"" type=""csapi:UUID"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the <code>snapshot</code>. </para> </wadl:doc> <para> The UUID of the <code>snapshot</code>. <resource path=""{event_id}"" id=""event_id""> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""event_id"" style=""template"" type=""csapi:UUID"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the <code>event</code> that is related to the resource in the stack. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""config_id"" style=""template"" type=""csapi:UUID"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the configuration. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""deployment_id"" style=""template"" type=""csapi:UUID"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the deployment. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""server_id"" style=""template"" type=""csapi:UUID"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the server for which to fetch configuration metadata. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""stack_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the system-assigned <code>stack</code>. </para> </wadl:doc> name=""config_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> The UUID of the software configuration resource that runs when applying to the server. </para> </wadl:doc> name=""server_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the compute server to which the configuration applies. </para> </wadl:doc> name=""config_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the software configuration resource to run when applying to the server. This UUID might not be the same configuration UUID with which the deployment was created because ephemeral configurations are created throughout the life cycle of the deployment. </para> </wadl:doc>"," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tenant_id"" style=""template""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The ID of the tenant. A tenant is also known as an account or project. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""stack_id"" style=""template"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The stack ID. </para> </wadl:doc> <method href=""#stack_update_preview""/> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""snapshot_id"" style=""template"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The snapshot ID. </para> </wadl:doc> <para>The snapshot ID. <resource path=""{event_id}"" id=""event_id""> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""event_id"" style=""template"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The ID of an event that is related to the resource in the stack. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""config_id"" style=""template"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The configuration ID. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""deployment_id"" style=""template"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The deployment ID. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""server_id"" style=""template"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The ID of the server for which to fetch configuration metadata. </para> </wadl:doc> <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""stack_id"" style=""plain"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The system-assigned ID for the stack. </para> </wadl:doc> name=""config_id"" style=""plain"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> The ID of the software configuration resource that runs when applying to the server. </para> </wadl:doc> name=""server_id"" style=""plain"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The ID of the compute server to which the configuration applies. </para> </wadl:doc> name=""config_id"" style=""plain"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> ID of the software configuration resource to run when applying to the server. This ID might not be the same configuration ID with which the deployment was created because ephemeral configurations are created throughout the life cycle of the deployment. </para> </wadl:doc>",113,100
openstack%2Fmagnum~master~I306eed493f6b6d21d74399b1a3d4e48c25bd0da2,openstack/magnum,master,I306eed493f6b6d21d74399b1a3d4e48c25bd0da2,Add external_network unit test for post baymodel,MERGED,2016-03-01 07:29:39.000000000,2016-03-06 02:50:25.000000000,2016-03-06 02:50:25.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 10263}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 18386}]","[{'number': 1, 'created': '2016-03-01 07:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/77f1423224b4067d183b44af36eacae705595ab5', 'message': 'Add external_network unit test for post baymodel\n\nChange-Id: I306eed493f6b6d21d74399b1a3d4e48c25bd0da2\n'}, {'number': 2, 'created': '2016-03-03 02:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/59eb12af4677dd1b8e947b38597980443a927122', 'message': 'Add external_network unit test for post baymodel\n\nChange-Id: I306eed493f6b6d21d74399b1a3d4e48c25bd0da2\n'}, {'number': 3, 'created': '2016-03-03 10:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fe7f5de99b0df740140d4a7ca58bb26b2303dc2a', 'message': 'Add external_network unit test for post baymodel\n\nChange-Id: I306eed493f6b6d21d74399b1a3d4e48c25bd0da2\n'}, {'number': 4, 'created': '2016-03-04 02:46:52.000000000', 'files': ['magnum/tests/unit/api/controllers/v1/test_baymodel.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a55c965ceb1d676229d8aa8579a54bedb7468bf6', 'message': 'Add external_network unit test for post baymodel\n\nChange-Id: I306eed493f6b6d21d74399b1a3d4e48c25bd0da2\n'}]",6,286419,a55c965ceb1d676229d8aa8579a54bedb7468bf6,33,8,4,18386,,,0,"Add external_network unit test for post baymodel

Change-Id: I306eed493f6b6d21d74399b1a3d4e48c25bd0da2
",git fetch https://review.opendev.org/openstack/magnum refs/changes/19/286419/4 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/unit/api/controllers/v1/test_baymodel.py'],1,77f1423224b4067d183b44af36eacae705595ab5,add_external_network_unit_test," @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_os_resources') def test_create_baymodel_with_external_network(self, mock_valid_os_res, mock_image_data): mock_valid_os_res.return_value = None mock_image_data.return_value = {'name': 'mock_name', 'os_distro': 'fedora-atomic'} bdict = apiutils.baymodel_post_data() response = self.post_json('/baymodels', bdict) self.assertEqual(201, response.status_int) self.assertEqual(bdict['external_network_id'], response.json['external_network_id']) @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_os_resources') def test_create_baymodel_with_no_exist_external_network(self, mock_valid_os_res, mock_image_data): mock_valid_os_res.side_effect = exception.NetworkNotFound(""test"") mock_image_data.return_value = {'name': 'mock_name', 'os_distro': 'fedora-atomic'} bdict = apiutils.baymodel_post_data() response = self.post_json('/baymodels', bdict, expect_errors=True) self.assertEqual(400, response.status_int) ",,26,0
openstack%2Fmagnum~master~Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f,openstack/magnum,master,Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f,Add Flannel troubleshooting,MERGED,2016-02-22 20:45:39.000000000,2016-03-06 02:50:19.000000000,2016-03-06 02:50:19.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7494}, {'_account_id': 9591}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}]","[{'number': 1, 'created': '2016-02-22 20:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/13510bf02e7a135d8656cc8aa87d3fa2e817f403', 'message': 'Add Flannel troubleshooting\n\nAdd section on Flannel to troubleshooting guide.\n\nFlannel provides the overlay network and is the default\nnetwork driver for Kubernetes COE.  It is also an optional\nnetwork driver for Swarm COE.  Failure in Flannel would\nmean that the containers cannot communicate with each other.\n\nThis section covers common failures, how to verify configuration,\nhow to check for correct operation, logs, known limitations.\n\nPartially implements:  blueprint magnum-troubleshooting-guide\nChange-Id: Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f\n'}, {'number': 2, 'created': '2016-02-23 06:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3278c2d576213e562efa937181213a0adaac1077', 'message': 'Add Flannel troubleshooting\n\nAdd section on Flannel to troubleshooting guide.\n\nFlannel provides the overlay network and is the default\nnetwork driver for Kubernetes COE.  It is also an optional\nnetwork driver for Swarm COE.  Failure in Flannel would\nmean that the containers cannot communicate with each other.\n\nThis section covers common failures, how to verify configuration,\nhow to check for correct operation, logs, known limitations.\n\nIf you have encountered other scenarios or have additional tips,\nplease comment or add your own patch.\n\nPartially implements:  blueprint magnum-troubleshooting-guide\nChange-Id: Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f\n'}, {'number': 3, 'created': '2016-02-26 00:07:47.000000000', 'files': ['doc/source/troubleshooting-guide.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/30a9d409995c823f7e6816f4d5b743947473f81f', 'message': 'Add Flannel troubleshooting\n\nAdd section on Flannel to troubleshooting guide.\n\nFlannel provides the overlay network and is the default\nnetwork driver for Kubernetes COE.  It is also an optional\nnetwork driver for Swarm COE.  Failure in Flannel would\nmean that the containers cannot communicate with each other.\n\nThis section covers common failures, how to verify configuration,\nhow to check for correct operation, logs, known limitations.\n\nIf you have encountered other scenarios or have additional tips,\nplease comment or add your own patch.\n\nPartially implements:  blueprint magnum-troubleshooting-guide\nChange-Id: Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f\n'}]",30,283250,30a9d409995c823f7e6816f4d5b743947473f81f,28,7,3,9591,,,0,"Add Flannel troubleshooting

Add section on Flannel to troubleshooting guide.

Flannel provides the overlay network and is the default
network driver for Kubernetes COE.  It is also an optional
network driver for Swarm COE.  Failure in Flannel would
mean that the containers cannot communicate with each other.

This section covers common failures, how to verify configuration,
how to check for correct operation, logs, known limitations.

If you have encountered other scenarios or have additional tips,
please comment or add your own patch.

Partially implements:  blueprint magnum-troubleshooting-guide
Change-Id: Icfc61d532a3381f3b70d36d8e765f0b6548e0c3f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/50/283250/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/troubleshooting-guide.rst'],1,13510bf02e7a135d8656cc8aa87d3fa2e817f403,bp/magnum-troubleshooting-guide," When deploying a COE, Flannel is available as a network driver for certain COE type. Magnum currently supports Flannel for a Kubernetes or Swarm bay. Flannel provides a flat network space for the containers in the bay: they are allocated IP in this network space and they will have connectivity to each other. Therefore, if Flannel fails, some containers will not be able to access services from other containers in the bay. This can be confirmed by running *ping* or *curl* from one container to another. The Flannel daemon is run as a systemd service on each node of the bay. To check Flannel, run on each node:: service flanneld status If the daemon is running, you should see that the service is successfully deployed:: Active: active (running) since .... If the daemon is not running, the status will show the service as failed, something like:: Active: failed (Result: timeout) .... Flannel daemon may also be running but not functioning correctly. Check the following: - Since Flannel relies on etcd, a common cause for failure is that the etcd service is not running on the master nodes. Check the `etcd service`_. If the etcd service failed, once it has been restored successfully, the Flannel service can be restarted by:: sudo service flannel restart - Magnum writes the configuration for Flannel in a local file on each node. Check for this file by:: cat /etc/sysconfig/flannel-network.json The content should be something like:: { ""Network"": ""10.100.0.0/16"", ""Subnetlen"": 24, ""Backend"": { ""Type"": ""udp"" } } where the values for the parameters must match the corresponding parameters from the bay model. - Each node is allocated a segment of the network space. Check for this segment on each node by:: grep FLANNEL_SUBNET /run/flannel/subnet.env The containers on this node should be assigned an IP in this range. The nodes negotiate for this segment through etcd, and the record in etcd can be verified by:: curl http://<master_node_ip>:2379/v2/keys/coreos.com/network/subnets You should receive a json snippet that describes all the segments allocated:: {""action"":""get"", ""node"":{ ""key"":""/coreos.com/network/subnets"", ""dir"":true, ""nodes"":[ {""key"":""/coreos.com/network/subnets/10.100.34.0-24"", ""value"":""{\""PublicIP\"":\""10.0.0.5\""}"", ""expiration"":""2016-02-17T18:29:24.966300612Z"", ""ttl"":45114, ""modifiedIndex"":776568, ""createdIndex"":776568}, {""key"":""/coreos.com/network/subnets/10.100.49.0-24"", ""value"":""{\""PublicIP\"":\""10.0.0.7\""}"", ""expiration"":""2016-02-17T18:31:37.111257747Z"", ""ttl"":45246, ""modifiedIndex"":776614, ""createdIndex"":776614}, {""key"":""/coreos.com/network/subnets/10.100.54.0-24"", ""value"":""{\""PublicIP\"":\""10.0.0.6\""}"", ""expiration"":""2016-02-17T23:32:25.908317829Z"", ""ttl"":63295,""modifiedIndex"":782329, ""createdIndex"":782329}], ""modifiedIndex"":4, ""createdIndex"":4} } - This network segment is passed to Docker via the parameter *--bip*. If this not configured correctly, Docker would not assign the correct IP in the Flannel network segment to the container. Check by:: cat /run/flannel/docker ps -aux | grep docker - Check the interface for Flannel:: ifconfig flannel0 The IP should be the first address in the Flannel subnet for this node. - Flannel has several different backend implementations and they have specific requirements. The *udp* backend is the most general and have no requirement on the network. The *vxlan* backend requires vxlan support in the kernel, so ensure that the image used does provide vxlan support. The *host-gw* backend requires that all the hosts are on the same L2 network. This is currently met by the private Neutron subnet created by Magnum; however, if other network topology is used instead, ensure that this requirement is met if *host-gw* is used. - Check the log for Flannel:: sudo journalctl -u flanneld Current known limitation: the image fedora-21-atomic-5.qcow2 has Flannel version 0.5.0. This version has known bugs that prevent the backend vxland and host-gw to work correctly. Only the backend udp works for this image. Version 0.5.3 and later should work correctly.",*To be filled in* ,123,1
openstack%2Fmagnum~master~I2bf093499b786dd368cda78bad3d3ea660b5f574,openstack/magnum,master,I2bf093499b786dd368cda78bad3d3ea660b5f574,Updated from global requirements,MERGED,2016-03-03 18:01:56.000000000,2016-03-06 02:50:13.000000000,2016-03-06 02:50:12.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 16272}, {'_account_id': 18386}]","[{'number': 1, 'created': '2016-03-03 18:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/01f797f900b2ae923316bc5b459cdee3e2277706', 'message': 'Updated from global requirements\n\nChange-Id: I2bf093499b786dd368cda78bad3d3ea660b5f574\n'}, {'number': 2, 'created': '2016-03-04 10:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3bda44c5d33574776c3073c73f2ce2af36dd01a7', 'message': 'Updated from global requirements\n\nChange-Id: I2bf093499b786dd368cda78bad3d3ea660b5f574\n'}, {'number': 3, 'created': '2016-03-05 15:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4c15cc242711fb8d0f854f170566cb4c5fd0b896', 'message': 'Updated from global requirements\n\nChange-Id: I2bf093499b786dd368cda78bad3d3ea660b5f574\n'}, {'number': 4, 'created': '2016-03-05 20:45:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/76468f1eea32ece35bb99735a3e07ab3dd2edee3', 'message': 'Updated from global requirements\n\nChange-Id: I2bf093499b786dd368cda78bad3d3ea660b5f574\n'}]",0,288020,76468f1eea32ece35bb99735a3e07ab3dd2edee3,24,6,4,11131,,,0,"Updated from global requirements

Change-Id: I2bf093499b786dd368cda78bad3d3ea660b5f574
",git fetch https://review.opendev.org/openstack/magnum refs/changes/20/288020/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,01f797f900b2ae923316bc5b459cdee3e2277706,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Faodh~master~Ib99f2e4c1f04666bc963bceeb60c9f8281284f13,openstack/aodh,master,Ib99f2e4c1f04666bc963bceeb60c9f8281284f13,A little typo of doc,MERGED,2016-03-06 01:02:35.000000000,2016-03-06 02:32:22.000000000,2016-03-06 02:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-03-06 01:02:35.000000000', 'files': ['aodh/api/controllers/v2/alarm_rules/combination.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/9c44733e8d2049a74abb9745e244c1d182f9780a', 'message': 'A little typo of doc\n\nChange the ""Combinarion"" to ""Combination"".\n\nChange-Id: Ib99f2e4c1f04666bc963bceeb60c9f8281284f13\n'}]",0,288952,9c44733e8d2049a74abb9745e244c1d182f9780a,6,2,1,16701,,,0,"A little typo of doc

Change the ""Combinarion"" to ""Combination"".

Change-Id: Ib99f2e4c1f04666bc963bceeb60c9f8281284f13
",git fetch https://review.opendev.org/openstack/aodh refs/changes/52/288952/1 && git format-patch -1 --stdout FETCH_HEAD,['aodh/api/controllers/v2/alarm_rules/combination.py'],1,9c44733e8d2049a74abb9745e244c1d182f9780a,typo," """"""Alarm Combination Rule"," """"""Alarm Combinarion Rule",1,1
openstack%2Fproject-config~master~Ib41bdb1e8d8b606a1ce0c2d9626a3b7b36c6bc6a,openstack/project-config,master,Ib41bdb1e8d8b606a1ce0c2d9626a3b7b36c6bc6a,Fix copy pasta typos in OSIC grafana graphs,MERGED,2016-03-06 01:46:31.000000000,2016-03-06 02:02:33.000000000,2016-03-06 02:02:33.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2016-03-06 01:46:31.000000000', 'files': ['grafana/nodepool-osic.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/feb11530b50c762aa7435cde690a4c95bbda4284', 'message': 'Fix copy pasta typos in OSIC grafana graphs\n\nThe OSIC grafyaml file was copied from vexxhost and the region name\ncarried over inappropriately. Fix that and refer to OSIC Cloud 1\ninstead.\n\nChange-Id: Ib41bdb1e8d8b606a1ce0c2d9626a3b7b36c6bc6a\n'}]",0,288956,feb11530b50c762aa7435cde690a4c95bbda4284,7,3,1,4146,,,0,"Fix copy pasta typos in OSIC grafana graphs

The OSIC grafyaml file was copied from vexxhost and the region name
carried over inappropriately. Fix that and refer to OSIC Cloud 1
instead.

Change-Id: Ib41bdb1e8d8b606a1ce0c2d9626a3b7b36c6bc6a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/288956/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/nodepool-osic.yaml'],1,feb11530b50c762aa7435cde690a4c95bbda4284,refine-osic-graphs," - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.CreateServerTask.mean, '0.001'), 'Cloud 1') - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.DeleteServerTask.mean, '0.001'), 'Cloud 1') - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.ListServersTask.mean, '0.001'), 'Cloud 1') - target: alias(smartSummarize(stats_counts.nodepool.launch.provider.osic-cloud1.ready, '1m'), 'Cloud 1') - target: alias(smartSummarize(sumSeries(stats_counts.nodepool.launch.provider.osic-cloud1.error.*), '1m'), 'Cloud 1') - target: alias(scale(stats.timers.nodepool.launch.provider.osic-cloud1.ready.mean, '0.001'), 'Cloud 1') - title: Test Nodes (Cloud 1) - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'Cloud 1') - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-neutron-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'Cloud 1')"," - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.CreateServerTask.mean, '0.001'), 'YMQ') - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.DeleteServerTask.mean, '0.001'), 'YMQ') - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.ListServersTask.mean, '0.001'), 'YMQ') - target: alias(smartSummarize(stats_counts.nodepool.launch.provider.osic-cloud1.ready, '1m'), 'YMQ') - target: alias(smartSummarize(sumSeries(stats_counts.nodepool.launch.provider.osic-cloud1.error.*), '1m'), 'YMQ') - target: alias(scale(stats.timers.nodepool.launch.provider.osic-cloud1.ready.mean, '0.001'), 'YMQ') - title: Test Nodes (YMQ) - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'YMQ') - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-neutron-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'YMQ')",9,9
openstack%2Fcinder~master~Id08c1b1f1e75188cacfb9b5586519a7fee827602,openstack/cinder,master,Id08c1b1f1e75188cacfb9b5586519a7fee827602,Fix HTTP sessions left open in Brocade zone driver,MERGED,2016-02-24 19:21:20.000000000,2016-03-06 00:57:07.000000000,2016-03-02 00:11:27.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14802}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16898}, {'_account_id': 17405}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-02-24 19:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/437035430f67c09dd78f11f4ef21542bc1da469f', 'message': 'Fix for HTTP sessions left open in Brocade zone driver HTTP connector\n\nAdd missing call to logout html page on FC switch to close the HTTP\nsession on the FC switch in HTTP connector.  Also, move the session\ncleanup calls in the zone driver so that it is invoked for all code\npaths.\n\nChange-Id: Id08c1b1f1e75188cacfb9b5586519a7fee827602\n'}, {'number': 2, 'created': '2016-02-29 19:10:50.000000000', 'files': ['cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c96825f6df16d3ad5bd0bf72e6ed589ac25552e', 'message': 'Fix HTTP sessions left open in Brocade zone driver\n\nAdd missing call to logout html page on FC switch to close the HTTP\nsession on the FC switch in HTTP connector.  Also, move the session\ncleanup calls in the zone driver so that it is invoked for all code\npaths.\n\nChange-Id: Id08c1b1f1e75188cacfb9b5586519a7fee827602\n'}]",1,284362,5c96825f6df16d3ad5bd0bf72e6ed589ac25552e,69,34,2,8757,,,0,"Fix HTTP sessions left open in Brocade zone driver

Add missing call to logout html page on FC switch to close the HTTP
session on the FC switch in HTTP connector.  Also, move the session
cleanup calls in the zone driver so that it is invoked for all code
paths.

Change-Id: Id08c1b1f1e75188cacfb9b5586519a7fee827602
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/284362/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py']",3,437035430f67c09dd78f11f4ef21542bc1da469f,bug/1549435," def _disconnect(self): """"""Disconnect from the switch using HTTP/HTTPS protocol. :raises: BrocadeZoningHttpException """""" try: headers = {zone_constant.AUTH_HEADER: self.auth_header} response = self.connect(zone_constant.GET_METHOD, zone_constant.LOGOUT_PAGE, header=headers) return response except requests.exceptions.ConnectionError as e: msg = (_(""Error while connecting the switch %(switch_id)s "" ""with protocol %(protocol)s. Error: %(error)s."") % {'switch_id': self.switch_ip, 'protocol': self.protocol, 'error': six.text_type(e)}) LOG.error(msg) raise exception.BrocadeZoningHttpException(reason=msg) except exception.BrocadeZoningHttpException as ex: msg = (_(""Unexpected status code from the switch %(switch_id)s "" ""with protocol %(protocol)s for url %(page)s. "" ""Error: %(error)s"") % {'switch_id': self.switch_ip, 'protocol': self.protocol, 'page': zone_constant.LOG_OUT_PAGE, 'error': six.text_type(ex)}) LOG.error(msg) raise exception.BrocadeZoningHttpException(reason=msg) self._disconnect()",,39,5
openstack%2Fcinder~master~Ia81da8b0208bb2a30ab301519cfc714f26480edd,openstack/cinder,master,Ia81da8b0208bb2a30ab301519cfc714f26480edd,Use is_int_like method from oslo_utils,MERGED,2016-02-29 10:45:01.000000000,2016-03-05 23:58:31.000000000,2016-03-02 00:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 10485}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14305}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-02-29 10:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80d9bb4efdf403dea4ec41b2652690153a536c56', 'message': 'Use is_int_like method from oslo_utils\n\nThis patch removes is_int_like method from\nutils.py and replaces it with is_int_like\nmethod from oslo_utils.strutils to eliminate\nduplicate code.\n\nTrivialFix\n\nChange-Id: Ia81da8b0208bb2a30ab301519cfc714f26480edd\n'}, {'number': 2, 'created': '2016-03-01 05:04:37.000000000', 'files': ['cinder/tests/unit/test_utils.py', 'cinder/utils.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/807c31dbce5bd4706df9e25f074ca4d099908039', 'message': 'Use is_int_like method from oslo_utils\n\nThis patch removes is_int_like method from\nutils.py and replaces it with is_int_like\nmethod from oslo_utils.strutils to eliminate\nduplicate code.\n\nTrivialFix\nChange-Id: Ia81da8b0208bb2a30ab301519cfc714f26480edd\n'}]",1,285973,807c31dbce5bd4706df9e25f074ca4d099908039,72,38,2,20181,,,0,"Use is_int_like method from oslo_utils

This patch removes is_int_like method from
utils.py and replaces it with is_int_like
method from oslo_utils.strutils to eliminate
duplicate code.

TrivialFix
Change-Id: Ia81da8b0208bb2a30ab301519cfc714f26480edd
",git fetch https://review.opendev.org/openstack/cinder refs/changes/73/285973/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_utils.py', 'cinder/utils.py', 'cinder/volume/api.py']",3,80d9bb4efdf403dea4ec41b2652690153a536c56,rm/2861,from oslo_utils import strutils if size and (not strutils.is_int_like(size) or int(size) <= 0):, if size and (not utils.is_int_like(size) or int(size) <= 0):,2,19
openstack%2Fopenstack-ansible-lxc_container_create~master~I2619b1090300a161c108fcc3f65059e8d50c851e,openstack/openstack-ansible-lxc_container_create,master,I2619b1090300a161c108fcc3f65059e8d50c851e,Test container creation based on IP address,MERGED,2016-03-05 22:14:38.000000000,2016-03-05 23:50:37.000000000,2016-03-05 23:50:37.000000000,"[{'_account_id': 3}, {'_account_id': 4268}, {'_account_id': 6816}, {'_account_id': 12807}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-05 22:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/98ce9b85f82bef00a63fe4c7b0d3673ded703838', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 2, 'created': '2016-03-05 22:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/9fb9b1165622065cd2847055da845965ccdf9675', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 3, 'created': '2016-03-05 22:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/2d72121c924608f7d35e84026a68663a1b4547f3', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 4, 'created': '2016-03-05 22:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/dbe2ee16a52ae05abde6eec986301af2592a0e9e', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 5, 'created': '2016-03-05 22:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/d448c9afc4996dbfe1bafb5bfc8b409fd59936e5', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 6, 'created': '2016-03-05 22:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/fe1718c31dae7e3ebf88b543b9c5107f408d97ee', 'message': 'Test container creation based on IP address\n\nThe test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nA forced apt-get update is also included as this is a required\nfirst step in OpenStack-CI.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 7, 'created': '2016-03-05 22:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/23ee7e574699ac2e789d9ee19720a9ba7d5584a5', 'message': 'Test container creation based on IP address\n\nThis test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nA forced apt-get update is also included as this is a required\nfirst step in OpenStack-CI.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n'}, {'number': 8, 'created': '2016-03-05 23:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/bd7f9d52aa1ae088335800f50acf10bb898c58cb', 'message': ""Test container creation based on IP address\n\nThis test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nThis patch also includes the following in order to unblock testing\nfor this role:\n - A forced apt-get update\n - A base other-requirements.txt file to ensure that the\n   OpenStack-CI fallback requirements aren't used, which conflict\n   with LXC and cause the instance to hang.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n""}, {'number': 9, 'created': '2016-03-05 23:05:04.000000000', 'files': ['other-requirements.txt', 'tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/23830066ad908bc28a37ae4cd9086f11dc00d101', 'message': ""Test container creation based on IP address\n\nThis test executes an LXC container listing from the LXC host, then\nverifies that the container is present by name and IP address.\n\nThe test will work whether there is one or more IP addresses in\neach containers created.\n\nThis patch also includes the following in order to unblock testing\nfor this role:\n - A forced apt-get update\n - A base other-requirements.txt file to ensure that the\n   OpenStack-CI fallback requirements aren't used, which conflict\n   with LXC and cause the instance to hang.\n\nChange-Id: I2619b1090300a161c108fcc3f65059e8d50c851e\n""}]",3,288942,23830066ad908bc28a37ae4cd9086f11dc00d101,22,5,9,6816,,,0,"Test container creation based on IP address

This test executes an LXC container listing from the LXC host, then
verifies that the container is present by name and IP address.

The test will work whether there is one or more IP addresses in
each containers created.

This patch also includes the following in order to unblock testing
for this role:
 - A forced apt-get update
 - A base other-requirements.txt file to ensure that the
   OpenStack-CI fallback requirements aren't used, which conflict
   with LXC and cause the instance to hang.

Change-Id: I2619b1090300a161c108fcc3f65059e8d50c851e
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/42/288942/8 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,98ce9b85f82bef00a63fe4c7b0d3673ded703838,bindep-requirements," - name: Test whether the role produced expected results hosts: hosts tasks: - name: List the LXC containers present on the host command: lxc-ls -1 -f -F name,ipv4 register: lxc_container_list - name: Verify that the expected containers are present with the correct addresses # Example stdout: # NAME IPV4 # -------------------------------------- # container1 172.16.12.3,10.100.100.101 # container2 10.100.100.102,172.16.12.4 - lxc_container_list.stdout | search(""container1\s+(?:(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3},)?)10.100.100.101(?:(,\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})?)\s+"") - lxc_container_list.stdout | search(""container2\s+(?:(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3},)?)10.100.100.102(?:(,\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})?)\s+"")"," post_tasks: - name: Confirm containers were created command: lxc-ls -f register: lxc_containers - name: Format output set_fact: _lxc_output: ""{{ lxc_containers.stdout.split() | lower }}"" - set_fact: lxc_output: ""{{ _lxc_output | join(' ') }}"" - debug: var: _lxc_output - debug: var: lxc_output - name: Check role functions - ""'container1 running 10.100.100.101' in lxc_output"" - ""'container2 running 10.100.100.102' in lxc_output""",15,16
openstack%2Fopenstack-ansible-lxc_container_create~master~I77a6ec97fcd650c2fc50fb6a23e02cfe04a40118,openstack/openstack-ansible-lxc_container_create,master,I77a6ec97fcd650c2fc50fb6a23e02cfe04a40118,[DO NOT MERGE] Diagnostic debugging,ABANDONED,2016-03-05 15:06:32.000000000,2016-03-05 23:19:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4268}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-05 15:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/3af7501708000e9488e2f45db4a7cdaa17b2a6ec', 'message': '[DO NOT MERGE] Diagnostic debugging\n\nChange-Id: I77a6ec97fcd650c2fc50fb6a23e02cfe04a40118\n'}, {'number': 2, 'created': '2016-03-05 19:56:00.000000000', 'files': ['tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/b546df36bd9b44cbd386dc6138049161e17b907f', 'message': '[DO NOT MERGE] Diagnostic debugging\n\nChange-Id: I77a6ec97fcd650c2fc50fb6a23e02cfe04a40118\n'}]",2,288876,b546df36bd9b44cbd386dc6138049161e17b907f,11,4,2,6816,,,0,"[DO NOT MERGE] Diagnostic debugging

Change-Id: I77a6ec97fcd650c2fc50fb6a23e02cfe04a40118
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/76/288876/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,3af7501708000e9488e2f45db4a7cdaa17b2a6ec,bindep-requirements, - debug: var: _lxc_output - debug: var: lxc_output,,4,0
openstack%2Fopenstack-ansible-lxc_container_create~master~Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8,openstack/openstack-ansible-lxc_container_create,master,Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8,Initial commit for bindep requirements,ABANDONED,2016-03-03 15:12:26.000000000,2016-03-05 23:07:16.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 4162}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 15:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/e28c68e4705264daa40c469805f13398fb2f1082', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8\n'}, {'number': 2, 'created': '2016-03-04 10:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/55c8a985dc24c5aecdfad8ea43111b5f764cd61f', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8\n'}, {'number': 3, 'created': '2016-03-04 14:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/c0875fee52f2c5110cba2c5c0561dd871c09de55', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8\n'}, {'number': 4, 'created': '2016-03-05 12:57:41.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/103c7cacb3c5be40c6e6dc71b78f54ff10741695', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8\n'}]",0,287872,103c7cacb3c5be40c6e6dc71b78f54ff10741695,37,7,4,6816,,,0,"Initial commit for bindep requirements

Change-Id: Ie841ce6c6c9423d2a69d1175261d399ffa7e0ce8
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/72/287872/4 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,e28c68e4705264daa40c469805f13398fb2f1082,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. ",,11,0
openstack%2Fopenstack-ansible-lxc_container_create~master~I33ad0532ca20336c9dfbee6bc4468d0b126fc56c,openstack/openstack-ansible-lxc_container_create,master,I33ad0532ca20336c9dfbee6bc4468d0b126fc56c,Tests: Ensure that the apt cache is always refreshed,ABANDONED,2016-03-04 10:04:57.000000000,2016-03-05 22:59:14.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-03-04 10:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/882ef6799722db01340221352992390656992ab6', 'message': 'Ensure that the apt cache is always refreshed\n\nChange-Id: I33ad0532ca20336c9dfbee6bc4468d0b126fc56c\n'}, {'number': 2, 'created': '2016-03-04 10:19:22.000000000', 'files': ['tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/30bfedb08a20985ddd28ff6b2db57dd004ca34f5', 'message': 'Tests: Ensure that the apt cache is always refreshed\n\nChange-Id: I33ad0532ca20336c9dfbee6bc4468d0b126fc56c\n'}]",0,288340,30bfedb08a20985ddd28ff6b2db57dd004ca34f5,12,3,2,6816,,,0,"Tests: Ensure that the apt cache is always refreshed

Change-Id: I33ad0532ca20336c9dfbee6bc4468d0b126fc56c
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/40/288340/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,882ef6799722db01340221352992390656992ab6,bindep-requirements, - name: First ensure apt cache is always refreshed apt: update_cache: yes,,3,0
openstack%2Fneutron~master~Ifd49d6b2b68fe31f27ae3eb26e272167683075c6,openstack/neutron,master,Ifd49d6b2b68fe31f27ae3eb26e272167683075c6,Continue the fwaas decoupling and cleanup,MERGED,2016-03-04 07:09:10.000000000,2016-03-05 22:49:58.000000000,2016-03-05 22:49:58.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 12999}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-03-04 07:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b195ae73456af048bd51fe2195c7b87e4a3fcd9', 'message': 'Continue the fwaas decoupling and cleanup\n\nRemove some stale code. FWaaS has its own tempest plugin now.\n\nChange-Id: Ifd49d6b2b68fe31f27ae3eb26e272167683075c6\n'}, {'number': 2, 'created': '2016-03-04 16:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ccf28c68f5a1fc18d2146ab11845b67eb42e57ed', 'message': 'Continue the fwaas decoupling and cleanup\n\nRemove some stale code. FWaaS has its own tempest plugin now.\n\nCloses-Bug: #1506760\n\nChange-Id: Ifd49d6b2b68fe31f27ae3eb26e272167683075c6\n'}, {'number': 3, 'created': '2016-03-05 00:22:25.000000000', 'files': ['neutron/tests/api/base.py', 'neutron/tests/tempest/services/network/json/network_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a7c60830104047a9750618e840b4b824866b0f2', 'message': 'Continue the fwaas decoupling and cleanup\n\nRemove some stale code. FWaaS has its own tempest plugin now.\n\nCloses-Bug: #1506760\n\nChange-Id: Ifd49d6b2b68fe31f27ae3eb26e272167683075c6\n'}]",6,288279,4a7c60830104047a9750618e840b4b824866b0f2,40,13,3,748,,,0,"Continue the fwaas decoupling and cleanup

Remove some stale code. FWaaS has its own tempest plugin now.

Closes-Bug: #1506760

Change-Id: Ifd49d6b2b68fe31f27ae3eb26e272167683075c6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/288279/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/api/base.py', 'neutron/tests/tempest/services/network/json/network_client.py']",2,3b195ae73456af048bd51fe2195c7b87e4a3fcd9,bug/1506760,," 'firewall_rules': 'fw', 'firewall_policies': 'fw', 'firewalls': 'fw', def insert_firewall_rule_in_policy(self, firewall_policy_id, firewall_rule_id, insert_after="""", insert_before=""""): uri = '%s/fw/firewall_policies/%s/insert_rule' % (self.uri_prefix, firewall_policy_id) body = { ""firewall_rule_id"": firewall_rule_id, ""insert_after"": insert_after, ""insert_before"": insert_before } body = json.dumps(body) resp, body = self.put(uri, body) self.expected_success(200, resp.status) body = json.loads(body) return service_client.ResponseBody(resp, body) def remove_firewall_rule_from_policy(self, firewall_policy_id, firewall_rule_id): uri = '%s/fw/firewall_policies/%s/remove_rule' % (self.uri_prefix, firewall_policy_id) update_body = {""firewall_rule_id"": firewall_rule_id} update_body = json.dumps(update_body) resp, body = self.put(uri, update_body) self.expected_success(200, resp.status) body = json.loads(body) return service_client.ResponseBody(resp, body) ",0,60
openstack%2Fopenstack-ansible-os_swift~master~I50a97ab64ab1db8be6fad7479301b1cc0abe9ba9,openstack/openstack-ansible-os_swift,master,I50a97ab64ab1db8be6fad7479301b1cc0abe9ba9,Removing unneeded with_items usage for clarity,MERGED,2016-03-02 20:55:09.000000000,2016-03-05 22:47:17.000000000,2016-03-05 22:47:17.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-02 20:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/b1c35d3eced1551a760f737f9d0bd91f429300c9', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: I50a97ab64ab1db8be6fad7479301b1cc0abe9ba9\n'}, {'number': 2, 'created': '2016-03-03 14:07:54.000000000', 'files': ['tasks/swift_storage_hosts_container.yml', 'tasks/swift_storage_hosts_object.yml', 'tasks/swift_proxy_hosts.yml', 'tasks/swift_storage_hosts_account.yml', 'tasks/swift_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/d610c38646bf41ffa6e03b5e0d920cd18ae1c490', 'message': 'Removing unneeded with_items usage for clarity\n\nChange-Id: I50a97ab64ab1db8be6fad7479301b1cc0abe9ba9\n'}]",0,287435,d610c38646bf41ffa6e03b5e0d920cd18ae1c490,15,3,2,19814,,,0,"Removing unneeded with_items usage for clarity

Change-Id: I50a97ab64ab1db8be6fad7479301b1cc0abe9ba9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/35/287435/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/swift_storage_hosts_container.yml', 'tasks/swift_storage_hosts_object.yml', 'tasks/swift_proxy_hosts.yml', 'tasks/swift_pre_install.yml', 'tasks/swift_storage_hosts_account.yml']",5,b1c35d3eced1551a760f737f9d0bd91f429300c9,unneeded_with_items," src: ""account-server.conf.j2"" dest: ""/etc/swift/account-server/account-server.conf"" config_overrides: ""{{ swift_account_server_conf_overrides }}"" config_type: ""ini"" src: ""account-server-replicator.conf.j2"" dest: ""/etc/swift/account-server/account-server-replicator.conf"" config_overrides: ""{{ swift_account_server_replicator_conf_overrides }}"" config_type: ""ini"""," src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" config_overrides: ""{{ item.config_overrides }}"" config_type: ""{{ item.config_type }}"" with_items: - src: ""account-server.conf.j2"" dest: ""/etc/swift/account-server/account-server.conf"" config_overrides: ""{{ swift_account_server_conf_overrides }}"" config_type: ""ini"" src: ""{{ item.src }}"" dest: ""{{ item.dest }}"" config_overrides: ""{{ item.config_overrides }}"" config_type: ""{{ item.config_type }}"" with_items: - src: ""account-server-replicator.conf.j2"" dest: ""/etc/swift/account-server/account-server-replicator.conf"" config_overrides: ""{{ swift_account_server_replicator_conf_overrides }}"" config_type: ""ini""",24,51
openstack%2Frally~master~I466139dbf836aad882ac3dc68edf050fb73be1c7,openstack/rally,master,I466139dbf836aad882ac3dc68edf050fb73be1c7,[CI] Fix rally-mos job to work with mos-8.0,MERGED,2016-03-03 10:16:34.000000000,2016-03-05 22:16:16.000000000,2016-03-05 22:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-03-03 10:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/85851fa6ce474e23ab102ee8ab42691e59cc3408', 'message': '[ci] try to add mos-0.8 job\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 2, 'created': '2016-03-03 10:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e165880c333bffff9a6342c4187adca837fe1404', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 3, 'created': '2016-03-03 10:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a48a2515d147d02b2420deb0bd3b05b419fc047b', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 4, 'created': '2016-03-03 11:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab2c56ae45828215ea03cda2ffdfd012879332d9', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 5, 'created': '2016-03-03 12:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/365ffa6173f050644c3c2702999a65df18550631', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 6, 'created': '2016-03-03 13:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5e59b3783e73caf10df26473ecaf933874ee1004', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 7, 'created': '2016-03-03 14:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/caa4be1b76161c1ea94134f71cca650d248270d9', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 8, 'created': '2016-03-03 17:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1109e7229200246a0dd9986e2d03f23650294204', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 9, 'created': '2016-03-03 17:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/864c8db1ace3cf34b0c90e144c2b74081fae3b26', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 10, 'created': '2016-03-03 18:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3c5e2309d7950f5fa88ba07f4b22a183fcca1192', 'message': '[ci] try to add mos-0.8 and mos-8.0-ssl jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 11, 'created': '2016-03-03 19:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/767dedb7dfb0ded86a6ee3536745eea40877e80a', 'message': '[ci] try to add mos-8.0-ssl job\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 12, 'created': '2016-03-04 09:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/27ddf401522823bbbd0243f62ef363fca5d1ecca', 'message': '[CI] Fix rally-mos job to work with mos-8.0\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 13, 'created': '2016-03-04 10:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8345a4255d8adbd0e169f8527ac9aba7f223d630', 'message': '[CI] Fix rally-mos job to work with mos-8.0\n\nAlso remove hardcoded values for some other jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 14, 'created': '2016-03-04 10:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/33c5854434751b404d267cf8668c8f915d172daf', 'message': '[CI] Fix rally-mos job to work with mos-8.0\n\nAlso remove hardcoded values for some other jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}, {'number': 15, 'created': '2016-03-04 12:08:12.000000000', 'files': ['rally-jobs/rally-mos.yaml', 'rally-jobs/sahara.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/7f31f3f9ff17f402216157953e2113d506713a11', 'message': '[CI] Fix rally-mos job to work with mos-8.0\n\nAlso remove hardcoded values for some other jobs\n\nChange-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7\n'}]",0,287687,7f31f3f9ff17f402216157953e2113d506713a11,45,5,15,7369,,,0,"[CI] Fix rally-mos job to work with mos-8.0

Also remove hardcoded values for some other jobs

Change-Id: I466139dbf836aad882ac3dc68edf050fb73be1c7
",git fetch https://review.opendev.org/openstack/rally refs/changes/87/287687/13 && git format-patch -1 --stdout FETCH_HEAD,['.rally-ci.yaml'],1,85851fa6ce474e23ab102ee8ab42691e59cc3408,mos80,"--- - job: name: mos-8.0 env: MOS_PUBLIC_VLAN: 100 MOS_MANAGEMENT_VLAN: 101 MOS_PRIVATE_VLAN: 103 MOS_PUBLIC_IP: 172.16.0.1/24 MOS_MANAGEMENT_IP: 192.168.0.254/24 MOS_PRIVATE_IP: 192.168.2.1/24 RCI_TASK: ""rally-jobs/rally-mos.yaml"" RCI_TASK_ARGS: '{""sahara_hadoop_version"":""2.6.0""}' OS_AUTH_URL: ""http://172.16.0.3:5000/v2.0/"" OS_USERNAME: admin OS_PASSWORD: admin OS_TENANT_NAME: admin provider: ci4950 vms: - name: mos_8_0_1 - name: mos_8_0_2 - name: mos_8_0_3 - name: u1404_rally_mos publish: - [""/tmp/mos-logs"", ""mos-logs""] - [""/home/rally/rally/rally-plot"", ""rally-plot""] scripts: - git_checkout - eth1_up - install_rally - create_deployment_mos - wait_current_deployment - upload_fedora - run_scenario post: - copy_mos_logs ",,37,0
openstack%2Fpython-novaclient~master~I2313c5d37a7cf87a8d75e37c93aab136cf028ec1,openstack/python-novaclient,master,I2313c5d37a7cf87a8d75e37c93aab136cf028ec1,Functional tests for trigger-crash-dump (microversion 2.17),MERGED,2016-02-15 10:35:32.000000000,2016-03-05 21:50:26.000000000,2016-02-25 17:59:29.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 6849}, {'_account_id': 9545}, {'_account_id': 9569}, {'_account_id': 10618}, {'_account_id': 14819}, {'_account_id': 16437}, {'_account_id': 20105}]","[{'number': 1, 'created': '2016-02-15 10:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/34b256bbff11b394287018aa848ef4fe17ee08be', 'message': 'Functional tests for trigger-crash-dump (microversion 2.17)\n\nIt\'s a resource-consuming task to implement full-flow (up to getting\nand reading a dump file) functional test for trigger-crash-dump.\nWe need to upload Ubuntu image for booting an instance based on it,\nand to install kdump with its further configuring on this instance.\n\nHere, the ""light"" version of functional test is proposed.\nIt\'s based on knowledge that trigger-crash-dump uses a NMI injection,\nand when the \'trigger-crash-dump\' operation is executed,\ninstance\'s kernel receives the MNI signal, and an appropriate\nmessage will appear in the instance\'s log.\n\nChange-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1\n'}, {'number': 2, 'created': '2016-02-15 18:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/e355e88bbd5efe25f390fad301807fee02f7e99c', 'message': 'Functional tests for trigger-crash-dump (microversion 2.17)\n\nIt\'s a resource-consuming task to implement full-flow (up to getting\nand reading a dump file) functional test for trigger-crash-dump.\nWe need to upload Ubuntu image for booting an instance based on it,\nand to install kdump with its further configuring on this instance.\n\nHere, the ""light"" version of functional test is proposed.\nIt\'s based on knowledge that trigger-crash-dump uses a NMI injection,\nand when the \'trigger-crash-dump\' operation is executed,\ninstance\'s kernel receives the MNI signal, and an appropriate\nmessage will appear in the instance\'s log.\n\nChange-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1\n'}, {'number': 3, 'created': '2016-02-17 14:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/14e07f27d63deb78914fd53a6442fc75f57df5be', 'message': 'Functional tests for trigger-crash-dump (microversion 2.17)\n\nIt\'s a resource-consuming task to implement full-flow (up to getting\nand reading a dump file) functional test for trigger-crash-dump.\nWe need to upload Ubuntu image for booting an instance based on it,\nand to install kdump with its further configuring on this instance.\n\nHere, the ""light"" version of functional test is proposed.\nIt\'s based on knowledge that trigger-crash-dump uses a NMI injection,\nand when the \'trigger-crash-dump\' operation is executed,\ninstance\'s kernel receives the MNI signal, and an appropriate\nmessage will appear in the instance\'s log.\n\nWait_for_server_os_boot() method has been added to ClientTestBase\nto check if instance\'s operational system  is completely booted.\n\nChange-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1\n'}, {'number': 4, 'created': '2016-02-18 11:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3001a10e6c4e166b26ba5fff500e01177f09c762', 'message': 'Functional tests for trigger-crash-dump (microversion 2.17)\n\nIt\'s a resource-consuming task to implement full-flow (up to getting\nand reading a dump file) functional test for trigger-crash-dump.\nWe need to upload Ubuntu image for booting an instance based on it,\nand to install kdump with its further configuring on this instance.\n\nHere, the ""light"" version of functional test is proposed.\nIt\'s based on knowledge that trigger-crash-dump uses a NMI injection,\nand when the \'trigger-crash-dump\' operation is executed,\ninstance\'s kernel receives the MNI signal, and an appropriate\nmessage will appear in the instance\'s log.\n\nWait_for_server_os_boot() method has been added to ClientTestBase\nto check if instance\'s operating system  is completely booted.\n\nChange-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1\n'}, {'number': 5, 'created': '2016-02-22 17:01:46.000000000', 'files': ['novaclient/tests/functional/base.py', 'novaclient/tests/functional/v2/test_trigger_crash_dump.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f5a25fe997b19ff71a335ece755c8904dc8136c8', 'message': 'Functional tests for trigger-crash-dump (microversion 2.17)\n\nIt\'s a resource-consuming task to implement full-flow (up to getting\nand reading a dump file) functional test for trigger-crash-dump.\nWe need to upload Ubuntu image for booting an instance based on it,\nand to install kdump with its further configuring on this instance.\n\nHere, the ""light"" version of functional test is proposed.\nIt\'s based on knowledge that trigger-crash-dump uses a NMI injection,\nand when the \'trigger-crash-dump\' operation is executed,\ninstance\'s kernel receives the MNI signal, and an appropriate\nmessage will appear in the instance\'s log.\n\nWait_for_server_os_boot() method has been added to ClientTestBase\nto check if instance\'s operating system  is completely booted.\n\nThe _create_server() method has been removed since the change\nwhich puts this method to the base test class has been merged.\n\nChange-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1\n'}]",9,280147,f5a25fe997b19ff71a335ece755c8904dc8136c8,29,11,5,16437,,,0,"Functional tests for trigger-crash-dump (microversion 2.17)

It's a resource-consuming task to implement full-flow (up to getting
and reading a dump file) functional test for trigger-crash-dump.
We need to upload Ubuntu image for booting an instance based on it,
and to install kdump with its further configuring on this instance.

Here, the ""light"" version of functional test is proposed.
It's based on knowledge that trigger-crash-dump uses a NMI injection,
and when the 'trigger-crash-dump' operation is executed,
instance's kernel receives the MNI signal, and an appropriate
message will appear in the instance's log.

Wait_for_server_os_boot() method has been added to ClientTestBase
to check if instance's operating system  is completely booted.

The _create_server() method has been removed since the change
which puts this method to the base test class has been merged.

Change-Id: I2313c5d37a7cf87a8d75e37c93aab136cf028ec1
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/47/280147/5 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/tests/functional/v2/test_trigger_crash_dump.py'],1,34b256bbff11b394287018aa848ef4fe17ee08be,micro-217,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import time from novaclient.tests.functional import base from novaclient.v2 import shell class TestTrigCrashDumpNovaClientV217(base.TenantTestBase): """"""Functional tests for trigger crash dump"""""" COMPUTE_API_VERSION = ""2.17"" # It's a resource-consuming task to implement full-flow (up to getting # and reading a dump file) functional test for trigger-crash-dump. # We need to upload Ubuntu image for booting an instance based on it, # and to install kdump with its further configuring on this instance. # Here, the ""light"" version of functional test is proposed. # It's based on knowledge that trigger-crash-dump uses a NMI injection, # and when the 'trigger-crash-dump' operation is executed, # instance's kernel receives the MNI signal, and an appropriate # message will appear in the instance's log. # The server status must be ACTIVE, PAUSED, RESCUED, RESIZED or ERROR. # If not, the conflictingRequest(409) code is returned def _create_server(self): name = self.name_generate(prefix='server') server = self.client.servers.create(name, self.image, self.flavor) self.addCleanup(server.delete) shell._poll_for_status( self.client.servers.get, server.id, 'building', ['active']) return server def test_trigger_crash_dump_in_active_state(self): server = self._create_server() self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) self.assertIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_error_state(self): server = self._create_server() self.nova('reset-state %s ' % server.id) shell._poll_for_status( self.client.servers.get, server.id, 'active', ['error']) self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) self.assertIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_paused_state(self): server = self._create_server() self.nova('pause %s ' % server.id) shell._poll_for_status( self.client.servers.get, server.id, 'active', ['paused']) self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) # In PAUSED state a server's kernel shouldn't react onto NMI self.assertNotIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_rescued_state(self): server = self._create_server() self.nova('rescue %s ' % server.id) shell._poll_for_status( self.client.servers.get, server.id, 'active', ['rescue']) self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) self.assertIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_resized_state(self): server = self._create_server() self.nova('resize %s %s' % (server.id, 'm1.small')) shell._poll_for_status( self.client.servers.get, server.id, 'active', ['verify_resize']) self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) self.assertIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_shutoff_state(self): server = self._create_server() self.nova('stop %s ' % server.id) shell._poll_for_status( self.client.servers.get, server.id, 'active', ['shutoff']) output = self.nova('trigger-crash-dump %s ' % server.id, fail_ok=True, merge_stderr=True) self.assertIn(""ERROR (Conflict): "" ""Cannot 'trigger_crash_dump' instance %s "" ""while it is in vm_state stopped (HTTP 409) "" % server.id, output) # If the specified server is locked, the conflictingRequest(409) code # is returned to a user without administrator privileges. def test_trigger_crash_dump_in_locked_state_admin(self): server = self._create_server() self.nova('lock %s ' % server.id) self.nova('trigger-crash-dump %s ' % server.id) time.sleep(5) output = self.nova('console-log %s ' % server.id) self.assertIn(""Uhhuh. NMI received for unknown reason "", output) def test_trigger_crash_dump_in_locked_state_nonadmin(self): name = self.name_generate(prefix='server') server = self.another_nova('boot --flavor %s --image %s --poll %s' % (self.flavor.name, self.image.name, name)) self.addCleanup(self.another_nova, 'delete', params=name) server_id = self._get_value_from_the_table( server, 'id') self.another_nova('lock %s ' % server_id) self.addCleanup(self.another_nova, 'unlock', params=name) output = self.another_nova('trigger-crash-dump %s ' % server_id, fail_ok=True, merge_stderr=True) self.assertIn(""ERROR (Conflict): Instance %s is in an invalid "" ""state for 'trigger_crash_dump' (HTTP 409) "" % server_id, output) ",,134,0
openstack%2Fheat~master~Id86c41d3379880896f17ab57885433c078aff441,openstack/heat,master,Id86c41d3379880896f17ab57885433c078aff441,Add scenario test for multi-region,ABANDONED,2015-11-20 10:36:51.000000000,2016-03-05 21:12:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 12363}, {'_account_id': 13998}, {'_account_id': 15755}]","[{'number': 1, 'created': '2015-11-20 10:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7f8fc962fa9f2d1971489a12023fef4fc4694f1f', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}, {'number': 2, 'created': '2015-11-20 13:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/06daa691bf2f16c32146c452319d2b70219d1dbf', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}, {'number': 3, 'created': '2015-11-20 14:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b02b71bc93de1dfff778ad6b4178a6d30a593a0d', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}, {'number': 4, 'created': '2015-12-07 10:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5b8072c1e805e9237e5d87fbea6233d0811ab175', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}, {'number': 5, 'created': '2015-12-11 13:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/72b599d510cb7d7b46aef30736f56362a969c1f4', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}, {'number': 6, 'created': '2016-01-06 02:46:10.000000000', 'files': ['heat_integrationtests/scenario/templates/test_multi_region.yaml', 'heat_integrationtests/scenario/test_multi_region.py', 'heat_integrationtests/prepare_test_env.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/78ba4b56d9029f23892e648c7dcfbbc34219d5ee', 'message': ""Add scenario test for multi-region\n\nAt the moment, this test is part of the 'skip_scenario_test_list'.\nThere are two reasons for this:\n1. At the moment multi-region setups are not possible in devstack-gate.\n   Because of this it is currently not possible to run this test at the\n   gate.\n\n2. As the README states, the defaults of the tests should match running\n   against a recent DevStack. A usual DevStack installation does only\n   consist of a single region. Logically, this test requires multiple\n   regions to work and would therefore fail in a normal DevStack\n   environments.\n\nblueprint: multi-region-test\nChange-Id: Id86c41d3379880896f17ab57885433c078aff441\n""}]",6,248011,78ba4b56d9029f23892e648c7dcfbbc34219d5ee,22,6,6,13998,,,0,"Add scenario test for multi-region

At the moment, this test is part of the 'skip_scenario_test_list'.
There are two reasons for this:
1. At the moment multi-region setups are not possible in devstack-gate.
   Because of this it is currently not possible to run this test at the
   gate.

2. As the README states, the defaults of the tests should match running
   against a recent DevStack. A usual DevStack installation does only
   consist of a single region. Logically, this test requires multiple
   regions to work and would therefore fail in a normal DevStack
   environments.

blueprint: multi-region-test
Change-Id: Id86c41d3379880896f17ab57885433c078aff441
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/248011/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat_integrationtests/scenario/templates/test_multi_region.yaml', 'heat_integrationtests/scenario/test_multi_region.py', 'heat_integrationtests/prepare_test_env.sh']",3,7f8fc962fa9f2d1971489a12023fef4fc4694f1f,bp/multi-region-test,"iniset heat_integrationtests.conf DEFAULT skip_scenario_test_list 'MultiRegionTest, SoftwareConfigIntegrationTest, VolumeBackupRestoreIntegrationTest'","iniset heat_integrationtests.conf DEFAULT skip_scenario_test_list 'SoftwareConfigIntegrationTest, VolumeBackupRestoreIntegrationTest'",166,1
openstack%2Fdevstack-gate~master~Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb,openstack/devstack-gate,master,Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb,Multi-region dg support,ABANDONED,2015-07-09 23:35:05.000000000,2016-03-05 21:12:31.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 7872}, {'_account_id': 13998}, {'_account_id': 15755}]","[{'number': 1, 'created': '2015-07-09 23:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fc33a329cddde92df98e5d2f1892e036633438d7', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n302\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 2, 'created': '2015-07-09 23:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/327b67266e54db52245df684d49d7246a4249c6f', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 3, 'created': '2015-07-09 23:38:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/a63824958a075b45dff75ce090d015b2964836fa', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 4, 'created': '2015-07-13 13:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fa3ff510c21339635da6231dc25cbc34a120a9f6', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 5, 'created': '2015-07-24 23:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/232c927a11b66b46c060766227cfdb2dd3061be4', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 6, 'created': '2015-07-29 22:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b62b3ec175c210cfc2de93126ead0a3bb0b52248', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}, {'number': 7, 'created': '2015-08-21 12:03:58.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ea2fcb3d08a5ac91774143d28a330a84ea7dd868', 'message': 'Multi-region dg support\n\nAdd basic multi-region support to devstack-gate. This allows to\nconfigure the nodes in a multinode setup with different regions.\nThe sub nodes in this configuration will use the keystone from the\nprimary node for authentication. The configuration is taken from [1].\n\n[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332\n\nChange-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb\n'}]",2,200309,ea2fcb3d08a5ac91774143d28a330a84ea7dd868,22,7,7,13998,,,0,"Multi-region dg support

Add basic multi-region support to devstack-gate. This allows to
configure the nodes in a multinode setup with different regions.
The sub nodes in this configuration will use the keystone from the
primary node for authentication. The configuration is taken from [1].

[1]: http://git.openstack.org/cgit/openstack-dev/devstack/tree/README.md#n332

Change-Id: Ieb654b4279ccd6de9468c1268afeb8c42aea9ddb
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/09/200309/6 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh']",2,fc33a329cddde92df98e5d2f1892e036633438d7,bp/multi-region-test,"# Set to 1 to create a multi-region environment with the primary node in RegionOne # and the sub nodes in RegionTwo. This does only have an effect when # DEVSTACK_GATE_TOPOLOGY=""multinoe"". export DEVSTACK_GATE_MULTIREGION=${DEVSTACK_GATE_MULTIREGION:-0} ",,14,1
openstack%2Fdevstack-gate~master~I2adff0d7195d3f53e19b600b2d91163a8271bf2c,openstack/devstack-gate,master,I2adff0d7195d3f53e19b600b2d91163a8271bf2c,Add support for ipmitool driver in Ironic,MERGED,2016-02-24 09:47:31.000000000,2016-03-05 21:10:45.000000000,2016-03-05 21:10:45.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 9542}, {'_account_id': 10343}, {'_account_id': 13362}, {'_account_id': 14525}, {'_account_id': 14923}]","[{'number': 1, 'created': '2016-02-24 09:47:31.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3630eae36ff75347c12598b35e091ba8c71ee04f', 'message': 'Add support for ipmitool driver in Ironic\n\nThe commit 7ffa1d58ce9fd9e32cdab142a1f12feae38c3097 added support to\nconfigure nodes with ipmitool drivers in DevStack ironic to run with\nvirtual machines. The main goal of that patch was to allow us to test\nthe production ipmitool drivers in the gate replacing the *_ssh testing\ndrivers in the future.\n\nLater a patch to project-config 2e577710e975983b594f6df59b504b4cae85e594\nadded two new jobs to the ironic gate: pxe_ipmitool and agent_ipmitool.\n\nThis patch contains the final pieces to enable ipmitool drivers to run\non gate.\n\nChange-Id: I2adff0d7195d3f53e19b600b2d91163a8271bf2c\nRelated-Bug: #1544642\n'}]",0,284036,3630eae36ff75347c12598b35e091ba8c71ee04f,26,8,1,6773,,,0,"Add support for ipmitool driver in Ironic

The commit 7ffa1d58ce9fd9e32cdab142a1f12feae38c3097 added support to
configure nodes with ipmitool drivers in DevStack ironic to run with
virtual machines. The main goal of that patch was to allow us to test
the production ipmitool drivers in the gate replacing the *_ssh testing
drivers in the future.

Later a patch to project-config 2e577710e975983b594f6df59b504b4cae85e594
added two new jobs to the ironic gate: pxe_ipmitool and agent_ipmitool.

This patch contains the final pieces to enable ipmitool drivers to run
on gate.

Change-Id: I2adff0d7195d3f53e19b600b2d91163a8271bf2c
Related-Bug: #1544642
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/36/284036/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,3630eae36ff75347c12598b35e091ba8c71ee04f,bug/1544642," echo ""IRONIC_DEPLOY_DRIVER=$DEVSTACK_GATE_IRONIC_DRIVER"" >>""$localrc_file"" if [[ -z ""${DEVSTACK_GATE_IRONIC_DRIVER%%agent*}"" ]]; then echo ""IRONIC_ENABLED_DRIVERS=fake,pxe_ssh,pxe_ipmitool"" >>""$localrc_file"" # In the future we might want to increase the number of compute nodes."," if [[ ""$DEVSTACK_GATE_IRONIC_DRIVER"" == ""agent_ssh"" ]]; then echo ""IRONIC_DEPLOY_DRIVER=agent_ssh"" >>""$localrc_file"" # In the future we might want to increase the number of compute nodes. ",4,3
openstack%2Ftempest~master~I89c151c23881a2ee13123c5fc73e27e287914387,openstack/tempest,master,I89c151c23881a2ee13123c5fc73e27e287914387,Dont-merge: check necessity of admin,ABANDONED,2016-03-05 19:30:23.000000000,2016-03-05 21:00:14.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-03-05 19:30:23.000000000', 'files': ['tempest/api/network/admin/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9d40d7fb7771f509adeb4f89d0f7b4a9a615844d', 'message': 'Dont-merge: check necessity of admin\n\nChange-Id: I89c151c23881a2ee13123c5fc73e27e287914387\n'}]",0,288931,9d40d7fb7771f509adeb4f89d0f7b4a9a615844d,5,3,1,6167,,,0,"Dont-merge: check necessity of admin

Change-Id: I89c151c23881a2ee13123c5fc73e27e287914387
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/288931/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/admin/test_l3_agent_scheduler.py'],1,9d40d7fb7771f509adeb4f89d0f7b4a9a615844d,dont-merge01, cls.routers_client.add_router_interface(, cls.admin_routers_client.add_router_interface(,1,1
openstack%2Frequirements~master~Idbbdf7aa905e42eb36733271ef482989120c426f,openstack/requirements,master,Idbbdf7aa905e42eb36733271ef482989120c426f,Comment other-requirements.txt,MERGED,2016-03-05 18:46:06.000000000,2016-03-05 20:43:01.000000000,2016-03-05 20:43:01.000000000,"[{'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2016-03-05 18:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a48f25807f7850c67d6a59baed3f79828657cbd3', 'message': 'Comment other-requirements.txt\n\nAdd a comment why the database packages are currently needed in the\nfile.\n\nChange-Id: Idbbdf7aa905e42eb36733271ef482989120c426f\n'}, {'number': 2, 'created': '2016-03-05 18:48:48.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e19caa9c0e8342e983132dab9e470ec69c973820', 'message': 'Comment other-requirements.txt\n\nAdd a comment why the database packages are currently needed in the\nfile.\n\nChange-Id: Idbbdf7aa905e42eb36733271ef482989120c426f\n'}]",0,288928,e19caa9c0e8342e983132dab9e470ec69c973820,7,2,2,6547,,,0,"Comment other-requirements.txt

Add a comment why the database packages are currently needed in the
file.

Change-Id: Idbbdf7aa905e42eb36733271ef482989120c426f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/288928/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,a48f25807f7850c67d6a59baed3f79828657cbd3,comment-other-requirements,# NOTE(jaegerandi): Temporarily needed for running as part of # OpenStack gates: libmysqlclient-dev mysql-client mysql-server postgresql postgresql-client,libmysqlclient-dev mysql-client mysql-serverpostgresql postgresql-client,7,5
openstack%2Foctavia~master~I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad,openstack/octavia,master,I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad,Better L7Policy API validations,MERGED,2016-02-28 12:53:07.000000000,2016-03-05 20:27:11.000000000,2016-03-05 20:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-02-28 12:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b07a65f27d56e9f2b26217ef4b61352a7e9a1f6a', 'message': ""Better L7Policy API validations\n\nTesting of the API shows that it didn't react well to having\nnon-essential parameters set to 'None' in update requests. This\npatch moves L7Policy validations much sooner in the update process\n(ie. we catch them at the API), and otherwise reorganizes most of\nthe L7Policy validation code into the common validations file both so\nthat it can be called from various locations in the code base, and\nso that we can have an easier time unit testing the validation code.\n\nChange-Id: I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad\nCloses-Bug: 1550913\n""}, {'number': 2, 'created': '2016-02-28 19:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2bc464d3372f019bdcf85a1e5a0cbde327bc1e38', 'message': ""Better L7Policy API validations\n\nTesting of the API shows that it didn't react well to having\nnon-essential parameters set to 'None' in update requests. This\npatch moves L7Policy validations much sooner in the update process\n(ie. we catch them at the API), and otherwise reorganizes most of\nthe L7Policy validation code into the common validations file both so\nthat it can be called from various locations in the code base, and\nso that we can have an easier time unit testing the validation code.\n\nCloses-Bug: 1550913\nChange-Id: I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad\n""}, {'number': 3, 'created': '2016-03-01 05:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4b6c1a0b9079f615c0bde21100a7e7f3918d0ed0', 'message': ""Better L7Policy API validations\n\nTesting of the API shows that it didn't react well to having\nnon-essential parameters set to 'None' in update requests. This\npatch moves L7Policy validations much sooner in the update process\n(ie. we catch them at the API), and otherwise reorganizes most of\nthe L7Policy validation code into the common validations file both so\nthat it can be called from various locations in the code base, and\nso that we can have an easier time unit testing the validation code.\n\nCloses-Bug: 1550913\nChange-Id: I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad\n""}, {'number': 4, 'created': '2016-03-04 21:49:23.000000000', 'files': ['octavia/tests/unit/api/v1/types/test_l7policies.py', 'octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_l7policy.py', 'octavia/common/constants.py', 'octavia/tests/unit/common/test_validations.py', 'octavia/api/v1/controllers/l7policy.py', 'octavia/db/repositories.py', 'octavia/api/v1/types/l7policy.py', 'octavia/db/prepare.py', 'octavia/common/exceptions.py', 'octavia/common/validate.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/0fac4f2cd91ebce2730a17d07e6f9e3d3efc6757', 'message': ""Better L7Policy API validations\n\nTesting of the API shows that it didn't react well to having\nnon-essential parameters set to 'None' in update requests. This\npatch moves L7Policy validations much sooner in the update process\n(ie. we catch them at the API), and otherwise reorganizes most of\nthe L7Policy validation code into the common validations file both so\nthat it can be called from various locations in the code base, and\nso that we can have an easier time unit testing the validation code.\n\nCloses-Bug: 1550913\nChange-Id: I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad\n""}]",19,285783,0fac4f2cd91ebce2730a17d07e6f9e3d3efc6757,36,8,4,11685,,,0,"Better L7Policy API validations

Testing of the API shows that it didn't react well to having
non-essential parameters set to 'None' in update requests. This
patch moves L7Policy validations much sooner in the update process
(ie. we catch them at the API), and otherwise reorganizes most of
the L7Policy validation code into the common validations file both so
that it can be called from various locations in the code base, and
so that we can have an easier time unit testing the validation code.

Closes-Bug: 1550913
Change-Id: I7c14a8cef3d74b2b8d6f4d1ec4f6f9f32f96b9ad
",git fetch https://review.opendev.org/openstack/octavia refs/changes/83/285783/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/api/v1/types/test_l7policies.py', 'octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_l7policy.py', 'octavia/tests/unit/common/test_validations.py', 'octavia/api/v1/controllers/l7policy.py', 'octavia/db/repositories.py', 'octavia/api/v1/types/l7policy.py', 'octavia/common/exceptions.py', 'octavia/common/validate.py']",9,b07a65f27d56e9f2b26217ef4b61352a7e9a1f6a,bug/1550913," def sanitize_l7policy_api_args(l7policy, create=False): """"""Validate and make consistent L7Policy API arguments. This method is mainly meant to sanitize L7 Policy create and update API dictionaries, so that we strip 'None' values that don't apply for our particular update. This method does *not* verify that any redirect_pool_id exists in the database, but will raise an error if a redirect_url doesn't look like a URL. :param l7policy: The L7 Policy dictionary we are santizing / validating """""" if 'action' in l7policy.keys(): if l7policy['action'] == constants.L7POLICY_ACTION_REJECT: l7policy.pop('redirect_url', None) l7policy.pop('redirect_pool_id', None) elif l7policy['action'] == constants.L7POLICY_ACTION_REDIRECT_TO_URL: l7policy.pop('redirect_pool_id', None) elif l7policy['action'] == constants.L7POLICY_ACTION_REDIRECT_TO_POOL: l7policy.pop('redirect_url', None) elif l7policy['action'] is None: if create: raise exceptions.InvalidL7PolicyAction(action='None') l7policy.pop('action', None) else: raise exceptions.InvalidL7PolicyAction( action=l7policy['action']) if ('redirect_pool_id' in l7policy.keys() and 'redirect_url' in l7policy.keys() and l7policy['redirect_pool_id'] is not None and l7policy['redirect_url'] is not None): raise exceptions.InvalidL7PolicyArgs( msg='Cannot specify redirect_pool_id and redirect_url ' 'at the same time') if 'redirect_pool_id' in l7policy.keys(): if l7policy['redirect_pool_id'] is not None: l7policy.update({ 'action': constants.L7POLICY_ACTION_REDIRECT_TO_POOL}) l7policy.pop('redirect_url', None) else: if create: raise exceptions.InvalidL7PolicyArgs( msg='redirect_pool_id must not be None') l7policy.pop('redirect_pool_id', None) if 'redirect_url' in l7policy.keys(): if l7policy['redirect_url'] is not None: url(l7policy['redirect_url']) l7policy.update({ 'action': constants.L7POLICY_ACTION_REDIRECT_TO_URL}) l7policy.pop('redirect_pool_id', None) else: if create: raise exceptions.InvalidL7PolicyArgs( msg='redirect_url must not be None') l7policy.pop('redirect_url', None) # If we are creating, we need an action at this point if create and 'action' not in l7policy.keys(): raise exceptions.InvalidL7PolicyAction(action='None') # See if we have anything left after that... if len(l7policy.keys()) == 0: raise exceptions.InvalidL7PolicyArgs(msg='Invalid update options') return l7policy",,234,51
openstack%2Fopenstack-ansible-lxc_container_create~master~I030ee54cc8de8223c1d5f3463977b5bfdea0ea67,openstack/openstack-ansible-lxc_container_create,master,I030ee54cc8de8223c1d5f3463977b5bfdea0ea67,Resolve directory creation race condition,ABANDONED,2016-03-05 14:49:15.000000000,2016-03-05 19:54:56.000000000,,"[{'_account_id': 3}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-05 14:49:15.000000000', 'files': ['tasks/container_create.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/ed88494bd0fb4c6d79746856e6757be3e0a6b12b', 'message': ""Resolve directory creation race condition\n\nThere appears to be a directory creation race condition when Ansible\nevaluates the task for creating the directories for the containers.\nIt fails when trying to create '/openstack/log/container1' after\ncreating '/openstack/log/container2' with the error message\nindicating that it tried to create '/openstack/log' but it already\nexists.\n\nChange-Id: I030ee54cc8de8223c1d5f3463977b5bfdea0ea67\n""}]",0,288873,ed88494bd0fb4c6d79746856e6757be3e0a6b12b,4,2,1,6816,,,0,"Resolve directory creation race condition

There appears to be a directory creation race condition when Ansible
evaluates the task for creating the directories for the containers.
It fails when trying to create '/openstack/log/container1' after
creating '/openstack/log/container2' with the error message
indicating that it tried to create '/openstack/log' but it already
exists.

Change-Id: I030ee54cc8de8223c1d5f3463977b5bfdea0ea67
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/73/288873/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/container_create.yml'],1,ed88494bd0fb4c6d79746856e6757be3e0a6b12b,bindep-requirements," # TODO(odyssey4me) Re-evaluate whether the next two directories need to be # included here when we move to Ansible 2.x. They're present here to work # around a race condition which appears to be a bug in Ansible 1.9x. - ""/openstack"" - ""/openstack/log""",,5,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I39d7b3f40de6ac691550c11d71bb6a182b3452f4,openstack/openstack-ansible-lxc_hosts,master,I39d7b3f40de6ac691550c11d71bb6a182b3452f4,Make corrections to LXC bridge template file,MERGED,2016-03-05 18:30:07.000000000,2016-03-05 19:51:18.000000000,2016-03-05 19:51:18.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-05 18:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/47643aab3c125395183e8cc0ecfc71ae0a2e2c85', 'message': ""Make corrections to LXC bridge template file\n\nThis change adjusts a few of the modifications made to the\nlxc-net-bridge.cfg.j2 file template in change\nI3c8225124a5f18db81259e1d52d0168ef52c3c17.\n\nThe minus signs have been removed from if and endif blocks so that\nwhitespace is kept intact between sections. The ordering of post-up and\npost-down commands has also been changed so that iptables rules are\ncreated before the dnsmasq service is started, as they were previously.\n\nThe default value of lxc_net_gateway has also been changed to null so\nthat it's evaluated as expected. Its current value, none, is evaluated\nas a string.\n\nChange-Id: I39d7b3f40de6ac691550c11d71bb6a182b3452f4\n""}, {'number': 2, 'created': '2016-03-05 18:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/af9e24a09320a4e77fac09e2659b4fa7445b8ad9', 'message': ""Make corrections to LXC bridge template file\n\nThis change adjusts a few of the modifications made to the\nlxc-net-bridge.cfg.j2 template file in change\nI3c8225124a5f18db81259e1d52d0168ef52c3c17.\n\nThe minus signs have been removed from if and endif blocks so that\nwhitespace is kept intact between sections. The ordering of post-up and\npost-down commands has also been changed so that iptables rules are\ncreated before the dnsmasq service is started, as they were previously.\n\nThe default value of lxc_net_gateway has also been changed to null so\nthat it's evaluated as expected. Its current value, none, is evaluated\nas a string.\n\nChange-Id: I39d7b3f40de6ac691550c11d71bb6a182b3452f4\n""}, {'number': 3, 'created': '2016-03-05 18:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d3d07a601984ca2e6bf6e6c425d4b687397d34f3', 'message': ""Make corrections to LXC bridge template file\n\nThis change adjusts a few of the modifications made to the\nlxc-net-bridge.cfg.j2 template file in change\nI3c8225124a5f18db81259e1d52d0168ef52c3c17.\n\nThe minus signs have been removed from if and endif blocks so that\nwhitespace is kept intact between sections. The ordering of post-up and\npost-down commands has also been changed so that iptables rules are\ncreated before the dnsmasq service is started, as they were previously.\n\nThe default value of lxc_net_gateway has also been changed to null so\nthat it's evaluated as expected. Its current value, none, is evaluated\nas a string.\n\nChange-Id: I39d7b3f40de6ac691550c11d71bb6a182b3452f4\n""}, {'number': 4, 'created': '2016-03-05 19:43:08.000000000', 'files': ['tests/files/expected-lxc-net-bridge.cfg', 'templates/lxc-net-bridge.cfg.j2', 'tests/test.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/158d035b92ae7e239f0c1bed78727eaa7ecb2942', 'message': ""Make corrections to LXC bridge template file\n\nThis change adjusts a few of the modifications made to the\nlxc-net-bridge.cfg.j2 template file in change\nI3c8225124a5f18db81259e1d52d0168ef52c3c17.\n\nThe minus signs have been removed from if and endif blocks so that\nwhitespace is kept intact between sections. The ordering of post-up and\npost-down commands has also been changed so that iptables rules are\ncreated before the dnsmasq service is started, as they were previously.\n\nThe default value of lxc_net_gateway has also been changed to null so\nthat it's evaluated as expected. Its current value, none, is evaluated\nas a string.\n\nA test has been added to compare the contents of the deployed lxc bridge\ninterface file with its expected contents.\n\nChange-Id: I39d7b3f40de6ac691550c11d71bb6a182b3452f4\n""}]",2,288926,158d035b92ae7e239f0c1bed78727eaa7ecb2942,14,4,4,14805,,,0,"Make corrections to LXC bridge template file

This change adjusts a few of the modifications made to the
lxc-net-bridge.cfg.j2 template file in change
I3c8225124a5f18db81259e1d52d0168ef52c3c17.

The minus signs have been removed from if and endif blocks so that
whitespace is kept intact between sections. The ordering of post-up and
post-down commands has also been changed so that iptables rules are
created before the dnsmasq service is started, as they were previously.

The default value of lxc_net_gateway has also been changed to null so
that it's evaluated as expected. Its current value, none, is evaluated
as a string.

A test has been added to compare the contents of the deployed lxc bridge
interface file with its expected contents.

Change-Id: I39d7b3f40de6ac691550c11d71bb6a182b3452f4
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/26/288926/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/lxc-net-bridge.cfg.j2', 'defaults/main.yml']",2,47643aab3c125395183e8cc0ecfc71ae0a2e2c85,lxc_bridge_template,"lxc_net_gateway: null ## if null no gateway will on the LXC bridge, nat must be ""false"" to use a gateway.","lxc_net_gateway: none ## if ""none"" no gateway will on the LXC bridge, nat must be ""false"" to use a gateway.",9,9
openstack%2Foctavia~master~Iaa6b12cbc3418dce40f689fb4812670784ea3018,openstack/octavia,master,Iaa6b12cbc3418dce40f689fb4812670784ea3018,"Use ""--pub-key"" instead of ""--pub_key""",MERGED,2016-03-04 07:41:18.000000000,2016-03-05 19:47:26.000000000,2016-03-05 19:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-03-04 07:41:18.000000000', 'files': ['devstack/samples/local.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/c5c50827eebe91398b57ad9cc9d0677c9bcc404b', 'message': 'Use ""--pub-key"" instead of ""--pub_key""\n\nOption ""--pub_key"" is deprecated and will be removed in novaclient 3.3.0.\n\nChange-Id: Iaa6b12cbc3418dce40f689fb4812670784ea3018\n'}]",5,288285,c5c50827eebe91398b57ad9cc9d0677c9bcc404b,20,6,1,6116,,,0,"Use ""--pub-key"" instead of ""--pub_key""

Option ""--pub_key"" is deprecated and will be removed in novaclient 3.3.0.

Change-Id: Iaa6b12cbc3418dce40f689fb4812670784ea3018
",git fetch https://review.opendev.org/openstack/octavia refs/changes/85/288285/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/samples/local.sh'],1,c5c50827eebe91398b57ad9cc9d0677c9bcc404b,pub_key, nova keypair-add --pub-key=${DEVSTACK_LBAAS_SSH_KEY}.pub ${DEVSTACK_LBAAS_SSH_KEY_NAME}, nova keypair-add --pub_key=${DEVSTACK_LBAAS_SSH_KEY}.pub ${DEVSTACK_LBAAS_SSH_KEY_NAME},1,1
openstack%2Foctavia~master~I7dbbb95ae327abb24a3d25376020be41375a4609,openstack/octavia,master,I7dbbb95ae327abb24a3d25376020be41375a4609,Adds the Cascade Deelete REST API doc,MERGED,2016-03-02 21:17:59.000000000,2016-03-05 19:45:33.000000000,2016-03-05 19:39:45.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-02 21:17:59.000000000', 'files': ['doc/source/api/octaviaapi.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/62cb739f8e212ab86911a56ad054610867f4a0c9', 'message': 'Adds the Cascade Deelete REST API doc\n\nChange-Id: I7dbbb95ae327abb24a3d25376020be41375a4609\nCloses-Bug: #1551436\n'}]",0,287443,62cb739f8e212ab86911a56ad054610867f4a0c9,17,7,1,10850,,,0,"Adds the Cascade Deelete REST API doc

Change-Id: I7dbbb95ae327abb24a3d25376020be41375a4609
Closes-Bug: #1551436
",git fetch https://review.opendev.org/openstack/octavia refs/changes/43/287443/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/octaviaapi.rst'],1,62cb739f8e212ab86911a56ad054610867f4a0c9,bug/1551436,"Delete Load Balancer Cascade **************************** Delete a load balancer and all the underlying resources (e.g. listener, pool). +----------------+-------------------------------------------------+ | Request Type | ``DELETE`` | +----------------+-------------------------------------------------+ | Endpoint | ``URL/v1/loadbalancers/{lb_id}/delete_cascade`` | +----------------+---------+---------------------------------------+ | | Success | 202 | | Response Codes +---------+---------------------------------------+ | | Error | 401, 404, 409, 500 | +----------------+---------+---------------------------------------+ **No request/response body** ",,18,0
openstack%2Foctavia~master~I0c216addf9e85d512fd2fe689db1e819d183b36c,openstack/octavia,master,I0c216addf9e85d512fd2fe689db1e819d183b36c,Add release notes for L7 and shared pools,MERGED,2016-03-01 06:50:32.000000000,2016-03-05 19:43:38.000000000,2016-03-05 19:39:39.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-03-01 06:50:32.000000000', 'files': ['releasenotes/notes/add-shared-pools-and-l7-ef9edf01bb9058e0.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/feb7a375fc3487d8b9106d9bb4cf2302dfe9d7b6', 'message': 'Add release notes for L7 and shared pools\n\nThe previously-merged patches for L7 and shared pools did not include\nrelease notes. This commit adds the missing release notes.\n\nChange-Id: I0c216addf9e85d512fd2fe689db1e819d183b36c\nPartially-Implements: blueprint lbaas-l7-rules\n'}]",0,286410,feb7a375fc3487d8b9106d9bb4cf2302dfe9d7b6,17,6,1,11685,,,0,"Add release notes for L7 and shared pools

The previously-merged patches for L7 and shared pools did not include
release notes. This commit adds the missing release notes.

Change-Id: I0c216addf9e85d512fd2fe689db1e819d183b36c
Partially-Implements: blueprint lbaas-l7-rules
",git fetch https://review.opendev.org/openstack/octavia refs/changes/10/286410/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/add-shared-pools-and-l7-ef9edf01bb9058e0.yaml'],1,feb7a375fc3487d8b9106d9bb4cf2302dfe9d7b6,bp/lbaas-l7-rules,--- features: - | Adds support for Layer 7 switching and shared pools features to Octavia. This supports the equivalent feature added to Neutron LBaaS v2. * Layer 7 policies allow a tenant / user to define actions the load balancer may take other than routing requests to the default pool. * Layer 7 rules control the logic behind whether a given Layer 7 policy is followed. * Works for HTTP and TERMINATED_HTTPS listeners. * Shared pools allow listeners or Layer 7 REDIRECT_TO_POOL policies to share back-end pools. upgrade: - | Upgrade requires a database migration. * Shared-pools introduces a new ``load_balancer_id`` column into the ``pools`` table. * ``pools.load_balancer_id`` column is populated from ``listeners`` data using ETL in the migration. * Two new tables are created to handle Layer 7 switching. These are ``l7policy`` and ``l7rule``. ,,26,0
openstack%2Ffuel-specs~master~I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc,openstack/fuel-specs,master,I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc,Spec for fuel-remove-conflict-openstack,MERGED,2016-02-24 17:40:48.000000000,2016-03-05 19:24:32.000000000,2016-03-05 19:24:32.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8797}, {'_account_id': 9387}, {'_account_id': 14200}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-24 17:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/486f245c71abb7d2fdd08a5053b617e5a9da8566', 'message': 'Spec for fuel-remove-conflict-openstack\n\nChange-Id: I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc\nBlueprint: fuel-remove-conflict-openstack\n'}, {'number': 2, 'created': '2016-02-24 20:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d0cec534b23741d870b1143145e72ccd9ba1a68e', 'message': 'Spec for fuel-remove-conflict-openstack\n\nChange-Id: I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc\nBlueprint: fuel-remove-conflict-openstack\n'}, {'number': 3, 'created': '2016-03-01 00:07:00.000000000', 'files': ['specs/9.0/fuel-remove-conflict-openstack.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/40353ad5e69ed85d60162584912d763ccef3bb67', 'message': 'Spec for fuel-remove-conflict-openstack\n\nChange-Id: I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc\nBlueprint: fuel-remove-conflict-openstack\n'}]",9,284294,40353ad5e69ed85d60162584912d763ccef3bb67,21,9,3,8797,,,0,"Spec for fuel-remove-conflict-openstack

Change-Id: I8bb67c01580fe767f3f2f3d05808c8bff06a6ccc
Blueprint: fuel-remove-conflict-openstack
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/94/284294/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/9.0/fuel-remove-conflict-openstack.rst'],1,486f245c71abb7d2fdd08a5053b617e5a9da8566,bp/fuel-remove-conflict-openstack,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Remove conflicting openstack module parts ========================================== https://blueprints.launchpad.net/fuel/+spec/fuel-remove-conflict-openstack The openstack module `deployment/puppet/openstack` has been obsolete for a long time in puppet-openstack, and with the migration to the tasks composition layer in fuel, it is obsolete, making only more work for people who need to maintain manifests that intersect with it. Portions of the openstack module conflict with supporting detached OpenStack version (proper, not the module) as defined in `fuel-openstack-tasks`_ -------------------- Problem description -------------------- Some of the tasks make indirect calls to puppet-openstack modules via the openstack module. In these cases, overloading the tasks as described in `fuel-openstack-tasks`_ will not result in success as it depends on being able change the calls between the task and puppet-openstack to support a specific version of the puppet-openstack modules. In these cases the calls to puppet-openstack modules must be moved to the task itself and my not proxy through openstack module anymore In this way we would change: cinder task => openstack::cinder => ::cinder swift task => openstack::swift => ::swift ... It would become: cinder task => ::cinder swift task => ::swift ---------------- Proposed changes ---------------- As described in Problem description, we will remove the indirection in the openstack module. Web UI ====== None Nailgun ======= None Data model ---------- None Orchestration ============= None RPC Protocol ------------ None Fuel Client =========== None Plugins ======= None Fuel Library ============ At a minimum the following openstack module manifests have to be moved up to their corresponding task:: deployment/puppet/openstack/manifests/auth_file.pp deployment/puppet/openstack/manifests/ceilometer.pp deployment/puppet/openstack/manifests/cinder.pp deployment/puppet/openstack/manifests/compute.pp deployment/puppet/openstack/manifests/glance.pp deployment/puppet/openstack/manifests/ha/murano.pp deployment/puppet/openstack/manifests/heat.pp deployment/puppet/openstack/manifests/horizon.pp deployment/puppet/openstack/manifests/keystone.pp deployment/puppet/openstack/manifests/nova/controller.pp deployment/puppet/openstack/manifests/swift/proxy.pp ------------ Alternatives ------------ None -------------- Upgrade impact -------------- None --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------- End user impact --------------- None ------------------ Performance impact ------------------ None ----------------- Deployment impact ----------------- None ---------------- Developer impact ---------------- This will further reduce the tech debt around the openstack module by removing more code out of it. This will simplify the interaction between the task and the module it calls making it easier for new developers to work on fuel-library --------------------- Infrastructure impact --------------------- None -------------------- Documentation impact -------------------- None -------------- Implementation -------------- Assignee(s) =========== Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: Andrew Woodward (xarses) Other contributors: <launchpad-id or None> Mandatory design review: <launchpad-id or None> Work Items ========== * Further identify any additional of the openstack manifests that need to be worked on for 9.0 * remove impacted openstack manifests by moving their calls into their respective tasks. Dependencies ============ Related to `fuel-openstack-tasks`_ ------------ Testing, QA ------------ Existing testing coverage should be sufficient to ensure that there are no regressions introduced by these changes. Acceptance criteria =================== * Impacted openstack manifests previously identified no longer exist * puppet-openstack calls should not be inderect from tasks via the openstack module ---------- References ---------- https://blueprints.launchpad.net/fuel/+spec/fuel-openstack-tasks Spec for `fuel-openstack-tasks`_ .. _`fuel-openstack-tasks`: https://review.openstack.org/#/c/281557/ ",,242,0
openstack%2Fsahara~master~Iddd4a041345ed2fed821257b5fc3ffef8ba7231b,openstack/sahara,master,Iddd4a041345ed2fed821257b5fc3ffef8ba7231b,Updated from global requirements,MERGED,2016-03-05 15:37:53.000000000,2016-03-05 19:18:09.000000000,2016-03-05 18:28:47.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 15:37:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9dd4c2533366f95725f5c14044acc13176e4735e', 'message': 'Updated from global requirements\n\nChange-Id: Iddd4a041345ed2fed821257b5fc3ffef8ba7231b\n'}]",0,288898,9dd4c2533366f95725f5c14044acc13176e4735e,10,4,1,11131,,,0,"Updated from global requirements

Change-Id: Iddd4a041345ed2fed821257b5fc3ffef8ba7231b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/98/288898/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9dd4c2533366f95725f5c14044acc13176e4735e,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Fopenstack-ansible-specs~master~Iaec716ce29d58fbe22717b590d09fabae3d244fb,openstack/openstack-ansible-specs,master,Iaec716ce29d58fbe22717b590d09fabae3d244fb,Remove other-requirements from specs repo,MERGED,2016-03-05 14:22:08.000000000,2016-03-05 19:16:45.000000000,2016-03-05 19:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-05 14:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-specs/commit/27b7673059934ec295dfba5a13a932505766f7f9', 'message': 'Specs: Remove other-requirements\n\nIn the specs repo we have no need to set other-requirements, or to\noverride the defaults set in infra as the profile of the image used\nhere is much the same as any other specs repo.\n\nChange-Id: Iaec716ce29d58fbe22717b590d09fabae3d244fb\n'}, {'number': 2, 'created': '2016-03-05 14:22:33.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-specs/commit/6ffdf4ea528f08085e67b0e217453a095e17ba4c', 'message': 'Remove other-requirements from specs repo\n\nIn the specs repo we have no need to set other-requirements, or to\noverride the defaults set in infra as the profile of the image used\nhere is much the same as any other specs repo.\n\nChange-Id: Iaec716ce29d58fbe22717b590d09fabae3d244fb\n'}]",0,288870,6ffdf4ea528f08085e67b0e217453a095e17ba4c,7,2,2,6816,,,0,"Remove other-requirements from specs repo

In the specs repo we have no need to set other-requirements, or to
override the defaults set in infra as the profile of the image used
here is much the same as any other specs repo.

Change-Id: Iaec716ce29d58fbe22717b590d09fabae3d244fb
",git fetch https://review.opendev.org/openstack/openstack-ansible-specs refs/changes/70/288870/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,27b7673059934ec295dfba5a13a932505766f7f9,bindep-requirements,,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",0,16
openstack%2Foctavia~master~I69e1fbb6f625e3a9491ee9e69263ed578c03610f,openstack/octavia,master,I69e1fbb6f625e3a9491ee9e69263ed578c03610f,Fixed make sure to get IPv4 value by awk in sample local.sh file,MERGED,2016-02-24 04:24:16.000000000,2016-03-05 19:16:01.000000000,2016-03-05 19:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}, {'_account_id': 19383}, {'_account_id': 19414}]","[{'number': 1, 'created': '2016-02-24 04:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/37ce99b3e43335b319494e1ab3eba414b27ba96b', 'message': 'Fixed  invalid IP value get by awk in sample local.sh file\nCloses-bug: #1549091\n\nChange-Id: I69e1fbb6f625e3a9491ee9e69263ed578c03610f\n'}, {'number': 2, 'created': '2016-02-24 06:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ea7abd64edfb01e21846d069603fd9989de89fe8', 'message': 'Fixed  invalid IP value get by awk in sample local.sh file\n\nCloses-bug: #1549091\n\nChange-Id: I69e1fbb6f625e3a9491ee9e69263ed578c03610f\n'}, {'number': 3, 'created': '2016-02-25 04:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/40a736cf80375fd64d29593af171d86fb384a1e8', 'message': 'Fixed make sure to get IPv4 value by awk in sample local.sh file\n\nSince the end user may enable IPv6. the nova-show command will\ndisplay network information format randomly. this fix will make\nsure always get IPv4 value to avoid error in rest steps\n\nCloses-bug: #1549091\nChange-Id: I69e1fbb6f625e3a9491ee9e69263ed578c03610f\n'}, {'number': 4, 'created': '2016-02-25 04:31:42.000000000', 'files': ['devstack/samples/local.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/05b3f7dce74cd92051d6aaf00a277da772e6d8ff', 'message': 'Fixed make sure to get IPv4 value by awk in sample local.sh file\n\nSince the end user may enable IPv6. the nova-show command will\ndisplay network information format randomly. this fix will make\nsure always get IPv4 value to avoid error in rest steps\n\nCloses-bug: #1549091\nChange-Id: I69e1fbb6f625e3a9491ee9e69263ed578c03610f\n'}]",3,283929,05b3f7dce74cd92051d6aaf00a277da772e6d8ff,45,9,4,19414,,,0,"Fixed make sure to get IPv4 value by awk in sample local.sh file

Since the end user may enable IPv6. the nova-show command will
display network information format randomly. this fix will make
sure always get IPv4 value to avoid error in rest steps

Closes-bug: #1549091
Change-Id: I69e1fbb6f625e3a9491ee9e69263ed578c03610f
",git fetch https://review.opendev.org/openstack/octavia refs/changes/29/283929/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/samples/local.sh'],1,37ce99b3e43335b319494e1ab3eba414b27ba96b,sample_local.sh," IP1=$(nova show node1 | grep ""private network"" | awk '{print $6}') IP2=$(nova show node2 | grep ""private network"" | awk '{print $6}')"," IP1=$(nova show node1 | grep ""private network"" | awk '{print $5}') IP2=$(nova show node2 | grep ""private network"" | awk '{print $5}')",2,2
openstack%2Fopenstack-ansible-apt_package_pinning~master~I7fcd5db6fbc368c810646bd631e47fa807ceeb24,openstack/openstack-ansible-apt_package_pinning,master,I7fcd5db6fbc368c810646bd631e47fa807ceeb24,Add curl to bindep requirements,MERGED,2016-03-04 19:20:39.000000000,2016-03-05 19:15:09.000000000,2016-03-05 19:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:20:39.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-apt_package_pinning/commit/42ec14a411b26a3704adbd71208f58e2d6e0e6a8', 'message': 'Add curl to bindep requirements\n\nChange-Id: I7fcd5db6fbc368c810646bd631e47fa807ceeb24\n'}]",0,288657,42ec14a411b26a3704adbd71208f58e2d6e0e6a8,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I7fcd5db6fbc368c810646bd631e47fa807ceeb24
",git fetch https://review.opendev.org/openstack/openstack-ansible-apt_package_pinning refs/changes/57/288657/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,42ec14a411b26a3704adbd71208f58e2d6e0e6a8,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-openstack_hosts~master~Ie1c2b310b365b67dda92a26e51c247485779afa8,openstack/openstack-ansible-openstack_hosts,master,Ie1c2b310b365b67dda92a26e51c247485779afa8,Add curl to bindep requirements,MERGED,2016-03-04 19:21:46.000000000,2016-03-05 19:13:58.000000000,2016-03-05 19:13:58.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/b2efb5187f42bf00fd91621303d519316b35d323', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ie1c2b310b365b67dda92a26e51c247485779afa8\n'}, {'number': 2, 'created': '2016-03-04 20:18:33.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/de63e497aefcc89a9431a192709a339345698a5e', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ie1c2b310b365b67dda92a26e51c247485779afa8\n'}]",0,288664,de63e497aefcc89a9431a192709a339345698a5e,10,4,2,6816,,,0,"Add curl to bindep requirements

Change-Id: Ie1c2b310b365b67dda92a26e51c247485779afa8
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/64/288664/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,b2efb5187f42bf00fd91621303d519316b35d323,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",,16,0
openstack%2Fopenstack-ansible-os_ironic~master~Ifba4bffde046d5fd6db1234af0becb4e44a71278,openstack/openstack-ansible-os_ironic,master,Ifba4bffde046d5fd6db1234af0becb4e44a71278,Add curl to bindep requirements,MERGED,2016-03-04 19:21:07.000000000,2016-03-05 19:12:51.000000000,2016-03-05 19:12:51.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:21:07.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/2bd2be25b806d4165046dd3c73b4d4727d0a74e5', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ifba4bffde046d5fd6db1234af0becb4e44a71278\n'}]",0,288660,2bd2be25b806d4165046dd3c73b4d4727d0a74e5,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ifba4bffde046d5fd6db1234af0becb4e44a71278
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/60/288660/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,2bd2be25b806d4165046dd3c73b4d4727d0a74e5,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-memcached_server~master~I98faa98e2f4f65309ba58564cce0386b563e7d4d,openstack/openstack-ansible-memcached_server,master,I98faa98e2f4f65309ba58564cce0386b563e7d4d,Add curl to bindep requirements,MERGED,2016-03-04 19:21:35.000000000,2016-03-05 19:12:46.000000000,2016-03-05 19:12:46.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:21:35.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/f26ca795b0e3f287b1a7eb77bab3f1935221f72c', 'message': 'Add curl to bindep requirements\n\nChange-Id: I98faa98e2f4f65309ba58564cce0386b563e7d4d\n'}]",0,288663,f26ca795b0e3f287b1a7eb77bab3f1935221f72c,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I98faa98e2f4f65309ba58564cce0386b563e7d4d
",git fetch https://review.opendev.org/openstack/openstack-ansible-memcached_server refs/changes/63/288663/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,f26ca795b0e3f287b1a7eb77bab3f1935221f72c,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-openstack_openrc~master~I3851e39f8c109c4ac78ec1ab621868e5e29ea4c0,openstack/openstack-ansible-openstack_openrc,master,I3851e39f8c109c4ac78ec1ab621868e5e29ea4c0,Add curl to bindep requirements,MERGED,2016-03-04 19:21:56.000000000,2016-03-05 19:12:28.000000000,2016-03-05 19:12:28.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:21:56.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_openrc/commit/997b6775b37ed8ad3a757a58d93d1be50fded0ea', 'message': 'Add curl to bindep requirements\n\nChange-Id: I3851e39f8c109c4ac78ec1ab621868e5e29ea4c0\n'}]",0,288665,997b6775b37ed8ad3a757a58d93d1be50fded0ea,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I3851e39f8c109c4ac78ec1ab621868e5e29ea4c0
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_openrc refs/changes/65/288665/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,997b6775b37ed8ad3a757a58d93d1be50fded0ea,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_aodh~master~I8f33162663651ec590fcf3b0b5f69ea5fb8f010d,openstack/openstack-ansible-os_aodh,master,I8f33162663651ec590fcf3b0b5f69ea5fb8f010d,Add curl to bindep requirements,MERGED,2016-03-04 19:22:06.000000000,2016-03-05 19:12:03.000000000,2016-03-05 19:12:02.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:06.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/0f2420a5a6139188103cbffce4f3be2e9db323b4', 'message': 'Add curl to bindep requirements\n\nChange-Id: I8f33162663651ec590fcf3b0b5f69ea5fb8f010d\n'}]",0,288666,0f2420a5a6139188103cbffce4f3be2e9db323b4,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I8f33162663651ec590fcf3b0b5f69ea5fb8f010d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/66/288666/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,0f2420a5a6139188103cbffce4f3be2e9db323b4,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_ceilometer~master~I4caa61674313c87d4f859f53ddd9fdced5882ff9,openstack/openstack-ansible-os_ceilometer,master,I4caa61674313c87d4f859f53ddd9fdced5882ff9,Add curl to bindep requirements,MERGED,2016-03-04 19:22:15.000000000,2016-03-05 19:11:54.000000000,2016-03-05 19:11:54.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:15.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/520feadfe82391c8f48d33242f04ae5f6cc81245', 'message': 'Add curl to bindep requirements\n\nChange-Id: I4caa61674313c87d4f859f53ddd9fdced5882ff9\n'}]",0,288668,520feadfe82391c8f48d33242f04ae5f6cc81245,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I4caa61674313c87d4f859f53ddd9fdced5882ff9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/68/288668/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,520feadfe82391c8f48d33242f04ae5f6cc81245,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I0be2139b6dc266a27bc14d68e60232d0e40844b1,openstack/openstack-ansible-lxc_hosts,master,I0be2139b6dc266a27bc14d68e60232d0e40844b1,Create /openstack/log base directory,MERGED,2016-03-05 17:37:12.000000000,2016-03-05 19:10:16.000000000,2016-03-05 19:10:16.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-05 17:37:12.000000000', 'files': ['tasks/lxc_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/9f70d44360cf9d96e6bb973ec73ef15f8d1ba86b', 'message': ""Create /openstack/log base directory\n\nEach container makes use of a subdirectory underneath the host's\n/openstack/log directory as a mount point for /var/log. Ensure that this\nbase directory is created upfront on each LXC host to avoid a potential\nrace condition when containers recursively create their subdirectories.\n\nChange-Id: I0be2139b6dc266a27bc14d68e60232d0e40844b1\n""}]",0,288918,9f70d44360cf9d96e6bb973ec73ef15f8d1ba86b,8,3,1,14805,,,0,"Create /openstack/log base directory

Each container makes use of a subdirectory underneath the host's
/openstack/log directory as a mount point for /var/log. Ensure that this
base directory is created upfront on each LXC host to avoid a potential
race condition when containers recursively create their subdirectories.

Change-Id: I0be2139b6dc266a27bc14d68e60232d0e40844b1
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/18/288918/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_pre_install.yml'],1,9f70d44360cf9d96e6bb973ec73ef15f8d1ba86b,race_condition, - /openstack/log,,1,0
openstack%2Fopenstack-ansible-os_glance~master~I250d15e3fdd54f4d4e581c5ced48ece7f8348261,openstack/openstack-ansible-os_glance,master,I250d15e3fdd54f4d4e581c5ced48ece7f8348261,Add curl to bindep requirements,MERGED,2016-03-04 19:22:35.000000000,2016-03-05 19:10:09.000000000,2016-03-05 19:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:35.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/6214801a2e645d24d83d01b74310472c65fc67b4', 'message': 'Add curl to bindep requirements\n\nChange-Id: I250d15e3fdd54f4d4e581c5ced48ece7f8348261\n'}]",0,288671,6214801a2e645d24d83d01b74310472c65fc67b4,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I250d15e3fdd54f4d4e581c5ced48ece7f8348261
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/71/288671/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,6214801a2e645d24d83d01b74310472c65fc67b4,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_cinder~master~Id9b0cdfb028a199b3bdb734e204178622fa422e7,openstack/openstack-ansible-os_cinder,master,Id9b0cdfb028a199b3bdb734e204178622fa422e7,Add curl to bindep requirements,MERGED,2016-03-04 19:22:24.000000000,2016-03-05 19:09:56.000000000,2016-03-05 19:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:24.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/2713a9528bce738dfbba00f251972aa00c06f8ad', 'message': 'Add curl to bindep requirements\n\nChange-Id: Id9b0cdfb028a199b3bdb734e204178622fa422e7\n'}]",0,288670,2713a9528bce738dfbba00f251972aa00c06f8ad,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Id9b0cdfb028a199b3bdb734e204178622fa422e7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/70/288670/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,2713a9528bce738dfbba00f251972aa00c06f8ad,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_heat~master~Ib003b1d089e82db606f6f35610cbd0bd874d7020,openstack/openstack-ansible-os_heat,master,Ib003b1d089e82db606f6f35610cbd0bd874d7020,Add curl to bindep requirements,MERGED,2016-03-04 19:22:45.000000000,2016-03-05 19:09:32.000000000,2016-03-05 19:09:32.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:45.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/540a425d7f3876e847712b08e93470ec2b7378e4', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ib003b1d089e82db606f6f35610cbd0bd874d7020\n'}]",0,288672,540a425d7f3876e847712b08e93470ec2b7378e4,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ib003b1d089e82db606f6f35610cbd0bd874d7020
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/72/288672/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,540a425d7f3876e847712b08e93470ec2b7378e4,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_horizon~master~Ieb83c641ed6847f1900e092b10ca2645d3d9c080,openstack/openstack-ansible-os_horizon,master,Ieb83c641ed6847f1900e092b10ca2645d3d9c080,Add curl to bindep requirements,MERGED,2016-03-04 19:22:54.000000000,2016-03-05 19:09:21.000000000,2016-03-05 19:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:22:54.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/f1284f02f7cc7a02ce948de6d540eaf62a6ff06e', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ieb83c641ed6847f1900e092b10ca2645d3d9c080\n'}]",0,288673,f1284f02f7cc7a02ce948de6d540eaf62a6ff06e,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ieb83c641ed6847f1900e092b10ca2645d3d9c080
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/73/288673/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,f1284f02f7cc7a02ce948de6d540eaf62a6ff06e,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_keystone~master~I7abb4a1f3ce21192ca0e9fdccd88668ba35ab27e,openstack/openstack-ansible-os_keystone,master,I7abb4a1f3ce21192ca0e9fdccd88668ba35ab27e,Add curl to bindep requirements,MERGED,2016-03-04 19:23:05.000000000,2016-03-05 19:09:06.000000000,2016-03-05 19:09:06.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:23:05.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/21fdea57fb859320adfce8399ccde420875ded65', 'message': 'Add curl to bindep requirements\n\nChange-Id: I7abb4a1f3ce21192ca0e9fdccd88668ba35ab27e\n'}]",0,288675,21fdea57fb859320adfce8399ccde420875ded65,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I7abb4a1f3ce21192ca0e9fdccd88668ba35ab27e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/75/288675/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,21fdea57fb859320adfce8399ccde420875ded65,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_neutron~master~Iab77869567641f20a67584baa1ba9e0b70b64e01,openstack/openstack-ansible-os_neutron,master,Iab77869567641f20a67584baa1ba9e0b70b64e01,Add curl to bindep requirements,MERGED,2016-03-04 19:23:15.000000000,2016-03-05 19:08:56.000000000,2016-03-05 19:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:23:15.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/62070394d02a3b109384e96d715b1373cde72e5d', 'message': 'Add curl to bindep requirements\n\nChange-Id: Iab77869567641f20a67584baa1ba9e0b70b64e01\n'}]",0,288677,62070394d02a3b109384e96d715b1373cde72e5d,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Iab77869567641f20a67584baa1ba9e0b70b64e01
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/77/288677/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,62070394d02a3b109384e96d715b1373cde72e5d,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fnova~master~Iabf21e51ceecb476c651553f86de4750fe95ef4c,openstack/nova,master,Iabf21e51ceecb476c651553f86de4750fe95ef4c,Nova.cells.messaging.instance_update_at_top assuming instance object resolved,ABANDONED,2015-12-01 20:19:32.000000000,2016-03-05 19:00:21.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 18336}]","[{'number': 1, 'created': '2015-12-01 20:19:32.000000000', 'files': ['nova/cells/messaging.py', 'nova/tests/unit/cells/test_cells_messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a2abd9e0d8914a93279ac9777997c8c0384bb944', 'message': 'Nova.cells.messaging.instance_update_at_top assuming instance object resolved\n\nNova.cells.messaging.instance_updatea_at_top allways assumes the instance parameter\nas an object but sometimes it gets dictionary of instances. This patch resolves the\nissue by checking the type of instance parameter and converts it to object if it is\nnot an object\n\nChange-Id: Iabf21e51ceecb476c651553f86de4750fe95ef4c\nCloses-Bug: 1514550\n'}]",3,252045,a2abd9e0d8914a93279ac9777997c8c0384bb944,16,10,1,18336,,,0,"Nova.cells.messaging.instance_update_at_top assuming instance object resolved

Nova.cells.messaging.instance_updatea_at_top allways assumes the instance parameter
as an object but sometimes it gets dictionary of instances. This patch resolves the
issue by checking the type of instance parameter and converts it to object if it is
not an object

Change-Id: Iabf21e51ceecb476c651553f86de4750fe95ef4c
Closes-Bug: 1514550
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/252045/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/cells/messaging.py', 'nova/tests/unit/cells/test_cells_messaging.py']",2,a2abd9e0d8914a93279ac9777997c8c0384bb944,bug/1514550," def test_instance_update_at_top_with_primitive_data(self): fake_uuid = fake_server_actions.FAKE_UUID fake_info_cache = objects.InstanceInfoCache(instance_uuid='fake-uuid') fake_sys_metadata = {'key1': 'value1', 'key2': 'value2'} fake_attrs = { 'uuid': fake_uuid, 'cell_name': 'fake', 'info_cache': fake_info_cache, 'system_metadata': fake_sys_metadata, } fake_instance = objects.Instance(**fake_attrs) fake_instance_primitive = fake_attrs fake_instance_primitive = dict(objects_base.obj_to_primitive(fake_instance_primitive)) result = self.src_msg_runner.instance_update_at_top(self.ctxt, instance=fake_instance_primitive) ",,19,0
openstack%2Fcinder~master~I989f9d591d1483a56a1bab3c20de583e85997562,openstack/cinder,master,I989f9d591d1483a56a1bab3c20de583e85997562,Copy StandardLogging fixture from Nova,MERGED,2016-02-29 17:32:18.000000000,2016-03-05 18:58:32.000000000,2016-03-01 11:45:58.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 19146}]","[{'number': 1, 'created': '2016-02-29 17:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ea130db8c5ad68c45166733f54abf16cd4a1617', 'message': 'WIP: Copy StandardLogging fixture from Nova\n\nChange-Id: I989f9d591d1483a56a1bab3c20de583e85997562\nRelated-Bug: #1551325\n'}, {'number': 2, 'created': '2016-02-29 18:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/274ae6e3dd658af5f9139e414c73365ddb5616eb', 'message': 'Copy StandardLogging fixture from Nova\n\nThis code was originally written for Nova by Joe Gordon\n<joe.gordon0@gmail.com> and Sean Dague <sean@dague.net>.\n\nThis enables debug logging that is exercised by unit test\nruns to be handled and detect formatting errors. The debug\nlogging does not actually go to the console unless the\nOS_DEBUG environment variable is set.\n\nChange-Id: I989f9d591d1483a56a1bab3c20de583e85997562\nRelated-Bug: #1551325\n'}, {'number': 3, 'created': '2016-02-29 18:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8226ff3d0baf2d18417dbfb3014f3b7ae01f957b', 'message': 'Copy StandardLogging fixture from Nova\n\nThis code was originally written for Nova by Joe Gordon\n<joe.gordon0@gmail.com> and Sean Dague <sean@dague.net>.\n\nThis enables debug logging that is exercised by unit test\nruns to be handled and detect formatting errors. The debug\nlogging does not actually go to the console unless the\nOS_DEBUG environment variable is set.\n\nAs a result, a few formatting errors are detected and\ncleaned up with this change.\n\nChange-Id: I989f9d591d1483a56a1bab3c20de583e85997562\nRelated-Bug: #1551325\n'}, {'number': 4, 'created': '2016-02-29 22:47:33.000000000', 'files': ['cinder/tests/fixtures.py', 'cinder/test.py', 'cinder/volume/drivers/hpe/hpe_lefthand_iscsi.py', 'cinder/tests/unit/test_vmware_vmdk.py', 'cinder/backup/chunkeddriver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/32719d4041fd547a41673539c62e5b76704c8cf8', 'message': 'Copy StandardLogging fixture from Nova\n\nThis code was originally written for Nova by Joe Gordon\n<joe.gordon0@gmail.com> and Sean Dague <sean@dague.net>.\n\nThis enables debug logging that is exercised by unit test\nruns to be handled and detect formatting errors. The debug\nlogging does not actually go to the console unless the\nOS_DEBUG environment variable is set.\n\nAs a result, a few formatting errors are detected and\ncleaned up with this change.\n\nThis also fixes a problem where debug logging from stevedore\nis dumped to the console every time an extension is loaded,\nwhich in a gate-cinder-python27 job is 65K+ times.\n\nChange-Id: I989f9d591d1483a56a1bab3c20de583e85997562\nCloses-Bug: #1551325\n'}]",0,286174,32719d4041fd547a41673539c62e5b76704c8cf8,42,18,4,6873,,,0,"Copy StandardLogging fixture from Nova

This code was originally written for Nova by Joe Gordon
<joe.gordon0@gmail.com> and Sean Dague <sean@dague.net>.

This enables debug logging that is exercised by unit test
runs to be handled and detect formatting errors. The debug
logging does not actually go to the console unless the
OS_DEBUG environment variable is set.

As a result, a few formatting errors are detected and
cleaned up with this change.

This also fixes a problem where debug logging from stevedore
is dumped to the console every time an extension is loaded,
which in a gate-cinder-python27 job is 65K+ times.

Change-Id: I989f9d591d1483a56a1bab3c20de583e85997562
Closes-Bug: #1551325
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/286174/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/fixtures.py', 'cinder/test.py']",2,6ea130db8c5ad68c45166733f54abf16cd4a1617,bug/1551325,from cinder.tests import fixtures as cinder_fixtures self.useFixture(cinder_fixtures.StandardLogging())," if environ_enabled('OS_LOG_CAPTURE'): log_format = '%(levelname)s [%(name)s] %(message)s' if environ_enabled('OS_DEBUG'): level = logging.DEBUG else: level = logging.INFO self.useFixture(fixtures.LoggerFixture(nuke_handlers=False, format=log_format, level=level)) def log_level(self, level): """"""Set logging level to the specified value."""""" log_root = logging.getLogger(None).logger log_root.setLevel(level) ",104,14
openstack%2Fproject-config~master~Ib337cefe9367a7b3c33604d6b2d92d20c660abe8,openstack/project-config,master,Ib337cefe9367a7b3c33604d6b2d92d20c660abe8,Grafana for OSIC,MERGED,2016-03-05 03:37:01.000000000,2016-03-05 18:52:24.000000000,2016-03-05 18:52:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 03:37:01.000000000', 'files': ['grafana/nodepool-osic.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b3068677f7f783f430913e3af744a9d66b924d13', 'message': 'Grafana for OSIC\n\nAdd Grafana dashboard for osic nodepool resources.\n\nChange-Id: Ib337cefe9367a7b3c33604d6b2d92d20c660abe8\n'}]",0,288832,b3068677f7f783f430913e3af744a9d66b924d13,8,4,1,4146,,,0,"Grafana for OSIC

Add Grafana dashboard for osic nodepool resources.

Change-Id: Ib337cefe9367a7b3c33604d6b2d92d20c660abe8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/32/288832/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/nodepool-osic.yaml'],1,b3068677f7f783f430913e3af744a9d66b924d13,grafana-osic,"dashboard: title: 'Nodepool: OSIC' rows: - title: Description height: 100px panels: - title: Description content: | **This dashboard is managed by [Grafyaml](http://docs.openstack.org/infra/system-config/grafyaml.html).** If you would like to make changes to this dashboard, please see the grafana directory in [project-config](https://git.openstack.org/cgit/openstack-infra/project-config/tree/grafana/nodepool-osic.yaml). type: text - title: Nodes showTitle: true height: 150px panels: - title: Building span: 3 sparkline: full: true show: true targets: - target: sumSeries(stats.gauges.nodepool.provider.osic-*.nodes.building) type: singlestat valueName: current - title: Ready span: 3 sparkline: full: true show: true targets: - target: sumSeries(stats.gauges.nodepool.provider.osic-*.nodes.ready) type: singlestat valueName: current - title: In Use span: 3 sparkline: full: true show: true targets: - target: sumSeries(stats.gauges.nodepool.provider.osic-*.nodes.used) type: singlestat valueName: current - title: Deleting span: 3 sparkline: full: true show: true targets: - target: sumSeries(stats.gauges.nodepool.provider.osic-*.nodes.delete) type: singlestat valueName: current - title: API Operations showTitle: true height: 250px panels: - title: Create Server type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.CreateServerTask.mean, '0.001'), 'YMQ') - title: Delete Server type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.DeleteServerTask.mean, '0.001'), 'YMQ') - title: List Servers type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.task.osic-cloud1.ListServersTask.mean, '0.001'), 'YMQ') - title: Node Launches showTitle: true height: 250px panels: - title: Ready Node Launch Attempts type: graph span: 4 nullPointMode: null as zero leftYAxisLabel: ""events / min"" targets: - target: alias(smartSummarize(stats_counts.nodepool.launch.provider.osic-cloud1.ready, '1m'), 'YMQ') - title: Error Node Launch Attempts type: graph span: 4 nullPointMode: null as zero leftYAxisLabel: ""events / min"" targets: - target: alias(smartSummarize(sumSeries(stats_counts.nodepool.launch.provider.osic-cloud1.error.*), '1m'), 'YMQ') - title: Time to Ready type: graph span: 4 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.launch.provider.osic-cloud1.ready.mean, '0.001'), 'YMQ') - title: Test Nodes (YMQ) type: graph span: 4 stack: true tooltip: value_type: individual leftYAxisLabel: ""nodes"" targets: - target: alias(stats.gauges.nodepool.provider.osic-cloud1.nodes.building, 'Building') - target: alias(stats.gauges.nodepool.provider.osic-cloud1.nodes.ready, 'Available') - target: alias(stats.gauges.nodepool.provider.osic-cloud1.nodes.used, 'In Use') - target: alias(stats.gauges.nodepool.provider.osic-cloud1.nodes.delete, 'Deleting') - target: alias(stats.gauges.nodepool.provider.osic-cloud1.max_servers, 'Max') seriesOverrides: - alias: Max stack: False - title: Job Runtimes showTitle: true height: 250px panels: - title: gate-tempest-dsvm-full type: graph span: 6 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'YMQ') - title: gate-tempest-dsvm-neutron-full type: graph span: 6 leftYAxisLabel: ""time"" y_formats: - s - none targets: - target: alias(scale(stats.timers.nodepool.job.gate-tempest-dsvm-neutron-full.master.devstack-trusty.osic-cloud1.runtime.mean, '0.001'), 'YMQ') ",,148,0
openstack%2Fheat~master~I6e6795374133d8634a30c8650700eb8b9db892f8,openstack/heat,master,I6e6795374133d8634a30c8650700eb8b9db892f8,Regenerated heat_integrationtests.conf.sample,MERGED,2016-03-02 03:49:12.000000000,2016-03-05 18:51:14.000000000,2016-03-05 18:51:14.000000000,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 10487}, {'_account_id': 12259}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-03-02 03:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/617d299211906b35132f5bcdebd430a3fe776551', 'message': 'Regenerated heat_integrationtests.conf.sample\n\nIt seems heat_integrationtests.conf.sample is not in sync with\nsome recent config.py changes.\n\nChange-Id: I6e6795374133d8634a30c8650700eb8b9db892f8\n'}, {'number': 2, 'created': '2016-03-03 14:39:34.000000000', 'files': ['heat_integrationtests/heat_integrationtests.conf.sample'], 'web_link': 'https://opendev.org/openstack/heat/commit/e924849b3e3ab815b335eb8f8ab0f594dc8a52b4', 'message': 'Regenerated heat_integrationtests.conf.sample\n\nIt seems heat_integrationtests.conf.sample is not in sync with\nsome recent config.py changes.\n\nChange-Id: I6e6795374133d8634a30c8650700eb8b9db892f8\n'}]",0,286965,e924849b3e3ab815b335eb8f8ab0f594dc8a52b4,19,5,2,8833,,,0,"Regenerated heat_integrationtests.conf.sample

It seems heat_integrationtests.conf.sample is not in sync with
some recent config.py changes.

Change-Id: I6e6795374133d8634a30c8650700eb8b9db892f8
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/286965/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/heat_integrationtests.conf.sample'],1,617d299211906b35132f5bcdebd430a3fe776551,fix_conf,"# Username to use for API requests. (string value) #username = <None> # API key to use when authenticating. (string value) #password = <None> # Tenant name to use for API requests. (string value) #tenant_name = <None> # Full URI of the OpenStack Identity API (Keystone) (string value) #auth_url = <None> # User/project domain name, if keystone v3 auth_urlis used (string value) #domain_name = default # The region name to use (string value) #region = <None> # Instance type for tests. Needs to be big enough for a full OS plus the test # workload (string value) #instance_type = <None> # Instance type enough for simplest cases. (string value) #minimal_instance_type = <None> # Name of image to use for tests which boot servers. (string value) #image_ref = <None> # Name of existing keypair to launch servers with. (string value) #keypair_name = <None> # Name of minimal (e.g cirros) image to use when launching test instances. # (string value) #minimal_image_ref = <None># List of scenario test class or class.method names to skip ex. # NeutronLoadBalancerTest, CeilometerAlarmTest.test_alarm (list value) #skip_scenario_test_list = <None> # List of stack actions in tests to skip ex. ABANDON, ADOPT, SUSPEND, RESUME # (list value) #skip_test_stack_action_list = <None> # Default size in GB for volumes created by volumes tests (integer value) #volume_size = 1 # Timeout in seconds to wait for connectivity to server. (integer value) #connectivity_timeout = 120 # Timeout in seconds to wait for adding or removing childprocess after # receiving of sighup signal (integer value) #sighup_timeout = 30 # Path to the script heat-config-notify (string value) #heat_config_notify_script = heat-config-notify","# List of scenario test class or class.method names to skip ex. # NeutronLoadBalancerTest, CeilometerAlarmTest.test_alarm (list value) #skip_scenario_test_list = <None># Timeout in seconds to wait for adding or removing childprocess after # receiving of sighup signal (integer value) #sighup_timeout = 30 # Default size in GB for volumes created by volumes tests (integer value) #volume_size = 1 # Timeout in seconds to wait for connectivity to server. (integer value) #connectivity_timeout = 120 # Username to use for API requests. (string value) #username = <None> # API key to use when authenticating. (string value) #password = <None> # Tenant name to use for API requests. (string value) #tenant_name = <None> # Full URI of the OpenStack Identity API (Keystone), v2 (string value) #auth_url = <None> # The region name to us (string value) #region = <None> # Instance type for tests. Needs to be big enough for a full OS plus the test # workload (string value) #instance_type = <None> # Instance type enough for simplest cases. (string value) #minimal_instance_type = <None> # Name of image to use for tests which boot servers. (string value) #image_ref = <None> # List of stack actions in tests to skip ex. ABANDON, ADOPT, SUSPEND, RESUME # (list value) #skip_test_stack_action_list = <None> # Name of existing keypair to launch servers with. (string value) #keypair_name = <None> # Name of minimal (e.g cirros) image to use when launching test instances. # (string value) #minimal_image_ref = <None> # Identity API version to be used for authentication for API tests. (string # value) #auth_version = v2",54,52
openstack%2Frequirements~master~I370d263eed5c337b284e07819c0f46638f89fa4d,openstack/requirements,master,I370d263eed5c337b284e07819c0f46638f89fa4d,Remove other-requirements.txt,ABANDONED,2016-03-05 18:07:57.000000000,2016-03-05 18:41:27.000000000,,[],"[{'number': 1, 'created': '2016-03-05 18:07:57.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a2ef88979e6e00d483f059b188cf01eef1c5294e', 'message': 'Remove other-requirements.txt\n\nThis file will only work on Ubuntu, it needs further work to be used\neverywhere. Also, our CI systems are not ready yet for full usage.\nRemove the file, it can be readded later once everything is prepared for\nit.\n\nChange-Id: I370d263eed5c337b284e07819c0f46638f89fa4d\n'}]",0,288923,a2ef88979e6e00d483f059b188cf01eef1c5294e,3,0,1,6547,,,0,"Remove other-requirements.txt

This file will only work on Ubuntu, it needs further work to be used
everywhere. Also, our CI systems are not ready yet for full usage.
Remove the file, it can be readded later once everything is prepared for
it.

Change-Id: I370d263eed5c337b284e07819c0f46638f89fa4d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/288923/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,a2ef88979e6e00d483f059b188cf01eef1c5294e,bindep,,"# These are needed to build all the things in global-requirements, which we do # for integration testing. (see tools/integration.sh) python-all-dev python3-all-dev libvirt-dev libxml2-dev libxslt1-dev libmysqlclient-dev mysql-client mysql-server libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev libldap2-dev libsasl2-dev ccache postgresql postgresql-client pypy pypy-dev # NOTE(flaper87): Temporarily needed for proton uuid-dev swig # Python things that change rarely and we're willing to risk breakage vs latest python-numpy [python] python-yaml [python] ",0,29
openstack%2Frequirements~stable%2Fliberty~I370d263eed5c337b284e07819c0f46638f89fa4d,openstack/requirements,stable/liberty,I370d263eed5c337b284e07819c0f46638f89fa4d,Remove other-requirements.txt,ABANDONED,2016-03-05 18:13:13.000000000,2016-03-05 18:41:23.000000000,,[],"[{'number': 1, 'created': '2016-03-05 18:13:13.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/11c0b364a2608bd228b48698d3097a4fd232cebe', 'message': 'Remove other-requirements.txt\n\nThis file will only work on Ubuntu, it needs further work to be used\neverywhere. Also, our CI systems are not ready yet for full usage.\nRemove the file, it can be readded later once everything is prepared for\nit.\n\nChange-Id: I370d263eed5c337b284e07819c0f46638f89fa4d\n(cherry picked from commit a2ef88979e6e00d483f059b188cf01eef1c5294e)\n'}]",0,288924,11c0b364a2608bd228b48698d3097a4fd232cebe,3,0,1,6547,,,0,"Remove other-requirements.txt

This file will only work on Ubuntu, it needs further work to be used
everywhere. Also, our CI systems are not ready yet for full usage.
Remove the file, it can be readded later once everything is prepared for
it.

Change-Id: I370d263eed5c337b284e07819c0f46638f89fa4d
(cherry picked from commit a2ef88979e6e00d483f059b188cf01eef1c5294e)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/288924/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,11c0b364a2608bd228b48698d3097a4fd232cebe,bindep,,"# These are needed to build all the things in global-requirements, which we do # for integration testing (see tools/integration.sh. python-all-dev python3-all-dev libvirt-dev libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev libldap2-dev libsasl2-dev ccache # NOTE(flaper87): Temporarly needed for proton uuid-dev swig # Python things that change rarely and we're willing to risk breakage vs latest python-numpy [python] python-yaml [python] ",0,23
openstack%2Fpython-saharaclient~master~I53ea6d6f4edf9d7654a9a2866afec7e30602e888,openstack/python-saharaclient,master,I53ea6d6f4edf9d7654a9a2866afec7e30602e888,Updated from global requirements,MERGED,2016-03-03 18:06:36.000000000,2016-03-05 18:41:10.000000000,2016-03-05 18:41:10.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-03 18:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/8c7282ab45038eef7491c4c8f792113ce63e7372', 'message': 'Updated from global requirements\n\nChange-Id: I53ea6d6f4edf9d7654a9a2866afec7e30602e888\n'}, {'number': 2, 'created': '2016-03-05 15:37:26.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/6a5f3e12899612d5f39902b25fa3749f3bd4ed06', 'message': 'Updated from global requirements\n\nChange-Id: I53ea6d6f4edf9d7654a9a2866afec7e30602e888\n'}]",0,288034,6a5f3e12899612d5f39902b25fa3749f3bd4ed06,12,3,2,11131,,,0,"Updated from global requirements

Change-Id: I53ea6d6f4edf9d7654a9a2866afec7e30602e888
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/34/288034/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8c7282ab45038eef7491c4c8f792113ce63e7372,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Fmagnum~master~Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf,openstack/magnum,master,Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf,limit access to certificate and container:create,MERGED,2016-02-26 06:49:02.000000000,2016-03-05 18:39:10.000000000,2016-03-05 18:39:09.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 18386}]","[{'number': 1, 'created': '2016-02-26 06:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/eb0d08ff0cfa887304ecea355af5b1b30648340c', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 2, 'created': '2016-02-26 06:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3b213cad96796b77ddb0aa42b073f5b151797374', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 3, 'created': '2016-02-26 07:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b61007353fbc9c85fded1ac7dfd4ae33a60e835e', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 4, 'created': '2016-02-26 09:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/70e38e257a871b6abe37f80ddd21a2ea9d7403dc', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 5, 'created': '2016-02-27 03:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/32708c238a8c6014c08b6671e9d5eccc69e06b51', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 6, 'created': '2016-02-27 03:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fa1f9a7435050a0d801c799e198736a9b4327ca7', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: ##1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 7, 'created': '2016-02-29 06:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2c69d7ed831d24fea1f83c6422f8a9269eda1fbb', 'message': 'limit access to certificate and container:create\n\nOnly the user who create the bay can create and get the certificate\nof the bay and create containers in the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: #1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}, {'number': 8, 'created': '2016-03-03 07:03:33.000000000', 'files': ['magnum/tests/unit/api/controllers/v1/test_certificate.py', 'magnum/api/controllers/v1/container.py', 'magnum/api/controllers/v1/certificate.py', 'etc/magnum/policy.json', 'magnum/tests/unit/api/controllers/v1/test_container.py', 'magnum/tests/unit/objects/utils.py', 'magnum/common/policy.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/ce5b55dd31a72a65d9fc3b37576a980b4ed73638', 'message': 'limit access to certificate and container:create\n\nOnly the user who creates the bay can get the certificate and call\nthe certificate signing request of the bay and create containers\nin the bay, which is needed by [1].\n\n[1] https://github.com/openstack/magnum/blob/master/specs/\n    create-trustee-user-for-each-bay.rst\n\nChange-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf\nCloses-Bug: #1536883\nPartially-Implements: blueprint create-trustee-user-for-each-bay\n'}]",6,285136,ce5b55dd31a72a65d9fc3b37576a980b4ed73638,30,5,8,12053,,,0,"limit access to certificate and container:create

Only the user who creates the bay can get the certificate and call
the certificate signing request of the bay and create containers
in the bay, which is needed by [1].

[1] https://github.com/openstack/magnum/blob/master/specs/
    create-trustee-user-for-each-bay.rst

Change-Id: Id959b76cb136ffbb0e6bcb8c3b83e02b30de66cf
Closes-Bug: #1536883
Partially-Implements: blueprint create-trustee-user-for-each-bay
",git fetch https://review.opendev.org/openstack/magnum refs/changes/36/285136/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/controllers/v1/test_certificate.py', 'magnum/api/controllers/v1/container.py', 'magnum/api/controllers/v1/certificate.py', 'etc/magnum/policy.json', 'magnum/common/policy.py']",5,eb0d08ff0cfa887304ecea355af5b1b30648340c,bug/1536883," do_raise=True, exc=exception.PolicyNotAuthorized, *args, **kwargs):"," do_raise=True, exc=None, *args, **kwargs):",33,24
openstack%2Fproject-config~master~I24896b292700a5ce8b83137be6b61b10ccead2eb,openstack/project-config,master,I24896b292700a5ce8b83137be6b61b10ccead2eb,Use entire osic quota,MERGED,2016-03-05 18:05:03.000000000,2016-03-05 18:34:03.000000000,2016-03-05 18:34:02.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6554}]","[{'number': 1, 'created': '2016-03-05 18:05:03.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/17d5ef33679ea1c0b01a628f853db9b59fdb8281', 'message': 'Use entire osic quota\n\nSet nodepool max-servers to 100 to use the entire available osic quota.\n\nChange-Id: I24896b292700a5ce8b83137be6b61b10ccead2eb\n'}]",0,288922,17d5ef33679ea1c0b01a628f853db9b59fdb8281,8,3,1,4146,,,0,"Use entire osic quota

Set nodepool max-servers to 100 to use the entire available osic quota.

Change-Id: I24896b292700a5ce8b83137be6b61b10ccead2eb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/288922/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,17d5ef33679ea1c0b01a628f853db9b59fdb8281,bump-osic, max-servers: 100, max-servers: 1,1,1
openstack%2Fneutron-vpnaas~master~I0a01efc670e08884ac76657d8842e2e993d3eca6,openstack/neutron-vpnaas,master,I0a01efc670e08884ac76657d8842e2e993d3eca6,Updated from global requirements,MERGED,2016-03-04 22:33:11.000000000,2016-03-05 18:27:27.000000000,2016-03-05 18:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 12403}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 22:33:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/413a9628da4571ca2af0006045b77482e1aed4f7', 'message': 'Updated from global requirements\n\nChange-Id: I0a01efc670e08884ac76657d8842e2e993d3eca6\n'}]",0,288775,413a9628da4571ca2af0006045b77482e1aed4f7,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I0a01efc670e08884ac76657d8842e2e993d3eca6
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/75/288775/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,413a9628da4571ca2af0006045b77482e1aed4f7,openstack/requirements,neutron-lib>=0.0.1 # Apache-2.0,neutron-lib>=0.0.1 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Ib0781f59f6c69654a2cd2e71bd5a4e4c0ef1a091,openstack/openstack-manuals,master,Ib0781f59f6c69654a2cd2e71bd5a4e4c0ef1a091,Removed extraneous repetitions in CLI doc,ABANDONED,2016-03-05 05:39:23.000000000,2016-03-05 18:13:22.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}, {'_account_id': 18591}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-03-05 05:39:23.000000000', 'files': ['doc/cli-reference/source/openstack.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1abf454eb6a02de33f93acda962d6cad95d36e83', 'message': 'Removed extraneous repetitions in CLI doc\n\nRemoved extraneous repetitions in CLI command doc code block.\nRepetitions are not present in in-console help.\n\nChange-Id: Ib0781f59f6c69654a2cd2e71bd5a4e4c0ef1a091\n'}]",1,288839,1abf454eb6a02de33f93acda962d6cad95d36e83,8,5,1,18591,,,0,"Removed extraneous repetitions in CLI doc

Removed extraneous repetitions in CLI command doc code block.
Repetitions are not present in in-console help.

Change-Id: Ib0781f59f6c69654a2cd2e71bd5a4e4c0ef1a091
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/288839/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/openstack.rst'],1,1abf454eb6a02de33f93acda962d6cad95d36e83,codeblock-repetition," [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] usage: openstack --os-auth-type token --os-identity-api-version 2 tld list [-h] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {html,json,shell,table,value,yaml}] [-f {csv,html,json,table,value,yaml}] [-f {html,json,shell,table,value,yaml}]"," [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] usage: openstack --os-auth-type token --os-identity-api-version 2 tld list [-h] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}] [-f {csv,html,json,json,table,value,yaml,yaml}] [-f {html,json,json,shell,table,value,yaml,yaml}]",209,209
openstack%2Fhorizon~master~Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388,openstack/horizon,master,Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388,Handle Volume launch as instance(NG) in Volume tables.,MERGED,2015-09-03 00:10:54.000000000,2016-03-05 18:08:03.000000000,2016-03-05 18:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6162}, {'_account_id': 6650}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8040}, {'_account_id': 9576}, {'_account_id': 9659}, {'_account_id': 9981}, {'_account_id': 12071}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 14124}, {'_account_id': 15742}, {'_account_id': 16769}, {'_account_id': 16994}, {'_account_id': 17002}, {'_account_id': 17130}, {'_account_id': 17172}, {'_account_id': 17645}]","[{'number': 1, 'created': '2015-09-03 00:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fed6b3352ddef952d4ea9417557a1c086774b825', 'message': 'Fix for the bug/1491645\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\n'}, {'number': 2, 'created': '2015-09-03 01:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f31f1cad2c48279c45a898bea7574acdea694f74', 'message': 'Fix for the bug/1491645\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\n'}, {'number': 3, 'created': '2015-09-03 05:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89d27b94e303ddbdc60991d953392dbbbb925057', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\n'}, {'number': 4, 'created': '2015-10-12 22:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b45a3ecb3a306a9af53ac68f67d08d9bd9efbae', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\n'}, {'number': 5, 'created': '2015-11-03 14:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9796525b6794e34b784e37c545ef80e75c0aaf75', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\n'}, {'number': 6, 'created': '2015-11-05 19:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bfd015ad02b14fb7c89ab14956407b916901356f', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 7, 'created': '2016-01-15 19:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c734baf67e5a564ce2877d612f561d011f68ecd1', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 8, 'created': '2016-02-06 15:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/61e1482b4bdba7d760f45a2493aa880bed9b8538', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 9, 'created': '2016-02-06 16:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e120da99f3f0506079e056e8a83ba4081717ca00', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 10, 'created': '2016-02-12 14:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/94577b6d148a6b84230f3b19fbeb79a66cd75a3e', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 11, 'created': '2016-02-29 15:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cc474616f7f9e59e98f799bcc9726ba1d1301891', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}, {'number': 12, 'created': '2016-03-04 05:01:34.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.js', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9a9772ab80318d8fa88600dcc719f178fdd318a2', 'message': 'Handle Volume launch as instance(NG) in Volume tables.\n\nThe launch as instance option for Volumes launches the legacy\nlaunch instance wizard even if local_settings is configured\nfor LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses\nthe issue.\n\nVolume snapshots will be a separate patch.\n\nHorizon tables.js has a separate bug that needs to be fixed:\n\nhttps://bugs.launchpad.net/horizon/+bug/1514627\n\nChange-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388\nCloses-bug: #1491645\nCo-Authored-By: Travis Tripp <travis.tripp@hpe.com>\n'}]",8,219925,9a9772ab80318d8fa88600dcc719f178fdd318a2,85,23,12,12721,,,0,"Handle Volume launch as instance(NG) in Volume tables.

The launch as instance option for Volumes launches the legacy
launch instance wizard even if local_settings is configured
for LAUNCH_INSTANCE_LEGACY_ENABLED = False. This Fix addresses
the issue.

Volume snapshots will be a separate patch.

Horizon tables.js has a separate bug that needs to be fixed:

https://bugs.launchpad.net/horizon/+bug/1514627

Change-Id: Id4a7dc2a48c63cbe27ece4dba1825eb89b7a0388
Closes-bug: #1491645
Co-Authored-By: Travis Tripp <travis.tripp@hpe.com>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/25/219925/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/volumes/volumes/tables.py'],1,fed6b3352ddef952d4ea9417557a1c086774b825,219925,"from django.conf import settingsclass LaunchVolumeNG(LaunchVolume): name = ""launch_volume"" verbose_name = _(""Launch as Instance"") url = ""horizon:project:volumes:index"" classes = (""btn-launch"", ) ajax = False def __init__(self, attrs=None, **kwargs): kwargs['preempt'] = True super(LaunchVolume, self).__init__(attrs, **kwargs) def get_link_url(self, datum): url = reverse(self.url) vol_id = ""%s:vol"" % self.table.get_object_id(datum) ngclick = ""modal.openLaunchInstanceWizard("" \ ""{successUrl: '%s', volumeId: '%s'})"" % (url, vol_id) self.attrs.update({ ""ng-controller"": ""LaunchInstanceModalController as modal"", ""ng-click"": ngclick }) return ""javascript:void(0);"" if getattr(settings, 'LAUNCH_INSTANCE_LEGACY_ENABLED', True): LaunchInstance = LaunchVolume if getattr(settings, 'LAUNCH_INSTANCE_NG_ENABLED', False): LaunchInstance = LaunchVolumeNG row_actions = (EditVolume, ExtendVolume, LaunchInstance, EditAttachments,"," row_actions = (EditVolume, ExtendVolume, LaunchVolume, EditAttachments,",29,1
openstack%2Ftripleo-incubator~master~Ib76a1560a361069ec9a2563b5afb7ae3c116791b,openstack/tripleo-incubator,master,Ib76a1560a361069ec9a2563b5afb7ae3c116791b,DO NOT MERGE - Just testing,ABANDONED,2016-03-05 15:25:39.000000000,2016-03-05 18:00:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-03-05 15:25:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/2341d0475d1f9f511b4a6832c33870cb218fb33f', 'message': 'DO NOT MERGE - Just testing\n\nChange-Id: Ib76a1560a361069ec9a2563b5afb7ae3c116791b\n'}]",0,288884,2341d0475d1f9f511b4a6832c33870cb218fb33f,4,1,1,6547,,,0,"DO NOT MERGE - Just testing

Change-Id: Ib76a1560a361069ec9a2563b5afb7ae3c116791b
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/84/288884/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2341d0475d1f9f511b4a6832c33870cb218fb33f,testing,"envlist = docs,pep8","envlist = docs,pep8",1,1
openstack%2Fsahara-dashboard~master~I1f042adba9d078efb96f87d74b75ae1b6b38a5aa,openstack/sahara-dashboard,master,I1f042adba9d078efb96f87d74b75ae1b6b38a5aa,Updated from global requirements,MERGED,2016-03-05 15:37:55.000000000,2016-03-05 17:38:52.000000000,2016-03-05 17:38:52.000000000,"[{'_account_id': 3}, {'_account_id': 12038}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 15:37:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/585e6b7944074eae210ede884626a629e867ad71', 'message': 'Updated from global requirements\n\nChange-Id: I1f042adba9d078efb96f87d74b75ae1b6b38a5aa\n'}]",0,288899,585e6b7944074eae210ede884626a629e867ad71,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1f042adba9d078efb96f87d74b75ae1b6b38a5aa
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/99/288899/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,585e6b7944074eae210ede884626a629e867ad71,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Fsahara-tests~master~I10b3dbe641abb86acad55845d7a1663af5a87e5b,openstack/sahara-tests,master,I10b3dbe641abb86acad55845d7a1663af5a87e5b,Updated from global requirements,MERGED,2016-03-05 15:37:59.000000000,2016-03-05 17:35:48.000000000,2016-03-05 17:35:24.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 15:37:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/60dea7dfb8970d5cf96a15e2f4b5479420c7f96d', 'message': 'Updated from global requirements\n\nChange-Id: I10b3dbe641abb86acad55845d7a1663af5a87e5b\n'}]",0,288900,60dea7dfb8970d5cf96a15e2f4b5479420c7f96d,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: I10b3dbe641abb86acad55845d7a1663af5a87e5b
",git fetch https://review.opendev.org/openstack/sahara-tests refs/changes/00/288900/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,60dea7dfb8970d5cf96a15e2f4b5479420c7f96d,openstack/requirements,"python-neutronclient!=4.1.0,>=2.6.0 # Apache-2.0",python-neutronclient>=2.6.0 # Apache-2.0,1,1
openstack%2Fnova~master~Ibc104a20c528ac6c8f84351f518f3dd7a185794f,openstack/nova,master,Ibc104a20c528ac6c8f84351f518f3dd7a185794f,VMware: Use actual VM state instead of using the instance vm_state,MERGED,2015-06-11 12:59:12.000000000,2016-03-05 17:29:01.000000000,2016-03-05 17:29:00.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 8688}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-06-11 12:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65940500aeb1f4342ceda2b0b8f0e52e1374d27e', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 2, 'created': '2015-06-17 14:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c78efeef71154eeda56952e47d158c93a0167b1', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 3, 'created': '2015-08-19 01:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/deb7e3752e5c4ec1f70db40792d1017d627acf98', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 4, 'created': '2015-09-16 12:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1682a0a0ebfea47a00ed45beef971caef2c81c3b', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 5, 'created': '2015-09-29 12:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d13629d009fc1bd0b6d303e7bac5713210a29115', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 6, 'created': '2015-10-13 10:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc827989876e32863b20648f76ed572f9625c9a0', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}, {'number': 7, 'created': '2016-02-28 10:33:37.000000000', 'files': ['nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f6367e667bdcd3d11c34af8b6e3c459b4b0ce81', 'message': 'VMware: Use actual VM state instead of using the instance vm_state\n\nIn review https://review.openstack.org/169732 it was suggested that\nwe use the actual VM state instead of relying on what the instance\nvm_state is.\n\nSo prior to attaching or detaching an IDE disk we check the VM state.\nThis is due to the fact that it does not support hot plugging.\n\nChange-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f\n'}]",0,190627,7f6367e667bdcd3d11c34af8b6e3c459b4b0ce81,101,15,7,1653,,,0,"VMware: Use actual VM state instead of using the instance vm_state

In review https://review.openstack.org/169732 it was suggested that
we use the actual VM state instead of relying on what the instance
vm_state is.

So prior to attaching or detaching an IDE disk we check the VM state.
This is due to the fact that it does not support hot plugging.

Change-Id: Ibc104a20c528ac6c8f84351f518f3dd7a185794f
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/190627/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/volumeops.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_volumeops.py']",4,65940500aeb1f4342ceda2b0b8f0e52e1374d27e,use-vm-state," return_value=vmdk_info), mock.patch.object(vm_util, 'get_vm_state', return_value='PoweredOn') ) as (get_vm_ref, get_volume_ref, get_vmdk_info, get_vm_state): get_vm_state.assert_called_once_with(self._volumeops._session, instance) return_value=vmdk_info), mock.patch.object(vm_util, 'get_vm_state', return_value='PoweredOn') get_vmdk_info, get_vm_state): get_vm_state.assert_called_once_with(self._volumeops._session, instance) if adapter_type == constants.ADAPTER_TYPE_IDE: vm_state = 'PoweredOff' else: vm_state = 'PoweredOn' mock.patch.object(self._volumeops, '_update_volume_details'), mock.patch.object(vm_util, 'get_vm_state', return_value=vm_state) update_volume_details, get_vm_state): if adapter_type == constants.ADAPTER_TYPE_IDE: get_vm_state.assert_called_once_with(self._volumeops._session, self._instance) else: self.assertFalse(get_vm_state.called)"," return_value=vmdk_info) ) as (get_vm_ref, get_volume_ref, get_vmdk_info): return_value=vmdk_info) get_vmdk_info): mock.patch.object(self._volumeops, '_update_volume_details') update_volume_details):",36,20
openstack%2Fsahara~master~Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2,openstack/sahara,master,Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2,Fix MapR 500 tempest test fails,MERGED,2016-03-03 19:51:43.000000000,2016-03-05 17:23:15.000000000,2016-03-05 17:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-03 19:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c72889f8381b8f3c270303ecf9f304b54e6f80a5', 'message': 'Fix MapR 500 tempest test fails\n\nAdd delay after starting Oozie.\n\nChange-Id: Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2\nCloses-Bug: #1552883\n'}, {'number': 2, 'created': '2016-03-03 19:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f591245d36841892bf2866b3d6c5e22551035022', 'message': 'Fix MapR 500 tempest test fails\n\nAdd delay after starting Oozie.\n\nChange-Id: Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2\nCloses-Bug: #1552883\n'}, {'number': 3, 'created': '2016-03-04 14:13:30.000000000', 'files': ['sahara/plugins/mapr/services/oozie/oozie.py', 'sahara/plugins/mapr/base/base_cluster_context.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1909419e818c209f07d1aa9f9d1e2067aa621002', 'message': 'Fix MapR 500 tempest test fails\n\nAdd delay after starting Oozie.\n\nChange-Id: Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2\nCloses-Bug: #1552883\n'}]",2,288088,1909419e818c209f07d1aa9f9d1e2067aa621002,23,4,3,18793,,,0,"Fix MapR 500 tempest test fails

Add delay after starting Oozie.

Change-Id: Ice864e72251212bcf5ca409cbdf6b7a1d367b3b2
Closes-Bug: #1552883
",git fetch https://review.opendev.org/openstack/sahara refs/changes/88/288088/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/mapr/services/oozie/oozie.py'],1,c72889f8381b8f3c270303ecf9f304b54e6f80a5,tmp-bug,import time time.sleep(30),,3,0
openstack%2Fsahara~master~Iedcaa002ff3d40cf61168769bc3946f8c6e42b87,openstack/sahara,master,Iedcaa002ff3d40cf61168769bc3946f8c6e42b87,Moved CORS middleware configuration into oslo-config-generator,MERGED,2016-03-02 18:29:41.000000000,2016-03-05 17:23:02.000000000,2016-03-05 17:23:01.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 9717}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-02 18:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cc289358d1e5747015c553260e07e8f23dcb1bac', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for sahara's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to the default initialization procedure. This ensures\nthat if a value remains unset in the configuration file, it will\nfallback to using sane defaults. It also ensures that an operator\nmodifying the configuration will be presented with that same\nset of defaults.\n\nChange-Id: Iedcaa002ff3d40cf61168769bc3946f8c6e42b87\nCloses-Bug: 1551836\n""}, {'number': 2, 'created': '2016-03-03 22:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/75837b86f4ea18e5f51c0e08550246a6a7d82885', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for sahara's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to the default initialization procedure. This ensures\nthat if a value remains unset in the configuration file, it will\nfallback to using sane defaults. It also ensures that an operator\nmodifying the configuration will be presented with that same\nset of defaults.\n\nChange-Id: Iedcaa002ff3d40cf61168769bc3946f8c6e42b87\nCloses-Bug: 1551836\n""}, {'number': 3, 'created': '2016-03-03 22:01:12.000000000', 'files': ['sahara/common/__init__.py', 'etc/sahara/api-paste.ini', 'setup.cfg', 'sahara/common/config.py', 'sahara/main.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8b4b3abdaf8d9392bd3a3b53813e5ed4eeed53b6', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for sahara's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to the default initialization procedure. This ensures\nthat if a value remains unset in the configuration file, it will\nfallback to using sane defaults. It also ensures that an operator\nmodifying the configuration will be presented with that same\nset of defaults.\n\nChange-Id: Iedcaa002ff3d40cf61168769bc3946f8c6e42b87\nCloses-Bug: 1551836\n""}]",0,287368,8b4b3abdaf8d9392bd3a3b53813e5ed4eeed53b6,40,10,3,9717,,,0,"Moved CORS middleware configuration into oslo-config-generator

The default values needed for sahara's implementation of cors
middleware have been moved from paste.ini into the configuration
hooks provided by oslo.config. Furthermore, these values have been
added to the default initialization procedure. This ensures
that if a value remains unset in the configuration file, it will
fallback to using sane defaults. It also ensures that an operator
modifying the configuration will be presented with that same
set of defaults.

Change-Id: Iedcaa002ff3d40cf61168769bc3946f8c6e42b87
Closes-Bug: 1551836
",git fetch https://review.opendev.org/openstack/sahara refs/changes/68/287368/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/config.py', 'etc/sahara/api-paste.ini', 'setup.cfg', 'sahara/main.py']",4,cc289358d1e5747015c553260e07e8f23dcb1bac,bug/1551836, config.set_config_defaults(),,34,3
openstack%2Fheat~master~Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61,openstack/heat,master,Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61,Updated from global requirements,MERGED,2016-03-04 10:14:29.000000000,2016-03-05 17:13:03.000000000,2016-03-05 17:13:02.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8833}, {'_account_id': 16272}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-03-04 10:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3473547aa0c119c3ea0df748a7affd633d2edc1', 'message': 'Updated from global requirements\n\nChange-Id: Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61\n'}, {'number': 2, 'created': '2016-03-05 03:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/15fbb623d83931506ca1ce4184f08b7d0c3ee4fb', 'message': 'Updated from global requirements\n\nChange-Id: Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61\n'}, {'number': 3, 'created': '2016-03-05 15:31:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/78d8897f1aa895649c444cdd85afe333bc395233', 'message': 'Updated from global requirements\n\nChange-Id: Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61\n'}]",0,288346,78d8897f1aa895649c444cdd85afe333bc395233,14,5,3,11131,,,0,"Updated from global requirements

Change-Id: Ie7b8599e96a223d3a38ebf8e75a5db1d605efd61
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/288346/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c3473547aa0c119c3ea0df748a7affd633d2edc1,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0python-senlinclient>=0.3.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0python-senlinclient>=0.1.7 # Apache-2.0,2,2
openstack%2Fcinder~master~Ib0fc9fa9abc6699f2971948d3d4c5e9902381072,openstack/cinder,master,Ib0fc9fa9abc6699f2971948d3d4c5e9902381072,NetApp: Add Consistency Group support for E-Series,MERGED,2016-02-19 15:31:23.000000000,2016-03-05 17:12:33.000000000,2016-03-01 11:23:37.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10439}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16821}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 19146}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-02-19 15:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b011e4a35a81d680321662e2876a12c749813b08', 'message': 'NetApp: Add Consistency Group support for E-Series\n\nAdd Consistency Group support to the E-Series driver. This\nimplementation utilizes the native Consistency Group feature\navailable on the E-Series backend to support Cinder\nConsistency Groups.\n\nCGs and standalone snapshots both utilize snapshot groups.\nThere is a limit of 3 snapshot groups per volume, so the number\nof standalone snapshots will be limited by the number of\nconsistency groups that are created, and likewise the reverse.\nEach CG/Snapshot Group will support up to 32 snapshots, so each\nCG that a volume is a part of will reduce the number of available\nstandalone snapshots that can be created by 32 (from a maximum\nof 96).\n\nImplements: blueprint netapp-eseries-consistency-groups\nChange-Id: Ib0fc9fa9abc6699f2971948d3d4c5e9902381072\n'}, {'number': 2, 'created': '2016-02-23 09:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/381016fed7b9ee7b679ae1363a45ef9bd4b8d898', 'message': 'NetApp: Add Consistency Group support for E-Series\n\nAdd Consistency Group support to the E-Series driver. This\nimplementation utilizes the native Consistency Group feature\navailable on the E-Series backend to support Cinder\nConsistency Groups.\n\nCGs and standalone snapshots both utilize snapshot groups.\nThere is a limit of 3 snapshot groups per volume, so the number\nof standalone snapshots will be limited by the number of\nconsistency groups that are created, and likewise the reverse.\nEach CG/Snapshot Group will support up to 32 snapshots, so each\nCG that a volume is a part of will reduce the number of available\nstandalone snapshots that can be created by 32 (from a maximum\nof 96).\n\nImplements: blueprint netapp-eseries-consistency-groups\nChange-Id: Ib0fc9fa9abc6699f2971948d3d4c5e9902381072\n'}, {'number': 3, 'created': '2016-02-23 17:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ec7ca16b41e71bf7009963335076d2376fbacb35', 'message': 'NetApp: Add Consistency Group support for E-Series\n\nAdd Consistency Group support to the E-Series driver. This\nimplementation utilizes the native Consistency Group feature\navailable on the E-Series backend to support Cinder\nConsistency Groups.\n\nCGs and standalone snapshots both utilize snapshot groups.\nThere is a limit of 3 snapshot groups per volume, so the number\nof standalone snapshots will be limited by the number of\nconsistency groups that are created, and likewise the reverse.\nEach CG/Snapshot Group will support up to 32 snapshots, so each\nCG that a volume is a part of will reduce the number of available\nstandalone snapshots that can be created by 32 (from a maximum\nof 96).\n\nImplements: blueprint netapp-eseries-consistency-groups\nChange-Id: Ib0fc9fa9abc6699f2971948d3d4c5e9902381072\n'}, {'number': 4, 'created': '2016-02-26 16:27:49.000000000', 'files': ['cinder/volume/drivers/netapp/eseries/fc_driver.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_driver.py', 'cinder/volume/drivers/netapp/eseries/iscsi_driver.py', 'cinder/volume/drivers/netapp/eseries/library.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_library.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/fakes.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_client.py', 'releasenotes/notes/netapp-eseries-consistency-groups-4f6b2af2d20c94e9.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6b7f47633567a1236732e46d9f4d7c80fa30f35c', 'message': 'NetApp: Add Consistency Group support for E-Series\n\nAdd Consistency Group support to the E-Series driver. This\nimplementation utilizes the native Consistency Group feature\navailable on the E-Series backend to support Cinder\nConsistency Groups.\n\nCGs and standalone snapshots both utilize snapshot groups.\nThere is a limit of 3 snapshot groups per volume, so the number\nof standalone snapshots will be limited by the number of\nconsistency groups that are created, and likewise the reverse.\nEach CG/Snapshot Group will support up to 32 snapshots, so each\nCG that a volume is a part of will reduce the number of available\nstandalone snapshots that can be created by 32 (from a maximum\nof 96).\n\nImplements: blueprint netapp-eseries-consistency-groups\nChange-Id: Ib0fc9fa9abc6699f2971948d3d4c5e9902381072\n'}]",6,282388,6b7f47633567a1236732e46d9f4d7c80fa30f35c,163,44,4,16821,,,0,"NetApp: Add Consistency Group support for E-Series

Add Consistency Group support to the E-Series driver. This
implementation utilizes the native Consistency Group feature
available on the E-Series backend to support Cinder
Consistency Groups.

CGs and standalone snapshots both utilize snapshot groups.
There is a limit of 3 snapshot groups per volume, so the number
of standalone snapshots will be limited by the number of
consistency groups that are created, and likewise the reverse.
Each CG/Snapshot Group will support up to 32 snapshots, so each
CG that a volume is a part of will reduce the number of available
standalone snapshots that can be created by 32 (from a maximum
of 96).

Implements: blueprint netapp-eseries-consistency-groups
Change-Id: Ib0fc9fa9abc6699f2971948d3d4c5e9902381072
",git fetch https://review.opendev.org/openstack/cinder refs/changes/88/282388/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/netapp/eseries/test_driver.py', 'cinder/volume/drivers/netapp/eseries/fc_driver.py', 'cinder/volume/drivers/netapp/eseries/iscsi_driver.py', 'cinder/volume/drivers/netapp/eseries/library.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_library.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/fakes.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_client.py']",8,b011e4a35a81d680321662e2876a12c749813b08,snapshots," def test_create_consistency_group(self): invoke = self.mock_object(self.my_client, '_invoke') name = 'fake' self.my_client.create_consistency_group(name) invoke.assert_called_once_with( 'POST', self.my_client.RESOURCE_PATHS['cgroups'], mock.ANY) def test_list_consistency_group(self): invoke = self.mock_object(self.my_client, '_invoke') ref = 'fake' self.my_client.get_consistency_group(ref) invoke.assert_called_once_with( 'GET', self.my_client.RESOURCE_PATHS['cgroup'], **{'object-id': ref}) def test_list_consistency_groups(self): invoke = self.mock_object(self.my_client, '_invoke') self.my_client.list_consistency_groups() invoke.assert_called_once_with( 'GET', self.my_client.RESOURCE_PATHS['cgroups']) def test_delete_consistency_group(self): invoke = self.mock_object(self.my_client, '_invoke') ref = 'fake' self.my_client.delete_consistency_group(ref) invoke.assert_called_once_with( 'DELETE', self.my_client.RESOURCE_PATHS['cgroup'], **{'object-id': ref}) def test_add_consistency_group_member(self): invoke = self.mock_object(self.my_client, '_invoke') vol_id = eseries_fake.VOLUME['id'] cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.add_consistency_group_member(vol_id, cg_id) invoke.assert_called_once_with( 'POST', self.my_client.RESOURCE_PATHS['cgroup_members'], mock.ANY, **{'object-id': cg_id}) def test_remove_consistency_group_member(self): invoke = self.mock_object(self.my_client, '_invoke') vol_id = eseries_fake.VOLUME['id'] cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.remove_consistency_group_member(vol_id, cg_id) invoke.assert_called_once_with( 'DELETE', self.my_client.RESOURCE_PATHS['cgroup_member'], **{'object-id': cg_id, 'vol-id': vol_id}) def test_create_consistency_group_snapshot(self): invoke = self.mock_object(self.my_client, '_invoke') path = self.my_client.RESOURCE_PATHS.get('cgroup_snapshots') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.create_consistency_group_snapshot(cg_id) invoke.assert_called_once_with('POST', path, **{'object-id': cg_id}) @ddt.data(0, 32) def test_delete_consistency_group_snapshot(self, seq_num): invoke = self.mock_object(self.my_client, '_invoke') path = self.my_client.RESOURCE_PATHS.get('cgroup_snapshot') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.delete_consistency_group_snapshot(cg_id, seq_num) invoke.assert_called_once_with( 'DELETE', path, **{'object-id': cg_id, 'seq-num': seq_num}) def test_get_consistency_group_snapshots(self): invoke = self.mock_object(self.my_client, '_invoke') path = self.my_client.RESOURCE_PATHS.get('cgroup_snapshots') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.get_consistency_group_snapshots(cg_id) invoke.assert_called_once_with( 'GET', path, **{'object-id': cg_id}) def test_create_cg_snapshot_view(self): cg_snap_view = copy.deepcopy( eseries_fake.FAKE_CONSISTENCY_GROUP_SNAPSHOT_VOLUME) view = copy.deepcopy(eseries_fake.SNAPSHOT_VOLUME) invoke = self.mock_object(self.my_client, '_invoke', mock.Mock( return_value=cg_snap_view)) list_views = self.mock_object( self.my_client, 'list_cg_snapshot_views', mock.Mock(return_value=[view])) name = view['name'] snap_id = view['basePIT'] path = self.my_client.RESOURCE_PATHS.get('cgroup_cgsnap_views') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.my_client.create_cg_snapshot_view(cg_id, name, snap_id) invoke.assert_called_once_with( 'POST', path, mock.ANY, **{'object-id': cg_id}) list_views.assert_called_once_with(cg_id, cg_snap_view['cgViewRef']) def test_create_cg_snapshot_view_not_found(self): cg_snap_view = copy.deepcopy( eseries_fake.FAKE_CONSISTENCY_GROUP_SNAPSHOT_VOLUME) view = copy.deepcopy(eseries_fake.SNAPSHOT_VOLUME) invoke = self.mock_object(self.my_client, '_invoke', mock.Mock( return_value=cg_snap_view)) list_views = self.mock_object( self.my_client, 'list_cg_snapshot_views', mock.Mock(return_value=[view])) del_view = self.mock_object(self.my_client, 'delete_cg_snapshot_view') name = view['name'] # Ensure we don't get a match on the retrieved views snap_id = None path = self.my_client.RESOURCE_PATHS.get('cgroup_cgsnap_views') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] self.assertRaises( exception.NetAppDriverException, self.my_client.create_cg_snapshot_view, cg_id, name, snap_id) invoke.assert_called_once_with( 'POST', path, mock.ANY, **{'object-id': cg_id}) list_views.assert_called_once_with(cg_id, cg_snap_view['cgViewRef']) del_view.assert_called_once_with(cg_id, cg_snap_view['id']) def test_list_cg_snapshot_views(self): invoke = self.mock_object(self.my_client, '_invoke') path = self.my_client.RESOURCE_PATHS.get('cgroup_snapshot_views') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] view_id = 'id' self.my_client.list_cg_snapshot_views(cg_id, view_id) invoke.assert_called_once_with( 'GET', path, **{'object-id': cg_id, 'view-id': view_id}) def test_delete_cg_snapshot_view(self): invoke = self.mock_object(self.my_client, '_invoke') path = self.my_client.RESOURCE_PATHS.get('cgroup_snap_view') cg_id = eseries_fake.FAKE_CONSISTENCY_GROUP['id'] view_id = 'id' self.my_client.delete_cg_snapshot_view(cg_id, view_id) invoke.assert_called_once_with( 'DELETE', path, **{'object-id': cg_id, 'view-id': view_id}) ",,1223,25
openstack%2Fneutron~master~I7b4c9c4d46ebc95aef34c4a001e62b88899aa196,openstack/neutron,master,I7b4c9c4d46ebc95aef34c4a001e62b88899aa196,Nit: Occurances of OpenStack,MERGED,2016-03-04 20:46:28.000000000,2016-03-05 16:22:21.000000000,2016-03-05 15:42:26.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7715}, {'_account_id': 8726}, {'_account_id': 9681}, {'_account_id': 14605}, {'_account_id': 18332}, {'_account_id': 20140}, {'_account_id': 20246}, {'_account_id': 20508}]","[{'number': 1, 'created': '2016-03-04 20:46:28.000000000', 'files': ['doc/source/policies/bugs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/31aa3516f56695fbc4949f4d4b6d706ed8dd451a', 'message': 'Nit: Occurances of OpenStack\n\nIncorrect capitalization replaced with ""OpenStack""\n\nChange-Id: I7b4c9c4d46ebc95aef34c4a001e62b88899aa196\n'}]",0,288726,31aa3516f56695fbc4949f4d4b6d706ed8dd451a,18,12,1,19591,,,0,"Nit: Occurances of OpenStack

Incorrect capitalization replaced with ""OpenStack""

Change-Id: I7b4c9c4d46ebc95aef34c4a001e62b88899aa196
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/288726/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/policies/bugs.rst'],1,31aa3516f56695fbc4949f4d4b6d706ed8dd451a,, test over time using `OpenStack Health <http://status.openstack.org/openstack-health/#/>`_ or `OpenStack Logstash <http://logstash.openstack.org/#/dashboard/file/logstash.json>`_., test over time using `Openstack Health <http://status.openstack.org/openstack-health/#/>`_ or `Openstack Logstash <http://logstash.openstack.org/#/dashboard/file/logstash.json>`_.,2,2
openstack%2Fpython-openstackclient~master~I4225179dca4aedf799e1656ec49236bdedc5e9bd,openstack/python-openstackclient,master,I4225179dca4aedf799e1656ec49236bdedc5e9bd,Refactor security group set to use SDK,MERGED,2016-03-03 12:34:36.000000000,2016-03-05 16:19:26.000000000,2016-03-05 16:08:20.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-03-03 12:34:36.000000000', 'files': ['openstackclient/tests/network/v2/test_security_group.py', 'setup.cfg', 'openstackclient/network/v2/security_group.py', 'openstackclient/compute/v2/security_group.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bac9fb18c1455f6a309e7acff9230a8d6bf7079b', 'message': ""Refactor security group set to use SDK\n\nRefactored the 'os security group set' command to use the SDK\nwhen neutron is enabled, but continue to use the nova client\nwhen nova network is enabled.\n\nThis patch set also fixes a compute bug which ignores name\nand description when set to an empty value.\n\nChange-Id: I4225179dca4aedf799e1656ec49236bdedc5e9bd\nPartial-Bug: #1519511\nImplements: blueprint neutron-client\n""}]",0,287763,bac9fb18c1455f6a309e7acff9230a8d6bf7079b,16,4,1,8410,,,0,"Refactor security group set to use SDK

Refactored the 'os security group set' command to use the SDK
when neutron is enabled, but continue to use the nova client
when nova network is enabled.

This patch set also fixes a compute bug which ignores name
and description when set to an empty value.

Change-Id: I4225179dca4aedf799e1656ec49236bdedc5e9bd
Partial-Bug: #1519511
Implements: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/63/287763/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_security_group.py', 'setup.cfg', 'openstackclient/network/v2/security_group.py', 'openstackclient/compute/v2/security_group.py']",4,bac9fb18c1455f6a309e7acff9230a8d6bf7079b,bug/1519511,,"class SetSecurityGroup(command.Command): """"""Set security group properties"""""" def get_parser(self, prog_name): parser = super(SetSecurityGroup, self).get_parser(prog_name) parser.add_argument( 'group', metavar='<group>', help='Security group to modify (name or ID)', ) parser.add_argument( '--name', metavar='<new-name>', help='New security group name', ) parser.add_argument( ""--description"", metavar=""<description>"", help=""New security group description"", ) return parser def take_action(self, parsed_args): compute_client = self.app.client_manager.compute data = utils.find_resource( compute_client.security_groups, parsed_args.group, ) if parsed_args.name: data.name = parsed_args.name if parsed_args.description: data.description = parsed_args.description compute_client.security_groups.update( data, data.name, data.description, ) ",190,42
openstack%2Frelease-tools~master~Ief8c81f11ac158227407befa308b98950ef9a693,openstack/release-tools,master,Ief8c81f11ac158227407befa308b98950ef9a693,Do not merge - TESTING,ABANDONED,2016-03-05 15:18:01.000000000,2016-03-05 15:45:56.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-03-05 15:18:01.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/d8f04746570b1e7ecaaad62e61a169bcfa499693', 'message': 'Do not merge - TESTING\n\nChange-Id: Ief8c81f11ac158227407befa308b98950ef9a693\n'}]",0,288882,d8f04746570b1e7ecaaad62e61a169bcfa499693,3,1,1,6547,,,0,"Do not merge - TESTING

Change-Id: Ief8c81f11ac158227407befa308b98950ef9a693
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/82/288882/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,d8f04746570b1e7ecaaad62e61a169bcfa499693,dummy,realpath [platform:dpkg],realpath [platform:ubuntu-trusty],1,1
openstack%2Fswift~master~If4fb6a5c4cb741d42953db3cee8cb17a1d774e15,openstack/swift,master,If4fb6a5c4cb741d42953db3cee8cb17a1d774e15,Remove Erasure Coding beta status from docs,MERGED,2016-03-04 09:31:31.000000000,2016-03-05 15:42:17.000000000,2016-03-05 15:42:17.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2016-03-04 09:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cb8a85384568c655c45de682cda8219588e13c09', 'message': 'Remove Erasure Coding beta status from docs\n\nThis removes notes stating support for Erasure coding as beta. Questions\nregarding the stability of EC are coming up regularly, and are often referring\nto the docs that state EC as still in beta.\n\nBesides this, a note marking statsd support as beta has been removed as well.\n\nChange-Id: If4fb6a5c4cb741d42953db3cee8cb17a1d774e15\n'}, {'number': 2, 'created': '2016-03-04 09:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/509a790b93bb9595dbe8eadcfce30f277a139cfd', 'message': 'Remove Erasure Coding beta status from docs\n\nThis removes notes stating support for Erasure coding as beta. Questions\nregarding the stability of EC are coming up regularly, and are often referring\nto the docs that state EC as still in beta.\n\nBesides this, a note marking statsd support as beta has been removed as well.\n\nChange-Id: If4fb6a5c4cb741d42953db3cee8cb17a1d774e15\n'}, {'number': 3, 'created': '2016-03-04 14:27:56.000000000', 'files': ['doc/source/overview_policies.rst', 'etc/swift.conf-sample', 'doc/source/overview_erasure_code.rst', 'doc/source/admin_guide.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/043fbca6d08648baa314ea2236f1ccdca8785f16', 'message': 'Remove Erasure Coding beta status from docs\n\nThis removes notes stating support for Erasure coding as beta. Questions\nregarding the stability of EC are coming up regularly, and are often referring\nto the docs that state EC as still in beta.\n\nBesides this, a note marking statsd support as beta has been removed as well.\n\nChange-Id: If4fb6a5c4cb741d42953db3cee8cb17a1d774e15\n'}]",5,288327,043fbca6d08648baa314ea2236f1ccdca8785f16,24,5,3,6968,,,0,"Remove Erasure Coding beta status from docs

This removes notes stating support for Erasure coding as beta. Questions
regarding the stability of EC are coming up regularly, and are often referring
to the docs that state EC as still in beta.

Besides this, a note marking statsd support as beta has been removed as well.

Change-Id: If4fb6a5c4cb741d42953db3cee8cb17a1d774e15
",git fetch https://review.opendev.org/openstack/swift refs/changes/27/288327/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/overview_policies.rst', 'etc/swift.conf-sample', 'doc/source/overview_erasure_code.rst', 'doc/source/admin_guide.rst']",4,cb8a85384568c655c45de682cda8219588e13c09,remove-ec-beta-status,are not locked down and will change over time.,"are not locked down and will change over time. StatsD logging is currently in a ""beta"" stage and will continue to evolve.",4,7
openstack%2Fkolla~master~I2369d5c4715ebdb679342bda3b794c6297d20a9c,openstack/kolla,master,I2369d5c4715ebdb679342bda3b794c6297d20a9c,WIP:Reconfigure for ceph,ABANDONED,2016-03-04 04:23:13.000000000,2016-03-05 15:41:48.000000000,,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 13642}, {'_account_id': 18009}]","[{'number': 1, 'created': '2016-03-04 04:23:13.000000000', 'files': ['ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/ceph/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5486fb4db7e6184056ac8321443d8df091e77623', 'message': 'WIP:Reconfigure for ceph\n\nAdd reconfiguration for ceph-mon, ceph-osd, ceph-rgw\n\nPartially-Implements: blueprint kolla-reconfig\n\nChange-Id: I2369d5c4715ebdb679342bda3b794c6297d20a9c\n'}]",3,288245,5486fb4db7e6184056ac8321443d8df091e77623,8,4,1,18009,,,0,"WIP:Reconfigure for ceph

Add reconfiguration for ceph-mon, ceph-osd, ceph-rgw

Partially-Implements: blueprint kolla-reconfig

Change-Id: I2369d5c4715ebdb679342bda3b794c6297d20a9c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/45/288245/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/ceph/tasks/do_reconfigure.yml']",2,5486fb4db7e6184056ac8321443d8df091e77623,bp/kolla-reconfig,"--- - name: Ensuring the containers up kolla_docker: name: ""{{ item.name }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false when: inventory_hostname in groups[item.group] with_items: - { name: manila_api, group: manila-api } - { name: manila_scheduler, group: manila-scheduler } - { name: manila_share, group: manila-share } - include: config.yml - name: Check the configs command: docker exec {{ item.name }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false register: check_results when: inventory_hostname in groups[item.group] with_items: - { name: manila_api, group: manila-api } - { name: manila_scheduler, group: manila-scheduler } - { name: manila_share, group: manila-share } # NOTE(jeffrey4l): when config_strategy == 'COPY_ALWAYS' # and container env['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE', # just remove the container and start again - name: Containers config strategy kolla_docker: name: ""{{ item.name }}"" action: ""get_container_env"" register: container_envs when: inventory_hostname in groups[item.group] with_items: - { name: manila_api, group: manila-api } - { name: manila_scheduler, group: manila-scheduler } - { name: manila_share, group: manila-share } - name: Remove the containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""remove_container"" register: remove_containers when: - config_strategy == ""COPY_ONCE"" or item[1]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: manila_api, group: manila-api }, { name: manila_scheduler, group: manila-scheduler }, { name: manila_share, group: manila-share }] - container_envs.results - check_results.results - include: start.yml when: remove_containers.changed - name: Restart containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""restart_container"" when: - config_strategy == 'COPY_ALWAYS' - item[1]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: manila_api, group: manila-api }, { name: manila_scheduler, group: manila-scheduler }, { name: manila_share, group: manila-share }] - container_envs.results - check_results.results ",,79,0
openstack%2Fkolla~master~I95f2e6d17ba7960b2f87344f30b7884d621f9ecb,openstack/kolla,master,I95f2e6d17ba7960b2f87344f30b7884d621f9ecb,Use alphabetical order in cleanup-containers,MERGED,2016-03-03 07:16:15.000000000,2016-03-05 15:36:51.000000000,2016-03-05 15:36:50.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 13642}, {'_account_id': 14119}, {'_account_id': 16233}, {'_account_id': 16620}, {'_account_id': 18009}, {'_account_id': 19300}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-03-03 07:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cac3c80889d40441e8f77372ff40fd7ad5a034c8', 'message': 'Use alphabetical order in cleanup-containers\n\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}, {'number': 2, 'created': '2016-03-03 16:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/20a9c0d773c49312c14ba6b61e55afbc556493b6', 'message': 'Use alphabetical order in cleanup-containers\n\nTrivialFix\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}, {'number': 3, 'created': '2016-03-04 16:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f65beb8f13bc0e2b063d998d6f8f77d544ac73c7', 'message': 'Use alphabetical order in cleanup-containers\n\nTrivialFix\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}, {'number': 4, 'created': '2016-03-04 16:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5ee2404bb438c2c387c8bcf3958d59e45c1c1c81', 'message': 'Use alphabetical order in cleanup-containers\n\nTrivialFix\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}, {'number': 5, 'created': '2016-03-04 16:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ff6593eec9d711d08892ddff712ff606d625c3e2', 'message': 'Use alphabetical order in cleanup-containers\n\nTrivialFix\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}, {'number': 6, 'created': '2016-03-05 10:52:23.000000000', 'files': ['tools/cleanup-containers'], 'web_link': 'https://opendev.org/openstack/kolla/commit/97ae06341adaca76d85b1e5800e623994ad30101', 'message': 'Use alphabetical order in cleanup-containers\n\nTrivialFix\nChange-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb\n'}]",0,287626,97ae06341adaca76d85b1e5800e623994ad30101,28,9,6,19300,,,0,"Use alphabetical order in cleanup-containers

TrivialFix
Change-Id: I95f2e6d17ba7960b2f87344f30b7884d621f9ecb
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/287626/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-containers'],1,cac3c80889d40441e8f77372ff40fd7ad5a034c8,heka-es-integration," elasticsearch \ heka \ kibana \ swift_{account_{auditor,reaper,replicator,server},container_{auditor,replicator,server,updater},object_{auditor,expirer,replicator,server,updater},proxy_server,rsyncd} elasticsearch \ glance \ ironic_pxe \ mariadb \ mongodb \ neutron_metadata_socket \ nova_{compute,libvirt} \ openvswitch_db \ rabbitmq"," heka \ swift_{account_{auditor,reaper,replicator,server},container_{auditor,replicator,server,updater},object_{auditor,expirer,replicator,server,updater},proxy_server,rsyncd} \ elasticsearch \ kibana glance \ ironic_pxe \ mariadb \ openvswitch_db \ neutron_metadata_socket \ nova_{compute,libvirt} \ rabbitmq \ mongodb \ elasticsearch",13,13
openstack%2Fkolla~master~I6ff7a4f0ad04c4c666e174693a35ff49914280bb,openstack/kolla,master,I6ff7a4f0ad04c4c666e174693a35ff49914280bb,Make Heka send logs to Elasticsearch,MERGED,2016-02-24 15:24:09.000000000,2016-03-05 15:36:44.000000000,2016-03-05 15:36:44.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6794}, {'_account_id': 13642}, {'_account_id': 14119}, {'_account_id': 16233}, {'_account_id': 16620}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-02-24 15:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e36a913f9ab25bde7229ad83fd050c0947cfc660', 'message': '[WIP] Make Heka send logs to Elasticsearch\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 2, 'created': '2016-02-25 08:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/15a0e180e9ec0d5a02d08f9fd98af6c2da50e722', 'message': '[WIP] Make Heka send logs to Elasticsearch\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 3, 'created': '2016-02-25 11:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/53d9994a7aee50d0ff75711a72f40050e36a66cd', 'message': '[WIP] Make Heka send logs to Elasticsearch\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 4, 'created': '2016-02-25 11:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8b2d65f7a61f115106bc5f866a723875bd4341d0', 'message': '[WIP] Make Heka send logs to Elasticsearch\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 5, 'created': '2016-02-25 19:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/09c0e56b074ec1ffcce38315b5c462a2905b828e', 'message': '[WIP] Make Heka send logs to Elasticsearch\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 6, 'created': '2016-02-25 20:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e29e96e9132ae34f03cf0e37ba915f700cb3ff7b', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nLogstash not being used the enable_elk deploy variable is renamed to\nenable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false.  If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to recreated (for Heka to get the new configuration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2.  This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka.  This is changed to always use ""log"" for the Type.  In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP.  Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs will include ""Plugin\nelasticsearch_output"" errors when Heka starts.  This occurs when Heka\nstarts processing logs while the Elasticsearch process is not yet\nstarted.  These are transient errors that go away when Elasticsearch\nis ready.  And with buffering enabled on the ElasticSearchOuput\nplugin logs will be buffered and retransmitted when Elasticsearch\nbecomes available.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 7, 'created': '2016-02-25 21:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9e91dd4194dfb39c82fcb27da16dbe5264ee96cf', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nLogstash not being used the enable_elk deploy variable is renamed to\nenable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to recreated (for Heka to get the new configuration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 8, 'created': '2016-02-26 12:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1a59be44447e67ab70b573e38c60f1a94d6aa334', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 9, 'created': '2016-02-26 12:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/08283471708d48a06271c3ca5f92cc76095235f4', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 10, 'created': '2016-02-29 08:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1705860b00c439a2d84c8f2e9c52473524ea7d5d', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 11, 'created': '2016-02-29 08:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e6cacdb657838707a372e5be0be756a48df9c882', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 12, 'created': '2016-03-03 07:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/49ec9ea437450ee9cf5e2aa5ddbae92400444419', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 13, 'created': '2016-03-04 16:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0d4143b2e92c0a4e037219638b947544fc318e64', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 14, 'created': '2016-03-04 16:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f2b96017e469b8116d1fdd85fbd5d7e689a0fc5f', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\n'}, {'number': 15, 'created': '2016-03-04 16:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/358333478c79132c4283f3508723199eb743026b', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\nImplements: blueprint central-logging-service\n'}, {'number': 16, 'created': '2016-03-05 10:52:23.000000000', 'files': ['ansible/roles/common/templates/heka-haproxy.toml.j2', 'ansible/roles/haproxy/templates/haproxy.cfg.j2', 'ansible/roles/elasticsearch/templates/elasticsearch.yml.j2', 'ansible/roles/elasticsearch/defaults/main.yml', 'ansible/site.yml', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/kibana/templates/kibana.yml.j2', 'docker/heka/plugins/decoders/os_syslog.lua', 'ansible/roles/common/templates/heka-elasticsearch.toml.j2', 'docker/heka/plugins/decoders/os_swift_log.lua', 'tools/cleanup-containers', 'ansible/group_vars/all.yml', 'ansible/roles/kibana/defaults/main.yml', 'ansible/roles/common/templates/heka-swift.toml.j2', 'ansible/roles/common/templates/heka.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/491aff0b88bc3dac13ea9180c952854fd0a67684', 'message': 'Make Heka send logs to Elasticsearch\n\nThis patch includes changes relative to integrating Heka with\nElasticsearch and Kibana.\n\nThe main change is the addition of an Heka ElasticSearchOutput plugin\nto make Heka send the logs it collects to Elasticsearch.\n\nSince Logstash is not used the enable_elk deploy variable is renamed\nto enable_central_logging.\n\nIf enable_central_logging is false then Elasticsearch and Kibana are\nnot started, and Heka won\'t attempt to send logs to Elasticsearch.\n\nBy default enable_central_logging is set to false. If\nenable_central_logging is set to true after deployment then the Heka\ncontainer needs to be recreated (for Heka to get the new\nconfiguration).\n\nThe Kibana configuration used property names that are deprecated in\nKibana 4.2. This is changed to use non-deprecated property names.\n\nPreviously logs read from files and from Syslog had a different Type\nin Heka. This is changed to always use ""log"" for the Type. In this\nway just one index instead of two is used in Elasticsearch, making\nthings easier to the user on the visualization side.\n\nThe HAProxy configuration is changed to add entries for Kibana.\nKibana server is now accessible via the internal VIP, and also via\nthe external VIP if there\'s one configured.\n\nThe HAProxy configuration is changed to add an entry for\nElasticsearch. So Elasticsearch is now accessible via the internal\nVIP. Heka uses that channel for communicating with Elasticsearch.\n\nNote that currently the Heka logs include ""Plugin\nelasticsearch_output"" errors when Heka starts. This occurs when Heka\nstarts processing logs while Elasticsearch is not yet started. These\nare transient errors that go away when Elasticsearch is ready. And\nwith buffering enabled on the ElasticSearchOuput plugin logs will be\nbuffered and then retransmitted when Elasticsearch is ready.\n\nChange-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb\nImplements: blueprint central-logging-service\n'}]",42,284188,491aff0b88bc3dac13ea9180c952854fd0a67684,69,8,16,19300,,,0,"Make Heka send logs to Elasticsearch

This patch includes changes relative to integrating Heka with
Elasticsearch and Kibana.

The main change is the addition of an Heka ElasticSearchOutput plugin
to make Heka send the logs it collects to Elasticsearch.

Since Logstash is not used the enable_elk deploy variable is renamed
to enable_central_logging.

If enable_central_logging is false then Elasticsearch and Kibana are
not started, and Heka won't attempt to send logs to Elasticsearch.

By default enable_central_logging is set to false. If
enable_central_logging is set to true after deployment then the Heka
container needs to be recreated (for Heka to get the new
configuration).

The Kibana configuration used property names that are deprecated in
Kibana 4.2. This is changed to use non-deprecated property names.

Previously logs read from files and from Syslog had a different Type
in Heka. This is changed to always use ""log"" for the Type. In this
way just one index instead of two is used in Elasticsearch, making
things easier to the user on the visualization side.

The HAProxy configuration is changed to add entries for Kibana.
Kibana server is now accessible via the internal VIP, and also via
the external VIP if there's one configured.

The HAProxy configuration is changed to add an entry for
Elasticsearch. So Elasticsearch is now accessible via the internal
VIP. Heka uses that channel for communicating with Elasticsearch.

Note that currently the Heka logs include ""Plugin
elasticsearch_output"" errors when Heka starts. This occurs when Heka
starts processing logs while Elasticsearch is not yet started. These
are transient errors that go away when Elasticsearch is ready. And
with buffering enabled on the ElasticSearchOuput plugin logs will be
buffered and then retransmitted when Elasticsearch is ready.

Change-Id: I6ff7a4f0ad04c4c666e174693a35ff49914280bb
Implements: blueprint central-logging-service
",git fetch https://review.opendev.org/openstack/kolla refs/changes/88/284188/13 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/templates/heka-elasticsearch.toml.j2', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/kibana/templates/kibana.yml.j2', 'ansible/roles/common/templates/heka.json.j2']",4,e36a913f9ab25bde7229ad83fd050c0947cfc660,heka-es-integration,"{% if enable_elk | bool %} { ""source"": ""{{ container_config_directory }}/heka-elasticsearch.toml"", ""dest"": ""/etc/heka/heka-elasticsearch.toml"", ""owner"": ""heka"", ""perm"": ""0600"" }, {% endif %}",,27,2
openstack%2Fcinder~master~Id92d58b4ccced907cc6e3e59d9e71650a459b4a8,openstack/cinder,master,Id92d58b4ccced907cc6e3e59d9e71650a459b4a8,Fixed logging for oslo versioned objects,MERGED,2016-01-12 10:49:46.000000000,2016-03-05 15:36:18.000000000,2016-03-02 14:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9382}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19213}, {'_account_id': 19852}, {'_account_id': 19917}]","[{'number': 1, 'created': '2016-01-12 10:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e44f206ee79a549ddddcddc54b602a3c311bc33', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log message with object as a parameter,\nobj_attr_is_set method used to check name parameter, which was wrong\napproach. Now, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume)\nand volume_size (in snapshot), and inproper condition statement in lvm\ndriver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 2, 'created': '2016-01-12 11:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f24e5bf73030e8b22bf06a3371ce6f92e35f89c', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. Now, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume)\nand volume_size (in snapshot), and inproper condition statement in lvm\ndriver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 3, 'created': '2016-01-12 11:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/31b664bbd5266052434944dfc8ea18d142277dcb', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. Now, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume)\nand volume_size (in snapshot), and inproper condition statement in lvm\ndriver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 4, 'created': '2016-01-13 10:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a0aff02841f6e0e3be1b36d22afcae763d2750f', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. The reason was, that the oslo logger, when received a\nversioned object as a resource parameter, is trying to get the 'name'\nparameter, which is a property, so the obj_attr_is_set method will\nreturn False and the logger will try to get the 'type' parameter, which\ndoes not exist in some versioned objects (please take a look at:\nhttps://github.com/openstack/oslo.log/blob/master/oslo_log/log.py,\nline 163-187).\nNow, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume\nobject) and volume_size (in snapshot object), and inproper condition\nstatement in lvm driver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 5, 'created': '2016-01-27 09:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/703dd080f08073c3e512b02af8f8997de088e6fa', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. The reason was, that the oslo logger, when received a\nversioned object as a resource parameter, is trying to get the 'name'\nparameter, which is a property, so the obj_attr_is_set method will\nreturn False and the logger will try to get the 'type' parameter, which\ndoes not exist in some versioned objects (please take a look at:\nhttps://github.com/openstack/oslo.log/blob/master/oslo_log/log.py,\nline 163-187).\nNow, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume\nobject) and volume_size (in snapshot object), and inproper condition\nstatement in lvm driver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 6, 'created': '2016-02-09 12:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fa996ae3de994b4da0331aa4708efe2f9cabc5c3', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. The reason was, that the oslo logger, when received a\nversioned object as a resource parameter, is trying to get the 'name'\nparameter, which is a property, so the obj_attr_is_set method will\nreturn False and the logger will try to get the 'type' parameter, which\ndoes not exist in some versioned objects (please take a look at:\nhttps://github.com/openstack/oslo.log/blob/master/oslo_log/log.py,\nline 163-187).\nNow, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume\nobject) and volume_size (in snapshot object), and inproper condition\nstatement in lvm driver.\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}, {'number': 7, 'created': '2016-03-01 18:21:45.000000000', 'files': ['cinder/tests/unit/objects/test_base.py', 'cinder/objects/base.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fedd45446992efc848178f4851b0405cfa7d2fdd', 'message': ""Fixed logging for oslo versioned objects\n\nEarlier, when we wanted to log a message with an object as a parameter,\nobj_attr_is_set method used to check name parameter, which was a wrong\napproach. The reason was, that the oslo logger, when received a\nversioned object as a resource parameter, is trying to get the 'name'\nparameter, which is a property, so the obj_attr_is_set method will\nreturn False and the logger will try to get the 'type' parameter, which\ndoes not exist in some versioned objects (please take a look at\noslo.logging code [1]).\n\nNow, when the parameter's name is present in obj_extra_fields\ndict, we avoid calling obj_attr_is_set and simply get() it.\n\nThe other cause was a difference between fields names: size (in volume\nobject) and volume_size (in snapshot object), and inproper condition\nstatement in lvm driver.\n\n[1] goo.gl/YffLcK\n\nChange-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8\nCloses-Bug: 1501521\n""}]",10,266289,fedd45446992efc848178f4851b0405cfa7d2fdd,171,58,7,19213,,,0,"Fixed logging for oslo versioned objects

Earlier, when we wanted to log a message with an object as a parameter,
obj_attr_is_set method used to check name parameter, which was a wrong
approach. The reason was, that the oslo logger, when received a
versioned object as a resource parameter, is trying to get the 'name'
parameter, which is a property, so the obj_attr_is_set method will
return False and the logger will try to get the 'type' parameter, which
does not exist in some versioned objects (please take a look at
oslo.logging code [1]).

Now, when the parameter's name is present in obj_extra_fields
dict, we avoid calling obj_attr_is_set and simply get() it.

The other cause was a difference between fields names: size (in volume
object) and volume_size (in snapshot object), and inproper condition
statement in lvm driver.

[1] goo.gl/YffLcK

Change-Id: Id92d58b4ccced907cc6e3e59d9e71650a459b4a8
Closes-Bug: 1501521
",git fetch https://review.opendev.org/openstack/cinder refs/changes/89/266289/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/objects/base.py', 'cinder/volume/drivers/lvm.py']",2,8e44f206ee79a549ddddcddc54b602a3c311bc33,bug/1501521, size_in_g = volume.get('volume_size') if is_snapshot \ else volume.get('size'), size_in_g = volume.get('volume_size') or volume.get('size'),4,2
openstack%2Fapp-catalog~master~I5d74dca55f5d149c4faa7a419c6bd9bf7b63d405,openstack/app-catalog,master,I5d74dca55f5d149c4faa7a419c6bd9bf7b63d405,Add last modified field to detail page,MERGED,2016-03-01 19:57:33.000000000,2016-03-05 15:28:51.000000000,2016-03-05 15:28:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7128}, {'_account_id': 9788}]","[{'number': 1, 'created': '2016-03-01 19:57:33.000000000', 'files': ['openstack_catalog/templates/index.html'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/5894ca7cbb2348818aab894763fa8a67cba2275f', 'message': 'Add last modified field to detail page\n\nThis commit adds the date found in ""last modified"" field for\neach asset in the catalog.\n\nChange-Id: I5d74dca55f5d149c4faa7a419c6bd9bf7b63d405\n'}]",0,286807,5894ca7cbb2348818aab894763fa8a67cba2275f,8,4,1,9788,,,0,"Add last modified field to detail page

This commit adds the date found in ""last modified"" field for
each asset in the catalog.

Change-Id: I5d74dca55f5d149c4faa7a419c6bd9bf7b63d405
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/07/286807/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/templates/index.html'],1,5894ca7cbb2348818aab894763fa8a67cba2275f,add-last-modified," <span class=""label"">Last modified: </span><span class=""value"">${last_modified}</span> </div> <div> <div> <span class=""label"">Last modified: </span><span class=""value"">${last_modified}</span> </div> <span class=""label"">Last modified: </span><span class=""value"">${last_modified}</span> </div> <div>",,9,0
openstack%2Frequirements~master~Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c,openstack/requirements,master,Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c,Bump python-neutronclient to 4.1.1,MERGED,2016-03-04 12:36:00.000000000,2016-03-05 15:28:36.000000000,2016-03-05 15:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 8833}, {'_account_id': 8851}, {'_account_id': 8871}, {'_account_id': 9656}, {'_account_id': 11536}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-04 12:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c284a104beff5523120bd8b6d0af9c97f38c2513', 'message': 'Bump python-neutronclient to 4.1.1\n\nAlso excludes neutronclient 4.1.0 because 4.0.0 has\na critical bug which breaks at least heat gate.\n\nChange-Id: Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c\nDepends-On: I183c1f935ce49032dff49d36ab37e3abceca35dc\n'}, {'number': 2, 'created': '2016-03-04 16:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2697862adea09f46790cda15901096bc532034bc', 'message': 'Bump python-neutronclient to 4.1.1\n\nAlso excludes neutronclient 4.1.0 because 4.0.0 has\na critical bug which breaks at least heat gate.\n\nChange-Id: Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c\nDepends-On: I183c1f935ce49032dff49d36ab37e3abceca35dc\n'}, {'number': 3, 'created': '2016-03-05 13:27:09.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e8f3f6869506728c596614d515f9959174b01d68', 'message': 'Bump python-neutronclient to 4.1.1\n\nAlso excludes neutronclient 4.1.0 because 4.0.0 has\na critical bug which breaks at least heat gate.\n\nDepends-On: Ie143ad862b88034ef47470b85fd02c1d040415a7\nChange-Id: Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c\nDepends-On: I183c1f935ce49032dff49d36ab37e3abceca35dc\n'}]",0,288428,e8f3f6869506728c596614d515f9959174b01d68,32,10,3,841,,,0,"Bump python-neutronclient to 4.1.1

Also excludes neutronclient 4.1.0 because 4.0.0 has
a critical bug which breaks at least heat gate.

Depends-On: Ie143ad862b88034ef47470b85fd02c1d040415a7
Change-Id: Ib80ab3ebb2a5dd8e1b1e1494677674375b9b5a3c
Depends-On: I183c1f935ce49032dff49d36ab37e3abceca35dc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/288428/3 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,c284a104beff5523120bd8b6d0af9c97f38c2513,neutronclient-4.1.1,python-neutronclient===4.1.1,python-neutronclient===4.1.0,2,2
openstack%2Fapp-catalog-ui~master~Ie6c8ee63afbda075298fdf2043990f5e9042308d,openstack/app-catalog-ui,master,Ie6c8ee63afbda075298fdf2043990f5e9042308d,Adding integration test support,MERGED,2016-02-04 20:50:25.000000000,2016-03-05 15:27:15.000000000,2016-03-05 15:27:15.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7128}, {'_account_id': 9237}, {'_account_id': 9788}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-04 20:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/bde2dd24c49c3908cc85f4bc6d4c0b8b45216177', 'message': 'Adding integration test support\n\n* Update requirements for selenium testing\n* Add run_tests.sh\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 2, 'created': '2016-02-04 22:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/2ebcbbd08407489196ff2f83f8f6fedf6a417803', 'message': 'Adding integration test support\n\n* Update requirements for selenium testing\n* Add run_tests.sh\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 3, 'created': '2016-02-05 15:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/ffecb0f8454855502535ef45a7775dc33e292118', 'message': 'Adding integration test support\n\n* Update requirements for selenium testing\n* Add run_tests.sh\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 4, 'created': '2016-02-09 18:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/e30e546260a4812d9ef1a74020e1f32e589e34bd', 'message': 'Adding integration test support\n\n* Update requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 5, 'created': '2016-02-19 15:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/16bf16cf0a707abae78153aab60ec2b1ea1dfd7b', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 6, 'created': '2016-02-22 17:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/b614223e7a08bf832c1afc64c11b03493411ee18', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 7, 'created': '2016-02-22 17:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/406306fe1fdb78bda6d894264061519f2faac550', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 8, 'created': '2016-02-22 21:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/e99f043dea87cc22089354e9dbee67b9d229871f', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 9, 'created': '2016-02-23 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/b9f7c33f365ecb8432d2b17a9947503d4538fc02', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 10, 'created': '2016-02-25 19:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/ebd178f6f8ceae95f331e44aa705180e95b51c69', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job: Ia5ea03b10249ae776a8857ad956c22e58c8eaac2\n\nBlueprint: add-integration-tests\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 11, 'created': '2016-03-03 18:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/b3ae8947b6fdda7198a8f7121cee657471bee030', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}, {'number': 12, 'created': '2016-03-04 16:12:45.000000000', 'files': ['tools/gate/integration/pre_test_hook.sh', 'app_catalog/tests/base.py', '.gitignore', 'test-requirements.txt', 'tools/gate/integration/commons', 'app_catalog/tests/integration_tests/pages/project/catalog/__init__.py', 'app_catalog/tests/integration_tests/tests/test_components.py', 'app_catalog/tests/integration_tests/pages/__init__.py', 'app_catalog/tests/settings.py', 'app_catalog/tests/integration_tests/horizon.conf', 'app_catalog/tests/integration_tests/__init__.py', 'app_catalog/tests/integration_tests/pages/project/catalog/applicationspage.py', 'requirements.txt', 'app_catalog/tests/urls.py', 'app_catalog/tests/__init__.py', 'app_catalog/tests/integration_tests/pages/project/__init__.py', 'app_catalog/tests/integration_tests/tests/__init__.py', 'tools/gate/integration/post_test_hook.sh', 'app_catalog/tests/integration_tests/pages/project/catalog/componentspage.py', 'app_catalog/tests/test_app_catalog.py', 'app_catalog/tests/integration_tests/tests/test_applications.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/app-catalog-ui/commit/16370f1a13935a971b0a7fb7f109dab9e69c0f56', 'message': 'Adding integration test support\n\n* Update test requirements for selenium testing\n* Add gate scripts\n* Add draft integration test config and test stub\n* Update tox for running integration tests\n\nThe patch for the gate job:\n\nChange-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d\n'}]",0,276438,16370f1a13935a971b0a7fb7f109dab9e69c0f56,42,6,12,7128,,,0,"Adding integration test support

* Update test requirements for selenium testing
* Add gate scripts
* Add draft integration test config and test stub
* Update tox for running integration tests

The patch for the gate job:

Change-Id: Ie6c8ee63afbda075298fdf2043990f5e9042308d
",git fetch https://review.opendev.org/openstack/app-catalog-ui refs/changes/38/276438/11 && git format-patch -1 --stdout FETCH_HEAD,"['tools/gate/integration/pre_test_hook.sh', 'test-requirements.txt', 'tools/gate/integration/commons', 'app_catalog/tests/integration_tests/tests/__init__.pyc', 'app_catalog/tests/integration_tests/pages/project/catalog/__init__.py', 'app_catalog/tests/__init__.pyc', 'app_catalog/tests/integration_tests/tests/test_components.py', 'app_catalog/tests/integration_tests/pages/__init__.py', 'app_catalog/tests/integration_tests/horizon.conf', 'app_catalog/tests/integration_tests/pages/project/catalog/applicationspage.py', 'requirements.txt', 'app_catalog/tests/base.pyc', 'app_catalog/tests/integration_tests/pages/project/__init__.py', 'app_catalog/tests/integration_tests/tests/__init__.py', 'app_catalog/tests/integration_tests/pages/__init__.pyc', 'app_catalog/tests/integration_tests/tests/test_applications.py', 'app_catalog/tests/base.py', 'app_catalog/tests/settings.py', 'app_catalog/tests/integration_tests/pages/project/catalog/__init__.pyc', 'app_catalog/tests/integration_tests/__init__.py', 'run_tests.sh', 'app_catalog/tests/integration_tests/pages/project/__init__.pyc', 'app_catalog/tests/urls.py', 'app_catalog/tests/__init__.py', 'app_catalog/tests/integration_tests/__init__.pyc', 'tools/gate/integration/post_test_hook.sh', 'app_catalog/tests/integration_tests/pages/project/catalog/componentspage.py', 'app_catalog/tests/test_app_catalog.py', 'tox.ini']",29,bde2dd24c49c3908cc85f4bc6d4c0b8b45216177,add-integration-tests,usedevelop = True install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} NOSE_WITH_OPENSTACK=1 NOSE_OPENSTACK_COLOR=1 NOSE_OPENSTACK_RED=0.05 NOSE_OPENSTACK_YELLOW=0.025 NOSE_OPENSTACK_SHOW_ELAPSED=1 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt whitelist_externals = /usr/bin/npm /bin/bash commands = python manage.py test [testenv:py27integration] basepython = python2.7 commands = /bin/bash run_tests.sh -N --integration --selenium-headless {posargs},deps = -r{toxinidir}/test-requirements.txt,1063,3
openstack%2Frequirements~master~I027d8080f4632f60a4cc4cab7a056e0fe5e7c82d,openstack/requirements,master,I027d8080f4632f60a4cc4cab7a056e0fe5e7c82d,Add heat-translator>=0.4.0,MERGED,2016-03-03 03:48:52.000000000,2016-03-05 15:22:16.000000000,2016-03-05 15:22:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6456}, {'_account_id': 13380}, {'_account_id': 16511}]","[{'number': 1, 'created': '2016-03-03 03:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ac9ce01ebcc9491c88475431740fdc882a27f874', 'message': 'Add heat-translator>=0.4.0\n\nThis adds heat-translator>=0.4.0 for use by Tacker in combination\nwith the existing tosca-parser library.\n\nThis library is in the OpenStack ecosystem along with tosca-parser\nand it maintained in conjuction with the tosca-parser library.\n\nChange-Id: I027d8080f4632f60a4cc4cab7a056e0fe5e7c82d\n'}, {'number': 2, 'created': '2016-03-05 13:26:09.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/eec35a7f08960d7e4475fdd0303612a8f67344fa', 'message': 'Add heat-translator>=0.4.0\n\nThis adds heat-translator>=0.4.0 for use by Tacker in combination\nwith the existing tosca-parser library.\n\nThis library is in the OpenStack ecosystem along with tosca-parser\nand it maintained in conjuction with the tosca-parser library.\n\nDepends-On: Ie143ad862b88034ef47470b85fd02c1d040415a7\nChange-Id: I027d8080f4632f60a4cc4cab7a056e0fe5e7c82d\n'}]",0,287581,eec35a7f08960d7e4475fdd0303612a8f67344fa,23,6,2,16511,,,0,"Add heat-translator>=0.4.0

This adds heat-translator>=0.4.0 for use by Tacker in combination
with the existing tosca-parser library.

This library is in the OpenStack ecosystem along with tosca-parser
and it maintained in conjuction with the tosca-parser library.

Depends-On: Ie143ad862b88034ef47470b85fd02c1d040415a7
Change-Id: I027d8080f4632f60a4cc4cab7a056e0fe5e7c82d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/81/287581/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,ac9ce01ebcc9491c88475431740fdc882a27f874,heat-translator,heat-translator===0.4.0,,2,0
openstack%2Frequirements~master~Ie143ad862b88034ef47470b85fd02c1d040415a7,openstack/requirements,master,Ie143ad862b88034ef47470b85fd02c1d040415a7,Fix other-requirements,MERGED,2016-03-05 08:17:31.000000000,2016-03-05 15:13:39.000000000,2016-03-05 15:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 8851}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-05 08:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3cfd11d260b86b2ed6caa5542d27dd353d05d7ed', 'message': 'Fix other-requirements\n\nWith the switch to bindep based packages the other-requirements.txt file\nis used. It contains an error: The package libxslt-devel is called\nlibxslt1-dev on Ubuntu. Add proper attributes.\n\nChange-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7\n'}, {'number': 2, 'created': '2016-03-05 08:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9a409952998560a8ff9aabd2cbac11ae41743446', 'message': 'Fix other-requirements\n\nWith the switch to bindep based packages the other-requirements.txt file\nis used. It contains an error: The libxslt devel is called\nlibxslt1-dev on Ubuntu Trusty.\n\nChange-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7\n'}, {'number': 3, 'created': '2016-03-05 08:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6c5cddf655ccf8ec6b7e419a6cd13ec9ce138687', 'message': 'Fix other-requirements\n\nWith the switch to bindep based packages the other-requirements.txt file\nis used. It contains an error: The libxslt devel is called\nlibxslt1-dev on Ubuntu Trusty.\n\nAlso, add mysql-server and mysql-client packages, those are needed by\ngate-requirements-python27.\n\nChange-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7\n'}, {'number': 4, 'created': '2016-03-05 13:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/8b8b8c115dd21045c25d3cddd0efea856d698039', 'message': 'Fix other-requirements\n\nWith the switch to bindep based packages the other-requirements.txt file\nis used. It contains an error: The libxslt devel is called\nlibxslt1-dev on Ubuntu Trusty.\n\nAlso, add mysql-server and mysql-client packages, as well as postgresql\npackages, those are needed by gate-requirements-python27.\n\nChange-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7\n'}, {'number': 5, 'created': '2016-03-05 13:17:38.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a9b887b4020431e177fd5f62092ef636a4ec398d', 'message': 'Fix other-requirements\n\nWith the switch to bindep based packages the other-requirements.txt file\nis used. It contains an error: The libxslt devel is called\nlibxslt1-dev on Ubuntu Trusty.\n\nAlso, add mysql-server and mysql-client packages, as well as postgresql\npackages, those are needed by gate-requirements-python27.\n\nAdd pypy packages for pypy gate.\n\nChange-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7\n'}]",0,288858,a9b887b4020431e177fd5f62092ef636a4ec398d,16,6,5,6547,,,0,"Fix other-requirements

With the switch to bindep based packages the other-requirements.txt file
is used. It contains an error: The libxslt devel is called
libxslt1-dev on Ubuntu Trusty.

Also, add mysql-server and mysql-client packages, as well as postgresql
packages, those are needed by gate-requirements-python27.

Add pypy packages for pypy gate.

Change-Id: Ie143ad862b88034ef47470b85fd02c1d040415a7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/58/288858/2 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,3cfd11d260b86b2ed6caa5542d27dd353d05d7ed,fix-other-requirements,libxslt-devel [platform:rpm] libxslt1-dev [platform:dpkg],libxslt-dev,2,1
openstack%2Foslo.config~master~I5201b8537b76ff731600720c8310ad4a2b9256e0,openstack/oslo.config,master,I5201b8537b76ff731600720c8310ad4a2b9256e0,Fallback if git is absent,MERGED,2016-03-02 21:28:07.000000000,2016-03-05 14:44:04.000000000,2016-03-05 14:44:04.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-02 21:28:07.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/a1a1c89c0d2963e4496cc8e7c0f1e6d0aa3a3104', 'message': 'Fallback if git is absent\n\nWhen building packages if git is absent, then we should\nfall back to a safe default.\n\nCloses-Bug: #1552251\nChange-Id: I5201b8537b76ff731600720c8310ad4a2b9256e0\n'}]",1,287448,a1a1c89c0d2963e4496cc8e7c0f1e6d0aa3a3104,9,3,1,5638,,,0,"Fallback if git is absent

When building packages if git is absent, then we should
fall back to a safe default.

Closes-Bug: #1552251
Change-Id: I5201b8537b76ff731600720c8310ad4a2b9256e0
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/48/287448/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,a1a1c89c0d2963e4496cc8e7c0f1e6d0aa3a3104,bug/1552251,"import timetry: html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0] except Exception: html_last_updated_fmt = time.ctime()","html_last_updated_fmt = subprocess.check_output(git_cmd, stdin=subprocess.PIPE)",6,2
openstack%2Foslo.messaging~master~I9731416117de088282259846d49c2ec3ce09d1dc,openstack/oslo.messaging,master,I9731416117de088282259846d49c2ec3ce09d1dc,Fallback if git is absent,MERGED,2016-03-02 21:27:20.000000000,2016-03-05 14:42:38.000000000,2016-03-05 14:42:38.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-02 21:27:20.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4e4caf67da4775167c941671a6ea694d6d409b88', 'message': 'Fallback if git is absent\n\nWhen building packages if git is absent, then we should\nfall back to a safe default.\n\nCloses-Bug: #1552251\nChange-Id: I9731416117de088282259846d49c2ec3ce09d1dc\n'}]",1,287447,4e4caf67da4775167c941671a6ea694d6d409b88,9,3,1,5638,,,0,"Fallback if git is absent

When building packages if git is absent, then we should
fall back to a safe default.

Closes-Bug: #1552251
Change-Id: I9731416117de088282259846d49c2ec3ce09d1dc
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/47/287447/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,4e4caf67da4775167c941671a6ea694d6d409b88,bug/1552251,"import timetry: html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0] except Exception: html_last_updated_fmt = time.ctime()","html_last_updated_fmt = subprocess.check_output(git_cmd, stdin=subprocess.PIPE)",6,2
openstack%2Foslo.messaging~master~I1e112d9ff0c3f1281b544f05d25eff2d3912fd6c,openstack/oslo.messaging,master,I1e112d9ff0c3f1281b544f05d25eff2d3912fd6c,Simulator: always use random messages for time-bound tests,MERGED,2016-03-03 11:01:11.000000000,2016-03-05 14:42:32.000000000,2016-03-05 14:42:32.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-03-03 11:01:11.000000000', 'files': ['tools/simulator.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/37c0db5769a3aa9417edb0db5a458b202e9d4522', 'message': 'Simulator: always use random messages for time-bound tests\n\nWhen the test is time-bound the simulator should use as many random\nmessages as possible.\n\nChange-Id: I1e112d9ff0c3f1281b544f05d25eff2d3912fd6c\n'}]",0,287711,37c0db5769a3aa9417edb0db5a458b202e9d4522,8,4,1,5950,,,0,"Simulator: always use random messages for time-bound tests

When the test is time-bound the simulator should use as many random
messages as possible.

Change-Id: I1e112d9ff0c3f1281b544f05d25eff2d3912fd6c
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/11/287711/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/simulator.py'],1,37c0db5769a3aa9417edb0db5a458b202e9d4522,sim-max-rnd-msgs,"MESSAGES_LIMIT = 1000def generate_messages(messages_count): # if an amount of messages to be sent is bigger than MESSAGES_LIMIT if messages_count > MESSAGES_LIMIT: messages_count = MESSAGES_LIMIT LOG.info(""Generating %d random messages"", messages_count) if args.mode in ['rpc-client', 'notify-client']: # always generate maximum number of messages for duration-limited tests generate_messages(MESSAGES_LIMIT if args.duration else args.messages) ","def init_msg(messages_count): # if an amount of messages to be sent is bigger than 1000 if messages_count > 1000: messages_count = 1000 LOG.info(""Preparing %d messages"", messages_count) i += 1 init_msg(args.messages)",11,7
openstack%2Foslo.log~master~I8b5dc551b51ea5b92d755927d811f9b60e87e4d2,openstack/oslo.log,master,I8b5dc551b51ea5b92d755927d811f9b60e87e4d2,Enable bandit in gate,MERGED,2016-03-01 03:29:57.000000000,2016-03-05 14:42:22.000000000,2016-03-05 14:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-03-01 03:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/dc828937331c9736194a54f772f6d58922a47a40', 'message': ""Enable bandit in gate\n\nRun security linter bandit as part of pep8. Pep8 is the usual\nlinter target and thus let's use it there instead of starting\nanother short-running job to enable it.\n\nChange-Id: I8b5dc551b51ea5b92d755927d811f9b60e87e4d2\n""}, {'number': 2, 'created': '2016-03-01 03:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ec7ed6682b528a50dde292d01f33183cf6db3999', 'message': ""Enable bandit in gate\n\nRun security linter bandit as part of pep8. Pep8 is the usual\nlinter target and thus let's use it there instead of starting\nanother short-running job to enable it.\n\nChange-Id: I8b5dc551b51ea5b92d755927d811f9b60e87e4d2\n""}, {'number': 3, 'created': '2016-03-03 03:35:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/a010cde94c6e70ce3fb87cede489936af1b90a98', 'message': ""Enable bandit in gate\n\nRun security linter bandit as part of pep8. Pep8 is the usual\nlinter target and thus let's use it there instead of starting\nanother short-running job to enable it.\n\nChange-Id: I8b5dc551b51ea5b92d755927d811f9b60e87e4d2\n""}]",4,286369,a010cde94c6e70ce3fb87cede489936af1b90a98,12,5,3,9796,,,0,"Enable bandit in gate

Run security linter bandit as part of pep8. Pep8 is the usual
linter target and thus let's use it there instead of starting
another short-running job to enable it.

Change-Id: I8b5dc551b51ea5b92d755927d811f9b60e87e4d2
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/69/286369/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dc828937331c9736194a54f772f6d58922a47a40,mv_bandit,"envlist = py34,py27,pep8deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_utils -n5","envlist = py34,py27,pep8,banditcommands = flake8",6,2
openstack%2Foslo.messaging~master~I60cbc6c452945000add5a65263d1ab4e42dd91f9,openstack/oslo.messaging,master,I60cbc6c452945000add5a65263d1ab4e42dd91f9,Simulator: implement own random generator instead of scipy,MERGED,2016-03-02 16:12:22.000000000,2016-03-05 14:40:05.000000000,2016-03-05 14:40:04.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-02 16:12:22.000000000', 'files': ['tools/simulator.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/97385ef5b5889c0b4eb7cbbe3323c26fed021e54', 'message': 'Simulator: implement own random generator instead of scipy\n\nDependency on scipy results in extra requirements to the system\n(include the need of Fortran compiler). With this patch the\nweighted random choice algorithm is implemented directly.\n\nChange-Id: I60cbc6c452945000add5a65263d1ab4e42dd91f9\n'}]",1,287292,97385ef5b5889c0b4eb7cbbe3323c26fed021e54,7,3,1,5950,,,0,"Simulator: implement own random generator instead of scipy

Dependency on scipy results in extra requirements to the system
(include the need of Fortran compiler). With this patch the
weighted random choice algorithm is implemented directly.

Change-Id: I60cbc6c452945000add5a65263d1ab4e42dd91f9
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/92/287292/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/simulator.py'],1,97385ef5b5889c0b4eb7cbbe3323c26fed021e54,sim-remove-scipy,"import bisectRANDOM_GENERATOR = NoneDISTRIBUTION_BUCKET_SIZE = 500 range_start = ((msg_length / DISTRIBUTION_BUCKET_SIZE) * DISTRIBUTION_BUCKET_SIZE + 1) accumulated_distribution = [] running_total = 0 for range_start in ranges_start: norm = float(ranges[range_start]) / total_count running_total += norm accumulated_distribution.append(running_total) def weighted_random_choice(): r = random.random() * running_total start = ranges_start[bisect.bisect_right(accumulated_distribution, r)] return random.randrange(start, start + DISTRIBUTION_BUCKET_SIZE) return weighted_random_choice for i in range(messages_count): length = RANDOM_GENERATOR() RANDOM_GENERATOR = init_random_generator()","from scipy.stats import rv_discrete RANDOM_VARIABLE = None range_start = (msg_length / 500) * 500 + 1 ranges_dist = [] for r in ranges_start: r_dist = float(ranges[r]) / total_count ranges_dist.append(r_dist) random_var = rv_discrete(values=(ranges_start, ranges_dist)) return random_var ranges = RANDOM_VARIABLE.rvs(size=messages_count) i = 0 for range_start in ranges: length = random.randint(range_start, range_start + 497) RANDOM_VARIABLE = init_random_generator()",23,15
openstack%2Foslo.middleware~master~I034ccced9ec0121bf75c737ac19a498b4ebce1a9,openstack/oslo.middleware,master,I034ccced9ec0121bf75c737ac19a498b4ebce1a9,CORS tests now use a transient configuration,MERGED,2016-02-26 19:03:42.000000000,2016-03-05 14:38:58.000000000,2016-03-05 14:38:58.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2016-02-26 19:03:42.000000000', 'files': ['oslo_middleware/tests/test_cors.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/cce21ca10b2ae1ff694280bc19f575abaef66365', 'message': 'CORS tests now use a transient configuration\n\nAs opposed to a global configuration. This should make testing\na bit more consistent, and less likely to have sideffects.\n\nChange-Id: I034ccced9ec0121bf75c737ac19a498b4ebce1a9\n'}]",0,285500,cce21ca10b2ae1ff694280bc19f575abaef66365,7,3,1,9717,,,0,"CORS tests now use a transient configuration

As opposed to a global configuration. This should make testing
a bit more consistent, and less likely to have sideffects.

Change-Id: I034ccced9ec0121bf75c737ac19a498b4ebce1a9
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/00/285500/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_middleware/tests/test_cors.py'],1,cce21ca10b2ae1ff694280bc19f575abaef66365,cors," def setUp(self): """"""Setup the tests."""""" super(CORSTestBase, self).setUp() # Set up the config fixture. self.config_fixture = self.useFixture(fixture.Config()) self.config = self.config_fixture.conf class CORSTestFilterFactory(CORSTestBase): self.config([]) self.config([]) self.config_fixture.load_raw_values(group='cors.subdomain') self.application = cors.CORS(test_application, self.config) fixture = self.config_fixture # Line length accommodation fixture.load_raw_values(group='cors', allowed_origin='http://valid.example.com', allow_credentials='False', max_age='', expose_headers='', allow_methods='GET', allow_headers='') fixture.load_raw_values(group='cors.credentials', allowed_origin='http://creds.example.com', allow_credentials='True') fixture.load_raw_values(group='cors.exposed-headers', allowed_origin='http://headers.example.com', expose_headers='X-Header-1,X-Header-2', allow_headers='X-Header-1,X-Header-2') fixture.load_raw_values(group='cors.cached', allowed_origin='http://cached.example.com', max_age='3600') fixture.load_raw_values(group='cors.get-only', allowed_origin='http://get.example.com', allow_methods='GET') fixture.load_raw_values(group='cors.all-methods', allowed_origin='http://all.example.com', allow_methods='GET,PUT,POST,DELETE,HEAD') fixture.load_raw_values(group='cors.duplicate', allowed_origin='http://domain1.example.com,' 'http://domain2.example.com') self.application = cors.CORS(test_application, self.config) gc = self.config.cors cc = self.config['cors.credentials'] ec = self.config['cors.exposed-headers'] chc = self.config['cors.cached'] goc = self.config['cors.get-only'] ac = self.config['cors.all-methods'] ac = self.config['cors.duplicate'] fixture = self.config_fixture # Line length accommodation fixture.load_raw_values(group='cors', allowed_origin='http://valid.example.com', allow_credentials='False', max_age='', expose_headers='', allow_methods='GET', allow_headers='') fixture.load_raw_values(group='cors.credentials', allowed_origin='http://creds.example.com', allow_credentials='True') fixture.load_raw_values(group='cors.exposed-headers', allowed_origin='http://headers.example.com', expose_headers='X-Header-1,X-Header-2', allow_headers='X-Header-1,X-Header-2') fixture.load_raw_values(group='cors.cached', allowed_origin='http://cached.example.com', max_age='3600') fixture.load_raw_values(group='cors.get-only', allowed_origin='http://get.example.com', allow_methods='GET') fixture.load_raw_values(group='cors.all-methods', allowed_origin='http://all.example.com', allow_methods='GET,PUT,POST,DELETE,HEAD') self.application = cors.CORS(test_application, self.config) gc = self.config.cors cc = self.config['cors.credentials'] ec = self.config['cors.exposed-headers'] chc = self.config['cors.cached'] goc = self.config['cors.get-only'] ac = self.config['cors.all-methods'] fixture = self.config_fixture # Line length accommodation fixture.load_raw_values(group='cors', allowed_origin='http://default.example.com', allow_credentials='True', max_age='', expose_headers='', allow_methods='GET,PUT,POST,DELETE,HEAD', allow_headers='') fixture.load_raw_values(group='cors.wildcard', allowed_origin='*', allow_methods='GET') self.application = cors.CORS(test_application, self.config) gc = self.config.cors ac = self.config['cors.wildcard'] fixture = self.config_fixture # Line length accommodation fixture.load_raw_values(group='cors', allowed_origin='http://default.example.com', allow_credentials='True', max_age='', expose_headers='X-Configured', allow_methods='GET', allow_headers='X-Configured') self.application = cors.CORS(test_application, self.config)","from oslo_config import cfgclass CORSTestFilterFactory(test_base.BaseTestCase): self.useFixture(fixture.Config()).conf([]) self.useFixture(fixture.Config()).conf([]) config = self.useFixture(fixture.Config(cfg.CONF)) config.load_raw_values(group='cors.subdomain') self.application = cors.CORS(test_application, cfg.CONF) # Set up the config fixture. config = self.useFixture(fixture.Config(cfg.CONF)) config.load_raw_values(group='cors', allowed_origin='http://valid.example.com', allow_credentials='False', max_age='', expose_headers='', allow_methods='GET', allow_headers='') config.load_raw_values(group='cors.credentials', allowed_origin='http://creds.example.com', allow_credentials='True') config.load_raw_values(group='cors.exposed-headers', allowed_origin='http://headers.example.com', expose_headers='X-Header-1,X-Header-2', allow_headers='X-Header-1,X-Header-2') config.load_raw_values(group='cors.cached', allowed_origin='http://cached.example.com', max_age='3600') config.load_raw_values(group='cors.get-only', allowed_origin='http://get.example.com', allow_methods='GET') config.load_raw_values(group='cors.all-methods', allowed_origin='http://all.example.com', allow_methods='GET,PUT,POST,DELETE,HEAD') config.load_raw_values(group='cors.duplicate', allowed_origin='http://domain1.example.com,' 'http://domain2.example.com') self.application = cors.CORS(test_application, cfg.CONF) gc = cfg.CONF.cors cc = cfg.CONF['cors.credentials'] ec = cfg.CONF['cors.exposed-headers'] chc = cfg.CONF['cors.cached'] goc = cfg.CONF['cors.get-only'] ac = cfg.CONF['cors.all-methods'] ac = cfg.CONF['cors.duplicate'] # Set up the config fixture. config = self.useFixture(fixture.Config(cfg.CONF)) config.load_raw_values(group='cors', allowed_origin='http://valid.example.com', allow_credentials='False', max_age='', expose_headers='', allow_methods='GET', allow_headers='') config.load_raw_values(group='cors.credentials', allowed_origin='http://creds.example.com', allow_credentials='True') config.load_raw_values(group='cors.exposed-headers', allowed_origin='http://headers.example.com', expose_headers='X-Header-1,X-Header-2', allow_headers='X-Header-1,X-Header-2') config.load_raw_values(group='cors.cached', allowed_origin='http://cached.example.com', max_age='3600') config.load_raw_values(group='cors.get-only', allowed_origin='http://get.example.com', allow_methods='GET') config.load_raw_values(group='cors.all-methods', allowed_origin='http://all.example.com', allow_methods='GET,PUT,POST,DELETE,HEAD') self.application = cors.CORS(test_application, cfg.CONF) gc = cfg.CONF.cors cc = cfg.CONF['cors.credentials'] ec = cfg.CONF['cors.exposed-headers'] chc = cfg.CONF['cors.cached'] goc = cfg.CONF['cors.get-only'] ac = cfg.CONF['cors.all-methods'] # Set up the config fixture. config = self.useFixture(fixture.Config(cfg.CONF)) config.load_raw_values(group='cors', allowed_origin='http://default.example.com', allow_credentials='True', max_age='', expose_headers='', allow_methods='GET,PUT,POST,DELETE,HEAD', allow_headers='') config.load_raw_values(group='cors.wildcard', allowed_origin='*', allow_methods='GET') self.application = cors.CORS(test_application, cfg.CONF) gc = cfg.CONF.cors ac = cfg.CONF['cors.wildcard'] # Set up the config fixture. config = self.useFixture(fixture.Config(cfg.CONF)) config.load_raw_values(group='cors', allowed_origin='http://default.example.com', allow_credentials='True', max_age='', expose_headers='X-Configured', allow_methods='GET', allow_headers='X-Configured') self.application = cors.CORS(test_application, cfg.CONF)",102,104
openstack%2Foslo.config~master~I4dc181ec30fd632043619e4a34093772de23eb2a,openstack/oslo.config,master,I4dc181ec30fd632043619e4a34093772de23eb2a,Move bandit into pep8,MERGED,2016-02-26 09:15:41.000000000,2016-03-05 14:32:39.000000000,2016-03-05 14:32:39.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-26 09:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/6af80f83187599351ae07f6187aba6ce457835d5', 'message': ""Move bandit into pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another node for this short-running job. And will remove\nthe bandit job in project-config.\n\nThis copy from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}, {'number': 2, 'created': '2016-02-26 09:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/ad0c47a20b8f66eab4ebacc90f002bbfc82e5854', 'message': ""Move bandit into pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another short-running job to enable it.\n\nThis copy from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}, {'number': 3, 'created': '2016-02-26 09:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/9ce75d16a090a634041c44de367ebc730b9ea426', 'message': ""Enable bandit in pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another short-running job to enable it.\n\nThis copy from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}, {'number': 4, 'created': '2016-02-26 15:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/224696a309113d61da4a6e19daf29cc9e29d8185', 'message': ""Move bandit into pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another short-running job to enable it.\n\nThis copy the idea from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}, {'number': 5, 'created': '2016-03-01 02:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/26efc66bb6f5cd60c053c2756d0a072c6a8423a2', 'message': ""Move bandit into pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another short-running job to enable it.\n\nThis copy the idea from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}, {'number': 6, 'created': '2016-03-02 05:27:15.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/47318f2490524482f30d40f3638848c771fd4b50', 'message': ""Move bandit into pep8\n\nRun security linter bandit as part of pep8. Pep8\nis the usual linter target and thus let's use it there instead of\nstarting another short-running job to enable it.\n\nThis copy the idea from I54a4fccebb375517f9cd129f62f8f0c795b6edcc\n\nChange-Id: I4dc181ec30fd632043619e4a34093772de23eb2a\n""}]",7,285176,47318f2490524482f30d40f3638848c771fd4b50,31,6,6,9796,,,0,"Move bandit into pep8

Run security linter bandit as part of pep8. Pep8
is the usual linter target and thus let's use it there instead of
starting another short-running job to enable it.

This copy the idea from I54a4fccebb375517f9cd129f62f8f0c795b6edcc

Change-Id: I4dc181ec30fd632043619e4a34093772de23eb2a
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/76/285176/5 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6af80f83187599351ae07f6187aba6ce457835d5,mv_bandit,commands = flake8 # Run security linter bandit -r oslo_config -n5,commands = flake8,4,1
openstack%2Fproject-config~master~I6bccea38b7492c294870388df2ceff43fb99124f,openstack/project-config,master,I6bccea38b7492c294870388df2ceff43fb99124f,Normalize projects.yaml,MERGED,2016-03-05 06:20:22.000000000,2016-03-05 13:35:00.000000000,2016-03-05 13:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 06:20:22.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c1bbde367de734a38b85153a6d04f418507c2a1', 'message': 'Normalize projects.yaml\n\nChange-Id: I6bccea38b7492c294870388df2ceff43fb99124f\n'}]",0,288847,6c1bbde367de734a38b85153a6d04f418507c2a1,16,4,1,11131,,,0,"Normalize projects.yaml

Change-Id: I6bccea38b7492c294870388df2ceff43fb99124f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/47/288847/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,6c1bbde367de734a38b85153a6d04f418507c2a1,project-yaml-normalization,, upstream: https://github.com/keedya/shovel-horizon.git,0,1
openstack%2Fproject-config~master~I974383bb035469e12093c1a961ff051c09cb7d93,openstack/project-config,master,I974383bb035469e12093c1a961ff051c09cb7d93,Clean up bindep-fallback.txt,MERGED,2016-03-05 00:09:53.000000000,2016-03-05 13:34:16.000000000,2016-03-05 13:34:16.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 11685}]","[{'number': 1, 'created': '2016-03-05 00:09:53.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cb7323eef1007db0f3abf1688e0bdc52921ed4c1', 'message': 'Clean up bindep-fallback.txt\n\nStop being overly-specific about platform matches, and simplify (or\nremove) platform tags where the end result matches the same systems\nfor platforms we actually run.\n\nChange-Id: I974383bb035469e12093c1a961ff051c09cb7d93\n'}]",0,288811,cb7323eef1007db0f3abf1688e0bdc52921ed4c1,13,5,1,5263,,,0,"Clean up bindep-fallback.txt

Stop being overly-specific about platform matches, and simplify (or
remove) platform tags where the end result matches the same systems
for platforms we actually run.

Change-Id: I974383bb035469e12093c1a961ff051c09cb7d93
",git fetch https://review.opendev.org/openstack/project-config refs/changes/11/288811/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,cb7323eef1007db0f3abf1688e0bdc52921ed4c1,bindep,liberasurecode-dev [platform:dpkg] liberasurecode-devel [platform:rpm]swig,liberasurecode-dev [platform:ubuntu-precise platform:ubuntu-trusty] liberasurecode-devel [platform:fedora-22 platform:fedora-23 platform:centos-7]swig [platform:dpkg] swig [platform:rpm],3,4
openstack%2Fopenstack-manuals~master~Id7a0b6f9f7d5d24df7d37bfc250f182efaefee2e,openstack/openstack-manuals,master,Id7a0b6f9f7d5d24df7d37bfc250f182efaefee2e,Fix name of flavor in slow VM description,MERGED,2016-03-04 17:33:28.000000000,2016-03-05 13:19:44.000000000,2016-03-05 13:19:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-03-04 17:33:28.000000000', 'files': ['doc/admin-guide-cloud/source/compute-flavors.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0990397e1ebb376929be3d87c93506511e4df726', 'message': 'Fix name of flavor in slow VM description\n\nThe flavor name in the slow VM example was set to m1.low_cpu but the example\ngiven used the flavor name FLAVOR-NAME. The change proposed is to correct the\ndescriptive text.\n\nChange-Id: Id7a0b6f9f7d5d24df7d37bfc250f182efaefee2e\n'}]",0,288604,0990397e1ebb376929be3d87c93506511e4df726,9,4,1,136,,,0,"Fix name of flavor in slow VM description

The flavor name in the slow VM example was set to m1.low_cpu but the example
given used the flavor name FLAVOR-NAME. The change proposed is to correct the
descriptive text.

Change-Id: Id7a0b6f9f7d5d24df7d37bfc250f182efaefee2e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/288604/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/source/compute-flavors.rst'],1,0990397e1ebb376929be3d87c93506511e4df726,wrongflavor," In this example, an instance of ``FLAVOR-NAME`` can only consume"," In this example, the instance of ``m1.low_cpu`` can only consume",1,1
openstack%2Fproject-config~master~Id84f4b7362434827fc27b829254614c9c510c3e5,openstack/project-config,master,Id84f4b7362434827fc27b829254614c9c510c3e5,Disable ovh-bhs1,ABANDONED,2016-03-05 08:28:43.000000000,2016-03-05 13:16:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-05 08:28:43.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0dae9a944f363dea43c293777c53310ed21aeaef', 'message': 'Disable ovh-bhs1\n\novh-bhs1 cannot reach our mirror and jobs fail completely. Disable the\ncloud until those can be fixed.\n\nChange-Id: Id84f4b7362434827fc27b829254614c9c510c3e5\n'}]",0,288859,0dae9a944f363dea43c293777c53310ed21aeaef,4,2,1,6547,,,0,"Disable ovh-bhs1

ovh-bhs1 cannot reach our mirror and jobs fail completely. Disable the
cloud until those can be fixed.

Change-Id: Id84f4b7362434827fc27b829254614c9c510c3e5
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/288859/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,0dae9a944f363dea43c293777c53310ed21aeaef,disable-ovh, max-servers: -1, max-servers: 159,1,1
openstack%2Fsecurity-doc~master~I9093e8b784377f24794deb80eb302b7124bfb2a8,openstack/security-doc,master,I9093e8b784377f24794deb80eb302b7124bfb2a8,Reworded section on SSL and TLS,MERGED,2016-03-04 21:14:50.000000000,2016-03-05 13:15:05.000000000,2016-03-05 13:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 12325}, {'_account_id': 12442}]","[{'number': 1, 'created': '2016-03-04 21:14:50.000000000', 'files': ['security-guide/source/secure-communication/introduction-to-ssl-and-tls.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/9bb988f73cc11da21c7a58548d5c41b9683a9826', 'message': 'Reworded section on SSL and TLS\n\nSlight wording tweak and spelling correction.\n\nCloses Bug: #1552013\n\nChange-Id: I9093e8b784377f24794deb80eb302b7124bfb2a8\n'}]",0,288742,9bb988f73cc11da21c7a58548d5c41b9683a9826,8,4,1,11397,,,0,"Reworded section on SSL and TLS

Slight wording tweak and spelling correction.

Closes Bug: #1552013

Change-Id: I9093e8b784377f24794deb80eb302b7124bfb2a8
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/42/288742/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/secure-communication/introduction-to-ssl-and-tls.rst'],1,9bb988f73cc11da21c7a58548d5c41b9683a9826,bug/1552013,"client compatibility, however exercise caution when enabling this protocol. Only enable TLS version 1.1 if there is a mandatory compatibility requirement and you are aware of the risks involved. All versions of SSL, the predecessor to TLS, must not be used due to multiple public vulnerabilities. When you are using TLS 1.2 and control both the clients and``ECDHE-ECDSA-AES256-GCM-SHA384``. In circumstances where you do not control both endpoints and are using TLS 1.1 or 1.2 the more general","client compatibility, however, excercise caution when enabling this protocol. Only enable TLS version 1.1 if there is a mandatory requirement and you are aware of the risks involved. Older versions of TLS should not be used as these versions include SSLv2 which is deprecated, and SSLv3 which suffers from the attack known as POODLE. When you are using TLS 1.2 and in control of both the clients and``ECDHE-ECDSA-AES256-GCM-SHA384``. In circumstances where you don’t control both ends and are using TLS 1.1 or 1.2 the more general",9,8
openstack%2Fproject-config~master~I14cfe21bbeee36bed71fe799ac5b0089c1bb1cf1,openstack/project-config,master,I14cfe21bbeee36bed71fe799ac5b0089c1bb1cf1,Sort bindep-fallback.txt,MERGED,2016-03-05 00:09:53.000000000,2016-03-05 13:10:30.000000000,2016-03-05 13:10:29.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 11685}]","[{'number': 1, 'created': '2016-03-05 00:09:53.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/48663e33119b245ae6dda4634f7decc9ad949fd1', 'message': 'Sort bindep-fallback.txt\n\nSort the bindep fallback list prior to making normalization cleanup\nchanges, for saner reviewing.\n\nChange-Id: I14cfe21bbeee36bed71fe799ac5b0089c1bb1cf1\n'}]",0,288810,48663e33119b245ae6dda4634f7decc9ad949fd1,22,5,1,5263,,,0,"Sort bindep-fallback.txt

Sort the bindep fallback list prior to making normalization cleanup
changes, for saner reviewing.

Change-Id: I14cfe21bbeee36bed71fe799ac5b0089c1bb1cf1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/10/288810/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,48663e33119b245ae6dda4634f7decc9ad949fd1,bindep,libuuid-devel [platform:rpm]python3-dev [platform:dpkg] python3-devel [platform:fedora]python34-devel [platform:centos]swig [platform:rpm],python3-dev [platform:dpkg]python3-devel [platform:fedora] python34-devel [platform:centos]swig [platform:rpm]libuuid-devel [platform:rpm],5,5
openstack%2Fopenstack-ansible-lxc_container_create~master~I4d0c24ad4338bbee82f174fc5f75eff1a5503b92,openstack/openstack-ansible-lxc_container_create,master,I4d0c24ad4338bbee82f174fc5f75eff1a5503b92,Add curl to bindep requirements,ABANDONED,2016-03-04 19:21:16.000000000,2016-03-05 12:58:06.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-04 19:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/35703698b0c6d14c4c399e68a297435e7abc23f5', 'message': 'Add curl to bindep requirements\n\nChange-Id: I4d0c24ad4338bbee82f174fc5f75eff1a5503b92\n'}, {'number': 2, 'created': '2016-03-05 04:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/dc249b743cec5deb2f8c0e8386cae8f36463bbea', 'message': 'Add curl to bindep requirements\n\nChange-Id: I4d0c24ad4338bbee82f174fc5f75eff1a5503b92\n'}, {'number': 3, 'created': '2016-03-05 05:49:44.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/f0cd541136e0fca68d3aec47837209080394afa6', 'message': 'Add curl to bindep requirements\n\nChange-Id: I4d0c24ad4338bbee82f174fc5f75eff1a5503b92\n'}]",0,288661,f0cd541136e0fca68d3aec47837209080394afa6,11,3,3,6816,,,0,"Add curl to bindep requirements

Change-Id: I4d0c24ad4338bbee82f174fc5f75eff1a5503b92
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/61/288661/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,35703698b0c6d14c4c399e68a297435e7abc23f5,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",,16,0
openstack%2Fopenstack-ansible-galera_server~master~If3c85426568317ec9c2990b53361d9efbd31dabb,openstack/openstack-ansible-galera_server,master,If3c85426568317ec9c2990b53361d9efbd31dabb,Add curl to bindep requirements,ABANDONED,2016-03-04 19:20:57.000000000,2016-03-05 12:54:34.000000000,,"[{'_account_id': 3}, {'_account_id': 538}]","[{'number': 1, 'created': '2016-03-04 19:20:57.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/9437a088b268152065e15d708edf8740bd22a50c', 'message': 'Add curl to bindep requirements\n\nChange-Id: If3c85426568317ec9c2990b53361d9efbd31dabb\n'}]",0,288659,9437a088b268152065e15d708edf8740bd22a50c,4,2,1,6816,,,0,"Add curl to bindep requirements

Change-Id: If3c85426568317ec9c2990b53361d9efbd31dabb
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/59/288659/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,9437a088b268152065e15d708edf8740bd22a50c,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",,16,0
openstack%2Fopenstack-ansible-galera_client~master~I8655eeef9b00cc4629b8f312450b3ce4cab3b7f0,openstack/openstack-ansible-galera_client,master,I8655eeef9b00cc4629b8f312450b3ce4cab3b7f0,Add curl to bindep requirements,ABANDONED,2016-03-04 19:20:48.000000000,2016-03-05 12:52:23.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-03-04 19:20:48.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/0d11ac0a6d996f8229e6fd084bf58c2d52de4302', 'message': 'Add curl to bindep requirements\n\nChange-Id: I8655eeef9b00cc4629b8f312450b3ce4cab3b7f0\n'}]",0,288658,0d11ac0a6d996f8229e6fd084bf58c2d52de4302,3,1,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I8655eeef9b00cc4629b8f312450b3ce4cab3b7f0
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/58/288658/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,0d11ac0a6d996f8229e6fd084bf58c2d52de4302,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",,16,0
openstack%2Fnova~master~I1254019a536badcd4effa5fba863f7390073bd52,openstack/nova,master,I1254019a536badcd4effa5fba863f7390073bd52,Fix return codes in force_complete API,ABANDONED,2016-02-24 11:04:51.000000000,2016-03-05 12:05:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 14131}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-24 11:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9f2f472e9bd3b2bb3b793d817f2aaefe2d2f7a5', 'message': '[WIP] Fix return codes in force_complete API\n\nChange-Id: I1254019a536badcd4effa5fba863f7390073bd52\n'}, {'number': 2, 'created': '2016-02-24 14:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d69b0363d58623a219ae1b7c1c710c4a068ab5a6', 'message': 'Fix return codes in force_complete API\n\nCurrently if migration is not found for instance we raise\nHTTPBadRequest which is not correct according to API guideline.\nThis patch changes this exception to HTTPNotFound\n\nChange-Id: I1254019a536badcd4effa5fba863f7390073bd52\n'}, {'number': 3, 'created': '2016-02-24 14:56:53.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_server_migrations.py', 'nova/api/openstack/compute/server_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/50ed7bd3cbc785fff95017e4a29caff9272ea19a', 'message': 'Fix return codes in force_complete API\n\nCurrently if migration is not found for instance we raise\nHTTPBadRequest which is not correct according to API guideline.\nThis patch changes this exception to HTTPNotFound\n\nChange-Id: I1254019a536badcd4effa5fba863f7390073bd52\n'}]",8,284068,50ed7bd3cbc785fff95017e4a29caff9272ea19a,33,16,3,12299,,,0,"Fix return codes in force_complete API

Currently if migration is not found for instance we raise
HTTPBadRequest which is not correct according to API guideline.
This patch changes this exception to HTTPNotFound

Change-Id: I1254019a536badcd4effa5fba863f7390073bd52
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/284068/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_server_migrations.py', 'nova/api/openstack/compute/server_migrations.py']",2,b9f2f472e9bd3b2bb3b793d817f2aaefe2d2f7a5,force-complete," except (exception.InstanceNotFound, exception.MigrationNotFoundForInstance) as e: raise exc.HTTPNotFound(explanation=e.format_message()) except exception.InvalidMigrationState as e:"," except exception.InstanceNotFound as e: raise exc.HTTPNotFound(explanation=e.format_message()) except (exception.MigrationNotFoundByStatus, exception.InvalidMigrationState, exception.MigrationNotFoundForInstance) as e:",9,9
openstack%2Fkolla~master~I05bc0c95533372af11575f345e64d6f57ef9c157,openstack/kolla,master,I05bc0c95533372af11575f345e64d6f57ef9c157,Fix Keystone v3 for Manila,MERGED,2016-03-04 16:13:57.000000000,2016-03-05 10:55:24.000000000,2016-03-04 17:57:09.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 14119}, {'_account_id': 16233}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-03-04 16:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/19c1de875e62304e51e8c185fc3e6c158732c021', 'message': 'Fix Keystone v3 and Horizon for Manila\n\nTrivialFix\n\nChange-Id: I05bc0c95533372af11575f345e64d6f57ef9c157\n'}, {'number': 2, 'created': '2016-03-04 16:29:24.000000000', 'files': ['ansible/roles/manila/tasks/register.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/93df1da8ddd7ff3cb7d7c2468045b5b67a853fc8', 'message': 'Fix Keystone v3 for Manila\n\nTrivialFix\n\nChange-Id: I05bc0c95533372af11575f345e64d6f57ef9c157\n'}]",9,288558,93df1da8ddd7ff3cb7d7c2468045b5b67a853fc8,14,6,2,16233,,,0,"Fix Keystone v3 for Manila

TrivialFix

Change-Id: I05bc0c95533372af11575f345e64d6f57ef9c157
",git fetch https://review.opendev.org/openstack/kolla refs/changes/58/288558/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/manila/tasks/register.yml'],1,19c1de875e62304e51e8c185fc3e6c158732c021,," - {'interface': 'admin', 'url': '{{ manila_admin_endpoint }}', 'service_name': 'manila', 'service_type': 'share'} - {'interface': 'internal', 'url': '{{ manila_internal_endpoint }}', 'service_name': 'manila', 'service_type': 'share'} - {'interface': 'public', 'url': '{{ manila_public_endpoint }}', 'service_name': 'manila', 'service_type': 'share'} - {'interface': 'admin', 'url': '{{ manila_admin_endpoint }}', 'service_name': 'manilav2', 'service_type': 'sharev2'} - {'interface': 'internal', 'url': '{{ manila_internal_endpoint }}', 'service_name': 'manilav2', 'service_type': 'sharev2'} - {'interface': 'public', 'url': '{{ manila_public_endpoint }}', 'service_name': 'manilav2', 'service_type': 'sharev2'}"," - {'interface': 'admin', 'url': '{{ mistral_admin_endpoint }}'} - {'interface': 'internal', 'url': '{{ mistral_internal_endpoint }}'} - {'interface': 'public', 'url': '{{ mistral_public_endpoint }}'} - {'interface': 'admin', 'url': '{{ mistral_v2_admin_endpoint }}'} - {'interface': 'internal', 'url': '{{ mistral_v2_internal_endpoint }}'} - {'interface': 'public', 'url': '{{ mistral_v2_public_endpoint }}'}",6,6
openstack%2Fglance~master~I6130c959d0d8420d7208d4e36fe23be5667ae9b5,openstack/glance,master,I6130c959d0d8420d7208d4e36fe23be5667ae9b5,Fix some words spelling,ABANDONED,2016-02-03 07:43:55.000000000,2016-03-05 09:58:13.000000000,,"[{'_account_id': 3}, {'_account_id': 5314}, {'_account_id': 9382}, {'_account_id': 14676}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-03 07:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/671660380c66d9946387046b3dc9650110456c9d', 'message': 'Fix some word spellings\n\nchange origional to original\nseperated to separated\n\nChange-Id: I6130c959d0d8420d7208d4e36fe23be5667ae9b5\n'}, {'number': 2, 'created': '2016-02-03 15:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f2fbe231afb387cb726a4ca9e3084d8a2d2d68e5', 'message': 'Fix some word spellings\n\nchange origional to original\nseperated to separated\n\nChange-Id: I6130c959d0d8420d7208d4e36fe23be5667ae9b5\n'}, {'number': 3, 'created': '2016-02-03 15:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e329a72c8f5fd82133237199e0d43ae43ada94c3', 'message': 'Fix some word spellings\n\nchange origional to original\nseperated to separated\n\nChange-Id: I6130c959d0d8420d7208d4e36fe23be5667ae9b5\n'}, {'number': 4, 'created': '2016-02-03 16:23:46.000000000', 'files': ['etc/glance-api.conf', 'doc/source/configuring.rst', 'etc/glance-registry.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/37ffdaa55eec5d1976da3252f6ed57a7ecd2ad9e', 'message': 'Fix some words spelling\n\nchange\nseperated to separated\n\nChange-Id: I6130c959d0d8420d7208d4e36fe23be5667ae9b5\n'}]",0,275543,37ffdaa55eec5d1976da3252f6ed57a7ecd2ad9e,16,5,4,16237,,,0,"Fix some words spelling

change
seperated to separated

Change-Id: I6130c959d0d8420d7208d4e36fe23be5667ae9b5
",git fetch https://review.opendev.org/openstack/glance refs/changes/43/275543/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/glance-api.conf', 'glance/db/sqlalchemy/migrate_repo/versions/039_add_changes_to_satisfy_models_metadef.py', 'doc/source/configuring.rst', 'etc/glance-registry.conf']",4,671660380c66d9946387046b3dc9650110456c9d,spell-fix,"# datacenter path, separated by "":"". An optional weight may be given # after the datastore name, separated again by "":"". Thus, the required","# datacenter path, seperated by "":"". An optional weight may be given # after the datastore name, seperated again by "":"". Thus, the required",9,9
openstack%2Fnova~stable%2Fliberty~I4fa1c258db58c70dfbf0178b7bb13978fda3a11f,openstack/nova,stable/liberty,I4fa1c258db58c70dfbf0178b7bb13978fda3a11f,Propagate qemu-img errors to compute manager,MERGED,2016-03-04 17:13:17.000000000,2016-03-05 09:57:22.000000000,2016-03-04 22:19:45.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-03-04 17:13:17.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/virt/test_images.py', 'nova/compute/manager.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b806adb032567c2c84d61834e6f8d2684723c194', 'message': 'Propagate qemu-img errors to compute manager\n\nWhen qemu-img is called with oslo_concurrency.process_utils.execute\nthe ProcessExecutionError was raised when qemu-img either fails to\nexecute or has a non-zero exit code. This error did not propagate\nup to the compute manager with any meaningful information meaning\nthat if an instance build fails the error message is the generic\n""There are not enough hosts available"".\n\nThis change captures ProcessExecutionError and re-raises the\nexception as either InvalidDiskInfo (in qemu_img_info) or\nImageUnacceptable (in convert_image and fetch_to_raw) and makes the\nmanager accept this as a cause for a BuildAbortException on the\nlogic that if the image is bad, things are dire, let\'s bail.\n\nBased on the code in qemu_img_info it appears there was a\nmisunderstanding of how process_utils.execute behaves so it seems\nlikely this problem is present elsewhere in the code. This change\nattempts to only address the issue as it shows up on the new\ninstance path described in the related bug.\n\nConflicts:\n\tnova/virt/images.py\n\nChange-Id: I4fa1c258db58c70dfbf0178b7bb13978fda3a11f\nCloses-Bug: #1436166\n(cherry picked from commit 9a4ecfd96dad32fd4726c46dc6d89e956f1f2a29)\n'}]",1,288594,b806adb032567c2c84d61834e6f8d2684723c194,10,5,1,11564,,,0,"Propagate qemu-img errors to compute manager

When qemu-img is called with oslo_concurrency.process_utils.execute
the ProcessExecutionError was raised when qemu-img either fails to
execute or has a non-zero exit code. This error did not propagate
up to the compute manager with any meaningful information meaning
that if an instance build fails the error message is the generic
""There are not enough hosts available"".

This change captures ProcessExecutionError and re-raises the
exception as either InvalidDiskInfo (in qemu_img_info) or
ImageUnacceptable (in convert_image and fetch_to_raw) and makes the
manager accept this as a cause for a BuildAbortException on the
logic that if the image is bad, things are dire, let's bail.

Based on the code in qemu_img_info it appears there was a
misunderstanding of how process_utils.execute behaves so it seems
likely this problem is present elsewhere in the code. This change
attempts to only address the issue as it shows up on the new
instance path described in the related bug.

Conflicts:
	nova/virt/images.py

Change-Id: I4fa1c258db58c70dfbf0178b7bb13978fda3a11f
Closes-Bug: #1436166
(cherry picked from commit 9a4ecfd96dad32fd4726c46dc6d89e956f1f2a29)
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/288594/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/virt/test_images.py', 'nova/compute/manager.py', 'nova/virt/images.py']",4,b806adb032567c2c84d61834e6f8d2684723c194,bug/1436166,"from oslo_concurrency import processutils try: out, err = utils.execute(*cmd) except processutils.ProcessExecutionError as exp: msg = (_(""qemu-img failed to execute on %(path)s : %(exp)s"") % {'path': path, 'exp': exp}) raise exception.InvalidDiskInfo(reason=msg) try: utils.execute(*cmd, run_as_root=run_as_root) except processutils.ProcessExecutionError as exp: msg = (_(""Unable to convert image to %(format)s: %(exp)s"") % {'format': out_format, 'exp': exp}) raise exception.ImageUnacceptable(image_id=source, reason=msg) try: convert_image(path_tmp, staged, fmt, 'raw') except exception.ImageUnacceptable as exp: # re-raise to include image_href raise exception.ImageUnacceptable(image_id=image_href, reason=_(""Unable to convert image to raw: %(exp)s"") % {'exp': exp}) "," out, err = utils.execute(*cmd) utils.execute(*cmd, run_as_root=run_as_root) convert_image(path_tmp, staged, fmt, 'raw')",52,5
openstack%2Ftempest~master~I69ba35eff591a5df28049273f3aba15c31f52d00,openstack/tempest,master,I69ba35eff591a5df28049273f3aba15c31f52d00,Unit tests: mock some time.sleep and time.time,MERGED,2016-03-03 13:33:59.000000000,2016-03-05 07:16:35.000000000,2016-03-04 07:08:54.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 12017}]","[{'number': 1, 'created': '2016-03-03 13:33:59.000000000', 'files': ['tempest/tests/common/test_waiters.py', 'tempest/tests/lib/test_ssh.py', 'tempest/tests/utils.py', 'tempest/tests/lib/test_rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e53b61f853dd055e6bf4df82068609bb5575d78', 'message': 'Unit tests: mock some time.sleep and time.time\n\nSimilar to what Cinder did here [1], this patch mocks time.sleep\nto make tests run faster. Some code actually measure the wall clock\nto wait for a specific duration before raising a TimeoutError, so\nwe also need to mock time.time.\n\nThis removes ~5sec in unit test and also removes some busy waiting.\n\n[1] https://review.openstack.org/#/c/285658/\n\nChange-Id: I69ba35eff591a5df28049273f3aba15c31f52d00\n'}]",0,287796,0e53b61f853dd055e6bf4df82068609bb5575d78,10,4,1,7350,,,0,"Unit tests: mock some time.sleep and time.time

Similar to what Cinder did here [1], this patch mocks time.sleep
to make tests run faster. Some code actually measure the wall clock
to wait for a specific duration before raising a TimeoutError, so
we also need to mock time.time.

This removes ~5sec in unit test and also removes some busy waiting.

[1] https://review.openstack.org/#/c/285658/

Change-Id: I69ba35eff591a5df28049273f3aba15c31f52d00
",git fetch https://review.opendev.org/openstack/tempest refs/changes/96/287796/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/common/test_waiters.py', 'tempest/tests/lib/test_ssh.py', 'tempest/tests/utils.py', 'tempest/tests/lib/test_rest_client.py']",4,0e53b61f853dd055e6bf4df82068609bb5575d78,,"import tempest.tests.utils as utils timeout = 1 self.rest_client.build_timeout = timeout time_mock = self.patch('time.time') time_mock.side_effect = utils.generate_timeout_series(timeout) # time.time() should be called twice, first to start the timer # and then to compute the timedelta self.assertEqual(2, time_mock.call_count) ", self.rest_client.build_timeout = 1,70,16
openstack%2Fsahara-dashboard~master~Ie8b7c7214fac6946e4b051c0c93fc0cf829ebb37,openstack/sahara-dashboard,master,Ie8b7c7214fac6946e4b051c0c93fc0cf829ebb37,Imported Translations from Zanata,MERGED,2016-03-05 06:04:53.000000000,2016-03-05 06:47:23.000000000,2016-03-05 06:47:23.000000000,"[{'_account_id': 3}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-03-05 06:04:53.000000000', 'files': ['sahara_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/6276a01b165aa7b513f5fd511b87bf9e64123b3d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie8b7c7214fac6946e4b051c0c93fc0cf829ebb37\n'}]",0,288843,6276a01b165aa7b513f5fd511b87bf9e64123b3d,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ie8b7c7214fac6946e4b051c0c93fc0cf829ebb37
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/43/288843/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po'],1,6276a01b165aa7b513f5fd511b87bf9e64123b3d,zanata/translations,"# Gaoxiao Zhu <zhu.gaoxiao@h3c.com>, 2016. #zanata""PO-Revision-Date: 2016-03-04 03:09+0000\n"" ""Last-Translator: Gaoxiao Zhu <zhu.gaoxiao@h3c.com>\n""msgid ""Configuration Value"" msgstr ""配置值"" msgid """" ""For configs and params, type the key name; for args, type the index as an "" ""integer, starting from 0."" msgstr ""对于配置和参数，定义键名类型；对于参数，定义索引类型为从0开始的整数。"" msgid """" ""For data sources, use a data source UUID or a path (as per data source "" ""creation.)"" msgstr ""对于数据源，使用数据源UUID或者路径（根据数据源创建。）"" msgid ""Named Parameter"" msgstr ""命名参数"" msgid ""Positional Argument"" msgstr ""定位参数"" ","""PO-Revision-Date: 2016-03-04 05:11+0000\n"" ""Last-Translator: Shengjing Zhu <zsj950618@gmail.com>\n""",22,2
openstack%2Fsenlin-dashboard~master~I0c7a1a8de5e100d8fb5f043894ce50bbe4fe696d,openstack/senlin-dashboard,master,I0c7a1a8de5e100d8fb5f043894ce50bbe4fe696d,Imported Translations from Zanata,MERGED,2016-03-05 06:15:38.000000000,2016-03-05 06:34:00.000000000,2016-03-05 06:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-03-05 06:15:38.000000000', 'files': ['senlin_dashboard/locale/zh_CN/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/aeaedc6d8d6767468cfd5d62bea4ad106ab957b9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I0c7a1a8de5e100d8fb5f043894ce50bbe4fe696d\n'}]",6,288844,aeaedc6d8d6767468cfd5d62bea4ad106ab957b9,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I0c7a1a8de5e100d8fb5f043894ce50bbe4fe696d
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/44/288844/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin_dashboard/locale/zh_CN/LC_MESSAGES/django.po'],1,aeaedc6d8d6767468cfd5d62bea4ad106ab957b9,zanata/translations,"# Zheng Xi Zhou <zzxwill@gmail.com>, 2016. #zanata""PO-Revision-Date: 2016-03-04 11:32+0000\n"" ""Last-Translator: Zheng Xi Zhou <zzxwill@gmail.com>\n""""接收端被用来准备Senlin引擎以完成对外部报警和事件做出响应，这样特定的Action可"" ""以在senlin集群上自动初始化。比如，当一个集群上的负载压力升高，接收端可以改变"" ""特定集群的容量。""msgstr ""策略是一套规则的集合，当Action在集群上执行时，它可以被检查或执行。"" msgid ""A profile encodes the information needed for node creation."" msgstr ""样版加密节点创建所需要的信息。"" msgid ""A spec file or yaml must be specified."" msgstr ""必须制定规格文件或yaml。""msgstr ""活跃""msgstr ""活跃""msgstr ""活跃"" msgstr ""Action"" msgid """" ""An integer between 0 and 100 representing the enforcement level. Default to "" ""0."" msgstr ""代表执行水平的从0到100的整数，默认是0"" msgid """" ""An integer indicating the cooldown seconds once the policy is effected. "" ""Default to 0."" msgstr ""当策略生效时，标记负载压力下降到正常值所花时间（秒）的整数，默认是0。""msgstr ""关联策略""msgstr ""已关联的策略""msgstr ""关联策略%(policy)s到集群%(cluster)s。""msgstr ""严重错误"" msgid ""Can not specify both sepc file and yaml."" msgstr ""无法同时指定规格文件和yaml。""msgstr ""集群创建超时时限，以秒计。""msgstr ""集群是云对象的集合，比如，Nova服务器，Heat的栈，Cinder的卷等。""msgid ""Create Profile"" msgstr ""创建样版"" msgstr ""创建接收端""msgstr ""创建时间""msgid ""Delete Policy"" msgid_plural ""Delete Policies"" msgstr[0] ""删除策略"" msgid ""Delete Profile"" msgid_plural ""Delete Profiles"" msgstr[0] ""删除样版"" msgid ""Delete Receiver"" msgid_plural ""Delete Receivers"" msgstr[0] ""删除接收端"" msgid ""Deleted Policy"" msgid_plural ""Deleted Policies"" msgstr[0] ""已删除的策略"" msgid ""Deleted Profile"" msgid_plural ""Deleted Profiles"" msgstr[0] ""删除的样版"" msgid ""Deleted Receiver"" msgid_plural ""Deleted Receivers"" msgstr[0] ""已删除的接收端"" msgid ""Desired capacity of the cluster. Default to 0."" msgstr ""集群期望的容量，默认是0。"" msgid ""Detach Policy"" msgid_plural ""Detach Policies"" msgstr[0] ""分离策略"" msgid ""Detaching Policy"" msgid_plural ""Detaching Policies"" msgstr[0] ""正在分离策略"" msgid ""Enabled"" msgstr ""Enabled"" msgstr ""容量上限""msgstr ""集群容量上限。默认为-1，表示无限制。""msgstr ""容量下限""msgstr ""集群容量下限。默认为0。""msgstr ""节点列表""msgstr ""节点是物理对象，可以成为任何样版类型相同的集群的成员。""msgid ""Profile"" msgstr ""样版"" msgid ""Profile Name"" msgstr ""样版名称"" msgid ""Profile Spec Examples"" msgstr ""样版规格文档"" msgid ""Profile used for this node."" msgstr ""用于该节点的样版。"" msgid ""Profiles"" msgstr ""样版"" msgstr ""接收端""msgid ""Select Profile"" msgstr ""选择样版"" msgstr ""规格""msgstr ""规格文件""msgstr ""规格来源"" msgid ""Spec YAML"" msgstr ""规格YAML""msgstr ""这个接收端所针对的集群。""msgstr ""该参数不是合法的YAML格式：%s"" msgid ""The spec file used to create the profile."" msgstr ""用于创建样版的规格文件。"" msgid ""The spec yaml used to create the policy."" msgstr ""用来创建策略的规格yaml文件"" msgid ""The spec yaml used to create the profile."" msgstr ""用于创建样版的规格文件的规格yaml文件。""msgstr ""所提供的数据不是合法的YAML数据：%s""msgstr ""所提供的文件不是合法的YAML文件：%s"" #, python-format msgid ""The specified metadata is not a valid YAML format: %s"" msgstr ""给定的元数据不是合法的Yaml格式：%s""msgstr ""所提供的元数据不是合法的YAML文件：%s""msgstr ""超时时限""msgstr ""待创建的接受端类型，默认是webhook。""msgstr ""无法关联策略。""msgid ""Unable to create new profile"" msgstr ""无法创建新的样版"" msgstr ""无法创建新的接收端。""msgstr ""无法创建节点。""msgstr ""无法获取集群事件列表""msgstr ""无法获取集群列表。""msgstr ""无法获取集群的节点列表。""msgstr ""无法获取节点列表。""msgstr ""无法获取策略列表。""msgid ""Unable to retrieve profile."" msgstr ""无法获取样版。"" msgid ""Unable to retrieve profiles."" msgstr ""无法获取样版。"" msgstr ""无法获取接收端。""msgstr ""无法获取接收端。"" msgid ""Unable to update profile"" msgstr ""无法更新样版"" msgid ""Update Profile"" msgstr ""更新样版""msgstr ""更新时间""msgid ""Whether the policy should be enabled once attached. Default to enabled."" msgstr ""策略一旦关联是否应该设置为有效，默认是enabled。"" msgstr ""YAML类型的参数在接受端被触发时将传递给目标动作。""msgid ""Your profile %s has been created."" msgstr ""你的样版%s已经创建了。"" #, python-format msgid ""Your profile %s has been updated."" msgstr ""你的样版%s已经更新了。"" #, python-formatmsgstr ""你的接收端%s已经被成功创建。""","# Zheng XI Zhou <zzxwill@gmail.com>, 2016. #zanata""PO-Revision-Date: 2016-03-03 02:07+0000\n"" ""Last-Translator: Zheng XI Zhou <zzxwill@gmail.com>\n""""接收者被用来准备Senlin engine以与报警和实践互动，这样特定的动作可以在senlin集"" ""群上自动初始化。比如，当一个节点上的工作压力升高，接收者可以改变特定集群的大"" ""小。""msgstr ""策略是一套规则的集合，当动作在集群上执行时，它可以被检查或强制执行。""msgstr ""有效""msgstr ""有效的""msgstr ""有效的"" #, fuzzymsgstr ""操作""msgstr ""应用策略""msgstr ""已应用的策略""msgstr ""应用策略%(policy)s到集群%(cluster)s。""msgstr ""严重的""#, fuzzymsgstr ""集群创建超时，以秒计。""msgstr ""集群是云对象的集合，比如，节点服务器，Heat的栈，Cinder的磁盘等。""msgstr ""创建接收者。""msgstr ""已创建""#, fuzzymsgstr ""最大值""msgstr ""集群最大值。默认为-1，表示无限制。""msgstr ""最小值""msgstr ""集群最小值。默认为0。""msgstr ""节点""msgstr ""节点是物理对象，它们属于相同配置类型的任意集群。""msgstr ""接收者""msgstr ""规格说明""msgstr ""规则说明文件""msgstr ""规格说明源""msgstr ""这个接收者的目标集群。""msgstr ""该参数不是有效的YAML格式：%s""msgstr ""这些特定的数据不是有效的YAML数据：%s""msgstr ""该特定的文件不是有效的YAML文件：%s""msgstr ""该元数据不是有效的YAML文件：%s""msgstr ""超时""msgstr ""待创建的接受者类型，默认是webhook。""msgstr ""无法应用策略""msgstr ""无法创建新的接收者。""msgstr ""不能创建节点。""msgstr ""无法获取集群事务列表""msgstr ""无法获取集群。""msgstr ""无法获取集群的节点。""msgstr ""无法获取节点。""msgstr ""无法获取策略。""msgstr ""无法获取接收者。""msgstr ""无法获取接收者。""msgstr ""已更新""msgstr ""YAML类型的参数在接受者被触发时将传递给目标动作。""msgstr ""你的接收者%s已经被成功创建。""",169,52
openstack%2Fkeystone~master~I86ec5d7bc317454b2a95e1afc2b380e292acf363,openstack/keystone,master,I86ec5d7bc317454b2a95e1afc2b380e292acf363,Remove _disable_domain from the resource API,MERGED,2016-03-04 22:38:36.000000000,2016-03-05 06:32:33.000000000,2016-03-05 06:32:33.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-03-04 22:38:36.000000000', 'files': ['keystone/resource/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/47dd812926c9c4f0bb09e2184b2205519494105d', 'message': 'Remove _disable_domain from the resource API\n\nThe _disable_domain method in was only there to act as a method we could put a\ndecorator on for notifications. The notification decorator has been replaced\nwith an inline statement for sending the notification. This means we no longer\nneed to have a specific method for the purpose of a decorator, so we can remove\n_disable_domain.\n\nChange-Id: I86ec5d7bc317454b2a95e1afc2b380e292acf363\n'}]",0,288778,47dd812926c9c4f0bb09e2184b2205519494105d,7,3,1,5046,,,0,"Remove _disable_domain from the resource API

The _disable_domain method in was only there to act as a method we could put a
decorator on for notifications. The notification decorator has been replaced
with an inline statement for sending the notification. This means we no longer
need to have a specific method for the purpose of a decorator, so we can remove
_disable_domain.

Change-Id: I86ec5d7bc317454b2a95e1afc2b380e292acf363
",git fetch https://review.opendev.org/openstack/keystone refs/changes/78/288778/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/resource/core.py'],1,47dd812926c9c4f0bb09e2184b2205519494105d,," notifications.Audit.disabled(self._DOMAIN, project_id, public=False)"," self._disable_domain(project_id) def _disable_domain(self, domain_id): """"""Emit a notification to the callback system domain is been disabled. This method, and associated callback listeners, removes the need for making direct calls to other managers to take action (e.g. revoking domain scoped tokens) when a domain is disabled. :param domain_id: domain identifier :type domain_id: string """""" notifications.Audit.disabled(self._DOMAIN, domain_id, public=False) ",2,13
openstack%2Fkeystone~master~I352e7e1edb2fad71ff940e0db8b6f1dd1697df77,openstack/keystone,master,I352e7e1edb2fad71ff940e0db8b6f1dd1697df77,Remove _disable_project from the resource API,MERGED,2016-03-04 22:38:36.000000000,2016-03-05 06:26:33.000000000,2016-03-05 06:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-03-04 22:38:36.000000000', 'files': ['keystone/resource/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d179e765d2e49d3a89f1dd23838664d792d7d377', 'message': 'Remove _disable_project from the resource API\n\nThe _disable_project method in was only there to act as a method we could put a\ndecorator on for notifications. The notification decorator has been replaced\nwith an inline statement for sending the notification. This means we no longer\nneed to have a specific method for the purpose of a decorator, so we can remove\n_disable_project.\n\nChange-Id: I352e7e1edb2fad71ff940e0db8b6f1dd1697df77\n'}]",0,288777,d179e765d2e49d3a89f1dd23838664d792d7d377,9,3,1,5046,,,0,"Remove _disable_project from the resource API

The _disable_project method in was only there to act as a method we could put a
decorator on for notifications. The notification decorator has been replaced
with an inline statement for sending the notification. This means we no longer
need to have a specific method for the purpose of a decorator, so we can remove
_disable_project.

Change-Id: I352e7e1edb2fad71ff940e0db8b6f1dd1697df77
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/288777/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/resource/core.py'],1,d179e765d2e49d3a89f1dd23838664d792d7d377,," notifications.Audit.disabled(self._PROJECT, project_id, public=False) notifications.Audit.disabled(self._PROJECT, child['id'], public=False)"," def _disable_project(self, project_id): """"""Emit a notification to the callback system project is been disabled. This method, and associated callback listeners, removes the need for making direct calls to other managers to take action (e.g. revoking project scoped tokens) when a project is disabled. :param project_id: project identifier :type project_id: string """""" notifications.Audit.disabled(self._PROJECT, project_id, public=False) self._disable_project(project_id) self._disable_project(child['id'])",4,14
openstack%2Fkeystone~master~Iad3fa683cfcacc87b28d03396eb631556d046f15,openstack/keystone,master,Iad3fa683cfcacc87b28d03396eb631556d046f15,Cleanup from from split of token backend tests,MERGED,2016-03-04 18:20:09.000000000,2016-03-05 06:25:23.000000000,2016-03-05 06:25:23.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2016-03-04 18:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/072862d6d83c342c563b9f36fe9632dec6016ba6', 'message': 'Cleanup from from split of token backend tests\n\nAbove patches on this chain have split the huge test_backend.py file.\nThere were no real code changes; just moving code around.\n\nThere were a couple of TODO comments left on changes that were not\njust moving code around. This patch fixes them.\n\nChange-Id: Iad3fa683cfcacc87b28d03396eb631556d046f15\n'}, {'number': 2, 'created': '2016-03-04 18:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f34a3fc29e74ba15811281c6101a8385f5ec0d69', 'message': 'Cleanup from from split of token backend tests\n\nAbove patches on this chain have split the huge test_backend.py file.\nThere were no real code changes; just moving code around.\n\nThere were a couple of TODO comments left on changes that were not\njust moving code around. This patch fixes them.\n\nChange-Id: Iad3fa683cfcacc87b28d03396eb631556d046f15\n'}, {'number': 3, 'created': '2016-03-04 21:01:01.000000000', 'files': ['keystone/tests/unit/assignment/test_backends.py', 'keystone/tests/unit/test_backend_ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd7733a36eab580007e172eb1d9fe8d9aff009d4', 'message': 'Cleanup from from split of token backend tests\n\nAbove patches on this chain have split the huge test_backend.py file.\nThere were no real code changes; just moving code around.\n\nThere were a couple of TODO comments left on changes that were not\njust moving code around. This patch fixes them.\n\nChange-Id: Iad3fa683cfcacc87b28d03396eb631556d046f15\n'}]",0,288622,cd7733a36eab580007e172eb1d9fe8d9aff009d4,14,3,3,17860,,,0,"Cleanup from from split of token backend tests

Above patches on this chain have split the huge test_backend.py file.
There were no real code changes; just moving code around.

There were a couple of TODO comments left on changes that were not
just moving code around. This patch fixes them.

Change-Id: Iad3fa683cfcacc87b28d03396eb631556d046f15
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/288622/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/assignment/test_backends.py', 'keystone/tests/unit/test_backend_ldap.py']",2,072862d6d83c342c563b9f36fe9632dec6016ba6,split-backend-tests," # The group and domain CRUD tests below override the standard ones in # unit.identity.test_backends.py so that we can exclude the update name # test, since we do not (and will not) support the update of either group # or domain names with LDAP. In the tests below, the update is demonstrated by # updating description."," # TODO(samueldmq): Bug is marked as won't fix. Update note below. # (spzala)The group and domain crud tests below override the standard ones # in unit.identity.test_backends.py so that we can exclude the update name # test, since we do not yet support the update of either group or domain # names with LDAP. In the tests below, the update is demonstrated by # updating description. Refer to bug 1136403 for more detail.",7,10
openstack%2Fkeystone~master~I5d765adaf592bbcb2f8414bb636f815ae06bd540,openstack/keystone,master,I5d765adaf592bbcb2f8414bb636f815ae06bd540,Split identity backend tests,MERGED,2016-01-18 15:42:22.000000000,2016-03-05 06:20:37.000000000,2016-03-05 06:20:36.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 17026}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-18 15:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/912c7c13b9dbc5ca90f8ce6c66b5f0b94cdc0968', 'message': 'Extract identity backend tests\n\ntest_backend.py was a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract identity-related tests to its directory\nunder unit/backend/policy.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n'}, {'number': 2, 'created': '2016-01-18 22:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57515fac49412bdb26e303d9b4f695edb3598c00', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 3, 'created': '2016-01-19 17:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d82f4aa33e2d078abdf3bf214b5b97fd6ec29d8a', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 4, 'created': '2016-01-27 14:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0ebb1a60656f11eb30edc2793df0bd3d89ca0a08', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 5, 'created': '2016-01-27 16:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0fc6bc6008a5492d6228c3703fbac4cb29d00950', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 6, 'created': '2016-01-28 14:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d2eaaa9ebcc385964293bb9731437e95c69214fa', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 7, 'created': '2016-01-28 21:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/631f5390fa835e4a557e42833daf713e87aed186', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 8, 'created': '2016-03-04 17:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7c4e8726dfb78d35f6abc9e001ee11fda3712e47', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 9, 'created': '2016-03-04 18:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9b810bcec503a563254705bed5d7902e073313a9', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}, {'number': 10, 'created': '2016-03-04 18:36:52.000000000', 'files': ['keystone/tests/unit/identity/test_backends.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/96f3a21e4799bf0a9e04babf25f9aa5642c3ff62', 'message': ""Split identity backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the identity backend.\n\nChange-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540\n""}]",0,269148,96f3a21e4799bf0a9e04babf25f9aa5642c3ff62,35,6,10,17860,,,0,"Split identity backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the identity backend.

Change-Id: I5d765adaf592bbcb2f8414bb636f815ae06bd540
",git fetch https://review.opendev.org/openstack/keystone refs/changes/48/269148/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/backend/identity/core.py', 'keystone/tests/unit/backend/identity/__init__.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py']",4,912c7c13b9dbc5ca90f8ce6c66b5f0b94cdc0968,split-backend-tests,"from keystone.tests.unit.backend.identity import core as identity_coreclass SqlIdentity(SqlTests, identity_core.IdentityTests,class SqlFilterTests(SqlTests, identity_core.FilterTests): # NOTE(henry-nash): This method is here rather than in # unit.backend.identity.core since any domain filtering with LDAP is # handled by the manager layer (and is already tested elsewhere) not # at the driver level.class SqlLimitTests(SqlTests, identity_core.LimitTests): identity_core.LimitTests.setUp(self)","from keystone.tests.unit import test_backendclass SqlIdentity(SqlTests, test_backend.IdentityTests,class SqlFilterTests(SqlTests, test_backend.FilterTests): # NOTE(henry-nash): This method is here rather than in test_backend # since any domain filtering with LDAP is handled by the manager # layer (and is already tested elsewhere) not at the driver level.class SqlLimitTests(SqlTests, test_backend.LimitTests): test_backend.LimitTests.setUp(self)",24,23
openstack%2Fkeystone~master~If88270a684d891e51f4ff45fa9b14626c0983541,openstack/keystone,master,If88270a684d891e51f4ff45fa9b14626c0983541,Split policy backend tests,MERGED,2016-01-18 15:16:58.000000000,2016-03-05 06:19:00.000000000,2016-03-05 06:19:00.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 17026}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-18 15:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9b37d0171a34007a2bc7eae02e39ba24a683dad4', 'message': 'Extract policy backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract policy-related tests to its directory\nunder unit/backend/policy.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n'}, {'number': 2, 'created': '2016-01-18 22:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1641958acc51a734f1570078ae21f62d09c9e4d4', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 3, 'created': '2016-01-18 22:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5f1e2d5415c356a2c122ec045db43557b4447307', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 4, 'created': '2016-01-27 13:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c5d8cd00ac2df94f07ca0e26c4db604e06902ef8', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 5, 'created': '2016-01-27 16:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4947d23a9428cd94b2337f62052ab1462fe98173', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 6, 'created': '2016-01-28 14:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f2364857da0cc51df735f4a4afe7d1b900ab2bd3', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 7, 'created': '2016-01-28 21:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/033401d2271f3bf4554b5a7d3d456b86e7e07ab6', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 8, 'created': '2016-03-04 17:40:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e7edb404a3dff45c5a3554db1ee3a258fcc0116', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 9, 'created': '2016-03-04 18:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36966e72b927ece5d9e00e9c9e58588088a901ad', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 10, 'created': '2016-03-04 18:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c4924401cf3f08f5f1964a6dd9d0ba5181b220cf', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}, {'number': 11, 'created': '2016-03-04 18:32:55.000000000', 'files': ['keystone/tests/unit/test_backend_rules.py', 'keystone/tests/unit/policy/test_backends.py', 'keystone/tests/unit/policy/__init__.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe43a867f005a82df8a0a1989ba1d2a2d467d548', 'message': ""Split policy backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the policy backend.\n\nChange-Id: If88270a684d891e51f4ff45fa9b14626c0983541\n""}]",0,269133,fe43a867f005a82df8a0a1989ba1d2a2d467d548,33,5,11,17860,,,0,"Split policy backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the policy backend.

Change-Id: If88270a684d891e51f4ff45fa9b14626c0983541
",git fetch https://review.opendev.org/openstack/keystone refs/changes/33/269133/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_rules.py', 'keystone/tests/unit/backend/policy/core.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/backend/policy/__init__.py', 'keystone/tests/unit/test_backend.py']",5,9b37d0171a34007a2bc7eae02e39ba24a683dad4,split-backend-tests,,"class PolicyTests(object): def test_create(self): ref = unit.new_policy_ref() res = self.policy_api.create_policy(ref['id'], ref) self.assertDictEqual(ref, res) def test_get(self): ref = unit.new_policy_ref() res = self.policy_api.create_policy(ref['id'], ref) res = self.policy_api.get_policy(ref['id']) self.assertDictEqual(ref, res) def test_list(self): ref = unit.new_policy_ref() self.policy_api.create_policy(ref['id'], ref) res = self.policy_api.list_policies() res = [x for x in res if x['id'] == ref['id']][0] self.assertDictEqual(ref, res) def test_update(self): ref = unit.new_policy_ref() self.policy_api.create_policy(ref['id'], ref) orig = ref ref = unit.new_policy_ref() # (cannot change policy ID) self.assertRaises(exception.ValidationError, self.policy_api.update_policy, orig['id'], ref) ref['id'] = orig['id'] res = self.policy_api.update_policy(orig['id'], ref) self.assertDictEqual(ref, res) def test_delete(self): ref = unit.new_policy_ref() self.policy_api.create_policy(ref['id'], ref) self.policy_api.delete_policy(ref['id']) self.assertRaises(exception.PolicyNotFound, self.policy_api.delete_policy, ref['id']) self.assertRaises(exception.PolicyNotFound, self.policy_api.get_policy, ref['id']) res = self.policy_api.list_policies() self.assertFalse(len([x for x in res if x['id'] == ref['id']])) def test_get_policy_returns_not_found(self): self.assertRaises(exception.PolicyNotFound, self.policy_api.get_policy, uuid.uuid4().hex) def test_update_policy_returns_not_found(self): ref = unit.new_policy_ref() self.assertRaises(exception.PolicyNotFound, self.policy_api.update_policy, ref['id'], ref) def test_delete_policy_returns_not_found(self): self.assertRaises(exception.PolicyNotFound, self.policy_api.delete_policy, uuid.uuid4().hex) ",92,73
openstack%2Fapi-site~master~I31d7e687c86e7f22c828c68bd2390450a1cbd0a5,openstack/api-site,master,I31d7e687c86e7f22c828c68bd2390450a1cbd0a5,"Identity v3 - Domain configuration: ""config"" have wrong type",MERGED,2016-02-22 01:21:05.000000000,2016-03-05 06:00:09.000000000,2016-03-05 06:00:09.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 10897}]","[{'number': 1, 'created': '2016-02-22 01:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/b448f0dca8de7be14e3342a9630dc8e086046501', 'message': 'Identity v3 - Domain configuration: ""config"" have wrong type\n\nChanging type of ""config"" parameter form ""xsd:string"" to ""xsd:dict""\n\nChange-Id: I31d7e687c86e7f22c828c68bd2390450a1cbd0a5\nCloses-Bug: #1547342\n'}, {'number': 2, 'created': '2016-02-29 16:47:23.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v3/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/58bdbdd6ce0a72512a588d379493a147b05b52f9', 'message': 'Identity v3 - Domain configuration: ""config"" have wrong type\n\nChanging type of ""config"" parameter from ""xsd:string"" to ""xsd:dict""\n\nChange-Id: I31d7e687c86e7f22c828c68bd2390450a1cbd0a5\nCloses-Bug: #1547342\n'}]",0,282916,58bdbdd6ce0a72512a588d379493a147b05b52f9,11,4,2,19935,,,0,"Identity v3 - Domain configuration: ""config"" have wrong type

Changing type of ""config"" parameter from ""xsd:string"" to ""xsd:dict""

Change-Id: I31d7e687c86e7f22c828c68bd2390450a1cbd0a5
Closes-Bug: #1547342
",git fetch https://review.opendev.org/openstack/api-site refs/changes/16/282916/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/identity-api/src/v3/common.ent'],1,b448f0dca8de7be14e3342a9630dc8e086046501,bug/1547342,"<param name=""config"" style=""plain"" type=""xsd:dict""","<param name=""config"" style=""plain"" type=""xsd:string""",1,1
openstack%2Fapi-site~master~Ie002e2537bcff53fcdbc60d6ac59fb0dd2edacd7,openstack/api-site,master,Ie002e2537bcff53fcdbc60d6ac59fb0dd2edacd7,[Orchestration API v1] Clarify language about stack names,MERGED,2016-03-04 00:58:02.000000000,2016-03-05 05:56:09.000000000,2016-03-05 05:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4328}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-04 00:58:02.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/ba12cd52cd9b781e6819402da78d54b46d9eaa02', 'message': '[Orchestration API v1] Clarify language about stack names\n\nAs was pointed out on the original review[1] that introduced it, the\nlanguage about unique stack names becoming available again only after an\n""unspecified amount of time"" is not based on any actual restriction that\nexists in Heat. Stacks are soft-deleted and therefore available to query\n(by UUID) even after they have been deleted until such time as they are\npurged from the database (an interval which is controlled by the operator,\nand hence could be considered unspecified), but the name becomes available\nas soon as the delete has successfully completed.\n\n[1] https://review.openstack.org/#/c/131277/1/api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl\n\nChange-Id: Ie002e2537bcff53fcdbc60d6ac59fb0dd2edacd7\n'}]",0,288202,ba12cd52cd9b781e6819402da78d54b46d9eaa02,8,4,1,4257,,,0,"[Orchestration API v1] Clarify language about stack names

As was pointed out on the original review[1] that introduced it, the
language about unique stack names becoming available again only after an
""unspecified amount of time"" is not based on any actual restriction that
exists in Heat. Stacks are soft-deleted and therefore available to query
(by UUID) even after they have been deleted until such time as they are
purged from the database (an interval which is controlled by the operator,
and hence could be considered unspecified), but the name becomes available
as soon as the delete has successfully completed.

[1] https://review.openstack.org/#/c/131277/1/api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl

Change-Id: Ie002e2537bcff53fcdbc60d6ac59fb0dd2edacd7
",git fetch https://review.opendev.org/openstack/api-site refs/changes/02/288202/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,ba12cd52cd9b781e6819402da78d54b46d9eaa02,bug/1355669," When you delete or abandon a stack, its name will not become available for reuse until the deletion completes successfully. When you delete or abandon a stack, its name will not become available for reuse until the deletion completes successfully. When you delete or abandon a stack, its name will not become available for reuse until the deletion completes successfully."," When you delete or abandon a stack, its name might not be available for reuse for an unspecified period of time. When you delete or abandon a stack, its name might not be available for reuse for an unspecified period of time. When you delete or abandon a stack, its name might not be available for reuse for an unspecified period of time.",9,7
openstack%2Fopenstack-manuals~master~I6621d28a643b4c786b6a5615fac95c998daf3432,openstack/openstack-manuals,master,I6621d28a643b4c786b6a5615fac95c998daf3432,Disable Insecure warnings,MERGED,2016-03-03 18:55:25.000000000,2016-03-05 05:54:56.000000000,2016-03-05 05:54:55.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 14151}, {'_account_id': 14947}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-03-03 18:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ff8e6776f67d019465ae0807b8506b39704c9407', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}, {'number': 2, 'created': '2016-03-03 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e40dbe64d86c9706a52f7ce968d42e9fcc823dac', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}, {'number': 3, 'created': '2016-03-03 19:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5fd21ebce6cc2ce51a4f0c886f5749b11bd4fa19', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}, {'number': 4, 'created': '2016-03-04 11:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f7d1d78486ef59f96fe633b9d0709047cda7451f', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}, {'number': 5, 'created': '2016-03-04 11:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df92db0a19ed3f2addccd79be89a0bfa72dff415', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}, {'number': 6, 'created': '2016-03-04 12:15:11.000000000', 'files': ['doc/config-reference/source/conf.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ce64f6e60672f3047aa5e5bec9a711497d31630', 'message': ""Disable Insecure warnings\n\nDisable urllib's warnings, there's no way to fix these in our builds\nright now.\n\nChange-Id: I6621d28a643b4c786b6a5615fac95c998daf3432\n""}]",0,288063,3ce64f6e60672f3047aa5e5bec9a711497d31630,29,8,6,6547,,,0,"Disable Insecure warnings

Disable urllib's warnings, there's no way to fix these in our builds
right now.

Change-Id: I6621d28a643b4c786b6a5615fac95c998daf3432
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/288063/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/conf.py'],1,ff8e6776f67d019465ae0807b8506b39704c9407,ssl-warnings,"# Disable warnings about HTTPS requests, see # https://urllib3.readthedocs.org/en/latest/security.html#disabling-warnings import urllib3 urllib3.disable_warnings() ",,5,0
openstack%2Fapi-site~master~Ibcf64e804d72df247a2cf3ab9b523548291f73a6,openstack/api-site,master,Ibcf64e804d72df247a2cf3ab9b523548291f73a6,[Orchestration API v1] Fix sort key names,MERGED,2016-03-04 00:58:02.000000000,2016-03-05 05:54:28.000000000,2016-03-05 05:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4715}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-04 00:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/49987d01b23ccf1285492f3e89dafdedd2a0967f', 'message': '[Orchestration API v1] Fix sort key names\n\nThe names of the keys to sort on are the same names as appear in the output\nof stack-list. The original API implementation used database column names;\nthat was fixed (as bug 1355669) before it was ever released, but the\ndocumentation was never updated.\n\nChange-Id: Ibcf64e804d72df247a2cf3ab9b523548291f73a6\nRelated-Bug: #1355669\n'}, {'number': 2, 'created': '2016-03-04 13:51:18.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/be3ce80f0e3cdfaceb471e384e3879e874782b35', 'message': '[Orchestration API v1] Fix sort key names\n\nThe names of the keys to sort on are the same names as appear in the output\nof stack-list. The original API implementation used database column names;\nthat was fixed (as bug 1355669) before it was ever released, but the\ndocumentation was never updated.\n\nChange-Id: Ibcf64e804d72df247a2cf3ab9b523548291f73a6\nRelated-Bug: #1355669\n'}]",0,288206,be3ce80f0e3cdfaceb471e384e3879e874782b35,9,4,2,4257,,,0,"[Orchestration API v1] Fix sort key names

The names of the keys to sort on are the same names as appear in the output
of stack-list. The original API implementation used database column names;
that was fixed (as bug 1355669) before it was ever released, but the
documentation was never updated.

Change-Id: Ibcf64e804d72df247a2cf3ab9b523548291f73a6
Related-Bug: #1355669
",git fetch https://review.opendev.org/openstack/api-site refs/changes/06/288206/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,49987d01b23ccf1285492f3e89dafdedd2a0967f,bug/1355669," Sorts the stack list by <code>stack_name</code>, <code>stack_status</code>, <code>creation_time</code>, or <code>updated_time</code> key."," Sorts the stack list by <code>name</code>, <code>status</code>, <code>created_at</code>, or <code>updated_at</code> key.",3,3
openstack%2Fapi-site~master~Ifa62c953fd968fdf4b536935b28ceedd8a56aaea,openstack/api-site,master,Ifa62c953fd968fdf4b536935b28ceedd8a56aaea,[Orchestration API v1] Fix stack-adopt response,MERGED,2016-03-04 00:58:02.000000000,2016-03-05 05:52:08.000000000,2016-03-05 05:52:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7256}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-03-04 00:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/223b5543fde7e19182433aef77768e2a43e46cfb', 'message': '[Orchestration API v1] Fix stack-adopt response\n\nThe response to adopting a stack is not the same as the response to\nabandoning a stack. It is the same as the response to creating a stack. In\nfact, it could not be otherwise because adopting a stack *is* creating a\nstack and uses the exact same endpoint and the exact same code.\n\nChange-Id: Ifa62c953fd968fdf4b536935b28ceedd8a56aaea\n'}, {'number': 2, 'created': '2016-03-04 13:51:59.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-response.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/d20b6061c4914ce595025bb863b113945182cebd', 'message': '[Orchestration API v1] Fix stack-adopt response\n\nThe response to adopting a stack is not the same as the response to\nabandoning a stack. It is the same as the response to creating a stack. In\nfact, it could not be otherwise because adopting a stack *is* creating a\nstack and uses the exact same endpoint and the exact same code.\n\nChange-Id: Ifa62c953fd968fdf4b536935b28ceedd8a56aaea\n'}]",0,288205,d20b6061c4914ce595025bb863b113945182cebd,9,4,2,4257,,,0,"[Orchestration API v1] Fix stack-adopt response

The response to adopting a stack is not the same as the response to
abandoning a stack. It is the same as the response to creating a stack. In
fact, it could not be otherwise because adopting a stack *is* creating a
stack and uses the exact same endpoint and the exact same code.

Change-Id: Ifa62c953fd968fdf4b536935b28ceedd8a56aaea
",git fetch https://review.opendev.org/openstack/api-site refs/changes/05/288205/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-response.json']",2,223b5543fde7e19182433aef77768e2a43e46cfb,bug/1355669,,"{ ""action"": ""CREATE"", ""id"": ""46c927bb-671a-43db-a29c-16a2610865ca"", ""name"": ""trove"", ""resources"": { ""mysql_server"": { ""action"": ""CREATE"", ""metadata"": {}, ""name"": ""mysql_server"", ""resource_data"": {}, ""resource_id"": ""74c5be7e-3e62-41e7-b455-93d1c32d56e3"", ""status"": ""COMPLETE"", ""type"": ""OS::Trove::Instance"" } }, ""status"": ""COMPLETE"", ""template"": { ""heat-template-version"": ""2013-05-23"", ""description"": ""MySQL server instance"", ""parameters"": { ""instance_name"": { ""description"": ""The database instance name"", ""type"": ""string"" } }, ""resources"": { ""mysql_server"": { ""properties"": { ""databases"": [ { ""name"": ""testdbonetwo"" } ], ""flavor"": ""m1.medium"", ""name"": ""test-trove-db"", ""size"": 30, ""users"": [ { ""databases"": [ ""testdbonetwo"" ], ""name"": ""testuser"", ""password"": ""testpass123"" } ] }, ""type"": ""OS::Trove::Instance"" } } } } ",1,52
openstack%2Fkeystone~master~I7a512e7662deac911c40763bd5f4c139b093a9e2,openstack/keystone,master,I7a512e7662deac911c40763bd5f4c139b093a9e2,Split catalog backend tests,MERGED,2016-01-18 15:03:58.000000000,2016-03-05 05:22:26.000000000,2016-03-05 05:22:26.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 17026}]","[{'number': 1, 'created': '2016-01-18 15:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5a20a6dc750e2fe6b6ded322c2208d0c18a435b0', 'message': 'Extract catalog backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract catalog-related tests to its directory\nunder unit/backend/catalog.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n'}, {'number': 2, 'created': '2016-01-18 21:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1e20fe64e3b07c425a2f5ce1a88bd3932ee59cc8', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 3, 'created': '2016-01-27 13:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe1a599f3a3d69eb8730e8b29d18754a8c6bc1db', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 4, 'created': '2016-01-27 16:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d4710b59e19bf73f7497314788d498fc65823127', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 5, 'created': '2016-01-28 14:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7f46f2ae661b435b9595f8b81a8977370f6cd6ef', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 6, 'created': '2016-01-28 21:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d01cfc511e218d18c7206acfa4753cbc7fc0de2', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 7, 'created': '2016-03-04 17:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd4b9af12d73b1d883f2c89ae7ca841b2eaab453', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 8, 'created': '2016-03-04 18:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/de7afd41b4556781148017b9c7857b9e1187432a', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 9, 'created': '2016-03-04 18:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/651bafb5904a7d00724510f2f830ddaaf3b2e3bf', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}, {'number': 10, 'created': '2016-03-04 18:32:33.000000000', 'files': ['keystone/tests/unit/catalog/test_backends.py', 'keystone/tests/unit/test_backend_templated.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/70dfe056a37194624aa32a9939ef87b2fe1b9f31', 'message': ""Split catalog backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the catalog backend.\n\nChange-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2\n""}]",0,269125,70dfe056a37194624aa32a9939ef87b2fe1b9f31,30,4,10,17860,,,0,"Split catalog backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the catalog backend.

Change-Id: I7a512e7662deac911c40763bd5f4c139b093a9e2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/25/269125/10 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/backend/catalog/__init__.py', 'keystone/tests/unit/test_backend_templated.py', 'keystone/tests/unit/backend/catalog/core.py', 'keystone/tests/unit/test_backend_kvs.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py']",6,5a20a6dc750e2fe6b6ded322c2208d0c18a435b0,split-backend-tests,,"import copyimport mockfrom keystone.catalog import coreclass CatalogTests(object): _legacy_endpoint_id_in_endpoint = False _enabled_default_to_true_when_creating_endpoint = False def test_region_crud(self): # create region_id = '0' * 255 new_region = unit.new_region_ref(id=region_id) res = self.catalog_api.create_region(new_region) # Ensure that we don't need to have a # parent_region_id in the original supplied # ref dict, but that it will be returned from # the endpoint, with None value. expected_region = new_region.copy() expected_region['parent_region_id'] = None self.assertDictEqual(expected_region, res) # Test adding another region with the one above # as its parent. We will check below whether deleting # the parent successfully deletes any child regions. parent_region_id = region_id new_region = unit.new_region_ref(parent_region_id=parent_region_id) region_id = new_region['id'] res = self.catalog_api.create_region(new_region) self.assertDictEqual(new_region, res) # list regions = self.catalog_api.list_regions() self.assertThat(regions, matchers.HasLength(2)) region_ids = [x['id'] for x in regions] self.assertIn(parent_region_id, region_ids) self.assertIn(region_id, region_ids) # update region_desc_update = {'description': uuid.uuid4().hex} res = self.catalog_api.update_region(region_id, region_desc_update) expected_region = new_region.copy() expected_region['description'] = region_desc_update['description'] self.assertDictEqual(expected_region, res) # delete self.catalog_api.delete_region(parent_region_id) self.assertRaises(exception.RegionNotFound, self.catalog_api.delete_region, parent_region_id) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, parent_region_id) # Ensure the child is also gone... self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_id) def _create_region_with_parent_id(self, parent_id=None): new_region = unit.new_region_ref(parent_region_id=parent_id) self.catalog_api.create_region(new_region) return new_region def test_list_regions_filtered_by_parent_region_id(self): new_region = self._create_region_with_parent_id() parent_id = new_region['id'] new_region = self._create_region_with_parent_id(parent_id) new_region = self._create_region_with_parent_id(parent_id) # filter by parent_region_id hints = driver_hints.Hints() hints.add_filter('parent_region_id', parent_id) regions = self.catalog_api.list_regions(hints) for region in regions: self.assertEqual(parent_id, region['parent_region_id']) @unit.skip_if_cache_disabled('catalog') def test_cache_layer_region_crud(self): new_region = unit.new_region_ref() region_id = new_region['id'] self.catalog_api.create_region(new_region.copy()) updated_region = copy.deepcopy(new_region) updated_region['description'] = uuid.uuid4().hex # cache the result self.catalog_api.get_region(region_id) # update the region bypassing catalog_api self.catalog_api.driver.update_region(region_id, updated_region) self.assertDictContainsSubset(new_region, self.catalog_api.get_region(region_id)) self.catalog_api.get_region.invalidate(self.catalog_api, region_id) self.assertDictContainsSubset(updated_region, self.catalog_api.get_region(region_id)) # delete the region self.catalog_api.driver.delete_region(region_id) # still get the old region self.assertDictContainsSubset(updated_region, self.catalog_api.get_region(region_id)) self.catalog_api.get_region.invalidate(self.catalog_api, region_id) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_id) @unit.skip_if_cache_disabled('catalog') def test_invalidate_cache_when_updating_region(self): new_region = unit.new_region_ref() region_id = new_region['id'] self.catalog_api.create_region(new_region) # cache the region self.catalog_api.get_region(region_id) # update the region via catalog_api new_description = {'description': uuid.uuid4().hex} self.catalog_api.update_region(region_id, new_description) # assert that we can get the new region current_region = self.catalog_api.get_region(region_id) self.assertEqual(new_description['description'], current_region['description']) def test_create_region_with_duplicate_id(self): new_region = unit.new_region_ref() self.catalog_api.create_region(new_region) # Create region again with duplicate id self.assertRaises(exception.Conflict, self.catalog_api.create_region, new_region) def test_get_region_returns_not_found(self): self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, uuid.uuid4().hex) def test_delete_region_returns_not_found(self): self.assertRaises(exception.RegionNotFound, self.catalog_api.delete_region, uuid.uuid4().hex) def test_create_region_invalid_parent_region_returns_not_found(self): new_region = unit.new_region_ref(parent_region_id='nonexisting') self.assertRaises(exception.RegionNotFound, self.catalog_api.create_region, new_region) def test_avoid_creating_circular_references_in_regions_update(self): region_one = self._create_region_with_parent_id() # self circle: region_one->region_one self.assertRaises(exception.CircularRegionHierarchyError, self.catalog_api.update_region, region_one['id'], {'parent_region_id': region_one['id']}) # region_one->region_two->region_one region_two = self._create_region_with_parent_id(region_one['id']) self.assertRaises(exception.CircularRegionHierarchyError, self.catalog_api.update_region, region_one['id'], {'parent_region_id': region_two['id']}) # region_one region_two->region_three->region_four->region_two region_three = self._create_region_with_parent_id(region_two['id']) region_four = self._create_region_with_parent_id(region_three['id']) self.assertRaises(exception.CircularRegionHierarchyError, self.catalog_api.update_region, region_two['id'], {'parent_region_id': region_four['id']}) @mock.patch.object(core.CatalogDriverV8, ""_ensure_no_circle_in_hierarchical_regions"") def test_circular_regions_can_be_deleted(self, mock_ensure_on_circle): # turn off the enforcement so that cycles can be created for the test mock_ensure_on_circle.return_value = None region_one = self._create_region_with_parent_id() # self circle: region_one->region_one self.catalog_api.update_region( region_one['id'], {'parent_region_id': region_one['id']}) self.catalog_api.delete_region(region_one['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_one['id']) # region_one->region_two->region_one region_one = self._create_region_with_parent_id() region_two = self._create_region_with_parent_id(region_one['id']) self.catalog_api.update_region( region_one['id'], {'parent_region_id': region_two['id']}) self.catalog_api.delete_region(region_one['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_one['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_two['id']) # region_one->region_two->region_three->region_one region_one = self._create_region_with_parent_id() region_two = self._create_region_with_parent_id(region_one['id']) region_three = self._create_region_with_parent_id(region_two['id']) self.catalog_api.update_region( region_one['id'], {'parent_region_id': region_three['id']}) self.catalog_api.delete_region(region_two['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_two['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_one['id']) self.assertRaises(exception.RegionNotFound, self.catalog_api.get_region, region_three['id']) def test_service_crud(self): # create new_service = unit.new_service_ref() service_id = new_service['id'] res = self.catalog_api.create_service(service_id, new_service) self.assertDictEqual(new_service, res) # list services = self.catalog_api.list_services() self.assertIn(service_id, [x['id'] for x in services]) # update service_name_update = {'name': uuid.uuid4().hex} res = self.catalog_api.update_service(service_id, service_name_update) expected_service = new_service.copy() expected_service['name'] = service_name_update['name'] self.assertDictEqual(expected_service, res) # delete self.catalog_api.delete_service(service_id) self.assertRaises(exception.ServiceNotFound, self.catalog_api.delete_service, service_id) self.assertRaises(exception.ServiceNotFound, self.catalog_api.get_service, service_id) def _create_random_service(self): new_service = unit.new_service_ref() service_id = new_service['id'] return self.catalog_api.create_service(service_id, new_service) def test_service_filtering(self): target_service = self._create_random_service() unrelated_service1 = self._create_random_service() unrelated_service2 = self._create_random_service() # filter by type hint_for_type = driver_hints.Hints() hint_for_type.add_filter(name=""type"", value=target_service['type']) services = self.catalog_api.list_services(hint_for_type) self.assertEqual(1, len(services)) filtered_service = services[0] self.assertEqual(target_service['type'], filtered_service['type']) self.assertEqual(target_service['id'], filtered_service['id']) # filter should have been removed, since it was already used by the # backend self.assertEqual(0, len(hint_for_type.filters)) # the backend shouldn't filter by name, since this is handled by the # front end hint_for_name = driver_hints.Hints() hint_for_name.add_filter(name=""name"", value=target_service['name']) services = self.catalog_api.list_services(hint_for_name) self.assertEqual(3, len(services)) # filter should still be there, since it wasn't used by the backend self.assertEqual(1, len(hint_for_name.filters)) self.catalog_api.delete_service(target_service['id']) self.catalog_api.delete_service(unrelated_service1['id']) self.catalog_api.delete_service(unrelated_service2['id']) @unit.skip_if_cache_disabled('catalog') def test_cache_layer_service_crud(self): new_service = unit.new_service_ref() service_id = new_service['id'] res = self.catalog_api.create_service(service_id, new_service) self.assertDictEqual(new_service, res) self.catalog_api.get_service(service_id) updated_service = copy.deepcopy(new_service) updated_service['description'] = uuid.uuid4().hex # update bypassing catalog api self.catalog_api.driver.update_service(service_id, updated_service) self.assertDictContainsSubset(new_service, self.catalog_api.get_service(service_id)) self.catalog_api.get_service.invalidate(self.catalog_api, service_id) self.assertDictContainsSubset(updated_service, self.catalog_api.get_service(service_id)) # delete bypassing catalog api self.catalog_api.driver.delete_service(service_id) self.assertDictContainsSubset(updated_service, self.catalog_api.get_service(service_id)) self.catalog_api.get_service.invalidate(self.catalog_api, service_id) self.assertRaises(exception.ServiceNotFound, self.catalog_api.delete_service, service_id) self.assertRaises(exception.ServiceNotFound, self.catalog_api.get_service, service_id) @unit.skip_if_cache_disabled('catalog') def test_invalidate_cache_when_updating_service(self): new_service = unit.new_service_ref() service_id = new_service['id'] self.catalog_api.create_service(service_id, new_service) # cache the service self.catalog_api.get_service(service_id) # update the service via catalog api new_type = {'type': uuid.uuid4().hex} self.catalog_api.update_service(service_id, new_type) # assert that we can get the new service current_service = self.catalog_api.get_service(service_id) self.assertEqual(new_type['type'], current_service['type']) def test_delete_service_with_endpoint(self): # create a service service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) # create an endpoint attached to the service endpoint = unit.new_endpoint_ref(service_id=service['id'], region_id=None) self.catalog_api.create_endpoint(endpoint['id'], endpoint) # deleting the service should also delete the endpoint self.catalog_api.delete_service(service['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.get_endpoint, endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.delete_endpoint, endpoint['id']) def test_cache_layer_delete_service_with_endpoint(self): service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) # create an endpoint attached to the service endpoint = unit.new_endpoint_ref(service_id=service['id'], region_id=None) self.catalog_api.create_endpoint(endpoint['id'], endpoint) # cache the result self.catalog_api.get_service(service['id']) self.catalog_api.get_endpoint(endpoint['id']) # delete the service bypassing catalog api self.catalog_api.driver.delete_service(service['id']) self.assertDictContainsSubset(endpoint, self.catalog_api. get_endpoint(endpoint['id'])) self.assertDictContainsSubset(service, self.catalog_api. get_service(service['id'])) self.catalog_api.get_endpoint.invalidate(self.catalog_api, endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.get_endpoint, endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.delete_endpoint, endpoint['id']) # multiple endpoints associated with a service second_endpoint = unit.new_endpoint_ref(service_id=service['id'], region_id=None) self.catalog_api.create_service(service['id'], service) self.catalog_api.create_endpoint(endpoint['id'], endpoint) self.catalog_api.create_endpoint(second_endpoint['id'], second_endpoint) self.catalog_api.delete_service(service['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.get_endpoint, endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.delete_endpoint, endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.get_endpoint, second_endpoint['id']) self.assertRaises(exception.EndpointNotFound, self.catalog_api.delete_endpoint, second_endpoint['id']) def test_get_service_returns_not_found(self): self.assertRaises(exception.ServiceNotFound, self.catalog_api.get_service, uuid.uuid4().hex) def test_delete_service_returns_not_found(self): self.assertRaises(exception.ServiceNotFound, self.catalog_api.delete_service, uuid.uuid4().hex) def test_create_endpoint_nonexistent_service(self): endpoint = unit.new_endpoint_ref(service_id=uuid.uuid4().hex, region_id=None) self.assertRaises(exception.ValidationError, self.catalog_api.create_endpoint, endpoint['id'], endpoint) def test_update_endpoint_nonexistent_service(self): dummy_service, enabled_endpoint, dummy_disabled_endpoint = ( self._create_endpoints()) new_endpoint = unit.new_endpoint_ref(service_id=uuid.uuid4().hex) self.assertRaises(exception.ValidationError, self.catalog_api.update_endpoint, enabled_endpoint['id'], new_endpoint) def test_create_endpoint_nonexistent_region(self): service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) endpoint = unit.new_endpoint_ref(service_id=service['id']) self.assertRaises(exception.ValidationError, self.catalog_api.create_endpoint, endpoint['id'], endpoint) def test_update_endpoint_nonexistent_region(self): dummy_service, enabled_endpoint, dummy_disabled_endpoint = ( self._create_endpoints()) new_endpoint = unit.new_endpoint_ref(service_id=uuid.uuid4().hex) self.assertRaises(exception.ValidationError, self.catalog_api.update_endpoint, enabled_endpoint['id'], new_endpoint) def test_get_endpoint_returns_not_found(self): self.assertRaises(exception.EndpointNotFound, self.catalog_api.get_endpoint, uuid.uuid4().hex) def test_delete_endpoint_returns_not_found(self): self.assertRaises(exception.EndpointNotFound, self.catalog_api.delete_endpoint, uuid.uuid4().hex) def test_create_endpoint(self): service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) endpoint = unit.new_endpoint_ref(service_id=service['id'], region_id=None) self.catalog_api.create_endpoint(endpoint['id'], endpoint.copy()) def test_update_endpoint(self): dummy_service_ref, endpoint_ref, dummy_disabled_endpoint_ref = ( self._create_endpoints()) res = self.catalog_api.update_endpoint(endpoint_ref['id'], {'interface': 'private'}) expected_endpoint = endpoint_ref.copy() expected_endpoint['interface'] = 'private' if self._legacy_endpoint_id_in_endpoint: expected_endpoint['legacy_endpoint_id'] = None if self._enabled_default_to_true_when_creating_endpoint: expected_endpoint['enabled'] = True self.assertDictEqual(expected_endpoint, res) def _create_endpoints(self): # Creates a service and 2 endpoints for the service in the same region. # The 'public' interface is enabled and the 'internal' interface is # disabled. def create_endpoint(service_id, region, **kwargs): ref = unit.new_endpoint_ref( service_id=service_id, region_id=region, url='http://localhost/%s' % uuid.uuid4().hex, **kwargs) self.catalog_api.create_endpoint(ref['id'], ref) return ref # Create a service for use with the endpoints. service_ref = unit.new_service_ref() service_id = service_ref['id'] self.catalog_api.create_service(service_id, service_ref) region = unit.new_region_ref() self.catalog_api.create_region(region) # Create endpoints enabled_endpoint_ref = create_endpoint(service_id, region['id']) disabled_endpoint_ref = create_endpoint( service_id, region['id'], enabled=False, interface='internal') return service_ref, enabled_endpoint_ref, disabled_endpoint_ref def test_list_endpoints(self): service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) expected_ids = set([uuid.uuid4().hex for _ in range(3)]) for endpoint_id in expected_ids: endpoint = unit.new_endpoint_ref(service_id=service['id'], id=endpoint_id, region_id=None) self.catalog_api.create_endpoint(endpoint['id'], endpoint) endpoints = self.catalog_api.list_endpoints() self.assertEqual(expected_ids, set(e['id'] for e in endpoints)) def test_get_catalog_endpoint_disabled(self): """"""Get back only enabled endpoints when get the v2 catalog."""""" service_ref, enabled_endpoint_ref, dummy_disabled_endpoint_ref = ( self._create_endpoints()) user_id = uuid.uuid4().hex project_id = uuid.uuid4().hex catalog = self.catalog_api.get_catalog(user_id, project_id) exp_entry = { 'id': enabled_endpoint_ref['id'], 'name': service_ref['name'], 'publicURL': enabled_endpoint_ref['url'], } region = enabled_endpoint_ref['region_id'] self.assertEqual(exp_entry, catalog[region][service_ref['type']]) def test_get_v3_catalog_endpoint_disabled(self): """"""Get back only enabled endpoints when get the v3 catalog."""""" enabled_endpoint_ref = self._create_endpoints()[1] user_id = uuid.uuid4().hex project_id = uuid.uuid4().hex catalog = self.catalog_api.get_v3_catalog(user_id, project_id) endpoint_ids = [x['id'] for x in catalog[0]['endpoints']] self.assertEqual([enabled_endpoint_ref['id']], endpoint_ids) @unit.skip_if_cache_disabled('catalog') def test_invalidate_cache_when_updating_endpoint(self): service = unit.new_service_ref() self.catalog_api.create_service(service['id'], service) # create an endpoint attached to the service endpoint = unit.new_endpoint_ref(service_id=service['id'], region_id=None) self.catalog_api.create_endpoint(endpoint['id'], endpoint) # cache the endpoint self.catalog_api.get_endpoint(endpoint['id']) # update the endpoint via catalog api new_url = {'url': uuid.uuid4().hex} self.catalog_api.update_endpoint(endpoint['id'], new_url) # assert that we can get the new endpoint current_endpoint = self.catalog_api.get_endpoint(endpoint['id']) self.assertEqual(new_url['url'], current_endpoint['url']) ",598,574
openstack%2Fneutron~master~I58e6056a9fe6460352855461e74700f4934e6e3f,openstack/neutron,master,I58e6056a9fe6460352855461e74700f4934e6e3f,Skip racey BGP tests,MERGED,2016-03-05 00:44:56.000000000,2016-03-05 05:21:04.000000000,2016-03-05 05:21:04.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-03-05 00:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f2049bca679e5759e0962ce62e57cb6e5c70205', 'message': 'Skip racey BGP tests\n\nChange-Id: I58e6056a9fe6460352855461e74700f4934e6e3f\nRelated-bug: #1553374\n'}, {'number': 2, 'created': '2016-03-05 00:55:17.000000000', 'files': ['neutron/tests/api/test_bgp_speaker_extensions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f556074c0219bab373535964888677da09dd27c', 'message': 'Skip racey BGP tests\n\nChange-Id: I58e6056a9fe6460352855461e74700f4934e6e3f\nRelated-bug: #1553374\n'}]",0,288818,3f556074c0219bab373535964888677da09dd27c,16,7,2,7448,,,0,"Skip racey BGP tests

Change-Id: I58e6056a9fe6460352855461e74700f4934e6e3f
Related-bug: #1553374
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/288818/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/api/test_bgp_speaker_extensions.py'],1,6f2049bca679e5759e0962ce62e57cb6e5c70205,bug/1553374,import testtools @testtools.skip('bug/1553374') @testtools.skip('bug/1553374'),,3,0
openstack%2Fkeystone~master~I7da7847817b024bb3be9d2501b0939029e41354f,openstack/keystone,master,I7da7847817b024bb3be9d2501b0939029e41354f,Remove the notification.disabled decorator,MERGED,2016-03-04 22:38:36.000000000,2016-03-05 05:20:27.000000000,2016-03-05 05:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-03-04 22:38:36.000000000', 'files': ['keystone/notifications.py', 'keystone/resource/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb88ffdfec004e131639f2d449c563420d4fb2cf', 'message': 'Remove the notification.disabled decorator\n\nThis was used in the resource API but not tested. This patch makes it so that\nthe resource API uses the preferred inline statement method of sending\nnotifications with:\n\n  notification.Audit.disabled()\n\nChange-Id: I7da7847817b024bb3be9d2501b0939029e41354f\n'}]",0,288776,cb88ffdfec004e131639f2d449c563420d4fb2cf,8,3,1,5046,,,0,"Remove the notification.disabled decorator

This was used in the resource API but not tested. This patch makes it so that
the resource API uses the preferred inline statement method of sending
notifications with:

  notification.Audit.disabled()

Change-Id: I7da7847817b024bb3be9d2501b0939029e41354f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/76/288776/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/notifications.py', 'keystone/resource/core.py']",2,cb88ffdfec004e131639f2d449c563420d4fb2cf,," notifications.Audit.disabled(self._PROJECT, project_id, public=False) notifications.Audit.disabled(self._DOMAIN, domain_id, public=False)"," @notifications.disabled(_PROJECT, public=False) pass @notifications.disabled(_DOMAIN, public=False) pass",2,9
openstack%2Fkeystone~master~Ifc032952a84a54a56845dfc8baf747c920f318a9,openstack/keystone,master,Ifc032952a84a54a56845dfc8baf747c920f318a9,Remove unused notification decorators,MERGED,2016-03-04 22:08:10.000000000,2016-03-05 05:17:12.000000000,2016-03-05 05:17:11.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2016-03-04 22:08:10.000000000', 'files': ['keystone/notifications.py', 'keystone/tests/unit/common/test_notifications.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/29de0869edec87fc657073d5f54014502cb99e05', 'message': 'Remove unused notification decorators\n\nThese decoratoes were only used in test_notification.py an nowhere else in\nkeystone. All other created, updated, and deleted notifications are issued with\n`notifications.Audit.<operation>` instead of the decorated methods.\n\nChange-Id: Ifc032952a84a54a56845dfc8baf747c920f318a9\n'}]",0,288762,29de0869edec87fc657073d5f54014502cb99e05,8,4,1,5046,,,0,"Remove unused notification decorators

These decoratoes were only used in test_notification.py an nowhere else in
keystone. All other created, updated, and deleted notifications are issued with
`notifications.Audit.<operation>` instead of the decorated methods.

Change-Id: Ifc032952a84a54a56845dfc8baf747c920f318a9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/62/288762/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/notifications.py', 'keystone/tests/unit/common/test_notifications.py']",2,29de0869edec87fc657073d5f54014502cb99e05,,,"class NotificationsWrapperTestCase(unit.BaseTestCase): def create_fake_ref(self): resource_id = uuid.uuid4().hex return resource_id, { 'id': resource_id, 'key': uuid.uuid4().hex } @notifications.created(EXP_RESOURCE_TYPE) def create_resource(self, resource_id, data): return data def test_resource_created_notification(self): exp_resource_id, data = self.create_fake_ref() callback = register_callback(CREATED_OPERATION) self.create_resource(exp_resource_id, data) callback.assert_called_with('identity', EXP_RESOURCE_TYPE, CREATED_OPERATION, {'resource_info': exp_resource_id}) @notifications.updated(EXP_RESOURCE_TYPE) def update_resource(self, resource_id, data): return data def test_resource_updated_notification(self): exp_resource_id, data = self.create_fake_ref() callback = register_callback(UPDATED_OPERATION) self.update_resource(exp_resource_id, data) callback.assert_called_with('identity', EXP_RESOURCE_TYPE, UPDATED_OPERATION, {'resource_info': exp_resource_id}) @notifications.deleted(EXP_RESOURCE_TYPE) def delete_resource(self, resource_id): pass def test_resource_deleted_notification(self): exp_resource_id = uuid.uuid4().hex callback = register_callback(DELETED_OPERATION) self.delete_resource(exp_resource_id) callback.assert_called_with('identity', EXP_RESOURCE_TYPE, DELETED_OPERATION, {'resource_info': exp_resource_id}) @notifications.created(EXP_RESOURCE_TYPE) def create_exception(self, resource_id): raise ArbitraryException() def test_create_exception_without_notification(self): callback = register_callback(CREATED_OPERATION) self.assertRaises( ArbitraryException, self.create_exception, uuid.uuid4().hex) self.assertFalse(callback.called) @notifications.created(EXP_RESOURCE_TYPE) def update_exception(self, resource_id): raise ArbitraryException() def test_update_exception_without_notification(self): callback = register_callback(UPDATED_OPERATION) self.assertRaises( ArbitraryException, self.update_exception, uuid.uuid4().hex) self.assertFalse(callback.called) @notifications.deleted(EXP_RESOURCE_TYPE) def delete_exception(self, resource_id): raise ArbitraryException() def test_delete_exception_without_notification(self): callback = register_callback(DELETED_OPERATION) self.assertRaises( ArbitraryException, self.delete_exception, uuid.uuid4().hex) self.assertFalse(callback.called) ",0,93
openstack%2Fmurano~master~I7b1e32d02885696977ac81460ff6d2aa4250ae1b,openstack/murano,master,I7b1e32d02885696977ac81460ff6d2aa4250ae1b,Moved CORS middleware configuration into oslo-config-generator,ABANDONED,2016-03-04 20:31:31.000000000,2016-03-05 05:04:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-03-04 20:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c6cf7d2b140feef608f607f92bf5a500e0f8c898', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for murano's implementation of cors middleware have\nbeen moved from paste.ini into the configuration hooks provided by oslo.config.\nFurthermore, these values have been added to murano's default configuration\nparsing. This ensures that if a value remains unset in murano.conf,\nit will be set to use sane defaults, and that an operator modifying the\nconfiguration file will be presented with a default set of necessary sane\nheaders.\n\nFixes Bug1551836\n\nChange-Id: I7b1e32d02885696977ac81460ff6d2aa4250ae1b\n""}, {'number': 2, 'created': '2016-03-05 02:52:12.000000000', 'files': ['murano/common/config.py', 'etc/murano/murano-paste.ini', 'murano/cmd/cfapi.py', 'murano/cmd/api.py', 'murano/common/wsgi.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/murano/commit/a02248c48c2c273fa301aad484fa347f78f361c2', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for murano's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have\nbeen added to murano's default configuration parsing. This ensures\nthat if a value remains unset in murano.conf, it will be set to use\nsane defaults, and that an operator modifying the configuration\nfile will be presented with a default set of necessary sane headers.\n\nFixes Bug1551836\n\nChange-Id: I7b1e32d02885696977ac81460ff6d2aa4250ae1b\n""}]",0,288724,a02248c48c2c273fa301aad484fa347f78f361c2,10,3,2,20661,,,0,"Moved CORS middleware configuration into oslo-config-generator

The default values needed for murano's implementation of cors
middleware have been moved from paste.ini into the configuration
hooks provided by oslo.config. Furthermore, these values have
been added to murano's default configuration parsing. This ensures
that if a value remains unset in murano.conf, it will be set to use
sane defaults, and that an operator modifying the configuration
file will be presented with a default set of necessary sane headers.

Fixes Bug1551836

Change-Id: I7b1e32d02885696977ac81460ff6d2aa4250ae1b
",git fetch https://review.opendev.org/openstack/murano refs/changes/24/288724/2 && git format-patch -1 --stdout FETCH_HEAD,"['murano/common/config.py', 'etc/murano/murano-paste.ini', 'murano/cmd/cfapi.py', 'murano/cmd/api.py', 'murano/common/wsgi.py', 'setup.cfg']",6,c6cf7d2b140feef608f607f92bf5a500e0f8c898,bug/1551836,oslo.config.opts.defaults = oslo.middleware = murano.common.config:set_middleware_defaults,,30,3
openstack%2Fopenstack-ansible~liberty~I157fd3f4e116afa886a27fc1f1422a3a04321c0a,openstack/openstack-ansible,liberty,I157fd3f4e116afa886a27fc1f1422a3a04321c0a,Ensure that the repo-server uses upper-constraints,MERGED,2016-03-04 11:39:18.000000000,2016-03-05 04:58:25.000000000,2016-03-05 04:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 12807}]","[{'number': 1, 'created': '2016-03-04 11:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c5b4073923c7e019c7b062590e60a9225ae19bc4', 'message': ""Ensure that the repo-server uses upper-constraints\n\nIn order to ensure that builds are repeatable (ie the result is\nalways the same when building from a tag), the repo server's\npackages must make use of OpenStack's upper-constraints file\nfor its own packages.\n\nThis patch ensures that this happens, and implements the\nadditional changes required for it to succeed.\n\nThis is a combined backport of:\n - https://review.openstack.org/284894\n - https://review.openstack.org/286923\n - https://review.openstack.org/286625 (partial)\n\nChange-Id: I157fd3f4e116afa886a27fc1f1422a3a04321c0a\n""}, {'number': 2, 'created': '2016-03-04 11:47:26.000000000', 'files': ['playbooks/roles/repo_build/tasks/repo_build_install.yml', 'playbooks/roles/repo_build/defaults/main.yml', 'playbooks/roles/repo_build/tasks/main.yml', 'playbooks/roles/repo_server/tasks/repo_install.yml', 'playbooks/roles/repo_server/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1a970ee0979576d9e17a683222d1b0343b5c3aa1', 'message': ""Ensure that the repo-server uses upper-constraints\n\nIn order to ensure that builds are repeatable (ie the result is\nalways the same when building from a tag), the repo server's\npackages must make use of OpenStack's upper-constraints file\nfor its own packages.\n\nThis patch ensures that this happens, and implements the\nadditional changes required for it to succeed.\n\nThis is a combined backport of:\n - https://review.openstack.org/284894\n - https://review.openstack.org/286923\n - https://review.openstack.org/286625 (partial)\n\nCloses-Bug: 1545505\nChange-Id: I157fd3f4e116afa886a27fc1f1422a3a04321c0a\n""}]",0,288405,1a970ee0979576d9e17a683222d1b0343b5c3aa1,15,3,2,6816,,,0,"Ensure that the repo-server uses upper-constraints

In order to ensure that builds are repeatable (ie the result is
always the same when building from a tag), the repo server's
packages must make use of OpenStack's upper-constraints file
for its own packages.

This patch ensures that this happens, and implements the
additional changes required for it to succeed.

This is a combined backport of:
 - https://review.openstack.org/284894
 - https://review.openstack.org/286923
 - https://review.openstack.org/286625 (partial)

Closes-Bug: 1545505
Change-Id: I157fd3f4e116afa886a27fc1f1422a3a04321c0a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/05/288405/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/repo_build/tasks/repo_build_install.yml', 'playbooks/roles/repo_build/defaults/main.yml', 'playbooks/roles/repo_build/tasks/main.yml', 'playbooks/roles/repo_server/tasks/repo_install.yml', 'playbooks/roles/repo_server/defaults/main.yml']",5,c5b4073923c7e019c7b062590e60a9225ae19bc4,repeatable-build,,repo_pip_packages: - cloudlib - PyCrypto - python-memcached - PyYAML - requests - turbolift - wheel - virtualenv - virtualenv-tools ,37,25
openstack%2Fnova~master~Ia79269e2bca0468edde830fc82a15b234e1abcbf,openstack/nova,master,Ia79269e2bca0468edde830fc82a15b234e1abcbf,deprecate ``volume_api_class`` and ``network_api_class``,MERGED,2016-03-03 19:26:03.000000000,2016-03-05 04:56:06.000000000,2016-03-04 22:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7173}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 19:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02f0e4694f660a329e214dc759495d6d9aa5c190', 'message': 'deprecate ``volume_api_class``\n\nThere is only one acceptable backend for the volume api which is our\ncinder driver. Deprecate this as a config option so it can be removed\nin Newton.\n\nChange-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf\n'}, {'number': 2, 'created': '2016-03-03 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3caba7e59472e5609ae179038f0a216154a86141', 'message': 'deprecate ``volume_api_class`` and ``network_api_class``\n\nBoth of these options only had one real in tree sensible\noption. Deprecate these so they can be removed and turned into\nconstants in Newton.\n\nChange-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf\n'}, {'number': 3, 'created': '2016-03-04 11:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e45b9f1f08c2feff8326f6f5fb49393286d2da7c', 'message': 'deprecate ``volume_api_class`` and ``network_api_class``\n\nBoth of these options only had one real in tree sensible\noption. Deprecate these so they can be removed and turned into\nconstants in Newton.\n\nChange-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf\n'}, {'number': 4, 'created': '2016-03-04 12:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2320559e8c49bfbbe9fb4f5cad8dfd6859f71391', 'message': 'deprecate ``volume_api_class`` and ``network_api_class``\n\nBoth of these options only had one real in tree sensible\noption. Deprecate these so they can be removed and turned into\nconstants in Newton.\n\nThis adds a new ``use_neutron`` config option to replace the\nnetwork_api_class option.\n\nChange-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf\n'}, {'number': 5, 'created': '2016-03-04 13:00:36.000000000', 'files': ['nova/tests/unit/network/test_config.py', 'nova/volume/__init__.py', 'nova/network/__init__.py', 'releasenotes/notes/rm_volume_manager-78fed5be43d285b3.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/6e8e322718529e50bf2035507b970058ddaa836a', 'message': 'deprecate ``volume_api_class`` and ``network_api_class``\n\nBoth of these options only had one real in tree sensible\noption. Deprecate these so they can be removed and turned into\nconstants in Newton.\n\nThis adds a new ``use_neutron`` config option to replace the\nnetwork_api_class option.\n\nChange-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf\n'}]",3,288077,6e8e322718529e50bf2035507b970058ddaa836a,55,16,5,2750,,,0,"deprecate ``volume_api_class`` and ``network_api_class``

Both of these options only had one real in tree sensible
option. Deprecate these so they can be removed and turned into
constants in Newton.

This adds a new ``use_neutron`` config option to replace the
network_api_class option.

Change-Id: Ia79269e2bca0468edde830fc82a15b234e1abcbf
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/288077/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/volume/__init__.py', 'releasenotes/notes/rm_volume_manager-78fed5be43d285b3.yaml']",2,02f0e4694f660a329e214dc759495d6d9aa5c190,deprecate_managers,--- deprecations: - Deprecate ``volume_api_class`` config option. We only support connecting to cinder so there is no reason to make this arbitrarily configurable. This option will be removed in Newton. ,,11,4
openstack%2Fcinder~master~Ia32cae8e4fe937f2512693acb7fcc552f01efa01,openstack/cinder,master,Ia32cae8e4fe937f2512693acb7fcc552f01efa01,Add 'conf' param for TextGuruMeditation autorun setup,MERGED,2016-02-16 16:53:13.000000000,2016-03-05 04:40:27.000000000,2016-03-03 19:01:46.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11600}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17103}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 20490}]","[{'number': 1, 'created': '2016-02-16 16:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/75aac59a36b2c481d6e705f4d612b67f1f91b5c7', 'message': ""Add 'conf' param for TextGuruMeditation autorun setup\n\nGuru Meditation Report (GMR) supports report generation to file\nin a configured directory. By default it will genarate\nreport to stdout stream. To configure GMR you have to add the\nfollowing section to cinder.conf:\n\n[oslo_reports]\nlog_dir = '/path/to/logs/dir'\n\nChange-Id: Ia32cae8e4fe937f2512693acb7fcc552f01efa01\nCloses-Bug: #1546199\n""}, {'number': 2, 'created': '2016-03-01 14:42:18.000000000', 'files': ['cinder/cmd/volume.py', 'cinder/cmd/api.py', 'cinder/cmd/all.py', 'cinder/cmd/scheduler.py', 'cinder/cmd/backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/68a92ea462e9378dcf5d835fda37b1b0001768b7', 'message': ""Add 'conf' param for TextGuruMeditation autorun setup\n\nGuru Meditation Report (GMR) supports report generation to file\nin a configured directory. By default it will genarate\nreport to stdout stream. To configure GMR you have to add the\nfollowing section to cinder.conf:\n\n[oslo_reports]\nlog_dir = '/path/to/logs/dir'\n\nDocImpact\nChange-Id: Ia32cae8e4fe937f2512693acb7fcc552f01efa01\nCloses-Bug: #1546199\n""}]",0,280815,68a92ea462e9378dcf5d835fda37b1b0001768b7,71,34,2,1736,,,0,"Add 'conf' param for TextGuruMeditation autorun setup

Guru Meditation Report (GMR) supports report generation to file
in a configured directory. By default it will genarate
report to stdout stream. To configure GMR you have to add the
following section to cinder.conf:

[oslo_reports]
log_dir = '/path/to/logs/dir'

DocImpact
Change-Id: Ia32cae8e4fe937f2512693acb7fcc552f01efa01
Closes-Bug: #1546199
",git fetch https://review.opendev.org/openstack/cinder refs/changes/15/280815/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/cmd/volume.py', 'cinder/cmd/api.py', 'cinder/cmd/scheduler.py', 'cinder/cmd/backup.py']",4,75aac59a36b2c481d6e705f4d612b67f1f91b5c7,bug/1546199,"from oslo_reports import opts as gmr_opts gmr_opts.set_defaults(CONF) gmr.TextGuruMeditation.setup_autorun(version, conf=CONF)", gmr.TextGuruMeditation.setup_autorun(version),12,4
openstack%2Fcinder~stable%2Fliberty~I06d1d39cb4b42d6652becaa49935987297004b97,openstack/cinder,stable/liberty,I06d1d39cb4b42d6652becaa49935987297004b97,Fixes LOG.exception related unit test failure,MERGED,2016-03-02 14:56:28.000000000,2016-03-05 04:12:06.000000000,2016-03-03 00:14:57.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 12540}, {'_account_id': 14101}, {'_account_id': 15296}, {'_account_id': 16595}, {'_account_id': 17852}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-02 14:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/92b97d1a0488ea732ed769b804c3e8a89e4e5172', 'message': 'Fixes LOG.exception related unit test failure\n\nLOG.exception is being called outside of an exception handler, causing\nthe python34 unit tests to fail. Changing it to LOG.error fixes\nthe issue.\n\nAccording to the documentation, LOG.exception must be called only from\nan exception handler:\nhttps://docs.python.org/3/library/logging.html#logging.Logger.exception\n\nChange-Id: I06d1d39cb4b42d6652becaa49935987297004b97\nCloses-Bug: #1552261\n'}, {'number': 2, 'created': '2016-03-02 14:58:02.000000000', 'files': ['cinder/volume/drivers/windows/vhdutils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/76b57b1d364caeacae64e2e63ae72495d2b8f1fd', 'message': 'Fixes LOG.exception related unit test failure\n\nLOG.exception is being called outside of an exception handler, causing\nthe python34 unit tests to fail. Changing it to LOG.error fixes\nthe issue.\n\nAccording to the documentation, LOG.exception must be called only from\nan exception handler:\nhttps://docs.python.org/3/library/logging.html#logging.Logger.exception\n\nNOTE(claudiub): This issue does not affect the master branch, as the\nvhdutils and other Windows related utils have been replaced with os-win.\n\nChange-Id: I06d1d39cb4b42d6652becaa49935987297004b97\nCloses-Bug: #1552261\n'}]",0,287245,76b57b1d364caeacae64e2e63ae72495d2b8f1fd,23,13,2,8213,,,0,"Fixes LOG.exception related unit test failure

LOG.exception is being called outside of an exception handler, causing
the python34 unit tests to fail. Changing it to LOG.error fixes
the issue.

According to the documentation, LOG.exception must be called only from
an exception handler:
https://docs.python.org/3/library/logging.html#logging.Logger.exception

NOTE(claudiub): This issue does not affect the master branch, as the
vhdutils and other Windows related utils have been replaced with os-win.

Change-Id: I06d1d39cb4b42d6652becaa49935987297004b97
Closes-Bug: #1552261
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/287245/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/windows/vhdutils.py'],1,92b97d1a0488ea732ed769b804c3e8a89e4e5172,bug/1552261, LOG.error(err), LOG.exception(err),1,1
openstack%2Fnova~master~Ie2cb64a43198e1155f768ceabe50ce8a004a1d41,openstack/nova,master,Ie2cb64a43198e1155f768ceabe50ce8a004a1d41,deprecate ``compute_stats_class`` config option,MERGED,2016-03-04 12:12:32.000000000,2016-03-05 03:38:50.000000000,2016-03-04 16:23:36.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}]","[{'number': 1, 'created': '2016-03-04 12:12:32.000000000', 'files': ['releasenotes/notes/deprecate_compute_stats_class-229abfcb8816bdbd.yaml', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3be36fcb7bdc0f48eae06f5378f3ba2e4a4975bd', 'message': ""deprecate ``compute_stats_class`` config option\n\nThere was only one implementation in tree, and this isn't an extension\npoint or interface we want people plugging out of tree code into.\n\nChange-Id: Ie2cb64a43198e1155f768ceabe50ce8a004a1d41\n""}]",0,288421,3be36fcb7bdc0f48eae06f5378f3ba2e4a4975bd,17,7,1,2750,,,0,"deprecate ``compute_stats_class`` config option

There was only one implementation in tree, and this isn't an extension
point or interface we want people plugging out of tree code into.

Change-Id: Ie2cb64a43198e1155f768ceabe50ce8a004a1d41
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/288421/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate_compute_stats_class-229abfcb8816bdbd.yaml', 'nova/compute/resource_tracker.py']",2,3be36fcb7bdc0f48eae06f5378f3ba2e4a4975bd,deprecate_managers," help='DEPRECATED: Class that will manage stats for the ' 'local compute host', deprecated_for_removal=True),"," help='Class that will manage stats for the local compute host'),",11,1
openstack%2Fnova~master~I0f9866320cd655134281193c50ec170ea20c011a,openstack/nova,master,I0f9866320cd655134281193c50ec170ea20c011a,Deprecate the ``vendordata_driver`` config option.,MERGED,2016-03-03 20:13:39.000000000,2016-03-05 03:37:15.000000000,2016-03-04 14:50:53.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebe3a27cbac039afeff47327e4b77d297bfa715c', 'message': 'Deprecate the ``vendordata_driver`` config option.\n\nThis allowed creating a differ class loader for defining vendordata\nmetadata for the metadata server. The default driver loads from a json\nfile that can be arbitrarily specified, so is still quite flexible.\n\nChange-Id: I0f9866320cd655134281193c50ec170ea20c011a\n'}, {'number': 2, 'created': '2016-03-04 11:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1c91ca1327a039ab466b27a43b01f9b01933019', 'message': 'Deprecate the ``vendordata_driver`` config option.\n\nThis allowed creating a differ class loader for defining vendordata\nmetadata for the metadata server. The default driver loads from a json\nfile that can be arbitrarily specified, so is still quite flexible.\n\nChange-Id: I0f9866320cd655134281193c50ec170ea20c011a\n'}, {'number': 3, 'created': '2016-03-04 12:12:32.000000000', 'files': ['releasenotes/notes/deprecate_vendordata_driver-eefc745365a881c3.yaml', 'nova/api/metadata/base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/21da1babce0a3f6a2e8e2b802e9cc0e8f491526b', 'message': 'Deprecate the ``vendordata_driver`` config option.\n\nThis allowed creating a differ class loader for defining vendordata\nmetadata for the metadata server. The default driver loads from a json\nfile that can be arbitrarily specified, so is still quite flexible.\n\nChange-Id: I0f9866320cd655134281193c50ec170ea20c011a\n'}]",2,288107,21da1babce0a3f6a2e8e2b802e9cc0e8f491526b,33,13,3,2750,,,0,"Deprecate the ``vendordata_driver`` config option.

This allowed creating a differ class loader for defining vendordata
metadata for the metadata server. The default driver loads from a json
file that can be arbitrarily specified, so is still quite flexible.

Change-Id: I0f9866320cd655134281193c50ec170ea20c011a
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/288107/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate_vendordata_driver-eefc745365a881c3.yaml', 'nova/api/metadata/base.py']",2,ebe3a27cbac039afeff47327e4b77d297bfa715c,deprecate_managers," help='DEPRECATED: Driver to use for vendor data', deprecated_for_removal=True),"," help='Driver to use for vendor data'),",12,1
openstack%2Fnova~master~If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126,openstack/nova,master,If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126,Deprecate db_driver config option,MERGED,2016-03-03 20:13:39.000000000,2016-03-05 03:18:43.000000000,2016-03-04 14:49:12.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/191c07173ca60d6f1b420ec805a757176e80ebdb', 'message': 'Deprecate db_driver config option\n\nPreviously this let you replace our SQLAlchemy database layer with\nyour own. This approach is deprecated. Deployments that felt the need\nto use the facility are encourage to work with upstream Nova to\naddress db driver concerns in the main SQLAlchemy code paths.\n\nChange-Id: If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126\n'}, {'number': 2, 'created': '2016-03-04 11:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a452d7e19ef2f79bf8362c16da85a03e6f3c767b', 'message': 'Deprecate db_driver config option\n\nPreviously this let you replace our SQLAlchemy database layer with\nyour own. This approach is deprecated. Deployments that felt the need\nto use the facility are encourage to work with upstream Nova to\naddress db driver concerns in the main SQLAlchemy code paths.\n\nChange-Id: If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126\n'}, {'number': 3, 'created': '2016-03-04 12:12:32.000000000', 'files': ['nova/db/base.py', 'releasenotes/notes/deprecate_db_driver-91c76ca8011d663c.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/c87ae92be56fa7f0f75749df5b8cbd527f539dcf', 'message': 'Deprecate db_driver config option\n\nPreviously this let you replace our SQLAlchemy database layer with\nyour own. This approach is deprecated. Deployments that felt the need\nto use the facility are encourage to work with upstream Nova to\naddress db driver concerns in the main SQLAlchemy code paths.\n\nChange-Id: If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126\n'}]",3,288106,c87ae92be56fa7f0f75749df5b8cbd527f539dcf,32,14,3,2750,,,0,"Deprecate db_driver config option

Previously this let you replace our SQLAlchemy database layer with
your own. This approach is deprecated. Deployments that felt the need
to use the facility are encourage to work with upstream Nova to
address db driver concerns in the main SQLAlchemy code paths.

Change-Id: If195a6bc399c8b1e2bfb0ea5579f2be21d0bc126
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/288106/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/base.py', 'releasenotes/notes/deprecate_db_driver-91c76ca8011d663c.yaml']",2,191c07173ca60d6f1b420ec805a757176e80ebdb,deprecate_managers,--- deprecations: - Deprecate the ``db_driver`` config option. Previously this let you replace our SQLAlchemy database layer with your own. This approach is deprecated. Deployments that felt the need to use the facility are encourage to work with upstream Nova to address db driver concerns in the main SQLAlchemy code paths. ,,18,3
openstack%2Fhorizon~master~I049eaf5eb9c34cfa9148401b4014f7e0c2820890,openstack/horizon,master,I049eaf5eb9c34cfa9148401b4014f7e0c2820890,Updated from global requirements,MERGED,2016-03-04 10:15:04.000000000,2016-03-05 03:07:01.000000000,2016-03-05 03:07:00.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 10:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d901e6d2aaa2bfeee274648ee4b129ad8c4e4bae', 'message': 'Updated from global requirements\n\nChange-Id: I049eaf5eb9c34cfa9148401b4014f7e0c2820890\n'}, {'number': 2, 'created': '2016-03-04 14:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fa994fa6157394dff5a85d9b28db091c37779719', 'message': 'Updated from global requirements\n\nChange-Id: I049eaf5eb9c34cfa9148401b4014f7e0c2820890\n'}, {'number': 3, 'created': '2016-03-04 22:30:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/62038cc82205afd20e8b2f81f7d4807a414fabe7', 'message': 'Updated from global requirements\n\nChange-Id: I049eaf5eb9c34cfa9148401b4014f7e0c2820890\n'}]",0,288350,62038cc82205afd20e8b2f81f7d4807a414fabe7,14,3,3,11131,,,0,"Updated from global requirements

Change-Id: I049eaf5eb9c34cfa9148401b4014f7e0c2820890
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/288350/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d901e6d2aaa2bfeee274648ee4b129ad8c4e4bae,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Frequirements~master~Ib8b6060427f3670c4fa5cbdb1becb724c77dac5e,openstack/requirements,master,Ib8b6060427f3670c4fa5cbdb1becb724c77dac5e,Need a new minimum for oslo.cache in Mitaka,MERGED,2016-03-04 19:41:27.000000000,2016-03-05 03:02:31.000000000,2016-03-05 03:02:29.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 18675}]","[{'number': 1, 'created': '2016-03-04 19:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4a46c33912b7cbeb5981faa0a0d3a15a2f1620ae', 'message': 'Need a new minimum for oslo.cache in Mitaka\n\nWe noticed a problem with oslo.cache having issues with\nolder versions of dogpile. So we updated the minimum version\nof dogpile in:\nefc1a96518b3c3e2fdd995ea5138b9cc03443ae7\n\nNow we need to make sure projects pick the right set of\noslo.cache and dogpile for Mitaka with this bump\n\nRelated-Bug: #1552897\nChange-Id: Ib8b6060427f3670c4fa5cbdb1becb724c77dac5e\n'}, {'number': 2, 'created': '2016-03-04 19:42:32.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9eec635b68276782d407eeabb84e93f1e0d34770', 'message': 'Need a new minimum for oslo.cache in Mitaka\n\nWe noticed a problem with oslo.cache having issues with\nolder versions of dogpile. So we updated the minimum version\nof dogpile in:\nefc1a96518b3c3e2fdd995ea5138b9cc03443ae7\n\nNow we need to make sure projects pick the right set of\noslo.cache and dogpile for Mitaka with this bump\n\nDepends-On: I186008bff7c72d8e5bf574db8c1f17cb806c6268\nRelated-Bug: #1552897\nChange-Id: Ib8b6060427f3670c4fa5cbdb1becb724c77dac5e\n'}]",0,288703,9eec635b68276782d407eeabb84e93f1e0d34770,10,3,2,5638,,,0,"Need a new minimum for oslo.cache in Mitaka

We noticed a problem with oslo.cache having issues with
older versions of dogpile. So we updated the minimum version
of dogpile in:
efc1a96518b3c3e2fdd995ea5138b9cc03443ae7

Now we need to make sure projects pick the right set of
oslo.cache and dogpile for Mitaka with this bump

Depends-On: I186008bff7c72d8e5bf574db8c1f17cb806c6268
Related-Bug: #1552897
Change-Id: Ib8b6060427f3670c4fa5cbdb1becb724c77dac5e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/03/288703/2 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,4a46c33912b7cbeb5981faa0a0d3a15a2f1620ae,bug/1552897,oslo.cache===1.5.0,oslo.cache===1.4.0,2,2
openstack%2Fglance~master~I6af3e0ae45ee535859c4ad278ccf995643225585,openstack/glance,master,I6af3e0ae45ee535859c4ad278ccf995643225585,Creating or updating a image member in a list causes 500,MERGED,2016-03-01 11:57:09.000000000,2016-03-05 03:02:22.000000000,2016-03-05 03:02:22.000000000,"[{'_account_id': 3}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 17116}, {'_account_id': 17123}, {'_account_id': 18675}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-01 11:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/82c247415981f2be7b15c26cb5e65d2e9e0660b3', 'message': 'Adding member in a list causes 500\n\nThis change catches a type error that can be raised if a user mistakenly\nuses a list over a dict.\n\nChange-Id: I6af3e0ae45ee535859c4ad278ccf995643225585\nCloses-Bug: 1551689\n'}, {'number': 2, 'created': '2016-03-01 16:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9c9ae02ce54d353e85e84d8e5ab24eb10125785b', 'message': 'Adding member in a list causes 500\n\nThis change catches a type error that can be raised if a user mistakenly\nuses a list over a dict.\n\nCatches it for both the create and update.\n\nChange-Id: I6af3e0ae45ee535859c4ad278ccf995643225585\nCloses-Bug: 1551689\n'}, {'number': 3, 'created': '2016-03-02 10:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b88e80a2515ce8efa58e5efe7a5454d88c72d383', 'message': 'Adding member in a list causes 500\n\nThis change catches a type error that can be raised if a user mistakenly\nuses a list over a dict.\n\nCatches it for both the create and update.\n\nChange-Id: I6af3e0ae45ee535859c4ad278ccf995643225585\nCloses-Bug: 1551689\n'}, {'number': 4, 'created': '2016-03-02 15:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bacf3233561d22966471aaeaa16dfa45262bb63b', 'message': 'Adding member in a list causes 500\n\nThis change catches a type error that can be raised if a user mistakenly\nuses a list over a dict.\n\nCatches it for both the create and update.\n\nChange-Id: I6af3e0ae45ee535859c4ad278ccf995643225585\nCloses-Bug: 1551689\n'}, {'number': 5, 'created': '2016-03-04 14:21:24.000000000', 'files': ['glance/tests/unit/v2/test_image_members_resource.py', 'glance/api/v2/image_members.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/6c6151af8ee8c4f5170f95b862b2b5b78f7fff8a', 'message': 'Creating or updating a image member in a list causes 500\n\nThis change catches a type error that can be raised if a user mistakenly\nuses a list over a dict. This occurs in both adding a new member and\nupdating a member that has already been added.\n\nThis will cause a HTTPBadRequest to be raised with instructions how to\nfix the problem.\n\nChange-Id: I6af3e0ae45ee535859c4ad278ccf995643225585\nCloses-Bug: 1551689\n'}]",9,286526,6c6151af8ee8c4f5170f95b862b2b5b78f7fff8a,30,7,5,17116,,,0,"Creating or updating a image member in a list causes 500

This change catches a type error that can be raised if a user mistakenly
uses a list over a dict. This occurs in both adding a new member and
updating a member that has already been added.

This will cause a HTTPBadRequest to be raised with instructions how to
fix the problem.

Change-Id: I6af3e0ae45ee535859c4ad278ccf995643225585
Closes-Bug: 1551689
",git fetch https://review.opendev.org/openstack/glance refs/changes/26/286526/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v2/test_image_members_resource.py', 'glance/api/v2/image_members.py']",2,82c247415981f2be7b15c26cb5e65d2e9e0660b3,bug/1551689," except TypeError: msg = _(""Please use a dict to supply the member."") raise webob.exc.HTTPBadRequest(explanation=msg)",,9,0
openstack%2Fnetworking-hyperv~master~I33bdbed5b65da25fc73d3246397f5c1569b9fa86,openstack/networking-hyperv,master,I33bdbed5b65da25fc73d3246397f5c1569b9fa86,Adds LOG.exception when an exception is raised,MERGED,2016-03-05 00:43:22.000000000,2016-03-05 02:35:48.000000000,2016-03-05 02:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2016-03-05 00:43:22.000000000', 'files': ['hyperv/neutron/security_groups_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/b5975fce89acf8fd072aa982b25211d2e8b0b5aa', 'message': 'Adds LOG.exception when an exception is raised\n\nIn order to make the logs more helpful when there is\nan exception being raised, LOG.exception will also\ninclude the exception trace.\n\nChange-Id: I33bdbed5b65da25fc73d3246397f5c1569b9fa86\n'}]",0,288817,b5975fce89acf8fd072aa982b25211d2e8b0b5aa,7,2,1,8213,,,0,"Adds LOG.exception when an exception is raised

In order to make the logs more helpful when there is
an exception being raised, LOG.exception will also
include the exception trace.

Change-Id: I33bdbed5b65da25fc73d3246397f5c1569b9fa86
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/17/288817/1 && git format-patch -1 --stdout FETCH_HEAD,['hyperv/neutron/security_groups_driver.py'],1,b5975fce89acf8fd072aa982b25211d2e8b0b5aa,," except Exception: LOG.exception(_LE('Exception encountered while adding rules for ' 'port: %s'), port_id) raise except Exception: LOG.exception(_LE('Exception encountered while removing rules for ' 'port: %s'), port_id) raise"," except Exception as ex: LOG.error(_LE('Hyper-V Exception: %(hyperv_exeption)s while ' 'adding rules for port: %(port_id)s'), dict(hyperv_exeption=ex, port_id=port_id)) raise ex except Exception as ex: LOG.error(_LE('Hyper-V Exception: %(hyperv_exeption)s while ' 'removing rules for port: %(port_id)s'), dict(hyperv_exeption=ex, port_id=port_id)) raise ex",8,10
openstack%2Fnetworking-hyperv~master~I4f4cc85ed3e22158c93ba49023804eba031ce958,openstack/networking-hyperv,master,I4f4cc85ed3e22158c93ba49023804eba031ce958,Removes WMI and pywin32 requirement,MERGED,2015-12-11 16:59:56.000000000,2016-03-05 02:34:43.000000000,2016-03-05 02:34:43.000000000,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2015-12-11 16:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/e59412a0081fb60399ab1434c28d68c1588f8bf0', 'message': 'Replaces WMI requirement with PyMI\n\nChange-Id: I4f4cc85ed3e22158c93ba49023804eba031ce958\n'}, {'number': 2, 'created': '2016-02-23 18:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/0c4a04f0185f392194ea3ed551dfda69c72bbc58', 'message': 'Replaces WMI requirement with PyMI\n\nCo-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>\n\nChange-Id: I4f4cc85ed3e22158c93ba49023804eba031ce958\n'}, {'number': 3, 'created': '2016-03-05 00:56:44.000000000', 'files': ['requirements-windows.txt', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/47d23d2182ab0cb79a8d6a7ae81db9e22874cdef', 'message': 'Removes WMI and pywin32 requirement\n\nRequirements no longer needed, thanks to os-win.\n\nCo-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>\n\nChange-Id: I4f4cc85ed3e22158c93ba49023804eba031ce958\n'}]",0,256585,47d23d2182ab0cb79a8d6a7ae81db9e22874cdef,17,5,3,3185,,,0,"Removes WMI and pywin32 requirement

Requirements no longer needed, thanks to os-win.

Co-Authored-By: Claudiu Belu <cbelu@cloudbasesolutions.com>

Change-Id: I4f4cc85ed3e22158c93ba49023804eba031ce958
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/85/256585/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-windows.txt', 'requirements.txt']",2,e59412a0081fb60399ab1434c28d68c1588f8bf0,replace_wmi_with_pymi,pymi>=1.0.0.dev4;sys_platform=='win32' ,wmi;sys_platform=='win32',2,2
openstack%2Fnova~master~Id25bd4870c6e2fda08dc0177b7ed61a8a6091838,openstack/nova,master,Id25bd4870c6e2fda08dc0177b7ed61a8a6091838,deprecate manager class options,MERGED,2016-03-03 15:09:31.000000000,2016-03-05 02:21:42.000000000,2016-03-04 14:47:39.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6773}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-03-03 15:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c702ab87c30081625358136ca910add60f650f2b', 'message': 'deprecate manager class options\n\nWe should deprecate the manager classes used for all of our\nservices. This is not a thing we actually expect or want to support\npeople replacing. If we want modular plug points at any of these all\nthe options should be in tree and specified by constants to switch\nbetween.\n\nChange-Id: Id25bd4870c6e2fda08dc0177b7ed61a8a6091838\n'}, {'number': 2, 'created': '2016-03-03 19:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c3d0e6156ed448d4e729300f2c2fba5df023dd3', 'message': 'deprecate manager class options\n\nWe should deprecate the manager classes used for all of our\nservices. This is not a thing we actually expect or want to support\npeople replacing. If we want modular plug points at any of these all\nthe options should be in tree and specified by constants to switch\nbetween.\n\nChange-Id: Id25bd4870c6e2fda08dc0177b7ed61a8a6091838\n'}, {'number': 3, 'created': '2016-03-03 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d3ac9785337eb9e58d8f7b7810240c7f3e558b4', 'message': 'deprecate manager class options\n\nWe should deprecate the manager classes used for all of our\nservices. This is not a thing we actually expect or want to support\npeople replacing. If we want modular plug points at any of these all\nthe options should be in tree and specified by constants to switch\nbetween.\n\nChange-Id: Id25bd4870c6e2fda08dc0177b7ed61a8a6091838\n'}, {'number': 4, 'created': '2016-03-04 11:36:35.000000000', 'files': ['nova/service.py', 'nova/conf/cells.py', 'releasenotes/notes/deprecate_pluggable_managers-ca0224bcd779454c.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/0fcec69a2346474ba033a435b1f82d1a833bad7c', 'message': 'deprecate manager class options\n\nWe should deprecate the manager classes used for all of our\nservices. This is not a thing we actually expect or want to support\npeople replacing. If we want modular plug points at any of these all\nthe options should be in tree and specified by constants to switch\nbetween.\n\nChange-Id: Id25bd4870c6e2fda08dc0177b7ed61a8a6091838\n'}]",16,287867,0fcec69a2346474ba033a435b1f82d1a833bad7c,62,21,4,2750,,,0,"deprecate manager class options

We should deprecate the manager classes used for all of our
services. This is not a thing we actually expect or want to support
people replacing. If we want modular plug points at any of these all
the options should be in tree and specified by constants to switch
between.

Change-Id: Id25bd4870c6e2fda08dc0177b7ed61a8a6091838
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/287867/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/service.py', 'nova/conf/cells.py', 'releasenotes/notes/deprecate_pluggable_managers-ca0224bcd779454c.yaml']",3,c702ab87c30081625358136ca910add60f650f2b,deprecate_managers,--- deprecations: - We have deprecated the options used to set custom managers for most of the services. This previous was a way to replace things like the compute manager with out of tree code. In Newton these options will be removed and the upstream defaults will just be constants. ,,28,9
openstack%2Ftripleo-heat-templates~master~Ie7a742bdf1db533edda2998a53d28528f80ef8e2,openstack/tripleo-heat-templates,master,Ie7a742bdf1db533edda2998a53d28528f80ef8e2,Add IPv6 Support to Isolated Networks,MERGED,2015-10-15 15:17:00.000000000,2016-03-05 02:20:16.000000000,2016-03-05 02:20:16.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 8449}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-10-15 15:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7b6767c93aa39e800341566111b03b57cbf5fa39', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThis change will likely require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack may need to be updated.\n\nThis was tested with only the Tenant network using IPv6, and resulted\nin a successful working deployment.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 2, 'created': '2015-10-21 21:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/542e0fa6090334d656e6ba2bb53ac42bd9d76a44', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/56\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will likely require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments may need to be updated.\n\nThis was tested with only the Tenant network using IPv6, and resulted\nin a successful working deployment.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 3, 'created': '2015-11-20 19:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/264aac8907e57c5c8b57aa38cdda4a4ef35c3a5f', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nThis was tested with only the Tenant network using IPv6, and resulted\nin a successful working deployment. Problems with the loadbalancer.pp\nPuppet module are currently preventing a successful deployment with\nIPv6 on the Internal API network, but changes are being made to\naccomodate.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 4, 'created': '2015-11-24 18:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3976874edf9b3c984a05d7e1aea30e9f3909666c', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nThis was tested with only the Tenant network using IPv6, and resulted\nin a successful working deployment. Problems with the loadbalancer.pp\nPuppet module are currently preventing a successful deployment with\nIPv6 on the Internal API network, but changes are being made to\naccomodate.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 5, 'created': '2015-12-02 02:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a73f599418eb8820402e2054038d95113358189', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 6, 'created': '2015-12-08 19:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/113cd1190bf8768447522d24a65faebc3af20519', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 7, 'created': '2015-12-08 20:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a129298361f838a34cb992c238bf98fc5e015399', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 8, 'created': '2015-12-09 17:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/43f0c7078970798cb8cea81909b436cbb631b1ee', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 9, 'created': '2015-12-09 21:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6acc1bd34acb629f7e40cb3a6234976c2fe4dbe4', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 10, 'created': '2015-12-10 00:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d078a2e20773a34ae2976c85920b3d083fcd7422', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 11, 'created': '2015-12-10 01:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a4fe1ba5bf9d97ae2ce0de88b1126a9c4b34a03', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 12, 'created': '2015-12-10 19:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3797da5d53cf890a10c2e4faeb47a918ce5c68e3', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 13, 'created': '2015-12-10 21:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/64027f1bd31aba03d42f6f4169483167f5614664', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 14, 'created': '2015-12-11 18:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47697bbda82c1cab4afa02f4958bc2ad5e3b2d1e', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 15, 'created': '2015-12-15 18:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dcff1f1f4fb2470a6f2eac2e9ebf7277f6ae32aa', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 16, 'created': '2016-01-04 11:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3623bba5816d6e58d7ea4d1d8cfc1743ca15a4e6', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 17, 'created': '2016-01-04 11:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d1187a0dc2b11b55584d6b49d2e50cd9371cd4f0', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 18, 'created': '2016-01-04 11:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/554b9b60ab4e542909865f5ca0b50db63929400e', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 19, 'created': '2016-01-04 13:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/238eb87017584f4a8562882ebc084cf2d04adf2c', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 20, 'created': '2016-01-04 13:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/593b7477cb215d1cad06ed31dbd391cec992957f', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 21, 'created': '2016-01-05 19:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2572e46197bc41323dc1b190fc5f8b1d3c0e7121', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 22, 'created': '2016-01-06 20:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/15d4bfc330eecdb2204f3e96a20c3c7e89d8b5aa', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 23, 'created': '2016-01-06 22:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/25201f415d6c1f4b43671555799bba472a1bbe2d', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 24, 'created': '2016-01-11 22:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fb40739c4d00ba5e84c3e038eceb67cbb1fea780', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 25, 'created': '2016-01-11 22:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/31a3b8a3d0a4ca900ba560e5a30a05f198a6de35', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 26, 'created': '2016-01-13 18:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3d07cf4d34287acf827e7e6dd725b06434e0348a', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 27, 'created': '2016-01-13 20:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a3e1784274a75ae307602f26eae0d785c726c8d9', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 28, 'created': '2016-01-13 20:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad946b1d856b59771d77e1bf6660ba9ca173e261', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 29, 'created': '2016-01-13 20:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/173a56d08e78097f49c9e651db99efeeee97c7a2', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 30, 'created': '2016-01-13 20:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/400b435db147ec52654d05d6225c5348555bd97c', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 31, 'created': '2016-01-13 20:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/952889b31ff9194ef1ef0e3dc3494b1fc1ca5830', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 32, 'created': '2016-01-13 22:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/10abd78c9161afd106471e1d95bcdfba0bb95ef0', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 33, 'created': '2016-01-13 23:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a856b6ccad95523a7fd3c372d47ec914c8fdf74e', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 34, 'created': '2016-01-13 23:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a54626d4b5a80b8a5c6c9d7463c80e75227edfd', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nDepends-On: Ide26ca1740dc12ea5f47a28f4cecacd6ef0b18f9\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 35, 'created': '2016-01-14 08:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2ace25bd53bbcaa69b4da5868ef96eac49cdad79', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 36, 'created': '2016-01-19 20:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cbbb5a896e90ff032fa26bf1651f3ef22aab4f8c', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 37, 'created': '2016-01-19 20:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f4938a87341b47ef737b3f42adb0fe723fe6e718', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 38, 'created': '2016-01-25 13:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4e3735f6e96000f0b0bc88e49528ea233765598', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 39, 'created': '2016-02-16 16:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c5ffa5e84f68e3d71433cbd3d257cc50c8b95508', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 40, 'created': '2016-02-24 16:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f8b998f6ac4f339ba9304e814f2608d7278d568', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 41, 'created': '2016-02-25 10:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9d83d48f690ce51443de4fcab2fda3bd9a8de74', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 42, 'created': '2016-02-25 14:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/99453f872b950090d57bc9a56cc4c3bafc0e3c1e', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 43, 'created': '2016-02-26 17:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55f03d6c4ba1e07231758201d1e15024a293fa5f', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 44, 'created': '2016-02-29 22:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a6ef1ccd9b789a271e6e604a4ff68e12811887f8', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 45, 'created': '2016-03-02 13:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a6cff8fed3c80a4af32fca8cb468b4dec05669df', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 46, 'created': '2016-03-03 22:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f1d436b8581e2d21db65416a47d84a0f1cca0e1d', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 47, 'created': '2016-03-03 22:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/870a8b5061dda12610cc55666c1767f8839ad0ae', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}, {'number': 48, 'created': '2016-03-04 13:35:12.000000000', 'files': ['network/ports/external.yaml', 'network/external_v6.yaml', 'network/endpoints/build_endpoint_map.py', 'network/ports/net_vip_map_external.yaml', 'network/ports/storage.yaml', 'network/ports/ctlplane_vip.yaml', 'network/ports/internal_api.yaml', 'puppet/cinder-storage.yaml', 'network/ports/vip.yaml', 'network/storage_v6.yaml', 'network/endpoints/endpoint_map.yaml', 'network/ports/management_v6.yaml', 'network/tenant_v6.yaml', 'network/ports/external_v6.yaml', 'network/ports/tenant_from_pool.yaml', 'puppet/controller.yaml', 'network/ports/internal_api_from_pool.yaml', 'network/ports/net_ip_map.yaml', 'network/ports/storage_v6.yaml', 'overcloud.yaml', 'puppet/compute.yaml', 'network/ports/tenant.yaml', 'network/ports/management.yaml', 'environments/network-isolation-v6.yaml', 'network/ports/management_from_pool.yaml', 'network/ports/noop.yaml', 'network/ports/tenant_v6.yaml', 'network/ports/storage_mgmt_v6.yaml', 'network/ports/vip_v6.yaml', 'network/ports/storage_from_pool.yaml', 'network/storage_mgmt_v6.yaml', 'network/ports/external_from_pool.yaml', 'network/ports/from_service.yaml', 'network/ports/storage_mgmt.yaml', 'network/ports/internal_api_v6.yaml', 'puppet/swift-storage.yaml', 'network/internal_api_v6.yaml', 'network/ports/storage_mgmt_from_pool.yaml', 'puppet/ceph-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/321e605a0a4c219415a3876a84fa063410380cac', 'message': 'Add IPv6 Support to Isolated Networks\n\nThis change adds a new set of network templates with IPv6 subnets\nthat can be used instead of the existing IPv4 networks. Each network\ncan use either the IPv4 or IPv6 template, and the Neutron subnet will\nbe created with the specified IP version.\n\nThe default addresses used for the IPv6 networks use the fd00::/8\nprefix for the internal isolated networks (this range is reserved\nfor private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64\nis used as an example default for the External network\n(2001:db8::/32 are the documentation addresses [RFC3849]), but this\nwould ordinarily be a globally addressable subnet. These\nparameters may be overridden in an environment file.\n\nThis change will require updates to the OpenStack Puppet\nModules to support IPv6 addresses in some of the hieradata values.\nMany of the OPM modules already have IPv6 support to support IPv6\ndeployments in Packstack, but some OPM packages that apply only to\nInstack/TripleO deployments need to be updated.\n\nIPv6 addresses used in URLs need to be surrounded by brackets in\norder to differentiate IP address from port number. This change\nadds a new output to the network/ports resources for\nip_address_uri, which is an IP address with brackets in the case\nof IPv6, and a raw IP address without brackets for IPv4 ports.\nThis change also updates some URLs which are constructed in Heat.\n\nThis has been tested and problems were found with Puppet not\naccepting IPv6 addresses. This is addressed in the latest Puppet.\nAdditional changes were required to make this work with Ceph.\n\nIPv6 tunnel endpoints with Open vSwitch are not yet supported\n(although support is coming soon), so this review leaves the\nTenant network as an isolated IPv4 network for the time being.\n\nChange-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2\n'}]",40,235423,321e605a0a4c219415a3876a84fa063410380cac,206,9,48,12398,,,0,"Add IPv6 Support to Isolated Networks

This change adds a new set of network templates with IPv6 subnets
that can be used instead of the existing IPv4 networks. Each network
can use either the IPv4 or IPv6 template, and the Neutron subnet will
be created with the specified IP version.

The default addresses used for the IPv6 networks use the fd00::/8
prefix for the internal isolated networks (this range is reserved
for private use similar to 10.0.0.0/8), and 2001:db8:fd00:1000::/64
is used as an example default for the External network
(2001:db8::/32 are the documentation addresses [RFC3849]), but this
would ordinarily be a globally addressable subnet. These
parameters may be overridden in an environment file.

This change will require updates to the OpenStack Puppet
Modules to support IPv6 addresses in some of the hieradata values.
Many of the OPM modules already have IPv6 support to support IPv6
deployments in Packstack, but some OPM packages that apply only to
Instack/TripleO deployments need to be updated.

IPv6 addresses used in URLs need to be surrounded by brackets in
order to differentiate IP address from port number. This change
adds a new output to the network/ports resources for
ip_address_uri, which is an IP address with brackets in the case
of IPv6, and a raw IP address without brackets for IPv4 ports.
This change also updates some URLs which are constructed in Heat.

This has been tested and problems were found with Puppet not
accepting IPv6 addresses. This is addressed in the latest Puppet.
Additional changes were required to make this work with Ceph.

IPv6 tunnel endpoints with Open vSwitch are not yet supported
(although support is coming soon), so this review leaves the
Tenant network as an isolated IPv4 network for the time being.

Change-Id: Ie7a742bdf1db533edda2998a53d28528f80ef8e2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/23/235423/5 && git format-patch -1 --stdout FETCH_HEAD,"['network/tenant_v6.yaml', 'network/external_v6.yaml', 'network/internal_api_v6.yaml', 'network/storage_mgmt_v6.yaml', 'environments/network-isolation-v6.yaml', 'network/storage_v6.yaml']",6,7b6767c93aa39e800341566111b03b57cbf5fa39,ipv6,"heat_template_version: 2015-04-30 description: > Storage network. parameters: # the defaults here work for static IP assignment (IPAM) only StorageNetCidr: default: 'fd00:fd00:fd00:3000::/56' description: Cidr for the storage network. type: string StorageNetValueSpecs: default: {'provider:physical_network': 'storage', 'provider:network_type': 'flat'} description: Value specs for the storage network. type: json StorageNetAdminStateUp: default: false description: This admin state of of the network. type: boolean StorageNetShared: default: false description: Whether this network is shared across all tenants. type: boolean StorageNetName: default: storage description: The name of the storage network. type: string StorageSubnetName: default: storage_subnet description: The name of the storage subnet in Neutron. type: string StorageAllocationPools: default: [{'start': 'fd00:fd00:fd00:3000:0000:0000:0000:0000', 'end': 'fd00:fd00:fd00:30ff:ffff:ffff:ffff:ffff'}] description: Ip allocation pool range for the storage network. type: json resources: StorageNetwork: type: OS::Neutron::Net properties: admin_state_up: {get_param: StorageNetAdminStateUp} name: {get_param: StorageNetName} shared: {get_param: StorageNetShared} value_specs: {get_param: StorageNetValueSpecs} StorageSubnet: type: OS::Neutron::Subnet properties: ip_version: 6 ipv6_address_mode: slaac ipv6_ra_mode: slaac cidr: {get_param: StorageNetCidr} name: {get_param: StorageSubnetName} network: {get_resource: StorageNetwork} allocation_pools: {get_param: StorageAllocationPools} outputs: OS::stack_id: description: Neutron storage network value: {get_resource: StorageNetwork} ",,338,0
openstack%2Fopenstack-ansible-os_heat~master~Ia6bc15d704329d380d38bebbf1e11cf9ae04c944,openstack/openstack-ansible-os_heat,master,Ia6bc15d704329d380d38bebbf1e11cf9ae04c944,Role should default to no external SSL termination,MERGED,2016-03-04 22:26:11.000000000,2016-03-05 02:09:39.000000000,2016-03-05 02:09:39.000000000,"[{'_account_id': 3}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-04 22:26:11.000000000', 'files': ['templates/heat.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/b7fffe923e4b26eb3d9452ce2d1e5f0b89b0686a', 'message': 'Role should default to no external SSL termination\n\nAlso, variable naming should match what is in\nId87fab39c929e0860abbc3755ad386aa6893b151\n\nChange-Id: Ia6bc15d704329d380d38bebbf1e11cf9ae04c944\n'}]",0,288769,b7fffe923e4b26eb3d9452ce2d1e5f0b89b0686a,7,2,1,19814,,,0,"Role should default to no external SSL termination

Also, variable naming should match what is in
Id87fab39c929e0860abbc3755ad386aa6893b151

Change-Id: Ia6bc15d704329d380d38bebbf1e11cf9ae04c944
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/69/288769/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/heat.conf.j2', 'defaults/main.yml']",2,b7fffe923e4b26eb3d9452ce2d1e5f0b89b0686a,external_ssl, # Set to true when terminating SSL/TLS at a load balancer heat_external_ssl: false ,heat_ssl_external: true,5,2
openstack%2Fopenstack-ansible-os_keystone~master~I076d20edd45a7b35e9db52e1fb65005971c06348,openstack/openstack-ansible-os_keystone,master,I076d20edd45a7b35e9db52e1fb65005971c06348,Role should default to no external SSL termination,MERGED,2016-03-04 21:48:57.000000000,2016-03-05 02:08:59.000000000,2016-03-05 02:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 21:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3afdb2d7ac35d7c34079e6c40f7e60dbdde83e35', 'message': 'Role should default to no external SSL termination\n\nChange-Id: I076d20edd45a7b35e9db52e1fb65005971c06348\n'}, {'number': 2, 'created': '2016-03-04 23:08:40.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/1c4e8aa7bbe27d238828ec6c9881b0ac13618896', 'message': 'Role should default to no external SSL termination\n\nThis decouples the role more completely from the AIO\nbuild default configuration in\nId87fab39c929e0860abbc3755ad386aa6893b151\nwhich enables SSL termination at the HAProxy LB.\n\nChange-Id: I076d20edd45a7b35e9db52e1fb65005971c06348\n'}]",2,288757,1c4e8aa7bbe27d238828ec6c9881b0ac13618896,10,4,2,19814,,,0,"Role should default to no external SSL termination

This decouples the role more completely from the AIO
build default configuration in
Id87fab39c929e0860abbc3755ad386aa6893b151
which enables SSL termination at the HAProxy LB.

Change-Id: I076d20edd45a7b35e9db52e1fb65005971c06348
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/57/288757/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,3afdb2d7ac35d7c34079e6c40f7e60dbdde83e35,default_no_ssl_termination,"keystone_service_proto: http keystone_service_publicuri_proto: ""{{ openstack_service_publicuri_proto | default(keystone_service_proto) }}"" keystone_service_adminuri_proto: ""{{ openstack_service_adminuri_proto | default(keystone_service_proto) }}"" keystone_service_internaluri_proto: ""{{ openstack_service_internaluri_proto | default(keystone_service_proto) }}"" keystone_service_internaluri_insecure: false keystone_service_adminuri_insecure: false # Set to true when terminating SSL/TLS at a load balancer keystone_external_ssl: false ","keystone_service_proto: http keystone_service_publicuri_proto: ""{{ openstack_service_publicuri_proto | default(keystone_service_proto) }}"" keystone_service_adminuri_proto: ""{{ openstack_service_adminuri_proto | default(keystone_service_proto) }}"" keystone_service_internaluri_proto: ""{{ openstack_service_internaluri_proto | default(keystone_service_proto) }}""keystone_service_internaluri_insecure: false keystone_service_adminuri_insecure: falsekeystone_ssl_external: true",12,7
openstack%2Fopenstack-ansible-os_nova~master~Iadf64979d01d15f459b8fcdd92a60b207745c006,openstack/openstack-ansible-os_nova,master,Iadf64979d01d15f459b8fcdd92a60b207745c006,Role should default to no external SSL termination,MERGED,2016-03-04 22:28:57.000000000,2016-03-05 02:08:33.000000000,2016-03-05 02:08:33.000000000,"[{'_account_id': 3}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-03-04 22:28:57.000000000', 'files': ['templates/nova.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/efbb8c288fcd8148283a28df445dad56bbf1fa1f', 'message': 'Role should default to no external SSL termination\n\nAlso, variable naming should match what is in\nId87fab39c929e0860abbc3755ad386aa6893b151\n\nChange-Id: Iadf64979d01d15f459b8fcdd92a60b207745c006\n'}]",0,288773,efbb8c288fcd8148283a28df445dad56bbf1fa1f,7,2,1,19814,,,0,"Role should default to no external SSL termination

Also, variable naming should match what is in
Id87fab39c929e0860abbc3755ad386aa6893b151

Change-Id: Iadf64979d01d15f459b8fcdd92a60b207745c006
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/73/288773/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/nova.conf.j2', 'defaults/main.yml']",2,efbb8c288fcd8148283a28df445dad56bbf1fa1f,external_ssl,# Set to true when terminating SSL/TLS at a load balancer nova_external_ssl: false ,nova_ssl_external: true,4,2
openstack%2Fopenstack-ansible-plugins~master~I684a1eab52282725f08f842a3446cc920695b2b8,openstack/openstack-ansible-plugins,master,I684a1eab52282725f08f842a3446cc920695b2b8,Add curl to bindep requirements,MERGED,2016-03-04 19:24:22.000000000,2016-03-05 02:06:59.000000000,2016-03-05 02:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:24:22.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/7fb1c5dd065762d59bc444ed4d935f52c6162f42', 'message': 'Add curl to bindep requirements\n\nChange-Id: I684a1eab52282725f08f842a3446cc920695b2b8\n'}]",0,288684,7fb1c5dd065762d59bc444ed4d935f52c6162f42,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I684a1eab52282725f08f842a3446cc920695b2b8
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/84/288684/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,7fb1c5dd065762d59bc444ed4d935f52c6162f42,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-pip_lock_down~master~Ifba1d18006e2ce48bde0f0491b2663d82bc0b7bf,openstack/openstack-ansible-pip_lock_down,master,Ifba1d18006e2ce48bde0f0491b2663d82bc0b7bf,Add curl to bindep requirements,MERGED,2016-03-04 19:24:12.000000000,2016-03-05 02:06:53.000000000,2016-03-05 02:06:53.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:24:12.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/90fcc0b74d9fd4055d8cbe3817d8e21ea1c9991d', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ifba1d18006e2ce48bde0f0491b2663d82bc0b7bf\n'}]",0,288683,90fcc0b74d9fd4055d8cbe3817d8e21ea1c9991d,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ifba1d18006e2ce48bde0f0491b2663d82bc0b7bf
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_lock_down refs/changes/83/288683/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,90fcc0b74d9fd4055d8cbe3817d8e21ea1c9991d,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-pip_install~master~I3a55cb69b27999bb90db7b3d0e559b154a1c35ff,openstack/openstack-ansible-pip_install,master,I3a55cb69b27999bb90db7b3d0e559b154a1c35ff,Add curl to bindep requirements,MERGED,2016-03-04 19:24:02.000000000,2016-03-05 02:06:48.000000000,2016-03-05 02:06:48.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:24:02.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/cc8de86570af169199892f4b3ae40db0e89186c3', 'message': 'Add curl to bindep requirements\n\nChange-Id: I3a55cb69b27999bb90db7b3d0e559b154a1c35ff\n'}]",0,288682,cc8de86570af169199892f4b3ae40db0e89186c3,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I3a55cb69b27999bb90db7b3d0e559b154a1c35ff
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/82/288682/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,cc8de86570af169199892f4b3ae40db0e89186c3,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fapi-site~master~Ibc7ee4650d087ec25f6a26c76bbb83b7d8dbf1cf,openstack/api-site,master,Ibc7ee4650d087ec25f6a26c76bbb83b7d8dbf1cf,"Missing ""share_server_id"" parameter in Response Parameters table.",MERGED,2016-02-26 10:36:46.000000000,2016-03-05 02:06:41.000000000,2016-03-05 02:06:41.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-26 10:36:46.000000000', 'files': ['api-ref/src/wadls/share-api/src/v2/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/61485f087683feaf33d58476737fab65c7356da0', 'message': 'Missing ""share_server_id"" parameter in Response Parameters table.\n\nThis patch fixes missing ""share_server_id"" parameter in Response\nParameters table when listing and showing the share instances using\nShared File Systems API v2.\n\nChange-Id: Ibc7ee4650d087ec25f6a26c76bbb83b7d8dbf1cf\nCloses-Bug: #1548196\n'}]",0,285206,61485f087683feaf33d58476737fab65c7356da0,7,3,1,17958,,,0,"Missing ""share_server_id"" parameter in Response Parameters table.

This patch fixes missing ""share_server_id"" parameter in Response
Parameters table when listing and showing the share instances using
Shared File Systems API v2.

Change-Id: Ibc7ee4650d087ec25f6a26c76bbb83b7d8dbf1cf
Closes-Bug: #1548196
",git fetch https://review.opendev.org/openstack/api-site refs/changes/06/285206/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/share-api/src/v2/common.ent'],1,61485f087683feaf33d58476737fab65c7356da0,bug/1548196,"<param xmlns=""http://wadl.dev.java.net/2009/02"" name=""share_server_id"" style=""plain"" required=""true"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the share server. </para> </wadl:doc> </param>",,11,1
openstack%2Fopenstack-ansible-repo_build~master~I6240716c44c57e54a5a3a8b8f81f12fb56a9e374,openstack/openstack-ansible-repo_build,master,I6240716c44c57e54a5a3a8b8f81f12fb56a9e374,Add curl to bindep requirements,MERGED,2016-03-04 19:24:51.000000000,2016-03-05 02:05:58.000000000,2016-03-05 02:05:58.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:24:51.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/2f9b6829d10af29ac8108c63da6e6c74bb53b73a', 'message': 'Add curl to bindep requirements\n\nChange-Id: I6240716c44c57e54a5a3a8b8f81f12fb56a9e374\n'}]",0,288687,2f9b6829d10af29ac8108c63da6e6c74bb53b73a,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I6240716c44c57e54a5a3a8b8f81f12fb56a9e374
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/87/288687/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,2f9b6829d10af29ac8108c63da6e6c74bb53b73a,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-rsyslog_server~master~Ibf7e68db9490cb7eb356944dcd478381e8dad335,openstack/openstack-ansible-rsyslog_server,master,Ibf7e68db9490cb7eb356944dcd478381e8dad335,Add curl to bindep requirements,MERGED,2016-03-04 19:25:22.000000000,2016-03-05 02:05:43.000000000,2016-03-05 02:05:43.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:25:22.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/e32374bd59f9b98d7bc2216b88c56b619517bae9', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ibf7e68db9490cb7eb356944dcd478381e8dad335\n'}]",0,288690,e32374bd59f9b98d7bc2216b88c56b619517bae9,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ibf7e68db9490cb7eb356944dcd478381e8dad335
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/90/288690/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,e32374bd59f9b98d7bc2216b88c56b619517bae9,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-specs~master~I5be06a9b15a2daa4e99cd6ed3867ef4f5578903d,openstack/openstack-ansible-specs,master,I5be06a9b15a2daa4e99cd6ed3867ef4f5578903d,Add curl to bindep requirements,MERGED,2016-03-04 19:25:43.000000000,2016-03-05 02:03:59.000000000,2016-03-05 02:03:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:25:43.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-specs/commit/c0b9072ea8ffd8a4530bcf32f1de63ff2e8b16ae', 'message': 'Add curl to bindep requirements\n\nChange-Id: I5be06a9b15a2daa4e99cd6ed3867ef4f5578903d\n'}]",0,288692,c0b9072ea8ffd8a4530bcf32f1de63ff2e8b16ae,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I5be06a9b15a2daa4e99cd6ed3867ef4f5578903d
",git fetch https://review.opendev.org/openstack/openstack-ansible-specs refs/changes/92/288692/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,c0b9072ea8ffd8a4530bcf32f1de63ff2e8b16ae,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl ",,16,0
openstack%2Fopenstack-ansible-os_nova~master~I8e3a91be0e4031a2716b27b053dc4427767f8631,openstack/openstack-ansible-os_nova,master,I8e3a91be0e4031a2716b27b053dc4427767f8631,Add curl to bindep requirements,MERGED,2016-03-04 19:23:24.000000000,2016-03-05 02:02:05.000000000,2016-03-05 02:02:05.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:23:24.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/39cb3bea8e3ea33ba052a6e1f097d603506cebe9', 'message': 'Add curl to bindep requirements\n\nChange-Id: I8e3a91be0e4031a2716b27b053dc4427767f8631\n'}]",0,288678,39cb3bea8e3ea33ba052a6e1f097d603506cebe9,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I8e3a91be0e4031a2716b27b053dc4427767f8631
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/78/288678/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,39cb3bea8e3ea33ba052a6e1f097d603506cebe9,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_tempest~master~I69641c9f96a87128efaf873a225ac1c05f7eeccb,openstack/openstack-ansible-os_tempest,master,I69641c9f96a87128efaf873a225ac1c05f7eeccb,Add curl to bindep requirements,MERGED,2016-03-04 19:23:52.000000000,2016-03-05 02:00:59.000000000,2016-03-05 02:00:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:23:52.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/4f522e69e948d3918c89af3d492498ea28345c65', 'message': 'Add curl to bindep requirements\n\nChange-Id: I69641c9f96a87128efaf873a225ac1c05f7eeccb\n'}]",0,288681,4f522e69e948d3918c89af3d492498ea28345c65,8,4,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I69641c9f96a87128efaf873a225ac1c05f7eeccb
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/81/288681/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,4f522e69e948d3918c89af3d492498ea28345c65,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Freleases~master~I84b65302faee76199a286570c5c6f3c774546403,openstack/releases,master,I84b65302faee76199a286570c5c6f3c774546403,Release ironic-ui 1.0.0,MERGED,2016-03-05 01:32:04.000000000,2016-03-05 01:50:38.000000000,2016-03-05 01:50:38.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11680}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-05 01:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/ca7985ad2145f5150adbaae6b09a286b42d8e7a1', 'message': 'Release ironic-ui 1.0.0\n\nFirst release of the Ironic UI plugin for Horizon. View bare metal\nnodes and node details. Apply maintenance and power actions to\nindividual nodes.\n\nChange-Id: I84b65302faee76199a286570c5c6f3c774546403\n'}, {'number': 2, 'created': '2016-03-05 01:42:17.000000000', 'files': ['deliverables/mitaka/ironic-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3f8187fbc500400f505614ae33aa4f506a6f0e7b', 'message': 'Release ironic-ui 1.0.0\n\nFirst release of the Ironic UI plugin for Horizon. View bare metal\nnodes and node details. Apply maintenance and power actions to\nindividual nodes.\n\nChange-Id: I84b65302faee76199a286570c5c6f3c774546403\n'}]",0,288823,3f8187fbc500400f505614ae33aa4f506a6f0e7b,10,4,2,16628,,,0,"Release ironic-ui 1.0.0

First release of the Ironic UI plugin for Horizon. View bare metal
nodes and node details. Apply maintenance and power actions to
individual nodes.

Change-Id: I84b65302faee76199a286570c5c6f3c774546403
",git fetch https://review.opendev.org/openstack/releases refs/changes/23/288823/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/ironic-ui.yaml'],1,ca7985ad2145f5150adbaae6b09a286b42d8e7a1,ironic-ui-1.0.0,send-announcements-to: openstack-announce@lists.openstack.org - version: 1.0.0 hash: 57837a3fd30ca19d344cbd80bd29ea04a5c30943 highlights: > First release of the Ironic UI plugin for Horizon. View bare metal nodes and node details. Apply maintenance and power actions to individual nodes.,send-announcements-to: jim@jimrollenhagen.com - version: 0.0.1 hash: 5f6ea0c900e98436c1fae9de4b04b7c74db6f82c,7,3
openstack%2Fsenlin-dashboard~master~I29a12891dc83c2def91a525ce71c57f7ba31b1e3,openstack/senlin-dashboard,master,I29a12891dc83c2def91a525ce71c57f7ba31b1e3,Updated from global requirements,MERGED,2016-03-04 10:21:54.000000000,2016-03-05 01:32:30.000000000,2016-03-05 01:32:30.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 10:21:54.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/0d68919987017378971a0e54a93468b4e408542e', 'message': 'Updated from global requirements\n\nChange-Id: I29a12891dc83c2def91a525ce71c57f7ba31b1e3\n'}]",0,288364,0d68919987017378971a0e54a93468b4e408542e,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I29a12891dc83c2def91a525ce71c57f7ba31b1e3
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/64/288364/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0d68919987017378971a0e54a93468b4e408542e,openstack/requirements,python-senlinclient>=0.3.0 # Apache-2.0,python-senlinclient>=0.1.7 # Apache-2.0,1,1
openstack%2Fneutron-lib~master~Ibdcf8ddc2ad832e031e3212392ad30364ceb3538,openstack/neutron-lib,master,Ibdcf8ddc2ad832e031e3212392ad30364ceb3538,Fix 'import neutron' hacking check,MERGED,2016-03-02 07:28:16.000000000,2016-03-05 01:28:41.000000000,2016-03-05 01:28:41.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-03-02 07:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/f0f448cc78de6efd18a78e097d1d7c555c09fc02', 'message': ""Fix 'import neutron' hacking check\n\nTurns out that the *name* of the first argument to your check function\nmatters, and must be 'logical_line' in this case. And fix the prefix\nused in the error string.\n\nOutput now looks like:\nneutron_lbaas/extensions/loadbalancerv2.py:24:1: N530  'from neutron_lib.api.v2 import attributes as attr' must be used instead of 'from neutron.api.v2 import attributes as attr'.\nfrom neutron.api.v2 import attributes as attr\n\nChange-Id: Ibdcf8ddc2ad832e031e3212392ad30364ceb3538\n""}, {'number': 2, 'created': '2016-03-04 21:29:26.000000000', 'files': ['neutron_lib/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/4b17f1da1a5f65f0c4db395034ed732174a19315', 'message': ""Fix 'import neutron' hacking check\n\nTurns out that the *name* of the first argument to your check function\nmatters, and must be 'logical_line' in this case. And fix the prefix\nused in the error string.\n\nOutput now looks like:\nneutron_lbaas/tests/base.py:19:1: N530  direct neutron imports not allowed\nfrom neutron.db import servicetype_db as st_db\n\nChange-Id: Ibdcf8ddc2ad832e031e3212392ad30364ceb3538\n""}]",1,287021,4b17f1da1a5f65f0c4db395034ed732174a19315,15,5,2,10980,,,0,"Fix 'import neutron' hacking check

Turns out that the *name* of the first argument to your check function
matters, and must be 'logical_line' in this case. And fix the prefix
used in the error string.

Output now looks like:
neutron_lbaas/tests/base.py:19:1: N530  direct neutron imports not allowed
from neutron.db import servicetype_db as st_db

Change-Id: Ibdcf8ddc2ad832e031e3212392ad30364ceb3538
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/21/287021/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/hacking/checks.py'],1,f0f448cc78de6efd18a78e097d1d7c555c09fc02,fix-hacking,"def check_neutron_namespace_imports(logical_line): x = _check_namespace_imports( 'N530', 'neutron', 'neutron_lib.', logical_line)","def check_neutron_namespace_imports(line): x = _check_namespace_imports('N530', 'neutron', 'neutron_lib', line)",3,2
openstack%2Fproject-config~master~I74e29ce8bda62d8f1077fabbe4ca59f9a6895549,openstack/project-config,master,I74e29ce8bda62d8f1077fabbe4ca59f9a6895549,Add zlib1g-dev to bindep-fallback.txt,MERGED,2016-03-05 00:03:33.000000000,2016-03-05 01:28:32.000000000,2016-03-05 01:28:32.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}]","[{'number': 1, 'created': '2016-03-05 00:03:33.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/123a08574af224cb10834ae8be296561dd87b089', 'message': 'Add zlib1g-dev to bindep-fallback.txt\n\nChange-Id: I74e29ce8bda62d8f1077fabbe4ca59f9a6895549\n'}]",0,288805,123a08574af224cb10834ae8be296561dd87b089,8,4,1,5263,,,0,"Add zlib1g-dev to bindep-fallback.txt

Change-Id: I74e29ce8bda62d8f1077fabbe4ca59f9a6895549
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/288805/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,123a08574af224cb10834ae8be296561dd87b089,bindep,zlib-devel [platform:rpm] zlib1g-dev [platform:dpkg],,2,0
openstack%2Fkeystone~master~I88b9d3976ab1e35e32a493f07c8f5be1ece7f531,openstack/keystone,master,I88b9d3976ab1e35e32a493f07c8f5be1ece7f531,Split trust backend tests,MERGED,2016-01-18 14:41:43.000000000,2016-03-05 01:27:04.000000000,2016-03-05 01:27:03.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 17026}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-18 14:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b757c0098dd5df8f736fa7a61387736bcb087ba', 'message': 'Extract trust backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract trust-related tests to its directory\nunder unit/backend/trust.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n'}, {'number': 2, 'created': '2016-01-18 14:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/971139d0ae0724ccb2468c3f4605b8a3576658b5', 'message': 'Extract trust backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract trust-related tests to its directory\nunder unit/backend/trust.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n'}, {'number': 3, 'created': '2016-01-18 21:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5fa4243be006e8ed5f95d46d6b0e07f1b481c527', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 4, 'created': '2016-01-27 13:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac904038016076cccd975fe7b33a51080c782da8', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 5, 'created': '2016-01-27 16:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c8ee7b88235f85a27e707ea4844c5a23eec2c872', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 6, 'created': '2016-01-28 13:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2f6ca1cd2e168589a83bd7ea5106fc2fb6b4feec', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 7, 'created': '2016-01-28 21:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/de1b852a691415f3c0218886212b51ed61364793', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 8, 'created': '2016-03-04 17:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d3627f60812704c8f85fb69b1449bd106ec8160', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 9, 'created': '2016-03-04 18:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cabcc17c49f8753a1258356c90fc6a58353bd917', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 10, 'created': '2016-03-04 18:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/99fbef5b7cae8a0b364a81de6bf9731c81885d95', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}, {'number': 11, 'created': '2016-03-04 18:32:08.000000000', 'files': ['keystone/tests/unit/trust/test_backends.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/trust/__init__.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f7a9113b693cdf8605c2ebfe38e5015ae8a6e8e', 'message': ""Split trust backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the trust backend.\n\nChange-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531\n""}]",0,269115,6f7a9113b693cdf8605c2ebfe38e5015ae8a6e8e,29,5,11,17860,,,0,"Split trust backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the trust backend.

Change-Id: I88b9d3976ab1e35e32a493f07c8f5be1ece7f531
",git fetch https://review.opendev.org/openstack/keystone refs/changes/15/269115/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py']",2,3b757c0098dd5df8f736fa7a61387736bcb087ba,split-backend-tests,,"import datetimefrom oslo_utils import timeutilsclass TrustTests(object): def create_sample_trust(self, new_id, remaining_uses=None): self.trustor = self.user_foo self.trustee = self.user_two expires_at = datetime.datetime.utcnow().replace(year=2031) trust_data = (self.trust_api.create_trust (new_id, {'trustor_user_id': self.trustor['id'], 'trustee_user_id': self.user_two['id'], 'project_id': self.tenant_bar['id'], 'expires_at': expires_at, 'impersonation': True, 'remaining_uses': remaining_uses}, roles=[{""id"": ""member""}, {""id"": ""other""}, {""id"": ""browser""}])) return trust_data def test_delete_trust(self): new_id = uuid.uuid4().hex trust_data = self.create_sample_trust(new_id) trust_id = trust_data['id'] self.assertIsNotNone(trust_data) trust_data = self.trust_api.get_trust(trust_id) self.assertEqual(new_id, trust_data['id']) self.trust_api.delete_trust(trust_id) self.assertRaises(exception.TrustNotFound, self.trust_api.get_trust, trust_id) def test_delete_trust_not_found(self): trust_id = uuid.uuid4().hex self.assertRaises(exception.TrustNotFound, self.trust_api.delete_trust, trust_id) def test_get_trust(self): new_id = uuid.uuid4().hex trust_data = self.create_sample_trust(new_id) trust_id = trust_data['id'] self.assertIsNotNone(trust_data) trust_data = self.trust_api.get_trust(trust_id) self.assertEqual(new_id, trust_data['id']) self.trust_api.delete_trust(trust_data['id']) def test_get_deleted_trust(self): new_id = uuid.uuid4().hex trust_data = self.create_sample_trust(new_id) self.assertIsNotNone(trust_data) self.assertIsNone(trust_data['deleted_at']) self.trust_api.delete_trust(new_id) self.assertRaises(exception.TrustNotFound, self.trust_api.get_trust, new_id) deleted_trust = self.trust_api.get_trust(trust_data['id'], deleted=True) self.assertEqual(trust_data['id'], deleted_trust['id']) self.assertIsNotNone(deleted_trust.get('deleted_at')) def test_create_trust(self): new_id = uuid.uuid4().hex trust_data = self.create_sample_trust(new_id) self.assertEqual(new_id, trust_data['id']) self.assertEqual(self.trustee['id'], trust_data['trustee_user_id']) self.assertEqual(self.trustor['id'], trust_data['trustor_user_id']) self.assertTrue(timeutils.normalize_time(trust_data['expires_at']) > timeutils.utcnow()) self.assertEqual([{'id': 'member'}, {'id': 'other'}, {'id': 'browser'}], trust_data['roles']) def test_list_trust_by_trustee(self): for i in range(3): self.create_sample_trust(uuid.uuid4().hex) trusts = self.trust_api.list_trusts_for_trustee(self.trustee['id']) self.assertEqual(3, len(trusts)) self.assertEqual(trusts[0][""trustee_user_id""], self.trustee['id']) trusts = self.trust_api.list_trusts_for_trustee(self.trustor['id']) self.assertEqual(0, len(trusts)) def test_list_trust_by_trustor(self): for i in range(3): self.create_sample_trust(uuid.uuid4().hex) trusts = self.trust_api.list_trusts_for_trustor(self.trustor['id']) self.assertEqual(3, len(trusts)) self.assertEqual(trusts[0][""trustor_user_id""], self.trustor['id']) trusts = self.trust_api.list_trusts_for_trustor(self.trustee['id']) self.assertEqual(0, len(trusts)) def test_list_trusts(self): for i in range(3): self.create_sample_trust(uuid.uuid4().hex) trusts = self.trust_api.list_trusts() self.assertEqual(3, len(trusts)) def test_trust_has_remaining_uses_positive(self): # create a trust with limited uses, check that we have uses left trust_data = self.create_sample_trust(uuid.uuid4().hex, remaining_uses=5) self.assertEqual(5, trust_data['remaining_uses']) # create a trust with unlimited uses, check that we have uses left trust_data = self.create_sample_trust(uuid.uuid4().hex) self.assertIsNone(trust_data['remaining_uses']) def test_trust_has_remaining_uses_negative(self): # try to create a trust with no remaining uses, check that it fails self.assertRaises(exception.ValidationError, self.create_sample_trust, uuid.uuid4().hex, remaining_uses=0) # try to create a trust with negative remaining uses, # check that it fails self.assertRaises(exception.ValidationError, self.create_sample_trust, uuid.uuid4().hex, remaining_uses=-12) def test_consume_use(self): # consume a trust repeatedly until it has no uses anymore trust_data = self.create_sample_trust(uuid.uuid4().hex, remaining_uses=2) self.trust_api.consume_use(trust_data['id']) t = self.trust_api.get_trust(trust_data['id']) self.assertEqual(1, t['remaining_uses']) self.trust_api.consume_use(trust_data['id']) # This was the last use, the trust isn't available anymore self.assertRaises(exception.TrustNotFound, self.trust_api.get_trust, trust_data['id']) def test_duplicate_trusts_not_allowed(self): self.trustor = self.user_foo self.trustee = self.user_two trust_data = {'trustor_user_id': self.trustor['id'], 'trustee_user_id': self.user_two['id'], 'project_id': self.tenant_bar['id'], 'expires_at': timeutils.parse_isotime( '2031-02-18T18:10:00Z'), 'impersonation': True, 'remaining_uses': None} roles = [{""id"": ""member""}, {""id"": ""other""}, {""id"": ""browser""}] self.trust_api.create_trust(uuid.uuid4().hex, trust_data, roles) self.assertRaises(exception.Conflict, self.trust_api.create_trust, uuid.uuid4().hex, trust_data, roles) ",2,156
openstack%2Fkeystone~master~If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19,openstack/keystone,master,If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19,Split token backend tests,MERGED,2016-01-18 14:31:59.000000000,2016-03-05 01:26:49.000000000,2016-03-05 01:26:49.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 17026}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-18 14:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/147e10c1602fff6d6cec5ddaaa0f7492446e3d65', 'message': 'Extract token backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract token-related tests to its directory\nunder unit/backend/token.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n'}, {'number': 2, 'created': '2016-01-18 21:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e826561ba70cd457809bfe77131635a4c02d7a00', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 3, 'created': '2016-01-27 13:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b7856fbbe1e41fedda72fccc204126ee20fffd1b', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 4, 'created': '2016-01-27 16:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/56dd29eb5e5b80d3ce94923229714e62f2da2a5e', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 5, 'created': '2016-01-28 13:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d64e6576f53a0a92dc66db927d8e15f886cab5d8', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 6, 'created': '2016-01-28 21:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e54cf2d7025445891660b0cbdad08a802e6a9146', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 7, 'created': '2016-03-04 17:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3cf2a565d5d3d47c705ac6dc3a9145f05120604a', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 8, 'created': '2016-03-04 18:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/27b8f8527f84e9651a5905110ecb5578f641e0a4', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 9, 'created': '2016-03-04 18:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd08f8a5297a2c043201a3cd31471c5ceecf2b3f', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}, {'number': 10, 'created': '2016-03-04 18:31:35.000000000', 'files': ['keystone/tests/unit/test_backend_kvs.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/token/test_backends.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2a7db0e31680002fb94ddef23d1986699086d858', 'message': ""Split token backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the token backend.\n\nChange-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19\n""}]",0,269111,2a7db0e31680002fb94ddef23d1986699086d858,28,5,10,17860,,,0,"Split token backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the token backend.

Change-Id: If14b8e7ec0477ca6126e65acf4d7108d6ce7ed19
",git fetch https://review.opendev.org/openstack/keystone refs/changes/11/269111/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/backend/token/__init__.py', 'keystone/tests/unit/backend/token/core.py', 'keystone/tests/unit/test_backend_kvs.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py']",5,147e10c1602fff6d6cec5ddaaa0f7492446e3d65,split-backend-tests,,"import hashlibfrom keystoneclient.common import cmsimport sixfrom keystone.tests.unit import utils as test_utils from keystone.token import providerNULL_OBJECT = object()class TokenTests(object): def _create_token_id(self): # Use a token signed by the cms module token_id = """" for i in range(1, 20): token_id += uuid.uuid4().hex return cms.cms_sign_token(token_id, CONF.signing.certfile, CONF.signing.keyfile) def _assert_revoked_token_list_matches_token_persistence( self, revoked_token_id_list): # Assert that the list passed in matches the list returned by the # token persistence service persistence_list = [ x['id'] for x in self.token_provider_api.list_revoked_tokens() ] self.assertEqual(persistence_list, revoked_token_id_list) def test_token_crud(self): token_id = self._create_token_id() data = {'id': token_id, 'a': 'b', 'trust_id': None, 'user': {'id': 'testuserid'}, 'token_data': {'access': {'token': { 'audit_ids': [uuid.uuid4().hex]}}}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) expires = data_ref.pop('expires') data_ref.pop('user_id') self.assertIsInstance(expires, datetime.datetime) data_ref.pop('id') data.pop('id') self.assertDictEqual(data, data_ref) new_data_ref = self.token_provider_api._persistence.get_token(token_id) expires = new_data_ref.pop('expires') self.assertIsInstance(expires, datetime.datetime) new_data_ref.pop('user_id') new_data_ref.pop('id') self.assertEqual(data, new_data_ref) self.token_provider_api._persistence.delete_token(token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api._persistence.get_token, token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api._persistence.delete_token, token_id) def create_token_sample_data(self, token_id=None, tenant_id=None, trust_id=None, user_id=None, expires=None): if token_id is None: token_id = self._create_token_id() if user_id is None: user_id = 'testuserid' # FIXME(morganfainberg): These tokens look nothing like ""Real"" tokens. # This should be fixed when token issuance is cleaned up. data = {'id': token_id, 'a': 'b', 'user': {'id': user_id}, 'access': {'token': {'audit_ids': [uuid.uuid4().hex]}}} if tenant_id is not None: data['tenant'] = {'id': tenant_id, 'name': tenant_id} if tenant_id is NULL_OBJECT: data['tenant'] = None if expires is not None: data['expires'] = expires if trust_id is not None: data['trust_id'] = trust_id data['access'].setdefault('trust', {}) # Testuserid2 is used here since a trustee will be different in # the cases of impersonation and therefore should not match the # token's user_id. data['access']['trust']['trustee_user_id'] = 'testuserid2' data['token_version'] = provider.V2 # Issue token stores a copy of all token data at token['token_data']. # This emulates that assumption as part of the test. data['token_data'] = copy.deepcopy(data) new_token = self.token_provider_api._persistence.create_token(token_id, data) return new_token['id'], data def test_delete_tokens(self): tokens = self.token_provider_api._persistence._list_tokens( 'testuserid') self.assertEqual(0, len(tokens)) token_id1, data = self.create_token_sample_data( tenant_id='testtenantid') token_id2, data = self.create_token_sample_data( tenant_id='testtenantid') token_id3, data = self.create_token_sample_data( tenant_id='testtenantid', user_id='testuserid1') tokens = self.token_provider_api._persistence._list_tokens( 'testuserid') self.assertEqual(2, len(tokens)) self.assertIn(token_id2, tokens) self.assertIn(token_id1, tokens) self.token_provider_api._persistence.delete_tokens( user_id='testuserid', tenant_id='testtenantid') tokens = self.token_provider_api._persistence._list_tokens( 'testuserid') self.assertEqual(0, len(tokens)) self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, token_id1) self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, token_id2) self.token_provider_api._persistence.get_token(token_id3) def test_delete_tokens_trust(self): tokens = self.token_provider_api._persistence._list_tokens( user_id='testuserid') self.assertEqual(0, len(tokens)) token_id1, data = self.create_token_sample_data( tenant_id='testtenantid', trust_id='testtrustid') token_id2, data = self.create_token_sample_data( tenant_id='testtenantid', user_id='testuserid1', trust_id='testtrustid1') tokens = self.token_provider_api._persistence._list_tokens( 'testuserid') self.assertEqual(1, len(tokens)) self.assertIn(token_id1, tokens) self.token_provider_api._persistence.delete_tokens( user_id='testuserid', tenant_id='testtenantid', trust_id='testtrustid') self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, token_id1) self.token_provider_api._persistence.get_token(token_id2) def _test_token_list(self, token_list_fn): tokens = token_list_fn('testuserid') self.assertEqual(0, len(tokens)) token_id1, data = self.create_token_sample_data() tokens = token_list_fn('testuserid') self.assertEqual(1, len(tokens)) self.assertIn(token_id1, tokens) token_id2, data = self.create_token_sample_data() tokens = token_list_fn('testuserid') self.assertEqual(2, len(tokens)) self.assertIn(token_id2, tokens) self.assertIn(token_id1, tokens) self.token_provider_api._persistence.delete_token(token_id1) tokens = token_list_fn('testuserid') self.assertIn(token_id2, tokens) self.assertNotIn(token_id1, tokens) self.token_provider_api._persistence.delete_token(token_id2) tokens = token_list_fn('testuserid') self.assertNotIn(token_id2, tokens) self.assertNotIn(token_id1, tokens) # tenant-specific tokens tenant1 = uuid.uuid4().hex tenant2 = uuid.uuid4().hex token_id3, data = self.create_token_sample_data(tenant_id=tenant1) token_id4, data = self.create_token_sample_data(tenant_id=tenant2) # test for existing but empty tenant (LP:1078497) token_id5, data = self.create_token_sample_data(tenant_id=NULL_OBJECT) tokens = token_list_fn('testuserid') self.assertEqual(3, len(tokens)) self.assertNotIn(token_id1, tokens) self.assertNotIn(token_id2, tokens) self.assertIn(token_id3, tokens) self.assertIn(token_id4, tokens) self.assertIn(token_id5, tokens) tokens = token_list_fn('testuserid', tenant2) self.assertEqual(1, len(tokens)) self.assertNotIn(token_id1, tokens) self.assertNotIn(token_id2, tokens) self.assertNotIn(token_id3, tokens) self.assertIn(token_id4, tokens) def test_token_list(self): self._test_token_list( self.token_provider_api._persistence._list_tokens) def test_token_list_trust(self): trust_id = uuid.uuid4().hex token_id5, data = self.create_token_sample_data(trust_id=trust_id) tokens = self.token_provider_api._persistence._list_tokens( 'testuserid', trust_id=trust_id) self.assertEqual(1, len(tokens)) self.assertIn(token_id5, tokens) def test_get_token_returns_not_found(self): self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, uuid.uuid4().hex) def test_delete_token_returns_not_found(self): self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.delete_token, uuid.uuid4().hex) def test_expired_token(self): token_id = uuid.uuid4().hex expire_time = timeutils.utcnow() - datetime.timedelta(minutes=1) data = {'id_hash': token_id, 'id': token_id, 'a': 'b', 'expires': expire_time, 'trust_id': None, 'user': {'id': 'testuserid'}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) data_ref.pop('user_id') self.assertDictEqual(data, data_ref) self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, token_id) def test_null_expires_token(self): token_id = uuid.uuid4().hex data = {'id': token_id, 'id_hash': token_id, 'a': 'b', 'expires': None, 'user': {'id': 'testuserid'}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) self.assertIsNotNone(data_ref['expires']) new_data_ref = self.token_provider_api._persistence.get_token(token_id) # MySQL doesn't store microseconds, so discard them before testing data_ref['expires'] = data_ref['expires'].replace(microsecond=0) new_data_ref['expires'] = new_data_ref['expires'].replace( microsecond=0) self.assertEqual(data_ref, new_data_ref) def check_list_revoked_tokens(self, token_infos): revocation_list = self.token_provider_api.list_revoked_tokens() revoked_ids = [x['id'] for x in revocation_list] revoked_audit_ids = [x['audit_id'] for x in revocation_list] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) for token_id, audit_id in token_infos: self.assertIn(token_id, revoked_ids) self.assertIn(audit_id, revoked_audit_ids) def delete_token(self): token_id = uuid.uuid4().hex audit_id = uuid.uuid4().hex data = {'id_hash': token_id, 'id': token_id, 'a': 'b', 'user': {'id': 'testuserid'}, 'token_data': {'token': {'audit_ids': [audit_id]}}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) self.token_provider_api._persistence.delete_token(token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api._persistence.get_token, data_ref['id']) self.assertRaises( exception.TokenNotFound, self.token_provider_api._persistence.delete_token, data_ref['id']) return (token_id, audit_id) def test_list_revoked_tokens_returns_empty_list(self): revoked_ids = [x['id'] for x in self.token_provider_api.list_revoked_tokens()] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) self.assertEqual([], revoked_ids) def test_list_revoked_tokens_for_single_token(self): self.check_list_revoked_tokens([self.delete_token()]) def test_list_revoked_tokens_for_multiple_tokens(self): self.check_list_revoked_tokens([self.delete_token() for x in range(2)]) def test_flush_expired_token(self): token_id = uuid.uuid4().hex expire_time = timeutils.utcnow() - datetime.timedelta(minutes=1) data = {'id_hash': token_id, 'id': token_id, 'a': 'b', 'expires': expire_time, 'trust_id': None, 'user': {'id': 'testuserid'}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) data_ref.pop('user_id') self.assertDictEqual(data, data_ref) token_id = uuid.uuid4().hex expire_time = timeutils.utcnow() + datetime.timedelta(minutes=1) data = {'id_hash': token_id, 'id': token_id, 'a': 'b', 'expires': expire_time, 'trust_id': None, 'user': {'id': 'testuserid'}} data_ref = self.token_provider_api._persistence.create_token(token_id, data) data_ref.pop('user_id') self.assertDictEqual(data, data_ref) self.token_provider_api._persistence.flush_expired_tokens() tokens = self.token_provider_api._persistence._list_tokens( 'testuserid') self.assertEqual(1, len(tokens)) self.assertIn(token_id, tokens) @unit.skip_if_cache_disabled('token') def test_revocation_list_cache(self): expire_time = timeutils.utcnow() + datetime.timedelta(minutes=10) token_id = uuid.uuid4().hex token_data = {'id_hash': token_id, 'id': token_id, 'a': 'b', 'expires': expire_time, 'trust_id': None, 'user': {'id': 'testuserid'}, 'token_data': {'token': { 'audit_ids': [uuid.uuid4().hex]}}} token2_id = uuid.uuid4().hex token2_data = {'id_hash': token2_id, 'id': token2_id, 'a': 'b', 'expires': expire_time, 'trust_id': None, 'user': {'id': 'testuserid'}, 'token_data': {'token': { 'audit_ids': [uuid.uuid4().hex]}}} # Create 2 Tokens. self.token_provider_api._persistence.create_token(token_id, token_data) self.token_provider_api._persistence.create_token(token2_id, token2_data) # Verify the revocation list is empty. self.assertEqual( [], self.token_provider_api._persistence.list_revoked_tokens()) self.assertEqual([], self.token_provider_api.list_revoked_tokens()) # Delete a token directly, bypassing the manager. self.token_provider_api._persistence.driver.delete_token(token_id) # Verify the revocation list is still empty. self.assertEqual( [], self.token_provider_api._persistence.list_revoked_tokens()) self.assertEqual([], self.token_provider_api.list_revoked_tokens()) # Invalidate the revocation list. self.token_provider_api._persistence.invalidate_revocation_list() # Verify the deleted token is in the revocation list. revoked_ids = [x['id'] for x in self.token_provider_api.list_revoked_tokens()] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) self.assertIn(token_id, revoked_ids) # Delete the second token, through the manager self.token_provider_api._persistence.delete_token(token2_id) revoked_ids = [x['id'] for x in self.token_provider_api.list_revoked_tokens()] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) # Verify both tokens are in the revocation list. self.assertIn(token_id, revoked_ids) self.assertIn(token2_id, revoked_ids) def _test_predictable_revoked_pki_token_id(self, hash_fn): token_id = self._create_token_id() token_id_hash = hash_fn(token_id.encode('utf-8')).hexdigest() token = {'user': {'id': uuid.uuid4().hex}, 'token_data': {'token': {'audit_ids': [uuid.uuid4().hex]}}} self.token_provider_api._persistence.create_token(token_id, token) self.token_provider_api._persistence.delete_token(token_id) revoked_ids = [x['id'] for x in self.token_provider_api.list_revoked_tokens()] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) self.assertIn(token_id_hash, revoked_ids) self.assertNotIn(token_id, revoked_ids) for t in self.token_provider_api._persistence.list_revoked_tokens(): self.assertIn('expires', t) def test_predictable_revoked_pki_token_id_default(self): self._test_predictable_revoked_pki_token_id(hashlib.md5) def test_predictable_revoked_pki_token_id_sha256(self): self.config_fixture.config(group='token', hash_algorithm='sha256') self._test_predictable_revoked_pki_token_id(hashlib.sha256) def test_predictable_revoked_uuid_token_id(self): token_id = uuid.uuid4().hex token = {'user': {'id': uuid.uuid4().hex}, 'token_data': {'token': {'audit_ids': [uuid.uuid4().hex]}}} self.token_provider_api._persistence.create_token(token_id, token) self.token_provider_api._persistence.delete_token(token_id) revoked_tokens = self.token_provider_api.list_revoked_tokens() revoked_ids = [x['id'] for x in revoked_tokens] self._assert_revoked_token_list_matches_token_persistence(revoked_ids) self.assertIn(token_id, revoked_ids) for t in revoked_tokens: self.assertIn('expires', t) def test_create_unicode_token_id(self): token_id = six.text_type(self._create_token_id()) self.create_token_sample_data(token_id=token_id) self.token_provider_api._persistence.get_token(token_id) def test_create_unicode_user_id(self): user_id = six.text_type(uuid.uuid4().hex) token_id, data = self.create_token_sample_data(user_id=user_id) self.token_provider_api._persistence.get_token(token_id) def test_token_expire_timezone(self): @test_utils.timezone def _create_token(expire_time): token_id = uuid.uuid4().hex user_id = six.text_type(uuid.uuid4().hex) return self.create_token_sample_data(token_id=token_id, user_id=user_id, expires=expire_time) for d in ['+0', '-11', '-8', '-5', '+5', '+8', '+14']: test_utils.TZ = 'UTC' + d expire_time = timeutils.utcnow() + datetime.timedelta(minutes=1) token_id, data_in = _create_token(expire_time) data_get = self.token_provider_api._persistence.get_token(token_id) self.assertEqual(data_in['id'], data_get['id'], 'TZ=%s' % test_utils.TZ) expire_time_expired = ( timeutils.utcnow() + datetime.timedelta(minutes=-1)) token_id, data_in = _create_token(expire_time_expired) self.assertRaises(exception.TokenNotFound, self.token_provider_api._persistence.get_token, data_in['id']) class TokenCacheInvalidation(object): def _create_test_data(self): self.user = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) self.tenant = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) # Create an equivalent of a scoped token token_dict = {'user': self.user, 'tenant': self.tenant, 'metadata': {}, 'id': 'placeholder'} token_id, data = self.token_provider_api.issue_v2_token(token_dict) self.scoped_token_id = token_id # ..and an un-scoped one token_dict = {'user': self.user, 'tenant': None, 'metadata': {}, 'id': 'placeholder'} token_id, data = self.token_provider_api.issue_v2_token(token_dict) self.unscoped_token_id = token_id # Validate them, in the various ways possible - this will load the # responses into the token cache. self._check_scoped_tokens_are_valid() self._check_unscoped_tokens_are_valid() def _check_unscoped_tokens_are_invalid(self): self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_token, self.unscoped_token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_v2_token, self.unscoped_token_id) def _check_scoped_tokens_are_invalid(self): self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_token, self.scoped_token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_token, self.scoped_token_id, self.tenant['id']) self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_v2_token, self.scoped_token_id) self.assertRaises( exception.TokenNotFound, self.token_provider_api.validate_v2_token, self.scoped_token_id, self.tenant['id']) def _check_scoped_tokens_are_valid(self): self.token_provider_api.validate_token(self.scoped_token_id) self.token_provider_api.validate_token( self.scoped_token_id, belongs_to=self.tenant['id']) self.token_provider_api.validate_v2_token(self.scoped_token_id) self.token_provider_api.validate_v2_token( self.scoped_token_id, belongs_to=self.tenant['id']) def _check_unscoped_tokens_are_valid(self): self.token_provider_api.validate_token(self.unscoped_token_id) self.token_provider_api.validate_v2_token(self.unscoped_token_id) def test_delete_unscoped_token(self): self.token_provider_api._persistence.delete_token( self.unscoped_token_id) self._check_unscoped_tokens_are_invalid() self._check_scoped_tokens_are_valid() def test_delete_scoped_token_by_id(self): self.token_provider_api._persistence.delete_token(self.scoped_token_id) self._check_scoped_tokens_are_invalid() self._check_unscoped_tokens_are_valid() def test_delete_scoped_token_by_user(self): self.token_provider_api._persistence.delete_tokens(self.user['id']) # Since we are deleting all tokens for this user, they should all # now be invalid. self._check_scoped_tokens_are_invalid() self._check_unscoped_tokens_are_invalid() def test_delete_scoped_token_by_user_and_tenant(self): self.token_provider_api._persistence.delete_tokens( self.user['id'], tenant_id=self.tenant['id']) self._check_scoped_tokens_are_invalid() self._check_unscoped_tokens_are_valid() ",558,528
openstack%2Fkeystone~master~Ibf09008e558b2cc9e53301c692737d305fb31695,openstack/keystone,master,Ibf09008e558b2cc9e53301c692737d305fb31695,Split resource backend tests,MERGED,2016-01-16 19:16:05.000000000,2016-03-05 01:26:34.000000000,2016-03-05 01:26:34.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 17026}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-16 19:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/53eea7bddbfaad9229b8f5aa616e00ae11343c77', 'message': 'Extract resource backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract resource-related tests to its directory\nunder unit/backend/resource.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n'}, {'number': 2, 'created': '2016-01-18 18:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e0267e81965cef4f0cbec1fb3d84c6592c1d63c1', 'message': 'Split resource backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract resource-related tests to its directory\nunder unit/resource.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n'}, {'number': 3, 'created': '2016-01-18 20:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/218ffa96c7211e8a43e987c3c3be4ef530dba2aa', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}, {'number': 4, 'created': '2016-01-27 13:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ece24e45f71dbb0933b9bab39421e5cf11b2802c', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}, {'number': 5, 'created': '2016-01-28 13:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ee1bbc74f9104a8f03bbe7a158c3f85cfd377cf', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}, {'number': 6, 'created': '2016-01-28 21:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/76f0ebb3ab3382b1c8f34c21e10e0d2e454f0f9c', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}, {'number': 7, 'created': '2016-03-04 17:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7bc9ec2eb2fd5c3981697fd32a7f716671eaab7c', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}, {'number': 8, 'created': '2016-03-04 18:26:21.000000000', 'files': ['keystone/tests/unit/resource/test_backends.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/08b05ae567cfcb330f60149ce5c4e9b1de2139b4', 'message': ""Split resource backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the resource backend.\n\nChange-Id: Ibf09008e558b2cc9e53301c692737d305fb31695\n""}]",0,268702,08b05ae567cfcb330f60149ce5c4e9b1de2139b4,30,7,8,17860,,,0,"Split resource backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the resource backend.

Change-Id: Ibf09008e558b2cc9e53301c692737d305fb31695
",git fetch https://review.opendev.org/openstack/keystone refs/changes/02/268702/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/backend/resource/__init__.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py', 'keystone/tests/unit/backend/resource/core.py']",5,53eea7bddbfaad9229b8f5aa616e00ae11343c77,split-backend-tests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import uuid from oslo_config import cfg from six.moves import range from keystone.common import driver_hints from keystone import exception from keystone.tests import unit from keystone.tests.unit import utils as test_utils CONF = cfg.CONF DEFAULT_DOMAIN_ID = CONF.identity.default_domain_id class ResourceTests(object): def test_get_project(self): tenant_ref = self.resource_api.get_project(self.tenant_bar['id']) self.assertDictEqual(self.tenant_bar, tenant_ref) def test_get_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, uuid.uuid4().hex) def test_get_project_by_name(self): tenant_ref = self.resource_api.get_project_by_name( self.tenant_bar['name'], DEFAULT_DOMAIN_ID) self.assertDictEqual(self.tenant_bar, tenant_ref) def test_get_project_by_name_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project_by_name, uuid.uuid4().hex, DEFAULT_DOMAIN_ID) def test_create_duplicate_project_id_fails(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project_id = project['id'] self.resource_api.create_project(project_id, project) project['name'] = 'fake2' self.assertRaises(exception.Conflict, self.resource_api.create_project, project_id, project) def test_create_duplicate_project_name_fails(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project_id = project['id'] self.resource_api.create_project(project_id, project) project['id'] = 'fake2' self.assertRaises(exception.Conflict, self.resource_api.create_project, project_id, project) def test_create_duplicate_project_name_in_different_domains(self): new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) project1 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project2 = unit.new_project_ref(name=project1['name'], domain_id=new_domain['id']) self.resource_api.create_project(project1['id'], project1) self.resource_api.create_project(project2['id'], project2) def test_move_project_between_domains(self): domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) project = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project['id'], project) project['domain_id'] = domain2['id'] self.resource_api.update_project(project['id'], project) updated_project_ref = self.resource_api.get_project(project['id']) self.assertEqual(domain2['id'], updated_project_ref['domain_id']) def test_move_project_between_domains_with_clashing_names_fails(self): domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) # First, create a project in domain1 project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) # Now create a project in domain2 with a potentially clashing # name - which should work since we have domain separation project2 = unit.new_project_ref(name=project1['name'], domain_id=domain2['id']) self.resource_api.create_project(project2['id'], project2) # Now try and move project1 into the 2nd domain - which should # fail since the names clash project1['domain_id'] = domain2['id'] self.assertRaises(exception.Conflict, self.resource_api.update_project, project1['id'], project1) def test_rename_duplicate_project_name_fails(self): project1 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project2 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project1['id'], project1) self.resource_api.create_project(project2['id'], project2) project2['name'] = project1['name'] self.assertRaises(exception.Error, self.resource_api.update_project, project2['id'], project2) def test_update_project_id_does_nothing(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project_id = project['id'] self.resource_api.create_project(project['id'], project) project['id'] = 'fake2' self.resource_api.update_project(project_id, project) project_ref = self.resource_api.get_project(project_id) self.assertEqual(project_id, project_ref['id']) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, 'fake2') def test_delete_domain_with_user_group_project_links(self): # TODO(chungg):add test case once expected behaviour defined pass def test_update_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.resource_api.update_project, uuid.uuid4().hex, dict()) def test_delete_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.resource_api.delete_project, uuid.uuid4().hex) def test_create_update_delete_unicode_project(self): unicode_project_name = u'name \u540d\u5b57' project = unit.new_project_ref( name=unicode_project_name, domain_id=CONF.identity.default_domain_id) self.resource_api.create_project(project['id'], project) self.resource_api.update_project(project['id'], project) self.resource_api.delete_project(project['id']) def test_create_project_with_no_enabled_field(self): ref = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) del ref['enabled'] self.resource_api.create_project(ref['id'], ref) project = self.resource_api.get_project(ref['id']) self.assertIs(project['enabled'], True) def test_create_project_long_name_fails(self): project = unit.new_project_ref(name='a' * 65, domain_id=DEFAULT_DOMAIN_ID) self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) def test_create_project_blank_name_fails(self): project = unit.new_project_ref(name='', domain_id=DEFAULT_DOMAIN_ID) self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) def test_create_project_invalid_name_fails(self): project = unit.new_project_ref(name=None, domain_id=DEFAULT_DOMAIN_ID) self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) project = unit.new_project_ref(name=123, domain_id=DEFAULT_DOMAIN_ID) self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) def test_update_project_blank_name_fails(self): project = unit.new_project_ref(name='fake1', domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) project['name'] = '' self.assertRaises(exception.ValidationError, self.resource_api.update_project, project['id'], project) def test_update_project_long_name_fails(self): project = unit.new_project_ref(name='fake1', domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) project['name'] = 'a' * 65 self.assertRaises(exception.ValidationError, self.resource_api.update_project, project['id'], project) def test_update_project_invalid_name_fails(self): project = unit.new_project_ref(name='fake1', domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) project['name'] = None self.assertRaises(exception.ValidationError, self.resource_api.update_project, project['id'], project) project['name'] = 123 self.assertRaises(exception.ValidationError, self.resource_api.update_project, project['id'], project) def test_update_project_invalid_enabled_type_string(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertTrue(project_ref['enabled']) # Strings are not valid boolean values project['enabled'] = ""false"" self.assertRaises(exception.ValidationError, self.resource_api.update_project, project['id'], project) def test_create_project_invalid_enabled_type_string(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, # invalid string value enabled=""true"") self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) def test_create_project_invalid_domain_id(self): project = unit.new_project_ref(domain_id=uuid.uuid4().hex) self.assertRaises(exception.DomainNotFound, self.resource_api.create_project, project['id'], project) def test_list_domains(self): domain1 = unit.new_domain_ref() domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) self.resource_api.create_domain(domain2['id'], domain2) domains = self.resource_api.list_domains() self.assertEqual(3, len(domains)) domain_ids = [] for domain in domains: domain_ids.append(domain.get('id')) self.assertIn(DEFAULT_DOMAIN_ID, domain_ids) self.assertIn(domain1['id'], domain_ids) self.assertIn(domain2['id'], domain_ids) def test_list_projects(self): projects = self.resource_api.list_projects() self.assertEqual(4, len(projects)) project_ids = [] for project in projects: project_ids.append(project.get('id')) self.assertIn(self.tenant_bar['id'], project_ids) self.assertIn(self.tenant_baz['id'], project_ids) def test_list_projects_with_multiple_filters(self): # Create a project project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) # Build driver hints with the project's name and inexistent description hints = driver_hints.Hints() hints.add_filter('name', project['name']) hints.add_filter('description', uuid.uuid4().hex) # Retrieve projects based on hints and check an empty list is returned projects = self.resource_api.list_projects(hints) self.assertEqual([], projects) # Build correct driver hints hints = driver_hints.Hints() hints.add_filter('name', project['name']) hints.add_filter('description', project['description']) # Retrieve projects based on hints projects = self.resource_api.list_projects(hints) # Check that the returned list contains only the first project self.assertEqual(1, len(projects)) self.assertEqual(project, projects[0]) def test_list_projects_for_domain(self): project_ids = ([x['id'] for x in self.resource_api.list_projects_in_domain( DEFAULT_DOMAIN_ID)]) self.assertEqual(4, len(project_ids)) self.assertIn(self.tenant_bar['id'], project_ids) self.assertIn(self.tenant_baz['id'], project_ids) self.assertIn(self.tenant_mtu['id'], project_ids) self.assertIn(self.tenant_service['id'], project_ids) @unit.skip_if_no_multiple_domains_support def test_list_projects_for_alternate_domain(self): domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project2['id'], project2) project_ids = ([x['id'] for x in self.resource_api.list_projects_in_domain( domain1['id'])]) self.assertEqual(2, len(project_ids)) self.assertIn(project1['id'], project_ids) self.assertIn(project2['id'], project_ids) def _create_projects_hierarchy(self, hierarchy_size=2, domain_id=DEFAULT_DOMAIN_ID, is_domain=False): """"""Creates a project hierarchy with specified size. :param hierarchy_size: the desired hierarchy size, default is 2 - a project with one child. :param domain_id: domain where the projects hierarchy will be created. :param is_domain: if the hierarchy will have the is_domain flag active or not. :returns projects: a list of the projects in the created hierarchy. """""" project = unit.new_project_ref(domain_id=domain_id, is_domain=is_domain) project_id = project['id'] self.resource_api.create_project(project_id, project) projects = [project] for i in range(1, hierarchy_size): new_project = unit.new_project_ref(parent_id=project_id, is_domain=is_domain, domain_id=domain_id) self.resource_api.create_project(new_project['id'], new_project) projects.append(new_project) project_id = new_project['id'] return projects @unit.skip_if_no_multiple_domains_support def test_create_domain_with_project_api(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, is_domain=True) ref = self.resource_api.create_project(project['id'], project) self.assertTrue(ref['is_domain']) self.assertEqual(DEFAULT_DOMAIN_ID, ref['domain_id']) @unit.skip_if_no_multiple_domains_support @test_utils.wip('waiting for sub projects acting as domains support') def test_is_domain_sub_project_has_parent_domain_id(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, is_domain=True) self.resource_api.create_project(project['id'], project) sub_project = unit.new_project_ref(domain_id=project['id'], parent_id=project['id'], is_domain=True) ref = self.resource_api.create_project(sub_project['id'], sub_project) self.assertTrue(ref['is_domain']) self.assertEqual(project['id'], ref['parent_id']) self.assertEqual(project['id'], ref['domain_id']) @unit.skip_if_no_multiple_domains_support @test_utils.wip('waiting for projects acting as domains implementation') def test_delete_domain_with_project_api(self): project = unit.new_project_ref(domain_id=None, is_domain=True) self.resource_api.create_project(project['id'], project) # Try to delete is_domain project that is enabled self.assertRaises(exception.ValidationError, self.resource_api.delete_project, project['id']) # Disable the project project['enabled'] = False self.resource_api.update_project(project['id'], project) # Successfully delete the project self.resource_api.delete_project(project['id']) @unit.skip_if_no_multiple_domains_support def test_create_subproject_acting_as_domain_fails(self): root_project = {'id': uuid.uuid4().hex, 'domain_id': DEFAULT_DOMAIN_ID, 'name': uuid.uuid4().hex, 'parent_id': None, 'is_domain': True} self.resource_api.create_project(root_project['id'], root_project) sub_project = {'id': uuid.uuid4().hex, 'domain_id': DEFAULT_DOMAIN_ID, 'name': uuid.uuid4().hex, 'parent_id': root_project['id'], 'is_domain': True} # Creation of sub projects acting as domains is not allowed yet self.assertRaises(exception.ValidationError, self.resource_api.create_project, sub_project['id'], sub_project) @unit.skip_if_no_multiple_domains_support def test_create_domain_under_regular_project_hierarchy_fails(self): # Projects acting as domains can't have a regular project as parent projects_hierarchy = self._create_projects_hierarchy() parent = projects_hierarchy[1] project = unit.new_project_ref(domain_id=parent['id'], parent_id=parent['id'], is_domain=True) self.assertRaises(exception.ValidationError, self.resource_api.create_project, project['id'], project) @unit.skip_if_no_multiple_domains_support @test_utils.wip('waiting for sub projects acting as domains support') def test_create_project_under_domain_hierarchy(self): projects_hierarchy = self._create_projects_hierarchy(is_domain=True) parent = projects_hierarchy[1] project = unit.new_project_ref(domain_id=parent['id'], parent_id=parent['id'], is_domain=False) ref = self.resource_api.create_project(project['id'], project) self.assertFalse(ref['is_domain']) self.assertEqual(parent['id'], ref['parent_id']) self.assertEqual(parent['id'], ref['domain_id']) def test_create_project_without_is_domain_flag(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) del project['is_domain'] ref = self.resource_api.create_project(project['id'], project) # The is_domain flag should be False by default self.assertFalse(ref['is_domain']) @unit.skip_if_no_multiple_domains_support def test_create_project_passing_is_domain_flag_true(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, is_domain=True) ref = self.resource_api.create_project(project['id'], project) self.assertTrue(ref['is_domain']) def test_create_project_passing_is_domain_flag_false(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, is_domain=False) ref = self.resource_api.create_project(project['id'], project) self.assertIs(False, ref['is_domain']) @test_utils.wip('waiting for projects acting as domains implementation') def test_create_project_with_parent_id_and_without_domain_id(self): project = unit.new_project_ref(domain_id=None) self.resource_api.create_project(project['id'], project) sub_project = unit.new_project_ref(parent_id=project['id']) ref = self.resource_api.create_project(sub_project['id'], sub_project) # The domain_id should be set to the parent domain_id self.assertEqual(project['domain_id'], ref['domain_id']) @test_utils.wip('waiting for projects acting as domains implementation') def test_create_project_with_domain_id_and_without_parent_id(self): project = unit.new_project_ref(parent_id=None) self.resource_api.create_project(project['id'], project) sub_project = unit.new_project_ref(domain_id=project['id']) ref = self.resource_api.create_project(sub_project['id'], sub_project) # The parent_id should be set to the domain_id self.assertEqual(project['id'], ref['parent_id']) def test_check_leaf_projects(self): projects_hierarchy = self._create_projects_hierarchy() root_project = projects_hierarchy[0] leaf_project = projects_hierarchy[1] self.assertFalse(self.resource_api.is_leaf_project( root_project['id'])) self.assertTrue(self.resource_api.is_leaf_project( leaf_project['id'])) # Delete leaf_project self.resource_api.delete_project(leaf_project['id']) # Now, root_project should be leaf self.assertTrue(self.resource_api.is_leaf_project( root_project['id'])) def test_list_projects_in_subtree(self): projects_hierarchy = self._create_projects_hierarchy(hierarchy_size=3) project1 = projects_hierarchy[0] project2 = projects_hierarchy[1] project3 = projects_hierarchy[2] project4 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=project2['id']) self.resource_api.create_project(project4['id'], project4) subtree = self.resource_api.list_projects_in_subtree(project1['id']) self.assertEqual(3, len(subtree)) self.assertIn(project2, subtree) self.assertIn(project3, subtree) self.assertIn(project4, subtree) subtree = self.resource_api.list_projects_in_subtree(project2['id']) self.assertEqual(2, len(subtree)) self.assertIn(project3, subtree) self.assertIn(project4, subtree) subtree = self.resource_api.list_projects_in_subtree(project3['id']) self.assertEqual(0, len(subtree)) def test_list_projects_in_subtree_with_circular_reference(self): project1 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=project1['id']) self.resource_api.create_project(project2['id'], project2) project1['parent_id'] = project2['id'] # Adds cyclic reference # NOTE(dstanek): The manager does not allow parent_id to be updated. # Instead will directly use the driver to create the cyclic # reference. self.resource_api.driver.update_project(project1['id'], project1) subtree = self.resource_api.list_projects_in_subtree(project1['id']) # NOTE(dstanek): If a cyclic reference is detected the code bails # and returns None instead of falling into the infinite # recursion trap. self.assertIsNone(subtree) def test_list_projects_in_subtree_invalid_project_id(self): self.assertRaises(exception.ValidationError, self.resource_api.list_projects_in_subtree, None) self.assertRaises(exception.ProjectNotFound, self.resource_api.list_projects_in_subtree, uuid.uuid4().hex) def test_list_project_parents(self): projects_hierarchy = self._create_projects_hierarchy(hierarchy_size=3) project1 = projects_hierarchy[0] project2 = projects_hierarchy[1] project3 = projects_hierarchy[2] project4 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=project2['id']) self.resource_api.create_project(project4['id'], project4) parents1 = self.resource_api.list_project_parents(project3['id']) self.assertEqual(2, len(parents1)) self.assertIn(project1, parents1) self.assertIn(project2, parents1) parents2 = self.resource_api.list_project_parents(project4['id']) self.assertEqual(parents1, parents2) parents = self.resource_api.list_project_parents(project1['id']) self.assertEqual(0, len(parents)) def test_list_project_parents_invalid_project_id(self): self.assertRaises(exception.ValidationError, self.resource_api.list_project_parents, None) self.assertRaises(exception.ProjectNotFound, self.resource_api.list_project_parents, uuid.uuid4().hex) def test_delete_project_with_role_assignments(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], project['id'], 'member') self.resource_api.delete_project(project['id']) self.assertRaises(exception.NotFound, self.resource_api.get_project, project['id']) def test_create_project_doesnt_modify_passed_in_dict(self): new_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) original_project = new_project.copy() self.resource_api.create_project(new_project['id'], new_project) self.assertDictEqual(original_project, new_project) def test_update_project_enable(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertTrue(project_ref['enabled']) project['enabled'] = False self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertEqual(project['enabled'], project_ref['enabled']) # If not present, enabled field should not be updated del project['enabled'] self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertFalse(project_ref['enabled']) project['enabled'] = True self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertEqual(project['enabled'], project_ref['enabled']) del project['enabled'] self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertTrue(project_ref['enabled']) def test_create_invalid_domain_fails(self): new_group = unit.new_group_ref(domain_id=""doesnotexist"") self.assertRaises(exception.DomainNotFound, self.identity_api.create_group, new_group) new_user = unit.new_user_ref(domain_id=""doesnotexist"") self.assertRaises(exception.DomainNotFound, self.identity_api.create_user, new_user) @unit.skip_if_no_multiple_domains_support def test_project_crud(self): domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) project = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertDictContainsSubset(project, project_ref) project['name'] = uuid.uuid4().hex self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertDictContainsSubset(project, project_ref) self.resource_api.delete_project(project['id']) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, project['id']) def test_domain_delete_hierarchy(self): domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) # Creating a root and a leaf project inside the domain projects_hierarchy = self._create_projects_hierarchy( domain_id=domain['id']) root_project = projects_hierarchy[0] leaf_project = projects_hierarchy[0] # Disable the domain domain['enabled'] = False self.resource_api.update_domain(domain['id'], domain) # Delete the domain self.resource_api.delete_domain(domain['id']) # Make sure the domain no longer exists self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain, domain['id']) # Make sure the root project no longer exists self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, root_project['id']) # Make sure the leaf project no longer exists self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, leaf_project['id']) def test_hierarchical_projects_crud(self): # create a hierarchy with just a root project (which is a leaf as well) projects_hierarchy = self._create_projects_hierarchy(hierarchy_size=1) root_project1 = projects_hierarchy[0] # create a hierarchy with one root project and one leaf project projects_hierarchy = self._create_projects_hierarchy() root_project2 = projects_hierarchy[0] leaf_project = projects_hierarchy[1] # update description from leaf_project leaf_project['description'] = 'new description' self.resource_api.update_project(leaf_project['id'], leaf_project) proj_ref = self.resource_api.get_project(leaf_project['id']) self.assertDictEqual(leaf_project, proj_ref) # update the parent_id is not allowed leaf_project['parent_id'] = root_project1['id'] self.assertRaises(exception.ForbiddenAction, self.resource_api.update_project, leaf_project['id'], leaf_project) # delete root_project1 self.resource_api.delete_project(root_project1['id']) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, root_project1['id']) # delete root_project2 is not allowed since it is not a leaf project self.assertRaises(exception.ForbiddenAction, self.resource_api.delete_project, root_project2['id']) def test_create_project_with_invalid_parent(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id='fake') self.assertRaises(exception.ProjectNotFound, self.resource_api.create_project, project['id'], project) @unit.skip_if_no_multiple_domains_support def test_create_leaf_project_with_different_domain(self): root_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(root_project['id'], root_project) domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) leaf_project = unit.new_project_ref(domain_id=domain['id'], parent_id=root_project['id']) self.assertRaises(exception.ValidationError, self.resource_api.create_project, leaf_project['id'], leaf_project) def test_delete_hierarchical_leaf_project(self): projects_hierarchy = self._create_projects_hierarchy() root_project = projects_hierarchy[0] leaf_project = projects_hierarchy[1] self.resource_api.delete_project(leaf_project['id']) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, leaf_project['id']) self.resource_api.delete_project(root_project['id']) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, root_project['id']) def test_delete_hierarchical_not_leaf_project(self): projects_hierarchy = self._create_projects_hierarchy() root_project = projects_hierarchy[0] self.assertRaises(exception.ForbiddenAction, self.resource_api.delete_project, root_project['id']) def test_update_project_parent(self): projects_hierarchy = self._create_projects_hierarchy(hierarchy_size=3) project1 = projects_hierarchy[0] project2 = projects_hierarchy[1] project3 = projects_hierarchy[2] # project2 is the parent from project3 self.assertEqual(project3.get('parent_id'), project2['id']) # try to update project3 parent to parent1 project3['parent_id'] = project1['id'] self.assertRaises(exception.ForbiddenAction, self.resource_api.update_project, project3['id'], project3) def test_create_project_under_disabled_one(self): project1 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, enabled=False) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=project1['id']) # It's not possible to create a project under a disabled one in the # hierarchy self.assertRaises(exception.ValidationError, self.resource_api.create_project, project2['id'], project2) def test_disable_hierarchical_leaf_project(self): projects_hierarchy = self._create_projects_hierarchy() leaf_project = projects_hierarchy[1] leaf_project['enabled'] = False self.resource_api.update_project(leaf_project['id'], leaf_project) project_ref = self.resource_api.get_project(leaf_project['id']) self.assertEqual(leaf_project['enabled'], project_ref['enabled']) def test_disable_hierarchical_not_leaf_project(self): projects_hierarchy = self._create_projects_hierarchy() root_project = projects_hierarchy[0] root_project['enabled'] = False self.assertRaises(exception.ForbiddenAction, self.resource_api.update_project, root_project['id'], root_project) def test_enable_project_with_disabled_parent(self): projects_hierarchy = self._create_projects_hierarchy() root_project = projects_hierarchy[0] leaf_project = projects_hierarchy[1] # Disable leaf and root leaf_project['enabled'] = False self.resource_api.update_project(leaf_project['id'], leaf_project) root_project['enabled'] = False self.resource_api.update_project(root_project['id'], root_project) # Try to enable the leaf project, it's not possible since it has # a disabled parent leaf_project['enabled'] = True self.assertRaises(exception.ForbiddenAction, self.resource_api.update_project, leaf_project['id'], leaf_project) def _get_hierarchy_depth(self, project_id): return len(self.resource_api.list_project_parents(project_id)) + 1 def test_check_hierarchy_depth(self): # First create a hierarchy with the max allowed depth projects_hierarchy = self._create_projects_hierarchy( CONF.max_project_tree_depth) leaf_project = projects_hierarchy[CONF.max_project_tree_depth - 1] depth = self._get_hierarchy_depth(leaf_project['id']) self.assertEqual(CONF.max_project_tree_depth, depth) # Creating another project in the hierarchy shouldn't be allowed project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=leaf_project['id']) self.assertRaises(exception.ForbiddenAction, self.resource_api.create_project, project['id'], project) def test_project_update_missing_attrs_with_a_value(self): # Creating a project with no description attribute. project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) del project['description'] self.resource_api.create_project(project['id'], project) # Add a description attribute. project['description'] = uuid.uuid4().hex self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertDictEqual(project, project_ref) def test_project_update_missing_attrs_with_a_falsey_value(self): # Creating a project with no description attribute. project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) del project['description'] self.resource_api.create_project(project['id'], project) # Add a description attribute. project['description'] = '' self.resource_api.update_project(project['id'], project) project_ref = self.resource_api.get_project(project['id']) self.assertDictEqual(project, project_ref) def test_domain_crud(self): domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) domain_ref = self.resource_api.get_domain(domain['id']) self.assertDictEqual(domain, domain_ref) domain['name'] = uuid.uuid4().hex self.resource_api.update_domain(domain['id'], domain) domain_ref = self.resource_api.get_domain(domain['id']) self.assertDictEqual(domain, domain_ref) # Ensure an 'enabled' domain cannot be deleted self.assertRaises(exception.ForbiddenAction, self.resource_api.delete_domain, domain_id=domain['id']) # Disable the domain domain['enabled'] = False self.resource_api.update_domain(domain['id'], domain) # Delete the domain self.resource_api.delete_domain(domain['id']) # Make sure the domain no longer exists self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain, domain['id']) @unit.skip_if_no_multiple_domains_support def test_create_domain_case_sensitivity(self): # create a ref with a lowercase name ref = unit.new_domain_ref(name=uuid.uuid4().hex.lower()) self.resource_api.create_domain(ref['id'], ref) # assign a new ID with the same name, but this time in uppercase ref['id'] = uuid.uuid4().hex ref['name'] = ref['name'].upper() self.resource_api.create_domain(ref['id'], ref) def test_project_attribute_update(self): project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project['id'], project) # pick a key known to be non-existent key = 'description' def assert_key_equals(value): project_ref = self.resource_api.update_project( project['id'], project) self.assertEqual(value, project_ref[key]) project_ref = self.resource_api.get_project(project['id']) self.assertEqual(value, project_ref[key]) def assert_get_key_is(value): project_ref = self.resource_api.update_project( project['id'], project) self.assertIs(project_ref.get(key), value) project_ref = self.resource_api.get_project(project['id']) self.assertIs(project_ref.get(key), value) # add an attribute that doesn't exist, set it to a falsey value value = '' project[key] = value assert_key_equals(value) # set an attribute with a falsey value to null value = None project[key] = value assert_get_key_is(value) # do it again, in case updating from this situation is handled oddly value = None project[key] = value assert_get_key_is(value) # set a possibly-null value to a falsey value value = '' project[key] = value assert_key_equals(value) # set a falsey value to a truthy value value = uuid.uuid4().hex project[key] = value assert_key_equals(value) @unit.skip_if_cache_disabled('resource') @unit.skip_if_no_multiple_domains_support def test_domain_rename_invalidates_get_domain_by_name_cache(self): domain = unit.new_domain_ref() domain_id = domain['id'] domain_name = domain['name'] self.resource_api.create_domain(domain_id, domain) domain_ref = self.resource_api.get_domain_by_name(domain_name) domain_ref['name'] = uuid.uuid4().hex self.resource_api.update_domain(domain_id, domain_ref) self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain_by_name, domain_name) @unit.skip_if_cache_disabled('resource') def test_cache_layer_domain_crud(self): domain = unit.new_domain_ref() domain_id = domain['id'] # Create Domain self.resource_api.create_domain(domain_id, domain) domain_ref = self.resource_api.get_domain(domain_id) updated_domain_ref = copy.deepcopy(domain_ref) updated_domain_ref['name'] = uuid.uuid4().hex # Update domain, bypassing resource api manager self.resource_api.driver.update_domain(domain_id, updated_domain_ref) # Verify get_domain still returns the domain self.assertDictContainsSubset( domain_ref, self.resource_api.get_domain(domain_id)) # Invalidate cache self.resource_api.get_domain.invalidate(self.resource_api, domain_id) # Verify get_domain returns the updated domain self.assertDictContainsSubset( updated_domain_ref, self.resource_api.get_domain(domain_id)) # Update the domain back to original ref, using the assignment api # manager self.resource_api.update_domain(domain_id, domain_ref) self.assertDictContainsSubset( domain_ref, self.resource_api.get_domain(domain_id)) # Make sure domain is 'disabled', bypass resource api manager domain_ref_disabled = domain_ref.copy() domain_ref_disabled['enabled'] = False self.resource_api.driver.update_domain(domain_id, domain_ref_disabled) # Delete domain, bypassing resource api manager self.resource_api.driver.delete_domain(domain_id) # Verify get_domain still returns the domain self.assertDictContainsSubset( domain_ref, self.resource_api.get_domain(domain_id)) # Invalidate cache self.resource_api.get_domain.invalidate(self.resource_api, domain_id) # Verify get_domain now raises DomainNotFound self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain, domain_id) # Recreate Domain self.resource_api.create_domain(domain_id, domain) self.resource_api.get_domain(domain_id) # Make sure domain is 'disabled', bypass resource api manager domain['enabled'] = False self.resource_api.driver.update_domain(domain_id, domain) # Delete domain self.resource_api.delete_domain(domain_id) # verify DomainNotFound raised self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain, domain_id) @unit.skip_if_cache_disabled('resource') @unit.skip_if_no_multiple_domains_support def test_project_rename_invalidates_get_project_by_name_cache(self): domain = unit.new_domain_ref() project = unit.new_project_ref(domain_id=domain['id']) project_id = project['id'] project_name = project['name'] self.resource_api.create_domain(domain['id'], domain) # Create a project self.resource_api.create_project(project_id, project) self.resource_api.get_project_by_name(project_name, domain['id']) project['name'] = uuid.uuid4().hex self.resource_api.update_project(project_id, project) self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project_by_name, project_name, domain['id']) @unit.skip_if_cache_disabled('resource') @unit.skip_if_no_multiple_domains_support def test_cache_layer_project_crud(self): domain = unit.new_domain_ref() project = unit.new_project_ref(domain_id=domain['id']) project_id = project['id'] self.resource_api.create_domain(domain['id'], domain) # Create a project self.resource_api.create_project(project_id, project) self.resource_api.get_project(project_id) updated_project = copy.deepcopy(project) updated_project['name'] = uuid.uuid4().hex # Update project, bypassing resource manager self.resource_api.driver.update_project(project_id, updated_project) # Verify get_project still returns the original project_ref self.assertDictContainsSubset( project, self.resource_api.get_project(project_id)) # Invalidate cache self.resource_api.get_project.invalidate(self.resource_api, project_id) # Verify get_project now returns the new project self.assertDictContainsSubset( updated_project, self.resource_api.get_project(project_id)) # Update project using the resource_api manager back to original self.resource_api.update_project(project['id'], project) # Verify get_project returns the original project_ref self.assertDictContainsSubset( project, self.resource_api.get_project(project_id)) # Delete project bypassing resource self.resource_api.driver.delete_project(project_id) # Verify get_project still returns the project_ref self.assertDictContainsSubset( project, self.resource_api.get_project(project_id)) # Invalidate cache self.resource_api.get_project.invalidate(self.resource_api, project_id) # Verify ProjectNotFound now raised self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, project_id) # recreate project self.resource_api.create_project(project_id, project) self.resource_api.get_project(project_id) # delete project self.resource_api.delete_project(project_id) # Verify ProjectNotFound is raised self.assertRaises(exception.ProjectNotFound, self.resource_api.get_project, project_id) @unit.skip_if_no_multiple_domains_support def test_get_default_domain_by_name(self): domain_name = 'default' domain = unit.new_domain_ref(name=domain_name) self.resource_api.create_domain(domain['id'], domain) domain_ref = self.resource_api.get_domain_by_name(domain_name) self.assertEqual(domain, domain_ref) def test_get_not_default_domain_by_name(self): domain_name = 'foo' self.assertRaises(exception.DomainNotFound, self.resource_api.get_domain_by_name, domain_name) def test_project_update_and_project_get_return_same_response(self): project = unit.new_project_ref( domain_id=CONF.identity.default_domain_id) self.resource_api.create_project(project['id'], project) updated_project = {'enabled': False} updated_project_ref = self.resource_api.update_project( project['id'], updated_project) # SQL backend adds 'extra' field updated_project_ref.pop('extra', None) self.assertIs(False, updated_project_ref['enabled']) project_ref = self.resource_api.get_project(project['id']) self.assertDictEqual(updated_project_ref, project_ref) ",,1166,1133
openstack%2Fkolla~master~Ie6f4b6bbdffed9a85c840a4f425d866fc5402f4b,openstack/kolla,master,Ie6f4b6bbdffed9a85c840a4f425d866fc5402f4b,Bump ansible version to head of devel,MERGED,2016-03-04 16:07:02.000000000,2016-03-05 01:24:39.000000000,2016-03-05 01:24:39.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 13642}, {'_account_id': 14119}, {'_account_id': 18009}]","[{'number': 1, 'created': '2016-03-04 16:07:02.000000000', 'files': ['docker/kolla-toolbox/kolla_keystone_service.py', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/kolla-toolbox/kolla_keystone_user.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6f23746177c87bc9bdbaaddf8db2b3c2ffb80b31', 'message': 'Bump ansible version to head of devel\n\nbcoca has asked we use head of devel to fix the loader issue\n\nTrivialFix\n\nChange-Id: Ie6f4b6bbdffed9a85c840a4f425d866fc5402f4b\n'}]",0,288553,6f23746177c87bc9bdbaaddf8db2b3c2ffb80b31,12,6,1,14119,,,0,"Bump ansible version to head of devel

bcoca has asked we use head of devel to fix the loader issue

TrivialFix

Change-Id: Ie6f4b6bbdffed9a85c840a4f425d866fc5402f4b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/53/288553/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/kolla-toolbox/kolla_keystone_service.py', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/kolla-toolbox/kolla_keystone_user.py']",3,6f23746177c87bc9bdbaaddf8db2b3c2ffb80b31,bump_ansible,," # bcoca broke the loader! bcoca is working on the loaded. until then... module.params['auth'] = json.loads( module.params['auth'].replace(""'"", '""'))",1,7
openstack%2Fironic-ui~master~I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca,openstack/ironic-ui,master,I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca,Register ironic-ui REST endpoints,MERGED,2016-03-04 16:57:04.000000000,2016-03-05 01:23:21.000000000,2016-03-05 01:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 16352}, {'_account_id': 16628}]","[{'number': 1, 'created': '2016-03-04 16:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/fa28ecd30f4c1fa910f4ecd1dcec680562ee2cc3', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}, {'number': 2, 'created': '2016-03-04 18:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/dbcb085aae3492812a640308872b873a53b18b21', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}, {'number': 3, 'created': '2016-03-05 00:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/83450b3909c237b9146f214162d419a6fb95ef92', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}, {'number': 4, 'created': '2016-03-05 00:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/9d0dd6862a5ac1547d6bf953a2a701f3bd6deef1', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}, {'number': 5, 'created': '2016-03-05 00:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/c6151b30dff834aa1ad51ca1c058a81645f9f88b', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}, {'number': 6, 'created': '2016-03-05 01:09:47.000000000', 'files': ['ironic_ui/content/ironic/urls.py'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/57837a3fd30ca19d344cbd80bd29ea04a5c30943', 'message': 'Register ironic-ui REST endpoints\n\nChange-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca\n'}]",1,288590,57837a3fd30ca19d344cbd80bd29ea04a5c30943,22,5,6,19380,,,0,"Register ironic-ui REST endpoints

Change-Id: I7e4ec10f2d19bf4bcad2a0f3a5d5feb3c62b59ca
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/90/288590/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_ui/content/ironic/urls.py'],1,fa28ecd30f4c1fa910f4ecd1dcec680562ee2cc3,register_endpoints,import ironic_ui.api.ironic_rest_api,,1,0
openstack%2Fpbr~master~Ie8cd35b292997989e33cdb8e82d8740ae2f74041,openstack/pbr,master,Ie8cd35b292997989e33cdb8e82d8740ae2f74041,Refactor packaging module into functional modules,ABANDONED,2014-11-11 04:49:58.000000000,2016-03-05 01:15:17.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 6486}, {'_account_id': 10408}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-11-11 04:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/fb98f1052190b218e6dc3c7f46bcc7ee11a88949', 'message': 'Refactor packaging module into functional modules\n\nThe packaging module has become large and complex module containing many\ndifferent functional features. Long term support and maintenance is\nsignificantly impacted.\n\nThe packaging module has been refactored into the following:\n\n    common - utility functions imported by several modules\n    git - all the git related functions\n    requirements - all the requirements processing functions\n    package cmds (aligned to how setuptools and distribute are defined)\n        build_doc\n        egg_info\n        install\n        install_scripts\n        sdist\n        test\n\nThe dependencies and test cases have been updated to point to the new\nmodules except for version. A separate refactoring of version will be\nhandled in a different patch, at which point the packaging module can\nbe deprecated and/or removed.\n\nChange-Id: Ie8cd35b292997989e33cdb8e82d8740ae2f74041\n'}, {'number': 2, 'created': '2014-11-28 18:16:03.000000000', 'files': ['pbr/packaging.py', 'pbr/cmds/build_doc.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'pbr/common.py', 'pbr/git.py', 'pbr/hooks/base.py', 'pbr/hooks/commands.py', 'pbr/cmds/install_scripts.py', 'pbr/cmds/test.py', 'pbr/cmds/sdist.py', 'pbr/hooks/metadata.py', 'pbr/tests/test_setup.py', 'pbr/cmds/__init__.py', 'pbr/requirements.py', 'pbr/cmds/egg_info.py', 'pbr/hooks/backwards.py', 'pbr/cmds/install.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/0ca2aa51f73e3a7ece54174513dd8efbad06ddc8', 'message': 'Refactor packaging module into functional modules\n\nThe packaging module has become large and complex module containing many\ndifferent functional features. Long term support and maintenance is\nsignificantly impacted.\n\nThe packaging module has been refactored into the following:\n\n    common - utility functions imported by several modules\n    git - all the git related functions\n    requirements - all the requirements processing functions\n    package cmds (aligned to how setuptools and distribute are defined)\n        build_doc\n        egg_info\n        install\n        install_scripts\n        sdist\n        test\n\nThe dependencies and test cases have been updated to point to the new\nmodules except for version. A separate refactoring of version will be\nhandled in a different patch, at which point the packaging module can\nbe deprecated and/or removed.\n\nChange-Id: Ie8cd35b292997989e33cdb8e82d8740ae2f74041\n'}]",2,133607,0ca2aa51f73e3a7ece54174513dd8efbad06ddc8,16,7,2,10408,,,0,"Refactor packaging module into functional modules

The packaging module has become large and complex module containing many
different functional features. Long term support and maintenance is
significantly impacted.

The packaging module has been refactored into the following:

    common - utility functions imported by several modules
    git - all the git related functions
    requirements - all the requirements processing functions
    package cmds (aligned to how setuptools and distribute are defined)
        build_doc
        egg_info
        install
        install_scripts
        sdist
        test

The dependencies and test cases have been updated to point to the new
modules except for version. A separate refactoring of version will be
handled in a different patch, at which point the packaging module can
be deprecated and/or removed.

Change-Id: Ie8cd35b292997989e33cdb8e82d8740ae2f74041
",git fetch https://review.opendev.org/openstack/pbr refs/changes/07/133607/2 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/cmds/build_doc.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'pbr/common.py', 'pbr/git.py', 'pbr/hooks/base.py', 'pbr/hooks/commands.py', 'pbr/cmds/install_scripts.py', 'pbr/cmds/test.py', 'pbr/cmds/sdist.py', 'pbr/hooks/metadata.py', 'pbr/tests/test_setup.py', 'pbr/cmds/__init__.py', 'pbr/requirements.py', 'pbr/cmds/egg_info.py', 'pbr/hooks/backwards.py', 'pbr/cmds/install.py']",17,fb98f1052190b218e6dc3c7f46bcc7ee11a88949,refactor/pbr-packaging,"# Copyright 2013 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import unicode_literals from distutils.command import install as du_install from setuptools.command import install from pbr import requirements class LocalInstall(install.install): """"""Runs python setup.py install in a sensible manner. Force a non-egg installed in the manner of single-version-externally-managed, which allows us to install manpages and config files. Because non-egg installs bypass the depend processing machinery, we need to do our own. Because easy_install is evil, just use pip to process our requirements files directly, which means we don't have to do crazy extra processing. Bypass installation if --single-version-externally-managed is given, so that behavior for packagers remains the same. """""" command_name = 'install' def run(self): option_dict = self.distribution.get_option_dict('pbr') if (not self.single_version_externally_managed and self.distribution.install_requires): requirements.pip_install( self.distribution.dependency_links, self.distribution.install_requires, self.root, option_dict=option_dict) return du_install.install.run(self) ",,1462,140
openstack%2Fproject-config~master~I951629fe14be4ab02fad82aaf7725c109056a845,openstack/project-config,master,I951629fe14be4ab02fad82aaf7725c109056a845,Use OSIC with nodepool,MERGED,2016-03-04 16:47:28.000000000,2016-03-05 01:04:14.000000000,2016-03-05 01:04:11.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-04 16:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9f22dd91b9c170c10a2513364228867d6e19f444', 'message': 'Use OSIC with nodepool\n\nAdd the OSIC cloud to nodepool with a max-servers of 1 to start. We have\nquota for 100 instances which we will ramp up to.\n\nChange-Id: I951629fe14be4ab02fad82aaf7725c109056a845\nDepends-On: If09d716b8aa466678fffd5bdddc176fbaaf7b949\n'}, {'number': 2, 'created': '2016-03-04 23:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9e64063e4b6d78196b0d1e1e7b4a8123e8741bc3', 'message': 'Use OSIC with nodepool\n\nAdd the OSIC cloud to nodepool with a max-servers of 1 to start. We have\nquota for 100 instances which we will ramp up to.\n\nChange-Id: I951629fe14be4ab02fad82aaf7725c109056a845\nDepends-On: If09d716b8aa466678fffd5bdddc176fbaaf7b949\n'}, {'number': 3, 'created': '2016-03-04 23:42:26.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/84587113717c41c06eab615c4eb05e35f8a48e4d', 'message': 'Use OSIC with nodepool\n\nAdd the OSIC cloud to nodepool with a max-servers of 1 to start. We have\nquota for 100 instances which we will ramp up to.\n\nChange-Id: I951629fe14be4ab02fad82aaf7725c109056a845\nDepends-On: I3f35db2911a44200f0486e71fc215d021aa7c227\n'}]",1,288584,84587113717c41c06eab615c4eb05e35f8a48e4d,15,6,3,4146,,,0,"Use OSIC with nodepool

Add the OSIC cloud to nodepool with a max-servers of 1 to start. We have
quota for 100 instances which we will ramp up to.

Change-Id: I951629fe14be4ab02fad82aaf7725c109056a845
Depends-On: I3f35db2911a44200f0486e71fc215d021aa7c227
",git fetch https://review.opendev.org/openstack/project-config refs/changes/84/288584/3 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,9f22dd91b9c170c10a2513364228867d6e19f444,nodepool-osic, - name: osic-cloud1 - name: osic-cloud1 - name: osic-cloud1 - name: osic-cloud1 - name: osic-cloud1 - name: osic-cloud1 region-name: 'RegionOne' cloud: osic api-timeout: 60 boot-timeout: 120 max-servers: 1 rate: 0.001 pool: 'GATEWAY_NET' images: - name: devstack-trusty min-ram: 8000 name-filter: 'm2.medium' diskimage: devstack-trusty username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: ubuntu-trusty min-ram: 8000 name-filter: 'm2.medium' diskimage: ubuntu-trusty username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: devstack-centos7 min-ram: 8000 name-filter: 'm2.medium' diskimage: devstack-centos7 username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: fedora-23 min-ram: 8000 name-filter: 'm2.medium' diskimage: fedora-23 username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true,,42,0
openstack%2Fnetworking-hyperv~master~I2bf598e1d183b13da0ed5c18ffc19cb800732b23,openstack/networking-hyperv,master,I2bf598e1d183b13da0ed5c18ffc19cb800732b23,Hyper-V Code Decomposed & Worker Script,ABANDONED,2015-10-16 08:58:45.000000000,2016-03-05 00:59:53.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8124}, {'_account_id': 8213}, {'_account_id': 10760}, {'_account_id': 15130}]","[{'number': 1, 'created': '2015-10-16 08:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/7f478614c519f3fd5c47c020a578f5d3ff6e2781', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 2, 'created': '2015-10-16 08:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/717e88ed7c6b18ec9a123525b7eb9c116a5960da', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 3, 'created': '2015-10-16 13:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/5aaca78cc9e0d018286c0496066a0347815dc3d3', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 4, 'created': '2015-10-27 05:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/590c55ed1640f37fb9e48afad8333f417d2073d3', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 5, 'created': '2015-11-18 09:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/0a781016da3d0a7781b4352653fc0c441ef860ca', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 6, 'created': '2015-11-19 09:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/50ab8c8ecfa0d0eb19cb8c5dae93a20795ac9c97', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 7, 'created': '2016-01-05 10:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/9fa8014514b0d49140869555d3937ca557b72113', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}, {'number': 8, 'created': '2016-01-05 12:16:58.000000000', 'files': ['hyperv/neutron/worker.py', 'hyperv/neutron/l2_agent.py', 'hyperv/neutron/security_groups_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/3939bd0785d8892df42ecb647306819dd66d2d45', 'message': ""Hyper-V Code Decomposed & Worker Script\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\n\nFiles :\nhyperv/neutron/config.py\nhyperv/neutron/l2_agent.py\nhyperv/neutron/worker.py\n\nWorker script (worker.py) is introduced. Per port\nprocessing will run this script in a child process\ncontext and returns the result to parent process.\nFor every new port addition a new short living\nprocess will be created and on completion it will\nbe killed.\n\nadd_to_security_group_map() & remove_from_security_group_map()\nis introduced to operate on security group map from\n'HyperVNeutronAgentMixin' object context.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23\n""}]",0,235793,3939bd0785d8892df42ecb647306819dd66d2d45,42,6,8,10760,,,0,"Hyper-V Code Decomposed & Worker Script

Code Decompose : Moved code from core neutron to
Hyper-V repository.

Files :
hyperv/neutron/config.py
hyperv/neutron/l2_agent.py
hyperv/neutron/worker.py

Worker script (worker.py) is introduced. Per port
processing will run this script in a child process
context and returns the result to parent process.
For every new port addition a new short living
process will be created and on completion it will
be killed.

add_to_security_group_map() & remove_from_security_group_map()
is introduced to operate on security group map from
'HyperVNeutronAgentMixin' object context.

Partially implements: blueprint scale-hyperv-neutron-agent

Change-Id: I2bf598e1d183b13da0ed5c18ffc19cb800732b23
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/93/235793/5 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/neutron/config.py', 'hyperv/neutron/worker.py', 'hyperv/neutron/l2_agent.py', 'hyperv/neutron/security_groups_driver.py']",4,7f478614c519f3fd5c47c020a578f5d3ff6e2781,bp/scale-hyperv-neutron-agent,"from neutron.agent import firewall def add_to_security_group_map(self, port): if not port: return self._security_ports[port['device']] = port LOG.debug('Created security group entry for port %s' % port['device']) def remove_from_security_group_map(self, port): self._security_ports.pop(port) class HyperVSecurityGroupsDriver(HyperVSecurityGroupsDriverMixin, firewall.FirewallDriver): """"""Security Groups Driver. Security Groups implementation for Hyper-V VMs. """""" pass",,291,0
openstack%2Fnetworking-hyperv~master~I9618fad541917b85a9f18f332d34ff9c47b740e3,openstack/networking-hyperv,master,I9618fad541917b85a9f18f332d34ff9c47b740e3,Concurrent port bind in child process context,ABANDONED,2015-09-15 07:06:52.000000000,2016-03-05 00:59:46.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 10760}, {'_account_id': 15130}]","[{'number': 1, 'created': '2015-09-15 07:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/4b4e46dd36fcde5a00a4f2bf5220e0e89788faa2', 'message': 'Implement concurrent port bind.\n\nDepends-On: Iaad9d1560863ccf7092f4d01ac8ffc5c08574a0c\nDepends-On: I8e4959ff1ee46582fd6fc37ab5cb208b0d44581f\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 2, 'created': '2015-10-01 10:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/c544339060350dc649b00659e352c5f645baf15d', 'message': 'Implement concurrent port bind.\n\nDepends-On: Iaad9d1560863ccf7092f4d01ac8ffc5c08574a0c\nDepends-On: I8e4959ff1ee46582fd6fc37ab5cb208b0d44581f\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 3, 'created': '2015-10-16 13:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/44d6de6d415fd256cb4d6685095df785eee4a994', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 4, 'created': '2015-10-27 05:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/adf86bfce7ef391d9466c44226ef427b3869397f', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 5, 'created': '2015-10-30 09:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/4a535125cf3bd6e69388249d99c0962f65738ee6', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 6, 'created': '2015-11-18 09:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/7ca8e63e6415ec5e1aeef1d3f5f70423b8dc60ff', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 7, 'created': '2015-11-18 09:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/dda47fc26afa6eb404709997c9faa34354e5794d', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 8, 'created': '2015-11-18 09:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/ddb333eece7e42df6168d6e0b25b05801d1329d4', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 9, 'created': '2015-11-19 09:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/55c9fe62ea4a2e53c2523a34cee32fbab97429e8', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}, {'number': 10, 'created': '2016-01-05 09:38:31.000000000', 'files': ['hyperv/tests/unit/neutron/test_hyperv_neutron_agent.py', 'test-requirements.txt', 'hyperv/neutron/hyperv_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/0381e6e6a3981183211c4e925c929e6defb8ec83', 'message': 'Concurrent port bind in child process context\n\nChanges Includes:\n\n1. _treat_devices_added() method modified to spawn short living child process.\nAfter child process is spawned the parent will record an entry in its cache\nand _update_worker_port_list() method will clear the entry from the cache\nor will a trigger retry.\n\n2. _update_worker_port_list() method will also update the security group\nmap in parent context after port bind success.\n\n3. process_port_worker_context() method will be called from child process\ncontext and will continue the port steps which will also include applying\nthe initial set of security group rules.\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3\n'}]",42,223442,0381e6e6a3981183211c4e925c929e6defb8ec83,34,5,10,10760,,,0,"Concurrent port bind in child process context

Changes Includes:

1. _treat_devices_added() method modified to spawn short living child process.
After child process is spawned the parent will record an entry in its cache
and _update_worker_port_list() method will clear the entry from the cache
or will a trigger retry.

2. _update_worker_port_list() method will also update the security group
map in parent context after port bind success.

3. process_port_worker_context() method will be called from child process
context and will continue the port steps which will also include applying
the initial set of security group rules.

Partially implements: blueprint scale-hyperv-neutron-agent

Change-Id: I9618fad541917b85a9f18f332d34ff9c47b740e3
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/42/223442/10 && git format-patch -1 --stdout FETCH_HEAD,['hyperv/neutron/hyperv_neutron_agent.py'],1,4b4e46dd36fcde5a00a4f2bf5220e0e89788faa2,bp/scale-hyperv-neutron-agent,"import osfrom neutron.agent.windows import hyperv_worker_monitor as hvworker def __init__(self, conf=None, config_flag=None, config_file_path=None, worker_command=None, port_to_process=None): 'worker_count': int, 'worker_retry': int, # Worker process context if worker_command: self._action = worker_command self._port = port_to_process # Parent process context else: self._flag = config_flag self._file_path = config_file_path self._relPath = os.path.dirname(os.path.realpath(__file__)) self._worker_count = agent_conf.get('worker_count', 10) self._worker_retry = agent_conf.get('worker_retry', 3) self._port_bind_worker_dict = {} # added should be equals to number of available worker if len(added): added = self._get_devices_to_schedule_to_worker(added) if len(added) == 0: LOG.info(_(""All %s workers are busy""), self._worker_count) # clear removed port from registered_ports registered_ports = registered_ports - removed # only keep track of existing and ports to be added ports = registered_ports.union(added) if ports == registered_ports: return for dev in devices: try: device_details = self.plugin_rpc.get_device_details( self.context, dev, self.agent_id) except Exception as e: LOG.debug(""Unable to get ports details for "" ""device %(dev)s: %(e)s"", {'dev': dev, 'e': e}) # resync is needed return True if device_details: device = device_details['device'] if 'port_id' in device_details: cmd = ['python', '%s\%s' % (self._relPath, 'worker.py'), self._flag, self._file_path, 'port-bind', device] if device not in self._port_bind_worker_dict: LOG.info(_(""Adding port %s""), device) LOG.debug(_(""Invoke worker for device : %s""), device) worker = hvworker.HyperVWorkerMonitor(cmd, addl_env=None) self._update_network_vswitch_map(device, device_details) worker.start() self._port_bind_worker_dict[device] = worker def process_port_worker_context(self): if self._action == 'port-bind': return self._process_bind_port() else: LOG.error(_(""Worker call with unknown action : %s""), self._action) return False def _process_bind_port(self): device_details = self.plugin_rpc.get_device_details(self.context, self._port, self.agent_id) device = device_details['device'] if 'port_id' in device_details: LOG.info(_LI(""Port %(device)s updated. "" ""Details: %(device_details)s""), {'device': device, 'device_details': device_details}) self._treat_vif_port(device_details['port_id'], device_details['network_id'], device_details['network_type'], device_details['physical_network'], device_details['segmentation_id'], device_details['admin_state_up']) # Update the rule caches for enhanced_rpc in worker process self._update_security_group_detail(self._port) # check if security groups is enabled. # if not, teardown the security group rules if CONF.SECURITYGROUP.enable_security_group: self.sec_groups_agent.prepare_devices_filter([device]) else: self._utils.remove_all_security_rules (device_details['port_id']) self.plugin_rpc.update_device_up(self.context, device, self.agent_id, cfg.CONF.host) def _update_worker_port_list(self, ports=None): for device, worker in self._port_bind_worker_dict.items(): worker_status = worker.get_worker_status() LOG.debug(""Port : %s Success : %s Worker Active : %s"", device, worker_status, worker.is_active) # Remove entry from dict if the result is True if worker_status: LOG.debug(""Port : %s Result : %s clear worker entry"", device, worker_status) worker.stop() self._port_bind_worker_dict.pop(device) # Parent proc must know that SG is enabled for this port if CONF.SECURITYGROUP.enable_security_group: devices = self._update_security_group_detail([device]) for dev in devices.values(): self.sg_plugin.add_to_security_group_map(dev) if CONF.AGENT.enable_metrics_collection: self._utils.enable_port_metrics_collection(device) self._port_metric_retries[device] =\ CONF.AGENT.metrics_max_retries # Reschedule worker if required else: # Before retry make sure port delete is not triggered if ports and 'removed' in ports: # Do not retry binding for removed ports if device in ports['removed']: LOG.info(_(""Port : %s removed clearing worker entry""), device) worker.stop() self._port_bind_worker_dict.pop(device) # Port removed, clear the sg detail from parent if CONF.SECURITYGROUP.enable_security_group: self.sg_plugin.remove_from_security_group_map( device) else: # Retry only if worker process completed with failure if not worker.is_active and not worker_status: worker.stop() if worker.num_of_retry <= self._worker_retry: LOG.info(_(""Re-try binding port : %s""), device) worker.start() else: self._port_bind_worker_dict.pop(device) LOG.info(_(""Stop re-try for port : %s""), device) def _update_network_vswitch_map(self, port, dev_details=None): net_uuid = dev_details['network_id'] vswitch = self._get_vswitch_name(dev_details['network_type'], dev_details['physical_network']) if net_uuid not in self._network_vswitch_map: map_entry = {'network_type': dev_details['network_type'], 'vswitch_name': vswitch, 'ports': [], 'vlan_id': dev_details['segmentation_id']} self._network_vswitch_map[net_uuid] = map_entry else: map_entry = self._network_vswitch_map[net_uuid] map_entry['ports'].append(port) return def _update_security_group_info(self, security_groups, security_group_member_ips): LOG.debug(""Update security group information"") for sg_id, sg_rules in security_groups.items(): self.sg_plugin.update_security_group_rules(sg_id, sg_rules) for remote_sg_id, member_ips in security_group_member_ips.items(): self.sg_plugin.update_security_group_members( remote_sg_id, member_ips) def _update_security_group_detail(self, port): if self.sec_groups_agent.use_enhanced_rpc: devices_info = self.plugin_rpc.security_group_info_for_devices( self.context, list(port)) device = devices_info['devices'] security_groups = devices_info['security_groups'] security_group_member_ips = devices_info['sg_member_ips'] # Update security context in parent for the port self._update_security_group_info(security_groups, security_group_member_ips) else: device = self.plugin_rpc.security_group_rules_for_devices( self.context, list(port)) LOG.debug(""RPC reply received for port : %s Reply : %s"", port, device) return device def _get_devices_to_schedule_to_worker(self, devices): dev = set() avlable_worker = self._worker_count - len(self._port_bind_worker_dict) if avlable_worker: count = 0 for entry in devices: if count == avlable_worker: break dev.add(entry) count = count + 1 return dev # Update the child process cache self._update_worker_port_list(port_info) "," def __init__(self, conf=None): try: devices_details_list = self.plugin_rpc.get_devices_details_list( self.context, devices, self.agent_id) except Exception as e: LOG.debug(""Unable to get ports details for "" ""devices %(devices)s: %(e)s"", {'devices': devices, 'e': e}) # resync is needed return True for device_details in devices_details_list: device = device_details['device'] LOG.info(_LI(""Adding port %s""), device) if 'port_id' in device_details: LOG.info(_LI(""Port %(device)s updated. Details: "" ""%(device_details)s""), {'device': device, 'device_details': device_details}) self._treat_vif_port( device_details['port_id'], device_details['network_id'], device_details['network_type'], device_details['physical_network'], device_details['segmentation_id'], device_details['admin_state_up']) # check if security groups is enabled. # if not, teardown the security group rules if self.enable_security_groups: self.sec_groups_agent.prepare_devices_filter([device]) else: self._utils.remove_all_security_rules( device_details['port_id']) self.plugin_rpc.update_device_up(self.context, device, self.agent_id, self._host)",195,38
openstack%2Fnetworking-hyperv~master~Ib0dc7838544e3d0c34505e79fc431d10b76f18be,openstack/networking-hyperv,master,Ib0dc7838544e3d0c34505e79fc431d10b76f18be,Hyper-V Code Decomposed & Async process support,ABANDONED,2015-10-16 11:19:53.000000000,2016-03-05 00:59:39.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 10760}, {'_account_id': 15130}]","[{'number': 1, 'created': '2015-10-16 11:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/59c8721e6e7ffbb269de14d5628d98549135b55b', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 2, 'created': '2015-10-27 05:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/d304e6a9e681d3e620ad2be041a7d5da8472c5c2', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 3, 'created': '2015-10-31 06:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/c827839b65fdee04aea38a5108a8c3d0020e4c99', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 4, 'created': '2015-10-31 06:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/80d3c94dcd2b40f72acf5bd04c55fddec6a9b343', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 5, 'created': '2015-11-18 04:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/abcbbdaacc593ee33893444095609f137b93daf3', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 6, 'created': '2015-11-18 09:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/942fb6619e24a0afb2ce2fd49c7dfada7d1fb6e7', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}, {'number': 7, 'created': '2016-01-05 09:37:31.000000000', 'files': ['test-requirements.txt', 'hyperv/common/async_process.py', 'hyperv/common/polling.py', 'hyperv/tests/unit/neutron/test_async_process.py', 'hyperv/tests/unit/neutron/test_hyperv_worker_monitor.py', 'hyperv/common/utils.py', 'hyperv/common/hyperv_worker_monitor.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/f0cc538705346ee8089f051e93c86d70d8cd834a', 'message': 'Hyper-V Code Decomposed & Async process support\n\nCode Decompose : Moved code from core neutron to\nHyper-V repository.\nFiles :\nhyperv/common/polling.py\nhyperv/common/utils.py\n\nAsync process support for windows.\nFiles :\nhyperv/common/async_process.py\nhyperv/common/hyperv_worker_monitor.py\n\nPartially implements: blueprint scale-hyperv-neutron-agent\n\nChange-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be\n'}]",10,235859,f0cc538705346ee8089f051e93c86d70d8cd834a,32,5,7,10760,,,0,"Hyper-V Code Decomposed & Async process support

Code Decompose : Moved code from core neutron to
Hyper-V repository.
Files :
hyperv/common/polling.py
hyperv/common/utils.py

Async process support for windows.
Files :
hyperv/common/async_process.py
hyperv/common/hyperv_worker_monitor.py

Partially implements: blueprint scale-hyperv-neutron-agent

Change-Id: Ib0dc7838544e3d0c34505e79fc431d10b76f18be
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/59/235859/4 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/common/async_process.py', 'hyperv/common/polling.py', 'hyperv/common/utils.py', 'hyperv/common/hyperv_worker_monitor.py']",4,59c8721e6e7ffbb269de14d5628d98549135b55b,bp/scale-hyperv-neutron-agent,"# (C) Copyright 2015 HP Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet import re from oslo_log import log as logging from hyperv.common import async_process LOG = logging.getLogger(__name__) errorpattern = re.compile(""^ERROR*"") class HyperVMonitor(async_process.AsyncProcess): """"""Manages an invocation of hyper-v neutron agent's child."""""" def __init__(self, cmd, addl_env=None): super(HyperVMonitor, self).__init__(cmd, addl_env=addl_env) def _read_stdout(self): data = self._process.stdout.readline() if not data: return self._stdout_lines.put(data) LOG.info(_('%s') % data) return data class HyperVWorkerMonitor(HyperVMonitor): """"""Monitors the hyper-v neutron agent's child process."""""" def __init__(self, cmd, addl_env=None): super(HyperVWorkerMonitor, self).__init__(cmd=cmd, addl_env=addl_env) self._worker_exit_status = False self._retries = 0 @property def num_of_retry(self): return self._retries @property def is_active(self): return (self._kill_event and not self._kill_event.ready()) def get_worker_status(self): return self._worker_exit_status def start(self, block=False, timeout=5): super(HyperVWorkerMonitor, self).start() if block: with eventlet.timeout.Timeout(timeout): while not self.is_active: eventlet.sleep() self._retries += 1 def stop(self): super(HyperVWorkerMonitor, self).stop() def _read_stdout(self): data = super(HyperVWorkerMonitor, self)._read_stdout() if data: if errorpattern.match(data): self._worker_exit_status = False else: self._worker_exit_status = True return data ",,336,0
openstack%2Fnetworking-hyperv~master~Iacf2773c1ab97c57147dffc871a5d724c894cdce,openstack/networking-hyperv,master,Iacf2773c1ab97c57147dffc871a5d724c894cdce,Replaces in-branch utils with os_win utils,MERGED,2016-02-18 15:50:50.000000000,2016-03-05 00:58:35.000000000,2016-03-05 00:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2016-02-18 15:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/ffea4ce45fe3134d04c2ac08823c92b73af917ab', 'message': 'WIP: Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 2, 'created': '2016-02-22 16:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/15dfad16521a22371cc6fd168a4d748856f588e9', 'message': 'WIP: Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 3, 'created': '2016-02-23 10:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/86c4c6c3cdd6ec705ecdf8af884beae911800d1a', 'message': 'WIP: Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 4, 'created': '2016-02-29 12:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/837ad57a26112cdde98e5fe9ab0216a8e7fa0301', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 5, 'created': '2016-03-01 12:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/2703b251cbab4b44a8add5da588cc339db99e084', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 6, 'created': '2016-03-01 14:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/41aa545fe66e86d9f3cea2c9a0ef81789ddd19e5', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 7, 'created': '2016-03-01 14:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/6432429ad8051c8a86555a0f6761e1a64c147209', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 8, 'created': '2016-03-02 23:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/67b3bdffc60d3672f440a9310a5b3f9b33247987', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 9, 'created': '2016-03-03 17:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/bd5aa8c7e7428d234afcccb4419f2bf557cad98d', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 10, 'created': '2016-03-03 20:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/d797b4c9f813e327b38d48c0128cbf7a8c701fd2', 'message': 'Replaces in-branch utils with os_win utils\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 11, 'created': '2016-03-04 23:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/7f7c02ca565ab4893ee4ec6b6ecc711b54ba4838', 'message': 'Replaces in-branch utils with os_win utils\n\nMoves the neutron_metadata_address config option to\nhyperv.neutron.config.\nCreates NetworkingHyperVException.\nCleans up hyperv_neutron_agent.\nRefactors nvgre_ops.HyperVNvgreOps.bind_nvgre_network.\n\nImplements: blueprint os-win-usage\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}, {'number': 12, 'created': '2016-03-04 23:36:45.000000000', 'files': ['hyperv/neutron/utilsv2.py', 'hyperv/neutron/utils.py', 'hyperv/neutron/utils_nvgre.py', 'hyperv/neutron/constants.py', 'hyperv/tests/unit/neutron/test_security_groups_driver.py', 'hyperv/tests/unit/neutron/test_utilsfactory.py', 'hyperv/neutron/nvgre_ops.py', 'hyperv/neutron/config.py', 'hyperv/tests/unit/neutron/test_hyperv_neutron_agent.py', 'requirements.txt', 'hyperv/neutron/exception.py', 'hyperv/tests/unit/neutron/test_utilsv2.py', 'hyperv/neutron/utilsfactory.py', 'hyperv/tests/unit/neutron/test_utils.py', 'hyperv/neutron/hyperv_neutron_agent.py', 'hyperv/neutron/security_groups_driver.py', 'hyperv/tests/unit/neutron/test_nvgre_ops.py', 'hyperv/tests/unit/neutron/test_utils_nvgre.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/2afabae54a9deaeaf791942937aa499f095cf15b', 'message': 'Replaces in-branch utils with os_win utils\n\nMoves the neutron_metadata_address config option to\nhyperv.neutron.config.\nCreates NetworkingHyperVException.\nCleans up hyperv_neutron_agent.\nRefactors nvgre_ops.HyperVNvgreOps.bind_nvgre_network.\n\nImplements: blueprint os-win-usage\n\nChange-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce\n'}]",1,281918,2afabae54a9deaeaf791942937aa499f095cf15b,56,4,12,8213,,,0,"Replaces in-branch utils with os_win utils

Moves the neutron_metadata_address config option to
hyperv.neutron.config.
Creates NetworkingHyperVException.
Cleans up hyperv_neutron_agent.
Refactors nvgre_ops.HyperVNvgreOps.bind_nvgre_network.

Implements: blueprint os-win-usage

Change-Id: Iacf2773c1ab97c57147dffc871a5d724c894cdce
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/18/281918/6 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/neutron/utilsv2.py', 'hyperv/neutron/utils.py', 'hyperv/neutron/utils_nvgre.py', 'hyperv/tests/unit/neutron/test_security_groups_driver.py', 'hyperv/tests/unit/neutron/test_utilsfactory.py', 'hyperv/neutron/nvgre_ops.py', 'hyperv/neutron/config.py', 'hyperv/tests/unit/neutron/test_hyperv_neutron_agent.py', 'hyperv/tests/unit/neutron/test_utilsv2.py', 'hyperv/neutron/utilsfactory.py', 'hyperv/tests/unit/neutron/test_utils.py', 'hyperv/neutron/hyperv_neutron_agent.py', 'hyperv/neutron/security_groups_driver.py', 'hyperv/tests/unit/neutron/test_nvgre_ops.py', 'hyperv/tests/unit/neutron/test_utils_nvgre.py']",15,ffea4ce45fe3134d04c2ac08823c92b73af917ab,,,"# Copyright 2015 Cloudbase Solutions SRL # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Unit tests for the Hyper-V NVGRE support. """""" import mock from oslo_config import cfg from hyperv.neutron import constants from hyperv.neutron import utils_nvgre from hyperv.tests import base CONF = cfg.CONF class TestHyperVNvgreUtils(base.BaseTestCase): _FAKE_RDID = 'fake_rdid' _FAKE_NETWORK_NAME = 'fake_network_name' _FAKE_VSID = 9001 _FAKE_DEST_PREFIX = 'fake_dest_prefix' _FAKE_GW_BAD = '10.0.0.1' _FAKE_GW = '10.0.0.2' def setUp(self): super(TestHyperVNvgreUtils, self).setUp() self.utils = utils_nvgre.NvgreUtils() self.utils._utils = mock.MagicMock() self.utils._scimv2 = mock.MagicMock() def _create_mock_binding(self): binding = mock.MagicMock() binding.BindName = self.utils._WNV_BIND_NAME binding.Name = mock.sentinel.fake_network net_binds = self.utils._scimv2.MSFT_NetAdapterBindingSettingData net_binds.return_value = [binding] return binding @mock.patch.object(utils_nvgre.NvgreUtils, 'get_network_iface_ip') @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_address(self, mock_get_iface_index, mock_get_iface_ip): mock_get_iface_index.return_value = mock.sentinel.iface_index mock_get_iface_ip.return_value = (mock.sentinel.iface_ip, mock.sentinel.prefix_len) provider_addr = mock.MagicMock() scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationProviderAddressSettingData obj_class.return_value = [provider_addr] self.utils.create_provider_address(mock.sentinel.fake_network, mock.sentinel.fake_vlan_id) self.assertTrue(provider_addr.Delete_.called) obj_class.new.assert_called_once_with( ProviderAddress=mock.sentinel.iface_ip, VlanID=mock.sentinel.fake_vlan_id, InterfaceIndex=mock.sentinel.iface_index, PrefixLength=mock.sentinel.prefix_len) @mock.patch.object(utils_nvgre.NvgreUtils, 'get_network_iface_ip') @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_address_none(self, mock_get_iface_index, mock_get_iface_ip): mock_get_iface_ip.return_value = (None, None) self.utils.create_provider_address(mock.sentinel.fake_network, mock.sentinel.fake_vlan_id) scimv2 = self.utils._scimv2 self.assertFalse( scimv2.MSFT_NetVirtualizationProviderAddressSettingData.new.called) @mock.patch.object(utils_nvgre.NvgreUtils, 'get_network_iface_ip') @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_address_exists(self, mock_get_iface_index, mock_get_iface_ip): mock_get_iface_index.return_value = mock.sentinel.iface_index mock_get_iface_ip.return_value = (mock.sentinel.iface_ip, mock.sentinel.prefix_len) provider_addr = mock.MagicMock( VlanID=mock.sentinel.fake_vlan_id, InterfaceIndex=mock.sentinel.iface_index) scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationProviderAddressSettingData obj_class.return_value = [provider_addr] self.utils.create_provider_address(mock.sentinel.fake_network, mock.sentinel.fake_vlan_id) self.assertFalse(obj_class.new.called) @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_route(self, mock_get_iface_index): mock_get_iface_index.return_value = mock.sentinel.iface_index self.utils._scimv2.MSFT_NetVirtualizationProviderRouteSettingData = ( mock.MagicMock(return_value=[])) self.utils.create_provider_route(mock.sentinel.fake_network) scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationProviderRouteSettingData obj_class.new.assert_called_once_with( InterfaceIndex=mock.sentinel.iface_index, DestinationPrefix='%s/0' % constants.IPV4_DEFAULT, NextHop=constants.IPV4_DEFAULT) @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_route_none(self, mock_get_iface_index): mock_get_iface_index.return_value = None self.utils.create_provider_route(mock.sentinel.fake_network) scimv2 = self.utils._scimv2 self.assertFalse( scimv2.MSFT_NetVirtualizationProviderRouteSettingData.new.called) @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_iface_index') def test_create_provider_route_exists(self, mock_get_iface_index): mock_get_iface_index.return_value = mock.sentinel.iface_index self.utils._scimv2.MSFT_NetVirtualizationProviderRouteSettingData = ( mock.MagicMock(return_value=[mock.MagicMock()])) self.utils.create_provider_route(mock.sentinel.fake_network) scimv2 = self.utils._scimv2 self.assertFalse( scimv2.MSFT_NetVirtualizationProviderRouteSettingData.new.called) @mock.patch.object(utils_nvgre.NvgreUtils, '_create_cust_route') def _check_create_customer_routes(self, mock_create_route, gateway=None): customer_route = mock.MagicMock() scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationCustomerRouteSettingData obj_class.return_value = [customer_route] self.utils.create_customer_routes( self._FAKE_VSID, self._FAKE_NETWORK_NAME, self._FAKE_DEST_PREFIX, gateway) routes = [(self._FAKE_DEST_PREFIX, constants.IPV4_DEFAULT)] if gateway and gateway[-1] != '1': routes.append(('%s/0' % constants.IPV4_DEFAULT, gateway)) routes.append(('%s/32' % CONF.AGENT.neutron_metadata_address, gateway)) expected_calls = [ mock.call(self._FAKE_VSID, dest_prefix, next_hop, mock.ANY) for dest_prefix, next_hop in routes] self.assertTrue(customer_route.Delete_.called) mock_create_route.assert_has_calls(expected_calls) def test_create_customer_route(self): self._check_create_customer_routes(gateway=self._FAKE_GW) def test_create_customer_route_no_gateway(self): self._check_create_customer_routes() def test_create_customer_route_bad_gateway(self): self._check_create_customer_routes(gateway=self._FAKE_GW_BAD) def test_create_cust_route(self): self.utils._create_cust_route( mock.sentinel.fake_vsid, mock.sentinel.dest_prefix, mock.sentinel.next_hop, self._FAKE_RDID) scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationCustomerRouteSettingData obj_class.new.assert_called_once_with( VirtualSubnetID=mock.sentinel.fake_vsid, DestinationPrefix=mock.sentinel.dest_prefix, NextHop=mock.sentinel.next_hop, Metric=255, RoutingDomainID='{%s}' % self._FAKE_RDID) def _check_create_lookup_record(self, customer_addr, expected_type): lookup = mock.MagicMock() scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationLookupRecordSettingData obj_class.return_value = [lookup] self.utils.create_lookup_record(mock.sentinel.provider_addr, customer_addr, mock.sentinel.mac_addr, mock.sentinel.fake_vsid) self.assertTrue(lookup.Delete_.called) obj_class.new.assert_called_once_with( VirtualSubnetID=mock.sentinel.fake_vsid, Rule=self.utils._TRANSLATE_ENCAP, Type=expected_type, MACAddress=mock.sentinel.mac_addr, CustomerAddress=customer_addr, ProviderAddress=mock.sentinel.provider_addr) def test_create_lookup_record_l2_only(self): self._check_create_lookup_record( constants.IPV4_DEFAULT, self.utils._LOOKUP_RECORD_TYPE_L2_ONLY) def test_create_lookup_record_static(self): self._check_create_lookup_record( mock.sentinel.customer_addr, self.utils._LOOKUP_RECORD_TYPE_STATIC) def test_create_lookup_record_exists(self): lookup = mock.MagicMock(VirtualSubnetID=mock.sentinel.fake_vsid, ProviderAddress=mock.sentinel.provider_addr, CustomerAddress=mock.sentinel.customer_addr, MACAddress=mock.sentinel.mac_addr) scimv2 = self.utils._scimv2 obj_class = scimv2.MSFT_NetVirtualizationLookupRecordSettingData obj_class.return_value = [lookup] self.utils.create_lookup_record(mock.sentinel.provider_addr, mock.sentinel.customer_addr, mock.sentinel.mac_addr, mock.sentinel.fake_vsid) self.assertFalse(obj_class.new.called) def test_get_network_iface_index(self): fake_network = mock.MagicMock(InterfaceIndex=mock.sentinel.iface_index) self.utils._scimv2.MSFT_NetAdapter.return_value = [fake_network] description = ( self.utils._utils.get_vswitch_external_network_name.return_value) index = self.utils._get_network_iface_index(mock.sentinel.fake_network) self.assertEqual(mock.sentinel.iface_index, index) self.assertIn(mock.sentinel.fake_network, self.utils._net_if_indexes) self.utils._scimv2.MSFT_NetAdapter.assert_called_once_with( InterfaceDescription=description) def test_get_network_iface_index_cached(self): self.utils._net_if_indexes[mock.sentinel.fake_network] = ( mock.sentinel.iface_index) index = self.utils._get_network_iface_index(mock.sentinel.fake_network) self.assertEqual(mock.sentinel.iface_index, index) self.assertFalse(self.utils._scimv2.MSFT_NetAdapter.called) @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_ifaces_by_name') def test_get_network_iface_ip(self, mock_get_net_ifaces): fake_network = mock.MagicMock( InterfaceIndex=mock.sentinel.iface_index, DriverDescription=self.utils._HYPERV_VIRT_ADAPTER) mock_get_net_ifaces.return_value = [fake_network] fake_netip = mock.MagicMock(IPAddress=mock.sentinel.provider_addr, PrefixLength=mock.sentinel.prefix_len) self.utils._scimv2.MSFT_NetIPAddress.return_value = [fake_netip] pair = self.utils.get_network_iface_ip(mock.sentinel.fake_network) self.assertEqual( (mock.sentinel.provider_addr, mock.sentinel.prefix_len), pair) @mock.patch.object(utils_nvgre.NvgreUtils, '_get_network_ifaces_by_name') def test_get_network_iface_ip_none(self, mock_get_net_ifaces): mock_get_net_ifaces.return_value = [] pair = self.utils.get_network_iface_ip(mock.sentinel.fake_network) self.assertEqual((None, None), pair) ",53,2544
openstack%2Fnetworking-hyperv~master~Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5,openstack/networking-hyperv,master,Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5,Checks if port features are being added,ABANDONED,2016-01-11 09:26:53.000000000,2016-03-05 00:54:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2016-01-11 09:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/a062da19e4842eb45fcd33ff8ce8ce23ccb2919a', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 2, 'created': '2016-01-12 12:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/129b14c3527fd9215853e57f0c402dad588e4bce', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 3, 'created': '2016-01-12 13:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/0853433acb9f7c8584136016598ebbec778377cd', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 4, 'created': '2016-01-13 10:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/d34626338d52e09c4bce6f47f9e346864723a440', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 5, 'created': '2016-01-13 13:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/9e72076b95a7678305424e028420296d33d34aab', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 6, 'created': '2016-01-21 18:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/9773151d2e9eecb35f21483ce0bdc824648d7eed', 'message': 'Checks if the VLAN has been properly set\n\nThere is a small chance that the VLAN is not properly set\nto a vSwitch port, even though Hyper-V reports the operation\nas succesful. Listening for the VLAN WMI object creation can help\ndetect this issue.\n\nCloses-Bug: #1536742\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 7, 'created': '2016-01-22 22:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/b4bc4d812f840b6ea64845edc2b598779a63d67f', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 8, 'created': '2016-01-24 22:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/ecc30436629b7ded2578ef6c5f2665c96292ca6d', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 9, 'created': '2016-01-24 22:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/f0e57260838192ffa30dc4f093872faa2fb0ce33', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 10, 'created': '2016-01-24 22:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/0a53e7bf2335f5e8e485ee4b7405a367a55c886d', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}, {'number': 11, 'created': '2016-02-12 03:09:16.000000000', 'files': ['hyperv/neutron/utilsv2.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/f45266d10506428119ac123baebed6d6c4cb83ca', 'message': 'Checks if port features are being added\n\nChange-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5\n'}]",3,265728,f45266d10506428119ac123baebed6d6c4cb83ca,49,4,11,8213,,,0,"Checks if port features are being added

Change-Id: Ib7ff827df70e730ccaa318b69ef52a4a254ef9f5
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/28/265728/11 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/neutron/utilsv2.py', 'hyperv/tests/unit/neutron/test_utilsv2.py']",2,a062da19e4842eb45fcd33ff8ce8ce23ccb2919a,bug/1536742," def test_get_event_wql_query(self): expected = (""SELECT * FROM %(event_type)s WITHIN %(timeframe)s "" ""WHERE TargetInstance ISA '%(class)s' AND "" ""%(like)s"" % {'class': ""FakeClass"", 'event_type': self._utils.EVENT_TYPE_CREATE, 'like': ""TargetInstance.foo LIKE bar%"", 'timeframe': 2}) query = self._utils._get_event_wql_query( ""FakeClass"", self._utils.EVENT_TYPE_CREATE, like=dict(foo=""bar"")) @mock.patch.object(utilsv2, 'wmi', create=True) def _check_add_virt_feature_listener(self, mock_wmi, error=True): mock_wmi.x_wmi = Exception mock_svc = self._utils._conn.Msvm_VirtualSystemManagementService()[0] mock_svc.AddFeatureSettings.return_value = ( mock.sentinel.job_path, mock.sentinel.out_res, self._FAKE_RET_VAL) element = mock.MagicMock() feature = mock.MagicMock() listener = mock.MagicMock() if error: listener.side_effect = mock_wmi.x_wmi if error: self.assertRaises(utils.HyperVException, self._utils._add_virt_feature, element, feature, listener) else: self._utils._add_virt_feature(element, feature, listener) def test_add_virt_feature_listener_pass(self): self._check_add_virt_feature_listener(error=False) def test_add_virt_feature_listener_fail(self): self._check_add_virt_feature_listener() @mock.patch.object(utilsv2.HyperVUtilsV2, '_get_event_wql_query') def test_set_vswitch_port_vlan_id(self, mock_get_default_sd, mock_get_event_query): vlan_class = self._utils._conn.Msvm_EthernetSwitchPortVlanSettingData vlan_class.watch_for.assert_called_once_with( mock_get_event_query.return_value)"," def test_set_vswitch_port_vlan_id(self, mock_get_default_sd):",120,5
openstack%2Fpuppet-openstack-integration~master~I8306a8b3c9111734095902657d6de42b9a2c3907,openstack/puppet-openstack-integration,master,I8306a8b3c9111734095902657d6de42b9a2c3907,Bump RDO repo to 2016-03-04 00:00,MERGED,2016-03-04 08:58:20.000000000,2016-03-05 00:43:23.000000000,2016-03-05 00:43:23.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}]","[{'number': 1, 'created': '2016-03-04 08:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/db3d48161feec901a514379274ea0f9a147217b0', 'message': 'Bump RDO repo to 2016-03-04 08:41\n\nTrunk Updating RDO repo to 95ae4cbf0d843e145acade2336f1a75bf88cde4b.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 2, 'created': '2016-03-04 09:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/bbf1739b9dc328f447271d486fd7bd482c504911', 'message': '[WIP] Bump RDO repo to 2016-03-03 10:18 (bisect)\n\nTrunk Updating RDO repo to 54fffcd296e393f00264c2ce72fd03980c2cfd14.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 3, 'created': '2016-03-04 10:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7ae4fc812e824d6777bc82b7883ee7df18479a32', 'message': '[WIP] Bump RDO repo to 2016-03-03 19:03 (bisect)\n\nTrunk Updating RDO repo to f8d540f7835a8eae7dc6c2e6ce6ca0aa1f64f894.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 4, 'created': '2016-03-04 11:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/624c765063a40ef96c4284cf9b5c8c5f52f59e20', 'message': '[WIP] Bump RDO repo to 2016-03-04 00:13 (bisect)\n\nTrunk Updating RDO repo to a3a877a4c2cac886c786493ae6b8c88e4a33cc46.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 5, 'created': '2016-03-04 11:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/14fb854076a31dc5135c5028c87a039622e9572c', 'message': '[WIP] Bump RDO repo to 2016-03-03 21:12 (bisect)\n\nTrunk Updating RDO repo to 1c1b591ff000896a94d97a381790bedf2119d7cf.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 6, 'created': '2016-03-04 12:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/59ccd9c45e5b719cd5708476ee471a5e96b29598', 'message': '[WIP] Bump RDO repo to 2016-03-03 23:06 (bisect)\n\nTrunk Updating RDO repo to e33f8b39c0922584e785732b94c6a5dbdcaffeba.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 7, 'created': '2016-03-04 13:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/dcfaf64c6528d5b7c5de6c061d2618fee3833f7e', 'message': '[WIP] Bump RDO repo to 2016-03-03 23:35 (bisect)\n\nTrunk Updating RDO repo to f4cfbf2fbc43a1635822ef7c193fcd393912355b.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 8, 'created': '2016-03-04 14:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/9bcb47819ad786aeea7b150ee22eae30ecd3aaef', 'message': '[WIP] Bump RDO repo to 2016-03-04 00:00 (bisect)\n\nTrunk Updating RDO repo to 8d57a1e2ab8aa779759ed0e290db098c77f833e0.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}, {'number': 9, 'created': '2016-03-04 16:18:13.000000000', 'files': ['manifests/repos.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/262a10d99b8e553bb828e0026bd7c6047a70dcc5', 'message': 'Bump RDO repo to 2016-03-04 00:00\n\nTrunk Updating RDO repo to 8d57a1e2ab8aa779759ed0e290db098c77f833e0.\n\nChange-Id: I8306a8b3c9111734095902657d6de42b9a2c3907\n'}]",1,288312,262a10d99b8e553bb828e0026bd7c6047a70dcc5,32,3,9,6645,,,0,"Bump RDO repo to 2016-03-04 00:00

Trunk Updating RDO repo to 8d57a1e2ab8aa779759ed0e290db098c77f833e0.

Change-Id: I8306a8b3c9111734095902657d6de42b9a2c3907
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/12/288312/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/repos.pp'],1,db3d48161feec901a514379274ea0f9a147217b0,bump/rdo," 'baseurl' => 'http://46.231.133.253/delorean/95/ae/95ae4cbf0d843e145acade2336f1a75bf88cde4b_c28e30d0/',"," 'baseurl' => 'https://trunk.rdoproject.org/centos7/e4/60/e460518d2d1c503725d799c2ce05c67e20acf2e4_ec46ffa0/',",1,1
openstack%2Fgrenade~master~Ie72b2ccdc85221425559a55b09e8486cc7019855,openstack/grenade,master,Ie72b2ccdc85221425559a55b09e8486cc7019855,Be more aggressive about timeout handling on ssh,MERGED,2016-03-03 14:37:06.000000000,2016-03-05 00:43:11.000000000,2016-03-05 00:43:11.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5196}, {'_account_id': 7166}]","[{'number': 1, 'created': '2016-03-03 14:37:06.000000000', 'files': ['projects/70_cinder/resources.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/009c1e1b5ac12c2d6872003756177432fa5d52d9', 'message': ""Be more aggressive about timeout handling on ssh\n\nOur ssh tests for cinder assume that ssh calls will return\nimmediately, however, if there is a fundamental network issue (like a\nbad mtu). We'll get long hangs here (up to 15 minutes). This can turn\nthis 30 second test into hours.\n\nWe can be more aggressive in both timing out an individual command as\nwell as keeping track of time better.\n\nChange-Id: Ie72b2ccdc85221425559a55b09e8486cc7019855\nCloses-Bug: #1552728\n""}]",0,287838,009c1e1b5ac12c2d6872003756177432fa5d52d9,14,4,1,2750,,,0,"Be more aggressive about timeout handling on ssh

Our ssh tests for cinder assume that ssh calls will return
immediately, however, if there is a fundamental network issue (like a
bad mtu). We'll get long hangs here (up to 15 minutes). This can turn
this 30 second test into hours.

We can be more aggressive in both timing out an individual command as
well as keeping track of time better.

Change-Id: Ie72b2ccdc85221425559a55b09e8486cc7019855
Closes-Bug: #1552728
",git fetch https://review.opendev.org/openstack/grenade refs/changes/38/287838/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/70_cinder/resources.sh'],1,009c1e1b5ac12c2d6872003756177432fa5d52d9,bug_1552728," local start=$(date +%s) timeout 30 $FSSH -i $CINDER_KEY_FILE cirros@$ip \ ""echo '$CINDER_STATE' > $CINDER_STATE_FILE"" local end=$(date +%s) local took=$((end - start)) timeleft=$((timeleft - took)) if [[ $timeleft -le 0 ]]; then"," $FSSH -i $CINDER_KEY_FILE cirros@$ip \ ""echo '$CINDER_STATE' > $CINDER_STATE_FILE"" timeleft=$((timeleft - 1)) if [[ $timeleft == 0 ]]; then",7,4
openstack%2Fhorizon~stable%2Fliberty~I75cec674516b07e141d74729b545e3d2cadee82d,openstack/horizon,stable/liberty,I75cec674516b07e141d74729b545e3d2cadee82d,exclude subnets without gateway in create interface,MERGED,2016-02-22 10:30:40.000000000,2016-03-05 00:42:54.000000000,2016-03-05 00:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 8358}, {'_account_id': 12281}]","[{'number': 1, 'created': '2016-02-22 10:30:40.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/ports/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/97994ae519c2fd0ba86d601d341e2c73754588d4', 'message': ""exclude subnets without gateway in create interface\n\nIn create interface form, if we select the subnet which\ndon't have gateway ip, the create will fail.\n\nwe can remove the subnets which don't have gateway ip\nfrom the sebnet options to prevent the unnecessary\nserver call.\n\nChange-Id: I75cec674516b07e141d74729b545e3d2cadee82d\nCloses-Bug: #1478939\n(cherry picked from commit ce65691bfc876400025eb8ba2ae18f8ff96e18f6)\n""}]",0,283027,97994ae519c2fd0ba86d601d341e2c73754588d4,11,7,1,10442,,,0,"exclude subnets without gateway in create interface

In create interface form, if we select the subnet which
don't have gateway ip, the create will fail.

we can remove the subnets which don't have gateway ip
from the sebnet options to prevent the unnecessary
server call.

Change-Id: I75cec674516b07e141d74729b545e3d2cadee82d
Closes-Bug: #1478939
(cherry picked from commit ce65691bfc876400025eb8ba2ae18f8ff96e18f6)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/283027/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/routers/ports/forms.py'],1,97994ae519c2fd0ba86d601d341e2c73754588d4,bug/1478939, if subnet.id not in router_subnet_ids and subnet.gateway_ip], if subnet.id not in router_subnet_ids],2,1
openstack%2Fkeystone~master~I43ecea73d8c4ee70dd861d010282affb2ec3232a,openstack/keystone,master,I43ecea73d8c4ee70dd861d010282affb2ec3232a,Split assignment backend tests,MERGED,2016-01-15 19:47:29.000000000,2016-03-05 00:42:39.000000000,2016-03-05 00:42:38.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}, {'_account_id': 13055}, {'_account_id': 17026}, {'_account_id': 17123}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-01-15 19:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/80e95072984df75b4cddd1a975587a189993ee07', 'message': 'WIP: Extract assignment backend tests to own file\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 2, 'created': '2016-01-16 13:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e4598f3afedbcde76792ccbd1e547236d62c49d', 'message': 'WIP: Extract assignment backend tests to own file\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 3, 'created': '2016-01-16 14:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b4225e632b3c8155ca4d14665322666d1652572f', 'message': 'Extract assignment backend tests to its own file\n\ntest_backend.py is a huge test file (over 6k lines), making it hard to\nunderstand what cases are currently covered.\n\nThis change proposes to extract assignment-related tests to its own\nfile: test_assignment_backend.py\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 4, 'created': '2016-01-16 14:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dffecbecd877c64fc4757b21e1f1c4be6caa018d', 'message': 'Extract assignment backend tests to its own file\n\ntest_backend.py is a huge test file (over 6k lines), making it hard to\nunderstand what cases are currently covered.\n\nThis change proposes to extract assignment-related tests to its own\nfile: test_assignment_backend.py\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 5, 'created': '2016-01-16 19:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b5d4e5265dc5eb61af87540184e9a0e80a5e347', 'message': 'Extract assignment backend tests to its own file\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract assignment-related tests to its\ndirectory under unit/backend/assignment.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 6, 'created': '2016-01-16 19:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/47dd28f82f0c931109e967b410240eab0f382a15', 'message': 'Extract assignment backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract assignment-related tests to its\ndirectory under unit/backend/assignment.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 7, 'created': '2016-01-18 18:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a93d78113bf95ac16a0c96506a86eca233a24d16', 'message': 'Split assignment backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract assignment-related tests to its\ndirectory under unit/assignment.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 8, 'created': '2016-01-18 18:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9fa9bfff3839c74f7958b75705c0c9842446563', 'message': 'Split assignment backend tests\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis change proposes to extract assignment-related tests to its\ndirectory under unit/assignment.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n'}, {'number': 9, 'created': '2016-01-18 20:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6531fc7082a27722b2ba9aa242fc6de181a3030', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 10, 'created': '2016-01-27 13:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e2eb67e60784eb6ad87086b56b25a09c2e2f26b6', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 11, 'created': '2016-01-28 13:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cf423c772b408ab792e7d8b65ec9e998dfd324e', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 12, 'created': '2016-01-28 21:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dfd3c741338e076e3847b9cf4781d8576d0f6d04', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 13, 'created': '2016-03-04 13:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/97e4eca1bdf23d34b475bd5252e2e57e5079d7ab', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 14, 'created': '2016-03-04 15:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0dbc8d957cd52ac5a4af037eec90a478ba600d7e', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 15, 'created': '2016-03-04 16:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/95ecc0ef5317a6a22523867992ed9fea175f716c', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}, {'number': 16, 'created': '2016-03-04 18:24:56.000000000', 'files': ['keystone/tests/unit/assignment/__init__.py', 'keystone/tests/unit/assignment/test_backends.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/bcf13b5daa43e0d0e82c3fa6687d237cd591fc57', 'message': ""Split assignment backend tests\n\nWhere to put a new test ? Is this behavior covered yet ? These and\nother questions require understanding the test coverage to be answered.\n\ntest_backend.py is a huge test file, making it hard to understand what\ncases are currently covered for each backend.\n\nThis chain of changes proposes to split it by the backends it covers;\nthe tests will be placed into 'unit/{backend}/test_backends.py'.\n\nThis change splits the tests for the assignment backend.\n\nChange-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a\n""}]",6,268307,bcf13b5daa43e0d0e82c3fa6687d237cd591fc57,53,7,16,17860,,,0,"Split assignment backend tests

Where to put a new test ? Is this behavior covered yet ? These and
other questions require understanding the test coverage to be answered.

test_backend.py is a huge test file, making it hard to understand what
cases are currently covered for each backend.

This chain of changes proposes to split it by the backends it covers;
the tests will be placed into 'unit/{backend}/test_backends.py'.

This change splits the tests for the assignment backend.

Change-Id: I43ecea73d8c4ee70dd861d010282affb2ec3232a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/268307/16 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/tests/unit/test_assignment_backend.py', 'keystone/tests/unit/test_backend.py']",4,80e95072984df75b4cddd1a975587a189993ee07,split-backend-tests,class IdentityTests(object):,"class AssignmentTestHelperMixin(object): """"""Mixin class to aid testing of assignments. This class supports data driven test plans that enable: - Creation of initial entities, such as domains, users, groups, projects and roles - Creation of assignments referencing the above entities - A set of input parameters and expected outputs to list_role_assignments based on the above test data A test plan is a dict of the form: test_plan = { entities: details and number of entities, group_memberships: group-user entity memberships, assignments: list of assignments to create, tests: list of pairs of input params and expected outputs} An example test plan: test_plan = { # First, create the entities required. Entities are specified by # a dict with the key being the entity type and the value an # entity specification which can be one of: # # - a simple number, e.g. {'users': 3} creates 3 users # - a dict where more information regarding the contents of the entity # is required, e.g. {'domains' : {'users : 3}} creates a domain # with three users # - a list of entity specifications if multiple are required # # The following creates a domain that contains a single user, group and # project, as well as creating three roles. 'entities': {'domains': {'users': 1, 'groups': 1, 'projects': 1}, 'roles': 3}, # If it is required that an existing domain be used for the new # entities, then the id of that domain can be included in the # domain dict. For example, if alternatively we wanted to add 3 users # to the default domain, add a second domain containing 3 projects as # well as 5 additional empty domains, the entities would be defined as: # # 'entities': {'domains': [{'id': DEFAULT_DOMAIN, 'users': 3}, # {'projects': 3}, 5]}, # # A project hierarchy can be specified within the 'projects' section by # nesting the 'project' key, for example to create a project with three # sub-projects you would use: 'projects': {'project': 3} # A more complex hierarchy can also be defined, for example the # following would define three projects each containing a # sub-project, each of which contain a further three sub-projects. 'projects': [{'project': {'project': 3}}, {'project': {'project': 3}}, {'project': {'project': 3}}] # A list of groups and their members. In this case make users with # index 0 and 1 members of group with index 0. Users and Groups are # indexed in the order they appear in the 'entities' key above. 'group_memberships': [{'group': 0, 'users': [0, 1]}] # Next, create assignments between the entities, referencing the # entities by index, i.e. 'user': 0 refers to user[0]. Entities are # indexed in the order they appear in the 'entities' key above within # their entity type. 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'group': 0, 'role': 2, 'domain': 0}, {'user': 0, 'role': 2, 'project': 0}], # Finally, define an array of tests where list_role_assignment() is # called with the given input parameters and the results are then # confirmed to be as given in 'results'. Again, all entities are # referenced by index. 'tests': [ {'params': {}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'group': 0, 'role': 2, 'domain': 0}, {'user': 0, 'role': 2, 'project': 0}]}, {'params': {'role': 2}, 'results': [{'group': 0, 'role': 2, 'domain': 0}, {'user': 0, 'role': 2, 'project': 0}]}] # The 'params' key also supports the 'effective' and # 'inherited_to_projects' options to list_role_assignments.} """""" def _handle_project_spec(self, test_data, domain_id, project_spec, parent_id=None): """"""Handle the creation of a project or hierarchy of projects. project_spec may either be a count of the number of projects to create, or it may be a list of the form: [{'project': project_spec}, {'project': project_spec}, ...] This method is called recursively to handle the creation of a hierarchy of projects. """""" def _create_project(domain_id, parent_id): new_project = unit.new_project_ref(domain_id=domain_id, parent_id=parent_id) new_project = self.resource_api.create_project(new_project['id'], new_project) return new_project if isinstance(project_spec, list): for this_spec in project_spec: self._handle_project_spec( test_data, domain_id, this_spec, parent_id=parent_id) elif isinstance(project_spec, dict): new_proj = _create_project(domain_id, parent_id) test_data['projects'].append(new_proj) self._handle_project_spec( test_data, domain_id, project_spec['project'], parent_id=new_proj['id']) else: for _ in range(project_spec): test_data['projects'].append( _create_project(domain_id, parent_id)) def _handle_domain_spec(self, test_data, domain_spec): """"""Handle the creation of domains and their contents. domain_spec may either be a count of the number of empty domains to create, a dict describing the domain contents, or a list of domain_specs. In the case when a list is provided, this method calls itself recursively to handle the list elements. This method will insert any entities created into test_data """""" def _create_domain(domain_id=None): if domain_id is None: new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) return new_domain else: # The test plan specified an existing domain to use return self.resource_api.get_domain(domain_id) def _create_entity_in_domain(entity_type, domain_id): """"""Create a user or group entity in the domain."""""" if entity_type == 'users': new_entity = unit.new_user_ref(domain_id=domain_id) new_entity = self.identity_api.create_user(new_entity) elif entity_type == 'groups': new_entity = unit.new_group_ref(domain_id=domain_id) new_entity = self.identity_api.create_group(new_entity) else: # Must be a bad test plan raise exception.NotImplemented() return new_entity if isinstance(domain_spec, list): for x in domain_spec: self._handle_domain_spec(test_data, x) elif isinstance(domain_spec, dict): # If there is a domain ID specified, then use it the_domain = _create_domain(domain_spec.get('id')) test_data['domains'].append(the_domain) for entity_type, value in domain_spec.items(): if entity_type == 'id': # We already used this above to determine whether to # use and existing domain continue if entity_type == 'projects': # If it's projects, we need to handle the potential # specification of a project hierarchy self._handle_project_spec( test_data, the_domain['id'], value) else: # It's a count of number of entities for _ in range(value): test_data[entity_type].append( _create_entity_in_domain( entity_type, the_domain['id'])) else: for _ in range(domain_spec): test_data['domains'].append(_create_domain()) def create_entities(self, entity_pattern): """"""Create the entities specified in the test plan. Process the 'entities' key in the test plan, creating the requested entities. Each created entity will be added to the array of entities stored in the returned test_data object, e.g.: test_data['users'] = [user[0], user[1]....] """""" def _create_role(): new_role = unit.new_role_ref() return self.role_api.create_role(new_role['id'], new_role) test_data = {} for entity in ['users', 'groups', 'domains', 'projects', 'roles']: test_data[entity] = [] # Create any domains requested and, if specified, any entities within # those domains if 'domains' in entity_pattern: self._handle_domain_spec(test_data, entity_pattern['domains']) # Create any roles requested if 'roles' in entity_pattern: for _ in range(entity_pattern['roles']): test_data['roles'].append(_create_role()) return test_data def _convert_entity_shorthand(self, key, shorthand_data, reference_data): """"""Convert a shorthand entity description into a full ID reference. In test plan definitions, we allow a shorthand for referencing to an entity of the form: 'user': 0 which is actually shorthand for: 'user_id': reference_data['users'][0]['id'] This method converts the shorthand version into the full reference. """""" expanded_key = '%s_id' % key reference_index = '%ss' % key index_value = ( reference_data[reference_index][shorthand_data[key]]['id']) return expanded_key, index_value def create_group_memberships(self, group_pattern, test_data): """"""Create the group memberships specified in the test plan."""""" for group_spec in group_pattern: # Each membership specification is a dict of the form: # # {'group': 0, 'users': [list of user indexes]} # # Add all users in the list to the specified group, first # converting from index to full entity ID. group_value = test_data['groups'][group_spec['group']]['id'] for user_index in group_spec['users']: user_value = test_data['users'][user_index]['id'] self.identity_api.add_user_to_group(user_value, group_value) return test_data def create_assignments(self, assignment_pattern, test_data): """"""Create the assignments specified in the test plan."""""" # First store how many assignments are already in the system, # so during the tests we can check the number of new assignments # created. test_data['initial_assignment_count'] = ( len(self.assignment_api.list_role_assignments())) # Now create the new assignments in the test plan for assignment in assignment_pattern: # Each assignment is a dict of the form: # # { 'user': 0, 'project':1, 'role': 6} # # where the value of each item is the index into the array of # entities created earlier. # # We process the assignment dict to create the args required to # make the create_grant() call. args = {} for param in assignment: if param == 'inherited_to_projects': args[param] = assignment[param] else: # Turn 'entity : 0' into 'entity_id = ac6736ba873d' # where entity in user, group, project or domain key, value = self._convert_entity_shorthand( param, assignment, test_data) args[key] = value self.assignment_api.create_grant(**args) return test_data def execute_assignment_cases(self, test_plan, test_data): """"""Execute the test plan, based on the created test_data."""""" def check_results(expected, actual, param_arg_count): if param_arg_count == 0: # It was an unfiltered call, so default fixture assignments # might be polluting our answer - so we take into account # how many assignments there were before the test. self.assertEqual( len(expected) + test_data['initial_assignment_count'], len(actual)) else: self.assertThat(actual, matchers.HasLength(len(expected))) for each_expected in expected: expected_assignment = {} for param in each_expected: if param == 'inherited_to_projects': expected_assignment[param] = each_expected[param] elif param == 'indirect': # We're expecting the result to contain an indirect # dict with the details how the role came to be placed # on this entity - so convert the key/value pairs of # that dict into real entity references. indirect_term = {} for indirect_param in each_expected[param]: key, value = self._convert_entity_shorthand( indirect_param, each_expected[param], test_data) indirect_term[key] = value expected_assignment[param] = indirect_term else: # Convert a simple shorthand entry into a full # entity reference key, value = self._convert_entity_shorthand( param, each_expected, test_data) expected_assignment[key] = value self.assertIn(expected_assignment, actual) # Go through each test in the array, processing the input params, which # we build into an args dict, and then call list_role_assignments. Then # check the results against those specified in the test plan. for test in test_plan.get('tests', []): args = {} for param in test['params']: if param in ['effective', 'inherited', 'include_subtree']: # Just pass the value into the args args[param] = test['params'][param] else: # Turn 'entity : 0' into 'entity_id = ac6736ba873d' # where entity in user, group, project or domain key, value = self._convert_entity_shorthand( param, test['params'], test_data) args[key] = value results = self.assignment_api.list_role_assignments(**args) check_results(test['results'], results, len(args)) def execute_assignment_plan(self, test_plan): """"""Create entities, assignments and execute the test plan. The standard method to call to create entities and assignments and execute the tests as specified in the test_plan. The test_data dict is returned so that, if required, the caller can execute additional manual tests with the entities and assignments created. """""" test_data = self.create_entities(test_plan['entities']) if 'group_memberships' in test_plan: self.create_group_memberships(test_plan['group_memberships'], test_data) if 'assignments' in test_plan: test_data = self.create_assignments(test_plan['assignments'], test_data) self.execute_assignment_cases(test_plan, test_data) return test_data class IdentityTests(AssignmentTestHelperMixin): def test_project_add_and_remove_user_role(self): user_ids = self.assignment_api.list_user_ids_for_project( self.tenant_bar['id']) self.assertNotIn(self.user_two['id'], user_ids) self.assignment_api.add_role_to_user_and_project( tenant_id=self.tenant_bar['id'], user_id=self.user_two['id'], role_id=self.role_other['id']) user_ids = self.assignment_api.list_user_ids_for_project( self.tenant_bar['id']) self.assertIn(self.user_two['id'], user_ids) self.assignment_api.remove_role_from_user_and_project( tenant_id=self.tenant_bar['id'], user_id=self.user_two['id'], role_id=self.role_other['id']) user_ids = self.assignment_api.list_user_ids_for_project( self.tenant_bar['id']) self.assertNotIn(self.user_two['id'], user_ids) def test_remove_user_role_not_assigned(self): # Expect failure if attempt to remove a role that was never assigned to # the user. self.assertRaises(exception.RoleNotFound, self.assignment_api. remove_role_from_user_and_project, tenant_id=self.tenant_bar['id'], user_id=self.user_two['id'], role_id=self.role_other['id']) def test_list_user_ids_for_project(self): user_ids = self.assignment_api.list_user_ids_for_project( self.tenant_baz['id']) self.assertEqual(2, len(user_ids)) self.assertIn(self.user_two['id'], user_ids) self.assertIn(self.user_badguy['id'], user_ids) def test_list_user_ids_for_project_no_duplicates(self): # Create user user_ref = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) user_ref = self.identity_api.create_user(user_ref) # Create project project_ref = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project( project_ref['id'], project_ref) # Create 2 roles and give user each role in project for i in range(2): role_ref = unit.new_role_ref() self.role_api.create_role(role_ref['id'], role_ref) self.assignment_api.add_role_to_user_and_project( user_id=user_ref['id'], tenant_id=project_ref['id'], role_id=role_ref['id']) # Get the list of user_ids in project user_ids = self.assignment_api.list_user_ids_for_project( project_ref['id']) # Ensure the user is only returned once self.assertEqual(1, len(user_ids)) def test_get_project_user_ids_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.assignment_api.list_user_ids_for_project, uuid.uuid4().hex) def test_list_role_assignments_unfiltered(self): """"""Test unfiltered listing of role assignments."""""" test_plan = { # Create a domain, with a user, group & project 'entities': {'domains': {'users': 1, 'groups': 1, 'projects': 1}, 'roles': 3}, # Create a grant of each type (user/group on project/domain) 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'group': 0, 'role': 2, 'domain': 0}, {'group': 0, 'role': 2, 'project': 0}], 'tests': [ # Check that we get back the 4 assignments {'params': {}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'group': 0, 'role': 2, 'domain': 0}, {'group': 0, 'role': 2, 'project': 0}]} ] } self.execute_assignment_plan(test_plan) def test_list_role_assignments_filtered_by_role(self): """"""Test listing of role assignments filtered by role ID."""""" test_plan = { # Create a user, group & project in the default domain 'entities': {'domains': {'id': DEFAULT_DOMAIN_ID, 'users': 1, 'groups': 1, 'projects': 1}, 'roles': 3}, # Create a grant of each type (user/group on project/domain) 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'group': 0, 'role': 2, 'domain': 0}, {'group': 0, 'role': 2, 'project': 0}], 'tests': [ # Check that when filtering by role, we only get back those # that match {'params': {'role': 2}, 'results': [{'group': 0, 'role': 2, 'domain': 0}, {'group': 0, 'role': 2, 'project': 0}]} ] } self.execute_assignment_plan(test_plan) def test_list_group_role_assignment(self): # When a group role assignment is created and the role assignments are # listed then the group role assignment is included in the list. test_plan = { 'entities': {'domains': {'id': DEFAULT_DOMAIN_ID, 'groups': 1, 'projects': 1}, 'roles': 1}, 'assignments': [{'group': 0, 'role': 0, 'project': 0}], 'tests': [ {'params': {}, 'results': [{'group': 0, 'role': 0, 'project': 0}]} ] } self.execute_assignment_plan(test_plan) def test_list_role_assignments_bad_role(self): assignment_list = self.assignment_api.list_role_assignments( role_id=uuid.uuid4().hex) self.assertEqual([], assignment_list) def test_add_duplicate_role_grant(self): roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertNotIn(self.role_admin['id'], roles_ref) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], self.role_admin['id']) self.assertRaises(exception.Conflict, self.assignment_api.add_role_to_user_and_project, self.user_foo['id'], self.tenant_bar['id'], self.role_admin['id']) def test_get_role_by_user_and_project_with_user_in_group(self): """"""Test for get role by user and project, user was added into a group. Test Plan: - Create a user, a project & a group, add this user to group - Create roles and grant them to user and project - Check the role list get by the user and project was as expected """""" user_ref = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) user_ref = self.identity_api.create_user(user_ref) project_ref = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(project_ref['id'], project_ref) group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) group_id = self.identity_api.create_group(group)['id'] self.identity_api.add_user_to_group(user_ref['id'], group_id) role_ref_list = [] for i in range(2): role_ref = unit.new_role_ref() self.role_api.create_role(role_ref['id'], role_ref) role_ref_list.append(role_ref) self.assignment_api.add_role_to_user_and_project( user_id=user_ref['id'], tenant_id=project_ref['id'], role_id=role_ref['id']) role_list = self.assignment_api.get_roles_for_user_and_project( user_id=user_ref['id'], tenant_id=project_ref['id']) self.assertEqual(set([r['id'] for r in role_ref_list]), set(role_list)) def test_get_role_by_user_and_project(self): roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertNotIn(self.role_admin['id'], roles_ref) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], self.role_admin['id']) roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertIn(self.role_admin['id'], roles_ref) self.assertNotIn('member', roles_ref) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], 'member') roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertIn(self.role_admin['id'], roles_ref) self.assertIn('member', roles_ref) def test_get_roles_for_user_and_domain(self): """"""Test for getting roles for user on a domain. Test Plan: - Create a domain, with 2 users - Check no roles yet exit - Give user1 two roles on the domain, user2 one role - Get roles on user1 and the domain - maybe sure we only get back the 2 roles on user1 - Delete both roles from user1 - Check we get no roles back for user1 on domain """""" new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) new_user1 = unit.new_user_ref(domain_id=new_domain['id']) new_user1 = self.identity_api.create_user(new_user1) new_user2 = unit.new_user_ref(domain_id=new_domain['id']) new_user2 = self.identity_api.create_user(new_user2) roles_ref = self.assignment_api.list_grants( user_id=new_user1['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) # Now create the grants (roles are defined in default_fixtures) self.assignment_api.create_grant(user_id=new_user1['id'], domain_id=new_domain['id'], role_id='member') self.assignment_api.create_grant(user_id=new_user1['id'], domain_id=new_domain['id'], role_id='other') self.assignment_api.create_grant(user_id=new_user2['id'], domain_id=new_domain['id'], role_id='admin') # Read back the roles for user1 on domain roles_ids = self.assignment_api.get_roles_for_user_and_domain( new_user1['id'], new_domain['id']) self.assertEqual(2, len(roles_ids)) self.assertIn(self.role_member['id'], roles_ids) self.assertIn(self.role_other['id'], roles_ids) # Now delete both grants for user1 self.assignment_api.delete_grant(user_id=new_user1['id'], domain_id=new_domain['id'], role_id='member') self.assignment_api.delete_grant(user_id=new_user1['id'], domain_id=new_domain['id'], role_id='other') roles_ref = self.assignment_api.list_grants( user_id=new_user1['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) def test_get_roles_for_user_and_domain_returns_not_found(self): """"""Test errors raised when getting roles for user on a domain. Test Plan: - Check non-existing user gives UserNotFound - Check non-existing domain gives DomainNotFound """""" new_domain = self._get_domain_fixture() new_user1 = unit.new_user_ref(domain_id=new_domain['id']) new_user1 = self.identity_api.create_user(new_user1) self.assertRaises(exception.UserNotFound, self.assignment_api.get_roles_for_user_and_domain, uuid.uuid4().hex, new_domain['id']) self.assertRaises(exception.DomainNotFound, self.assignment_api.get_roles_for_user_and_domain, new_user1['id'], uuid.uuid4().hex) def test_get_roles_for_user_and_project_returns_not_found(self): self.assertRaises(exception.UserNotFound, self.assignment_api.get_roles_for_user_and_project, uuid.uuid4().hex, self.tenant_bar['id']) self.assertRaises(exception.ProjectNotFound, self.assignment_api.get_roles_for_user_and_project, self.user_foo['id'], uuid.uuid4().hex) def test_add_role_to_user_and_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.assignment_api.add_role_to_user_and_project, self.user_foo['id'], uuid.uuid4().hex, self.role_admin['id']) self.assertRaises(exception.RoleNotFound, self.assignment_api.add_role_to_user_and_project, self.user_foo['id'], self.tenant_bar['id'], uuid.uuid4().hex) def test_add_role_to_user_and_project_no_user(self): # If add_role_to_user_and_project and the user doesn't exist, then # no error. user_id_not_exist = uuid.uuid4().hex self.assignment_api.add_role_to_user_and_project( user_id_not_exist, self.tenant_bar['id'], self.role_admin['id']) def test_remove_role_from_user_and_project(self): self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], 'member') self.assignment_api.remove_role_from_user_and_project( self.user_foo['id'], self.tenant_bar['id'], 'member') roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertNotIn('member', roles_ref) self.assertRaises(exception.NotFound, self.assignment_api. remove_role_from_user_and_project, self.user_foo['id'], self.tenant_bar['id'], 'member') def test_get_role_grant_by_user_and_project(self): roles_ref = self.assignment_api.list_grants( user_id=self.user_foo['id'], project_id=self.tenant_bar['id']) self.assertEqual(1, len(roles_ref)) self.assignment_api.create_grant(user_id=self.user_foo['id'], project_id=self.tenant_bar['id'], role_id=self.role_admin['id']) roles_ref = self.assignment_api.list_grants( user_id=self.user_foo['id'], project_id=self.tenant_bar['id']) self.assertIn(self.role_admin['id'], [role_ref['id'] for role_ref in roles_ref]) self.assignment_api.create_grant(user_id=self.user_foo['id'], project_id=self.tenant_bar['id'], role_id='member') roles_ref = self.assignment_api.list_grants( user_id=self.user_foo['id'], project_id=self.tenant_bar['id']) roles_ref_ids = [] for ref in roles_ref: roles_ref_ids.append(ref['id']) self.assertIn(self.role_admin['id'], roles_ref_ids) self.assertIn('member', roles_ref_ids) def test_remove_role_grant_from_user_and_project(self): self.assignment_api.create_grant(user_id=self.user_foo['id'], project_id=self.tenant_baz['id'], role_id='member') roles_ref = self.assignment_api.list_grants( user_id=self.user_foo['id'], project_id=self.tenant_baz['id']) self.assertDictEqual(self.role_member, roles_ref[0]) self.assignment_api.delete_grant(user_id=self.user_foo['id'], project_id=self.tenant_baz['id'], role_id='member') roles_ref = self.assignment_api.list_grants( user_id=self.user_foo['id'], project_id=self.tenant_baz['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, user_id=self.user_foo['id'], project_id=self.tenant_baz['id'], role_id='member') def test_get_role_assignment_by_project_not_found(self): self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.check_grant_role_id, user_id=self.user_foo['id'], project_id=self.tenant_baz['id'], role_id='member') self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.check_grant_role_id, group_id=uuid.uuid4().hex, project_id=self.tenant_baz['id'], role_id='member') def test_get_role_assignment_by_domain_not_found(self): self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.check_grant_role_id, user_id=self.user_foo['id'], domain_id=self.domain_default['id'], role_id='member') self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.check_grant_role_id, group_id=uuid.uuid4().hex, domain_id=self.domain_default['id'], role_id='member') def test_del_role_assignment_by_project_not_found(self): self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, user_id=self.user_foo['id'], project_id=self.tenant_baz['id'], role_id='member') self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=uuid.uuid4().hex, project_id=self.tenant_baz['id'], role_id='member') def test_del_role_assignment_by_domain_not_found(self): self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, user_id=self.user_foo['id'], domain_id=self.domain_default['id'], role_id='member') self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=uuid.uuid4().hex, domain_id=self.domain_default['id'], role_id='member') def test_get_and_remove_role_grant_by_group_and_project(self): new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) new_group = unit.new_group_ref(domain_id=new_domain['id']) new_group = self.identity_api.create_group(new_group) new_user = unit.new_user_ref(domain_id=new_domain['id']) new_user = self.identity_api.create_user(new_user) self.identity_api.add_user_to_group(new_user['id'], new_group['id']) roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], project_id=self.tenant_bar['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(group_id=new_group['id'], project_id=self.tenant_bar['id'], role_id='member') roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], project_id=self.tenant_bar['id']) self.assertDictEqual(self.role_member, roles_ref[0]) self.assignment_api.delete_grant(group_id=new_group['id'], project_id=self.tenant_bar['id'], role_id='member') roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], project_id=self.tenant_bar['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=new_group['id'], project_id=self.tenant_bar['id'], role_id='member') def test_get_and_remove_role_grant_by_group_and_domain(self): new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) new_group = unit.new_group_ref(domain_id=new_domain['id']) new_group = self.identity_api.create_group(new_group) new_user = unit.new_user_ref(domain_id=new_domain['id']) new_user = self.identity_api.create_user(new_user) self.identity_api.add_user_to_group(new_user['id'], new_group['id']) roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertDictEqual(self.role_member, roles_ref[0]) self.assignment_api.delete_grant(group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') def test_get_and_remove_correct_role_grant_from_a_mix(self): new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) new_project = unit.new_project_ref(domain_id=new_domain['id']) self.resource_api.create_project(new_project['id'], new_project) new_group = unit.new_group_ref(domain_id=new_domain['id']) new_group = self.identity_api.create_group(new_group) new_group2 = unit.new_group_ref(domain_id=new_domain['id']) new_group2 = self.identity_api.create_group(new_group2) new_user = unit.new_user_ref(domain_id=new_domain['id']) new_user = self.identity_api.create_user(new_user) new_user2 = unit.new_user_ref(domain_id=new_domain['id']) new_user2 = self.identity_api.create_user(new_user2) self.identity_api.add_user_to_group(new_user['id'], new_group['id']) # First check we have no grants roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) # Now add the grant we are going to test for, and some others as # well just to make sure we get back the right one self.assignment_api.create_grant(group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') self.assignment_api.create_grant(group_id=new_group2['id'], domain_id=new_domain['id'], role_id=self.role_admin['id']) self.assignment_api.create_grant(user_id=new_user2['id'], domain_id=new_domain['id'], role_id=self.role_admin['id']) self.assignment_api.create_grant(group_id=new_group['id'], project_id=new_project['id'], role_id=self.role_admin['id']) roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertDictEqual(self.role_member, roles_ref[0]) self.assignment_api.delete_grant(group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') roles_ref = self.assignment_api.list_grants( group_id=new_group['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=new_group['id'], domain_id=new_domain['id'], role_id='member') def test_get_and_remove_role_grant_by_user_and_domain(self): new_domain = unit.new_domain_ref() self.resource_api.create_domain(new_domain['id'], new_domain) new_user = unit.new_user_ref(domain_id=new_domain['id']) new_user = self.identity_api.create_user(new_user) roles_ref = self.assignment_api.list_grants( user_id=new_user['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(user_id=new_user['id'], domain_id=new_domain['id'], role_id='member') roles_ref = self.assignment_api.list_grants( user_id=new_user['id'], domain_id=new_domain['id']) self.assertDictEqual(self.role_member, roles_ref[0]) self.assignment_api.delete_grant(user_id=new_user['id'], domain_id=new_domain['id'], role_id='member') roles_ref = self.assignment_api.list_grants( user_id=new_user['id'], domain_id=new_domain['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, user_id=new_user['id'], domain_id=new_domain['id'], role_id='member') def test_get_and_remove_role_grant_by_group_and_cross_domain(self): group1_domain1_role = unit.new_role_ref() self.role_api.create_role(group1_domain1_role['id'], group1_domain1_role) group1_domain2_role = unit.new_role_ref() self.role_api.create_role(group1_domain2_role['id'], group1_domain2_role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain1['id']) self.assertEqual(0, len(roles_ref)) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain2['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=group1_domain1_role['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain2['id'], role_id=group1_domain2_role['id']) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain1['id']) self.assertDictEqual(group1_domain1_role, roles_ref[0]) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain2['id']) self.assertDictEqual(group1_domain2_role, roles_ref[0]) self.assignment_api.delete_grant(group_id=group1['id'], domain_id=domain2['id'], role_id=group1_domain2_role['id']) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain2['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, group_id=group1['id'], domain_id=domain2['id'], role_id=group1_domain2_role['id']) def test_get_and_remove_role_grant_by_user_and_cross_domain(self): user1_domain1_role = unit.new_role_ref() self.role_api.create_role(user1_domain1_role['id'], user1_domain1_role) user1_domain2_role = unit.new_role_ref() self.role_api.create_role(user1_domain2_role['id'], user1_domain2_role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain1['id']) self.assertEqual(0, len(roles_ref)) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain2['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=user1_domain1_role['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain2['id'], role_id=user1_domain2_role['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain1['id']) self.assertDictEqual(user1_domain1_role, roles_ref[0]) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain2['id']) self.assertDictEqual(user1_domain2_role, roles_ref[0]) self.assignment_api.delete_grant(user_id=user1['id'], domain_id=domain2['id'], role_id=user1_domain2_role['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain2['id']) self.assertEqual(0, len(roles_ref)) self.assertRaises(exception.RoleAssignmentNotFound, self.assignment_api.delete_grant, user_id=user1['id'], domain_id=domain2['id'], role_id=user1_domain2_role['id']) def test_role_grant_by_group_and_cross_domain_project(self): role1 = unit.new_role_ref() self.role_api.create_role(role1['id'], role1) role2 = unit.new_role_ref() self.role_api.create_role(role2['id'], role2) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) project1 = unit.new_project_ref(domain_id=domain2['id']) self.resource_api.create_project(project1['id'], project1) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role1['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role2['id']) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], project_id=project1['id']) roles_ref_ids = [] for ref in roles_ref: roles_ref_ids.append(ref['id']) self.assertIn(role1['id'], roles_ref_ids) self.assertIn(role2['id'], roles_ref_ids) self.assignment_api.delete_grant(group_id=group1['id'], project_id=project1['id'], role_id=role1['id']) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], project_id=project1['id']) self.assertEqual(1, len(roles_ref)) self.assertDictEqual(role2, roles_ref[0]) def test_role_grant_by_user_and_cross_domain_project(self): role1 = unit.new_role_ref() self.role_api.create_role(role1['id'], role1) role2 = unit.new_role_ref() self.role_api.create_role(role2['id'], role2) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) project1 = unit.new_project_ref(domain_id=domain2['id']) self.resource_api.create_project(project1['id'], project1) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role1['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role2['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) roles_ref_ids = [] for ref in roles_ref: roles_ref_ids.append(ref['id']) self.assertIn(role1['id'], roles_ref_ids) self.assertIn(role2['id'], roles_ref_ids) self.assignment_api.delete_grant(user_id=user1['id'], project_id=project1['id'], role_id=role1['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(1, len(roles_ref)) self.assertDictEqual(role2, roles_ref[0]) def test_delete_user_grant_no_user(self): # Can delete a grant where the user doesn't exist. role = unit.new_role_ref() role_id = role['id'] self.role_api.create_role(role_id, role) user_id = uuid.uuid4().hex self.assignment_api.create_grant(role_id, user_id=user_id, project_id=self.tenant_bar['id']) self.assignment_api.delete_grant(role_id, user_id=user_id, project_id=self.tenant_bar['id']) def test_delete_group_grant_no_group(self): # Can delete a grant where the group doesn't exist. role = unit.new_role_ref() role_id = role['id'] self.role_api.create_role(role_id, role) group_id = uuid.uuid4().hex self.assignment_api.create_grant(role_id, group_id=group_id, project_id=self.tenant_bar['id']) self.assignment_api.delete_grant(role_id, group_id=group_id, project_id=self.tenant_bar['id']) def test_grant_crud_throws_exception_if_invalid_role(self): """"""Ensure RoleNotFound thrown if role does not exist."""""" def assert_role_not_found_exception(f, **kwargs): self.assertRaises(exception.RoleNotFound, f, role_id=uuid.uuid4().hex, **kwargs) user = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) user_resp = self.identity_api.create_user(user) group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) group_resp = self.identity_api.create_group(group) project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) project_resp = self.resource_api.create_project(project['id'], project) for manager_call in [self.assignment_api.create_grant, self.assignment_api.get_grant, self.assignment_api.delete_grant]: assert_role_not_found_exception( manager_call, user_id=user_resp['id'], project_id=project_resp['id']) assert_role_not_found_exception( manager_call, group_id=group_resp['id'], project_id=project_resp['id']) assert_role_not_found_exception( manager_call, user_id=user_resp['id'], domain_id=DEFAULT_DOMAIN_ID) assert_role_not_found_exception( manager_call, group_id=group_resp['id'], domain_id=DEFAULT_DOMAIN_ID) def test_multi_role_grant_by_user_group_on_project_domain(self): role_list = [] for _ in range(10): role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) group2 = unit.new_group_ref(domain_id=domain1['id']) group2 = self.identity_api.create_group(group2) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) self.identity_api.add_user_to_group(user1['id'], group1['id']) self.identity_api.add_user_to_group(user1['id'], group2['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role_list[1]['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=role_list[2]['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=role_list[3]['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role_list[4]['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role_list[5]['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role_list[6]['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role_list[7]['id']) roles_ref = self.assignment_api.list_grants(user_id=user1['id'], domain_id=domain1['id']) self.assertEqual(2, len(roles_ref)) self.assertIn(role_list[0], roles_ref) self.assertIn(role_list[1], roles_ref) roles_ref = self.assignment_api.list_grants(group_id=group1['id'], domain_id=domain1['id']) self.assertEqual(2, len(roles_ref)) self.assertIn(role_list[2], roles_ref) self.assertIn(role_list[3], roles_ref) roles_ref = self.assignment_api.list_grants(user_id=user1['id'], project_id=project1['id']) self.assertEqual(2, len(roles_ref)) self.assertIn(role_list[4], roles_ref) self.assertIn(role_list[5], roles_ref) roles_ref = self.assignment_api.list_grants(group_id=group1['id'], project_id=project1['id']) self.assertEqual(2, len(roles_ref)) self.assertIn(role_list[6], roles_ref) self.assertIn(role_list[7], roles_ref) # Now test the alternate way of getting back lists of grants, # where user and group roles are combined. These should match # the above results. combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(4, len(combined_list)) self.assertIn(role_list[4]['id'], combined_list) self.assertIn(role_list[5]['id'], combined_list) self.assertIn(role_list[6]['id'], combined_list) self.assertIn(role_list[7]['id'], combined_list) combined_role_list = self.assignment_api.get_roles_for_user_and_domain( user1['id'], domain1['id']) self.assertEqual(4, len(combined_role_list)) self.assertIn(role_list[0]['id'], combined_role_list) self.assertIn(role_list[1]['id'], combined_role_list) self.assertIn(role_list[2]['id'], combined_role_list) self.assertIn(role_list[3]['id'], combined_role_list) def test_multi_group_grants_on_project_domain(self): """"""Test multiple group roles for user on project and domain. Test Plan: - Create 6 roles - Create a domain, with a project, user and two groups - Make the user a member of both groups - Check no roles yet exit - Assign a role to each user and both groups on both the project and domain - Get a list of effective roles for the user on both the project and domain, checking we get back the correct three roles """""" role_list = [] for _ in range(6): role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) group2 = unit.new_group_ref(domain_id=domain1['id']) group2 = self.identity_api.create_group(group2) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) self.identity_api.add_user_to_group(user1['id'], group1['id']) self.identity_api.add_user_to_group(user1['id'], group2['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=role_list[1]['id']) self.assignment_api.create_grant(group_id=group2['id'], domain_id=domain1['id'], role_id=role_list[2]['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role_list[3]['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role_list[4]['id']) self.assignment_api.create_grant(group_id=group2['id'], project_id=project1['id'], role_id=role_list[5]['id']) # Read by the roles, ensuring we get the correct 3 roles for # both project and domain combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(3, len(combined_list)) self.assertIn(role_list[3]['id'], combined_list) self.assertIn(role_list[4]['id'], combined_list) self.assertIn(role_list[5]['id'], combined_list) combined_role_list = self.assignment_api.get_roles_for_user_and_domain( user1['id'], domain1['id']) self.assertEqual(3, len(combined_role_list)) self.assertIn(role_list[0]['id'], combined_role_list) self.assertIn(role_list[1]['id'], combined_role_list) self.assertIn(role_list[2]['id'], combined_role_list) def test_delete_role_with_user_and_group_grants(self): role1 = unit.new_role_ref() self.role_api.create_role(role1['id'], role1) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role1['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role1['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=role1['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=role1['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(1, len(roles_ref)) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], project_id=project1['id']) self.assertEqual(1, len(roles_ref)) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain1['id']) self.assertEqual(1, len(roles_ref)) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain1['id']) self.assertEqual(1, len(roles_ref)) self.role_api.delete_role(role1['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], domain_id=domain1['id']) self.assertEqual(0, len(roles_ref)) roles_ref = self.assignment_api.list_grants( group_id=group1['id'], domain_id=domain1['id']) self.assertEqual(0, len(roles_ref)) def test_list_role_assignment_by_domain(self): """"""Test listing of role assignment filtered by domain."""""" test_plan = { # A domain with 3 users, 1 group, a spoiler domain and 2 roles. 'entities': {'domains': [{'users': 3, 'groups': 1}, 1], 'roles': 2}, # Users 1 & 2 are in the group 'group_memberships': [{'group': 0, 'users': [1, 2]}], # Assign a role for user 0 and the group 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'group': 0, 'role': 1, 'domain': 0}], 'tests': [ # List all effective assignments for domain[0]. # Should get one direct user role and user roles for each of # the users in the group. {'params': {'domain': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 1, 'role': 1, 'domain': 0, 'indirect': {'group': 0}}, {'user': 2, 'role': 1, 'domain': 0, 'indirect': {'group': 0}} ]}, # Using domain[1] should return nothing {'params': {'domain': 1, 'effective': True}, 'results': []}, ] } self.execute_assignment_plan(test_plan) def test_list_role_assignment_by_user_with_domain_group_roles(self): """"""Test listing assignments by user, with group roles on a domain."""""" test_plan = { # A domain with 3 users, 3 groups, a spoiler domain # plus 3 roles. 'entities': {'domains': [{'users': 3, 'groups': 3}, 1], 'roles': 3}, # Users 1 & 2 are in the group 0, User 1 also in group 1 'group_memberships': [{'group': 0, 'users': [0, 1]}, {'group': 1, 'users': [0]}], 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'group': 0, 'role': 1, 'domain': 0}, {'group': 1, 'role': 2, 'domain': 0}, # ...and two spoiler assignments {'user': 1, 'role': 1, 'domain': 0}, {'group': 2, 'role': 2, 'domain': 0}], 'tests': [ # List all effective assignments for user[0]. # Should get one direct user role and a user roles for each of # groups 0 and 1 {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'domain': 0, 'indirect': {'group': 0}}, {'user': 0, 'role': 2, 'domain': 0, 'indirect': {'group': 1}} ]}, # Adding domain[0] as a filter should return the same data {'params': {'user': 0, 'domain': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'domain': 0, 'indirect': {'group': 0}}, {'user': 0, 'role': 2, 'domain': 0, 'indirect': {'group': 1}} ]}, # Using domain[1] should return nothing {'params': {'user': 0, 'domain': 1, 'effective': True}, 'results': []}, # Using user[2] should return nothing {'params': {'user': 2, 'domain': 0, 'effective': True}, 'results': []}, ] } self.execute_assignment_plan(test_plan) def test_add_user_to_project(self): self.assignment_api.add_user_to_project(self.tenant_baz['id'], self.user_foo['id']) tenants = self.assignment_api.list_projects_for_user( self.user_foo['id']) self.assertIn(self.tenant_baz, tenants) def test_add_user_to_project_missing_default_role(self): self.role_api.delete_role(CONF.member_role_id) self.assertRaises(exception.RoleNotFound, self.role_api.get_role, CONF.member_role_id) self.assignment_api.add_user_to_project(self.tenant_baz['id'], self.user_foo['id']) tenants = ( self.assignment_api.list_projects_for_user(self.user_foo['id'])) self.assertIn(self.tenant_baz, tenants) default_role = self.role_api.get_role(CONF.member_role_id) self.assertIsNotNone(default_role) def test_add_user_to_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.assignment_api.add_user_to_project, uuid.uuid4().hex, self.user_foo['id']) def test_add_user_to_project_no_user(self): # If add_user_to_project and the user doesn't exist, then # no error. user_id_not_exist = uuid.uuid4().hex self.assignment_api.add_user_to_project(self.tenant_bar['id'], user_id_not_exist) def test_remove_user_from_project(self): self.assignment_api.add_user_to_project(self.tenant_baz['id'], self.user_foo['id']) self.assignment_api.remove_user_from_project(self.tenant_baz['id'], self.user_foo['id']) tenants = self.assignment_api.list_projects_for_user( self.user_foo['id']) self.assertNotIn(self.tenant_baz, tenants) def test_remove_user_from_project_race_delete_role(self): self.assignment_api.add_user_to_project(self.tenant_baz['id'], self.user_foo['id']) self.assignment_api.add_role_to_user_and_project( tenant_id=self.tenant_baz['id'], user_id=self.user_foo['id'], role_id=self.role_other['id']) # Mock a race condition, delete a role after # get_roles_for_user_and_project() is called in # remove_user_from_project(). roles = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_baz['id']) self.role_api.delete_role(self.role_other['id']) self.assignment_api.get_roles_for_user_and_project = mock.Mock( return_value=roles) self.assignment_api.remove_user_from_project(self.tenant_baz['id'], self.user_foo['id']) tenants = self.assignment_api.list_projects_for_user( self.user_foo['id']) self.assertNotIn(self.tenant_baz, tenants) def test_remove_user_from_project_returns_not_found(self): self.assertRaises(exception.ProjectNotFound, self.assignment_api.remove_user_from_project, uuid.uuid4().hex, self.user_foo['id']) self.assertRaises(exception.UserNotFound, self.assignment_api.remove_user_from_project, self.tenant_bar['id'], uuid.uuid4().hex) self.assertRaises(exception.NotFound, self.assignment_api.remove_user_from_project, self.tenant_baz['id'], self.user_foo['id']) def test_list_user_project_ids_returns_not_found(self): self.assertRaises(exception.UserNotFound, self.assignment_api.list_projects_for_user, uuid.uuid4().hex) def test_delete_role_returns_not_found(self): self.assertRaises(exception.RoleNotFound, self.role_api.delete_role, uuid.uuid4().hex) def test_delete_role_check_role_grant(self): role = unit.new_role_ref() alt_role = unit.new_role_ref() self.role_api.create_role(role['id'], role) self.role_api.create_role(alt_role['id'], alt_role) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], role['id']) self.assignment_api.add_role_to_user_and_project( self.user_foo['id'], self.tenant_bar['id'], alt_role['id']) self.role_api.delete_role(role['id']) roles_ref = self.assignment_api.get_roles_for_user_and_project( self.user_foo['id'], self.tenant_bar['id']) self.assertNotIn(role['id'], roles_ref) self.assertIn(alt_role['id'], roles_ref) def test_list_projects_for_user(self): domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) user1 = unit.new_user_ref(domain_id=domain['id']) user1 = self.identity_api.create_user(user1) user_projects = self.assignment_api.list_projects_for_user(user1['id']) self.assertEqual(0, len(user_projects)) self.assignment_api.create_grant(user_id=user1['id'], project_id=self.tenant_bar['id'], role_id=self.role_member['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=self.tenant_baz['id'], role_id=self.role_member['id']) user_projects = self.assignment_api.list_projects_for_user(user1['id']) self.assertEqual(2, len(user_projects)) def test_list_projects_for_user_with_grants(self): # Create two groups each with a role on a different project, and # make user1 a member of both groups. Both these new projects # should now be included, along with any direct user grants. domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) user1 = unit.new_user_ref(domain_id=domain['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain['id']) group1 = self.identity_api.create_group(group1) group2 = unit.new_group_ref(domain_id=domain['id']) group2 = self.identity_api.create_group(group2) project1 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project2['id'], project2) self.identity_api.add_user_to_group(user1['id'], group1['id']) self.identity_api.add_user_to_group(user1['id'], group2['id']) # Create 3 grants, one user grant, the other two as group grants self.assignment_api.create_grant(user_id=user1['id'], project_id=self.tenant_bar['id'], role_id=self.role_member['id']) self.assignment_api.create_grant(group_id=group1['id'], project_id=project1['id'], role_id=self.role_admin['id']) self.assignment_api.create_grant(group_id=group2['id'], project_id=project2['id'], role_id=self.role_admin['id']) user_projects = self.assignment_api.list_projects_for_user(user1['id']) self.assertEqual(3, len(user_projects)) def test_create_grant_no_user(self): # If call create_grant with a user that doesn't exist, doesn't fail. self.assignment_api.create_grant( self.role_other['id'], user_id=uuid.uuid4().hex, project_id=self.tenant_bar['id']) def test_create_grant_no_group(self): # If call create_grant with a group that doesn't exist, doesn't fail. self.assignment_api.create_grant( self.role_other['id'], group_id=uuid.uuid4().hex, project_id=self.tenant_bar['id']) def test_delete_group_removes_role_assignments(self): # When a group is deleted any role assignments for the group are # removed. MEMBER_ROLE_ID = 'member' def get_member_assignments(): assignments = self.assignment_api.list_role_assignments() return [x for x in assignments if x['role_id'] == MEMBER_ROLE_ID] orig_member_assignments = get_member_assignments() # Create a group. new_group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) new_group = self.identity_api.create_group(new_group) # Create a project. new_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(new_project['id'], new_project) # Assign a role to the group. self.assignment_api.create_grant( group_id=new_group['id'], project_id=new_project['id'], role_id=MEMBER_ROLE_ID) # Delete the group. self.identity_api.delete_group(new_group['id']) # Check that the role assignment for the group is gone member_assignments = get_member_assignments() self.assertThat(member_assignments, matchers.Equals(orig_member_assignments)) def test_get_roles_for_groups_on_domain(self): """"""Test retrieving group domain roles. Test Plan: - Create a domain, three groups and three roles - Assign one an inherited and the others a non-inherited group role to the domain - Ensure that only the non-inherited roles are returned on the domain """""" domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) group_list = [] group_id_list = [] role_list = [] for _ in range(3): group = unit.new_group_ref(domain_id=domain1['id']) group = self.identity_api.create_group(group) group_list.append(group) group_id_list.append(group['id']) role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) # Assign the roles - one is inherited self.assignment_api.create_grant(group_id=group_list[0]['id'], domain_id=domain1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(group_id=group_list[1]['id'], domain_id=domain1['id'], role_id=role_list[1]['id']) self.assignment_api.create_grant(group_id=group_list[2]['id'], domain_id=domain1['id'], role_id=role_list[2]['id'], inherited_to_projects=True) # Now get the effective roles for the groups on the domain project. We # shouldn't get back the inherited role. role_refs = self.assignment_api.get_roles_for_groups( group_id_list, domain_id=domain1['id']) self.assertThat(role_refs, matchers.HasLength(2)) self.assertIn(role_list[0], role_refs) self.assertIn(role_list[1], role_refs) def test_get_roles_for_groups_on_project(self): """"""Test retrieving group project roles. Test Plan: - Create two domains, two projects, six groups and six roles - Project1 is in Domain1, Project2 is in Domain2 - Domain2/Project2 are spoilers - Assign a different direct group role to each project as well as both an inherited and non-inherited role to each domain - Get the group roles for Project 1 - depending on whether we have enabled inheritance, we should either get back just the direct role or both the direct one plus the inherited domain role from Domain 1 """""" domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain2['id']) self.resource_api.create_project(project2['id'], project2) group_list = [] group_id_list = [] role_list = [] for _ in range(6): group = unit.new_group_ref(domain_id=domain1['id']) group = self.identity_api.create_group(group) group_list.append(group) group_id_list.append(group['id']) role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) # Assign the roles - one inherited and one non-inherited on Domain1, # plus one on Project1 self.assignment_api.create_grant(group_id=group_list[0]['id'], domain_id=domain1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(group_id=group_list[1]['id'], domain_id=domain1['id'], role_id=role_list[1]['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group_list[2]['id'], project_id=project1['id'], role_id=role_list[2]['id']) # ...and a duplicate set of spoiler assignments to Domain2/Project2 self.assignment_api.create_grant(group_id=group_list[3]['id'], domain_id=domain2['id'], role_id=role_list[3]['id']) self.assignment_api.create_grant(group_id=group_list[4]['id'], domain_id=domain2['id'], role_id=role_list[4]['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group_list[5]['id'], project_id=project2['id'], role_id=role_list[5]['id']) # Now get the effective roles for all groups on the Project1. With # inheritance off, we should only get back the direct role. self.config_fixture.config(group='os_inherit', enabled=False) role_refs = self.assignment_api.get_roles_for_groups( group_id_list, project_id=project1['id']) self.assertThat(role_refs, matchers.HasLength(1)) self.assertIn(role_list[2], role_refs) # With inheritance on, we should also get back the inherited role from # its owning domain. self.config_fixture.config(group='os_inherit', enabled=True) role_refs = self.assignment_api.get_roles_for_groups( group_id_list, project_id=project1['id']) self.assertThat(role_refs, matchers.HasLength(2)) self.assertIn(role_list[1], role_refs) self.assertIn(role_list[2], role_refs) def test_list_domains_for_groups(self): """"""Test retrieving domains for a list of groups. Test Plan: - Create three domains, three groups and one role - Assign a non-inherited group role to two domains, and an inherited group role to the third - Ensure only the domains with non-inherited roles are returned """""" domain_list = [] group_list = [] group_id_list = [] for _ in range(3): domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) domain_list.append(domain) group = unit.new_group_ref(domain_id=domain['id']) group = self.identity_api.create_group(group) group_list.append(group) group_id_list.append(group['id']) role1 = unit.new_role_ref() self.role_api.create_role(role1['id'], role1) # Assign the roles - one is inherited self.assignment_api.create_grant(group_id=group_list[0]['id'], domain_id=domain_list[0]['id'], role_id=role1['id']) self.assignment_api.create_grant(group_id=group_list[1]['id'], domain_id=domain_list[1]['id'], role_id=role1['id']) self.assignment_api.create_grant(group_id=group_list[2]['id'], domain_id=domain_list[2]['id'], role_id=role1['id'], inherited_to_projects=True) # Now list the domains that have roles for any of the 3 groups # We shouldn't get back domain[2] since that had an inherited role. domain_refs = ( self.assignment_api.list_domains_for_groups(group_id_list)) self.assertThat(domain_refs, matchers.HasLength(2)) self.assertIn(domain_list[0], domain_refs) self.assertIn(domain_list[1], domain_refs) def test_list_projects_for_groups(self): """"""Test retrieving projects for a list of groups. Test Plan: - Create two domains, four projects, seven groups and seven roles - Project1-3 are in Domain1, Project4 is in Domain2 - Domain2/Project4 are spoilers - Project1 and 2 have direct group roles, Project3 has no direct roles but should inherit a group role from Domain1 - Get the projects for the group roles that are assigned to Project1 Project2 and the inherited one on Domain1. Depending on whether we have enabled inheritance, we should either get back just the projects with direct roles (Project 1 and 2) or also Project3 due to its inherited role from Domain1. """""" domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) project1 = unit.new_project_ref(domain_id=domain1['id']) project1 = self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain1['id']) project2 = self.resource_api.create_project(project2['id'], project2) project3 = unit.new_project_ref(domain_id=domain1['id']) project3 = self.resource_api.create_project(project3['id'], project3) project4 = unit.new_project_ref(domain_id=domain2['id']) project4 = self.resource_api.create_project(project4['id'], project4) group_list = [] role_list = [] for _ in range(7): group = unit.new_group_ref(domain_id=domain1['id']) group = self.identity_api.create_group(group) group_list.append(group) role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) # Assign the roles - one inherited and one non-inherited on Domain1, # plus one on Project1 and Project2 self.assignment_api.create_grant(group_id=group_list[0]['id'], domain_id=domain1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(group_id=group_list[1]['id'], domain_id=domain1['id'], role_id=role_list[1]['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group_list[2]['id'], project_id=project1['id'], role_id=role_list[2]['id']) self.assignment_api.create_grant(group_id=group_list[3]['id'], project_id=project2['id'], role_id=role_list[3]['id']) # ...and a few of spoiler assignments to Domain2/Project4 self.assignment_api.create_grant(group_id=group_list[4]['id'], domain_id=domain2['id'], role_id=role_list[4]['id']) self.assignment_api.create_grant(group_id=group_list[5]['id'], domain_id=domain2['id'], role_id=role_list[5]['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group_list[6]['id'], project_id=project4['id'], role_id=role_list[6]['id']) # Now get the projects for the groups that have roles on Project1, # Project2 and the inherited role on Domain!. With inheritance off, # we should only get back the projects with direct role. self.config_fixture.config(group='os_inherit', enabled=False) group_id_list = [group_list[1]['id'], group_list[2]['id'], group_list[3]['id']] project_refs = ( self.assignment_api.list_projects_for_groups(group_id_list)) self.assertThat(project_refs, matchers.HasLength(2)) self.assertIn(project1, project_refs) self.assertIn(project2, project_refs) # With inheritance on, we should also get back the Project3 due to the # inherited role from its owning domain. self.config_fixture.config(group='os_inherit', enabled=True) project_refs = ( self.assignment_api.list_projects_for_groups(group_id_list)) self.assertThat(project_refs, matchers.HasLength(3)) self.assertIn(project1, project_refs) self.assertIn(project2, project_refs) self.assertIn(project3, project_refs) def test_update_role_no_name(self): # A user can update a role and not include the name. # description is picked just because it's not name. self.role_api.update_role(self.role_member['id'], {'description': uuid.uuid4().hex}) # If the previous line didn't raise an exception then the test passes. def test_update_role_same_name(self): # A user can update a role and set the name to be the same as it was. self.role_api.update_role(self.role_member['id'], {'name': self.role_member['name']}) # If the previous line didn't raise an exception then the test passes. class InheritanceTests(AssignmentTestHelperMixin): def test_role_assignments_user_domain_to_project_inheritance(self): test_plan = { 'entities': {'domains': {'users': 2, 'projects': 1}, 'roles': 3}, 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 2, 'domain': 0, 'inherited_to_projects': True}, {'user': 1, 'role': 1, 'project': 0}], 'tests': [ # List all direct assignments for user[0] {'params': {'user': 0}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 2, 'domain': 0, 'inherited_to_projects': 'projects'}]}, # Now the effective ones - so the domain role should turn into # a project role {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 2, 'project': 0, 'indirect': {'domain': 0}}]}, # Narrow down to effective roles for user[0] and project[0] {'params': {'user': 0, 'project': 0, 'effective': True}, 'results': [{'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 2, 'project': 0, 'indirect': {'domain': 0}}]} ] } self.config_fixture.config(group='os_inherit', enabled=True) self.execute_assignment_plan(test_plan) def test_inherited_role_assignments_excluded_if_os_inherit_false(self): test_plan = { 'entities': {'domains': {'users': 2, 'groups': 1, 'projects': 1}, 'roles': 4}, 'group_memberships': [{'group': 0, 'users': [0]}], 'assignments': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 2, 'domain': 0, 'inherited_to_projects': True}, {'user': 1, 'role': 1, 'project': 0}, {'group': 0, 'role': 3, 'project': 0}], 'tests': [ # List all direct assignments for user[0], since os-inherit is # disabled, we should not see the inherited role {'params': {'user': 0}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}]}, # Same in effective mode - inherited roles should not be # included or expanded...but the group role should now # turn up as a user role, since group expansion is not # part of os-inherit. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'domain': 0}, {'user': 0, 'role': 1, 'project': 0}, {'user': 0, 'role': 3, 'project': 0, 'indirect': {'group': 0}}]}, ] } self.config_fixture.config(group='os_inherit', enabled=False) self.execute_assignment_plan(test_plan) def _test_crud_inherited_and_direct_assignment(self, **kwargs): """"""Tests inherited and direct assignments for the actor and target Ensure it is possible to create both inherited and direct role assignments for the same actor on the same target. The actor and the target are specified in the kwargs as ('user_id' or 'group_id') and ('project_id' or 'domain_id'), respectively. """""" self.config_fixture.config(group='os_inherit', enabled=True) # Create a new role to avoid assignments loaded from default fixtures role = unit.new_role_ref() role = self.role_api.create_role(role['id'], role) # Define the common assignment entity assignment_entity = {'role_id': role['id']} assignment_entity.update(kwargs) # Define assignments under test direct_assignment_entity = assignment_entity.copy() inherited_assignment_entity = assignment_entity.copy() inherited_assignment_entity['inherited_to_projects'] = 'projects' # Create direct assignment and check grants self.assignment_api.create_grant(inherited_to_projects=False, **assignment_entity) grants = self.assignment_api.list_role_assignments(role_id=role['id']) self.assertThat(grants, matchers.HasLength(1)) self.assertIn(direct_assignment_entity, grants) # Now add inherited assignment and check grants self.assignment_api.create_grant(inherited_to_projects=True, **assignment_entity) grants = self.assignment_api.list_role_assignments(role_id=role['id']) self.assertThat(grants, matchers.HasLength(2)) self.assertIn(direct_assignment_entity, grants) self.assertIn(inherited_assignment_entity, grants) # Delete both and check grants self.assignment_api.delete_grant(inherited_to_projects=False, **assignment_entity) self.assignment_api.delete_grant(inherited_to_projects=True, **assignment_entity) grants = self.assignment_api.list_role_assignments(role_id=role['id']) self.assertEqual([], grants) def test_crud_inherited_and_direct_assignment_for_user_on_domain(self): self._test_crud_inherited_and_direct_assignment( user_id=self.user_foo['id'], domain_id=DEFAULT_DOMAIN_ID) def test_crud_inherited_and_direct_assignment_for_group_on_domain(self): group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) group = self.identity_api.create_group(group) self._test_crud_inherited_and_direct_assignment( group_id=group['id'], domain_id=DEFAULT_DOMAIN_ID) def test_crud_inherited_and_direct_assignment_for_user_on_project(self): self._test_crud_inherited_and_direct_assignment( user_id=self.user_foo['id'], project_id=self.tenant_baz['id']) def test_crud_inherited_and_direct_assignment_for_group_on_project(self): group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) group = self.identity_api.create_group(group) self._test_crud_inherited_and_direct_assignment( group_id=group['id'], project_id=self.tenant_baz['id']) def test_inherited_role_grants_for_user(self): """"""Test inherited user roles. Test Plan: - Enable OS-INHERIT extension - Create 3 roles - Create a domain, with a project and a user - Check no roles yet exit - Assign a direct user role to the project and a (non-inherited) user role to the domain - Get a list of effective roles - should only get the one direct role - Now add an inherited user role to the domain - Get a list of effective roles - should have two roles, one direct and one by virtue of the inherited user role - Also get effective roles for the domain - the role marked as inherited should not show up """""" self.config_fixture.config(group='os_inherit', enabled=True) role_list = [] for _ in range(3): role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) # Create the first two roles - the domain one is not inherited self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role_list[1]['id']) # Now get the effective roles for the user and project, this # should only include the direct role assignment on the project combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(1, len(combined_list)) self.assertIn(role_list[0]['id'], combined_list) # Now add an inherited role on the domain self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain1['id'], role_id=role_list[2]['id'], inherited_to_projects=True) # Now get the effective roles for the user and project again, this # should now include the inherited role on the domain combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(2, len(combined_list)) self.assertIn(role_list[0]['id'], combined_list) self.assertIn(role_list[2]['id'], combined_list) # Finally, check that the inherited role does not appear as a valid # directly assigned role on the domain itself combined_role_list = self.assignment_api.get_roles_for_user_and_domain( user1['id'], domain1['id']) self.assertEqual(1, len(combined_role_list)) self.assertIn(role_list[1]['id'], combined_role_list) # TODO(henry-nash): The test above uses get_roles_for_user_and_project # and get_roles_for_user_and_domain, which will, in a subsequent patch, # be re-implemented to simply call list_role_assignments (see blueprint # remove-role-metadata). # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once get_roles_for_user_and # project/domain have been re-implemented then the manual tests above # can be refactored to simply ensure it gives the same answers. test_plan = { # A domain with a user & project, plus 3 roles. 'entities': {'domains': {'users': 1, 'projects': 1}, 'roles': 3}, 'assignments': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'domain': 0}, {'user': 0, 'role': 2, 'domain': 0, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] on project[0]. # Should get one direct role and one inherited role. {'params': {'user': 0, 'project': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 2, 'project': 0, 'indirect': {'domain': 0}}]}, # Ensure effective mode on the domain does not list the # inherited role on that domain {'params': {'user': 0, 'domain': 0, 'effective': True}, 'results': [{'user': 0, 'role': 1, 'domain': 0}]}, # Ensure non-inherited mode also only returns the non-inherited # role on the domain {'params': {'user': 0, 'domain': 0, 'inherited': False}, 'results': [{'user': 0, 'role': 1, 'domain': 0}]}, ] } self.execute_assignment_plan(test_plan) def test_inherited_role_grants_for_group(self): """"""Test inherited group roles. Test Plan: - Enable OS-INHERIT extension - Create 4 roles - Create a domain, with a project, user and two groups - Make the user a member of both groups - Check no roles yet exit - Assign a direct user role to the project and a (non-inherited) group role on the domain - Get a list of effective roles - should only get the one direct role - Now add two inherited group roles to the domain - Get a list of effective roles - should have three roles, one direct and two by virtue of inherited group roles """""" self.config_fixture.config(group='os_inherit', enabled=True) role_list = [] for _ in range(4): role = unit.new_role_ref() self.role_api.create_role(role['id'], role) role_list.append(role) domain1 = unit.new_domain_ref() self.resource_api.create_domain(domain1['id'], domain1) user1 = unit.new_user_ref(domain_id=domain1['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain1['id']) group1 = self.identity_api.create_group(group1) group2 = unit.new_group_ref(domain_id=domain1['id']) group2 = self.identity_api.create_group(group2) project1 = unit.new_project_ref(domain_id=domain1['id']) self.resource_api.create_project(project1['id'], project1) self.identity_api.add_user_to_group(user1['id'], group1['id']) self.identity_api.add_user_to_group(user1['id'], group2['id']) roles_ref = self.assignment_api.list_grants( user_id=user1['id'], project_id=project1['id']) self.assertEqual(0, len(roles_ref)) # Create two roles - the domain one is not inherited self.assignment_api.create_grant(user_id=user1['id'], project_id=project1['id'], role_id=role_list[0]['id']) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain1['id'], role_id=role_list[1]['id']) # Now get the effective roles for the user and project, this # should only include the direct role assignment on the project combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(1, len(combined_list)) self.assertIn(role_list[0]['id'], combined_list) # Now add to more group roles, both inherited, to the domain self.assignment_api.create_grant(group_id=group2['id'], domain_id=domain1['id'], role_id=role_list[2]['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group2['id'], domain_id=domain1['id'], role_id=role_list[3]['id'], inherited_to_projects=True) # Now get the effective roles for the user and project again, this # should now include the inherited roles on the domain combined_list = self.assignment_api.get_roles_for_user_and_project( user1['id'], project1['id']) self.assertEqual(3, len(combined_list)) self.assertIn(role_list[0]['id'], combined_list) self.assertIn(role_list[2]['id'], combined_list) self.assertIn(role_list[3]['id'], combined_list) # TODO(henry-nash): The test above uses get_roles_for_user_and_project # which will, in a subsequent patch, be re-implemented to simply call # list_role_assignments (see blueprint remove-role-metadata). # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once # get_roles_for_user_and_project has been re-implemented then the # manual tests above can be refactored to simply ensure it gives # the same answers. test_plan = { # A domain with a user and project, 2 groups, plus 4 roles. 'entities': {'domains': {'users': 1, 'projects': 1, 'groups': 2}, 'roles': 4}, 'group_memberships': [{'group': 0, 'users': [0]}, {'group': 1, 'users': [0]}], 'assignments': [{'user': 0, 'role': 0, 'project': 0}, {'group': 0, 'role': 1, 'domain': 0}, {'group': 1, 'role': 2, 'domain': 0, 'inherited_to_projects': True}, {'group': 1, 'role': 3, 'domain': 0, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] on project[0]. # Should get one direct role and both inherited roles, but # not the direct one on domain[0], even though user[0] is # in group[0]. {'params': {'user': 0, 'project': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 2, 'project': 0, 'indirect': {'domain': 0, 'group': 1}}, {'user': 0, 'role': 3, 'project': 0, 'indirect': {'domain': 0, 'group': 1}}]} ] } self.execute_assignment_plan(test_plan) def test_list_projects_for_user_with_inherited_grants(self): """"""Test inherited user roles. Test Plan: - Enable OS-INHERIT extension - Create a domain, with two projects and a user - Assign an inherited user role on the domain, as well as a direct user role to a separate project in a different domain - Get a list of projects for user, should return all three projects """""" self.config_fixture.config(group='os_inherit', enabled=True) domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) user1 = unit.new_user_ref(domain_id=domain['id']) user1 = self.identity_api.create_user(user1) project1 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project2['id'], project2) # Create 2 grants, one on a project and one inherited grant # on the domain self.assignment_api.create_grant(user_id=user1['id'], project_id=self.tenant_bar['id'], role_id=self.role_member['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain['id'], role_id=self.role_admin['id'], inherited_to_projects=True) # Should get back all three projects, one by virtue of the direct # grant, plus both projects in the domain user_projects = self.assignment_api.list_projects_for_user(user1['id']) self.assertEqual(3, len(user_projects)) # TODO(henry-nash): The test above uses list_projects_for_user # which may, in a subsequent patch, be re-implemented to call # list_role_assignments and then report only the distinct projects. # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once list_projects_for_user # has been re-implemented then the manual tests above can be # refactored. test_plan = { # A domain with 1 project, plus a second domain with 2 projects, # as well as a user. Also, create 2 roles. 'entities': {'domains': [{'projects': 1}, {'users': 1, 'projects': 2}], 'roles': 2}, 'assignments': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'domain': 1, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] # Should get one direct role plus one inherited role for each # project in domain {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'project': 1, 'indirect': {'domain': 1}}, {'user': 0, 'role': 1, 'project': 2, 'indirect': {'domain': 1}}]} ] } self.execute_assignment_plan(test_plan) def test_list_projects_for_user_with_inherited_user_project_grants(self): """"""Test inherited role assignments for users on nested projects. Test Plan: - Enable OS-INHERIT extension - Create a hierarchy of projects with one root and one leaf project - Assign an inherited user role on root project - Assign a non-inherited user role on root project - Get a list of projects for user, should return both projects - Disable OS-INHERIT extension - Get a list of projects for user, should return only root project """""" # Enable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=True) root_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(root_project['id'], root_project) leaf_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=root_project['id']) self.resource_api.create_project(leaf_project['id'], leaf_project) user = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) user = self.identity_api.create_user(user) # Grant inherited user role self.assignment_api.create_grant(user_id=user['id'], project_id=root_project['id'], role_id=self.role_admin['id'], inherited_to_projects=True) # Grant non-inherited user role self.assignment_api.create_grant(user_id=user['id'], project_id=root_project['id'], role_id=self.role_member['id']) # Should get back both projects: because the direct role assignment for # the root project and inherited role assignment for leaf project user_projects = self.assignment_api.list_projects_for_user(user['id']) self.assertEqual(2, len(user_projects)) self.assertIn(root_project, user_projects) self.assertIn(leaf_project, user_projects) # Disable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=False) # Should get back just root project - due the direct role assignment user_projects = self.assignment_api.list_projects_for_user(user['id']) self.assertEqual(1, len(user_projects)) self.assertIn(root_project, user_projects) # TODO(henry-nash): The test above uses list_projects_for_user # which may, in a subsequent patch, be re-implemented to call # list_role_assignments and then report only the distinct projects. # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once list_projects_for_user # has been re-implemented then the manual tests above can be # refactored. test_plan = { # A domain with a project and sub-project, plus a user. # Also, create 2 roles. 'entities': { 'domains': {'id': DEFAULT_DOMAIN_ID, 'users': 1, 'projects': {'project': 1}}, 'roles': 2}, # A direct role and an inherited role on the parent 'assignments': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'project': 0, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] - should get back # one direct role plus one inherited role. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'project': 1, 'indirect': {'project': 0}}]} ] } test_plan_with_os_inherit_disabled = { 'tests': [ # List all effective assignments for user[0] - should only get # back the one direct role. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0}]} ] } self.config_fixture.config(group='os_inherit', enabled=True) test_data = self.execute_assignment_plan(test_plan) self.config_fixture.config(group='os_inherit', enabled=False) # Pass the existing test data in to allow execution of 2nd test plan self.execute_assignment_cases( test_plan_with_os_inherit_disabled, test_data) def test_list_projects_for_user_with_inherited_group_grants(self): """"""Test inherited group roles. Test Plan: - Enable OS-INHERIT extension - Create two domains, each with two projects - Create a user and group - Make the user a member of the group - Assign a user role two projects, an inherited group role to one domain and an inherited regular role on the other domain - Get a list of projects for user, should return both pairs of projects from the domain, plus the one separate project """""" self.config_fixture.config(group='os_inherit', enabled=True) domain = unit.new_domain_ref() self.resource_api.create_domain(domain['id'], domain) domain2 = unit.new_domain_ref() self.resource_api.create_domain(domain2['id'], domain2) project1 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project1['id'], project1) project2 = unit.new_project_ref(domain_id=domain['id']) self.resource_api.create_project(project2['id'], project2) project3 = unit.new_project_ref(domain_id=domain2['id']) self.resource_api.create_project(project3['id'], project3) project4 = unit.new_project_ref(domain_id=domain2['id']) self.resource_api.create_project(project4['id'], project4) user1 = unit.new_user_ref(domain_id=domain['id']) user1 = self.identity_api.create_user(user1) group1 = unit.new_group_ref(domain_id=domain['id']) group1 = self.identity_api.create_group(group1) self.identity_api.add_user_to_group(user1['id'], group1['id']) # Create 4 grants: # - one user grant on a project in domain2 # - one user grant on a project in the default domain # - one inherited user grant on domain # - one inherited group grant on domain2 self.assignment_api.create_grant(user_id=user1['id'], project_id=project3['id'], role_id=self.role_member['id']) self.assignment_api.create_grant(user_id=user1['id'], project_id=self.tenant_bar['id'], role_id=self.role_member['id']) self.assignment_api.create_grant(user_id=user1['id'], domain_id=domain['id'], role_id=self.role_admin['id'], inherited_to_projects=True) self.assignment_api.create_grant(group_id=group1['id'], domain_id=domain2['id'], role_id=self.role_admin['id'], inherited_to_projects=True) # Should get back all five projects, but without a duplicate for # project3 (since it has both a direct user role and an inherited role) user_projects = self.assignment_api.list_projects_for_user(user1['id']) self.assertEqual(5, len(user_projects)) # TODO(henry-nash): The test above uses list_projects_for_user # which may, in a subsequent patch, be re-implemented to call # list_role_assignments and then report only the distinct projects. # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once list_projects_for_user # has been re-implemented then the manual tests above can be # refactored. test_plan = { # A domain with a 1 project, plus a second domain with 2 projects, # as well as a user & group and a 3rd domain with 2 projects. # Also, created 2 roles. 'entities': {'domains': [{'projects': 1}, {'users': 1, 'groups': 1, 'projects': 2}, {'projects': 2}], 'roles': 2}, 'group_memberships': [{'group': 0, 'users': [0]}], 'assignments': [{'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 0, 'project': 3}, {'user': 0, 'role': 1, 'domain': 1, 'inherited_to_projects': True}, {'user': 0, 'role': 1, 'domain': 2, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] # Should get back both direct roles plus roles on both projects # from each domain. Duplicates should not be filtered out. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 3}, {'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 1, 'project': 1, 'indirect': {'domain': 1}}, {'user': 0, 'role': 1, 'project': 2, 'indirect': {'domain': 1}}, {'user': 0, 'role': 1, 'project': 3, 'indirect': {'domain': 2}}, {'user': 0, 'role': 1, 'project': 4, 'indirect': {'domain': 2}}]} ] } self.execute_assignment_plan(test_plan) def test_list_projects_for_user_with_inherited_group_project_grants(self): """"""Test inherited role assignments for groups on nested projects. Test Plan: - Enable OS-INHERIT extension - Create a hierarchy of projects with one root and one leaf project - Assign an inherited group role on root project - Assign a non-inherited group role on root project - Get a list of projects for user, should return both projects - Disable OS-INHERIT extension - Get a list of projects for user, should return only root project """""" self.config_fixture.config(group='os_inherit', enabled=True) root_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID) self.resource_api.create_project(root_project['id'], root_project) leaf_project = unit.new_project_ref(domain_id=DEFAULT_DOMAIN_ID, parent_id=root_project['id']) self.resource_api.create_project(leaf_project['id'], leaf_project) user = unit.new_user_ref(domain_id=DEFAULT_DOMAIN_ID) user = self.identity_api.create_user(user) group = unit.new_group_ref(domain_id=DEFAULT_DOMAIN_ID) group = self.identity_api.create_group(group) self.identity_api.add_user_to_group(user['id'], group['id']) # Grant inherited group role self.assignment_api.create_grant(group_id=group['id'], project_id=root_project['id'], role_id=self.role_admin['id'], inherited_to_projects=True) # Grant non-inherited group role self.assignment_api.create_grant(group_id=group['id'], project_id=root_project['id'], role_id=self.role_member['id']) # Should get back both projects: because the direct role assignment for # the root project and inherited role assignment for leaf project user_projects = self.assignment_api.list_projects_for_user(user['id']) self.assertEqual(2, len(user_projects)) self.assertIn(root_project, user_projects) self.assertIn(leaf_project, user_projects) # Disable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=False) # Should get back just root project - due the direct role assignment user_projects = self.assignment_api.list_projects_for_user(user['id']) self.assertEqual(1, len(user_projects)) self.assertIn(root_project, user_projects) # TODO(henry-nash): The test above uses list_projects_for_user # which may, in a subsequent patch, be re-implemented to call # list_role_assignments and then report only the distinct projects. # # The test plan below therefore mirrors this test, to ensure that # list_role_assignments works the same. Once list_projects_for_user # has been re-implemented then the manual tests above can be # refactored. test_plan = { # A domain with a project ans sub-project, plus a user. # Also, create 2 roles. 'entities': { 'domains': {'id': DEFAULT_DOMAIN_ID, 'users': 1, 'groups': 1, 'projects': {'project': 1}}, 'roles': 2}, 'group_memberships': [{'group': 0, 'users': [0]}], # A direct role and an inherited role on the parent 'assignments': [{'group': 0, 'role': 0, 'project': 0}, {'group': 0, 'role': 1, 'project': 0, 'inherited_to_projects': True}], 'tests': [ # List all effective assignments for user[0] - should get back # one direct role plus one inherited role. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0, 'indirect': {'group': 0}}, {'user': 0, 'role': 1, 'project': 1, 'indirect': {'group': 0, 'project': 0}}]} ] } test_plan_with_os_inherit_disabled = { 'tests': [ # List all effective assignments for user[0] - should only get # back the one direct role. {'params': {'user': 0, 'effective': True}, 'results': [{'user': 0, 'role': 0, 'project': 0, 'indirect': {'group': 0}}]} ] } self.config_fixture.config(group='os_inherit', enabled=True) test_data = self.execute_assignment_plan(test_plan) self.config_fixture.config(group='os_inherit', enabled=False) # Pass the existing test data in to allow execution of 2nd test plan self.execute_assignment_cases( test_plan_with_os_inherit_disabled, test_data) def test_list_assignments_for_tree(self): """"""Test we correctly list direct assignments for a tree"""""" # Enable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=True) test_plan = { # Create a domain with a project hierarchy 3 levels deep: # # project 0 # ____________|____________ # | | # project 1 project 4 # ______|_____ ______|_____ # | | | | # project 2 project 3 project 5 project 6 # # Also, create 1 user and 4 roles. 'entities': { 'domains': { 'projects': {'project': [{'project': 2}, {'project': 2}]}, 'users': 1}, 'roles': 4}, 'assignments': [ # Direct assignment to projects 1 and 2 {'user': 0, 'role': 0, 'project': 1}, {'user': 0, 'role': 1, 'project': 2}, # Also an inherited assignment on project 1 {'user': 0, 'role': 2, 'project': 1, 'inherited_to_projects': True}, # ...and two spoiler assignments, one to the root and one # to project 4 {'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 3, 'project': 4}], 'tests': [ # List all assignments for project 1 and its subtree. {'params': {'project': 1, 'include_subtree': True}, 'results': [ # Only the actual assignments should be returned, no # expansion of inherited assignments {'user': 0, 'role': 0, 'project': 1}, {'user': 0, 'role': 1, 'project': 2}, {'user': 0, 'role': 2, 'project': 1, 'inherited_to_projects': 'projects'}]} ] } self.execute_assignment_plan(test_plan) def test_list_effective_assignments_for_tree(self): """"""Test we correctly list effective assignments for a tree"""""" # Enable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=True) test_plan = { # Create a domain with a project hierarchy 3 levels deep: # # project 0 # ____________|____________ # | | # project 1 project 4 # ______|_____ ______|_____ # | | | | # project 2 project 3 project 5 project 6 # # Also, create 1 user and 4 roles. 'entities': { 'domains': { 'projects': {'project': [{'project': 2}, {'project': 2}]}, 'users': 1}, 'roles': 4}, 'assignments': [ # An inherited assignment on project 1 {'user': 0, 'role': 1, 'project': 1, 'inherited_to_projects': True}, # A direct assignment to project 2 {'user': 0, 'role': 2, 'project': 2}, # ...and two spoiler assignments, one to the root and one # to project 4 {'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 3, 'project': 4}], 'tests': [ # List all effective assignments for project 1 and its subtree. {'params': {'project': 1, 'effective': True, 'include_subtree': True}, 'results': [ # The inherited assignment on project 1 should appear only # on its children {'user': 0, 'role': 1, 'project': 2, 'indirect': {'project': 1}}, {'user': 0, 'role': 1, 'project': 3, 'indirect': {'project': 1}}, # And finally the direct assignment on project 2 {'user': 0, 'role': 2, 'project': 2}]} ] } self.execute_assignment_plan(test_plan) def test_list_effective_assignments_for_tree_with_mixed_assignments(self): """"""Test that we correctly combine assignments for a tree. In this test we want to ensure that when asking for a list of assignments in a subtree, any assignments inherited from above the subtree are correctly combined with any assignments within the subtree itself. """""" # Enable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=True) test_plan = { # Create a domain with a project hierarchy 3 levels deep: # # project 0 # ____________|____________ # | | # project 1 project 4 # ______|_____ ______|_____ # | | | | # project 2 project 3 project 5 project 6 # # Also, create 2 users, 1 group and 4 roles. 'entities': { 'domains': { 'projects': {'project': [{'project': 2}, {'project': 2}]}, 'users': 2, 'groups': 1}, 'roles': 4}, # Both users are part of the same group 'group_memberships': [{'group': 0, 'users': [0, 1]}], # We are going to ask for listing of assignment on project 1 and # it's subtree. So first we'll add two inherited assignments above # this (one user and one for a group that contains this user). 'assignments': [{'user': 0, 'role': 0, 'project': 0, 'inherited_to_projects': True}, {'group': 0, 'role': 1, 'project': 0, 'inherited_to_projects': True}, # Now an inherited assignment on project 1 itself, # which should ONLY show up on its children {'user': 0, 'role': 2, 'project': 1, 'inherited_to_projects': True}, # ...and a direct assignment on one of those # children {'user': 0, 'role': 3, 'project': 2}, # The rest are spoiler assignments {'user': 0, 'role': 2, 'project': 5}, {'user': 0, 'role': 3, 'project': 4}], 'tests': [ # List all effective assignments for project 1 and its subtree. {'params': {'project': 1, 'user': 0, 'effective': True, 'include_subtree': True}, 'results': [ # First, we should see the inherited user assignment from # project 0 on all projects in the subtree {'user': 0, 'role': 0, 'project': 1, 'indirect': {'project': 0}}, {'user': 0, 'role': 0, 'project': 2, 'indirect': {'project': 0}}, {'user': 0, 'role': 0, 'project': 3, 'indirect': {'project': 0}}, # Also the inherited group assignment from project 0 on # the subtree {'user': 0, 'role': 1, 'project': 1, 'indirect': {'project': 0, 'group': 0}}, {'user': 0, 'role': 1, 'project': 2, 'indirect': {'project': 0, 'group': 0}}, {'user': 0, 'role': 1, 'project': 3, 'indirect': {'project': 0, 'group': 0}}, # The inherited assignment on project 1 should appear only # on its children {'user': 0, 'role': 2, 'project': 2, 'indirect': {'project': 1}}, {'user': 0, 'role': 2, 'project': 3, 'indirect': {'project': 1}}, # And finally the direct assignment on project 2 {'user': 0, 'role': 3, 'project': 2}]} ] } self.execute_assignment_plan(test_plan) def test_list_effective_assignments_for_tree_with_domain_assignments(self): """"""Test we correctly honor domain inherited assignments on the tree"""""" # Enable OS-INHERIT extension self.config_fixture.config(group='os_inherit', enabled=True) test_plan = { # Create a domain with a project hierarchy 3 levels deep: # # project 0 # ____________|____________ # | | # project 1 project 4 # ______|_____ ______|_____ # | | | | # project 2 project 3 project 5 project 6 # # Also, create 1 user and 4 roles. 'entities': { 'domains': { 'projects': {'project': [{'project': 2}, {'project': 2}]}, 'users': 1}, 'roles': 4}, 'assignments': [ # An inherited assignment on the domain (which should be # applied to all the projects) {'user': 0, 'role': 1, 'domain': 0, 'inherited_to_projects': True}, # A direct assignment to project 2 {'user': 0, 'role': 2, 'project': 2}, # ...and two spoiler assignments, one to the root and one # to project 4 {'user': 0, 'role': 0, 'project': 0}, {'user': 0, 'role': 3, 'project': 4}], 'tests': [ # List all effective assignments for project 1 and its subtree. {'params': {'project': 1, 'effective': True, 'include_subtree': True}, 'results': [ # The inherited assignment from the domain should appear # only on the part of the subtree we are interested in {'user': 0, 'role': 1, 'project': 1, 'indirect': {'domain': 0}}, {'user': 0, 'role': 1, 'project': 2, 'indirect': {'domain': 0}}, {'user': 0, 'role': 1, 'project': 3, 'indirect': {'domain': 0}}, # And finally the direct assignment on project 2 {'user': 0, 'role': 2, 'project': 2}]} ] } self.execute_assignment_plan(test_plan) def test_list_user_ids_for_project_with_inheritance(self): test_plan = { # A domain with a project and sub-project, plus four users, # two groups, as well as 4 roles. 'entities': { 'domains': {'id': DEFAULT_DOMAIN_ID, 'users': 4, 'groups': 2, 'projects': {'project': 1}}, 'roles': 4}, # Each group has a unique user member 'group_memberships': [{'group': 0, 'users': [1]}, {'group': 1, 'users': [3]}], # Set up assignments so that there should end up with four # effective assignments on project 1 - one direct, one due to # group membership and one user assignment inherited from the # parent and one group assignment inhertied from the parent. 'assignments': [{'user': 0, 'role': 0, 'project': 1}, {'group': 0, 'role': 1, 'project': 1}, {'user': 2, 'role': 2, 'project': 0, 'inherited_to_projects': True}, {'group': 1, 'role': 3, 'project': 0, 'inherited_to_projects': True}], } # Use assignment plan helper to create all the entities and # assignments - then we'll run our own tests using the data test_data = self.execute_assignment_plan(test_plan) self.config_fixture.config(group='os_inherit', enabled=True) user_ids = self.assignment_api.list_user_ids_for_project( test_data['projects'][1]['id']) self.assertThat(user_ids, matchers.HasLength(4)) for x in range(0, 4): self.assertIn(test_data['users'][x]['id'], user_ids) ",4593,2962
openstack%2Fhorizon~stable%2Fliberty~I4d8690b035dedd7ebcacb3479d346cfb3fb324f1,openstack/horizon,stable/liberty,I4d8690b035dedd7ebcacb3479d346cfb3fb324f1,Hide delete volume if it has snapshot,MERGED,2016-02-22 10:21:23.000000000,2016-03-05 00:42:21.000000000,2016-03-05 00:42:20.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 8358}, {'_account_id': 12281}]","[{'number': 1, 'created': '2016-02-22 10:21:23.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/238e2351f8c616931b5be7cfba5ed153bb302bd8', 'message': 'Hide delete volume if it has snapshot\n\nIf the volume has a snapshot, it is not allowed to\ndelete it. In tables the delete action is hidden but\nif we go to the volume detail page, the delete action\nis available.\n\nThis patch hides the delete volume on detail page too.\n\nChange-Id: I4d8690b035dedd7ebcacb3479d346cfb3fb324f1\nCloses-Bug: #1546423\n(cherry picked from commit 49a1a6356d8239d5f463c4e09564171dcccaa662)\n'}]",0,283024,238e2351f8c616931b5be7cfba5ed153bb302bd8,11,7,1,10442,,,0,"Hide delete volume if it has snapshot

If the volume has a snapshot, it is not allowed to
delete it. In tables the delete action is hidden but
if we go to the volume detail page, the delete action
is available.

This patch hides the delete volume on detail page too.

Change-Id: I4d8690b035dedd7ebcacb3479d346cfb3fb324f1
Closes-Bug: #1546423
(cherry picked from commit 49a1a6356d8239d5f463c4e09564171dcccaa662)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/283024/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/volumes/views.py']",2,238e2351f8c616931b5be7cfba5ed153bb302bd8,bug/1546423," snapshots = cinder.volume_snapshot_list( self.request, search_opts={'volume_id': volume.id}) if snapshots: setattr(volume, 'has_snapshot', True)",,10,1
openstack%2Fhorizon~stable%2Fliberty~I27708a8fe3053dd86f08f5574492d301473997af,openstack/horizon,stable/liberty,I27708a8fe3053dd86f08f5574492d301473997af,Trust sql middleware value conversion and stick to the spec type.,MERGED,2016-02-24 14:31:09.000000000,2016-03-05 00:42:01.000000000,2016-03-05 00:42:01.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 12281}]","[{'number': 1, 'created': '2016-02-24 14:31:09.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f68a2a1241b3be5b854aaeaf926f04b1d1ee58f7', 'message': 'Trust sql middleware value conversion and stick to the spec type.\n\nWe had a fix for this for the standard launch instance dialog:\nI2c5bc22c2e024e22ad641d2b367fa3de2dd7636b\n\nBut NG dialog was forgotten.\n\nChange-Id: I27708a8fe3053dd86f08f5574492d301473997af\nCloses-Bug: #1548017\n(cherry picked from commit e822657e2dc85587d48bd7c5020e229dd058822f)\n'}]",0,284158,f68a2a1241b3be5b854aaeaf926f04b1d1ee58f7,9,5,1,4460,,,0,"Trust sql middleware value conversion and stick to the spec type.

We had a fix for this for the standard launch instance dialog:
I2c5bc22c2e024e22ad641d2b367fa3de2dd7636b

But NG dialog was forgotten.

Change-Id: I27708a8fe3053dd86f08f5574492d301473997af
Closes-Bug: #1548017
(cherry picked from commit e822657e2dc85587d48bd7c5020e229dd058822f)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/284158/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.js'],1,f68a2a1241b3be5b854aaeaf926f04b1d1ee58f7,bug/1548017," volumePromises.push(cinderAPI.getVolumes({ status: 'available', bootable: true })"," volumePromises.push(cinderAPI.getVolumes({ status: 'available', bootable: 1 })",1,1
openstack%2Fopenstack-ansible-repo_build~master~I720ccaa576e62cf321a986e1f724417532ef65da,openstack/openstack-ansible-repo_build,master,I720ccaa576e62cf321a986e1f724417532ef65da,Remove allow-all-external from pip install/wheel commands,MERGED,2016-03-04 09:38:34.000000000,2016-03-05 00:31:35.000000000,2016-03-05 00:31:35.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-04 09:38:34.000000000', 'files': ['tasks/repo_build.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/8ef7855ebe868fe67cd56a5afab1992917ecf595', 'message': 'Remove allow-all-external from pip install/wheel commands\n\nAs per the resulting log when using the option, --allow-all-external\nhas been deprecated and will be removed in the future. Due to\nchanges in the repository protocol, it no longer has any effect.\n\nChange-Id: I720ccaa576e62cf321a986e1f724417532ef65da\n'}]",0,288332,8ef7855ebe868fe67cd56a5afab1992917ecf595,9,4,1,6816,,,0,"Remove allow-all-external from pip install/wheel commands

As per the resulting log when using the option, --allow-all-external
has been deprecated and will be removed in the future. Due to
changes in the repository protocol, it no longer has any effect.

Change-Id: I720ccaa576e62cf321a986e1f724417532ef65da
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/32/288332/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/repo_build.yml'],1,8ef7855ebe868fe67cd56a5afab1992917ecf595,pip-options-update,, --allow-all-external \ --allow-all-external \,0,2
openstack%2Fmurano~master~Ie5de5aa17ffd535ce9ae08514dc00175a037d511,openstack/murano,master,Ie5de5aa17ffd535ce9ae08514dc00175a037d511,"Wrong usage of ""an"" in the docstring:",ABANDONED,2016-01-12 03:23:10.000000000,2016-03-05 00:28:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 12597}, {'_account_id': 13323}, {'_account_id': 14107}, {'_account_id': 15168}, {'_account_id': 16237}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-01-12 03:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/109f22ff2bb5e82a8bdfc27eca3f6324bf6db947', 'message': 'Wrong usage of ""an"" in the mesages:\n\nan tenant-id -> a tenant-id\n\nChange-Id: Ie5de5aa17ffd535ce9ae08514dc00175a037d511\n'}, {'number': 2, 'created': '2016-01-18 06:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ce53690dded9ceeedd082ff0bd946a3ff35a1cb6', 'message': 'Wrong usage of ""an"" in the mesages:\n\nan tenant-id -> a tenant-id\nan relation source -> a relation source\nan wrong environment -> a wrong environment\nan template -> a template\n\nChange-Id: Ie5de5aa17ffd535ce9ae08514dc00175a037d511\n'}, {'number': 3, 'created': '2016-01-18 08:37:49.000000000', 'files': ['murano/api/v1/templates.py', 'murano/tests/unit/api/v1/test_env_templates.py', 'murano/tests/functional/api/v1/test_env_templates.py', 'murano/policy/modify/actions/default_actions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/da2746d53e2334f1639d2933a63c4da879c20356', 'message': 'Wrong usage of ""an"" in the docstring:\n\nan tenant-id -> a tenant-id\nan relation source -> a relation source\nan wrong environment -> a wrong environment\nan template -> a template\n\nChange-Id: Ie5de5aa17ffd535ce9ae08514dc00175a037d511\n'}]",0,266129,da2746d53e2334f1639d2933a63c4da879c20356,26,8,3,17130,,,0,"Wrong usage of ""an"" in the docstring:

an tenant-id -> a tenant-id
an relation source -> a relation source
an wrong environment -> a wrong environment
an template -> a template

Change-Id: Ie5de5aa17ffd535ce9ae08514dc00175a037d511
",git fetch https://review.opendev.org/openstack/murano refs/changes/29/266129/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/api/v1/templates.py'],1,109f22ff2bb5e82a8bdfc27eca3f6324bf6db947,bug/1533038," """"""It lists the env templates associated to a tenant-id."," """"""It lists the env templates associated to an tenant-id.",1,1
openstack%2Fneutron~master~I86f571c576141d3574a0b5efd0f62670ed6e2dcd,openstack/neutron,master,I86f571c576141d3574a0b5efd0f62670ed6e2dcd,hacking: remove oslo.* import check,MERGED,2016-03-03 10:03:54.000000000,2016-03-05 00:23:08.000000000,2016-03-05 00:23:07.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7448}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 11159}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 18485}]","[{'number': 1, 'created': '2016-03-03 10:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66fc3c4445e7d6b9933390962852a806de1494ba', 'message': ""hacking: remove oslo.* import check\n\nOslo libraries don't ship oslo.* namespace anymore (since Liberty). Time\nto clean those up.\n\nChange-Id: I86f571c576141d3574a0b5efd0f62670ed6e2dcd\n""}, {'number': 2, 'created': '2016-03-03 11:48:11.000000000', 'files': ['neutron/hacking/checks.py', 'neutron/tests/unit/hacking/test_checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a03a207262d3a0b4855374e7eead25136483a83', 'message': ""hacking: remove oslo.* import check\n\nOslo libraries don't ship oslo.* namespace anymore (since Liberty). Time\nto clean those up.\n\nChange-Id: I86f571c576141d3574a0b5efd0f62670ed6e2dcd\n""}]",0,287684,8a03a207262d3a0b4855374e7eead25136483a83,41,16,2,9656,,,0,"hacking: remove oslo.* import check

Oslo libraries don't ship oslo.* namespace anymore (since Liberty). Time
to clean those up.

Change-Id: I86f571c576141d3574a0b5efd0f62670ed6e2dcd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/287684/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/hacking/checks.py', 'HACKING.rst']",2,66fc3c4445e7d6b9933390962852a806de1494ba,287241,,- [N323] Enforce namespace-less imports for oslo libraries,0,23
openstack%2Fapp-catalog~master~I77c5b4d32ad4c5f45caee2132ed1789e09144c77,openstack/app-catalog,master,I77c5b4d32ad4c5f45caee2132ed1789e09144c77,Rotate recently added apps,MERGED,2016-03-02 01:09:18.000000000,2016-03-05 00:22:07.000000000,2016-03-05 00:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 9237}, {'_account_id': 9788}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-03-02 01:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/623fab48d8c3034398522f9e9106244a7d76e747', 'message': '[WIP] Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 2, 'created': '2016-03-02 23:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/a1847a9447ed18af4b25f7bf136c1c4837c5e3d7', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 3, 'created': '2016-03-02 23:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/c3c1fe83705446285b7170a3ca08fb41312b2ffc', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 4, 'created': '2016-03-03 02:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/6b746e907941f8b8179e739b40ee2ac6fed91cf8', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 5, 'created': '2016-03-04 01:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/b0e1ac7d7aeae80063c6f24d82e62abeaa2eb503', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 6, 'created': '2016-03-04 01:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/ec4ee61ef6c3ad97ba07d364a915efc2f592a546', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 7, 'created': '2016-03-04 17:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/535c7bab19eba3a7242424412636431787084276', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 8, 'created': '2016-03-04 18:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/e561f2493a1d349d9ee741eb0bc52d30559052eb', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}, {'number': 9, 'created': '2016-03-04 19:18:00.000000000', 'files': ['openstack_catalog/templates/index.html', 'openstack_catalog/web/static/images/openstack-icon.png', 'openstack_catalog/web/static/js/apps-catalog.js'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/86fec992dd98bca1296b3b6c2b84e10746c700ee', 'message': 'Rotate recently added apps\n\nThis commit will rotate the apps displayed in the ""Recently Added\nApps"" section of the front page. This is achieved by sorting the\nassets array by last modified date, picking the 15 most recent assets,\nrandomizing that list, and then displaying 5 from that randomized list.\n\nCo-Authored-By: Ryan Moe <rmoe@mirantis.com>\n\nChange-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77\n'}]",4,286927,86fec992dd98bca1296b3b6c2b84e10746c700ee,27,4,9,9788,,,0,"Rotate recently added apps

This commit will rotate the apps displayed in the ""Recently Added
Apps"" section of the front page. This is achieved by sorting the
assets array by last modified date, picking the 15 most recent assets,
randomizing that list, and then displaying 5 from that randomized list.

Co-Authored-By: Ryan Moe <rmoe@mirantis.com>

Change-Id: I77c5b4d32ad4c5f45caee2132ed1789e09144c77
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/27/286927/6 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_catalog/web/static/images/openstack-icon.png', 'openstack_catalog/web/static/js/apps-catalog.js']",2,623fab48d8c3034398522f9e9106244a7d76e747,rotate-recently-added,"var recent_apps = [];function build_recently_added () { assets.assets.sort(function(a,b) { return new Date(b.last_modified) - new Date(a.last_modified) }) sorted_assets = assets.assets.slice(0,5) sorted_assets.sort( function() { return 0.5 - Math.random() }); for (var i = 0; i < 5; i++) { if (typeof(sorted_assets[i].icon) === 'undefined') { var iconurl = ""static/images/openstack-icon.png"" } else { var iconurl = sorted_assets[i].icon.url } if (sorted_assets[i].name.length > 15) { var fittedname = sorted_assets[i].name.slice(0,13) + ""..."" } else { var fittedname = sorted_assets[i].name } if (sorted_assets[i].service.type == 'glance') { recent_apps[i] = '<div class=""inner glance""><a href=""#tab=glance-images&' } else if (sorted_assets[i].service.type == 'heat') { recent_apps[i] = '<div class=""inner heat""><a href=""#tab=heat-templates&' } else if (sorted_assets[i].service.type == 'murano') { recent_apps[i] = '<div class=""inner murano""><a href=""#tab=murano-apps&' } recent_apps[i] = recent_apps[i] + sorted_assets[i].name + '""><img src=""' + iconurl + '""><p>' + fittedname + '</p></a></div>' } } ",,36,0
openstack%2Fopenstack-ansible-lxc_hosts~master~Ie38288702a5f92388e9253b3ed220f7459ea8fa4,openstack/openstack-ansible-lxc_hosts,master,Ie38288702a5f92388e9253b3ed220f7459ea8fa4,Fix apparmor profile load handler,MERGED,2016-03-03 14:53:20.000000000,2016-03-05 00:17:52.000000000,2016-03-05 00:17:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 14:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/a866869c939eee173c13a35d01250cf24e0bbbd9', 'message': 'Fix apparmor profile load handler\n\nThe apparmor load handler has an incorrectly spelled profile name.\n\nChange-Id: Ie38288702a5f92388e9253b3ed220f7459ea8fa4\n'}, {'number': 2, 'created': '2016-03-04 23:44:48.000000000', 'files': ['handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/47de991138e48f1770cb3322f7187dd5c713ebfa', 'message': 'Fix apparmor profile load handler\n\nThe apparmor load handler has an incorrectly spelled profile name.\n\nChange-Id: Ie38288702a5f92388e9253b3ed220f7459ea8fa4\n'}]",0,287855,47de991138e48f1770cb3322f7187dd5c713ebfa,25,5,2,6816,,,0,"Fix apparmor profile load handler

The apparmor load handler has an incorrectly spelled profile name.

Change-Id: Ie38288702a5f92388e9253b3ed220f7459ea8fa4
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/55/287855/2 && git format-patch -1 --stdout FETCH_HEAD,['handlers/main.yml'],1,a866869c939eee173c13a35d01250cf24e0bbbd9,bindep-requirements, command: apparmor_parser -Kr /etc/apparmor.d/lxc-openstack, command: apparmor_parser -Kr /etc/apparmor.d/lxc-containers,1,1
openstack%2Fha-guide~master~Ibffe37cd32ce07385e193eeacbc8e0ba0d83fa47,openstack/ha-guide,master,Ibffe37cd32ce07385e193eeacbc8e0ba0d83fa47,Add the command to start and enable RabbitMQ,MERGED,2016-02-19 22:49:19.000000000,2016-03-05 00:16:06.000000000,2016-03-05 00:16:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}, {'_account_id': 16237}, {'_account_id': 19779}, {'_account_id': 20761}]","[{'number': 1, 'created': '2016-02-19 22:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/73ed438ff95960b927c317bdf562731c4a8f176b', 'message': 'Add the command to start and enable RabbitMQ\n\nChange-Id: Ibffe37cd32ce07385e193eeacbc8e0ba0d83fa47\nCloses-Bug: #1547449\n'}, {'number': 2, 'created': '2016-02-22 10:02:38.000000000', 'files': ['doc/ha-guide/source/controller-ha-rabbitmq.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/297d1025fc2a4437d9f93db123e2707e052cf7d0', 'message': 'Add the command to start and enable RabbitMQ\n\nChange-Id: Ibffe37cd32ce07385e193eeacbc8e0ba0d83fa47\nCloses-Bug: #1547449\n'}]",1,282558,297d1025fc2a4437d9f93db123e2707e052cf7d0,15,8,2,10497,,,0,"Add the command to start and enable RabbitMQ

Change-Id: Ibffe37cd32ce07385e193eeacbc8e0ba0d83fa47
Closes-Bug: #1547449
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/58/282558/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/controller-ha-rabbitmq.rst'],1,73ed438ff95960b927c317bdf562731c4a8f176b,bug/1547449,"#. Start the message queue service and configure it to start when the system boots on all nodes. On Ubuntu, it is configured by default. On CentOS, RHEL, openSUSE, and SLES: .. code-block:: console # systemctl enable rabbitmq-server.service # systemctl start rabbitmq-server.service #. Verify that the nodes are running:",#. Start RabbitMQ on all nodes and verify that the nodes are running:,13,1
openstack%2Fironic-ui~master~Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394,openstack/ironic-ui,master,Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394,Changed naming of Ironic api files,MERGED,2016-03-03 15:35:47.000000000,2016-03-05 00:16:01.000000000,2016-03-05 00:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 16352}, {'_account_id': 16628}, {'_account_id': 19380}]","[{'number': 1, 'created': '2016-03-03 15:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/97892953bee8e27c60d2e0199188944986bcd14b', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningul names for the Ironic-UI.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 2, 'created': '2016-03-03 17:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/e4e911c92d400993223a3489c25a797910809f52', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningul names for the Ironic-UI.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 3, 'created': '2016-03-03 17:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/dc064a86b1ea9b6f6bf9bd01d0df0147b5ee8e33', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 4, 'created': '2016-03-04 11:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/dd9d6ddbd6ddf6b809603114561024a5bb1577eb', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 5, 'created': '2016-03-04 11:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/36aceace75874e6212837cd482494ee4b05746de', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 6, 'created': '2016-03-04 13:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/0f47c3ad3ca910ab0c687ffe2fb7b58cccfd62c2', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 7, 'created': '2016-03-04 15:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/f2754e7c6f2dd5176818a18ce64f765cf58e3191', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 8, 'created': '2016-03-04 16:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/51e689ba125e0832892dd499b1af3520cc46f63d', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 9, 'created': '2016-03-04 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/fb1a1f973b070fc17af40cdcfe3e406174fd5dfc', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 10, 'created': '2016-03-04 18:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/8ac8a6171655629b4ed0741981c05177b8ca7408', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 11, 'created': '2016-03-04 23:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/f8fa41027d47fa894fb583fe26a4602202638245', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}, {'number': 12, 'created': '2016-03-04 23:25:13.000000000', 'files': ['ironic_ui/api/ironic_rest_api.py', 'ironic_ui/api/ironic.py'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/df7ba412ea76b203d7cf2396b145ee7ae2ab54e7', 'message': 'Changed naming of Ironic api files\n\nChanged naming of Ironic api files from horizon plugin defaults to\nmeaningful names for the Ironic-UI. Code has also been amended where\nnecessary to account for changes to file names.\n\nChange-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394\n'}]",2,287916,df7ba412ea76b203d7cf2396b145ee7ae2ab54e7,33,6,12,16628,,,0,"Changed naming of Ironic api files

Changed naming of Ironic api files from horizon plugin defaults to
meaningful names for the Ironic-UI. Code has also been amended where
necessary to account for changes to file names.

Change-Id: Ibfb60e8705d2d599bb9c15fa5aeb44c3b2e90394
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/16/287916/10 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/content/ironic/urls.py', 'ironic_ui/api/ironic_rest_api.py', 'ironic_ui/api/ironic.py']",3,97892953bee8e27c60d2e0199188944986bcd14b,split-patch,,,9,9
openstack%2Fironic-ui~master~I17e4c749038dfa9f4a8423796186c133d248fba0,openstack/ironic-ui,master,I17e4c749038dfa9f4a8423796186c133d248fba0,Added node details page to the plugin,MERGED,2016-02-23 12:14:35.000000000,2016-03-05 00:15:55.000000000,2016-03-05 00:15:55.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 16628}, {'_account_id': 19380}]","[{'number': 1, 'created': '2016-02-23 12:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/4f9bc3a47266989f3b4f0497a3465edbf481d85a', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 2, 'created': '2016-02-27 23:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a0bce0d4c76780ca5d382e924f65a9e574a5d78f', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 3, 'created': '2016-02-29 21:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a2975e0cddd6952c2b4fbfe3a402ee4936b987a8', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 4, 'created': '2016-03-01 17:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/f0b0058c94b7dcf2203d2a8b1144a86020824341', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 5, 'created': '2016-03-03 15:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/3a168cec5ca6fed87464ef12fd1ab250a5dec05c', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 6, 'created': '2016-03-03 17:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/13cc9d63cb88c27003302569bb64dd5ad45dbc10', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 7, 'created': '2016-03-04 11:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/2fabf8590325abc7d105819d0c59ab259c724e89', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 8, 'created': '2016-03-04 11:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/e87da762f609af5095c1fbbc89387888bda7cae5', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 9, 'created': '2016-03-04 15:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/d3d85ec36d70c1b59aa6df09a4114621007129da', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 10, 'created': '2016-03-04 16:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/61641261361b69cd5155d69e70bc3dbc6dc956ea', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 11, 'created': '2016-03-04 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/2227d62b60190656f4fbf98b1967ea733ead2849', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 12, 'created': '2016-03-04 18:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a7a6ef8fc12dec0a86f3a9dabcbf67367c234ca3', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 13, 'created': '2016-03-04 21:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/5dddacac05a9cd3cd3f5d32f3abb0e30731406c7', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 14, 'created': '2016-03-04 23:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/2ea4410b67a341a0667d19656fff55bd15bac30e', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 15, 'created': '2016-03-04 23:25:13.000000000', 'files': ['ironic_ui/static/dashboard/admin/ironic/node-details/sections/overview.html', 'ironic_ui/content/ironic/templates/ironic/node_detail.html', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/sections/configuration.html', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.spec.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.html'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/f230e96da5089c33825b5a2d2bf6711e01f12363', 'message': 'Added node details page to the plugin\n\nAdded details page files to the plugin.\n\nChange-Id: I17e4c749038dfa9f4a8423796186c133d248fba0\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}]",12,283542,f230e96da5089c33825b5a2d2bf6711e01f12363,43,5,15,16628,,,0,"Added node details page to the plugin

Added details page files to the plugin.

Change-Id: I17e4c749038dfa9f4a8423796186c133d248fba0
Co-Authored-By: Peter Piela <ppiela@cray.com>
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/42/283542/10 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/static/dashboard/admin/ironic/node-details/sections/overview.html', 'ironic_ui/content/ironic/templates/ironic/node_detail.html', 'ironic_ui/static/dashboard/admin/ironic/node-details/sections/configuration.html', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.spec.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.html']",6,4f9bc3a47266989f3b4f0497a3465edbf481d85a,split-patch,"<div class=""detail-page"" ng-controller=""horizon.dashboard.admin.ironic.NodeDetailsController as ctrl"" ng-init=""ctrl.init()""> <div class=""pull-right""> <action-list dropdown> <action button-type=""split-button"" action-classes=""'btn btn-default btn-sm'"" callback=""actions.powerOn"" item=""ctrl.node"" disabled=""ctrl.node['power_state']!=='power off'""> {$ 'Power on' | translate $} </action> <menu> <action button-type=""menu-item"" callback=""actions.powerOff"" item=""ctrl.node"" disabled=""ctrl.node['power_state']!=='power on'""> {$ 'Power off' | translate $} </action> <action button-type=""menu-item"" callback=""actions.promptForPutNodeInMaintenanceMode"" item=""ctrl.node"" disabled=""ctrl.node['maintenance']""> {$ 'Maintenance on' | translate $} </action> <action button-type=""menu-item"" callback=""actions.removeNodeFromMaintenanceMode"" item=""ctrl.node"" disabled=""!ctrl.node['maintenance']""> {$ 'Maintenance off' | translate $} </action> </menu> </action-list> </div> <div class=""clearfix""></div> <tabset> <tab ng-repeat=""section in ctrl.sections"" heading=""{$ section.heading $}""> <ng-include src=""section.templateUrl""></ng-include> </tab> </tabset> </div> ",,388,0
openstack%2Fpuppet-nova~stable%2Fliberty~Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7,openstack/puppet-nova,stable/liberty,Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7,Only require netaddr when needed,MERGED,2016-03-04 20:13:09.000000000,2016-03-05 00:14:23.000000000,2016-03-05 00:14:22.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10540}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-04 20:13:09.000000000', 'files': ['lib/puppet/provider/nova_floating/nova_manage.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/99bbfbb3426a1c3bb0b3966e72495117b13991dd', 'message': ""Only require netaddr when needed\n\nNot all functions of the nova_floating provider require the netaddr gem.\nIf this gets autoloaded for dependencies or otherwise, then the netaddr\ngem is required even if the provider isn't instantiated.\n\nChange-Id: Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7\n(cherry picked from commit cff330053d11620bccea3bb2216c1a787767a3b5)\n""}]",0,288718,99bbfbb3426a1c3bb0b3966e72495117b13991dd,9,4,1,8482,,,0,"Only require netaddr when needed

Not all functions of the nova_floating provider require the netaddr gem.
If this gets autoloaded for dependencies or otherwise, then the netaddr
gem is required even if the provider isn't instantiated.

Change-Id: Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7
(cherry picked from commit cff330053d11620bccea3bb2216c1a787767a3b5)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/18/288718/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/nova_floating/nova_manage.rb'],1,99bbfbb3426a1c3bb0b3966e72495117b13991dd,hooks, require 'netaddr' require 'netaddr',require 'netaddr' ,2,2
openstack%2Fmanila~master~I3c883b652f83115434ede89fc12d17aa962af86d,openstack/manila,master,I3c883b652f83115434ede89fc12d17aa962af86d,Admin networks in NetApp cDOT multi-SVM driver,MERGED,2016-02-18 16:44:16.000000000,2016-03-05 00:13:48.000000000,2016-02-27 00:32:37.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-18 16:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9ca5af1167b450927ce415764cfc3783e9ca4180', 'message': 'Admin networks in NetApp cDOT multi-SVM driver\n\nThe admin network is needed by the share migration service.\nThis commit creates exactly one admin LIF for each cDOT\nshare server (DHSS=True) if an admin network is configured\nin manila.conf.\n\nImplements: blueprint netapp-cdot-admin-network\nChange-Id: I3c883b652f83115434ede89fc12d17aa962af86d\n'}, {'number': 3, 'created': '2016-02-26 20:08:00.000000000', 'files': ['manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_single_svm.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/fakes.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_single_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_multi_svm.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_multi_svm.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/88dd551bf789d61ae7a08fb059ac22b4488b7cb9', 'message': 'Admin networks in NetApp cDOT multi-SVM driver\n\nThe admin network is needed by the share migration service.\nThis commit creates exactly one admin LIF for each cDOT\nshare server (DHSS=True) if an admin network is configured\nin manila.conf.\n\nImplements: blueprint netapp-cdot-admin-network\nDepends-On: Ibb88c64ddd899c09cd148f398e21ac613be9f15b\nChange-Id: I3c883b652f83115434ede89fc12d17aa962af86d\n'}]",0,281950,88dd551bf789d61ae7a08fb059ac22b4488b7cb9,41,14,2,11865,,,0,"Admin networks in NetApp cDOT multi-SVM driver

The admin network is needed by the share migration service.
This commit creates exactly one admin LIF for each cDOT
share server (DHSS=True) if an admin network is configured
in manila.conf.

Implements: blueprint netapp-cdot-admin-network
Depends-On: Ibb88c64ddd899c09cd148f398e21ac613be9f15b
Change-Id: I3c883b652f83115434ede89fc12d17aa962af86d
",git fetch https://review.opendev.org/openstack/manila refs/changes/50/281950/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_single_svm.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/fakes.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_single_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_multi_svm.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_multi_svm.py']",11,9ca5af1167b450927ce415764cfc3783e9ca4180,bp/netapp-cdot-admin-network," self.mock_object(self.library, '_create_vserver_admin_lif') self.library._create_vserver_admin_lif.assert_called_with( vserver_name, vserver_client, fake.NETWORK_INFO, fake.IPSPACE) network_info['network_allocations'][0]['segmentation_id'] = None network_info['network_allocations'][0]['network_type'] = network_type '_get_lif_name', mock.Mock(side_effect=['fake_lif1', 'fake_lif2'])) self.mock_object(self.library, '_create_lif') self.library._create_lif.assert_has_calls([ mock.call('fake_vserver_client', fake.VSERVER1, fake.IPSPACE, fake.CLUSTER_NODES[0], 'fake_lif1', fake.NETWORK_INFO['network_allocations'][0]), mock.call('fake_vserver_client', fake.VSERVER1, fake.IPSPACE, fake.CLUSTER_NODES[1], 'fake_lif2', fake.NETWORK_INFO['network_allocations'][1])]) def test_create_vserver_admin_lif(self): self.mock_object(self.library._client, 'list_cluster_nodes', mock.Mock(return_value=fake.CLUSTER_NODES)) self.mock_object(self.library, '_get_lif_name', mock.Mock(return_value='fake_admin_lif')) self.mock_object(self.library, '_create_lif') self.library._create_vserver_admin_lif(fake.VSERVER1, 'fake_vserver_client', fake.NETWORK_INFO, fake.IPSPACE) self.library._create_lif.assert_has_calls([ mock.call('fake_vserver_client', fake.VSERVER1, fake.IPSPACE, fake.CLUSTER_NODES[0], 'fake_admin_lif', fake.NETWORK_INFO['admin_network_allocations'][0])]) def test_create_vserver_admin_lif_no_admin_network(self): fake_network_info = copy.deepcopy(fake.NETWORK_INFO) fake_network_info['admin_network_allocations'] = [] self.mock_object(self.library._client, 'list_cluster_nodes', mock.Mock(return_value=fake.CLUSTER_NODES)) self.mock_object(self.library, '_get_lif_name', mock.Mock(return_value='fake_admin_lif')) self.mock_object(self.library, '_create_lif') self.library._create_vserver_admin_lif(fake.VSERVER1, 'fake_vserver_client', fake_network_info, fake.IPSPACE) self.assertFalse(self.library._create_lif.called) def test_get_lif_name(self): result = self.library._get_lif_name( 'fake_node', fake.NETWORK_INFO['network_allocations'][0]) self.assertEqual('os_132dbb10-9a36-46f2-8d89-3d909830c356', result) def test_create_lif(self): self.mock_object(self.library, '_get_node_data_port', mock.Mock(return_value='fake_port')) self.library._create_lif(vserver_client, 'fake_vserver', 'fake_ipspace', 'fake_node', 'fake_lif', fake.NETWORK_INFO['network_allocations'][0]) mock.call('10.10.10.10', '255.255.255.0', '1000', 'fake_node', 'fake_port', 'fake_vserver', 'fake_lif', 'fake_ipspace')]) self.mock_object(self.library, '_get_node_data_port', mock.Mock(return_value='fake_port')) self.library._create_lif(vserver_client, 'fake_vserver', fake.IPSPACE, 'fake_node', 'fake_lif', fake.NETWORK_INFO['network_allocations'][0]) def test_get_admin_network_allocations_number(self): result = self.library.get_admin_network_allocations_number( 'fake_admin_network_api') self.assertEqual(1, result) def test_get_admin_network_allocations_number_no_admin_network(self): result = self.library.get_admin_network_allocations_number(None) self.assertEqual(0, result) "," network_info['segmentation_id'] = None network_info['network_type'] = network_type '_get_node_data_port', mock.Mock(return_value=fake.NODE_DATA_PORT)) self.mock_object(self.library, '_create_lif_if_nonexistent') self.library._create_lif_if_nonexistent.assert_has_calls([ mock.call( fake.VSERVER1, fake.NETWORK_INFO['network_allocations'][0]['id'], fake.NETWORK_INFO['segmentation_id'], fake.CLUSTER_NODES[0], fake.NODE_DATA_PORT, fake.NETWORK_INFO['network_allocations'][0]['ip_address'], fake.NETWORK_INFO_NETMASK, fake.IPSPACE, 'fake_vserver_client'), mock.call( fake.VSERVER1, fake.NETWORK_INFO['network_allocations'][1]['id'], fake.NETWORK_INFO['segmentation_id'], fake.CLUSTER_NODES[1], fake.NODE_DATA_PORT, fake.NETWORK_INFO['network_allocations'][1]['ip_address'], fake.NETWORK_INFO_NETMASK, fake.IPSPACE, 'fake_vserver_client')]) def test_create_lif_if_nonexistent(self): self.library._create_lif_if_nonexistent('fake_vserver', 'fake_allocation_id', 'fake_vlan', 'fake_node', 'fake_port', 'fake_ip', 'fake_netmask', fake.IPSPACE, vserver_client) mock.call( 'fake_ip', 'fake_netmask', 'fake_vlan', 'fake_node', 'fake_port', 'fake_vserver', 'fake_allocation_id', fake.LIF_NAME_TEMPLATE, fake.IPSPACE)]) self.library._create_lif_if_nonexistent('fake_vserver', 'fake_allocation_id', 'fake_vlan', 'fake_node', 'fake_port', 'fake_ip', 'fake_netmask', fake.IPSPACE, vserver_client)",285,115
openstack%2Fha-guide~master~I01c8d956093d98c1422693a6fad942b819717dd6,openstack/ha-guide,master,I01c8d956093d98c1422693a6fad942b819717dd6,Change controller IP addresses for HAProxy,MERGED,2016-02-13 10:08:44.000000000,2016-03-05 00:13:45.000000000,2016-03-05 00:13:45.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 10497}, {'_account_id': 14947}, {'_account_id': 19779}, {'_account_id': 20761}]","[{'number': 1, 'created': '2016-02-13 10:08:44.000000000', 'files': ['doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/controller-ha-haproxy.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/21a39a2511d64149079071d4df75ef2045e86619', 'message': 'Change controller IP addresses for HAProxy\n\nChange-Id: I01c8d956093d98c1422693a6fad942b819717dd6\nCloses-Bug: #1545232\n'}]",0,279873,21a39a2511d64149079071d4df75ef2045e86619,10,6,1,10497,,,0,"Change controller IP addresses for HAProxy

Change-Id: I01c8d956093d98c1422693a6fad942b819717dd6
Closes-Bug: #1545232
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/73/279873/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/controller-ha-haproxy.rst']",2,21a39a2511d64149079071d4df75ef2045e86619,bug/1545232, server controller1 10.0.0.12:443 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:443 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:443 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:3306 check port 9200 inter 2000 rise 2 fall 5 server controller2 10.0.0.13:3306 backup check port 9200 inter 2000 rise 2 fall 5 server controller3 10.0.0.14:3306 backup check port 9200 inter 2000 rise 2 fall 5 server controller1 10.0.0.12:9292 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:9292 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:9292 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:9191 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:9191 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:9191 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:35357 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:35357 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:35357 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:5000 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:5000 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:5000 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8773 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8773 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8773 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8774 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8774 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8774 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8775 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8775 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8775 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8776 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8776 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8776 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8777 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8777 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8777 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:6080 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:6080 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:6080 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:9696 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:9696 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:9696 check inter 2000 rise 2 fall 5 server controller1 10.0.0.12:8080 check inter 2000 rise 2 fall 5 server controller2 10.0.0.13:8080 check inter 2000 rise 2 fall 5 server controller3 10.0.0.14:8080 check inter 2000 rise 2 fall 5, server controller1 10.0.0.1:443 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:443 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:443 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:3306 check port 9200 inter 2000 rise 2 fall 5 server controller2 10.0.0.2:3306 backup check port 9200 inter 2000 rise 2 fall 5 server controller3 10.0.0.3:3306 backup check port 9200 inter 2000 rise 2 fall 5 server controller1 10.0.0.1:9292 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:9292 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:9292 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:9191 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:9191 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:9191 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:35357 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:35357 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:35357 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:5000 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:5000 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:5000 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8773 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8773 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8773 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8774 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8774 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8774 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8775 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8775 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8775 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8776 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8776 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8776 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8777 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8777 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8777 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:6080 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:6080 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:6080 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:9696 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:9696 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:9696 check inter 2000 rise 2 fall 5 server controller1 10.0.0.1:8080 check inter 2000 rise 2 fall 5 server controller2 10.0.0.2:8080 check inter 2000 rise 2 fall 5 server controller3 10.0.0.3:8080 check inter 2000 rise 2 fall 5,51,46
openstack%2Fcinder-specs~master~I9fc6870ea657906e9ff35b3134e6b61bf69a4193,openstack/cinder-specs,master,I9fc6870ea657906e9ff35b3134e6b61bf69a4193,Spec for Cheesecake approach to replication,MERGED,2016-01-29 14:43:40.000000000,2016-03-05 00:12:40.000000000,2016-01-29 16:34:34.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 12924}, {'_account_id': 13258}, {'_account_id': 16917}, {'_account_id': 20531}]","[{'number': 1, 'created': '2016-01-29 14:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0ed5ca402840960a680748443035c5c56ccdf32c', 'message': 'Spec for Cheesecake approach to replication\n\nScale back a bit again, nail this one before M since nothing has\nreleased on old version and move on to Tiramisu.\n\nChange-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193\n'}, {'number': 2, 'created': '2016-01-29 15:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/59024a31004036a6bd5d35a406fab2692152650c', 'message': 'Spec for Cheesecake approach to replication\n\nScale back a bit again, nail this one before M since nothing has\nreleased on old version and move on to Tiramisu.\n\nChange-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193\n'}, {'number': 3, 'created': '2016-01-29 15:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b2a21f39f22e7914cc1e18bf96cc496ae781c685', 'message': 'Spec for Cheesecake approach to replication\n\nScale back a bit again, nail this one before M since nothing has\nreleased on old version and move on to Tiramisu.\n\nChange-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193\n'}, {'number': 4, 'created': '2016-01-29 16:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1953218ef758af1a726627e0106dcb9b7cf4bc12', 'message': 'Spec for Cheesecake approach to replication\n\nScale back a bit again, nail this one before M since nothing has\nreleased on old version and move on to Tiramisu.\n\nChange-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193\n'}, {'number': 5, 'created': '2016-01-29 16:15:56.000000000', 'files': ['specs/mitaka/cheesecake.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/be5cbb9bd2b9d2a87185c7de24d8d4ceaf6b2b80', 'message': 'Spec for Cheesecake approach to replication\n\nScale back a bit again, nail this one before M since nothing has\nreleased on old version and move on to Tiramisu.\n\nChange-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193\n'}]",50,274088,be5cbb9bd2b9d2a87185c7de24d8d4ceaf6b2b80,31,11,5,2243,,,0,"Spec for Cheesecake approach to replication

Scale back a bit again, nail this one before M since nothing has
released on old version and move on to Tiramisu.

Change-Id: I9fc6870ea657906e9ff35b3134e6b61bf69a4193
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/88/274088/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/cheesecake.rst'],1,0ed5ca402840960a680748443035c5c56ccdf32c,274088,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Cheesecake ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/cheesecake This spec proposes further refinement to the Cinder replication. After more vendors have tried to implement replication and we've learned more lessons about the differences in backends and their semantics we've decided we should step back and look at simplifying this even further. The goal of the new design is to address a large amount of confusion and differences in interpretation. Rather than try and cover multiple use cases in the first iteration, this spec aims to address a single fairly well defined use case. Then we can iterate and move on from there. Problem description =================== The existing design is great for some backends, but is challenging for many devices to fit in to. It's also filled with pitfalls with the question of managed/unmanaged, not to mention trying to deal with failing over some volumes and leaving others. The concept of failing over on a volume basis instead of on a device basis while nice for testing doesn't fit well into the intended use case and results in quite a bit of complexity and also is not something that a number of backends can even support. Use Cases ========= This is intended to be a DR mechanism. The model Use Case is a catastrophic event occurring on the backend storage device, but some or all volumes that were on the primary backend may have been replicated to another backend device in which case those volumes may still be accessible. The flow of events are as follows: 1. Admin configures a backend device to enable replication. We have a configured cinder backend just as always (Backend-A) but we add config options for a replication target (Backend-B). a. We no longer deal with differentiation between managed and unmanaged Now, to enable a replication target(s), the replication_target entry is the ONLY method allowed and is specified as a section in the driver. b. Depending on the back-end device enabling this may mean that EVERY volume created on the device is replicated, or for those that have the capability and if admins choose to do so a Volume-Type of ""replicated=True"" can be created and used by tenants. Note that if the backend only supports repliating ""all"" volumes, or if the Admin wants to set things up so that ""all"" volumes are replicated that the Type creation may or may not be necessary. 2. Tenant creates a Volume that is replicated (either by specifying apropriate Type, or by the nature of the backend device) Result in this example is a Volume we'll call ""Foo"" 3. Backend-A is caught in the crossfire of a water ballloon fight that shouldn't have been taking place in the data center, and looses it's magic smoke, ""It's dead Jim!"" 4. Admin issues ""cinder replication-failover"" command with possible arguments a. Call propogates to Cinder Driver, which performs appropriate steps for that driver to now point to the secondary (target) device (Backend-B). b. The Service Table in Cinder's database is updated to indicate that a replication failover event has occured, and the driver is currently pointing to an alternate taret device. In this scenario volumes that were replicated should still be accessible by tenants. The usage may or may not be restricted depending on options provided in the failover command. If no restrictions are set we expect to be able to continue using them as we would prior to the failure event. Volumes that were attached/in-use are a special case in this scenario and will require additional steps. The Tenant will be required in this case to detach the volumes from any instances manually. Cinder does not have the ability to call Nova's volume-detach methods, so this has to be done by the Tenant or the Admin. c. Freeze option provided as an argument to Failover The failover command includes a ""freeze"" option. This option indicates that a volume may still be read or written to, HOWEVER that we will not allow any additonal resource create or delete options until an admin issues an ""thaw"" command. This means that attempts to call snapshot-create, xxx-delete, resize, retype etc should return an InvalidCommand error. This is intended to try and keep things in as stable of a state as possible, to help in recovering from the catastrophic event. 5. How to get back to ""normal"" a. If the oroginal backend device is salvageable, the failover command should be used to switch back to the original primary device. This of course means that there should be some mechanism on the backend and operations performed by the Admin that ensures the resources still exist on the Primary (Backend-A) and that their data is updated based on what may have been written while they were hosted on Backend-B. This indicates that for backends to support this something like 2-way replication is going to be required. For backends that can't support this, it's likely that we'll need to instead swap the primary and secondary configuration info (Reconfigure making Backend-B the Primary). It's important to emphasize, if the volume is not of type ""replicated"" it will NOT be accessible after the failover. This approach fails over the entire backend to another device. Proposed change =============== One of the goals of this patch is to try and eliminate some of the challenges with the differences between manage and unmanaged replication tarets. In this model we make this easier for backends. Rather than having some volumes on one backend and some on another and not doing things like stats update, we now fail over the entire backend including stats updates and everything. This does mean that non-replicated type volumes will be left behind and inaccessible (unavailable), that's an expectation in this use case (the device burst into flames). For simplicity in the first iteration, we're specifying the device as a driver parameter in the config file and we're not trying to just read in a secondary configured backend device. [driver-foo] volume_driver=xxxx valid_replication_devices='remote_device={'some unique access meta}',... NOTE That the remote_device access MUST be handled via the configured driver. * Add the following API calls replication-enable/disable 'backend-name' This will issue a command to the backend to update the capabilities being reported for replication. replication-failover [--freeze] 'backend-name' This triggers the failover event, assuming that the current primary backend is no longer accessible. Special considerations ----------------- * volume-types There should not be a requirement of an exact match of volume-types between the primary and secondary volumes in the replication set. If a backend ""can"" match these exactly, then that's fine, if they can't, that's ok as well. Ideally, if the volume fails over the type specifications would match, but if this isn't possible it's probably acceptable, and if it needs to be handled by the driver via a retype/modification after the failover, that's fine as well. * async vs sync This spec assumes async replication only for now. It can easily be extended later for the synchronous case, but for now it's specific to async. If/When sync is added it can be specified as an additional backend capability. It's also possible for this to be specified via extra-specs if desired. * transport Implementation details and the *how* the backend performs replication is completely up to the backend. The requirements are that the interfaces and end results are consistent. * The Volume driver for the replicated backend MUST have the ability to communicate with the other backend and route the calls correctly based on what's selected as the current primary. One example of an important detail here is the ""update stats"" call. In the case of a failover, it is expected that the secondary/target device is now reporting stats/capabilities, NOT the now *dead* backend. * Tenant visibility The visibility by tenants is LIMITED!!! In other words the tenant should know very little about what's going on. The only information that should really be propogated is that the backend and the volume is in a ""failed-over"" state, and if it's ""frozen"". In the case of a failover where volumes are no longer available on the new backend, the driver should raise a NotFound Exception for an API calls that attempt to access them. Alternatives ------------ There are all sorts of alternatives, the most obvious of which is to leave the implementation we have and iron it out. Maybe that's good, maybe that's not. In my opinion this approach is simpler, easier to maintain and more flexible; otherwise I wouldn't propose it. The fact that there's only one vendor that's implemented replication in the existing setup and they have a number of open issues currently we're not causing a terrible amount of churn or disturbance if we move forward with this now. The result will be something that should be easier to implement and as an option will have less impact on the core code. Data model impact ----------------- * What new data objects and/or database schema changes is this going to require? We'll need a new column in the host table that indicates ""failed-over"" and ""frozen"" status. We'll also need a new property for volumes, indicating if they're failed-over and if they're frozen or not. REST API impact --------------- replication-enable/disable 'backend-name' This will issue a command to the backend to update the capabilities being reported for replication. replication-failover [--freeze] 'backend-name' This triggers the failover event, assuming that the current primary backend is no longer accessible. Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? Nope * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? Nope, not that I know of * Does this change involve cryptography or hashing? Nope, not that I know of * Does this change require the use of sudo or any elevated privileges? Nope, not that I know of * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Nope, not that I know of * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. Nope, not that I know of For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Notifications impact -------------------- We'd certainly want to add a notification event that we ""failed over"" Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-cinderclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition but when considering large scale deployments the proposed call may in fact be performed on hundreds of nodes. * Scheduler filters get called once per host for every volume being created, so any latency they introduce is linear with the size of the system. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries can have a profound impact on performance, especially in critical sections of code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other volume drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that targets (LVM) are stored in, how do we handle any used directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the volumes in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other volume drivers would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: john-griffith Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in cinder, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Cinder (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. Obviously this is going to need docs References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. link to any vendor documentation) * Anything else you feel it is worthwhile to refer to The specs process is a bit much, we should revisit it. It's rather bloated, and while the first few sections are fantastic for requiring thought and planning, towards the end it just gets silly. ",,430,0
openstack%2Fneutron-lbaas~master~I32d3b122ea098302290dddd2df0638d24c82089e,openstack/neutron-lbaas,master,I32d3b122ea098302290dddd2df0638d24c82089e,WIP - Test fix to run agent during dsvm test,ABANDONED,2016-03-01 00:18:26.000000000,2016-03-05 00:10:58.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 12040}, {'_account_id': 15226}]","[{'number': 1, 'created': '2016-03-01 00:18:26.000000000', 'files': ['neutron_lbaas/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b470c6a700d709f7529c2b796246de3eb7f2ef03', 'message': 'WIP - Test fix to run agent during dsvm test\n\nChange-Id: I32d3b122ea098302290dddd2df0638d24c82089e\n'}]",0,286332,b470c6a700d709f7529c2b796246de3eb7f2ef03,6,5,1,10980,,,0,"WIP - Test fix to run agent during dsvm test

Change-Id: I32d3b122ea098302290dddd2df0638d24c82089e
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/32/286332/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/contrib/gate_hook.sh'],1,b470c6a700d709f7529c2b796246de3eb7f2ef03,fix-namespace-test," export NEUTRON_LBAAS_SERVICE_PROVIDERV2=""LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default"" # cat > $DEVSTACK_PATH/local.conf <<EOF #[[post-config|\$NEUTRON_LBAAS_CONF]] # #[service_providers] #service_provider=LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default #EOF", cat > $DEVSTACK_PATH/local.conf <<EOF [[post-config|\$NEUTRON_LBAAS_CONF]] [service_providers] service_provider=LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default EOF,7,6
openstack%2Fpython-cinderclient~master~Ibb680769cc73bd513dee81e55817d87df5958359,openstack/python-cinderclient,master,Ibb680769cc73bd513dee81e55817d87df5958359,Add backup list sorted by data_timestamp,MERGED,2016-01-20 09:06:08.000000000,2016-03-05 00:07:47.000000000,2016-03-05 00:07:47.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 11904}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-01-20 09:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/52156cdd7c80114e6865555887a0b04b9cfcf931', 'message': 'Add backup list sorted by data_timestamp\n\nAs Mitaka implments snapshot backup function, created_at\nshows when backups are created, and data_timestamp shows\ntime when data are taken from volumes.\n\nThis patch adds data_timestamp as a sort item, so that\ncustomers can list backups sorted by data_timestamp. As\na result, they can know which backup has latest data.\n\nCloses_bug: #1536065\n\nChange-Id: Ibb680769cc73bd513dee81e55817d87df5958359\n'}, {'number': 2, 'created': '2016-02-24 02:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/52da7bbb6878645a0d24c5c8c67f5fc12b1ba350', 'message': 'Add backup list sorted by data_timestamp\n\nAs Mitaka implments snapshot backup function, created_at\nshows when backups are created, and data_timestamp shows\ntime when data are taken from volumes.\n\nThis patch adds data_timestamp as a sort item, so that\ncustomers can list backups sorted by data_timestamp. As\na result, they can know which backup has latest data.\n\nCloses_bug: #1536065\n\nChange-Id: Ibb680769cc73bd513dee81e55817d87df5958359\n'}, {'number': 3, 'created': '2016-02-24 02:20:41.000000000', 'files': ['cinderclient/base.py', 'cinderclient/tests/unit/v2/test_volume_backups.py', 'cinderclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1d0037e47bf71a11a240a287749b4c6d4e022ebf', 'message': 'Add backup list sorted by data_timestamp\n\nAs Mitaka implments snapshot backup function, created_at\nshows when backups are created, and data_timestamp shows\ntime when data are taken from volumes.\n\nThis patch adds data_timestamp as a sort item, so that\ncustomers can list backups sorted by data_timestamp. As\na result, they can know which backup has latest data.\n\nCloses-Bug: #1536065\n\nChange-Id: Ibb680769cc73bd513dee81e55817d87df5958359\n'}]",0,270067,1d0037e47bf71a11a240a287749b4c6d4e022ebf,12,4,3,15961,,,0,"Add backup list sorted by data_timestamp

As Mitaka implments snapshot backup function, created_at
shows when backups are created, and data_timestamp shows
time when data are taken from volumes.

This patch adds data_timestamp as a sort item, so that
customers can list backups sorted by data_timestamp. As
a result, they can know which backup has latest data.

Closes-Bug: #1536065

Change-Id: Ibb680769cc73bd513dee81e55817d87df5958359
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/67/270067/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/base.py', 'cinderclient/tests/unit/v2/test_volume_backups.py', 'cinderclient/tests/unit/v2/test_shell.py']",3,52156cdd7c80114e6865555887a0b04b9cfcf931,bug/1536065," def test_backup_list_data_timestamp(self): self.run_command('backup-list --sort data_timestamp') self.assert_called('GET', '/backups/detail?sort=data_timestamp') ",,25,11
openstack%2Fproject-config~master~If211df15659b4dcb820ec2a2052a72e71a86007c,openstack/project-config,master,If211df15659b4dcb820ec2a2052a72e71a86007c,Add libjpeg to bindep-fallback.txt,MERGED,2016-03-04 21:04:57.000000000,2016-03-05 00:04:06.000000000,2016-03-04 23:12:18.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-04 21:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2fa38700416f52b154474a0dc8efc2103cce390b', 'message': 'Add libjpeg to bindep-fallback.txt\n\nChange-Id: If211df15659b4dcb820ec2a2052a72e71a86007c\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}, {'number': 2, 'created': '2016-03-04 21:06:42.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1a0978267fe1acf3f81817e59b777ca87bbbad48', 'message': 'Add libjpeg to bindep-fallback.txt\n\nChange-Id: If211df15659b4dcb820ec2a2052a72e71a86007c\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,288738,1a0978267fe1acf3f81817e59b777ca87bbbad48,10,3,2,4162,,,0,"Add libjpeg to bindep-fallback.txt

Change-Id: If211df15659b4dcb820ec2a2052a72e71a86007c
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/38/288738/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,2fa38700416f52b154474a0dc8efc2103cce390b,,libjpeg-dev [platform:apt] libjpeg-turbo-devel [platform:rpm],,2,0
openstack%2Ftrove-integration~master~I8f74ab10181e7282bc4d4dca503209325907653e,openstack/trove-integration,master,I8f74ab10181e7282bc4d4dca503209325907653e,Fedora updates,MERGED,2016-02-24 14:43:31.000000000,2016-03-05 00:03:49.000000000,2016-03-05 00:03:49.000000000,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 10440}]","[{'number': 1, 'created': '2016-02-24 14:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/9b6237abd5190a2aa017580639fb8e0c630312ba', 'message': 'Fedora updates\n\nUpdates for F23 host, F22 guest:\n- unbound default Fedora requirements\n- reinstate python-mysql install\n- remove enable/start for mysqld under systemd\n- adjust mysql /etc config manipulations\n\nChange-Id: I8f74ab10181e7282bc4d4dca503209325907653e\nCloses-Bug: 1549313\n'}, {'number': 2, 'created': '2016-03-02 14:31:03.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/functions_qemu', 'scripts/files/elements/fedora-mongodb/install.d/25-trove-mongo-dep', 'scripts/files/requirements/fedora-requirements-default.txt', 'scripts/redstack', 'scripts/files/elements/fedora-mysql/post-install.d/30-register-mysql-service', 'scripts/files/elements/fedora-mysql/install.d/10-mysql', 'scripts/files/elements/fedora-postgresql/install.d/10-postgresql'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/fd2442a7f227931f7100765d37c7da95b6fa5abe', 'message': 'Fedora updates\n\nUpdates for F23 host, F22 guest:\n- unbound default Fedora requirements\n- reinstate python-mysql install\n- remove enable/start for mysqld under systemd\n- adjust mysql /etc config manipulations\n- update postgresql vendor rpm\n- fix broken pymongo install\n- make sure SSH_DIR perms are correct\n\nChange-Id: I8f74ab10181e7282bc4d4dca503209325907653e\nCloses-Bug: 1549313\n'}]",2,284162,fd2442a7f227931f7100765d37c7da95b6fa5abe,13,5,2,14823,,,0,"Fedora updates

Updates for F23 host, F22 guest:
- unbound default Fedora requirements
- reinstate python-mysql install
- remove enable/start for mysqld under systemd
- adjust mysql /etc config manipulations
- update postgresql vendor rpm
- fix broken pymongo install
- make sure SSH_DIR perms are correct

Change-Id: I8f74ab10181e7282bc4d4dca503209325907653e
Closes-Bug: 1549313
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/62/284162/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/requirements/fedora-requirements-default.txt', 'scripts/redstack', 'scripts/files/elements/fedora-mysql/post-install.d/30-register-mysql-service', 'scripts/files/elements/fedora-mysql/install.d/10-mysql']",5,9b6237abd5190a2aa017580639fb8e0c630312ba,bug/1549313,dnf -y install https://repo.mysql.com/mysql-community-release-fc22.rpm# move the config dir for now but leave /etc/my.cnf alone,dnf -y install https://dev.mysql.com/get/mysql-community-release-fc21-6.noarch.rpm# move the config until proper changes are placed in the service file for fedoramv /etc/my.cnf /etc/mysql/my.cnf,9,14
openstack%2Fpuppet-murano~master~Id7ecb475555f87c09ccfa4d9e481834939f863e9,openstack/puppet-murano,master,Id7ecb475555f87c09ccfa4d9e481834939f863e9,Replace deprecated syncdb command on migrate,MERGED,2016-03-04 15:12:50.000000000,2016-03-04 23:56:55.000000000,2016-03-04 23:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-04 15:12:50.000000000', 'files': ['manifests/dashboard.pp', 'spec/classes/murano_dashboard_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/a4fddbb1dd74f1a783f23d5bce4d651d3f59cd52', 'message': ""Replace deprecated syncdb command on migrate\n\nDashboard manifest has deprecated django 'syncdb' command, which was\nreplaced on 'migrate' since Django 1.7.\n\nChange-Id: Id7ecb475555f87c09ccfa4d9e481834939f863e9\nCloses-bug: #1529649\n""}]",0,288518,a4fddbb1dd74f1a783f23d5bce4d651d3f59cd52,7,3,1,7745,,,0,"Replace deprecated syncdb command on migrate

Dashboard manifest has deprecated django 'syncdb' command, which was
replaced on 'migrate' since Django 1.7.

Change-Id: Id7ecb475555f87c09ccfa4d9e481834939f863e9
Closes-bug: #1529649
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/18/288518/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/dashboard.pp', 'spec/classes/murano_dashboard_spec.rb']",2,a4fddbb1dd74f1a783f23d5bce4d651d3f59cd52,, :command => '/usr/share/openstack-dashboard/manage.py migrate --noinput', :command => '/usr/share/openstack-dashboard/manage.py syncdb --noinput',2,2
openstack%2Fpython-openstackclient~master~Id9d7246f89ae65273505f36dcb664996534ae986,openstack/python-openstackclient,master,Id9d7246f89ae65273505f36dcb664996534ae986,[compute] Support restore server,MERGED,2016-02-23 15:58:57.000000000,2016-03-04 23:41:42.000000000,2016-03-04 23:41:42.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6062}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-02-23 15:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b42e21b51c9c47bf08ed06a4217eed61174743c6', 'message': '[compute] Support restore server\n\nServer in soft-delete state can be restored, add this command.\n\nChange-Id: Id9d7246f89ae65273505f36dcb664996534ae986\n'}, {'number': 2, 'created': '2016-02-24 13:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5a698a04787289e92aafe2770bd0c4b42dcdbd0d', 'message': '[compute] Support restore server\n\nServer in soft-delete state can be restored, add this command.\n\nChange-Id: Id9d7246f89ae65273505f36dcb664996534ae986\n'}, {'number': 3, 'created': '2016-02-25 20:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d278e0d9c35b1cc392b56d10e144b1d101860b6c', 'message': '[compute] Support restore server\n\nServer in soft-delete state can be restored, add this command.\n\nChange-Id: Id9d7246f89ae65273505f36dcb664996534ae986\n'}, {'number': 4, 'created': '2016-03-04 15:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8680e6164385b543d66f8fad991c9fd67a253ffb', 'message': '[compute] Support restore server\n\nServer in soft-delete state can be restored, add this command.\n\nChange-Id: Id9d7246f89ae65273505f36dcb664996534ae986\n'}, {'number': 5, 'created': '2016-03-04 19:03:12.000000000', 'files': ['doc/source/commands.rst', 'doc/source/command-objects/server.rst', 'openstackclient/tests/compute/v2/test_server.py', 'releasenotes/notes/add-restore-server-d8c73e0e83df17dd.yaml', 'setup.cfg', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6902a288f8e403cfa143e5c8946ad39bcb2dc396', 'message': '[compute] Support restore server\n\nServer in soft-delete state can be restored, add this command.\n\nChange-Id: Id9d7246f89ae65273505f36dcb664996534ae986\n'}]",8,283658,6902a288f8e403cfa143e5c8946ad39bcb2dc396,21,5,5,6062,,,0,"[compute] Support restore server

Server in soft-delete state can be restored, add this command.

Change-Id: Id9d7246f89ae65273505f36dcb664996534ae986
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/58/283658/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/test_server.py', 'setup.cfg', 'openstackclient/compute/v2/server.py']",3,b42e21b51c9c47bf08ed06a4217eed61174743c6,add_restore_server,"class RestoreServer(command.Command): """"""Restore server(s)"""""" def get_parser(self, prog_name): parser = super(RestoreServer, self).get_parser(prog_name) parser.add_argument( 'server', metavar='<server>', nargs='+', help=_('Server(s) to restore (name or ID)'), ) return parser def take_action(self, parsed_args): compute_client = self.app.client_manager.compute for server in parsed_args.server: utils.find_resource( compute_client.servers, server ).restore() ",,43,0
openstack%2Fnova~master~I2edf69140897ced9751c7a5698440ee53cf1fa79,openstack/nova,master,I2edf69140897ced9751c7a5698440ee53cf1fa79,Fix path to nova-config-generator.conf file,ABANDONED,2016-03-02 19:32:09.000000000,2016-03-04 23:40:44.000000000,,"[{'_account_id': 679}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12841}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-03-02 19:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/130c7e404a8c2a9b8d1ff7b5bdc22015c81e5d9d', 'message': 'Fix path to nova-config-generator.conf file\n\nThis patch fixes issue during man build:\n\nSPHINX_DEBUG=1 sphinx-build -b man -c source source build/man\n\n```\nRunning Sphinx v1.2.3\nloading pickled environment... not yet created\nUsing openstack theme from /usr/lib/python2.7/site-packages/oslosphinx/theme\n\nException occurred:\n  File ""/root/rpmbuild/BUILD/lol/lib/python2.7/site-packages/oslo_config/sphinxconfiggen.py"", line 47, in generate_sample\n    app.config.config_generator_config_file)\nValueError: Could not find config_generator_config_file \'../../etc/nova/nova-config-generator.conf\'\n```\n\nChange-Id: I2edf69140897ced9751c7a5698440ee53cf1fa79\n'}, {'number': 2, 'created': '2016-03-02 19:36:45.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/495d18fd73203c58eb959bcce492027482af6e9c', 'message': 'Fix path to nova-config-generator.conf file\n\nThis patch fixes issue during man build:\n\nSPHINX_DEBUG=1 sphinx-build -b man -c source source build/man\n\n```\nRunning Sphinx v1.2.3\nloading pickled environment... not yet created\nUsing openstack theme from /usr/lib/python2.7/site-packages/oslosphinx/theme\n\nException occurred:\n  File ""/home/ai/virtenv/nova-env/lib/python2.7/site-packages/oslo_config/sphinxconfiggen.py"", line 47, in generate_sample\n    app.config.config_generator_config_file)\nValueError: Could not find config_generator_config_file \'../../etc/nova/nova-config-generator.conf\'\n```\n\nChange-Id: I2edf69140897ced9751c7a5698440ee53cf1fa79\n'}]",2,287403,495d18fd73203c58eb959bcce492027482af6e9c,11,6,2,12841,,,0,"Fix path to nova-config-generator.conf file

This patch fixes issue during man build:

SPHINX_DEBUG=1 sphinx-build -b man -c source source build/man

```
Running Sphinx v1.2.3
loading pickled environment... not yet created
Using openstack theme from /usr/lib/python2.7/site-packages/oslosphinx/theme

Exception occurred:
  File ""/home/ai/virtenv/nova-env/lib/python2.7/site-packages/oslo_config/sphinxconfiggen.py"", line 47, in generate_sample
    app.config.config_generator_config_file)
ValueError: Could not find config_generator_config_file '../../etc/nova/nova-config-generator.conf'
```

Change-Id: I2edf69140897ced9751c7a5698440ee53cf1fa79
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/287403/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,130c7e404a8c2a9b8d1ff7b5bdc22015c81e5d9d,,config_generator_config_file = '../etc/nova/nova-config-generator.conf',config_generator_config_file = '../../etc/nova/nova-config-generator.conf',1,1
openstack%2Foctavia~master~I8b954ac6e12ec994cb63e5b56eecac7fc67c4e83,openstack/octavia,master,I8b954ac6e12ec994cb63e5b56eecac7fc67c4e83,Block deletion of pool in use by L7Policies,MERGED,2016-02-26 09:57:11.000000000,2016-03-04 23:40:28.000000000,2016-03-04 23:36:34.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-02-26 09:57:11.000000000', 'files': ['octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_pool.py', 'octavia/common/exceptions.py', 'octavia/api/v1/controllers/pool.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/ae82d21f0c87526f993e066d40eccfa84a3ee452', 'message': 'Block deletion of pool in use by L7Policies\n\nAfter a discussion, we decided that the best user experience to have if\nthey attempt to delete a pool in use by an l7policy (even an inactive\none) is to block the deletion. This patch implements this behavior.\n\nChange-Id: I8b954ac6e12ec994cb63e5b56eecac7fc67c4e83\nCloses-Bug: 1549097\n'}]",1,285192,ae82d21f0c87526f993e066d40eccfa84a3ee452,11,6,1,11685,,,0,"Block deletion of pool in use by L7Policies

After a discussion, we decided that the best user experience to have if
they attempt to delete a pool in use by an l7policy (even an inactive
one) is to block the deletion. This patch implements this behavior.

Change-Id: I8b954ac6e12ec994cb63e5b56eecac7fc67c4e83
Closes-Bug: 1549097
",git fetch https://review.opendev.org/openstack/octavia refs/changes/92/285192/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_pool.py', 'octavia/common/exceptions.py', 'octavia/api/v1/controllers/pool.py']",4,ae82d21f0c87526f993e066d40eccfa84a3ee452,bug/1549097," if len(db_pool.l7policies) > 0: raise exceptions.PoolInUseByL7Policy( id=db_pool.id, l7policy_id=db_pool.l7policies[0].id)",,24,0
openstack%2Fpython-openstackclient~master~Id702ccaad239b916340bb17014d1ede0a28aaec9,openstack/python-openstackclient,master,Id702ccaad239b916340bb17014d1ede0a28aaec9,[compute] Add unit test for keypair,MERGED,2016-02-29 21:29:21.000000000,2016-03-04 23:39:16.000000000,2016-03-04 23:39:16.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6062}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-29 21:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0d2a904b05e78c71211ece5b1cfe7223443ade23', 'message': '[compute] Add unit test for keypair\n\nkeypair do not have functional test, this patch adds it.\n\nChange-Id: Id702ccaad239b916340bb17014d1ede0a28aaec9\n'}, {'number': 2, 'created': '2016-03-01 11:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9c0971ef890b4c256cdcfded163e70f20c0eb368', 'message': '[compute] Add unit test for keypair\n\nkeypair do not have functional test, this patch adds it.\n\nChange-Id: Id702ccaad239b916340bb17014d1ede0a28aaec9\n'}, {'number': 3, 'created': '2016-03-01 19:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/158da3714c136ab9c774773b64a0d9216931e6a3', 'message': '[compute] Add unit test for keypair\n\nkeypair do not have functional test, this patch adds it.\n\nChange-Id: Id702ccaad239b916340bb17014d1ede0a28aaec9\n'}, {'number': 4, 'created': '2016-03-04 15:22:19.000000000', 'files': ['openstackclient/tests/compute/v2/test_keypair.py', 'openstackclient/tests/compute/v2/fakes.py', 'openstackclient/compute/v2/keypair.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/042e2b7d53222618c76870effa3d74759ccc696a', 'message': '[compute] Add unit test for keypair\n\nkeypair do not have unit test, this patch adds it.\n\nChange-Id: Id702ccaad239b916340bb17014d1ede0a28aaec9\n'}]",15,286289,042e2b7d53222618c76870effa3d74759ccc696a,17,6,4,6062,,,0,"[compute] Add unit test for keypair

keypair do not have unit test, this patch adds it.

Change-Id: Id702ccaad239b916340bb17014d1ede0a28aaec9
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/89/286289/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/test_keypair.py', 'openstackclient/tests/compute/v2/fakes.py', 'openstackclient/compute/v2/keypair.py']",3,0d2a904b05e78c71211ece5b1cfe7223443ade23,add_ut_keypair,"import io with io.open(os.path.expanduser(parsed_args.public_key), ""rb"") as p:", with open(os.path.expanduser(parsed_args.public_key)) as p:,294,1
openstack%2Fpython-openstackclient~master~Ife3956a1109ffa2faf367953cc13b8cb5f64e5c2,openstack/python-openstackclient,master,Ife3956a1109ffa2faf367953cc13b8cb5f64e5c2,Updated from global requirements,MERGED,2016-03-04 17:48:05.000000000,2016-03-04 23:32:23.000000000,2016-03-04 23:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 15241}, {'_account_id': 16272}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-03-04 17:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/364afeed492d7e044d64f3e15a4e6f32570dbad1', 'message': 'Updated from global requirements\n\nChange-Id: Ife3956a1109ffa2faf367953cc13b8cb5f64e5c2\n'}, {'number': 2, 'created': '2016-03-04 19:42:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3ede46d4d089a315bc1792bca318d8481013b585', 'message': 'Updated from global requirements\n\nChange-Id: Ife3956a1109ffa2faf367953cc13b8cb5f64e5c2\n'}]",0,288609,3ede46d4d089a315bc1792bca318d8481013b585,11,5,2,11131,,,0,"Updated from global requirements

Change-Id: Ife3956a1109ffa2faf367953cc13b8cb5f64e5c2
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/09/288609/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,364afeed492d7e044d64f3e15a4e6f32570dbad1,openstack/requirements,openstacksdk>=0.8.1 # Apache-2.0,openstacksdk>=0.7.4 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~I08b90bc8e9ae09351231da57d93da70da73b9698,openstack/openstack-manuals,master,I08b90bc8e9ae09351231da57d93da70da73b9698,[cli-ref] Update python-cloudkittyclient to 0.5.0,MERGED,2016-03-04 16:25:56.000000000,2016-03-04 23:30:31.000000000,2016-03-04 23:30:31.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-03-04 16:25:56.000000000', 'files': ['doc/cli-reference/source/cloudkitty.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fce6eebb89c15d252e394b2ea8c79b88496ed694', 'message': '[cli-ref] Update python-cloudkittyclient to 0.5.0\n\nChange-Id: I08b90bc8e9ae09351231da57d93da70da73b9698\n'}]",0,288567,fce6eebb89c15d252e394b2ea8c79b88496ed694,7,3,1,16237,,,0,"[cli-ref] Update python-cloudkittyclient to 0.5.0

Change-Id: I08b90bc8e9ae09351231da57d93da70da73b9698
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/288567/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/cloudkitty.rst'],1,fce6eebb89c15d252e394b2ea8c79b88496ed694,cli-reference,"This chapter documents :command:`cloudkitty` version ``0.5.0``. [--os-project-domain-id <project-domain-id>] [--os-project-domain-name <project-domain-name>] [--os-user-id <user-id>]**Subcommands:** Create collector mapping. Delete collector mapping. Show collector mapping detail. List collector mapping. Disable collector state. Enable collector state. Show collector state. List tenant report. Get total reports. List dataframes. List fields.``pyscripts-script-create`` Create a script. ``pyscripts-script-delete`` Delete a script. ``pyscripts-script-get`` Get script. ``pyscripts-script-get-data`` Get script data. ``pyscripts-script-list`` List scripts. ``pyscripts-script-update`` Update a mapping. ``--os-project-domain-id <project-domain-id>`` Defaults to ``env[OS_PROJECT_DOMAIN_ID]``. ``--os-project-domain-name <project-domain-name>`` Defaults to ``env[OS_PROJECT_DOMAIN_NAME]``. ``--os-user-id <user-id>`` Defaults to ``env[OS_USER_ID]``. Create collector mapping. **Optional arguments:** Map a service to this collector. required. Map a collector to this service. required.Delete collector mapping. **Optional arguments:** Filter on this service. required.Show collector mapping detail. **Optional arguments:** Which service to get the mapping for. required.List collector mapping. **Optional arguments:**Disable collector state. **Optional arguments:** Name of the collector. required.Enable collector state. **Optional arguments:** Name of the collector. required.Show collector state. **Optional arguments:** Name of the collector. required.**Optional arguments:** Field name required. Service id required.**Optional arguments:** Field uuid required.List fields. **Optional arguments:** Service id required.**Optional arguments:** Group name required.**Optional arguments:** Group uuid required. usage: cloudkitty hashmap-mapping-create [-s SERVICE_ID] [-f FIELD_ID] -c COST [-v VALUE] [-t TYPE] [-g GROUP_ID]**Optional arguments:** Service id. Field id. ``-c COST, --cost COST`` Mapping cost required. ``-v VALUE, --value VALUE`` Mapping value. ``-t TYPE, --type TYPE`` Mapping type (flat, rate). Group id.**Optional arguments:** Mapping uuid required.**Optional arguments:** Service id. Field id. Group id.**Optional arguments:** Mapping id required. Mapping cost. Mapping value. Mapping type (flat, rate). Group id.**Optional arguments:** Service name required.**Optional arguments:** Service uuid required. usage: cloudkitty hashmap-threshold-create [-s SERVICE_ID] [-f FIELD_ID] -l LEVEL -c COST [-m MAP_TYPE]**Optional arguments:** Service id. Field id. ``-l LEVEL, --level LEVEL`` Threshold level required. ``-c COST, --cost COST`` Threshold cost required. ``-m MAP_TYPE, --map-type MAP_TYPE`` Threshold type (flat, rate). Group id.**Optional arguments:** Threshold uuid required.**Optional arguments:** Threshold uuid required.**Optional arguments:** Threshold uuid required.**Optional arguments:** Service id. Field id. Group id. If True, list only orhpaned thresholds.**Optional arguments:** Threshold id required. Threshold level. Threshold cost. Threshold type (flat, rate). Group id.**Optional arguments:** Module name required.**Optional arguments:** Module name required... _cloudkitty_pyscripts-script-create: cloudkitty pyscripts-script-create ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-create -n NAME [-f FILE] Create a script. **Optional arguments:** ``-n NAME, --name NAME`` Script name required. ``-f FILE, --file FILE`` Script file. .. _cloudkitty_pyscripts-script-delete: cloudkitty pyscripts-script-delete ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-delete -s SCRIPT_ID Delete a script. **Optional arguments:** ``-s SCRIPT_ID, --script-id SCRIPT_ID`` Script uuid required. .. _cloudkitty_pyscripts-script-get: cloudkitty pyscripts-script-get ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-get -s SCRIPT_ID Get script. **Optional arguments:** ``-s SCRIPT_ID, --script-id SCRIPT_ID`` Script uuid required. .. _cloudkitty_pyscripts-script-get-data: cloudkitty pyscripts-script-get-data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-get-data -s SCRIPT_ID Get script data. **Optional arguments:** ``-s SCRIPT_ID, --script-id SCRIPT_ID`` Script uuid required. .. _cloudkitty_pyscripts-script-list: cloudkitty pyscripts-script-list ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-list [-d SHOW_DATA] List scripts. **Optional arguments:** ``-d SHOW_DATA, --show-data SHOW_DATA`` Show data in the listing Defaults to False. .. _cloudkitty_pyscripts-script-update: cloudkitty pyscripts-script-update ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. code-block:: console usage: cloudkitty pyscripts-script-update -s SCRIPT_ID -f FILE Update a mapping. **Optional arguments:** ``-s SCRIPT_ID, --script-id SCRIPT_ID`` Script uuid required. ``-f FILE, --file FILE`` Script file required. List tenant report.List dataframes. **Optional arguments:** required. required. [-s SERVICE] Get total reports. **Optional arguments:** Tenant id. Begin timestamp. End timestamp. ``-s SERVICE, --service SERVICE`` Service Type.","This chapter documents :command:`cloudkitty` version ``0.4.1``.Subcommands ----------- Create a field. Optional arguments ------------------ Map a service to this collector. Required. Map a collector to this service. Required. Optional arguments ------------------ Filter on this service. Required. Optional arguments ------------------ Which service to get the mapping for. Required. Optional arguments ------------------ Optional arguments ------------------ Name of the collector. Required. Optional arguments ------------------ Name of the collector. Required. Optional arguments ------------------ Name of the collector. Required.Optional arguments ------------------ Field name Required. Service id Required.Optional arguments ------------------ Field uuid Required.Create a field. Optional arguments ------------------ Service id Required.Optional arguments ------------------ Group name Required.Optional arguments ------------------ Group uuid Required. usage: cloudkitty hashmap-mapping-create -c COST [-v VALUE] [-t TYPE] [-s SERVICE_ID] [-f FIELD_ID] [-g GROUP_ID]Optional arguments ------------------ ``-c COST, --cost COST`` Mapping cost Required. ``-v VALUE, --value VALUE`` Mapping value ``-t TYPE, --type TYPE`` Mapping type (flat, rate) Service id Field id Group idOptional arguments ------------------ Mapping uuid Required.Optional arguments ------------------ Service id Field id Group idOptional arguments ------------------ Mapping id Required. Mapping cost Mapping value Mapping type (flat, rate) Group idOptional arguments ------------------ Service name Required.Optional arguments ------------------ Service uuid Required. usage: cloudkitty hashmap-threshold-create -l LEVEL -c COST [-m MAP_TYPE] [-s SERVICE_ID] [-f FIELD_ID]Optional arguments ------------------ ``-l LEVEL, --level LEVEL`` Threshold level Required. ``-c COST, --cost COST`` Threshold cost Required. ``-m MAP_TYPE, --map-type MAP_TYPE`` Threshold type (flat, rate) Service id Field id Group idOptional arguments ------------------ Threshold uuid Required.Optional arguments ------------------ Threshold uuid Required.Optional arguments ------------------ Threshold uuid Required.Optional arguments ------------------ Service id Field id Group id If True, list only orhpaned thresholdsOptional arguments ------------------ Threshold id Required. Threshold level Threshold cost Threshold type (flat, rate) Group idOptional arguments ------------------ Module name Required.Optional arguments ------------------ Module name Required. Optional arguments ------------------ Required. Required. Optional arguments ------------------ Tenant id Begin timestamp End timestamp",259,133
openstack%2Fopenstack-ansible~liberty~Ib80fe6521ef825f68b41c2f79e2becffceb7a655,openstack/openstack-ansible,liberty,Ib80fe6521ef825f68b41c2f79e2becffceb7a655,Updates all repo SHAs to open up work on 12.0.8,MERGED,2016-03-04 11:08:34.000000000,2016-03-04 23:27:54.000000000,2016-03-04 23:27:53.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 11:08:34.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'playbooks/roles/os_neutron/templates/policy.json.j2', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml', 'playbooks/roles/os_ceilometer/templates/gnocchi_resources.yaml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c5ff6c6cb0cd932088c94ea2ce1f52c96a8cfa10', 'message': 'Updates all repo SHAs to open up work on 12.0.8\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins.\n\nChange-Id: Ib80fe6521ef825f68b41c2f79e2becffceb7a655\n'}]",0,288391,c5ff6c6cb0cd932088c94ea2ce1f52c96a8cfa10,12,3,1,6816,,,0,"Updates all repo SHAs to open up work on 12.0.8

This patch includes updates of any changed paste, policy and rootwrap
configurations. It also includes updates to the pip, wheel and
setuptools pins.

Change-Id: Ib80fe6521ef825f68b41c2f79e2becffceb7a655
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/91/288391/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'requirements.txt', 'playbooks/roles/os_neutron/templates/policy.json.j2', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml', 'playbooks/roles/os_ceilometer/templates/gnocchi_resources.yaml.j2']",8,c5ff6c6cb0cd932088c94ea2ce1f52c96a8cfa10,bump_version, - 'cpu.delta' - resource_type: stack, - resource_type: orchestration,35,34
openstack%2Fcompute-hyperv~master~I70735ef1544622fbad2bf88d105192afe087a5b0,openstack/compute-hyperv,master,I70735ef1544622fbad2bf88d105192afe087a5b0,Fix live-migration when using ovs-vif-driver,MERGED,2015-12-10 03:39:38.000000000,2016-03-04 23:26:51.000000000,2016-03-04 23:26:51.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 12604}, {'_account_id': 20783}]","[{'number': 1, 'created': '2015-12-10 03:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/0abef76a9b14a87bffc51e0f09e75e2c0646046b', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 2, 'created': '2016-02-17 08:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/55c3f9cacf3b04a039e9f2ae3ebb428bad88759b', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 3, 'created': '2016-02-25 09:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/b8af6c13e8de66d0218c91098504c08e399c7f9a', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 4, 'created': '2016-02-29 12:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/25506d3c0e3e59f460eea47ca4712f02e9f0112a', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 5, 'created': '2016-02-29 13:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/12a135e59ede2bb1a0fcd188c4c110cd6a31c9b6', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nCloses-Bug: #1551222\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 6, 'created': '2016-03-01 08:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/1c2293d88967b5b96c529a944c9862278ce47153', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nCloses-Bug: #1551222\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 7, 'created': '2016-03-03 09:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/3009c60e31fef0dba3fbe4dcdd4f93abea4fc62c', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nCloses-Bug: #1551222\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 8, 'created': '2016-03-03 13:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/47056a6140ca915c0bfc512aa522ce9c126b53de', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nCloses-Bug: #1551222\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}, {'number': 9, 'created': '2016-03-04 20:26:03.000000000', 'files': ['hyperv/nova/vmops.py', 'hyperv/nova/livemigrationops.py', 'hyperv/nova/driver.py', 'hyperv/tests/unit/test_driver.py', 'hyperv/tests/unit/test_vmops.py', 'hyperv/tests/unit/test_livemigrationops.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/ce3e4e9317ab7ba0d780bd157d63abc827ffa5ef', 'message': 'Fix live-migration when using ovs-vif-driver\n\nWhen live-migrating a vm the ports are not added to the bridge\nat the destination. This patch ensures that ports are added\ncorrectly during live migration.\n\nCloses-Bug: #1551222\nChange-Id: I70735ef1544622fbad2bf88d105192afe087a5b0\n'}]",3,255658,ce3e4e9317ab7ba0d780bd157d63abc827ffa5ef,42,6,9,12604,,,0,"Fix live-migration when using ovs-vif-driver

When live-migrating a vm the ports are not added to the bridge
at the destination. This patch ensures that ports are added
correctly during live migration.

Closes-Bug: #1551222
Change-Id: I70735ef1544622fbad2bf88d105192afe087a5b0
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/58/255658/9 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/vmops.py', 'hyperv/nova/livemigrationops.py', 'hyperv/nova/driver.py', 'hyperv/tests/unit/test_driver.py', 'hyperv/tests/unit/test_vmops.py', 'hyperv/tests/unit/test_livemigrationops.py']",6,0abef76a9b14a87bffc51e0f09e75e2c0646046b,bug/1551222," fake_dest, False, None)"," fake_dest, False)",98,28
openstack%2Fastara-appliance~master~I5875cd647a4cc4f60f3058a98ea8a829cf056c43,openstack/astara-appliance,master,I5875cd647a4cc4f60f3058a98ea8a829cf056c43,Astara appliance oslo.rootwrap,MERGED,2016-02-17 03:43:27.000000000,2016-03-04 23:21:52.000000000,2016-03-04 23:21:52.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 19951}]","[{'number': 1, 'created': '2016-02-17 03:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/cfd25a905387210757761a1d9c37589992a3ed26', 'message': 'Astara appliance oslo.rootwrap\n\nUse oslo.rootwrap to replace the default root_helper sudo.\n\nChange-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43\nImplements: blueprint astara-rootwrap\n'}, {'number': 2, 'created': '2016-02-18 02:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/96059c1f1e27161d4c316c8b4c1b654a9988b57c', 'message': 'Astara appliance oslo.rootwrap\n\nUse oslo.rootwrap to replace the default root_helper sudo.\n\nChange-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43\nImplements: blueprint astara-rootwrap\n'}, {'number': 3, 'created': '2016-02-18 06:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/b2bcf9b297f62be01e1931382a553fc98aba809b', 'message': 'Astara appliance oslo.rootwrap\n\nUse oslo.rootwrap to replace the default root_helper sudo.\n\nChange-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43\nImplements: blueprint astara-rootwrap\n'}, {'number': 4, 'created': '2016-02-18 08:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/c44d7bd50b1f753a02a56e918578e9cf9c9af448', 'message': 'Astara appliance oslo.rootwrap\n\nUse oslo.rootwrap to replace the default root_helper sudo.\n\nChange-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43\nImplements: blueprint astara-rootwrap\n'}, {'number': 5, 'created': '2016-02-18 08:55:43.000000000', 'files': ['astara_router/drivers/ping.py', 'etc/rootwrap.d/network.filters', 'etc/rootwrap.conf', 'test/unit/drivers/test_arp.py', 'astara_router/drivers/bird.py', 'astara_router/drivers/ip.py', 'astara_router/drivers/dnsmasq.py', 'ansible/tasks/astara.yml', 'requirements.txt', 'astara_router/drivers/loadbalancer/nginx.py', 'diskimage-builder/elements/debug-user/package-installs.yaml', 'astara_router/drivers/base.py', 'scripts/etc/init.d/astara-router-api-server', 'test/unit/drivers/test_dnsmasq.py', 'test/unit/drivers/test_iptables.py', 'test/unit/drivers/test_bird.py', 'astara_router/drivers/iptables.py', 'ansible/templates/gunicorn', 'astara_router/api/v1/system.py', 'test/unit/drivers/test_hostname.py', 'astara_router/drivers/metadata.py', 'astara_router/drivers/arp.py', 'astara_router/drivers/hostname.py', 'test/unit/drivers/test_ip.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/abd07978e0711c39658d77ca87c7711451080be8', 'message': 'Astara appliance oslo.rootwrap\n\nUse oslo.rootwrap to replace the default root_helper sudo.\n\nChange-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43\nImplements: blueprint astara-rootwrap\n'}]",0,281034,abd07978e0711c39658d77ca87c7711451080be8,29,4,5,19951,,,0,"Astara appliance oslo.rootwrap

Use oslo.rootwrap to replace the default root_helper sudo.

Change-Id: I5875cd647a4cc4f60f3058a98ea8a829cf056c43
Implements: blueprint astara-rootwrap
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/34/281034/5 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/etc/init.d/astara-router-api-server', 'astara_router/drivers/ping.py', 'ansible/tasks/base.yml', 'etc/rootwrap.d/network.filters', 'astara_router/drivers/iptables.py', 'etc/rootwrap.conf', 'ansible/templates/gunicorn', 'astara_router/drivers/bird.py', 'astara_router/drivers/ip.py', 'astara_router/api/v1/system.py', 'astara_router/drivers/dnsmasq.py', 'ansible/tasks/astara.yml', 'requirements.txt', 'astara_router/drivers/loadbalancer/nginx.py', 'astara_router/drivers/metadata.py', 'diskimage-builder/elements/debug-user/package-installs.yaml', 'astara_router/drivers/arp.py', 'astara_router/drivers/hostname.py', 'setup.cfg', 'astara_router/drivers/base.py']",20,cfd25a905387210757761a1d9c37589992a3ed26,bp/astara-rootwrap," def __init__(self, root_helper='sudo astara-rootwrap /etc/rootwrap.conf'):"," def __init__(self, root_helper='sudo'):",121,30
openstack%2Fkolla~master~I82b8724526c24f4481a80165520d624f6a02c336,openstack/kolla,master,I82b8724526c24f4481a80165520d624f6a02c336,Fix horizon with ssl,MERGED,2016-03-04 02:57:07.000000000,2016-03-04 23:17:52.000000000,2016-03-04 23:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 3098}, {'_account_id': 13642}, {'_account_id': 18009}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-03-04 02:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2a817c908dadc25be398cea31ff69bbd34ad4fc3', 'message': ""Fix haproxy\n\nRemove unused variable and adjust 'when' conditional positioning\n\nTrivialFix\n\nChange-Id: I82b8724526c24f4481a80165520d624f6a02c336\n""}, {'number': 2, 'created': '2016-03-04 03:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bbb5c930c83056b1548aef89c40c5dba1695d0df', 'message': ""Fix horizon with ssl\n\nUbuntu did not have mod_headers enabled by default\n\nRemove unused variable and adjust 'when' conditional positioning\n\nTrivialFix\n\nChange-Id: I82b8724526c24f4481a80165520d624f6a02c336\n""}, {'number': 3, 'created': '2016-03-04 14:52:01.000000000', 'files': ['docker/horizon/Dockerfile.j2', 'ansible/group_vars/all.yml', 'etc/kolla/globals.yml', 'ansible/roles/haproxy/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/dd8e1cb2eee2d0f767985425985c445743d04189', 'message': ""Fix horizon with ssl\n\nUbuntu did not have mod_headers enabled by default\n\nRemove unused variable and adjust 'when' conditional positioning\n\nTrivialFix\n\nChange-Id: I82b8724526c24f4481a80165520d624f6a02c336\n""}]",1,288225,dd8e1cb2eee2d0f767985425985c445743d04189,15,6,3,14119,,,0,"Fix horizon with ssl

Ubuntu did not have mod_headers enabled by default

Remove unused variable and adjust 'when' conditional positioning

TrivialFix

Change-Id: I82b8724526c24f4481a80165520d624f6a02c336
",git fetch https://review.opendev.org/openstack/kolla refs/changes/25/288225/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'etc/kolla/globals.yml', 'ansible/roles/haproxy/tasks/config.yml']",3,2a817c908dadc25be398cea31ff69bbd34ad4fc3,haproxy_fix, when: kolla_enable_tls_external | bool, when: kolla_enable_tls_external | bool,1,3
openstack%2Fkolla~master~I672e9e0f7f8def523b2a18c8271984f0118bba28,openstack/kolla,master,I672e9e0f7f8def523b2a18c8271984f0118bba28,Fix rst syntax in the list of images provided by Kolla,MERGED,2016-03-04 19:22:10.000000000,2016-03-04 23:14:46.000000000,2016-03-04 23:14:46.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 13642}, {'_account_id': 13998}, {'_account_id': 14119}, {'_account_id': 14967}]","[{'number': 1, 'created': '2016-03-04 19:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f1206cfae00b544537a8ab9304a9518216ce780b', 'message': 'Fix rst syntax in the list of images provided by Kolla\n\nMarila is written with wrong syntax.\n\nDocImpact\n\nChange-Id: I672e9e0f7f8def523b2a18c8271984f0118bba28\n'}, {'number': 2, 'created': '2016-03-04 19:32:16.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1e7914147c4837179f77d9f142ac8314f2e1f9f7', 'message': 'Fix rst syntax in the list of images provided by Kolla\n\nManila is written with wrong syntax.\n\nDocImpact\n\nChange-Id: I672e9e0f7f8def523b2a18c8271984f0118bba28\n'}]",2,288667,1e7914147c4837179f77d9f142ac8314f2e1f9f7,12,6,2,14967,,,0,"Fix rst syntax in the list of images provided by Kolla

Manila is written with wrong syntax.

DocImpact

Change-Id: I672e9e0f7f8def523b2a18c8271984f0118bba28
",git fetch https://review.opendev.org/openstack/kolla refs/changes/67/288667/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,f1206cfae00b544537a8ab9304a9518216ce780b,fix-manila-link-rst-syntax,- `Manila <http://docs.openstack.org/developer/manila/>`__,- `Manila <http://docs.openstack.org/developer/manila`__,1,1
openstack%2Fnova-powervm~master~I9c4175532a4f92635c3437ca702aa4d1b4893e50,openstack/nova-powervm,master,I9c4175532a4f92635c3437ca702aa4d1b4893e50,Coordinated LU upload 2: marker LUs,MERGED,2016-03-04 17:56:46.000000000,2016-03-04 23:11:47.000000000,2016-03-04 23:11:47.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13562}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}]","[{'number': 1, 'created': '2016-03-04 17:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/fef57697d0c4925774e1acaec35c82938631de05', 'message': ""WIP: Coordinated LU upload 2: marker LUs\n\nWIP: UT and live testing\n\nPrevious change Ie54fd2b205c7ffae90dc960dfe0bfc46f952a8d8 performed\ncoordinated LU upload to an SSP using an algorithm that assumed it was\npossible to rename an existing Logical Unit.  This turns out not to be\nthe case.\n\nThis change set makes a second attempt at coordinated LU upload by\ncreating a specially-named LU that acts as a marker indicating that the\nupload (to the LU with the real, final name) is not yet complete.  The\nmarker LU is removed when the upload is finished.  The other aspects of\nthe coordination algorithm are similar:\n\n- Check whether the LU already exists.  (Now this is indicated by the\n  presence of the LU with the final name, and NO marker LUs.)  If so,\n  return it.\n- Check whether an upload is in progress.  (Now this is indicated by the\n  presence of any marker LU, whether or not the LU with the real name\n  has been created yet.)  If so, spin and wait for it to complete.\n- Create a marker LU.\n- Pull back the LU list and see if anyone else created a marker and/or\n  started the upload while we were creating our marker.\n- If someone else started an upload, delete our marker, and spin waiting\n  for it to complete.\n- If we have multiple markers, alpha-sort them by name.  The first one\n  wins.  If it's someone else, delete our marker and spin.\n- If there was just one marker (ours), or if ours was first in the\n  alpha-sort, do the actual upload.\n- Remove the marker LU to signal completion.\n- Return the LU we uploaded.\n\nChange-Id: I9c4175532a4f92635c3437ca702aa4d1b4893e50\n""}, {'number': 2, 'created': '2016-03-04 20:58:14.000000000', 'files': ['nova_powervm/tests/virt/powervm/disk/test_ssp.py', 'nova_powervm/virt/powervm/disk/ssp.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/a5e6b5a88880373c737e19c7b65e765592829f0a', 'message': ""Coordinated LU upload 2: marker LUs\n\nPrevious change Ie54fd2b205c7ffae90dc960dfe0bfc46f952a8d8 performed\ncoordinated LU upload to an SSP using an algorithm that assumed it was\npossible to rename an existing Logical Unit.  This turns out not to be\nthe case.\n\nThis change set makes a second attempt at coordinated LU upload by\ncreating a specially-named LU that acts as a marker indicating that the\nupload (to the LU with the real, final name) is not yet complete.  The\nmarker LU is removed when the upload is finished.  The other aspects of\nthe coordination algorithm are similar:\n\n- Check whether the LU already exists.  (Now this is indicated by the\n  presence of the LU with the final name, and NO marker LUs.)  If so,\n  return it.\n- Check whether an upload is in progress.  (Now this is indicated by the\n  presence of any marker LU, whether or not the LU with the real name\n  has been created yet.)  If so, spin and wait for it to complete.\n- Create a marker LU.\n- Pull back the LU list and see if anyone else created a marker and/or\n  started the upload while we were creating our marker.\n- If someone else started an upload, delete our marker, and spin waiting\n  for it to complete.\n- If we have multiple markers, alpha-sort them by name.  The first one\n  wins.  If it's someone else, delete our marker and spin.\n- If there was just one marker (ours), or if ours was first in the\n  alpha-sort, do the actual upload.\n- Remove the marker LU to signal completion.\n- Return the LU we uploaded.\n\nChange-Id: I9c4175532a4f92635c3437ca702aa4d1b4893e50\n""}]",0,288616,a5e6b5a88880373c737e19c7b65e765592829f0a,12,7,2,14070,,,0,"Coordinated LU upload 2: marker LUs

Previous change Ie54fd2b205c7ffae90dc960dfe0bfc46f952a8d8 performed
coordinated LU upload to an SSP using an algorithm that assumed it was
possible to rename an existing Logical Unit.  This turns out not to be
the case.

This change set makes a second attempt at coordinated LU upload by
creating a specially-named LU that acts as a marker indicating that the
upload (to the LU with the real, final name) is not yet complete.  The
marker LU is removed when the upload is finished.  The other aspects of
the coordination algorithm are similar:

- Check whether the LU already exists.  (Now this is indicated by the
  presence of the LU with the final name, and NO marker LUs.)  If so,
  return it.
- Check whether an upload is in progress.  (Now this is indicated by the
  presence of any marker LU, whether or not the LU with the real name
  has been created yet.)  If so, spin and wait for it to complete.
- Create a marker LU.
- Pull back the LU list and see if anyone else created a marker and/or
  started the upload while we were creating our marker.
- If someone else started an upload, delete our marker, and spin waiting
  for it to complete.
- If we have multiple markers, alpha-sort them by name.  The first one
  wins.  If it's someone else, delete our marker and spin.
- If there was just one marker (ours), or if ours was first in the
  alpha-sort, do the actual upload.
- Remove the marker LU to signal completion.
- Return the LU we uploaded.

Change-Id: I9c4175532a4f92635c3437ca702aa4d1b4893e50
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/16/288616/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/tests/virt/powervm/disk/test_ssp.py', 'nova_powervm/virt/powervm/disk/ssp.py']",2,fef57697d0c4925774e1acaec35c82938631de05,no_rename_lu," sleep_s = 3 # Marker (upload-in-progress) LU name prefixed with 'partxxxxxxxx' mkr_luname = prefix + luname # Look for all LUs containing the right name. lus = self._find_lu(luname, imgtyp, whole_name=False, find_all=True, ssp=ssp) # Does the LU already exist in its final, uploaded form? If so, # then only that LU will exist, with an exact name match. if len(lus) == 1 and lus[0].name == luname: return lus[0] # Is there an upload in progress? mkr_lus = [lu for lu in lus if lu.name != luname and lu.name.endswith(luname)] if mkr_lus: LOG.debug('Waiting for in-progress upload(s) to complete. ' 'Marker LU(s): %s', str([lu.name for lu in mkr_lus]), instance=instance) time.sleep(sleep_s) LOG.info('Creating marker LU %s', mkr_luname) ssp, mkrlu = tsk_stg.crt_lu(ssp, mkr_luname, 0.001, typ=imgtyp) # multiple marker LUs out there. We all use the next chunk to # First of all, if someone else already started the upload, we bail if any([lu for lu in lus if lu.name == luname]): LOG.info(_LI('Abdicating in favor of in-progress upload.')) tsk_stg.rm_ssp_storage(ssp, [mkrlu]) time.sleep(sleep_s) continue # The lus list should be all markers at this point. If there's # more than one (ours), then the first (by alpha sort) wins. if len(lus) > 1: lus.sort(key=lambda l: l.name) if winner != mkr_luname: LOG.info(_LI('Abdicating upload in favor of marker %s.'), winner) tsk_stg.rm_ssp_storage(ssp, [mkrlu]) time.sleep(sleep_s) # Okay, we won. Do the actual upload. strm = self._get_image_upload(context, image_meta) LOG.info(_LI('Uploading to image LU %(lu)s (marker %(mkr)s).'), {'lu': luname, 'mkr': mkr_luname}) try: lu, f_wrap = tsk_stg.upload_new_lu( self._any_vios_uuid(), ssp, strm, luname, image_meta.size) except Exception as exc: LOG.exception(exc) # It's possible the LU creation succeeded, but the upload # failed. If so, we need to remove the LU so it doesn't block # others attempting to use the same one. lu = self._find_lu(luname, imgtyp) if lu: LOG.exception(_LE('Removing failed LU %s.'), luname) tsk_stg.rm_ssp_storage(ssp, [lu]) finally: # Signal completion (or clean up) by removing the marker LU. tsk_stg.rm_ssp_storage(ssp, [mkrlu]) # Return the uploaded LU. return lu","import pypowervm.utils.transaction as pvm_tx @pvm_tx.entry_transaction def _rename_lu(sspw, lu2r, new_name): """"""Rename a Logical Unit. :param sspw: The SSP wrapper housing the LU to be renamed. :param lu2r: LU wrapper representing the LU to be renamed. :param new_name: New name (string) for the LU. :return: The ssp, updated with the renamed LU. """""" lu = self._find_lu(lu2r.name, lu2r.lu_type, ssp=sspw) lu.name = new_name return sspw.update() # Temporary (upload-in-progress) LU name prefixed with 'partxxxxxxxx' tmp_luname = prefix + luname lu_gb = pvm_u.convert_bytes_to_gb(image_meta.size, dp=2) # Does the LU already exist in its final, uploaded form? lu = self._find_lu(luname, imgtyp, ssp=ssp) if lu: return lu # It's not there. Is someone already uploading it? lu = self._find_lu(luname, imgtyp, whole_name=False, ssp=ssp) if lu: LOG.debug('Waiting for in-progress upload %s to complete.', lu.name, instance=instance) time.sleep(3) # Create the LU with our temporary name. ssp, tmplu = tsk_stg.crt_lu(ssp, tmp_luname, lu_gb, typ=imgtyp) # multiple temporary LUs out there. We all use the next chunk to if len(lus) > 1: # The ""first"" (by alpha sort) wins. lus.sort(key=lambda lu: lu.name) if winner != tmp_luname: LOG.info(_LI('Abdicating our upload (%(our_lu)s) in favor ' 'of %(winner_lu)s.'), {'our_lu': tmp_luname, 'winner_lu': winner}) tsk_stg.rm_ssp_storage(ssp, [tmplu]) LOG.info( _LI('Waiting for in-progress upload %s to complete.'), winner) time.sleep(3) # Okay, we won. Do the actual upload (to the temporary name). stream = self._get_image_upload(context, image_meta) LOG.info(_LI('Uploading to image LU %s.'), tmp_luname) try: tsk_stg.upload_lu( self._any_vios_uuid(), tmplu, stream, image_meta.size) # Now signal completion and make the LU usable by giving it its # ""real"" name. ssp = _rename_lu(ssp, tmplu, luname) # Finally, re-find the LU we just renamed and return it. return self._find_lu(luname, imgtyp, ssp=ssp) except Exception as exc: LOG.exception(_LE('Removing LU %(luname)s due to exception: ' '%(exc)s.'), {'luname': tmplu.name, 'exc': exc}) tsk_stg.rm_ssp_storage(ssp, [tmplu])",57,56
openstack%2Fnetworking-odl~master~Ib00614b4ae9d666255d68e1aa379ab93c6aac953,openstack/networking-odl,master,Ib00614b4ae9d666255d68e1aa379ab93c6aac953,Prevent unit tests from accidentally connecting to OpenDaylight,MERGED,2016-02-22 09:29:40.000000000,2016-03-04 23:10:13.000000000,2016-03-04 23:10:13.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 10386}, {'_account_id': 11114}, {'_account_id': 11347}, {'_account_id': 17377}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-22 09:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/5aabd91bd55a970fa8f8a6d3babc8040cc7a6aa9', 'message': ""Prevent mech driver unit tests from accidentally connecting to any service\n\nnetworking_topology relies on operative system domain name resolution to translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and download the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 2, 'created': '2016-02-22 09:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/92725595c632b4275e8e44c1bfc401c4988ed8b5', 'message': ""Prevent mech driver unit tests from accidentally connecting to any service\n\nnetworking_topology relies on operative system domain name resolution to translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and download the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 3, 'created': '2016-02-22 09:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/3644de78e111136b720b053fc0bcaff7abc23d7a', 'message': ""Prevent mech driver unit tests from accidentally connecting\n\nnetworking_topology relies on operative system domain name resolution to translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and download the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 4, 'created': '2016-02-22 09:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/e556fa0f88b46073f83444e933471b43c1911300', 'message': ""Prevent mech driver unit tests from accidentally connecting\n\nnetworking_topology relies on operative system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 5, 'created': '2016-02-22 09:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/636afc78ddfddc558c60eaeea941fe4215763d6b', 'message': ""Prevent mech driver unit tests from accidentally connecting\n\nnetworking_topology relies on operative system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 6, 'created': '2016-02-22 09:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/57baf95430c738551d5e197c7205d7f181e04d25', 'message': ""Prevent mech driver unit tests from accidentally connecting\n\nnetworking_topology relies on operative system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 7, 'created': '2016-02-23 09:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/5a81a8b122f5eac0801aad117a62435a98e44484', 'message': ""Prevent mech driver unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 8, 'created': '2016-02-23 09:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/46b63e951c91b44a7203afc052de98df024949c1', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 9, 'created': '2016-02-23 20:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/7addbcda411e8d1df1db4cbc9793b722e2821c43', 'message': ""oPrevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 10, 'created': '2016-02-23 20:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/5b0e73da9bf164b706def5e46464c63a1478e1e4', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 11, 'created': '2016-02-24 11:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/26d20867ceae117651840b8a51bd8cf9891ffcf4', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 12, 'created': '2016-02-24 17:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/20c414f62cafbd389f7513b88df40e8d5839d9a0', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 13, 'created': '2016-03-01 17:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/5222f4d6eac73ac1abbe0d23d2d47673d1f4e554', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 14, 'created': '2016-03-03 01:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/472ef8c6b31ac440088292d84c3835ed15ded53d', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 15, 'created': '2016-03-03 09:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/ead5546aea2a8e2fa2b3a66dfd54de9dd2b146e7', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}, {'number': 16, 'created': '2016-03-04 10:13:56.000000000', 'files': ['networking_odl/tests/unit/ml2/test_mechanism_odl.py'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/872625c3680d327e2d1cdfb0dbfde59bbea72390', 'message': ""Prevent unit tests from accidentally connecting to OpenDaylight\n\nnetworking_topology relies on operating system domain name resolution\nto translate host name to IP addresses with the purpose of looking for\ncompute node networking capabilities parsing network topology provided\nby OpenDaylight.\n\nNetworking ODL uses requests library to connect to OpenDaylight and\ndownload the network topology from OpenDaylight.\n\nSome tests doesn't expect it and they could actually have success doing\none of above operations when a failure is expected. In such case the\nbehaviour of networking_topology would be different from the one expected\nat the moment unit tests has been written.\n\nChange-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953\nCloses-Bug: #1548239\n""}]",8,283018,872625c3680d327e2d1cdfb0dbfde59bbea72390,77,7,16,17377,,,0,"Prevent unit tests from accidentally connecting to OpenDaylight

networking_topology relies on operating system domain name resolution
to translate host name to IP addresses with the purpose of looking for
compute node networking capabilities parsing network topology provided
by OpenDaylight.

Networking ODL uses requests library to connect to OpenDaylight and
download the network topology from OpenDaylight.

Some tests doesn't expect it and they could actually have success doing
one of above operations when a failure is expected. In such case the
behaviour of networking_topology would be different from the one expected
at the moment unit tests has been written.

Change-Id: Ib00614b4ae9d666255d68e1aa379ab93c6aac953
Closes-Bug: #1548239
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/18/283018/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_odl/tests/unit/ml2/test_mechanism_odl.py', 'networking_odl/ml2/network_topology.py']",2,5aabd91bd55a970fa8f8a6d3babc8040cc7a6aa9,bug/1548239, # The cache calls this method to fetch new elements when at least one, # The cache calls this method to fecth new elements when at least one,20,12
openstack%2Fkolla~master~I83da0298067d5f37603c52fb312828ea1fbbb00c,openstack/kolla,master,I83da0298067d5f37603c52fb312828ea1fbbb00c,Retry token retrival in keystone bootstrap script,MERGED,2016-03-04 16:01:32.000000000,2016-03-04 23:08:14.000000000,2016-03-04 22:51:00.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 13642}]","[{'number': 1, 'created': '2016-03-04 16:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3d72141650d40c80f04254ffd8a1532f2d0e08a3', 'message': 'Retry token retrival in bootstrap script\n\nTrivialFix\n\nChange-Id: I83da0298067d5f37603c52fb312828ea1fbbb00c\n'}, {'number': 3, 'created': '2016-03-04 16:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6d55ea32e249460da9971cd41698c0ae4898c139', 'message': 'Retry token retrival in keystone bootstrap script\n\nTrivialFix\n\nChange-Id: I83da0298067d5f37603c52fb312828ea1fbbb00c\n'}, {'number': 4, 'created': '2016-03-04 18:14:40.000000000', 'files': ['docker/keystone/keystone_bootstrap.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d83cb3c47317766e2cdc05942e2b1c8c288c53a1', 'message': 'Retry token retrival in keystone bootstrap script\n\nTrivialFix\n\nChange-Id: I83da0298067d5f37603c52fb312828ea1fbbb00c\n'}]",0,288551,d83cb3c47317766e2cdc05942e2b1c8c288c53a1,18,5,3,14119,,,0,"Retry token retrival in keystone bootstrap script

TrivialFix

Change-Id: I83da0298067d5f37603c52fb312828ea1fbbb00c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/51/288551/4 && git format-patch -1 --stdout FETCH_HEAD,['docker/keystone/keystone_bootstrap.sh'],1,3d72141650d40c80f04254ffd8a1532f2d0e08a3,keystone_wait,"count=0 while [[ ! ""${OS_TOKEN}"" && ""${count}"" -lt 5 ]]; do get_token ((count++)) sleep done if [[ ! ""${OS_TOKEN}"" ]] fail_json ""Unable to retrieve token after 5 attempts""","get_token if [[ ! ""${OS_TOKEN}"" ]]; then fail_json ""Unable to issue token""",9,3
openstack%2Freleases~master~I1ed69934ef34dc64af6bcb67cd14a53fd86a7b24,openstack/releases,master,I1ed69934ef34dc64af6bcb67cd14a53fd86a7b24,ironic-ui 0.0.1,MERGED,2016-03-04 19:04:24.000000000,2016-03-04 23:07:13.000000000,2016-03-04 23:07:13.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-03-04 19:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e6413f823a50426de0f0fda2ed776f251286ff14', 'message': 'ironic-ui 0.0.1\n\nChange-Id: I1ed69934ef34dc64af6bcb67cd14a53fd86a7b24\n'}, {'number': 2, 'created': '2016-03-04 19:07:04.000000000', 'files': ['deliverables/mitaka/ironic-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ab77f8354f042547b0202c98808a86282023b756', 'message': ""ironic-ui 0.0.1\n\nNote the weird announce email is because we don't really want to\nannounce 0.0.1; this will change to openstack-announce for the 1.0.0\nrelease.\n\nChange-Id: I1ed69934ef34dc64af6bcb67cd14a53fd86a7b24\n""}]",0,288650,ab77f8354f042547b0202c98808a86282023b756,7,2,2,10343,,,0,"ironic-ui 0.0.1

Note the weird announce email is because we don't really want to
announce 0.0.1; this will change to openstack-announce for the 1.0.0
release.

Change-Id: I1ed69934ef34dc64af6bcb67cd14a53fd86a7b24
",git fetch https://review.opendev.org/openstack/releases refs/changes/50/288650/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/ironic-ui.yaml'],1,e6413f823a50426de0f0fda2ed776f251286ff14,ironic-ui-0.0.1,--- launchpad: ironic-ui send-announcements-to: openstack-dev@lists.openstack.org include-pypi-link: yes releases: - version: 0.0.1 projects: - repo: openstack/ironic-ui hash: 5f6ea0c900e98436c1fae9de4b04b7c74db6f82c ,,9,0
openstack%2Fcongress~master~Ia7bf0b57461152658fe74f787c866fa4cf57311b,openstack/congress,master,Ia7bf0b57461152658fe74f787c866fa4cf57311b,Use argparse instead of optparse,MERGED,2016-03-04 07:13:15.000000000,2016-03-04 23:07:03.000000000,2016-03-04 23:07:03.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2016-03-04 07:13:15.000000000', 'files': ['congress/datalog/compile.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f1cd3397ad9352d3b059d09b8fe4bfd26c750a64', 'message': 'Use argparse instead of optparse\n\nThis commit uses argparse to parse arguments instead of optparse\nas optprase is deprecated in python 2.7.\nhttps://docs.python.org/2/library/optparse.html\n\nCloses-Bug:#1553039\nChange-Id: Ia7bf0b57461152658fe74f787c866fa4cf57311b\n'}]",0,288280,f1cd3397ad9352d3b059d09b8fe4bfd26c750a64,6,2,1,11278,,,0,"Use argparse instead of optparse

This commit uses argparse to parse arguments instead of optparse
as optprase is deprecated in python 2.7.
https://docs.python.org/2/library/optparse.html

Closes-Bug:#1553039
Change-Id: Ia7bf0b57461152658fe74f787c866fa4cf57311b
",git fetch https://review.opendev.org/openstack/congress refs/changes/80/288280/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/datalog/compile.py'],1,f1cd3397ad9352d3b059d09b8fe4bfd26c750a64,argparse,"import argparse parser = argparse.ArgumentParser() parser.add_argument( (options, inputs) = parser.parse_known_args(args)","import optparse parser = optparse.OptionParser() parser.add_option( (options, inputs) = parser.parse_args(args)",4,4
openstack%2Fcongress~master~Id0b6dd406c3abe8c4e0825de6cbdd0295382020c,openstack/congress,master,Id0b6dd406c3abe8c4e0825de6cbdd0295382020c,DataModelExceptioncreate to raise proper exception,MERGED,2016-03-04 08:46:24.000000000,2016-03-04 23:06:58.000000000,2016-03-04 23:06:57.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 8878}]","[{'number': 1, 'created': '2016-03-04 08:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/67a370c2f7bf013952db8bdeec4eb83a522599ce', 'message': ""DataModelExceptioncreate to raise proper exception\n\nDataModelException.create doesn't raise proper exception if the\nname of error is not present in error_codes.py.\nFor example, exception.NotFound doesn't get wrapped into proper\ndatamodel exception and always raises Unknown Error in description\ninstead.\n\nThis patch gets the description from httplib if not present in\nerror_codes instead of directly raising UnknownError.\n\nCloses-Bug:#1553076\nChange-Id: Id0b6dd406c3abe8c4e0825de6cbdd0295382020c\n""}, {'number': 2, 'created': '2016-03-04 11:03:21.000000000', 'files': ['congress/api/webservice.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/669fe0f6b473c190947416e3c1327cf6b6e63ba5', 'message': ""DataModelExceptioncreate to raise proper exception\n\nDataModelException.create doesn't raise proper exception if the\nname of error is not present in error_codes.py.\nFor example, exception.NotFound doesn't get wrapped into proper\ndatamodel exception and always raises Unknown Error in description\ninstead.\n\nThis patch gets the description from httplib if not present in\nerror_codes instead of directly raising UnknownError.\n\nCloses-Bug:#1553076\nChange-Id: Id0b6dd406c3abe8c4e0825de6cbdd0295382020c\n""}]",1,288308,669fe0f6b473c190947416e3c1327cf6b6e63ba5,11,3,2,11278,,,0,"DataModelExceptioncreate to raise proper exception

DataModelException.create doesn't raise proper exception if the
name of error is not present in error_codes.py.
For example, exception.NotFound doesn't get wrapped into proper
datamodel exception and always raises Unknown Error in description
instead.

This patch gets the description from httplib if not present in
error_codes instead of directly raising UnknownError.

Closes-Bug:#1553076
Change-Id: Id0b6dd406c3abe8c4e0825de6cbdd0295382020c
",git fetch https://review.opendev.org/openstack/congress refs/changes/08/288308/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/api/webservice.py'],1,67a370c2f7bf013952db8bdeec4eb83a522599ce,webservice," name = getattr(error, ""name"", None) if name: error_code = error_codes.get_num(name) description = error_codes.get_desc(name) http_status_code = error_codes.get_http(name) else: # Check if it's default http error or else return 'Unknown error' error_code = error.code or httplib.BAD_REQUEST description = httplib.responses.get(error_code, ""Unknown error"") http_status_code = error_code return cls(error_code=error_code, http_status_code=http_status_code)"," name = getattr(error, ""name"", error_codes.UNKNOWN) description = error_codes.get_desc(name) return cls(error_code=error_codes.get_num(name), http_status_code=error_codes.get_http(name))",13,4
openstack%2Fcongress~master~Ie1fdddbc49e67b34a252d18af5e0c47b46ef9d89,openstack/congress,master,Ie1fdddbc49e67b34a252d18af5e0c47b46ef9d89,Updated from global requirements,MERGED,2016-03-04 10:13:47.000000000,2016-03-04 23:06:55.000000000,2016-03-04 23:06:54.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 10:13:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/82628dcf0b70361e5eda81b1a66afc14feb09927', 'message': 'Updated from global requirements\n\nChange-Id: Ie1fdddbc49e67b34a252d18af5e0c47b46ef9d89\n'}]",0,288345,82628dcf0b70361e5eda81b1a66afc14feb09927,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie1fdddbc49e67b34a252d18af5e0c47b46ef9d89
",git fetch https://review.opendev.org/openstack/congress refs/changes/45/288345/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,82628dcf0b70361e5eda81b1a66afc14feb09927,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Fcongress~master~I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2,openstack/congress,master,I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2,Require dse2 partitioning in unittesting,MERGED,2016-03-02 03:41:05.000000000,2016-03-04 23:06:46.000000000,2016-03-04 23:06:45.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 8878}, {'_account_id': 11278}, {'_account_id': 18591}]","[{'number': 1, 'created': '2016-03-02 03:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c78b048dc0df5c0dd537f37a4364bd0d51b43697', 'message': ""Require dse2 partitioning in unittesting\n\nAdded a check in DseNode that requires partition to be set when\nin unittesting mode.\n\nPurpose: It's really easy to forget to add partition in testing\n(latest one discovered by this change, fixed in the same patch),\nleading to test failures down the road.\nThis change immediately raises error, telling test writer to use\npartition.\n\nChange-Id: I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2\n""}, {'number': 2, 'created': '2016-03-02 22:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/af40dd56e46b46a7e89ae6c5556a73624829f31b', 'message': ""Require dse2 partitioning in unittesting\n\nIn unit testing, use wrapper functions to make DseNodes in partitions.\n\nPurpose: It's really easy to forget to add partition in testing,\nleading to test failures down the road.\n\nChange-Id: I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2\n""}, {'number': 3, 'created': '2016-03-04 05:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5749dec7834224b1432283f5511e6c2dcbb24ce4', 'message': ""Require dse2 partitioning in unittesting\n\nIn unit testing, use wrapper functions to make DseNodes in partitions.\n\nPurpose: It's really easy to forget to add partition in testing,\nleading to test failures down the road.\n\nChange-Id: I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2\n""}, {'number': 4, 'created': '2016-03-04 19:21:18.000000000', 'files': ['congress/tests2/dse2/test_datasource.py', 'congress/tests/helper.py', 'congress/tests2/api/base.py', 'congress/tests2/dse2/test_dse2.py', 'congress/tests2/managers/test_datasource.py', 'congress/tests2/dse2/test_dse_node.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/ac78242a8f354aadeda3067fef6c41a62ed1eba7', 'message': ""Require dse2 partitioning in unittesting\n\nIn unit testing, use wrapper functions to make DseNodes in partitions.\n\nPurpose: It's really easy to forget to add partition in testing,\nleading to test failures down the road.\n\nChange-Id: I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2\n""}]",3,286961,ac78242a8f354aadeda3067fef6c41a62ed1eba7,33,5,4,18591,,,0,"Require dse2 partitioning in unittesting

In unit testing, use wrapper functions to make DseNodes in partitions.

Purpose: It's really easy to forget to add partition in testing,
leading to test failures down the road.

Change-Id: I2aa6292247e7dfff343d021fa7ba8321fe9cfeb2
",git fetch https://review.opendev.org/openstack/congress refs/changes/61/286961/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/base.py', 'congress/tests/helper.py', 'congress/dse2/dse_node.py', 'congress/tests2/dse2/test_dse2.py', 'congress/tests2/dse2/test_dse_node.py']",5,c78b048dc0df5c0dd537f37a4364bd0d51b43697,test-get_node-2," def test_unittesting_nopartition_exception(self): self.assertRaises(helper.TestingException, DseNode, self.messaging_config, ""test"", []) def test_production_nopartition_noexception(self): try: cfg.CONF.unittesting = False DseNode(self.messaging_config, ""test"", []) finally: cfg.CONF.unittesting = True",,27,1
openstack%2Fsolum~master~I994c40ae710a23b208745be042ef367d6050f1df,openstack/solum,master,I994c40ae710a23b208745be042ef367d6050f1df,Checking git url format,MERGED,2016-03-02 20:45:49.000000000,2016-03-04 23:03:19.000000000,2016-03-04 23:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-03-02 20:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ddbc5bb86c20209b514534bc72cb1e73cab8c0d8', 'message': 'Checking git url format\n\nChange-Id: I994c40ae710a23b208745be042ef367d6050f1df\nCloses-Bug: #1552401\n'}, {'number': 2, 'created': '2016-03-03 17:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/fcb7921d291f705ec781487b00d38e7d2c53c8f9', 'message': 'Checking git url format\n\nChange-Id: I994c40ae710a23b208745be042ef367d6050f1df\nCloses-Bug: #1552401\n'}, {'number': 3, 'created': '2016-03-03 18:54:20.000000000', 'files': ['solum/tests/api/handlers/test_lp_handler.py', 'solum/api/handlers/language_pack_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/bdc0fae7451ea1da03e78a97117f2b661df6e599', 'message': 'Checking git url format\n\nChange-Id: I994c40ae710a23b208745be042ef367d6050f1df\nCloses-Bug: #1552401\n'}]",4,287428,bdc0fae7451ea1da03e78a97117f2b661df6e599,17,4,3,2506,,,0,"Checking git url format

Change-Id: I994c40ae710a23b208745be042ef367d6050f1df
Closes-Bug: #1552401
",git fetch https://review.opendev.org/openstack/solum refs/changes/28/287428/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/api/handlers/test_lp_handler.py', 'solum/api/handlers/language_pack_handler.py']",2,ddbc5bb86c20209b514534bc72cb1e73cab8c0d8,bug/1552401,"import re def check_lp_url(self, data): # try to use a correct git uri pt = re.compile(r'github\.com[:/](.+?)/(.+?)($|/.*$|\.git$|\.git/.*$)') match = pt.search(data['source_uri']) if not match: msg = ""Bad git url. Provide the git url in the following format: \n"" msg = msg + "" for public repo: https://github.com/<USER>/<REPO>.git\n"" msg = msg + "" for private repo: git@github.com:<USER>/<REPO>.git\n"" raise exc.BadRequest(reason=msg) self.check_lp_url(data) ",,26,1
openstack%2Fironic-ui~master~I0a18be8bee56f6919d8fde1b35b2410aa1033ce9,openstack/ironic-ui,master,I0a18be8bee56f6919d8fde1b35b2410aa1033ce9,Added node list pages to the plugin,MERGED,2016-02-23 12:14:35.000000000,2016-03-04 23:01:27.000000000,2016-03-04 23:01:27.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 11680}, {'_account_id': 16352}, {'_account_id': 16628}, {'_account_id': 19380}]","[{'number': 1, 'created': '2016-02-23 12:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/2ee857f9bb4b335aa3aacce0cb04cfc978895dc8', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 2, 'created': '2016-03-01 15:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/8d7452476f3c76ac18c52a3d2390d16454be1133', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 3, 'created': '2016-03-02 19:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/ee16048762e91ddbd48da8bb7f2bc767856a083f', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 4, 'created': '2016-03-03 00:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/49bdb689f10661bc3fdb297f926d22f743a4307c', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 5, 'created': '2016-03-03 12:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/74b5962fe4d5c9fc1fdc19cab739cf3d3083c5be', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 6, 'created': '2016-03-03 15:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/b30779c2671acd08a60bb75e8c4fdb7030f356a7', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 7, 'created': '2016-03-04 11:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/6825ec0ddbde967ea470416ee7a8839a1a3abd33', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 8, 'created': '2016-03-04 11:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/e388e9dab76f21fb68648f64604c03ed8e36f7bd', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 9, 'created': '2016-03-04 15:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/08233dda282f173a035ead04111ad09a728d5e92', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 10, 'created': '2016-03-04 16:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/6f8340267345b14b412a2c7c26e6c93df81e9dbb', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 11, 'created': '2016-03-04 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/13ac5a4960b4ab37620b7ab1c67d8b0dfef4eb61', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 12, 'created': '2016-03-04 18:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/caefcd018852f4713f32194f673b96a112b8dcd2', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 13, 'created': '2016-03-04 20:56:19.000000000', 'files': ['ironic_ui/static/dashboard/admin/ironic/node-list/node-list.html', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.controller.js', 'ironic_ui/content/ironic/templates/ironic/index.html'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/5f8fc8b7a0f0654c49f0da8feeac2c2da499995b', 'message': 'Added node list pages to the plugin\n\nAdded overview page to the plugin and amended index.html to show\nnode-detail page and title.\n\nChange-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}]",29,283541,5f8fc8b7a0f0654c49f0da8feeac2c2da499995b,49,7,13,16628,,,0,"Added node list pages to the plugin

Added overview page to the plugin and amended index.html to show
node-detail page and title.

Change-Id: I0a18be8bee56f6919d8fde1b35b2410aa1033ce9
Co-Authored-By: Peter Piela <ppiela@cray.com>
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/41/283541/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/static/dashboard/admin/ironic/node-list/node-list.html', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.controller.js']",2,2ee857f9bb4b335aa3aacce0cb04cfc978895dc8,split-patch,"/* * © Copyright 2016 Hewlett Packard Enterprise Development Company LP * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function () { 'use strict'; angular .module('horizon.dashboard.admin.ironic') .controller('IronicNodeListController', IronicNodeListController); IronicNodeListController.$inject = [ '$scope', 'horizon.app.core.openstack-service-api.ironic', 'horizon.dashboard.admin.ironic.actions', 'horizon.dashboard.admin.basePath' ]; function IronicNodeListController($scope, ironic, actions, basePath) { var ctrl = this; console.log(""Instantiating IronicNodeListController"") ctrl.nodes = []; ctrl.checked = {}; ctrl.basePath = basePath; $scope.nodes = ctrl.nodesSrc = []; $scope.actions = actions; $scope.$watchCollection('selected', function () { var selected = $scope.selected || {}; selected.isEmpty = true; for (var key in selected) { if (selected[key].checked) { selected.isEmpty = false; return; } } }); init(); // RETRIVE NODES AND PORTS function init() { console.log(""IronicNodeController.init()"") retrieveNodes(); } function retrieveNodes() { return ironic.getNodes().then(onGetNotes); } function onGetNotes(response) { $scope.nodes = ctrl.nodesSrc = response.data.items; ctrl.nodesSrc.forEach(function (node) { node.id = node.uuid; retrievePorts(node); }); } function retrievePorts(node) { return ironic.getPortsWithNode(node.uuid).then( function (response) { node.ports = response.data.items; } ); } } })(); ",,228,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I3c8225124a5f18db81259e1d52d0168ef52c3c17,openstack/openstack-ansible-lxc_hosts,master,I3c8225124a5f18db81259e1d52d0168ef52c3c17,Resolve bad assumptions about the base OS,MERGED,2016-03-03 17:45:27.000000000,2016-03-04 23:01:20.000000000,2016-03-04 23:01:20.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 18784}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 17:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/84887213779d79bef48e9244ed2f155089928437', 'message': 'added the aparmor package to the install list\n\nThe change aims to fix this role when used against a minimal OS.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-03-03 17:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e10478ad49d5192b7bb0c7112e5978eb1309f622', 'message': 'added the aparmor package to the install list\n\nThe change aims to fix this role when used against a minimal OS.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2016-03-03 18:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6b0244918c4f6b03696756c273163450f50401e9', 'message': 'added the aparmor package to the install list\n\nThe change aims to fix this role when used against a minimal OS.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2016-03-03 18:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/670adf0d18628b9b91bfdfc8ad2ed05d64419858', 'message': 'Update the lxc_host role for Minimal OS\n\nThe change moves several tasks around and adds packages to the install\nprocess. This also updates the lxc-net-bridge template to be more\nconfigurable which addresses issues some users that may have when\ndeploying into a minimal OS.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2016-03-04 17:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/cd7f86f0522a2fed102cd3482f9ad9ad139852a1', 'message': 'Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2016-03-04 19:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/b56853f36854f3628c731ed5633d4f40583d0e0e', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2016-03-04 19:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/3027034db919a38de6753cc8c873e3fecf953e1d', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2016-03-04 19:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0dd6020b0a68d9499e8cdd3c152b98ff30c89bbc', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2016-03-04 20:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e4defe6cc11e34f7cf8128e1e6409890c9a9e9c5', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2016-03-04 20:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/dc4df58349e7e46c8778acb7f75cab1de8ba8d00', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2016-03-04 20:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/7b68c45b0387ce999717f3af3ab5a1e49b6c5f65', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 12, 'created': '2016-03-04 21:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ecaf382abc81204253ef5d29ddb821d520bd3c8f', 'message': '[WIP] Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 13, 'created': '2016-03-04 21:03:56.000000000', 'files': ['tasks/main.yml', 'templates/lxc-net-bridge.cfg.j2', 'tasks/lxc_post_install.yml', 'other-requirements.txt', 'tasks/lxc_pre_install.yml', 'tox.ini', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/fe999d17150ca1011a8b2bedfc9ba6d0a5affcb3', 'message': 'Resolve bad assumptions about the base OS\n\nThe change moves several tasks around and adds packages to the install\nprocess which were previously assumed to be present on the base OS.\n\nThis also updates the lxc-net-bridge template to be more configurable\nto address issues where the base OS is more minimal than previously\nexpected.\n\nChange-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",10,288006,fe999d17150ca1011a8b2bedfc9ba6d0a5affcb3,49,7,13,7353,,,0,"Resolve bad assumptions about the base OS

The change moves several tasks around and adds packages to the install
process which were previously assumed to be present on the base OS.

This also updates the lxc-net-bridge template to be more configurable
to address issues where the base OS is more minimal than previously
expected.

Change-Id: I3c8225124a5f18db81259e1d52d0168ef52c3c17
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/06/288006/9 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,84887213779d79bef48e9244ed2f155089928437,bindep-requirements, - apparmor,,1,0
openstack%2Ftacker~master~I04945e50b762e83744d48e5dce6a8396d2a6eb39,openstack/tacker,master,I04945e50b762e83744d48e5dce6a8396d2a6eb39,Remove sleep timer in monitor respawn,MERGED,2016-03-04 01:37:14.000000000,2016-03-04 22:58:18.000000000,2016-03-04 20:16:04.000000000,"[{'_account_id': 3}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 15755}, {'_account_id': 16511}, {'_account_id': 18265}, {'_account_id': 18955}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-04 01:37:14.000000000', 'files': ['tacker/vm/monitor.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/4abe664fd2862c897c88e8af2d8dc51f6ee68bf2', 'message': 'Remove sleep timer in monitor respawn\n\nThis fix removes the sleep hack that was introduced for the nova\nlibvirt error: device or resource busy. The original bug has been\nfixed in nova project.\n\nChange-Id: I04945e50b762e83744d48e5dce6a8396d2a6eb39\nCloses-Bug: #1552981\n'}]",0,288211,4abe664fd2862c897c88e8af2d8dc51f6ee68bf2,15,8,1,13485,,,0,"Remove sleep timer in monitor respawn

This fix removes the sleep hack that was introduced for the nova
libvirt error: device or resource busy. The original bug has been
fixed in nova project.

Change-Id: I04945e50b762e83744d48e5dce6a8396d2a6eb39
Closes-Bug: #1552981
",git fetch https://review.opendev.org/openstack/tacker refs/changes/11/288211/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vm/monitor.py'],1,4abe664fd2862c897c88e8af2d8dc51f6ee68bf2,bug/1552981,, # TODO(sripriya): sleep timer has been provided as a temporary # workaround for the nova neutron port still in use issue. Need # to come up with a better fix for the issue LOG.debug('Sleeping for 10 seconds before initiating respawn') time.sleep(10) ,0,6
openstack%2Fopenstack-ansible~master~I1c9c43582c99ebd1fb7bacb6545bcad34a692880,openstack/openstack-ansible,master,I1c9c43582c99ebd1fb7bacb6545bcad34a692880,Replacing LBaaSv1 with v2 configuration,ABANDONED,2016-02-02 23:19:06.000000000,2016-03-04 22:49:41.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12892}, {'_account_id': 14552}]","[{'number': 1, 'created': '2016-02-02 23:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b82c3433e5b84f44a484e29fc5cf1e83c695a0d2', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 2, 'created': '2016-02-05 17:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9dce6be43e275dbaf053cffe1686a53a0ccf7a84', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 3, 'created': '2016-02-29 20:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/266cc6c88fb712bab7c73df1db8f048438385a50', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 4, 'created': '2016-02-29 20:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d706664476f6c1f99f14599755c5bc18fc01f4b1', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 5, 'created': '2016-02-29 21:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/98594c98cb4f1de9b67f4d401f3cce83c2922fc0', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 6, 'created': '2016-02-29 21:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0122e5283ffdc35a199104bf29c171edd6bbdfef', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 7, 'created': '2016-02-29 21:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ec1a6c99f97e90d8a7e6f212f966b14df1b50f21', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}, {'number': 8, 'created': '2016-03-01 21:24:37.000000000', 'files': ['releasenotes/notes/neutron-enable-lbaasv2-agent-bc402800792d4c3c.yaml', 'playbooks/roles/os_neutron/defaults/main.yml', 'doc/source/install-guide/configure-lbaas.rst', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_neutron/tasks/main.yml', 'playbooks/roles/os_neutron/templates/neutron.conf.j2', 'playbooks/roles/os_neutron/templates/lbaas_agent.ini.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8f540fe579bb5366fc16f31cf133a85cd2d93027', 'message': 'Replacing LBaaSv1 with v2 configuration\n\nThis fix will change the default configuration to LBaaSv2\nand update the haproxy driver to use the new v2 compatible classes\nNor LBaaSv2 or the lbaas-agent will be enabled by default.\n\nChange-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880\nCloses-Bug: #1541130\n'}]",7,275440,8f540fe579bb5366fc16f31cf133a85cd2d93027,40,6,8,14552,,,0,"Replacing LBaaSv1 with v2 configuration

This fix will change the default configuration to LBaaSv2
and update the haproxy driver to use the new v2 compatible classes
Nor LBaaSv2 or the lbaas-agent will be enabled by default.

Change-Id: I1c9c43582c99ebd1fb7bacb6545bcad34a692880
Closes-Bug: #1541130
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/40/275440/8 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_neutron/defaults/main.yml', 'doc/source/install-guide/configure-lbaas.rst', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_neutron/templates/neutron.conf.j2', 'playbooks/roles/os_neutron/templates/lbaas_agent.ini.j2']",5,b82c3433e5b84f44a484e29fc5cf1e83c695a0d2,bug/1541130,#LBaaSv1 device_driver = neutron_lbaas.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver #LBaaSv2 device_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver device_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver,device_driver = neutron_lbaas.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver,14,11
openstack%2Fkolla~master~I904d5e4b33c82e20a8e7e84308b62573f59de714,openstack/kolla,master,I904d5e4b33c82e20a8e7e84308b62573f59de714,Reconfigure ceph service,MERGED,2016-03-04 05:42:47.000000000,2016-03-04 22:35:45.000000000,2016-03-04 22:35:45.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-04 05:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/39edf8cbeca15a2861caa03a2cc0b6a76d5c4986', 'message': 'Reconfigure ceph service\n\nThis patch set implements reconfiguring the ceph service.\n\nChange-Id: I904d5e4b33c82e20a8e7e84308b62573f59de714\nPartially-implements: bp kolla-reconfig\n'}, {'number': 2, 'created': '2016-03-04 19:06:55.000000000', 'files': ['ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/ceph/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/efd10993353ff214ccb262a1c47e300b066f5ab0', 'message': 'Reconfigure ceph service\n\nThis patch set implements reconfiguring the ceph service.\n\nChange-Id: I904d5e4b33c82e20a8e7e84308b62573f59de714\nPartially-implements: bp kolla-reconfig\n'}]",8,288252,efd10993353ff214ccb262a1c47e300b066f5ab0,18,6,2,13642,,,0,"Reconfigure ceph service

This patch set implements reconfiguring the ceph service.

Change-Id: I904d5e4b33c82e20a8e7e84308b62573f59de714
Partially-implements: bp kolla-reconfig
",git fetch https://review.opendev.org/openstack/kolla refs/changes/52/288252/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/ceph/tasks/do_reconfigure.yml']",2,39edf8cbeca15a2861caa03a2cc0b6a76d5c4986,bp/kolla-reconfig,"--- - name: Ensuring the containers ceph_mon and ceph_rgw are up kolla_docker: name: ""{{ item.name }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false when: inventory_hostname in groups[item.group] with_items: - { name: ceph_mon, group: ceph-mon } - { name: ceph_rgw, group: ceph-rgw } - name: Gathering OSD IDs command: ""cat /var/lib/ceph/osd/{{ item['fs_uuid'] }}/whoami"" with_items: osds register: id changed_when: False failed_when: id.rc != 0 - name: Ensuring the ceph_osd container is up kolla_docker: name: ""ceph_osd_{{ item.0.stdout }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false with_together: - id.results - osds when: osds - include: config.yml - name: Check the configs in ceph_mon and ceph_rgw containers command: docker exec {{ item.name }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false register: check_results when: inventory_hostname in groups[item.group] with_items: - { name: ceph_mon, group: ceph-mon } - { name: ceph_rgw, group: ceph-rgw } - name: Check the configs in the ceph_osd container command: docker exec ceph_osd_{{ item.0.stdout }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false with_together: - id.results - osds when: osds # NOTE(jeffrey4l): when config_strategy == 'COPY_ALWAYS' # and container env['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE', # just remove the container and start again - name: Containers config strategy for ceph_mon and ceph_rgw containers kolla_docker: name: ""{{ item.name }}"" action: ""get_container_env"" register: container_envs when: inventory_hostname in groups[item.group] with_items: - { name: ceph_mon, group: ceph-mon } - { name: ceph_rgw, group: ceph-rgw } - name: Containers config strategy for the ceph_osd container kolla_docker: name: ""ceph_osd_{{ item.0.stdout }}"" action: ""get_container_env"" with_together: - id.results - osds when: osds - name: Remove the ceph_mon and ceph_rgw containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""remove_container"" register: remove_containers when: - config_strategy == ""COPY_ONCE"" or item[1]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: ceph_mon, group: ceph-mon }, { name: ceph_rgw, group: ceph-rgw }] - container_envs.results - check_results.results - name: Remove th ceph_osd container kolla_docker: name: ""ceph_osd_{{ item.0.stdout }}"" action: ""remove_container"" when: - config_strategy == ""COPY_ONCE"" or item[2]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[3]['rc'] == 1 - osds with_together: - id.results - osds - container_envs.results - check_results.results - include: deploy.yml when: remove_containers.changed - name: Restart the ceph_mon and ceph_rgw containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""restart_container"" when: - config_strategy == 'COPY_ALWAYS' - item[1]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - [{ name: ceph_mon, group: ceph-mon }, { name: ceph_rgw, group: ceph-rgw }] - container_envs.results - check_results.results - name: Restart the ceph_osd container kolla_docker: name: ""ceph_osd_{{ item.0.stdout }}"" action: ""restart_container"" when: - config_strategy == 'COPY_ALWAYS' - item[2]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[3]['rc'] == 1 - osds with_together: - id.results - osds - container_envs.results - check_results.results ",,139,0
openstack%2Fpuppet-cinder~master~Ie2ca974dfa583c176fce4907f1d81c80426ecccc,openstack/puppet-cinder,master,Ie2ca974dfa583c176fce4907f1d81c80426ecccc,Add Cinder API v3 support,MERGED,2016-03-03 02:06:59.000000000,2016-03-04 22:22:39.000000000,2016-03-04 19:57:25.000000000,"[{'_account_id': 3}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 14007}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-03 02:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7b0a71d159432f52a745780ecf9380ecdd016aac', 'message': 'Add Cinder API v3 support\n\nThe v1 api is deprecated and is not under active development.\n\nThis patch:\n* allow to activate cinder v3 api (enabled by default, like recommended\n  by OpenStack logs)\n* allow to manage Keystone resources for v3 API, enabled by default from\n  Mitaka.\n\nChange-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc\n'}, {'number': 2, 'created': '2016-03-03 02:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/5c729eb9fdca4f181ca6460fa87e7350e53ff63d', 'message': 'Add Cinder API v3 support\n\nThe v1 api is deprecated and is not under active development.\n\nThis patch:\n* activate v2 Keystone resources by default from now.\n* allow to activate cinder v3 api (enabled by default, like recommended\n  by OpenStack logs)\n* allow to manage Keystone resources for v3 API, enabled by default from\n  Mitaka.\n\nChange-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc\n'}, {'number': 3, 'created': '2016-03-03 15:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/23fae490f30cd443829d3734acad78519506f793', 'message': 'Add Cinder API v3 support\n\nThe v1 api is deprecated and is not under active development.\n\nThis patch:\n* activate v2 Keystone resources by default from now.\n* allow to activate cinder v3 api (enabled by default, like recommended\n  by OpenStack logs)\n* allow to manage Keystone resources for v3 API, enabled by default from\n  Mitaka.\n\nChange-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc\n'}, {'number': 4, 'created': '2016-03-03 19:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/49f0e2fc0c792458a0ab93ebb593102d167c231a', 'message': 'Add Cinder API v3 support\n\nThe v1 api is deprecated and is not under active development.\n\nThis patch:\n* activate v2 Keystone resources by default from now.\n* allow to activate cinder v3 api (enabled by default, like recommended\n  by OpenStack logs)\n* allow to manage Keystone resources for v3 API, enabled by default from\n  Mitaka.\n\nChange-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc\n'}, {'number': 5, 'created': '2016-03-03 23:13:50.000000000', 'files': ['spec/classes/cinder_keystone_auth_spec.rb', 'manifests/init.pp', 'spec/classes/cinder_spec.rb', 'manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7034a70d5a44329eba4bd6a0aa31d52bb3501bde', 'message': 'Add Cinder API v3 support\n\nThe v1 api is deprecated and is not under active development.\n\nThis patch:\n* activate v2 Keystone resources by default from now.\n* allow to activate cinder v3 api (enabled by default, like recommended\n  by OpenStack logs)\n* allow to manage Keystone resources for v3 API, enabled by default from\n  Mitaka.\n\nDepends-On: Ibfc3988a4de47c9d7d97159e7d1c0e57d64979ae\nChange-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc\n'}]",0,287559,7034a70d5a44329eba4bd6a0aa31d52bb3501bde,25,5,5,3153,,,0,"Add Cinder API v3 support

The v1 api is deprecated and is not under active development.

This patch:
* activate v2 Keystone resources by default from now.
* allow to activate cinder v3 api (enabled by default, like recommended
  by OpenStack logs)
* allow to manage Keystone resources for v3 API, enabled by default from
  Mitaka.

Depends-On: Ibfc3988a4de47c9d7d97159e7d1c0e57d64979ae
Change-Id: Ie2ca974dfa583c176fce4907f1d81c80426ecccc
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/59/287559/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_keystone_auth_spec.rb', 'manifests/init.pp', 'spec/classes/cinder_spec.rb', 'manifests/keystone/auth.pp']",4,7b0a71d159432f52a745780ecf9380ecdd016aac,v3,"# [*password_user_v3*] # Password for Cinder v3 user. Optional. Defaults to undef. # # [*email_user_v3*] # Email for Cinder v3 user. Optional. Defaults to 'cinderv3@localhost'. ## [*auth_name_v3*] # Username for Cinder v3 service. Optional. Defaults to 'cinderv3'. ## [*configure_endpoint_v3*] # Should Cinder v3 endpoint be configured? Optional. Defaults to 'true'. ## Should the service user be configured for cinder v2? Optional. Defaults to 'true'. # # [*configure_user_v3*] # Should the service user be configured for cinder v3? Optional. Defaults to 'true'.# Optional. Defaults to 'true'. # # [*configure_user_role_v3*] # Should the admin role be configured for the service user for cinder v3? # Optional. Defaults to 'true'.# [*service_name_v3*] # (optional) Name of the v3 service. # Defaults to the value of auth_name_v3, but must differ from the value # of service_name. ## [*service_type_v3*] # Type of API v3 service. Optional. Defaults to 'volumev3'. ## [*service_description_v3*] # (optional) Description for keystone v3 service. # Defaults to 'Cinder Service v3'. ## [*public_url_v3*] # (optional) The v3 endpoint's public url. (Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s') # This url should *not* contain any trailing '/'. # # [*internal_url_v3*] # (optional) The v3 endpoint's internal url. (Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s') # This url should *not* contain any trailing '/'. # # [*admin_url_v3*] # (optional) The v3 endpoint's admin url. (Defaults to 'http://127.0.0.1:8776/v3/%(tenant_id)s') # This url should *not* contain any trailing '/'. # $auth_name_v3 = 'cinderv3', $tenant_user_v3 = 'services', $email_user_v3 = 'cinderv3@localhost', $public_url_v3 = 'http://127.0.0.1:8776/v3/%(tenant_id)s', $internal_url_v3 = 'http://127.0.0.1:8776/v3/%(tenant_id)s', $admin_url_v3 = 'http://127.0.0.1:8776/v3/%(tenant_id)s', $configure_endpoint_v3 = true, $configure_user_v2 = true, $configure_user_v3 = true, $configure_user_role_v2 = true, $configure_user_role_v3 = true, $service_name_v3 = undef, $service_type_v3 = 'volumev3', $service_description_v3 = 'Cinder Service v3', keystone::resource::service_identity { 'cinderv3': configure_user => $configure_user_v3, configure_user_role => $configure_user_role_v3, configure_endpoint => $configure_endpoint_v3, service_type => $service_type_v3, service_description => $service_description_v3, service_name => $real_service_name_v3, region => $region, auth_name => $auth_name_v3, password => $password_user_v3, email => $email_user_v3, tenant => $tenant_user_v3, public_url => $public_url_v3, admin_url => $admin_url_v3, internal_url => $internal_url_v3, } ","# Should the service user be configured for cinder v2? Optional. Defaults to 'false'.# Optional. Defaults to 'false'. $configure_user_v2 = false, $configure_user_role_v2 = false,",132,9
openstack%2Fsolum~master~I6f30224ac1b11fc4019dbc5ae5ec1e1fedbfe97d,openstack/solum,master,I6f30224ac1b11fc4019dbc5ae5ec1e1fedbfe97d,Moved CORS middleware configuration into oslo-config-generator,MERGED,2016-03-04 15:29:25.000000000,2016-03-04 22:22:25.000000000,2016-03-04 22:22:25.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-03-04 15:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/efe56e7d5ad3c265db971e5ec66dc32fb6e41253', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for solum's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to the default configuration parsing. This ensures\nthat if a value remains unset in mistral.conf, it will be set\nto use sane defaults, and that an operator modifying the\nconfiguration file will be presented with a default set of\nnecessary sane headers.\n\nChange-Id: I6f30224ac1b11fc4019dbc5ae5ec1e1fedbfe97d\nCloses-Bug: 1551836\n""}, {'number': 2, 'created': '2016-03-04 16:09:21.000000000', 'files': ['solum/config.py', 'solum/api/app.py', 'solum/common/config.py', 'solum/common/service.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/solum/commit/dbfdf9f5db2c216e222dfa20e49e7afba932f34c', 'message': ""Moved CORS middleware configuration into oslo-config-generator\n\nThe default values needed for solum's implementation of cors\nmiddleware have been moved from paste.ini into the configuration\nhooks provided by oslo.config. Furthermore, these values have been\nadded to the default configuration parsing. This ensures\nthat if a value remains unset in solum.conf, it will be set\nto use sane defaults, and that an operator modifying the\nconfiguration file will be presented with a default set of\nnecessary sane headers.\n\nChange-Id: I6f30224ac1b11fc4019dbc5ae5ec1e1fedbfe97d\nCloses-Bug: 1551836\n""}]",1,288528,dbfdf9f5db2c216e222dfa20e49e7afba932f34c,10,3,2,9717,,,0,"Moved CORS middleware configuration into oslo-config-generator

The default values needed for solum's implementation of cors
middleware have been moved from paste.ini into the configuration
hooks provided by oslo.config. Furthermore, these values have been
added to the default configuration parsing. This ensures
that if a value remains unset in solum.conf, it will be set
to use sane defaults, and that an operator modifying the
configuration file will be presented with a default set of
necessary sane headers.

Change-Id: I6f30224ac1b11fc4019dbc5ae5ec1e1fedbfe97d
Closes-Bug: 1551836
",git fetch https://review.opendev.org/openstack/solum refs/changes/28/288528/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/config.py', 'solum/api/app.py', 'solum/common/config.py', 'solum/common/service.py', 'setup.cfg']",5,efe56e7d5ad3c265db971e5ec66dc32fb6e41253,bug/1551836,oslo.config.opts.defaults = oslo.middleware.cors = solum.common.config:set_cors_middleware_defaults ,,48,7
openstack%2Fcue~master~Ic0849f0e14dd13d4f6d3e45d0785b21de4b1c7bc,openstack/cue,master,Ic0849f0e14dd13d4f6d3e45d0785b21de4b1c7bc,Add debug testenv in tox,MERGED,2016-01-11 13:46:03.000000000,2016-03-04 22:22:09.000000000,2016-03-04 22:22:09.000000000,"[{'_account_id': 3}, {'_account_id': 10584}, {'_account_id': 19132}, {'_account_id': 19136}]","[{'number': 1, 'created': '2016-01-11 13:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/c552bc5287f739b5553562fb14af272658fa703c', 'message': 'Add debug testenv in tox\n\nOnce we add debug testenv, we can use ""tox -e debug -- --debug""\nto debug test cases when tox is running.\n\nChange-Id: Ic0849f0e14dd13d4f6d3e45d0785b21de4b1c7bc\n'}, {'number': 2, 'created': '2016-03-04 19:34:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cue/commit/1a04a9c6a45ac22d57135a903a95b26b7f911583', 'message': 'Add debug testenv in tox\n\nOnce we add debug testenv, we can use ""tox -e debug -- --debug""\nto debug test cases when tox is running.\n\nChange-Id: Ic0849f0e14dd13d4f6d3e45d0785b21de4b1c7bc\n'}]",0,265828,1a04a9c6a45ac22d57135a903a95b26b7f911583,14,4,2,19136,,,0,"Add debug testenv in tox

Once we add debug testenv, we can use ""tox -e debug -- --debug""
to debug test cases when tox is running.

Change-Id: Ic0849f0e14dd13d4f6d3e45d0785b21de4b1c7bc
",git fetch https://review.opendev.org/openstack/cue refs/changes/28/265828/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c552bc5287f739b5553562fb14af272658fa703c,,[testenv:debug] commands = oslo_debug_helper {posargs} [testenv:debug-py27] basepython = python2.7 commands = oslo_debug_helper {posargs} [testenv:debug-py34] basepython = python3.4 commands = oslo_debug_helper {posargs} ,,11,0
openstack%2Fcue~master~I18330c66cddf527d5fddfdbc29656e0313b04e16,openstack/cue,master,I18330c66cddf527d5fddfdbc29656e0313b04e16,Validate cluster flavor with image metadata,MERGED,2015-12-22 21:54:56.000000000,2016-03-04 22:22:04.000000000,2016-03-04 22:22:03.000000000,"[{'_account_id': 3}, {'_account_id': 5390}, {'_account_id': 10584}, {'_account_id': 13771}, {'_account_id': 14955}]","[{'number': 1, 'created': '2015-12-22 21:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/536d96412eb8f64c673e5b7f80b2341701b03369', 'message': 'Validate cluster flavor with image metadata\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 2, 'created': '2015-12-23 07:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/fe2306955918b4dfaf6a094756f0f7ee143278ef', 'message': 'Validate cluster flavor with image metadata\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 3, 'created': '2015-12-23 21:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/3d51223d5a5e23b9aeb605b8747797675b43d429', 'message': 'Validate cluster flavor with image metadata\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 4, 'created': '2015-12-23 23:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/07c300cf92a5475e9cc0735db63de9550b5041c8', 'message': 'Validate cluster flavor with image metadata\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 5, 'created': '2015-12-23 23:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/bc443ab412f27b8033edfca7687c03e3d01b774c', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 6, 'created': '2015-12-24 00:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/0c3cdcd6262a2d0f917b7b75ea3354689859db96', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 7, 'created': '2016-01-08 22:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/5c8ae92bd7722aac7615f91846818080eb090246', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 8, 'created': '2016-01-08 22:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/a3c50951e4dbadc9a4fca7451335b6da68e79638', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 9, 'created': '2016-01-08 22:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/2380d367305baa9c48bf0b5d4f5210b5c5198832', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 10, 'created': '2016-01-11 20:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/377e507b59ad86e653b4bdea75d3e1a8f00bb276', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 11, 'created': '2016-01-11 21:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/5bd69cd89cf9ded072c1dce57471b81844745d05', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 12, 'created': '2016-01-12 00:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/a3373dff128ba3ecfafaf612aed07c991609e983', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 13, 'created': '2016-01-17 07:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/8c793264170019820d901604c90d5a71f3aee1c5', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 14, 'created': '2016-01-19 04:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/1d5580e9159d1ed82fbbdcd7c57bba5d5db9f294', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 15, 'created': '2016-01-25 22:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/7fdd65aa60ca491c10e48b502af582c4feed5803', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}, {'number': 16, 'created': '2016-03-04 19:34:31.000000000', 'files': ['cue/common/exception.py', 'cue/tests/functional/api/v1/test_cluster.py', 'cue/tests/functional/utils.py', 'cue/tests/functional/api/__init__.py', 'devstack/plugin.sh', 'cue/tests/functional/fixtures/nova.py', 'cue/api/controllers/v1/cluster.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/5d4550122d265f8ada934b8570d555ac94234ce9', 'message': 'Validate cluster flavor with image metadata\n\n  cue cluster creation fails if the flavor disk size is too small\nfor the broker image.this fix validates the flavor disk size with\nimage metadata ,raising the exception from api instead of nova.\n\nChange-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16\n'}]",46,260722,5d4550122d265f8ada934b8570d555ac94234ce9,57,5,16,14955,,,0,"Validate cluster flavor with image metadata

  cue cluster creation fails if the flavor disk size is too small
for the broker image.this fix validates the flavor disk size with
image metadata ,raising the exception from api instead of nova.

Change-Id: I18330c66cddf527d5fddfdbc29656e0313b04e16
",git fetch https://review.opendev.org/openstack/cue refs/changes/22/260722/16 && git format-patch -1 --stdout FETCH_HEAD,['cue/api/controllers/v1/cluster.py'],1,536d96412eb8f64c673e5b7f80b2341701b03369,refactor_test,"import cue.client as client # image metadata os_client = client.nova_client() image_metadata = os_client.images.get(image_id) image_minRam = image_metadata.minRam image_minDisk = image_metadata.minDisk # flavor metadata flavor_metadata = os_client.flavors.get(cluster.flavor) flavor_ram = flavor_metadata.ram flavor_disk = flavor_metadata.disk if not (flavor_ram >= image_minRam) and (flavor_disk >= image_minDisk): job_args = { 'tenant_id': new_cluster.project_id, 'flavor': cluster.flavor, 'image': image_id, 'volume_size': cluster.volume_size, 'network_id': cluster.network_id, 'port': '5672', 'context': context.to_dict(), # TODO(sputnik13: this needs to come from the create request # and default to a configuration value rather than always using # config value 'security_groups': [CONF.os_security_group], 'port': CONF.rabbit_port, 'key_name': CONF.openstack.os_key_name, 'erlang_cookie': erlang_cookie, 'default_rabbit_user': default_rabbit_user, 'default_rabbit_pass': default_rabbit_pass, } job_client = task_flow_client.get_client_instance() #TODO(dagnello): might be better to use request_id for job_uuid job_uuid = uuidutils.generate_uuid() job_client.post(create_cluster, job_args, flow_kwargs=flow_kwargs, tx_uuid=job_uuid) LOG.info(_LI('Create Cluster Request Cluster ID %(cluster_id)s ' 'Cluster size %(size)s network ID %(network_id)s ' 'Job ID %(job_id)s Broker name %(broker_name)s') % ( {""cluster_id"": cluster.id, ""size"": cluster.size, ""network_id"": cluster.network_id, ""job_id"": job_uuid, ""broker_name"": broker_name})) cluster.additional_information = [] cluster.additional_information.append( dict(def_rabbit_user=default_rabbit_user)) cluster.additional_information.append( dict(def_rabbit_pass=default_rabbit_pass)) cluster.unset_empty_fields() return cluster else: raise exception.Invalid(_(""Flavor disk/ram is smaller than the "" ""minimum specified in image metadata""))"," job_args = { 'tenant_id': new_cluster.project_id, 'flavor': cluster.flavor, 'image': image_id, 'volume_size': cluster.volume_size, 'port': '5672', 'context': context.to_dict(), # TODO(sputnik13: this needs to come from the create request and # default to a configuration value rather than always using config # value 'security_groups': [CONF.os_security_group], 'port': CONF.rabbit_port, 'key_name': CONF.openstack.os_key_name, 'erlang_cookie': erlang_cookie, 'default_rabbit_user': default_rabbit_user, 'default_rabbit_pass': default_rabbit_pass, } job_client = task_flow_client.get_client_instance() #TODO(dagnello): might be better to use request_id for job_uuid job_uuid = uuidutils.generate_uuid() job_client.post(create_cluster, job_args, flow_kwargs=flow_kwargs, tx_uuid=job_uuid) LOG.info(_LI('Create Cluster Request Cluster ID %(cluster_id)s Cluster' ' size %(size)s network ID %(network_id)s Job ID ' '%(job_id)s Broker name %(broker_name)s') % ( {""cluster_id"": cluster.id, ""size"": cluster.size, ""network_id"": cluster.network_id, ""job_id"": job_uuid, ""broker_name"": broker_name})) cluster.additional_information = [] cluster.additional_information.append( dict(def_rabbit_user=default_rabbit_user)) cluster.additional_information.append( dict(def_rabbit_pass=default_rabbit_pass)) cluster.unset_empty_fields() return cluster",56,39
openstack%2Fcue~master~Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6,openstack/cue,master,Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6,Changing the documentation for Cue to the Openstack theme,MERGED,2016-01-12 16:19:47.000000000,2016-03-04 22:21:58.000000000,2016-03-04 22:21:58.000000000,"[{'_account_id': 3}, {'_account_id': 10584}, {'_account_id': 16132}]","[{'number': 1, 'created': '2016-01-12 16:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/d03df0cdc8c94392c4120ff856f12be744a3ffa8', 'message': 'Changing the documentation for Cue to the Openstack theme\n\nThe changes were made to the conf.py in docs so that Sphinx\nbuilds the right theme for the documentation.\n\nChange-Id: Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6\n'}, {'number': 2, 'created': '2016-01-19 18:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/c32c66ec242a57e2d866e8c282e4f0482d91018e', 'message': 'Changing the documentation for Cue to the Openstack theme\n\nThe changes were made to the conf.py in docs so that Sphinx\nbuilds the right theme for the documentation.\n\nChange-Id: Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6\n'}, {'number': 3, 'created': '2016-01-19 21:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/d17eddf3b7d3c6a307dd72b5197d4fec52a0fa12', 'message': 'Changing the documentation for Cue to the Openstack theme\n\nThe changes were made to the conf.py in docs so that Sphinx\nbuilds the right theme for the documentation.\n\nChange-Id: Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6\n'}, {'number': 4, 'created': '2016-03-04 19:34:27.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/dfb332dc361ba6c13547ac5108f3e66202567572', 'message': 'Changing the documentation for Cue to the Openstack theme\n\nThe changes were made to the conf.py in docs so that Sphinx\nbuilds the right theme for the documentation.\n\nChange-Id: Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6\n'}]",1,266459,dfb332dc361ba6c13547ac5108f3e66202567572,23,3,4,16132,,,0,"Changing the documentation for Cue to the Openstack theme

The changes were made to the conf.py in docs so that Sphinx
builds the right theme for the documentation.

Change-Id: Iff24544dddf2c6c7a0a6baad6dc17ce92b05acf6
",git fetch https://review.opendev.org/openstack/cue refs/changes/59/266459/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,d03df0cdc8c94392c4120ff856f12be744a3ffa8,cue_docs_2," # -*- coding: utf-8 -*- # # -- General configuration ----------------------------------------------------# Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones. extensions = ['sphinx.ext.todo', 'oslosphinx']# The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. # The full version, including alpha/beta/rc tags. # The short X.Y version. exclude_patterns = ['_build'] # The reST default role (used for this markup: `text`) to use for all documentsadd_function_parentheses = Trueadd_module_names = True#show_authors = False# If true, keep warnings as ""system message"" paragraphs in the built documents. #keep_warnings = False # -- Options for HTML output --------------------------------------------------# html_theme_path = ["".""] # html_theme = '_theme' # html_static_path = ['_static']# Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". # html_static_path = ['_static'] #html_last_updated_fmt = '%b %d, %Y'#html_domain_indices = True#html_use_index = True# -- Options for LaTeX output ------------------------------------------------- # The paper size ('letterpaper' or 'a4paper'). #'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). #'pointsize': '10pt', # Additional stuff for the LaTeX preamble. #'preamble': '',# (source start file, target name, title, author, documentclass [howto/manual]) # -- Options for manual page output ------------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). # man_pages = [ # ( # 'index', # '%s' % project, # u'%s Documentation' % project, # u'OpenStack Foundation', # 1 # ), # ] # If true, show URL addresses after external links. #man_show_urls = False # -- Options for Texinfo output ----------------------------------------------- u'OpenStack Cue Team', 'Cue-specs', 'Design specifications for the Cue project.',# If true, do not generate a @detailmenu in the ""Top"" node's menu. #texinfo_no_detailmenu = False # -- Options for Epub output --------------------------------------------------# A sequence of (type, uri, title) tuples for the guide element of content.opf. #epub_guide = () # Fix unsupported image types using the PIL. #epub_fix_images = False # Scale large images. #epub_max_image_width = 0 # If 'no', URL addresses will not be shown. #epub_show_urls = 'inline' # If false, no index is generated. #epub_use_index = True","# -- General configuration -----------------------------------------------------# Add any Sphinx extension module names here, as strings. They can be extensions # coming with Sphinx (named 'sphinx.ext.*') or your custom ones. extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo', 'sphinx.ext.graphviz', 'sphinxcontrib.httpdomain', ] todo_include_todos = Trueexclude_patterns = ['_build', 'specs/skeleton.rst', 'specs/template.rst'] # The reST default role (used for this markup: `text`) to use for all documents.#add_function_parentheses = Trueadd_module_names = Falseshow_authors = False# -- Options for man page output ---------------------------------------------- man_pages = [] # -- Options for HTML output ---------------------------------------------------html_theme = 'default'git_cmd = ""git log --pretty=format:'%ad, commit %h' --date=local -n1"" html_last_updated_fmt = os.popen(git_cmd).read()html_domain_indices = Truehtml_use_index = True# -- Options for LaTeX output --------------------------------------------------# The paper size ('letterpaper' or 'a4paper'). #'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). #'pointsize': '10pt', # Additional stuff for the LaTeX preamble. #'preamble': '',# (source start file, target name, title, author, documentclass [howto/manual]).# -- Options for Texinfo output ------------------------------------------------ u'OpenStack Cue Team', 'Cue-specs', 'Design specifications for the Cue project.', # -- Options for Epub output ---------------------------------------------------",86,34
openstack%2Fastara-appliance~master~Ifaf53a26f6d89da199101f386f4674c9f39f8326,openstack/astara-appliance,master,Ifaf53a26f6d89da199101f386f4674c9f39f8326,Remove iptables assumption that all routers have external networks,MERGED,2016-03-02 20:45:01.000000000,2016-03-04 22:21:51.000000000,2016-03-04 22:21:51.000000000,"[{'_account_id': 3}, {'_account_id': 986}, {'_account_id': 2592}]","[{'number': 1, 'created': '2016-03-02 20:45:01.000000000', 'files': ['test/unit/drivers/test_iptables.py', 'astara_router/drivers/iptables.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/33ee88897c9c17d28059901ff82c6851f6d92f65', 'message': 'Remove iptables assumption that all routers have external networks\n\nIn order to remove the auto-addition of external networks, we need\nto remove the assumption in the appliance that all routers have one.\nThis avoids adding external network related iptables rules when the\nrouter config does not have an external port.\n\nChange-Id: Ifaf53a26f6d89da199101f386f4674c9f39f8326\n'}]",0,287427,33ee88897c9c17d28059901ff82c6851f6d92f65,11,3,1,1420,,,0,"Remove iptables assumption that all routers have external networks

In order to remove the auto-addition of external networks, we need
to remove the assumption in the appliance that all routers have one.
This avoids adding external network related iptables rules when the
router config does not have an external port.

Change-Id: Ifaf53a26f6d89da199101f386f4674c9f39f8326
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/27/287427/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/drivers/test_iptables.py', 'astara_router/drivers/iptables.py', 'setup.cfg']",3,33ee88897c9c17d28059901ff82c6851f6d92f65,,, [nosetests] where = test verbosity = 2 detailed-errors = 1 cover-package = astara_router,59,34
openstack%2Fhorizon~master~Ib1d4143251421d03e4e9c3071d43d2423e3b0d8c,openstack/horizon,master,Ib1d4143251421d03e4e9c3071d43d2423e3b0d8c,Deprecate default_*_subnet_pool_label options,MERGED,2016-02-29 17:15:33.000000000,2016-03-04 22:21:26.000000000,2016-03-04 22:21:26.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 9622}, {'_account_id': 12281}]","[{'number': 1, 'created': '2016-02-29 17:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/08dd4bd9461c5f093637da5cdfdd5a93b4a0d209', 'message': ""Deprecate default_*_subnet_pool_label options\n\nStarting with Mitaka, Neutron API handing of default subnetpool has changed [1].\n\nIf a default subnetpool exists in Neutron it will show up in the subnetpool list. Thus no change in Horizon is needed to handle this part.\n\nThe following changes are required in Horizon:\n- Mark the 'default_ipv4_subnet_pool_label' and 'default_ipv6_subnet_pool_label' configuration options for use with Liberty only, deprecate them and tag them for removal in future release.\n- When the configuration options are removed the _check_subnet_data function should no longer allow to pass empty 'cidr' and 'subnetpool_id'.\n\nReferences:\n1: http://docs.openstack.org/releasenotes/neutron/unreleased.html\n\nChange-Id: Ib1d4143251421d03e4e9c3071d43d2423e3b0d8c\nCloses-Bug: #1551333\n""}, {'number': 2, 'created': '2016-03-02 20:28:29.000000000', 'files': ['doc/source/topics/settings.rst', 'releasenotes/notes/deprecation-of-default-subnet-pool-label-options-b05ebccbf6f68ecf.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a68857bfc39bf833facbe76d1fe01ea43df876f', 'message': ""Deprecate default_*_subnet_pool_label options\n\nStarting with Mitaka, Neutron API handing of default subnetpool has\nchanged [1].\n\nIf a default subnetpool exists in Neutron it will show up in the\nsubnetpool list. Thus no change in Horizon is needed to handle this\npart.\n\nThe following changes are required in Horizon:\n- Mark the 'default_ipv4_subnet_pool_label' and\n  'default_ipv6_subnet_pool_label' configuration options for use\n  with Liberty only, deprecate them and tag them for removal in\n  future release.\n- When the configuration options are removed the _check_subnet_data\n  function should no longer allow to pass empty 'cidr' and\n  'subnetpool_id'.\n\nReferences:\n1: http://docs.openstack.org/releasenotes/neutron/unreleased.html\n\nChange-Id: Ib1d4143251421d03e4e9c3071d43d2423e3b0d8c\nCloses-Bug: #1551333\n""}]",0,286163,5a68857bfc39bf833facbe76d1fe01ea43df876f,15,4,2,13686,,,0,"Deprecate default_*_subnet_pool_label options

Starting with Mitaka, Neutron API handing of default subnetpool has
changed [1].

If a default subnetpool exists in Neutron it will show up in the
subnetpool list. Thus no change in Horizon is needed to handle this
part.

The following changes are required in Horizon:
- Mark the 'default_ipv4_subnet_pool_label' and
  'default_ipv6_subnet_pool_label' configuration options for use
  with Liberty only, deprecate them and tag them for removal in
  future release.
- When the configuration options are removed the _check_subnet_data
  function should no longer allow to pass empty 'cidr' and
  'subnetpool_id'.

References:
1: http://docs.openstack.org/releasenotes/neutron/unreleased.html

Change-Id: Ib1d4143251421d03e4e9c3071d43d2423e3b0d8c
Closes-Bug: #1551333
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/286163/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/settings.rst'],1,08dd4bd9461c5f093637da5cdfdd5a93b4a0d209,bug/1551333,"This option is now marked as ""deprecated"" and will be removed in Newton or a later release. If there exists a default Subnet Pool it will be automatically detected through the Neutron API and the label will be set to the name of the default Subnet Pool. When using Liberty Neutron you must set this to enable IPv6 Prefix Delegation in a PD-capable environment. This option is now marked as ""deprecated"" and will be removed in Newton or a later release. If there exists a default Subnet Pool it will be automatically detected through the Neutron API and the label will be set to the name of the default Subnet Pool."," 'default_ipv4_subnet_pool_label': None, 'default_ipv6_subnet_pool_label': None,You must set this to enable IPv6 Prefix Delegation in a PD-capable environment.",12,3
openstack%2Fnova~master~Ic2f239f634f917a5771b0401a5073546c710c036,openstack/nova,master,Ic2f239f634f917a5771b0401a5073546c710c036,Don't lazy-load instance.services if the instance is deleted,MERGED,2016-02-23 21:52:29.000000000,2016-03-04 22:16:52.000000000,2016-03-04 22:16:50.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12712}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-23 21:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06894862e8e81f4837339e6e775471007cabc47d', 'message': ""Don't lazy-load instance.services if the instance is deleted\n\nThe 2.16 microversion added the host_status extended\nserver attribute which relies on the instance.services field.\n\nThe primary join in the database for that field is dependent on\nthe instance not being deleted.\n\nWhen listing deleted instances at microversion>=2.16, the\ncompute API attempts to lazy-load the instance.services field\nwhich fails with an InstanceNotFound because the instance\nis deleted.\n\nIn this case, it's best to just set instance.services to an\nempty ServiceList when lazy loading the services field on a\ndeleted instance since the DB object won't have any value for\nthe services attribute anyway.\n\nChange-Id: Ic2f239f634f917a5771b0401a5073546c710c036\nCloses-Bug: #1548980\n""}, {'number': 2, 'created': '2016-02-25 15:08:37.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1548980.py', 'nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d6bb233828ce63ae649e98e02dc59e04f3db2f5', 'message': ""Don't lazy-load instance.services if the instance is deleted\n\nThe 2.16 microversion added the host_status extended\nserver attribute which relies on the instance.services field.\n\nThe primary join in the database for that field is dependent on\nthe instance not being deleted.\n\nWhen listing deleted instances at microversion>=2.16, the\ncompute API attempts to lazy-load the instance.services field\nwhich fails with an InstanceNotFound because the instance\nis deleted.\n\nIn this case, it's best to just set instance.services to an\nempty ServiceList when lazy loading the services field on a\ndeleted instance since the DB object won't have any value for\nthe services attribute anyway.\n\nChange-Id: Ic2f239f634f917a5771b0401a5073546c710c036\nCloses-Bug: #1548980\n""}]",1,283820,3d6bb233828ce63ae649e98e02dc59e04f3db2f5,48,19,2,6873,,,0,"Don't lazy-load instance.services if the instance is deleted

The 2.16 microversion added the host_status extended
server attribute which relies on the instance.services field.

The primary join in the database for that field is dependent on
the instance not being deleted.

When listing deleted instances at microversion>=2.16, the
compute API attempts to lazy-load the instance.services field
which fails with an InstanceNotFound because the instance
is deleted.

In this case, it's best to just set instance.services to an
empty ServiceList when lazy loading the services field on a
deleted instance since the DB object won't have any value for
the services attribute anyway.

Change-Id: Ic2f239f634f917a5771b0401a5073546c710c036
Closes-Bug: #1548980
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/283820/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py']",2,06894862e8e81f4837339e6e775471007cabc47d,bug/1548980," def test_lazy_load_services_on_deleted_instance(self): # We should avoid trying to hit the database to reload the instance # and just set the services attribute to an empty list. instance = objects.Instance(self.context, uuid=uuids.instance, deleted=True) self.assertEqual(0, len(instance.services)) ",,12,0
openstack%2Fnova~master~I90f6c7a17bb773798ae77d19d744dcac02de215c,openstack/nova,master,I90f6c7a17bb773798ae77d19d744dcac02de215c,Add specific method to lazy-load instance.pci_devices,MERGED,2016-02-25 21:44:02.000000000,2016-03-04 22:15:37.000000000,2016-03-04 22:15:35.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15286}]","[{'number': 1, 'created': '2016-02-25 21:44:02.000000000', 'files': ['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7fbd9ec0c6bcda33c77f67169403939e7befff5d', 'message': ""Add specific method to lazy-load instance.pci_devices\n\nThe pci_devices field is generically lazy-loaded today by\ngetting the instance record from the database with a join\non the pci_devices table. We can make this smarter by just\ngetting the PciDeviceList via the instance uuid directly\nso we don't need to do the join and query on the instances\ntable.\n\nChange-Id: I90f6c7a17bb773798ae77d19d744dcac02de215c\nRelated-Bug: #1540526\n""}]",0,284945,7fbd9ec0c6bcda33c77f67169403939e7befff5d,19,7,1,6873,,,0,"Add specific method to lazy-load instance.pci_devices

The pci_devices field is generically lazy-loaded today by
getting the instance record from the database with a join
on the pci_devices table. We can make this smarter by just
getting the PciDeviceList via the instance uuid directly
so we don't need to do the join and query on the instances
table.

Change-Id: I90f6c7a17bb773798ae77d19d744dcac02de215c
Related-Bug: #1540526
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/284945/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py']",2,7fbd9ec0c6bcda33c77f67169403939e7befff5d,bug/1540526-pci-devices," @mock.patch('nova.objects.PciDeviceList.get_by_instance_uuid') def test_load_pci_devices(self, mock_get): fake_pci_devices = pci_device.PciDeviceList() mock_get.return_value = fake_pci_devices inst = objects.Instance(context=self.context, uuid=uuids.pci_devices) pci_devices = inst.pci_devices mock_get.assert_called_once_with(self.context, uuids.pci_devices) self.assertEqual(fake_pci_devices, pci_devices) ",,15,0
openstack%2Fnova~master~I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec,openstack/nova,master,I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec,Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm,MERGED,2015-12-03 09:25:40.000000000,2016-03-04 22:14:06.000000000,2016-03-04 22:14:04.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-03 09:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab70df3db07ffe9f1b80a237974f0fd0594966e1', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 2, 'created': '2015-12-15 06:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/233066d35c70c4ef8dc4ee1fb988c9631e8e5142', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 3, 'created': '2015-12-15 08:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9e4a235da0235be3a2c1dd942440f9546d1bcc7', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 4, 'created': '2015-12-16 06:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/949557dcb68ccbfd9741e6c63d304b6988d5e5a7', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 5, 'created': '2015-12-17 01:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cd9512c8533f5996be568b9a9f5f37387fa984b', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 6, 'created': '2016-02-29 02:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce86677b62af8b40ec7e560894fc3ecb3a0a03ae', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 7, 'created': '2016-03-04 02:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83c46d7bdd9798cf64f20185fb9aa8a0b793229d', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}, {'number': 8, 'created': '2016-03-04 06:19:31.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/66157aaeadc23d2183dae9046516abad0bcb81d5', 'message': ""Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm\n\nIn compute.api._check_and_transform_bdm() we have a logic to\navoid boot instances with both image-ref and a volume named\nas 'vda' is supplied. Currently, we check the bdm's 'source_type',\nbut infact we should check its' 'destination_type' as this\nshows it is a cinder volume.\n\nChange-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec\nCloses-Bug: #1522329\n""}]",2,252836,66157aaeadc23d2183dae9046516abad0bcb81d5,102,18,8,15888,,,0,"Check 'destination_type' instead of 'source_type' in _check_and_transform_bdm

In compute.api._check_and_transform_bdm() we have a logic to
avoid boot instances with both image-ref and a volume named
as 'vda' is supplied. Currently, we check the bdm's 'source_type',
but infact we should check its' 'destination_type' as this
shows it is a cinder volume.

Change-Id: I1fe2cf7c6655e0e0c61371c6d7379ecfc7071cec
Closes-Bug: #1522329
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/252836/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",2,ab70df3db07ffe9f1b80a237974f0fd0594966e1,bug/1522329, if (bdm.get('destination_type') == 'volume' and, if (bdm.get('source_type') == 'volume' and,2,1
openstack%2Fnova~master~I04dff9e7935e63988cdc70df05c1eaad0d679808,openstack/nova,master,I04dff9e7935e63988cdc70df05c1eaad0d679808,Add unit tests for live_migration_cleanup_flags,MERGED,2016-03-03 14:20:40.000000000,2016-03-04 22:12:57.000000000,2016-03-04 22:12:56.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5441}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-03-03 14:20:40.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0796afe00554ca9e3add90624ad8b63d83433225', 'message': 'Add unit tests for live_migration_cleanup_flags\n\nChange-Id: I04dff9e7935e63988cdc70df05c1eaad0d679808\n'}]",1,287821,0796afe00554ca9e3add90624ad8b63d83433225,13,5,1,12299,,,0,"Add unit tests for live_migration_cleanup_flags

Change-Id: I04dff9e7935e63988cdc70df05c1eaad0d679808
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/287821/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/compute/test_compute_mgr.py'],1,0796afe00554ca9e3add90624ad8b63d83433225,bug/1552303," def test_live_migration_cleanup_flags_block_migrate_libvirt(self): migrate_data = objects.LibvirtLiveMigrateData( is_shared_block_storage=False, is_shared_instance_path=False) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( True, migrate_data) self.assertTrue(do_cleanup) self.assertTrue(destroy_disks) def test_live_migration_cleanup_flags_shared_block_libvirt(self): migrate_data = objects.LibvirtLiveMigrateData( is_shared_block_storage=True, is_shared_instance_path=False) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( False, migrate_data) self.assertTrue(do_cleanup) self.assertFalse(destroy_disks) def test_live_migration_cleanup_flags_shared_path_libvirt(self): migrate_data = objects.LibvirtLiveMigrateData( is_shared_block_storage=False, is_shared_instance_path=True) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( False, migrate_data) self.assertFalse(do_cleanup) self.assertTrue(destroy_disks) def test_live_migration_cleanup_flags_shared_libvirt(self): migrate_data = objects.LibvirtLiveMigrateData( is_shared_block_storage=True, is_shared_instance_path=True) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( False, migrate_data) self.assertFalse(do_cleanup) self.assertFalse(destroy_disks) def test_live_migration_cleanup_flags_block_migrate_xenapi(self): migrate_data = objects.XenapiLiveMigrateData(block_migration=True) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( True, migrate_data) self.assertTrue(do_cleanup) self.assertTrue(destroy_disks) def test_live_migration_cleanup_flags_live_migrate_xenapi(self): migrate_data = objects.XenapiLiveMigrateData(block_migration=False) do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( False, migrate_data) self.assertFalse(do_cleanup) self.assertFalse(destroy_disks) def test_live_migration_cleanup_flags_live_migrate(self): do_cleanup, destroy_disks = self.compute._live_migration_cleanup_flags( False, {}) self.assertFalse(do_cleanup) self.assertFalse(destroy_disks) ",,56,0
openstack%2Fnova~master~I77d10551650776c06ee4b413f1b027abf6620e83,openstack/nova,master,I77d10551650776c06ee4b413f1b027abf6620e83,Documentation fix regarding triggering crash dump,MERGED,2016-03-04 04:06:52.000000000,2016-03-04 22:11:28.000000000,2016-03-04 22:11:24.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10385}, {'_account_id': 19896}]","[{'number': 1, 'created': '2016-03-04 04:06:52.000000000', 'files': ['api-guide/source/server_concepts.rst', 'doc/source/support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/230958c002736444bfb36c9f0845f4f4e5253d0e', 'message': 'Documentation fix regarding triggering crash dump\n\nHow to trigger crash dump depends on hypervisors. NMI is not the only way to\nimplement the feature. This patch modifies description regarding this feature.\n\nChange-Id: I77d10551650776c06ee4b413f1b027abf6620e83\n'}]",0,288242,230958c002736444bfb36c9f0845f4f4e5253d0e,15,7,1,13689,,,0,"Documentation fix regarding triggering crash dump

How to trigger crash dump depends on hypervisors. NMI is not the only way to
implement the feature. This patch modifies description regarding this feature.

Change-Id: I77d10551650776c06ee4b413f1b027abf6620e83
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/288242/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-guide/source/server_concepts.rst', 'doc/source/support-matrix.ini']",2,230958c002736444bfb36c9f0845f4f4e5253d0e,fix-doc-crash-dump, a crash dump in an instance. The feature is typically implemented by injecting an NMI (Non-maskable Interrupt) into the instance. It provides a means to dump the production memory image as a dump file which is useful for users. Therefore this operation is considered optional to support., a crash dump in an instance by injecting an NMI (Non-maskable Interrupt) into the instance. It provides a means to dump the production memory image as a dump file which is useful for users. Therefore this operation is considered optional to support.,5,5
openstack%2Fneutron-vpnaas~master~Ic2acd8a9aec86337c6d1345c827b3fee64f650a6,openstack/neutron-vpnaas,master,Ic2acd8a9aec86337c6d1345c827b3fee64f650a6,VPNaaS: make use of neutron_lib exceptions,MERGED,2016-03-01 23:03:21.000000000,2016-03-04 22:11:16.000000000,2016-03-04 22:11:16.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 6659}, {'_account_id': 7018}, {'_account_id': 9970}, {'_account_id': 10980}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-03-01 23:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/661b5c83e2bcfb7ee599ab88138dc9cacc294246', 'message': 'VPNaaS: make use of neutron_lib exceptions\n\nCommit 87a79256c494c36f2d9597313f430b24c0110161 added shared exceptions\nto neutron-lib. This patch makes use of the aforementioned library.\n\nChange-Id: Ic2acd8a9aec86337c6d1345c827b3fee64f650a6\n'}, {'number': 2, 'created': '2016-03-02 19:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/e9e0ea39a179979757c9ccf21bac6678a5a32c39', 'message': 'VPNaaS: make use of neutron_lib exceptions\n\nCommit 87a79256c494c36f2d9597313f430b24c0110161 added shared exceptions\nto neutron-lib. This patch makes use of the aforementioned library.\n\nChange-Id: Ic2acd8a9aec86337c6d1345c827b3fee64f650a6\n'}, {'number': 3, 'created': '2016-03-02 22:50:55.000000000', 'files': ['neutron_vpnaas/tests/unit/db/vpn/test_vpn_validator.py', 'neutron_vpnaas/services/vpn/service_drivers/cisco_validator.py', 'neutron_vpnaas/services/vpn/service_drivers/ipsec_validator.py', 'neutron_vpnaas/db/vpn/vpn_validator.py', 'requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/service_drivers/cisco_csr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/6dff32040c09be51b14954f3479cd81fcf00ac9f', 'message': 'VPNaaS: make use of neutron_lib exceptions\n\nCommit 87a79256c494c36f2d9597313f430b24c0110161 added shared exceptions\nto neutron-lib. This patch makes use of the aforementioned library.\n\nChange-Id: Ic2acd8a9aec86337c6d1345c827b3fee64f650a6\n'}]",9,286875,6dff32040c09be51b14954f3479cd81fcf00ac9f,20,9,3,7018,,,0,"VPNaaS: make use of neutron_lib exceptions

Commit 87a79256c494c36f2d9597313f430b24c0110161 added shared exceptions
to neutron-lib. This patch makes use of the aforementioned library.

Change-Id: Ic2acd8a9aec86337c6d1345c827b3fee64f650a6
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/75/286875/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/services/vpn/service_drivers/cisco_validator.py', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_validator.py', 'neutron_vpnaas/db/vpn/vpn_validator.py', 'neutron_vpnaas/services/vpn/service_drivers/ipsec_validator.py', 'requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/service_drivers/cisco_csr_db.py']",8,661b5c83e2bcfb7ee599ab88138dc9cacc294246,bp/neutron-lib,from neutron_lib import exceptions,from neutron.common import exceptions,8,7
openstack%2Fhorizon~master~I220d2f8a87e9a55b95884251b3368abe1167cafa,openstack/horizon,master,I220d2f8a87e9a55b95884251b3368abe1167cafa,Hamburger navigation now sits above containers,MERGED,2016-03-03 20:42:55.000000000,2016-03-04 22:10:25.000000000,2016-03-04 22:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 11778}, {'_account_id': 12281}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-03-03 20:42:55.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/components/_resource_browser.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7c56d99fc1d010b592808a3c68410aff5dd204f4', 'message': 'Hamburger navigation now sits above containers\n\nIn the material theme, if the screen is too narrow, the navigation pane\nbecomes a collapsable ""hamburger-menu"" style button.  Currently, on the\ncontainers page, when that button is pressed the navigation pane is\nbelow the containers list.  This makes navigation impossible.\n\nSee screenshot here: http://i.imgur.com/uzdX66E.png\n\nAdjusting the z-index of the container down from 10 to 2 aleviates this\nissue.  Obviously the containers page is being reworked elsewhere; so\nkeeping this change as small as possible is appropriate.\n\nChange-Id: I220d2f8a87e9a55b95884251b3368abe1167cafa\nCloses-Bug: 1552898\nPartially-implements: blueprint horizon-theme-css-reorg\n'}]",0,288117,7c56d99fc1d010b592808a3c68410aff5dd204f4,10,6,1,9659,,,0,"Hamburger navigation now sits above containers

In the material theme, if the screen is too narrow, the navigation pane
becomes a collapsable ""hamburger-menu"" style button.  Currently, on the
containers page, when that button is pressed the navigation pane is
below the containers list.  This makes navigation impossible.

See screenshot here: http://i.imgur.com/uzdX66E.png

Adjusting the z-index of the container down from 10 to 2 aleviates this
issue.  Obviously the containers page is being reworked elsewhere; so
keeping this change as small as possible is appropriate.

Change-Id: I220d2f8a87e9a55b95884251b3368abe1167cafa
Closes-Bug: 1552898
Partially-implements: blueprint horizon-theme-css-reorg
",git fetch https://review.opendev.org/openstack/horizon refs/changes/17/288117/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/components/_resource_browser.scss'],1,7c56d99fc1d010b592808a3c68410aff5dd204f4,bug/1552898, z-index: 2;, z-index: 10;,1,1
openstack%2Fhorizon~master~I03796253fc6b6c56572c6e841f3ce3102c9c6cdd,openstack/horizon,master,I03796253fc6b6c56572c6e841f3ce3102c9c6cdd,Don't force people to security groups after they add a FIP,MERGED,2016-02-25 22:44:20.000000000,2016-03-04 22:08:00.000000000,2016-03-04 22:08:00.000000000,"[{'_account_id': 3}, {'_account_id': 128}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6650}, {'_account_id': 7665}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 19896}]","[{'number': 1, 'created': '2016-02-25 22:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/740b5d2469184102680709dd44db36227383dbff', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}, {'number': 2, 'created': '2016-03-02 16:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0e57637b71f5c4ec87a77da88bb2b0c6b73c6a56', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}, {'number': 3, 'created': '2016-03-02 17:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6603e4cba5d84b64dd576f7d050cf29c8e84fb6a', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}, {'number': 4, 'created': '2016-03-02 20:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2d0e05a748bcc800088f12cd045364501ff93e8e', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}, {'number': 5, 'created': '2016-03-03 17:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2ee7cb7d344c9074934ba57dfb0ef9e2c7c6ae8', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}, {'number': 6, 'created': '2016-03-04 15:48:16.000000000', 'files': ['openstack_dashboard/dashboards/project/access_and_security/floating_ips/tests.py', 'horizon/workflows/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8a4aa96d7c0b0902acd23160ecf917431d5d7005', 'message': ""Don't force people to security groups after they add a FIP\n\nHorizon should not move people from the instances page to\nthe security groups page after adding a FIP. It's already\ntoo late to prevent bad things from happening and this\nimplies that it is not too late.\n\nChange-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd\nCloses-bug: #1550023\n""}]",0,284973,8a4aa96d7c0b0902acd23160ecf917431d5d7005,42,9,6,128,,,0,"Don't force people to security groups after they add a FIP

Horizon should not move people from the instances page to
the security groups page after adding a FIP. It's already
too late to prevent bad things from happening and this
implies that it is not too late.

Change-Id: I03796253fc6b6c56572c6e841f3ce3102c9c6cdd
Closes-bug: #1550023
",git fetch https://review.opendev.org/openstack/horizon refs/changes/73/284973/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/access_and_security/floating_ips/workflows.py'],1,740b5d2469184102680709dd44db36227383dbff,bug/1550023,," success_url = ""horizon:project:access_and_security:index""",0,1
openstack%2Fneutron-vpnaas~master~I9457f7e05adb77d4b034ef01e7e51d95fc066013,openstack/neutron-vpnaas,master,I9457f7e05adb77d4b034ef01e7e51d95fc066013,Put py34 first in the env order of tox,MERGED,2016-03-03 13:48:39.000000000,2016-03-04 22:07:57.000000000,2016-03-04 22:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 9656}, {'_account_id': 9970}, {'_account_id': 14605}]","[{'number': 1, 'created': '2016-03-03 13:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/6916784d6235cf85676fe589018f3d535fff9b2b', 'message': 'Put py34 first in the env order of tox\n\nTo solve the problem of ""db type could not be determined"" on py34\nwe have to run first the py34 env to, then, run py27. This patch\nputs py34 first on the tox.ini list of envs to avoid this problem\nto happen.\n\nChange-Id: I9457f7e05adb77d4b034ef01e7e51d95fc066013\nCloses-bug: #1489059\n'}, {'number': 2, 'created': '2016-03-03 13:58:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b4b22a1f373794a7a13ec85a8386587fc541cb49', 'message': 'Put py34 first in the env order of tox\n\nTo solve the problem of ""db type could not be determined"" on py34 we\nhave to run first the py34 env, then, run py27. This patch puts py34\nfirst on the tox.ini list of envs to avoid this problem to happen.\n\nChange-Id: I9457f7e05adb77d4b034ef01e7e51d95fc066013\nCloses-bug: #1489059\n'}]",4,287802,b4b22a1f373794a7a13ec85a8386587fc541cb49,14,6,2,9656,,,0,"Put py34 first in the env order of tox

To solve the problem of ""db type could not be determined"" on py34 we
have to run first the py34 env, then, run py27. This patch puts py34
first on the tox.ini list of envs to avoid this problem to happen.

Change-Id: I9457f7e05adb77d4b034ef01e7e51d95fc066013
Closes-bug: #1489059
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/02/287802/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6916784d6235cf85676fe589018f3d535fff9b2b,286182,"envlist = {py34,py27,pep8}-constraints","envlist = {py27,py34,pep8}-constraints",1,1
openstack%2Fnova~stable%2Fliberty~Ib48990100ecc02325d323c8e933a859fa839a1a2,openstack/nova,stable/liberty,Ib48990100ecc02325d323c8e933a859fa839a1a2,Fix evacuate support with Nova cells v1,MERGED,2016-03-03 14:32:15.000000000,2016-03-04 22:07:09.000000000,2016-03-04 22:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7156}, {'_account_id': 8213}, {'_account_id': 12898}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-03-03 14:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1900abb230c6baa3758e7f3898cb693bfeb4ad3', 'message': ""Fix evacuate support with Nova cells v1\n\nCells v1 does not properly support evacuate when destination node is provided.\nIf a destination node is provided, evacuated instance will stay\nin 'REBUILDING' state forever.\n\nThe evacuate method expects host to be the actual node name,\nnot one with complete cell_path. Stripping the cell_path from the host\nfixes the problem.\n\nCloses-bug: #1552046\nChange-Id: Ib48990100ecc02325d323c8e933a859fa839a1a2\n(cherry picked from commit 022802997c10fc4ed56b1e1875cd7ccb16cc0688)\n""}, {'number': 2, 'created': '2016-03-03 19:03:39.000000000', 'files': ['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_cells.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4e1957f084e34baac7da30780abade03a32fcd45', 'message': ""Fix evacuate support with Nova cells v1\n\nCells v1 does not properly support evacuate when destination node is provided.\nIf a destination node is provided, evacuated instance will stay\nin 'REBUILDING' state forever.\n\nThe evacuate method expects host to be the actual node name,\nnot one with complete cell_path. Stripping the cell_path from the host\nfixes the problem.\n\nNOTE(mriedem): The test_compute_cells test is modified slightly to\nhard-code the instance uuid since the uuids sentinel code was not\nin liberty.\n\nCloses-bug: #1552046\nChange-Id: Ib48990100ecc02325d323c8e933a859fa839a1a2\n(cherry picked from commit 022802997c10fc4ed56b1e1875cd7ccb16cc0688)\n""}]",1,287831,4e1957f084e34baac7da30780abade03a32fcd45,16,7,2,6873,,,0,"Fix evacuate support with Nova cells v1

Cells v1 does not properly support evacuate when destination node is provided.
If a destination node is provided, evacuated instance will stay
in 'REBUILDING' state forever.

The evacuate method expects host to be the actual node name,
not one with complete cell_path. Stripping the cell_path from the host
fixes the problem.

NOTE(mriedem): The test_compute_cells test is modified slightly to
hard-code the instance uuid since the uuids sentinel code was not
in liberty.

Closes-bug: #1552046
Change-Id: Ib48990100ecc02325d323c8e933a859fa839a1a2
(cherry picked from commit 022802997c10fc4ed56b1e1875cd7ccb16cc0688)
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/287831/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_cells.py']",2,f1900abb230c6baa3758e7f3898cb693bfeb4ad3,bug/1552046," @mock.patch.object(compute_api.API, 'evacuate') def _test(mock_evacuate): instance = objects.Instance(uuid=uuids.evacuate_instance, cell_name='fake_cell_name') dest_host = 'fake_cell_name@fakenode2' self.compute_api.evacuate(self.context, instance, host=dest_host) mock_evacuate.assert_called_once_with( self.context, instance, 'fakenode2') _test()"," self.skipTest(""Test is incompatible with cells."")",15,5
openstack%2Fglance~master~Ie9353bc254d11870abc102a7b9b4c7db3917abb4,openstack/glance,master,Ie9353bc254d11870abc102a7b9b4c7db3917abb4,Return 204 rather than 403 when no image data,MERGED,2015-12-07 18:02:23.000000000,2016-03-04 22:06:58.000000000,2016-03-04 22:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 11391}, {'_account_id': 12000}, {'_account_id': 17123}]","[{'number': 1, 'created': '2015-12-07 18:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b5d63c1bbe18a5b5da8510d8e0ac186fb514d470', 'message': 'Revert ""Fix error when downloading image status is not active""\n\nThis reverts commit d4d94b290ceb9147dd285822e201dd85ce812ef0.\n\nThe above commit impacted the documented API behaviour:\n\n http://developer.openstack.org/api-ref-image-v2.html\n ""If no image data exists, the call returns the HTTP 204 status code. ""\n\nI think we should consider reverting this change since:\n\n * the server can still return 204 in some cases\n * the change still causes a stack trace in clients\n * it\'s better to fix this on the client side (without changing the API)\n * the changed behaviour hasn\'t been released or backported to liberty\n\nAPIImpact\n\nChange-Id: Ie9353bc254d11870abc102a7b9b4c7db3917abb4\n'}, {'number': 2, 'created': '2016-02-25 16:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b0dffe21b49630ad2ff52af413a4f079880c3c89', 'message': 'Return 204 rather than 403 when no image data\n\nAs per http://developer.openstack.org/api-ref-image-v2.html:\n ""If no image data exists, the call returns the HTTP 204 status code. ""\n\nThis commit changed that to 403:\n\n d4d94b290ceb9147dd285822e201dd85ce812ef0\n\nWe should revert to the juno/kilo/liberty behaviour.\n\nAPIImpact\n\nCloses-bug: 1549869\n\nChange-Id: Ie9353bc254d11870abc102a7b9b4c7db3917abb4\n'}, {'number': 3, 'created': '2016-02-26 14:50:48.000000000', 'files': ['glance/api/v2/image_data.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/functional/test_cache_middleware.py', 'glance/tests/unit/v2/test_image_data_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3077339f9fcd23ba0f7667571f885353fb03d7e1', 'message': 'Return 204 rather than 403 when no image data\n\nAs per http://developer.openstack.org/api-ref-image-v2.html:\n ""If no image data exists, the call returns the HTTP 204 status code. ""\n\nThis commit changed that to 403:\n\n d4d94b290ceb9147dd285822e201dd85ce812ef0\n\nWe should revert to the juno/kilo/liberty behaviour.\n\nAPIImpact\n\nCloses-bug: 1549869\n\nChange-Id: Ie9353bc254d11870abc102a7b9b4c7db3917abb4\n'}]",0,254334,3077339f9fcd23ba0f7667571f885353fb03d7e1,31,8,3,455,,,0,"Return 204 rather than 403 when no image data

As per http://developer.openstack.org/api-ref-image-v2.html:
 ""If no image data exists, the call returns the HTTP 204 status code. ""

This commit changed that to 403:

 d4d94b290ceb9147dd285822e201dd85ce812ef0

We should revert to the juno/kilo/liberty behaviour.

APIImpact

Closes-bug: 1549869

Change-Id: Ie9353bc254d11870abc102a7b9b4c7db3917abb4
",git fetch https://review.opendev.org/openstack/glance refs/changes/34/254334/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/image_data.py', 'glance/tests/functional/v2/test_images.py', 'glance/tests/functional/test_cache_middleware.py', 'glance/tests/unit/v2/test_image_data_resource.py']",4,b5d63c1bbe18a5b5da8510d8e0ac186fb514d470,bug/1549869, request = unit_test_utils.get_fake_request() self.image_repo.result = FakeImage('abcd') image = FakeImage('abcd')," status='active', request = unit_test_utils.get_fake_request(is_admin=False) request = unit_test_utils.get_fake_request(is_admin=True) image = FakeImage('abcd', status='deactivated', locations=[{'url': 'http://example.com/image', 'metadata': {}, 'status': 'active'}]) self.image_repo.result = image image = self.controller.download(request, unit_test_utils.UUID1) self.assertEqual('abcd', image.image_id) def test_download_is_not_active(self): state = ['queued', 'deleted', 'saving', 'killed', 'pending_delete'] for st in state: request = unit_test_utils.get_fake_request() image = FakeImage('abcd', status=st, locations=[{'url': 'http://example.com/image', 'metadata': {}, 'status': 'active'}]) self.image_repo.result = image self.assertRaises(webob.exc.HTTPForbidden, self.controller.download, request, str(uuid.uuid4())) self.image_repo.result = FakeImage('abcd', status='active') image = FakeImage('abcd', status='active')",9,33
openstack%2Fnova~stable%2Fliberty~Ie7df9a78632ff01453b07ee9fed3dffdd8b4a0c7,openstack/nova,stable/liberty,Ie7df9a78632ff01453b07ee9fed3dffdd8b4a0c7,VMware: Handle image size correctly for OVA and streamOptimized images,MERGED,2016-02-09 17:53:05.000000000,2016-03-04 22:06:11.000000000,2016-03-04 22:06:10.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 6873}, {'_account_id': 9008}]","[{'number': 1, 'created': '2016-02-09 17:53:05.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/virt/vmwareapi/test_images.py', 'nova/virt/vmwareapi/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2c6c67422e0e9dac5e4bd0b61085d3ca1b32e789', 'message': 'VMware: Handle image size correctly for OVA and streamOptimized images\n\nThe image size is different from the virtual disk size when the image is\nstreamOptimized or OVA. In this case we need to use the size of the\nvirtual disk which belongs to the temporary VM created by ImportVApp.\nThis works for both vSAN and VMFS datastores.\n\n(cherry picked from commit bfc5edc405138e3412ae1af01abbf098c319c77c)\n\nRelated-Bug: #1240373\nRelated-Bug: #1472955\nChange-Id: Ie7df9a78632ff01453b07ee9fed3dffdd8b4a0c7\n'}]",0,277990,2c6c67422e0e9dac5e4bd0b61085d3ca1b32e789,12,4,1,19173,,,0,"VMware: Handle image size correctly for OVA and streamOptimized images

The image size is different from the virtual disk size when the image is
streamOptimized or OVA. In this case we need to use the size of the
virtual disk which belongs to the temporary VM created by ImportVApp.
This works for both vSAN and VMFS datastores.

(cherry picked from commit bfc5edc405138e3412ae1af01abbf098c319c77c)

Related-Bug: #1240373
Related-Bug: #1472955
Change-Id: Ie7df9a78632ff01453b07ee9fed3dffdd8b4a0c7
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/277990/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/virt/vmwareapi/test_images.py', 'nova/virt/vmwareapi/images.py']",4,2c6c67422e0e9dac5e4bd0b61085d3ca1b32e789,bug/1240373,"from nova.virt.vmwareapi import vm_util vmdk = vm_util.get_vmdk_info(session, imported_vm_ref, vm_name) return vmdk.capacity_in_bytes vmdk = vm_util.get_vmdk_info(session, imported_vm_ref, vm_name) return vmdk.capacity_in_bytes", return,49,9
openstack%2Frequirements~master~Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b,openstack/requirements,master,Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b,Bumps os-win version to 0.2.3,MERGED,2016-03-04 12:43:39.000000000,2016-03-04 22:06:01.000000000,2016-03-04 22:06:00.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-04 12:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/674490ef3c309a7c92c60259dde1071c76971b4a', 'message': 'Bumps os-win version to 0.2.3\n\nChange-Id: Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b\n'}, {'number': 2, 'created': '2016-03-04 15:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d1d6eb56cc5eec1a441e7dfb9cb5f286ad5e624a', 'message': 'Bumps os-win version to 0.2.3\n\nVersion 0.2.3 will be needed in order to properly use os-win in\nnetworking-hyperv.\nChanges:\n\nutilsfactory.get_networkutils can now return NetworkUtilsR2, needed for\nWindows / Hyper-V Server 2012 R2 or newer.\nRenamed metrics ACLs related methods in networkutils to better\nreflect their functionality.\nget_vm_power_state_change_listener now returns a function that listens\nfor VM power state changes rather than a WMI event listener. This way,\na WMI object will not have to be used outside os-win.\n\nChange-Id: Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b\n'}, {'number': 3, 'created': '2016-03-04 15:36:03.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f0f6f5c27450e1cb0ed9729f7159c893046cb8e3', 'message': 'Bumps os-win version to 0.2.3\n\nVersion 0.2.3 will be needed in order to properly use os-win in\nnetworking-hyperv.\nChanges:\n\nutilsfactory.get_networkutils can now return NetworkUtilsR2, needed for\nWindows / Hyper-V Server 2012 R2 or newer. This is need by the\nneutron-hyperv-agent in order to properly bind security group rules to\nports.\nRenamed metrics ACLs related methods in networkutils to better\nreflect their functionality.\nget_vm_power_state_change_listener now returns a function that listens\nfor VM power state changes rather than a WMI event listener. This way,\na WMI object will not have to be used outside os-win.\n\nChange-Id: Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b\n'}]",0,288429,f0f6f5c27450e1cb0ed9729f7159c893046cb8e3,10,3,3,8213,,,0,"Bumps os-win version to 0.2.3

Version 0.2.3 will be needed in order to properly use os-win in
networking-hyperv.
Changes:

utilsfactory.get_networkutils can now return NetworkUtilsR2, needed for
Windows / Hyper-V Server 2012 R2 or newer. This is need by the
neutron-hyperv-agent in order to properly bind security group rules to
ports.
Renamed metrics ACLs related methods in networkutils to better
reflect their functionality.
get_vm_power_state_change_listener now returns a function that listens
for VM power state changes rather than a WMI event listener. This way,
a WMI object will not have to be used outside os-win.

Change-Id: Iea2ca458d8b7d00535bb1e6cfc94da0b8de9554b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/29/288429/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,674490ef3c309a7c92c60259dde1071c76971b4a,,os-win===0.2.3,os-win===0.2.2,2,2
openstack%2Fnova-powervm~stable%2Fliberty~I8065aeea33d95189bcc2df74dd882cb98605ba5c,openstack/nova-powervm,stable/liberty,I8065aeea33d95189bcc2df74dd882cb98605ba5c,Rebase on LogicalUnit.name @property setter,ABANDONED,2016-02-26 16:08:05.000000000,2016-03-04 21:53:41.000000000,,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13562}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}]","[{'number': 1, 'created': '2016-02-26 16:08:05.000000000', 'files': ['nova_powervm/tests/virt/powervm/disk/test_ssp.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/67d1c161a5b2b9a8290d7a107499c64deb3434e0', 'message': 'Rebase on LogicalUnit.name @property setter\n\nRecent pypowervm commit 5f4e66ff1a7c6b335b881dcf8daac7414abc1f3a exposed\nthe private _name method of LogicalUnit as a public @property setter.\nRebase on the change.\n\nChange-Id: I8065aeea33d95189bcc2df74dd882cb98605ba5c\n(cherry picked from commit cf3daa9145f01d095af3d0d192c0fcde34d44776)\n'}]",0,285396,67d1c161a5b2b9a8290d7a107499c64deb3434e0,10,7,1,14070,,,0,"Rebase on LogicalUnit.name @property setter

Recent pypowervm commit 5f4e66ff1a7c6b335b881dcf8daac7414abc1f3a exposed
the private _name method of LogicalUnit as a public @property setter.
Rebase on the change.

Change-Id: I8065aeea33d95189bcc2df74dd882cb98605ba5c
(cherry picked from commit cf3daa9145f01d095af3d0d192c0fcde34d44776)
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/96/285396/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/tests/virt/powervm/disk/test_ssp.py'],1,67d1c161a5b2b9a8290d7a107499c64deb3434e0,rebase_lu_name, vios1.scsi_mappings[3].backing_storage.name = 'boot_my_instance_name', vios1.scsi_mappings[3].backing_storage._name('boot_my_instance_name'),1,1
openstack%2Fhorizon~master~I1fda0b626576ec2b07af1a34f9e8e002426f033c,openstack/horizon,master,I1fda0b626576ec2b07af1a34f9e8e002426f033c,Required icon for forms is not styled correctly,ABANDONED,2016-02-26 19:41:58.000000000,2016-03-04 21:53:05.000000000,,"[{'_account_id': 3}, {'_account_id': 11778}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 17172}, {'_account_id': 17645}, {'_account_id': 18675}]","[{'number': 1, 'created': '2016-02-26 19:41:58.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/components/_forms.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9a9139a4acfed9e6d184bb68f7636a9c1acf057d', 'message': 'Required icon for forms is not styled correctly\n\nIt was recently fixed for workflows, but forgot about it for forms.\nAdd hz-icon-required class to _forms.scss to capture all cases.\n\nRequired icon is used for input fields as well as workflow nav tabs.\n\nTo test:\nCheck Users Setting form\nCheck Cinder Manage Volume form\nCheck Create Instance workflow form\n\nChange-Id: I1fda0b626576ec2b07af1a34f9e8e002426f033c\nCloses-Bug: #1550469\n'}]",0,285515,9a9139a4acfed9e6d184bb68f7636a9c1acf057d,10,7,1,9622,,,0,"Required icon for forms is not styled correctly

It was recently fixed for workflows, but forgot about it for forms.
Add hz-icon-required class to _forms.scss to capture all cases.

Required icon is used for input fields as well as workflow nav tabs.

To test:
Check Users Setting form
Check Cinder Manage Volume form
Check Create Instance workflow form

Change-Id: I1fda0b626576ec2b07af1a34f9e8e002426f033c
Closes-Bug: #1550469
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/285515/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/components/_forms.scss'],1,9a9139a4acfed9e6d184bb68f7636a9c1acf057d,bug/1550469,".form-group { /**** Prevent long image names from breaking form layout in Firefox ****/ input[type=""file""] { width: 100%; white-space: normal; } .hz-icon-required { font-size: 50%; vertical-align: top; color: $brand-primary; }","/**** Prevent long image names from breaking form layout in Firefox ****/ .form-group input[type=""file""] { width: 100%; white-space: normal;",12,4
openstack%2Fkolla~master~Ie7968f5b58b0a2add28299571d0c4c18d686b499,openstack/kolla,master,Ie7968f5b58b0a2add28299571d0c4c18d686b499,Remove external deps for rabbitmq,ABANDONED,2015-11-20 14:27:05.000000000,2016-03-04 21:43:41.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 14119}, {'_account_id': 16620}]","[{'number': 1, 'created': '2015-11-20 14:27:05.000000000', 'files': ['docker/rabbitmq/rabbitmq-server-3.5.5-3.noarch.rpm', 'docker/rabbitmq/rabbitmq_clusterer-3.5.x-189b3a81.ez', 'docker/rabbitmq/Dockerfile.j2', 'docker/rabbitmq/rabbitmq-server_3.5.5-3_all.deb', 'ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4bb981370dd85bb30d582834a7861b3d82442b73', 'message': 'Remove external deps for rabbitmq\n\nAdditionally change the pinning method for rabbitmq to match Centos\nfor consistency. This changes rabbitmq to 3.5.5 as well for Ubuntu,\nagain to match in consistency across distros.\n\nPotential-Backport: Liberty\nChange-Id: Ie7968f5b58b0a2add28299571d0c4c18d686b499\nParitially-Implements: blueprint remove-external-deps\n'}]",1,248109,4bb981370dd85bb30d582834a7861b3d82442b73,11,6,1,14119,,,0,"Remove external deps for rabbitmq

Additionally change the pinning method for rabbitmq to match Centos
for consistency. This changes rabbitmq to 3.5.5 as well for Ubuntu,
again to match in consistency across distros.

Potential-Backport: Liberty
Change-Id: Ie7968f5b58b0a2add28299571d0c4c18d686b499
Paritially-Implements: blueprint remove-external-deps
",git fetch https://review.opendev.org/openstack/kolla refs/changes/09/248109/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/rabbitmq/rabbitmq-server-3.5.5-3.noarch.rpm', 'docker/rabbitmq/rabbitmq_clusterer-3.5.x-189b3a81.ez', 'docker/rabbitmq/Dockerfile.j2', 'docker/rabbitmq/rabbitmq-server_3.5.5-3_all.deb', 'ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2']",5,4bb981370dd85bb30d582834a7861b3d82442b73,bp/remove-external-deps,"RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=""-pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.5.5/plugins/rabbitmq_clusterer-3.5.x-189b3a81.ez/rabbitmq_clusterer-3.5.x-189b3a81/ebin""","RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=""-pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.5.5/plugins/rabbitmq_clusterer-3.5.x-189b3a81.ez/rabbitmq_clusterer-3.5.x-189b3a81/ebin""{% else %} RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=""-pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.5.4/plugins/rabbitmq_clusterer-3.5.x-189b3a81.ez/rabbitmq_clusterer-3.5.x-189b3a81/ebin""",11,10
openstack%2Fkolla~stable%2Fliberty~I400d1b83b0581030d6dee51193e235f3b7e90a90,openstack/kolla,stable/liberty,I400d1b83b0581030d6dee51193e235f3b7e90a90,Bump liberty kolla-ansible continer ansible,ABANDONED,2016-02-04 16:20:58.000000000,2016-03-04 21:43:28.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10787}]","[{'number': 1, 'created': '2016-02-04 16:20:58.000000000', 'files': ['docker/kolla-ansible/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e9baa119bb175d1e2790c6d62fa38a6005fa83a4', 'message': 'Bump liberty kolla-ansible continer ansible\n\nAlso pin shade and os-client-config to avoid issues\n\nChange-Id: I400d1b83b0581030d6dee51193e235f3b7e90a90\nCloses-Bug: #1530962\n'}]",0,276328,e9baa119bb175d1e2790c6d62fa38a6005fa83a4,8,3,1,14119,,,0,"Bump liberty kolla-ansible continer ansible

Also pin shade and os-client-config to avoid issues

Change-Id: I400d1b83b0581030d6dee51193e235f3b7e90a90
Closes-Bug: #1530962
",git fetch https://review.opendev.org/openstack/kolla refs/changes/28/276328/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kolla-ansible/Dockerfile.j2'],1,e9baa119bb175d1e2790c6d62fa38a6005fa83a4,bug/1530962,RUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \ && python get-pip.py \ && rm get-pip.py \ && pip --no-cache-dir install --upgrade wheel \ && pip --no-cache-dir install \ MySQL-python \ os-client-config==1.13.1 \ pyudev \ shade==1.3.0 RUN git clone --depth 1 -b v2.0.0-0.7.rc2 https://github.com/ansible/ansible.git \,RUN pip --no-cache-dir install \ shade \ pyudev RUN git clone --depth 1 -b v2.0.0-0.2.alpha2 https://github.com/ansible/ansible.git \,10,4
openstack%2Fkolla~master~I465fe7414d3118150fb4ebf8c5b0dbd19ce31e7a,openstack/kolla,master,I465fe7414d3118150fb4ebf8c5b0dbd19ce31e7a,Bump versions of ansible in kolla-ansible,ABANDONED,2016-01-04 02:20:32.000000000,2016-03-04 21:42:49.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 10419}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-01-04 02:20:32.000000000', 'files': ['docker/kolla-ansible/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/47927b5ca599857761e94ac5a528385b778fa131', 'message': 'Bump versions of ansible in kolla-ansible\n\nBumping up the versions of our pinned software.\n\nTrivialFix\n\nChange-Id: I465fe7414d3118150fb4ebf8c5b0dbd19ce31e7a\n'}]",0,263086,47927b5ca599857761e94ac5a528385b778fa131,9,4,1,14119,,,0,"Bump versions of ansible in kolla-ansible

Bumping up the versions of our pinned software.

TrivialFix

Change-Id: I465fe7414d3118150fb4ebf8c5b0dbd19ce31e7a
",git fetch https://review.opendev.org/openstack/kolla refs/changes/86/263086/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kolla-ansible/Dockerfile.j2'],1,47927b5ca599857761e94ac5a528385b778fa131,bump_os_client_config,RUN git clone --depth 1 -b v2.0.0-0.8.rc3 https://github.com/ansible/ansible.git \,RUN git clone --depth 1 -b v2.0.0-0.7.rc2 https://github.com/ansible/ansible.git \,1,1
openstack%2Fpython-keystoneclient~master~Ie1a20a1e5e958a3133f0b86d1580a833e8928a43,openstack/python-keystoneclient,master,Ie1a20a1e5e958a3133f0b86d1580a833e8928a43,Now keystone enables listing of user by name,ABANDONED,2015-03-25 10:18:25.000000000,2016-03-04 21:39:03.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 8978}, {'_account_id': 13912}]","[{'number': 1, 'created': '2015-03-25 10:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ed5e27ab2e991fbadfeac419f9a51506ff2f181b', 'message': ""Now keystone enables listing of user by name\n\nAPI support listing of user by name but keystone client does\nnot. It was required by user in some scenario(as described in bug\ndescription).\n\nFor supporting this feature, user option need to be added for help\nand displaying to user. It makes me to change shell.py.\n\ndo_user_list method uses list method of user.py, which need to be\nupdated according to the keystone API. In case of list of users,\nkeystone returns a dictionary having 'users' as key and list of\nall users as the value. But in case of display by name, we get,\na dictionary having 'user' as key and user details as value.\nWhich makes it necessary to pass 'user' as reponse key.\n\nIn base.py's _list method, in our case, we get a dictionary, which\nneeds to be convert to list before proceeding further. On the\nbasis of reponse_key, this decision is being made.\n\nChange-Id: Ie1a20a1e5e958a3133f0b86d1580a833e8928a43\nCloses-Bug: #1417189\n""}, {'number': 2, 'created': '2015-03-30 04:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9ae038ad115b36a48ecde387ab7b12a5723794e1', 'message': ""Now keystone enables listing of user by name\n\nAPI support listing of user by name but keystone client does\nnot. It was required by user in some scenario(as described in bug\ndescription).\n\nFor supporting this feature, user option need to be added for help\nand displaying to user. It makes me to change shell.py.\n\ndo_user_list method uses list method of user.py, which need to be\nupdated according to the keystone API. In case of list of users,\nkeystone returns a dictionary having 'users' as key and list of\nall users as the value. But in case of display by name, we get,\na dictionary having 'user' as key and user details as value.\nWhich makes it necessary to pass 'user' as reponse key.\n\nIn base.py's _list method, in our case, we get a dictionary, which\nneeds to be convert to list before proceeding further. On the\nbasis of reponse_key, this decision is being made.\n\nChange-Id: Ie1a20a1e5e958a3133f0b86d1580a833e8928a43\nCloses-Bug: #1417189\n""}, {'number': 3, 'created': '2015-04-13 13:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/492876a4c9365d471a7502bd4ca14e5809e1785a', 'message': ""Now keystone enables listing of user by name\n\nThe API supports listing of user by name but keystone client\ndoes not. It was required by a user in some scenario(as\ndescribed in bug description).\n\nTo supporting this feature, the user option needs to be added for\nhelp and displaying to user.\n\ndo_user_list method uses list method of user.py, which needs to be\nupdated according to the keystone API. In the case of list of users,\nkeystone returns a dictionary having 'users' as key and list of\nall users as the value. But in case of display by name, we get,\na dictionary having 'user' as key and user details as value.\nWhich makes it necessary to pass 'user' as reponse key.\n\nIn base.py's _list method, in our case, we get a dictionary, which\nneeds to be converted to list before proceeding further. On the\nbasis of response_key, this decision is being made.\n\nChange-Id: Ie1a20a1e5e958a3133f0b86d1580a833e8928a43\nCloses-Bug: #1417189\n""}, {'number': 4, 'created': '2015-04-13 13:44:56.000000000', 'files': ['keystoneclient/v2_0/users.py', 'keystoneclient/base.py', 'keystoneclient/v3/users.py', 'keystoneclient/tests/unit/v2_0/test_users.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1502d7fb37626dba11e935ddfbf702d69f55d448', 'message': ""Now keystone enables listing of user by name\n\nThe API supports listing of user by name but keystone client\ndoes not. It was required by a user in some scenario(as\ndescribed in bug description).\n\nTo supporting this feature, the user option needs to be added for\nhelp and displaying to user.\n\ndo_user_list method uses list method of user.py, which needs to be\nupdated according to the keystone API. In the case of list of users,\nkeystone returns a dictionary having 'users' as key and list of\nall users as the value. But in case of display by name, we get,\na dictionary having 'user' as key and user details as value.\nWhich makes it necessary to pass 'user' as reponse key.\n\nIn base.py's _list method, in our case, we get a dictionary, which\nneeds to be converted to list before proceeding further. On the\nbasis of response_key, this decision is being made.\n\nChange-Id: Ie1a20a1e5e958a3133f0b86d1580a833e8928a43\nCloses-Bug: #1417189\n""}]",14,167543,1502d7fb37626dba11e935ddfbf702d69f55d448,28,11,4,13912,,,0,"Now keystone enables listing of user by name

The API supports listing of user by name but keystone client
does not. It was required by a user in some scenario(as
described in bug description).

To supporting this feature, the user option needs to be added for
help and displaying to user.

do_user_list method uses list method of user.py, which needs to be
updated according to the keystone API. In the case of list of users,
keystone returns a dictionary having 'users' as key and list of
all users as the value. But in case of display by name, we get,
a dictionary having 'user' as key and user details as value.
Which makes it necessary to pass 'user' as reponse key.

In base.py's _list method, in our case, we get a dictionary, which
needs to be converted to list before proceeding further. On the
basis of response_key, this decision is being made.

Change-Id: Ie1a20a1e5e958a3133f0b86d1580a833e8928a43
Closes-Bug: #1417189
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/43/167543/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v2_0/users.py', 'keystoneclient/base.py', 'keystoneclient/v2_0/shell.py']",3,ed5e27ab2e991fbadfeac419f9a51506ff2f181b,bug/1417189,"@utils.arg('--user', '--user-name', metavar='<user>', help='User; lists specified user if exist.') users = kc.users.list(tenant_id=tenant_id, user=args.user)", users = kc.users.list(tenant_id=tenant_id),12,3
openstack%2Fkeystone~master~I7301555522b7184237d6e3facef38dc83cf2198a,openstack/keystone,master,I7301555522b7184237d6e3facef38dc83cf2198a,Move endpoint catalog filtering to default driver,ABANDONED,2015-03-25 16:16:09.000000000,2016-03-04 21:37:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 9101}, {'_account_id': 9276}, {'_account_id': 9751}, {'_account_id': 13055}, {'_account_id': 13063}, {'_account_id': 14966}, {'_account_id': 17123}]","[{'number': 1, 'created': '2015-03-25 16:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3a82967d4975e9bab17a1364a198820bf3d4f148', 'message': ""Restore name to services listed in catalog\n\nAdded 'name' property to those transferred from the service found\nto the formatted service added to the catalog for filtered endpoint\nlists.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 2, 'created': '2015-03-30 12:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c84c39d8e204c38415f33e7460fbc6ae68cf74f', 'message': ""Restore name to services listed in catalog\n\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 3, 'created': '2015-03-30 14:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8882dd5a5757020f9d06069a069ffb36aea89ec0', 'message': ""Restore name to services listed in catalog\n\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 4, 'created': '2015-04-01 10:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/afd137b85f657a07c970fa5599507ad2a8ab4589', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 5, 'created': '2015-04-01 10:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f275fbc284fb242715a3f281a5b11eb1d6201187', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 6, 'created': '2015-04-07 02:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dfbc588e9685ca3a15d0efd7a2da112277a64e0a', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 7, 'created': '2015-04-07 08:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/da03c431a508ff72dda53022f7698c97e1a45c58', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 8, 'created': '2015-04-10 09:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/169686fb609e114cf9ceab7b772152b2749ca66a', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 9, 'created': '2015-04-17 16:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2548c0852c95e216b298f193bad117471581c437', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: 1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 10, 'created': '2015-04-20 15:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/72be4855f7a3ecf9bac8e8a57e6491462768e4f0', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-bug: #1436704\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 11, 'created': '2015-04-20 17:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eb0bf8e968d8c12a1e61b052d1308a452fc56ec4', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1436704\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 12, 'created': '2015-04-20 22:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83d64421e09ea9151aabb46166e921ab310d68e1', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1436704\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 13, 'created': '2015-04-21 09:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/28690f08e5ccde913459ff5e568c937b6e33091b', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1436704\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 14, 'created': '2015-04-22 10:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb9be8216d02be2d659900fe3862bcc272a02e34', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 15, 'created': '2015-04-22 14:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a408fa07b189980c108becca279c248a235372aa', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 16, 'created': '2015-04-29 09:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/09520b8c4d77fb40a9a025cf745b5eaae2d2f7aa', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 17, 'created': '2015-04-29 11:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0c758f41bbd7b3e688c6405f9fcc5de43683d9e1', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 18, 'created': '2015-04-30 16:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/90bd964213c972153cd2d5d470735acbfd12888e', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 19, 'created': '2015-05-01 10:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e41ad70cc9de767dc65e689d420fa073809fe40', 'message': ""Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\nMaintained support for CONF.endpoint_filter.return_all_endpoints_if_no_filter flag.\nAdded tests to verify both filtering function and also that 'name' is returned in each\nservice within the catalog.\nFixed other tests that now implicitly rely on endpoint_filter_api.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n""}, {'number': 20, 'created': '2015-06-22 17:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/882b9a8f9de6f1215dc64f3eac2d7615bd9e094b', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 21, 'created': '2015-07-06 16:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ea5680dd90a44cea55b22017f099c4bdf290e6aa', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 22, 'created': '2015-07-09 11:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1901d377aae3acc687a78b241f35dced05e897ae', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 23, 'created': '2015-07-22 10:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/564044b939995b89069703ca4585d13647fa1390', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 24, 'created': '2015-08-05 15:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0ecbc9342de7907a2314c4bec56071e799ddd175', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 25, 'created': '2015-08-06 10:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83a40d5196582890a8e3f548c323e1cbf0c037b6', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 26, 'created': '2015-09-07 10:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0942d4ecee30e4a063f9af64c0db5b4ccee90e0a', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 27, 'created': '2015-09-08 08:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb68d57c71b9e5ec9fb0ed921554492da370b7c7', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 28, 'created': '2015-09-21 19:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cfbfddd9ca93e5c73f9b5cd601fcada392182c61', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 29, 'created': '2015-09-21 22:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fa85b4985aef7bd57be6ed1da25062f69f3740d7', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCo-Authored-By: Guang Yee <guang.yee@hpe.com>\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}, {'number': 30, 'created': '2015-09-22 15:39:32.000000000', 'files': ['keystone/tests/unit/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ed6d53508dfda5f695df8020feac1fa686aae0fb', 'message': 'Move endpoint catalog filtering to default driver\n\nRestored name to services listed in catalog\nMoved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py\nto keystone.catalog.backends.sql.py so that filtering is both the default and supported\nby the default driver.\n\nCo-Authored-By: Guang Yee <guang.yee@hpe.com>\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\n\nCloses-Bug: #1410543\n\nChange-Id: I7301555522b7184237d6e3facef38dc83cf2198a\n'}]",142,167675,ed6d53508dfda5f695df8020feac1fa686aae0fb,150,16,30,9276,,,0,"Move endpoint catalog filtering to default driver

Restored name to services listed in catalog
Moved endpoint filtering from keystone.contrib.endpoint_filter.backends.catalog_sql.py
to keystone.catalog.backends.sql.py so that filtering is both the default and supported
by the default driver.

Co-Authored-By: Guang Yee <guang.yee@hpe.com>
Co-Authored-By: David Stanek <dstanek@dstanek.com>

Closes-Bug: #1410543

Change-Id: I7301555522b7184237d6e3facef38dc83cf2198a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/75/167675/12 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/endpoint_filter/backends/catalog_sql.py'],1,3a82967d4975e9bab17a1364a198820bf3d4f148,bug_1436704, formatted_service['name'] = service['name'],,1,0
openstack%2Fheat~master~I5645bca10f70b8ffb179bbd1690ba841b377735f,openstack/heat,master,I5645bca10f70b8ffb179bbd1690ba841b377735f,Check that network is not 'None' before fetching resource,ABANDONED,2016-01-13 22:55:56.000000000,2016-03-04 21:17:07.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7128}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 8833}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-01-13 22:55:56.000000000', 'files': ['heat/engine/resources/openstack/neutron/port.py', 'heat/tests/openstack/neutron/test_neutron_port.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a0e330e1cea1645ab2a7e8575dd208a9e26e96f9', 'message': ""Check that network is not 'None' before fetching resource\n\nChange-Id: I5645bca10f70b8ffb179bbd1690ba841b377735f\nCloses-Bug: 1533356\n""}]",11,267216,a0e330e1cea1645ab2a7e8575dd208a9e26e96f9,24,8,1,7253,,,0,"Check that network is not 'None' before fetching resource

Change-Id: I5645bca10f70b8ffb179bbd1690ba841b377735f
Closes-Bug: 1533356
",git fetch https://review.opendev.org/openstack/heat refs/changes/16/267216/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/neutron/port.py', 'heat/tests/openstack/neutron/test_neutron_port.py']",2,a0e330e1cea1645ab2a7e8575dd208a9e26e96f9,bug/1533356," def test_port_needs_update_none(self): props = {'network_id': u'net1234', 'name': utils.PhysName('test_stack', 'port'), 'admin_state_up': True, 'device_owner': u'network:dhcp'} create_props = props.copy() neutronclient.Client.create_port( {'port': create_props} ).AndReturn({'port': { ""status"": ""BUILD"", ""id"": ""fc68ea2c-b60b-4b4f-bd82-94ec81110766"" }}) neutronclient.Client.show_port( 'fc68ea2c-b60b-4b4f-bd82-94ec81110766' ).AndReturn({'port': { ""status"": ""ACTIVE"", ""id"": ""fc68ea2c-b60b-4b4f-bd82-94ec81110766"", ""fixed_ips"": { ""subnet_id"": ""d0e971a6-a6b4-4f4c-8c88-b75e9c120b7e"", ""ip_address"": ""10.0.0.2"" } }}) neutronV20.find_resourceid_by_name_or_id( mox.IsA(neutronclient.Client), 'network', 'net1234', cmd_resource=None, ).MultipleTimes().AndReturn('net1234') neutronV20.find_resourceid_by_name_or_id( mox.IsA(neutronclient.Client), 'network', 'old_network', cmd_resource=None, ).AndReturn('net1234') neutronV20.find_resourceid_by_name_or_id( mox.IsA(neutronclient.Client), 'network', 'net1234', cmd_resource=None, ).MultipleTimes().AndReturn('net1234') neutronV20.find_resourceid_by_name_or_id( mox.IsA(neutronclient.Client), 'network', 'new_network', cmd_resource=None, ).AndReturn('net5678') self.m.ReplayAll() # create port t = template_format.parse(neutron_port_template) t['resources']['port']['properties'].pop('fixed_ips') stack = utils.parse_stack(t) port = stack['port'] scheduler.TaskRunner(port.create)() # Switch from network_id=ID to network=ID (no replace) new_props = props.copy() new_props['network'] = 'None' # To reproduce bug 1533356 new_props['network_id'] = None update_snippet = rsrc_defn.ResourceDefinition(port.name, port.type(), new_props) self.assertTrue(port._needs_update(update_snippet, port.frozen_definition(), new_props, port.properties, None)) # Switch from network=ID to network=NAME (no replace) new_props['network'] = 'old_network' update_snippet = rsrc_defn.ResourceDefinition(port.name, port.type(), new_props) self.assertTrue(port._needs_update(update_snippet, port.frozen_definition(), new_props, port.properties, None)) # Switch to a different network (replace) new_props['network'] = 'new_network' update_snippet = rsrc_defn.ResourceDefinition(port.name, port.type(), new_props) self.assertRaises(exception.UpdateReplace, port._needs_update, update_snippet, port.frozen_definition(), new_props, port.properties, None) self.m.VerifyAll() ",,94,6
openstack%2Fglance-specs~master~I2c3f659c400ecf0c8e354ff5f80100724e7879a8,openstack/glance-specs,master,I2c3f659c400ecf0c8e354ff5f80100724e7879a8,Image Import Refactor Update,MERGED,2016-02-09 21:04:44.000000000,2016-03-04 21:06:35.000000000,2016-02-24 15:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2472}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 12000}]","[{'number': 1, 'created': '2016-02-09 21:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/2ba80d3fc021c57f21029c124fe9e5de385042d2', 'message': 'Image Import Refactor Update\n\nRecent discussions in #openstack-glance and at the virtual midcycle\nmeeting indicate that some key agreements are not sufficiently clear\nin the current text.  This patch adds a section titled ""Summary\nof the Constraints Around This Project"" to clarify these key points.\n\nChange-Id: I2c3f659c400ecf0c8e354ff5f80100724e7879a8\n'}, {'number': 2, 'created': '2016-02-18 14:01:05.000000000', 'files': ['specs/mitaka/approved/image-import/image-import-refactor.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/396ce3b5e5ec0e0478bff9501b36a385a24a57b5', 'message': 'Image Import Refactor Update\n\nRecent discussions in #openstack-glance and at the virtual midcycle\nmeeting indicate that some key agreements are not sufficiently clear\nin the current text.  This patch adds a section titled ""Summary\nof the Constraints Around This Project"" to clarify these key points.\n\nMitakaPriority\nChange-Id: I2c3f659c400ecf0c8e354ff5f80100724e7879a8\n'}]",24,278086,396ce3b5e5ec0e0478bff9501b36a385a24a57b5,18,7,2,5314,,,0,"Image Import Refactor Update

Recent discussions in #openstack-glance and at the virtual midcycle
meeting indicate that some key agreements are not sufficiently clear
in the current text.  This patch adds a section titled ""Summary
of the Constraints Around This Project"" to clarify these key points.

MitakaPriority
Change-Id: I2c3f659c400ecf0c8e354ff5f80100724e7879a8
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/86/278086/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/approved/image-import/image-import-refactor.rst'],1,2ba80d3fc021c57f21029c124fe9e5de385042d2,import-refactor-update,"Summary of the Constraints Around This Project ============================================== Here are, to the best of my recollection, what was agreed upon between the Glance community, DefCore (mostly Doug Hellman), infra (mostly Monty), and various interested parties who showed up at the design session on image import at the Tokyo summit. First, background, so you can see what problems needed to be addressed: #. (At least some) Public cloud operators do not want to expose the current glance v1/v2 image upload as it is too fragile. #. The TC has mandated that OpenStack clouds MUST support what's known in the industry as ""image import"". [NEW1_, NEW2_] #. Just have to support import of a vanilla linux image; no mandate about image format, size, etc. #. The ""Tasks"" API is a disaster from the interoperability and discoverability standpoint. (We know this because at least one large public cloud has exposed image import via Glance Tasks, and the openstack infra team has a lot to say about how bad it is. Just ask them.) #. interoperability failures: The Task object, as defined by ``v2/schemas/task`` contains an ""input"" and ""result"" element which are defined to be JSON blobs; anything could go in there, so possibly radically different stuff for each OpenStack cloud #. discoverability failures: You don't have to support a particular disk/container format, but there must be a way to find out what a particular cloud supports (and this ""way"" should be the same for all openstack clouds, and no, documentation doesn't count) #. There are three cases for ""image upload"" that Glance should support. #. Admin upload of ""base"" or ""public"" images #. Image upload from OpenStack services (for example, Nova or Cinder) #. End user image import (My view is that we are working on the image import use case, and what we come up with there could, but doesn't have to, be used/usable for the other two use cases. The key point to keep in mind here is that the discovery of various vulnerabilities may cause operators to halt import (temporarily), and they will want to do that while still keeping the other 2 use cases operational.) OK, without further ado, here's what was agreed upon: The constraints that an adequate image import solution must meet ---------------------------------------------------------------- #. There must be a well-defined image import structure/framework that should be supportable by all OpenStack clouds. #. ""well-defined"" #. calls have request/response schemas that are discoverable #. the values that will enable a client to have a successful image import (e.g., supported formats) must be discoverable #. ""discoverable"" == via API call #. specific API request #. available in headers #. ""supportable by all OpenStack clouds"" #. it's acceptable for there to be multiple import methods (as long as each is well defined) #. no cloud has to support all import methods, but it's expected that to achieve certification as ""OpenStack Powered Compute"" (and hence, to even have a shot at certification as an ""OpenStack Powered Platform""), a cloud must expose at least one of these. #. Since Swift is not part of the ""OpenStack Powered Compute"" program, Glance must expose at least one import method that does not rely upon the presence of an end-user-accessible object store. #. The ""three step dance"" import style was deemed acceptable #. one: create image record, two: upload data, three: import call #. steps one and two can be independent #. The import workflow should allow for server-side operator customization, but no operator is required to perform such customization. #. We're talking about customization in processing the uploaded data. The API request/response structure is not customizable. .. [NEW1] https://governance.openstack.org/resolutions/20151211-bring-your-own-kernel.html .. [NEW2] https://github.com/openstack/defcore/commit/10562c245a6332f52cb5c5d15739dfab15b2baa6",,97,0
openstack%2Fnetworking-calico~master~Ia4ea03cf0b006652ecd0a718842104a6404273f1,openstack/networking-calico,master,Ia4ea03cf0b006652ecd0a718842104a6404273f1,New DHCP agent driven by etcd data instead of by Neutron RPC,MERGED,2015-11-03 17:37:55.000000000,2016-03-04 21:04:58.000000000,2016-02-01 09:33:20.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 13734}, {'_account_id': 19461}]","[{'number': 1, 'created': '2015-11-03 17:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/c10fa8bd6bf9cdaae687e05354c8409085c90dda', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 2, 'created': '2015-11-03 18:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/56211b82ed98ca4319c0fbe58b546e93756bbf18', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 3, 'created': '2015-11-04 11:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/f79e7f9f5c3f8d53dbb20844e6064d930b675bfb', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 4, 'created': '2015-11-04 11:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/b6cfdc3a737efbec76c78658a97f0f49b5c68e11', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 5, 'created': '2015-11-04 12:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/6da4f7e04eb33bbccb32e48f35add5c1755fe26f', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 6, 'created': '2015-11-04 13:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/e5f89d65b1bedae4265a47886f0d54be18398a40', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 7, 'created': '2015-11-04 17:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/01cb609e5015eaf506243a022b2566885c4c012a', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 8, 'created': '2015-11-04 18:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/391b578500135dbc60b0553a7c609eaf410b7653', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 9, 'created': '2016-01-12 12:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/254d803cf13b3ad3045a8087d488e33e4147c21d', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 10, 'created': '2016-01-12 13:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/9db4483a17ad0024ce3aa120c4428d1241b6d3f2', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 11, 'created': '2016-01-12 14:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/8b2b165db9a3a2262e34762aa3d12e045a9a229d', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 12, 'created': '2016-01-12 16:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/f51a0a273a49d79bfc5ec1d19e275e22cb69d2a9', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 13, 'created': '2016-01-13 12:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/7bf202a7c3705ac2e9ec1d93053c3d04a305a91a', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 14, 'created': '2016-01-13 17:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/9fc97ca20afa7ac2a8ee9dd968afb29277a61cc4', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 15, 'created': '2016-01-14 18:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/6e10a0df362341d976c639e7d91831505e2fecd1', 'message': 'Etcd-driven DHCP agent for Calico\n\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n'}, {'number': 16, 'created': '2016-01-18 13:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/bb5dd12eabf0431dd71e40392ab845b002ad6c21', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 17, 'created': '2016-01-18 13:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/d1c7a64ae6b76351c37c2bd0a5bf70d4c49f004e', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 18, 'created': '2016-01-18 15:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/c77dbd52133c131d0fca0caed4154be01206225f', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 19, 'created': '2016-01-19 14:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/7e3bad00f197ed2fb0197ba2521cc454cfb5c16a', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 20, 'created': '2016-01-21 12:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/5b86a1bfc3ff905192867e0af2f90d7111015758', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 21, 'created': '2016-01-21 13:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/0af361c2d7a51d17fccdc163e1e5e52f72942a42', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 22, 'created': '2016-01-25 17:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/c707a432d45d813a788268c5a3d3375fdcefda21', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 23, 'created': '2016-01-25 17:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/a0d55fe7438439cfc32c38193ae53eb75b204e14', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 24, 'created': '2016-01-25 18:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/c0977334f87740c076a7b3c52f10a1d2001b5153', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 25, 'created': '2016-01-27 12:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/d60c925636ed35d470a9495fafaed7a42a0dc854', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}, {'number': 26, 'created': '2016-01-31 20:42:12.000000000', 'files': ['debian/changelog', 'networking_calico/plugins/ml2/drivers/calico/mech_calico.py', 'devstack/plugin.sh', 'networking_calico/agent/__init__.py', 'devstack/settings', 'doc/source/_static/neutron-dhcp-agent.png', 'networking_calico/plugins/ml2/drivers/calico/test/test_plugin_etcd.py', 'doc/source/index.rst', 'debian/calico-compute.install', 'networking_calico/tests/test_dhcp_agent.py', 'networking_calico/agent/linux/dhcp.py', 'networking_calico/plugins/ml2/drivers/calico/test/lib.py', '.testr.conf', 'rpm/networking-calico.spec', 'doc/source/_static/calico-dhcp-agent.png', 'networking_calico/agent/dhcp_agent.py', 'networking_calico/plugins/ml2/drivers/calico/t_etcd.py', 'setup.cfg', '.coveragerc', 'doc/source/dhcp-agent.rst'], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/9bd6055513c429a3f8e3f4d42f6e659584f60154', 'message': ""New DHCP agent driven by etcd data instead of by Neutron RPC\n\nA Calico network is not bridged across all the involved compute hosts,\nand therefore requires a different DHCP provision approach from the\nstandard Neutron ones, which provide DHCP for all instances on a\nNeutron Network from a single DHCP agent located on the 'network\nnode'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the\napproach we've taken is to run a DHCP agent on each compute host.\n\nIt turns out, though, that (with more than about a couple of hundred\ncompute hosts) the agent/server RPC communications place too much load\non the Neutron server(s), such that the Neutron servers become\nunresponsive to Nova when the latter is trying to bring up a new VM;\nand hence new VM creations fail.  For more details, see the referenced\nbug.\n\nIn Calico we already have another mechanism for communicating between\nthe controller and compute nodes - the distributed etcd database - and\nthis mechanism already includes almost all the information that is\nneeded for DHCP provision.  Therefore we can avoid the problem in\nscaling of the Neutron RPC mechanism by creating and using an\netcd-driven DHCP agent instead.\n\nThis commit contains the following consequent changes.\n\n- Add a Calico-specific top-level DHCP agent class and executable\n  script, like the Neutron analogs but driven by etcd data instead of\n  by Neutron RPC.  (For more detailed design see\n  doc/source/dhcp-agent.rst.)\n\n- Update the Calico DevStack plugin so that it runs the Calico DHCP\n  agent instead of the reference Neutron DHCP agent.\n\n- Revert a recently added optimization in\n  networking_calico/agent/linux/dhcp.py that limits the config that is\n  fed to Dnsmasq to be only what is needed for the local compute host\n  (as opposed to for all ports on all compute hosts).  This is now not\n  needed, as the etcd mechanism already limits the information that it\n  processes to what is relevant on the local compute host.\n\n- Enhance the Calico mechanism driver so that it writes per-subnet\n  information, that the DHCP agent needs, into etcd.  Specifically\n  this means, for each subnet:\n\n  - the subnet CIDR\n\n  - any DNS servers that are configured for the subnet.\n\n  Previously there was no subnet-scope data in Calico's etcd data\n  model.\n\n- Enhance the Calico mechanism driver so that it writes additional\n  information that the DHCP agent needs for each endpoint, namely:\n\n  - for each fixed IP, which subnet it is associated with\n\n  - the FQDN that has been configured for the endpoint, if any.\n\n- Related new and updated testing.\n\nCloses-Bug: #1519803\nChange-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1\n""}]",78,241310,9bd6055513c429a3f8e3f4d42f6e659584f60154,76,4,26,13734,,,0,"New DHCP agent driven by etcd data instead of by Neutron RPC

A Calico network is not bridged across all the involved compute hosts,
and therefore requires a different DHCP provision approach from the
standard Neutron ones, which provide DHCP for all instances on a
Neutron Network from a single DHCP agent located on the 'network
node'.  (Or from a few DHCP agents, for HA.)  For Calico thus far, the
approach we've taken is to run a DHCP agent on each compute host.

It turns out, though, that (with more than about a couple of hundred
compute hosts) the agent/server RPC communications place too much load
on the Neutron server(s), such that the Neutron servers become
unresponsive to Nova when the latter is trying to bring up a new VM;
and hence new VM creations fail.  For more details, see the referenced
bug.

In Calico we already have another mechanism for communicating between
the controller and compute nodes - the distributed etcd database - and
this mechanism already includes almost all the information that is
needed for DHCP provision.  Therefore we can avoid the problem in
scaling of the Neutron RPC mechanism by creating and using an
etcd-driven DHCP agent instead.

This commit contains the following consequent changes.

- Add a Calico-specific top-level DHCP agent class and executable
  script, like the Neutron analogs but driven by etcd data instead of
  by Neutron RPC.  (For more detailed design see
  doc/source/dhcp-agent.rst.)

- Update the Calico DevStack plugin so that it runs the Calico DHCP
  agent instead of the reference Neutron DHCP agent.

- Revert a recently added optimization in
  networking_calico/agent/linux/dhcp.py that limits the config that is
  fed to Dnsmasq to be only what is needed for the local compute host
  (as opposed to for all ports on all compute hosts).  This is now not
  needed, as the etcd mechanism already limits the information that it
  processes to what is relevant on the local compute host.

- Enhance the Calico mechanism driver so that it writes per-subnet
  information, that the DHCP agent needs, into etcd.  Specifically
  this means, for each subnet:

  - the subnet CIDR

  - any DNS servers that are configured for the subnet.

  Previously there was no subnet-scope data in Calico's etcd data
  model.

- Enhance the Calico mechanism driver so that it writes additional
  information that the DHCP agent needs for each endpoint, namely:

  - for each fixed IP, which subnet it is associated with

  - the FQDN that has been configured for the endpoint, if any.

- Related new and updated testing.

Closes-Bug: #1519803
Change-Id: Ia4ea03cf0b006652ecd0a718842104a6404273f1
",git fetch https://review.opendev.org/openstack/networking-calico refs/changes/10/241310/7 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'networking_calico/agent/dhcp_agent.py', 'setup.cfg', 'devstack/settings']",4,c10fa8bd6bf9cdaae687e05354c8409085c90dda,etcd-based-dhcp," ENABLED_SERVICES=n-cpu,neutron,calico-dhcp,n-api-meta,calico,calico-bird # Neutron server; 'calico-dhcp' means the Calico DHCP agent; and enable_service calico-dhcp"," ENABLED_SERVICES=n-cpu,neutron,q-dhcp,n-api-meta,calico,calico-bird # Neutron server; 'q-dhcp' means the Neutron DHCP agent; and enable_service q-dhcp",289,4
openstack%2Fopenstack-ansible-lxc_hosts~master~Ieb53bf6d4368ad7cbcdfec98bc2f186a595d5a73,openstack/openstack-ansible-lxc_hosts,master,Ieb53bf6d4368ad7cbcdfec98bc2f186a595d5a73,Add curl to bindep requirements,ABANDONED,2016-03-04 19:21:26.000000000,2016-03-04 21:04:34.000000000,,"[{'_account_id': 3}, {'_account_id': 538}]","[{'number': 1, 'created': '2016-03-04 19:21:26.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0bdc010c9ba77bc83949a871a4b9a0d7833dc4bd', 'message': 'Add curl to bindep requirements\n\nChange-Id: Ieb53bf6d4368ad7cbcdfec98bc2f186a595d5a73\n'}]",0,288662,0bdc010c9ba77bc83949a871a4b9a0d7833dc4bd,4,2,1,6816,,,0,"Add curl to bindep requirements

Change-Id: Ieb53bf6d4368ad7cbcdfec98bc2f186a595d5a73
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/62/288662/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,0bdc010c9ba77bc83949a871a4b9a0d7833dc4bd,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fneutron~master~I25e65b591138342637e4000f06c06c844b1b8f53,openstack/neutron,master,I25e65b591138342637e4000f06c06c844b1b8f53,Use logger.warning() in favor of warn() in Python3,ABANDONED,2016-03-04 10:35:20.000000000,2016-03-04 20:58:35.000000000,,"[{'_account_id': 1131}, {'_account_id': 10386}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-03-04 10:35:20.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/hyperv/agent/security_groups_driver.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/db/agentschedulers_db.py', 'neutron/quota/resource_registry.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/debug/debug_agent.py', 'neutron/policy.py', 'neutron/api/extensions.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/plugins/ml2/managers.py', 'neutron/agent/dhcp/agent.py', 'neutron/agent/common/ovs_lib.py', 'neutron/api/api_common.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ofswitch.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/pecan_wsgi/controllers/root.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/agent/l3/router_info.py', 'neutron/agent/rpc.py', 'neutron/db/agents_db.py', 'neutron/agent/l3/agent.py', 'neutron/agent/metadata/agent.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/services/bgp/scheduler/bgp_dragent_scheduler.py', 'neutron/pecan_wsgi/startup.py', 'neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d4f0e859c97f00f71000f74954085756e0d8f73', 'message': 'Use logger.warning() in favor of warn() in Python3\n\nPython 3 deprecated the logger.warn method, see:\nhttps://docs.python.org/3/library/logging.html#logging.warning,\nso we prefer to use warning to avoid DeprecationWarning.\n\nChange-Id: I25e65b591138342637e4000f06c06c844b1b8f53\n'}]",0,288372,7d4f0e859c97f00f71000f74954085756e0d8f73,6,5,1,14439,,,0,"Use logger.warning() in favor of warn() in Python3

Python 3 deprecated the logger.warn method, see:
https://docs.python.org/3/library/logging.html#logging.warning,
so we prefer to use warning to avoid DeprecationWarning.

Change-Id: I25e65b591138342637e4000f06c06c844b1b8f53
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/288372/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/hyperv/agent/security_groups_driver.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/db/agentschedulers_db.py', 'neutron/quota/resource_registry.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/debug/debug_agent.py', 'neutron/policy.py', 'neutron/api/extensions.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/plugins/ml2/managers.py', 'neutron/agent/dhcp/agent.py', 'neutron/agent/common/ovs_lib.py', 'neutron/api/api_common.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ofswitch.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/pecan_wsgi/controllers/root.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/agent/l3/router_info.py', 'neutron/agent/rpc.py', 'neutron/db/agents_db.py', 'neutron/agent/l3/agent.py', 'neutron/agent/metadata/agent.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/services/bgp/scheduler/bgp_dragent_scheduler.py', 'neutron/pecan_wsgi/startup.py', 'neutron/db/l3_agentschedulers_db.py']",30,7d4f0e859c97f00f71000f74954085756e0d8f73,deprecate_warn, LOG.warning(_LW(, LOG.warn(_LW(,58,58
openstack%2Fpython-cinderclient~master~If600f2163258946a2c87c45ff7a30eddd040ea2b,openstack/python-cinderclient,master,If600f2163258946a2c87c45ff7a30eddd040ea2b,Don't reset volume status when resetting migration status,ABANDONED,2016-03-04 20:53:11.000000000,2016-03-04 20:56:36.000000000,,[],"[{'number': 1, 'created': '2016-03-04 20:53:11.000000000', 'files': ['cinderclient/tests/unit/v2/test_volumes.py', 'cinderclient/tests/unit/v2/fakes.py', 'cinderclient/v2/volumes.py', 'cinderclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b2e8bef4b16522cb004819eba025a45c5e38d124', 'message': ""Don't reset volume status when resetting migration status\n\nIn case of failed volume migration, status of the volume is\nstill in-use and the migration status is set to error.\n\nCurrent reset-migration-status command resets not only\nmigration status but also volume status. However the volume\nstatus should not reset because the volume is still attached.\n\nCloses-Bug #1552058\nChange-Id: If600f2163258946a2c87c45ff7a30eddd040ea2b\n""}]",0,288729,b2e8bef4b16522cb004819eba025a45c5e38d124,2,0,1,10115,,,0,"Don't reset volume status when resetting migration status

In case of failed volume migration, status of the volume is
still in-use and the migration status is set to error.

Current reset-migration-status command resets not only
migration status but also volume status. However the volume
status should not reset because the volume is still attached.

Closes-Bug #1552058
Change-Id: If600f2163258946a2c87c45ff7a30eddd040ea2b
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/29/288729/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/unit/v2/test_volumes.py', 'cinderclient/tests/unit/v2/fakes.py', 'cinderclient/v2/volumes.py', 'cinderclient/tests/unit/v2/test_shell.py']",4,b2e8bef4b16522cb004819eba025a45c5e38d124,bug/1552058, expected = {'os-reset_status': {'migration_status': 'none'}}," expected = {'os-reset_status': {'status': 'available', 'migration_status': 'none'}}",10,4
openstack%2Fopenstack-ansible-os_heat~master~I422b56cc745864cd38aaee0fe5d58891d176aa8d,openstack/openstack-ansible-os_heat,master,I422b56cc745864cd38aaee0fe5d58891d176aa8d,Enable SSL termination for all services,MERGED,2016-03-03 17:05:30.000000000,2016-03-04 20:44:02.000000000,2016-03-04 20:44:02.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 17:05:30.000000000', 'files': ['templates/heat.conf.j2', 'tasks/heat_service_setup.yml', 'tasks/heat_domain_setup.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/5566163746a45193d856c9edd00f304a7d54ccf4', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: I422b56cc745864cd38aaee0fe5d58891d176aa8d\nRe-Implementation-Of: https://review.openstack.org/#/c/277199/9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,287983,5566163746a45193d856c9edd00f304a7d54ccf4,7,3,1,7353,,,0,"Enable SSL termination for all services

This change makes it so that all services are expecting SSL termination
at the load balancer by default. This is more indicative of how a real
world deployment will be setup and is being added such that we can test
a more production like deployment system by default.

The AIO will now terminate SSL in HAProxy using a self-signed cert.

Change-Id: I422b56cc745864cd38aaee0fe5d58891d176aa8d
Re-Implementation-Of: https://review.openstack.org/#/c/277199/9
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/83/287983/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/heat.conf.j2', 'tasks/heat_service_setup.yml', 'tasks/heat_domain_setup.yml', 'defaults/main.yml']",4,5566163746a45193d856c9edd00f304a7d54ccf4,,# External SSL forwarding proto heat_ssl_external: true heat_secure_proxy_ssl_header: HTTP_X_FORWARDED_PROTO ,,11,2
openstack%2Fshade~master~Iae2d926a7d8b899ef842b8cb1e898a38ed17adf7,openstack/shade,master,Iae2d926a7d8b899ef842b8cb1e898a38ed17adf7,Mock glance v1 image with object not dict,MERGED,2016-03-04 14:53:10.000000000,2016-03-04 20:43:34.000000000,2016-03-04 20:43:34.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 4146}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-04 14:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/dbb1a1cf31875b9601aa38f1ef3edc5e39eb5540', 'message': 'Mock glance v1 image with object not dict\n\nglance v1 objects are not dict like. They are just regular objects.\nMaking them dictlike triggers an unreal path. This also allows us to\nremove the _shadeunittest logic line in obj_to_dict.\n\nChange-Id: Iae2d926a7d8b899ef842b8cb1e898a38ed17adf7\n'}, {'number': 2, 'created': '2016-03-04 15:08:59.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/meta.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/cf43b98e335e5bbb409e6209dada5e3c86bb8ceb', 'message': 'Mock glance v1 image with object not dict\n\nglance v1 objects are not dict like. They are just regular objects.\nMaking them dictlike triggers an unreal path. This also allows us to\nremove the _shadeunittest logic line in obj_to_dict.\n\nChange-Id: Iae2d926a7d8b899ef842b8cb1e898a38ed17adf7\n'}]",0,288503,cf43b98e335e5bbb409e6209dada5e3c86bb8ceb,13,4,2,2,,,0,"Mock glance v1 image with object not dict

glance v1 objects are not dict like. They are just regular objects.
Making them dictlike triggers an unreal path. This also allows us to
remove the _shadeunittest logic line in obj_to_dict.

Change-Id: Iae2d926a7d8b899ef842b8cb1e898a38ed17adf7
",git fetch https://review.opendev.org/openstack/shade refs/changes/03/288503/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_caching.py', 'shade/meta.py']",2,dbb1a1cf31875b9601aa38f1ef3edc5e39eb5540,fix_things,," elif hasattr(obj, '_shadeunittest'): # Hook for unittesting instance = munch.Munch()",13,14
openstack%2Fopenstack-ansible-os_swift~master~I406ff5225a3a6720d24fa3f01ba93976ec24e75c,openstack/openstack-ansible-os_swift,master,I406ff5225a3a6720d24fa3f01ba93976ec24e75c,Add curl to bindep requirements,MERGED,2016-03-04 19:23:34.000000000,2016-03-04 20:43:13.000000000,2016-03-04 20:43:13.000000000,"[{'_account_id': 3}, {'_account_id': 12807}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-04 19:23:34.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/27cf4973c1f93584651c06829cf5a2f16a0dd7f7', 'message': 'Add curl to bindep requirements\n\nChange-Id: I406ff5225a3a6720d24fa3f01ba93976ec24e75c\n'}]",0,288679,27cf4973c1f93584651c06829cf5a2f16a0dd7f7,7,3,1,6816,,,0,"Add curl to bindep requirements

Change-Id: I406ff5225a3a6720d24fa3f01ba93976ec24e75c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/79/288679/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,27cf4973c1f93584651c06829cf5a2f16a0dd7f7,bindep-requirements, # OpenStack-CI's Jenkins needs curl # TODO(odyssey4me) remove this once https://review.openstack.org/288634 has merged # and the disk images are rebuilt and redeployed. curl,,5,0
openstack%2Fopenstack-ansible-os_aodh~master~Ib6d81582352c0f03f1991b26eade4629dbb738b8,openstack/openstack-ansible-os_aodh,master,Ib6d81582352c0f03f1991b26eade4629dbb738b8,Enable SSL termination for all services,MERGED,2016-03-03 17:10:12.000000000,2016-03-04 20:41:39.000000000,2016-03-04 20:41:39.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 17:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/64959ca43ade157561929e7b73443acddb022cf3', 'message': '[WIP] Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nRe-Implementation-Of: https://review.openstack.org/#/c/277199/9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-03-03 17:11:31.000000000', 'files': ['tasks/aodh_service_add.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/6876a6c8e5932c133c6108b015a09c78d9b5b945', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: Ib6d81582352c0f03f1991b26eade4629dbb738b8\nRe-Implementation-Of: https://review.openstack.org/#/c/277199/9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,287990,6876a6c8e5932c133c6108b015a09c78d9b5b945,9,4,2,7353,,,0,"Enable SSL termination for all services

This change makes it so that all services are expecting SSL termination
at the load balancer by default. This is more indicative of how a real
world deployment will be setup and is being added such that we can test
a more production like deployment system by default.

The AIO will now terminate SSL in HAProxy using a self-signed cert.

Change-Id: Ib6d81582352c0f03f1991b26eade4629dbb738b8
Re-Implementation-Of: https://review.openstack.org/#/c/277199/9
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/90/287990/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/aodh_service_add.yml'],1,64959ca43ade157561929e7b73443acddb022cf3,," insecure: ""{{ keystone_service_adminuri_insecure }}"" insecure: ""{{ keystone_service_adminuri_insecure }}"" insecure: ""{{ keystone_service_adminuri_insecure }}"" insecure: ""{{ keystone_service_adminuri_insecure }}""",,4,0
openstack%2Freleases~master~I186008bff7c72d8e5bf574db8c1f17cb806c6268,openstack/releases,master,I186008bff7c72d8e5bf574db8c1f17cb806c6268,oslo.cache 1.5.0 for Mitaka,MERGED,2016-03-04 19:37:33.000000000,2016-03-04 20:40:00.000000000,2016-03-04 20:40:00.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-04 19:37:33.000000000', 'files': ['deliverables/mitaka/oslo.cache.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f2e9842cfdaa45f384c1513f3d3e4a47ef9a5729', 'message': 'oslo.cache 1.5.0 for Mitaka\n\nWe bumped dogpile.cache in global requirements in:\nefc1a96518b3c3e2fdd995ea5138b9cc03443ae7\n\noslo.cache is the only library that directly references\nthe dogpile version and other projects rely on the correct\nminumum value of dogpile to work properly.\n\nChange-Id: I186008bff7c72d8e5bf574db8c1f17cb806c6268\n'}]",0,288702,f2e9842cfdaa45f384c1513f3d3e4a47ef9a5729,8,3,1,5638,,,0,"oslo.cache 1.5.0 for Mitaka

We bumped dogpile.cache in global requirements in:
efc1a96518b3c3e2fdd995ea5138b9cc03443ae7

oslo.cache is the only library that directly references
the dogpile version and other projects rely on the correct
minumum value of dogpile to work properly.

Change-Id: I186008bff7c72d8e5bf574db8c1f17cb806c6268
",git fetch https://review.opendev.org/openstack/releases refs/changes/02/288702/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/oslo.cache.yaml'],1,f2e9842cfdaa45f384c1513f3d3e4a47ef9a5729,, - version: 1.5.0 projects: - repo: openstack/oslo.cache hash: efc1a96518b3c3e2fdd995ea5138b9cc03443ae7,,4,0
openstack%2Fsolum~master~I86c19bd5b1c9c7b482cd1eaa8b4ea31b27f40303,openstack/solum,master,I86c19bd5b1c9c7b482cd1eaa8b4ea31b27f40303,Added devstack-provenance file,MERGED,2016-03-03 21:29:02.000000000,2016-03-04 20:38:30.000000000,2016-03-04 20:38:29.000000000,"[{'_account_id': 3}, {'_account_id': 6662}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-03-03 21:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/abc33dcc985cf3c0e63be12d05d1c9ed4beda620', 'message': 'Added devstack-provenance file\n\nAdded devstack-provenance file that contains\nhashes and versions of all the services and\npackages in devstack that led to successful\napp deployment.\n\nIf your devstack environment is not deploying\napplications correctly then you can use this\nfile to find the versions of services and packages\nthat have worked before. You can then pin different\nservices and packages to versions identified here\nto get a working devstack environment.\n\nUpdate this file only when after a successful\napp deployment in devstack\n\nChange-Id: I86c19bd5b1c9c7b482cd1eaa8b4ea31b27f40303\n'}, {'number': 2, 'created': '2016-03-03 21:29:57.000000000', 'files': ['devstack/devstack-provenance'], 'web_link': 'https://opendev.org/openstack/solum/commit/bbf50a9a4bb88ec57b3a3a23e47de2617bba8175', 'message': 'Added devstack-provenance file\n\nAdded devstack-provenance file that contains\nhashes and versions of all the services and\npackages in devstack that led to successful\napp deployment.\n\nIf your devstack environment is not deploying\napplications correctly then you can use this\nfile to find the versions of services and packages\nthat have worked before. You can then pin different\nservices and packages to versions identified here\nto get a working devstack environment.\n\nUpdate this file only after a successful\napp deployment in devstack\n\nChange-Id: I86c19bd5b1c9c7b482cd1eaa8b4ea31b27f40303\n'}]",0,288136,bbf50a9a4bb88ec57b3a3a23e47de2617bba8175,8,3,2,2506,,,0,"Added devstack-provenance file

Added devstack-provenance file that contains
hashes and versions of all the services and
packages in devstack that led to successful
app deployment.

If your devstack environment is not deploying
applications correctly then you can use this
file to find the versions of services and packages
that have worked before. You can then pin different
services and packages to versions identified here
to get a working devstack environment.

Update this file only after a successful
app deployment in devstack

Change-Id: I86c19bd5b1c9c7b482cd1eaa8b4ea31b27f40303
",git fetch https://review.opendev.org/openstack/solum refs/changes/36/288136/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstack-provenance'],1,abc33dcc985cf3c0e63be12d05d1c9ed4beda620,devstack-provenance,"os|distro=trusty os|vendor=Ubuntu os|release=14.04 git|barbican|master[7ed6940] git|cinder|master[5be8ba1] git|dib-utils|master[ec92ab4] git|glance|master[971fd94] git|heat|master[b24215a] git|heat-cfntools|master[43c79ad] git|heat-templates|master[e53f5d3] git|horizon|master[347023f] git|keystone|master[faf713e] git|neutron|master[775893b] git|noVNC|master[b403cb9] git|nova|master[b863d24] git|nova-docker|master[7e55fd5] git|os-apply-config|master[2e4362d] git|os-collect-config|master[54a60dd] git|os-refresh-config|master[651426d] git|python-barbicanclient|master[3aecbde] git|python-solumclient|master[bde4a81] git|requirements|master[d40a929] git|solum|lp-url-format-validation[bdc0fae] git|solum-gui|master[4a0107d] git|solum_parent|lp-url-format-validation[bdc0fae] git|swift|master[6192844] git|tempest|master[c276478] pkg|libkrb5-dev|1.12+dfsg-2ubuntu5.2 pkg|libldap2-dev|2.4.31-1+nmu2ubuntu8.2 pkg|libsasl2-dev|2.1.25.dfsg1-17build1 pkg|memcached|1.4.14-0ubuntu9 pkg|python-mysqldb|1.2.3-2ubuntu1 pkg|sqlite3|3.8.2-1ubuntu2.1 pkg|fping|3.8-1 pkg|conntrack|1:1.4.1-1ubuntu1 pkg|curl|7.35.0-1ubuntu2.6 pkg|dnsmasq-base|2.68-1ubuntu0.1 pkg|dnsmasq-utils|2.68-1ubuntu0.1 pkg|ebtables|2.0.10.4-3ubuntu1 pkg|gawk|1:4.0.1+dfsg-2.1ubuntu2 pkg|genisoimage|9:1.1.11-2ubuntu3 pkg|iptables|1.4.21-1ubuntu1 pkg|iputils-arping|3:20121221-4ubuntu1.1 pkg|kpartx|0.4.9-3ubuntu7.9 pkg|libjs-jquery-tablesorter|8-2 pkg|libmysqlclient-dev|5.5.47-0ubuntu0.14.04.1 pkg|parted|2.3-19ubuntu1.14.04.1 pkg|pm-utils|1.4.1-13ubuntu0.2 pkg|python-mysqldb|1.2.3-2ubuntu1 pkg|socat|1.7.2.3-1 pkg|sqlite3|3.8.2-1ubuntu2.1 pkg|sudo|1.8.9p5-1ubuntu1.2 pkg|vlan|1.9-3ubuntu10 pkg|cryptsetup|2:1.6.1-1ubuntu1 pkg|genisoimage|9:1.1.11-2ubuntu3 pkg|gir1.2-libosinfo-1.0|0.2.9-1 pkg|open-iscsi|2.0.873-3ubuntu9 pkg|qemu-utils|2.0.0+dfsg-2ubuntu1.22 pkg|sg3-utils|1.36-1ubuntu1 pkg|sysfsutils|2.1.0+repack-3ubuntu1 pkg|lvm2|2.02.98-6ubuntu2 pkg|open-iscsi|2.0.873-3ubuntu9 pkg|qemu-utils|2.0.0+dfsg-2ubuntu1.22 pkg|libpcre3-dev|1:8.31-2ubuntu2.1 pkg|dstat|0.7.2-3build1 pkg|acl|2.2.52-1 pkg|dnsmasq-base|2.68-1ubuntu0.1 pkg|ebtables|2.0.10.4-3ubuntu1 pkg|iptables|1.4.21-1ubuntu1 pkg|iputils-arping|3:20121221-4ubuntu1.1 pkg|iputils-ping|3:20121221-4ubuntu1.1 pkg|libmysqlclient-dev|5.5.47-0ubuntu0.14.04.1 pkg|postgresql-server-dev-all|154ubuntu1 pkg|python-mysqldb|1.2.3-2ubuntu1 pkg|sqlite3|3.8.2-1ubuntu2.1 pkg|sudo|1.8.9p5-1ubuntu1.2 pkg|uuid-runtime|2.20.1-5.1ubuntu20.7 pkg|vlan|1.9-3ubuntu10 pkg|ipset|6.20.1-1 pkg|conntrack|1:1.4.1-1ubuntu1 pkg|conntrackd|1:1.4.1-1ubuntu1 pkg|keepalived|1:1.2.7-1ubuntu1 pkg|curl|7.35.0-1ubuntu2.6 pkg|liberasurecode-dev|1.1.0-2~ubuntu14.04.1 pkg|make|3.81-8.2ubuntu3 pkg|memcached|1.4.14-0ubuntu9 pkg|sqlite3|3.8.2-1ubuntu2.1 pkg|xfsprogs|3.1.9ubuntu2 pkg|gettext|0.18.3.1-1ubuntu3 pip|alembic|0.8.4 pip|amqp|1.4.9 pip|anyjson|0.3.3 pip|appdirs|1.4.0 pip|apt-xapian-index|0.45 pip|astroid|1.3.8 pip|automaton|1.2.0 pip|Babel|2.2.0 pip|backports.ssl-match-hostname|3.5.0.1 pip|bandit|0.17.3 pip|bashate|0.4.0 pip|beautifulsoup4|4.4.1 pip|boto|2.39.0 pip|cachetools|1.1.5 pip|castellan|0.3.1 pip|cffi|1.5.2 pip|chardet|2.0.1 pip|Cheetah|2.4.4 pip|https://git.openstack.org/openstack/cinder.git|5be8ba1586440d274cf34111659802ed5adaf9df pip|cliff|2.0.0 pip|cloud-init|0.7.5 pip|cmd2|0.6.8 pip|colorama|0.3.6 pip|configobj|4.7.2 pip|contextlib2|0.5.1 pip|coverage|4.0.3 pip|croniter|0.3.11 pip|cryptography|1.2.2 pip|ddt|1.0.1 pip|debtcollector|1.3.0 pip|decorator|4.0.9 pip|discover|0.4.0 pip|Django|1.8.9 pip|django-appconf|1.0.1 pip|django-babel|0.4.0 pip|django-compressor|2.0 pip|django-nose|1.4.3 pip|django-openstack-auth|2.1.1 pip|django-pyscss|2.0.2 pip|dnspython|1.12.0 pip|docker-py|1.7.2 pip|docutils|0.12 pip|dogpile.cache|0.5.7 pip|dogpile.core|0.4.1 pip|ecdsa|0.13 pip|enum34|1.1.2 pip|eventlet|0.18.4 pip|extras|0.0.3 pip|fasteners|0.14.1 pip|fixtures|1.4.0 pip|flake8|2.2.4 pip|flake8-docstrings|0.2.1.post1 pip|funcsigs|0.4 pip|functools32|3.2.3.post2 pip|futures|3.0.5 pip|futurist|0.13.0 pip|gitdb|0.6.4 pip|GitPython|1.0.2 pip|https://git.openstack.org/openstack/glance.git|971fd945340224c0f0f8bcb004ac3c7b44c57ba0 pip|glance-store|0.11.0 pip|google-api-python-client|1.5.0 pip|greenlet|0.4.9 pip|hacking|0.10.2 pip|https://git.openstack.org/openstack/heat.git|b24215a492164143161893ced1920fcd7cd4a4ae pip|https://git.openstack.org/openstack/horizon.git|347023f35ac7bced70912d55fdced56bea2416f3 pip|html5lib|0.999 pip|httplib2|0.9.2 pip|idna|2.0 pip|ipaddress|1.0.16 pip|iso8601|0.1.11 pip|Jinja2|2.8 pip|jsonpatch|1.13 pip|jsonpointer|1.10 pip|jsonschema|2.5.1 pip|kazoo|2.2.1 pip|keyring|3.5 pip|https://git.openstack.org/openstack/keystone.git|faf713e18a5f86e0900af1190712f475a4777331 pip|keystoneauth1|2.3.0 pip|keystonemiddleware|4.3.0 pip|kombu|3.0.33 pip|Landscape-Client|14.12 pip|launchpadlib|1.10.2 pip|lazr.restfulclient|0.13.3 pip|lazr.uri|1.0.3 pip|linecache2|1.0.0 pip|logilab-common|1.1.0 pip|logutils|0.3.3 pip|lxml|3.5.0 pip|M2Crypto|0.21.1 pip|Mako|1.0.3 pip|MarkupSafe|0.23 pip|mccabe|0.2.1 pip|mock|1.3.0 pip|monotonic|0.6 pip|mox|0.5.3 pip|mox3|0.14.0 pip|msgpack-python|0.4.7 pip|mysql-connector-python|1.1.6 pip|MySQL-python|1.2.3 pip|netaddr|0.7.18 pip|netifaces|0.10.4 pip|networkx|1.11 pip|https://git.openstack.org/openstack/neutron.git|775893bb7f61c4641acbcb4ae16edf16e0989c39 pip|neutron-lib|0.0.2 pip|nodeenv|0.13.6 pip|nose|1.3.7 pip|nose-exclude|0.4.1 pip|nosehtmloutput|0.0.5 pip|nosexcover|1.0.10 pip|https://github.com/openstack/nova.git|b863d248f1452f33247210528bb493db7e8c8c3c pip|https://github.com/openstack/nova-docker.git|7e55fd551ef4faf3499a8db056efc9535c20e434 pip|numpy|1.10.4 pip|oauth|1.0.1 pip|oauth2client|2.0.0.post1 pip|oauthlib|1.0.3 pip|openstack.nose-plugin|0.11 pip|openstackdocstheme|1.2.7 pip|openstacksdk|0.8.0 pip|os-brick|1.1.0 pip|os-client-config|1.16.0 pip|os-testr|0.6.0 pip|os-win|0.2.2 pip|oslo.cache|1.4.0 pip|oslo.concurrency|3.6.0 pip|oslo.config|3.9.0 pip|oslo.context|2.2.0 pip|oslo.db|4.6.0 pip|oslo.i18n|3.4.0 pip|oslo.log|3.2.0 pip|oslo.messaging|4.5.0 pip|oslo.middleware|3.7.0 pip|oslo.policy|1.5.0 pip|oslo.reports|1.6.0 pip|oslo.rootwrap|4.1.0 pip|oslo.serialization|2.4.0 pip|oslo.service|1.7.0 pip|oslo.utils|3.7.0 pip|oslo.versionedobjects|1.7.0 pip|oslo.vmware|2.5.0 pip|oslosphinx|4.3.0 pip|oslotest|2.3.0 pip|osprofiler|1.2.0 pip|ovs|2.4.0 pip|PAM|0.4.2 pip|paramiko|1.16.0 pip|passlib|1.6.5 pip|Paste|2.0.2 pip|PasteDeploy|1.5.2 pip|pathlib|1.0.1 pip|pbr|1.8.1 pip|pecan|1.0.4 pip|pep257|0.7.0 pip|pep8|1.5.7 pip|pika|0.10.0 pip|pika-pool|0.1.3 pip|Pint|0.7.1 pip|pluggy|0.3.1 pip|positional|1.0.1 pip|prettytable|0.7.2 pip|psutil|1.2.1 pip|psycopg2|2.6.1 pip|py|1.4.31 pip|pyasn1|0.1.9 pip|pyasn1-modules|0.0.8 pip|pycadf|2.1.0 pip|pycparser|2.14 pip|pycrypto|2.6.1 pip|pycurl|7.19.3 pip|PyECLib|1.2.0 pip|pyflakes|0.8.1 pip|Pygments|2.1.1 pip|pygobject|3.12.0 pip|pyinotify|0.9.6 pip|pylint|1.4.5 pip|PyMySQL|0.7.2 pip|pyOpenSSL|0.15.1 pip|pyparsing|2.1.0 pip|pyrsistent|0.11.12 pip|pysaml2|4.0.2 pip|pyScss|1.3.4 pip|pysendfile|2.0.1 pip|pyserial|2.6 pip|python-apt=|0.9.3.5ubuntu1 pip|python-barbicanclient|3.3.0 pip|python-ceilometerclient|2.3.0 pip|python-cinderclient|1.5.0 pip|python-dateutil|2.5.0 pip|python-debian=|0.1.21-nmu2ubuntu2 pip|python-designateclient|2.0.0 pip|python-editor|0.5 pip|python-glanceclient|1.2.0 pip|python-heatclient|0.9.0 pip|python-ironicclient|1.1.0 pip|python-keystoneclient|2.3.0 pip|python-ldap|2.4.25 pip|python-magnumclient|1.1.0 pip|python-manilaclient|1.7.0 pip|python-memcached|1.57 pip|python-mimeparse|1.5.1 pip|python-mistralclient|1.2.0 pip|python-neutronclient|4.0.0 pip|python-novaclient|3.2.0 pip|python-openstackclient|2.1.0 pip|python-saharaclient|0.12.0 pip|python-senlinclient|0.3.0 pip|https://github.com/openstack/python-solumclient.git|bde4a81dc9b259a484715fc298f84029ed0569e5 pip|python-subunit|1.2.0 pip|python-swiftclient|2.7.0 pip|python-troveclient|2.0.0 pip|python-zaqarclient|0.3.0 pip|pytz|2015.7 pip|PyYAML|3.11 pip|qpid-python|0.32 pip|rcssmin|1.0.6 pip|reno|1.5.0 pip|repoze.lru|0.6 pip|repoze.who|2.2 pip|requests|2.9.1 pip|requests-mock|0.7.0 pip|requestsexceptions|1.1.3 pip|retrying|1.3.3 pip|rfc3986|0.3.1 pip|rjsmin|1.0.12 pip|Routes|2.2 pip|rsa|3.3 pip|rtslib-fb|2.1.58 pip|ryu|3.30 pip|SecretStorage|2.0.0 pip|selenium|2.52.0 pip|semantic-version|2.5.0 pip|simplegeneric|0.8.1 pip|simplejson|3.8.2 pip|singledispatch|3.4.0.3 pip|six|1.10.0 pip|smmap|0.9.0 pip|https://github.com/openstack/solum.git|bdc0fae7451ea1da03e78a97117f2b661df6e599 pip|Sphinx|1.2.3 pip|sphinxcontrib-httpdomain|1.4.0 pip|sphinxcontrib-pecanwsme|0.8.0 pip|SQLAlchemy|1.0.12 pip|sqlalchemy-migrate|0.10.0 pip|sqlparse|0.1.18 pip|ssh-import-id|3.21 pip|stevedore|1.12.0 pip|suds-jurko|0.6 pip|https://git.openstack.org/openstack/swift.git|61928443edc35e6c25d2edc7bbced39c736bcb01 pip|taskflow|1.30.0 pip|https://git.openstack.org/openstack/tempest.git|c276478e8fd3332c142326c893f8a5cb53155e1f pip|tempest-lib|0.14.0 pip|Tempita|0.5.2 pip|termcolor|1.1.0 pip|testrepository|0.0.20 pip|testresources|1.0.0 pip|testscenarios|0.5.0 pip|testtools|2.0.0 pip|tooz|1.34.0 pip|tox|2.3.1 pip|traceback2|1.4.0 pip|Twisted-Core|13.2.0 pip|Twisted-Names|13.2.0 pip|Twisted-Web|13.2.0 pip|unicodecsv|0.14.1 pip|unittest2|1.1.0 pip|uritemplate|0.6 pip|urllib3|1.14 pip|virtualenv|14.0.6 pip|voluptuous|0.8.8 pip|wadllib|1.3.2 pip|waitress|0.8.10 pip|warlock|1.2.0 pip|WebOb|1.5.1 pip|websocket-client|0.35.0 pip|websockify|0.8.0 pip|WebTest|2.0.20 pip|wheel|0.24.0 pip|wrapt|1.10.6 pip|WSME|0.8.0 pip|xattr|0.7.9 pip|XStatic|1.0.1 pip|XStatic-Angular|1.3.7.0 pip|XStatic-Angular-Bootstrap|0.11.0.2 pip|XStatic-Angular-Gettext|2.1.0.2 pip|XStatic-Angular-lrdragndrop|1.0.2.2 pip|XStatic-Bootstrap-Datepicker|1.3.1.0 pip|XStatic-Bootstrap-SCSS|3.2.0.0 pip|XStatic-bootswatch|3.3.5.3 pip|XStatic-D3|3.1.6.2 pip|XStatic-Font-Awesome|4.3.0.0 pip|XStatic-Hogan|2.0.0.2 pip|XStatic-Jasmine|2.1.2.0 pip|XStatic-jQuery|1.10.2.1 pip|XStatic-JQuery-Migrate|1.2.1.1 pip|XStatic-jquery-ui|1.11.0.1 pip|XStatic-JQuery.quicksearch|2.0.3.1 pip|XStatic-JQuery.TableSorter|2.14.5.1 pip|XStatic-JSEncrypt|2.0.0.2 pip|XStatic-mdi|1.1.70.1 pip|XStatic-Rickshaw|1.5.0.0 pip|XStatic-roboto-fontface|0.4.3.2 pip|XStatic-smart-table|1.4.5.3 pip|XStatic-Spin|1.2.5.2 pip|XStatic-term.js|0.0.7.0 pip|xvfbwrapper|0.2.8 pip|zake|0.2.2 pip|zope.interface|4.1.3 localrc|LOGFILE=/opt/stack/logs/stack.sh.log localrc|DATABASE_PASSWORD=<password> localrc|RABBIT_PASSWORD=<password> localrc|SERVICE_TOKEN=solum localrc|SERVICE_PASSWORD=<password> localrc|ADMIN_PASSWORD=<password> localrc|NOVNC_FROM_PACKAGE=false localrc|SCREEN_LOGDIR=/opt/stack/logs/screen localrc|SOLUM_INSTALL_CEDARISH=False localrc|SOLUM_INSTALL_DOCKERFILE=False localrc|GIT_BASE=https://git.openstack.org localrc|VIRT_DRIVER=docker localrc|SOLUM_IMAGE_FORMAT=docker localrc|SOLUM_INSTALL_DRONE=True localrc|SOLUM_DRONE_URL=http://f4e976e84d9bb06108f6-ff40fde470ff7ecea31955ec7c479471.r49.cf2.rackcdn.com/drone.deb localrc|DEFAULT_IMAGE_NAME=cirros localrc|IMAGE_URLS="" "" localrc|enable_plugin solum git://git.openstack.org/openstack/solum localrc|IP_VERSION=4 localrc|SERVICE_IP_VERSION=4 localrc|enable_service solum-api localrc|enable_service solum-conductor localrc|enable_service solum-deployer localrc|enable_service solum-worker localrc|disable_service n-net localrc|enable_service q-svc localrc|enable_service q-agt localrc|enable_service q-dhcp localrc|enable_service q-l3 localrc|enable_service q-meta localrc|enable_service neutron localrc|enable_service s-proxy localrc|enable_service s-object localrc|enable_service s-container localrc|enable_service s-account localrc|enable_service heat localrc|enable_service h-api localrc|enable_service h-api-cfn localrc|enable_service h-api-cw localrc|enable_service h-eng vagrant@devstack:~$ docker --version Docker version 1.9.1, build a34a1d5 wget -qO- https://get.docker.io/gpg | sudo apt-key add - sudo sh -c ""echo deb http://get.docker.io/ubuntu docker main > /etc/apt/sources.list.d/docker.list"" sudo apt-get update sudo apt-get install lxc-docker service docker restart sudo chmod o=rwx /var/run/docker.sock",,445,0
openstack%2Fpuppet-tripleo~stable%2Fliberty~Ibe7941bec02f5facf21732910c9ad96f547ff8e5,openstack/puppet-tripleo,stable/liberty,Ibe7941bec02f5facf21732910c9ad96f547ff8e5,loadbalancer: fix Redis timeout HAproxy config,MERGED,2016-03-03 16:46:53.000000000,2016-03-04 20:36:16.000000000,2016-03-04 20:36:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-03-03 16:46:53.000000000', 'files': ['manifests/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/38a41fe5b5f985820ef4400386691557988d4201', 'message': ""loadbalancer: fix Redis timeout HAproxy config\n\nCurrent HAproxy config is broken for Redis timeout parameters. This is what we\nhave today by default in HAproxy logs:\n[WARNING] 238/115010 (13878) : config : missing timeouts for proxy 'redis'.\n| While not properly invalid, you will certainly encounter various problems\n| with such a configuration. To fix this, please ensure that all following\n| timeouts are set to a non-zero value: 'client', 'connect', 'server'.\n\nThis patch removes the explicit setting of client and server timeouts to 0,\nwhich is the cause of the above warning.  Instead, Redis will simply inherit the\nhaproxy defaults, which should be a more reasonable setting, and result in no\nwarnings.\n\nChange-Id: Ibe7941bec02f5facf21732910c9ad96f547ff8e5\n(cherry picked from commit 6e4870915281c80176ea08584f337099e60e2b2d)\n""}]",0,287974,38a41fe5b5f985820ef4400386691557988d4201,8,3,1,7984,,,0,"loadbalancer: fix Redis timeout HAproxy config

Current HAproxy config is broken for Redis timeout parameters. This is what we
have today by default in HAproxy logs:
[WARNING] 238/115010 (13878) : config : missing timeouts for proxy 'redis'.
| While not properly invalid, you will certainly encounter various problems
| with such a configuration. To fix this, please ensure that all following
| timeouts are set to a non-zero value: 'client', 'connect', 'server'.

This patch removes the explicit setting of client and server timeouts to 0,
which is the cause of the above warning.  Instead, Redis will simply inherit the
haproxy defaults, which should be a more reasonable setting, and result in no
warnings.

Change-Id: Ibe7941bec02f5facf21732910c9ad96f547ff8e5
(cherry picked from commit 6e4870915281c80176ea08584f337099e60e2b2d)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/74/287974/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/loadbalancer.pp'],1,38a41fe5b5f985820ef4400386691557988d4201,fix-redis-timeouts,," 'timeout' => [ 'client 0', 'server 0' ],",0,1
openstack%2Fcue~master~I29524df86146762aac5430efafaf7a02b705f539,openstack/cue,master,I29524df86146762aac5430efafaf7a02b705f539,fix for horizon/devstack issue,MERGED,2016-03-03 21:41:21.000000000,2016-03-04 20:29:25.000000000,2016-03-04 20:29:24.000000000,"[{'_account_id': 3}, {'_account_id': 10584}]","[{'number': 1, 'created': '2016-03-03 21:41:21.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/cue/commit/ea98738844b5ca6b9b6a4aba057ecceb2df5faa6', 'message': ""fix for horizon/devstack issue\n\nAs of pip 8.x installing from external links is not allowed when\nconstraints are enforced, this is causing cue-dashboard\ninstallation to fail because cue-dashboard is pulling in\nhorizon as an external link as part of test-requirements.\n\nSince test requirements won't be needed during devstack gate\ntesting, cue-dashboard/test-requirements.txt is being shuffled\naround to avoid installing cue-dashboard/test-requirements.  This\nfollows the approach that Manila uses in\nI841b56f65b50e9c5673cc02e93b4329ed29125ba\n\nChange-Id: I29524df86146762aac5430efafaf7a02b705f539\n""}]",0,288140,ea98738844b5ca6b9b6a4aba057ecceb2df5faa6,6,2,1,10584,,,0,"fix for horizon/devstack issue

As of pip 8.x installing from external links is not allowed when
constraints are enforced, this is causing cue-dashboard
installation to fail because cue-dashboard is pulling in
horizon as an external link as part of test-requirements.

Since test requirements won't be needed during devstack gate
testing, cue-dashboard/test-requirements.txt is being shuffled
around to avoid installing cue-dashboard/test-requirements.  This
follows the approach that Manila uses in
I841b56f65b50e9c5673cc02e93b4329ed29125ba

Change-Id: I29524df86146762aac5430efafaf7a02b705f539
",git fetch https://review.opendev.org/openstack/cue refs/changes/40/288140/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,ea98738844b5ca6b9b6a4aba057ecceb2df5faa6,, mv $CUEDASHBOARD_DIR/test-requirements.txt $CUEDASHBOARD_DIR/_test-requirements.txt mv $CUEDASHBOARD_DIR/_test-requirements.txt $CUEDASHBOARD_DIR/test-requirements.txt,,2,0
openstack%2Fceilometer~master~If5084cc23212a0a6bd9dac8438d5d286f3415730,openstack/ceilometer,master,If5084cc23212a0a6bd9dac8438d5d286f3415730,timedelta plugin for meter definition process,MERGED,2016-03-01 09:41:09.000000000,2016-03-04 20:29:17.000000000,2016-03-04 20:29:16.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 10987}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-03-01 09:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8278b6c5dbdb7a7f26b2bf495327c1c336f80027', 'message': 'timedelta plugin for meter definition process\n\nwith timedelta plugin we could create new metric for latency time of\nnstance booting without using events and its transformation.\nwe could define new meter in meters.yaml with volume as in example::\n   volume:\n      fields: [$.payload.created_at, $.payload.launched_at]\n      plugin: ‘timedelta’\n\nas a result we get volume value equal to difference between two mentioned\ntimestamp fields in seconds.\n\nChange-Id: If5084cc23212a0a6bd9dac8438d5d286f3415730\n'}, {'number': 2, 'created': '2016-03-01 14:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/198a910084241ad27fe854cfc04c42f074f9df26', 'message': 'timedelta plugin for meter definition process\n\nwith timedelta plugin we could create new metric for latency time of\nnstance booting without using events and its transformation.\nwe could define new meter in meters.yaml with volume as in example::\n   volume:\n      fields: [$.payload.created_at, $.payload.launched_at]\n      plugin: ‘timedelta’\n\nas a result we get volume value equal to difference between two mentioned\ntimestamp fields in seconds.\n\nChange-Id: If5084cc23212a0a6bd9dac8438d5d286f3415730'}, {'number': 3, 'created': '2016-03-02 14:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5fc6634f71a99227d1baa64f1266d5f183293a24', 'message': 'timedelta plugin for meter definition process\n\nwith timedelta plugin we could create new metric for latency time of\nnstance booting without using events and its transformation.\nwe could define new meter in meters.yaml with volume as in example::\n   volume:\n      fields: [$.payload.created_at, $.payload.launched_at]\n      plugin: ‘timedelta’\n\nas a result we get volume value equal to difference between two mentioned\ntimestamp fields in seconds.\n\nChange-Id: If5084cc23212a0a6bd9dac8438d5d286f3415730\n'}, {'number': 4, 'created': '2016-03-04 12:26:58.000000000', 'files': ['ceilometer/event/trait_plugins.py', 'ceilometer/tests/unit/meter/test_notifications.py', 'ceilometer/tests/unit/meter/test_meter_plugins.py', 'setup.cfg', 'ceilometer/meter/data/meters.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98de1315bb08b91cd9dc48d94994ad7d0a5eb455', 'message': 'timedelta plugin for meter definition process\n\nwith timedelta plugin we could create new metric for latency time of\nnstance booting without using events and its transformation.\nwe could define new meter in meters.yaml with volume as in example::\n   volume:\n      fields: [$.payload.created_at, $.payload.launched_at]\n      plugin: ‘timedelta’\n\nas a result we get volume value equal to difference between two mentioned\ntimestamp fields in seconds.\n\nChange-Id: If5084cc23212a0a6bd9dac8438d5d286f3415730\n'}]",14,286469,98de1315bb08b91cd9dc48d94994ad7d0a5eb455,24,6,4,10987,,,0,"timedelta plugin for meter definition process

with timedelta plugin we could create new metric for latency time of
nstance booting without using events and its transformation.
we could define new meter in meters.yaml with volume as in example::
   volume:
      fields: [$.payload.created_at, $.payload.launched_at]
      plugin: ‘timedelta’

as a result we get volume value equal to difference between two mentioned
timestamp fields in seconds.

Change-Id: If5084cc23212a0a6bd9dac8438d5d286f3415730
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/69/286469/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/event/trait_plugins.py', 'ceilometer/tests/unit/meter/test_notifications.py', 'setup.cfg', 'ceilometer/meter/data/meters.yaml']",4,8278b6c5dbdb7a7f26b2bf495327c1c336f80027,meter_plugin," - name: 'compute.instance.booting.time' event_type: 'compute.instance.create.end' type: 'gauge' unit: 'sec' volume: fields: [$.payload.created_at, $.payload.launched_at] plugin: 'timedelta' project_id: $.payload.tenant_id resource_id: $.payload.instance_id ",,64,1
openstack%2Fpython-designateclient~master~I8f973e52561d4644821148690430be4c0c1944c0,openstack/python-designateclient,master,I8f973e52561d4644821148690430be4c0c1944c0,Improved TestRecordsetNegative,MERGED,2016-03-04 17:55:29.000000000,2016-03-04 20:27:56.000000000,2016-03-04 20:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8174}, {'_account_id': 11662}, {'_account_id': 11714}]","[{'number': 1, 'created': '2016-03-04 17:55:29.000000000', 'files': ['designateclient/functionaltests/v2/test_recordsets.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/319a331e513a57ce1419b11f1a618158a5e33870', 'message': 'Improved TestRecordsetNegative\n\nAdded a parent to the class and hardcoded the zone id and name in one of the tests.\n\nChange-Id: I8f973e52561d4644821148690430be4c0c1944c0\n'}]",0,288614,319a331e513a57ce1419b11f1a618158a5e33870,9,5,1,15241,,,0,"Improved TestRecordsetNegative

Added a parent to the class and hardcoded the zone id and name in one of the tests.

Change-Id: I8f973e52561d4644821148690430be4c0c1944c0
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/14/288614/1 && git format-patch -1 --stdout FETCH_HEAD,['designateclient/functionaltests/v2/test_recordsets.py'],1,319a331e513a57ce1419b11f1a618158a5e33870,FixNegativeRecordsetTest,"class TestRecordsetNegative(BaseDesignateTest): cmd = 'recordset create de47d30b-41c5-4e38-b2c5-e0b908e19ec7 ' \ 'aaa.desig.com. --type A --records 1.2.3.4 ' \ '--invalid ""not valid""'","class TestRecordsetNegative(object): cmd = 'recordset create {0} aaa.{1} --type A --records 1.2.3.4 ' \ '--invalid ""not valid""'.format(self.zone.id, self.zone.name)",4,3
openstack%2Fcastellan~master~I9b1206b802dff1f54080eb0f428ce02ab5f48ac7,openstack/castellan,master,I9b1206b802dff1f54080eb0f428ce02ab5f48ac7,Allow Castellan Object List,ABANDONED,2015-10-14 06:03:19.000000000,2016-03-04 20:26:08.000000000,,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7764}, {'_account_id': 8623}, {'_account_id': 16046}]","[{'number': 1, 'created': '2015-10-14 06:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/5388b67d97004c4f029620cee7d0ce7b0b071530', 'message': 'Allow Barbican Object List\n\nThis patch will allow Castellan to be able to display\na list of specific Barbican Objects. It is useful\nbecause the user will be able to see additional\nmetadata associated with their Objects and be able\nto further sort by that metadata with their own services.\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 2, 'created': '2015-10-22 03:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/f5cefd5915294569198c62eaa1fe69b5a34de6bb', 'message': 'Allow Barbican Object List\n\nThis patch will allow Castellan to be able to display\na list of specific Barbican Objects. It is useful\nbecause the user will be able to see additional\nmetadata associated with their Objects and be able\nto further sort by that metadata with their own services.\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 3, 'created': '2015-10-22 04:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/c4753218a627de1afee2e0ba9ea4df810590abae', 'message': 'Allow Barbican Object List\n\nThis patch will allow Castellan to be able to display\na list of specific Barbican Objects. It is useful\nbecause the user will be able to see additional\nmetadata associated with their Objects and be able\nto further sort by that metadata with their own services.\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 4, 'created': '2015-11-03 01:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/7bf86cf40e6d9b0b0f37ab4df0767f69542004ab', 'message': 'Allow Barbican Object List\n\nThis patch will allow Castellan to be able to display\na list of specific Barbican Objects. It is useful\nbecause the user will be able to see additional\nmetadata associated with their Objects and be able\nto further sort by that metadata with their own services.\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 5, 'created': '2015-11-04 19:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/79e64a42fda31ccf953ac6ba7eef77ff5dca90f5', 'message': 'Allow Barbican Object List\n\nThis patch will allow Castellan to be able to display\na list of specific Barbican Objects. It is useful\nbecause the user will be able to see additional\nmetadata associated with their Objects and be able\nto further sort by that metadata with their own services.\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 6, 'created': '2015-11-05 04:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/f01ecc887cc57fd0b42b356fdb8e131705dca3f1', 'message': 'Allow Castellan Object List\n\nThis patch will allow Castellan to be able to display\na list of Secrets. It is useful because the user will\nbe able to see additional metadata associated with their\nObjects and be able to further sort using that metadata\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}, {'number': 7, 'created': '2015-11-15 04:44:55.000000000', 'files': ['castellan/tests/unit/key_manager/test_barbican_key_manager.py', 'castellan/tests/unit/key_manager/test_not_implemented_key_manager.py', 'castellan/key_manager/barbican_key_manager.py', 'castellan/tests/unit/key_manager/mock_key_manager.py', 'castellan/key_manager/key_manager.py', 'castellan/key_manager/not_implemented_key_manager.py', 'castellan/tests/functional/key_manager/test_key_manager.py', 'castellan/tests/unit/key_manager/test_mock_key_manager.py'], 'web_link': 'https://opendev.org/openstack/castellan/commit/4f6ce45d1af535ca88e9b7e5210b58159f7f5240', 'message': 'Allow Castellan Object List\n\nThis patch will allow Castellan to be able to display\na list of Secrets. It is useful because the user will\nbe able to see additional metadata associated with their\nObjects and be able to further sort using that metadata\n\nChange-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7\n'}]",20,234580,4f6ce45d1af535ca88e9b7e5210b58159f7f5240,37,5,7,16046,,,0,"Allow Castellan Object List

This patch will allow Castellan to be able to display
a list of Secrets. It is useful because the user will
be able to see additional metadata associated with their
Objects and be able to further sort using that metadata

Change-Id: I9b1206b802dff1f54080eb0f428ce02ab5f48ac7
",git fetch https://review.opendev.org/openstack/castellan refs/changes/80/234580/5 && git format-patch -1 --stdout FETCH_HEAD,"['castellan/key_manager/barbican_key_manager.py', 'castellan/key_manager/key_manager.py']",2,5388b67d97004c4f029620cee7d0ce7b0b071530,list-objects," def list(self, context, entity_type, limit=10, offset=0): """"""Retrieves a list of specified managed objects Implementations should verify that the caller has permission to list the managed objects by checking the context object (context). A NotAuthorized exception should be raised if the caller lacks permission. If the specified entity type does not exist in a list of available types, then a KeyError should be raised. Implementations should preclude users from discerning the UUIDs of objects that belong to other users by repeatedly calling this method. That is, objects that belong to other users should be considered ""non-existent"" and completely invisible. """""" pass @abc.abstractmethod",,45,0
openstack%2Fbarbican~master~Iddebf9b46cfdf1568a351f3413f2d18cf2f833e2,openstack/barbican,master,Iddebf9b46cfdf1568a351f3413f2d18cf2f833e2,Fix index for API secrets user-guide,MERGED,2016-03-04 18:51:20.000000000,2016-03-04 20:17:56.000000000,2016-03-04 20:17:56.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 11970}, {'_account_id': 17579}]","[{'number': 1, 'created': '2016-03-04 18:51:20.000000000', 'files': ['doc/source/api/index.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b2a557ce7d74b88bcf3ab3eb4c9715a97aa0c7a9', 'message': 'Fix index for API secrets user-guide\n\nIndex has wrong bath for the User-Guide. This patch resolves the\npath.\n\nChange-Id: Iddebf9b46cfdf1568a351f3413f2d18cf2f833e2\n'}]",0,288641,b2a557ce7d74b88bcf3ab3eb4c9715a97aa0c7a9,9,14,1,16046,,,0,"Fix index for API secrets user-guide

Index has wrong bath for the User-Guide. This patch resolves the
path.

Change-Id: Iddebf9b46cfdf1568a351f3413f2d18cf2f833e2
",git fetch https://review.opendev.org/openstack/barbican refs/changes/41/288641/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/index.rst'],1,b2a557ce7d74b88bcf3ab3eb4c9715a97aa0c7a9,, ./userguide/secrets, ./userguide/secret,1,1
openstack%2Ffuel-web~master~Ia25bf9f18b4e4e591ff231cc093cf3ea581b8ff7,openstack/fuel-web,master,Ia25bf9f18b4e4e591ff231cc093cf3ea581b8ff7,Insert provider_specific hash into endpoints in the network_scheme,ABANDONED,2016-03-04 19:50:03.000000000,2016-03-04 20:17:37.000000000,,"[{'_account_id': 8971}, {'_account_id': 17877}]","[{'number': 1, 'created': '2016-03-04 19:50:03.000000000', 'files': ['nailgun/nailgun/orchestrator/neutron_serializers.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_70.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_90.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e6652f89654c01957e89f88b0de64700a7aebb8f', 'message': 'Insert provider_specific hash into endpoints in the network_scheme\n\nthat contain gateway for described network.\n\nCo-Authored-By: Vitalii Myhal <vmygal@mirantis.com>\nCo-Authored-By: Sergey Vasilenko <svasilenko@mirantis.com>\n\nChange-Id: Ia25bf9f18b4e4e591ff231cc093cf3ea581b8ff7\nCloses-bug: #1549034\n'}]",0,288707,e6652f89654c01957e89f88b0de64700a7aebb8f,9,2,1,7468,,,0,"Insert provider_specific hash into endpoints in the network_scheme

that contain gateway for described network.

Co-Authored-By: Vitalii Myhal <vmygal@mirantis.com>
Co-Authored-By: Sergey Vasilenko <svasilenko@mirantis.com>

Change-Id: Ia25bf9f18b4e4e591ff231cc093cf3ea581b8ff7
Closes-bug: #1549034
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/07/288707/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/neutron_serializers.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_70.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_90.py']",3,e6652f89654c01957e89f88b0de64700a7aebb8f,bug/1549034,"from nailgun import objects from nailgun.orchestrator.deployment_serializers import \ get_serializer_for_cluster def check_selective_gateway(self, use_net_template=False): node = self.env.create_node( cluster_id=self.cluster.id, roles=['controller'], primary_roles=['controller'] ) objects.Cluster.set_network_template( self.cluster, self.net_template if use_net_template else None) objects.Cluster.prepare_for_deployment(self.cluster) serializer = get_serializer_for_cluster(self.cluster) net_serializer = serializer.get_net_provider_serializer(self.cluster) nm = objects.Cluster.get_network_manager(self.cluster) networks_list = nm.get_node_networks(node) networks = {net['name']: net for net in networks_list} endpoints = net_serializer.generate_network_scheme( node, networks_list)['endpoints'] na = self.net_template[ 'adv_net_template']['default']['network_assignments'] ep_net_map = {na[net_name]['ep']: net_name for net_name in na} for name in endpoints: if name not in ep_net_map: continue if networks[ep_net_map[name]].get('gateway') is None: self.assertNotIn('vendor_specific', endpoints[name]) else: self.assertIn('vendor_specific', endpoints[name]) self.assertEqual( endpoints[name]['vendor_specific']['provider_gateway'], networks[ep_net_map[name]]['gateway']) def test_selective_gateway_in_deployment_serializer(self): self.check_selective_gateway() def test_selective_gateway_in_template_serializer(self): self.check_selective_gateway(use_net_template=True) ",,91,1
openstack%2Fopenstack-ansible~liberty~Ib4634b8de84b614c33df60255ddf1134c023cf05,openstack/openstack-ansible,liberty,Ib4634b8de84b614c33df60255ddf1134c023cf05,Information about the keepalived bug when multiple backup nodes have the same priority.,MERGED,2016-02-12 16:48:45.000000000,2016-03-04 20:17:03.000000000,2016-03-04 20:17:02.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12402}, {'_account_id': 14552}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-02-12 16:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/68bf512c6e03ddf009bb03a60f114a3297d29aec', 'message': 'Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n'}, {'number': 2, 'created': '2016-02-12 17:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2a24b9493e702832d0408225d07fc04ba830b86e', 'message': 'Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n'}, {'number': 3, 'created': '2016-02-12 18:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca557b098f2b835b06c736e65deba3375cd54eeb', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 4, 'created': '2016-02-17 15:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b19a2f12bcfd4850df1772f7f8d6af4d56eb85ed', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 5, 'created': '2016-02-17 15:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/40182536335a7939266bdd2116f1c4a001cc7f2c', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 6, 'created': '2016-02-17 16:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0aab67f29debd0082673af4cbcea70a32121aa1', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 7, 'created': '2016-02-29 11:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/642be051c8e336fb839367f38794ffcd4ae1dcd4', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 8, 'created': '2016-02-29 11:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0f25f46118f8b215349e6f2969c3a3ed0442b39e', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}, {'number': 9, 'created': '2016-02-29 12:06:24.000000000', 'files': ['doc/source/install-guide/configure-haproxy.rst', 'releasenotes/notes/keepalived-issue-a99e1d157ae49462.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/03cfb7e9fd12694243bac9696328591f4e5428c1', 'message': ""Information about the keepalived bug when multiple backup nodes\nhave the same priority.\n\nThis text is only relevant if the latest version of the\nkeepalived role doesn't get backported to liberty.\n\nBug: #1545066\nChange-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05\n""}]",4,279664,03cfb7e9fd12694243bac9696328591f4e5428c1,26,7,9,17068,,,0,"Information about the keepalived bug when multiple backup nodes
have the same priority.

This text is only relevant if the latest version of the
keepalived role doesn't get backported to liberty.

Bug: #1545066
Change-Id: Ib4634b8de84b614c33df60255ddf1134c023cf05
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/279664/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install-guide/configure-haproxy.rst'],1,68bf512c6e03ddf009bb03a60f114a3297d29aec,bug/1545066,".. note:: A bug currently affects the current keepalived shipped with Ubuntu 14.04. Please read below if you have more than two HAProxy/keepalived nodes. If you are running a keepalived version < 1.2.8, you'll encounter a bug when two (or more) backup hosts have the same priority. Please provide your own keepalived file to overcome this problem, by setting priorities to the level you appropriate to your infrastructure. ",,9,0
openstack%2Fopenstack-ansible~kilo~I61795b3afb4804060d494a08975c10adcf52f468,openstack/openstack-ansible,kilo,I61795b3afb4804060d494a08975c10adcf52f468,"Use current, but pinned versions of pip, setuptools and wheel",MERGED,2016-03-03 17:42:11.000000000,2016-03-04 20:16:55.000000000,2016-03-04 20:16:55.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 7414}]","[{'number': 1, 'created': '2016-03-03 17:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/87a69be5eb69b11155bae1d1d8690143d00cb4d0', 'message': 'Use current, but pinned versions of pip, setuptools and wheel\n\nThis patch provides a convenience script to check for the current\nversion of any package on PyPI, then output it in various ways.\n\nThis script is used in the SHA updating script in order to provide\na current set of critical packages to ensure that each SHA bump\nincludes an update to a current version of pip, setuptools and\nwheel but also to ensure that they are pinned to a specific version\nwith this particular set of packages.\n\nThis ensures that we keep current with these packages as they\nchange, but also ensures that the versions tested for each tag are\nthe versions used forever.\n\nThe patch also ensures that any package installed by pip is upgraded\nto the expected versions.\n\nThis is a combined backport of:\n - https://review.openstack.org/284701\n - https://review.openstack.org/284977\n - https://review.openstack.org/287700\n - https://review.openstack.org/287739\n\nChange-Id: I61795b3afb4804060d494a08975c10adcf52f468\n(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)\n'}, {'number': 2, 'created': '2016-03-03 18:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5afdad6c5f0c0fcf6afafcc000d3c9b7e488078d', 'message': 'Use current, but pinned versions of pip, setuptools and wheel\n\nThis patch provides a convenience script to check for the current\nversion of any package on PyPI, then output it in various ways.\n\nThis script is used in the SHA updating script in order to provide\na current set of critical packages to ensure that each SHA bump\nincludes an update to a current version of pip, setuptools and\nwheel but also to ensure that they are pinned to a specific version\nwith this particular set of packages.\n\nThis ensures that we keep current with these packages as they\nchange, but also ensures that the versions tested for each tag are\nthe versions used forever.\n\nThe patch also ensures that any package installed by pip is upgraded\nto the expected versions.\n\nThis is a combined backport of:\n - https://review.openstack.org/284701\n - https://review.openstack.org/284977\n - https://review.openstack.org/287700\n - https://review.openstack.org/287739\n\nIt also reverts https://review.openstack.org/283039 as the pinning\nis now handled properly elsewhere. It also undoes the pip pinning\ndone via global-requirements in https://review.openstack.org/270312\nwhich was not done in other branches.\n\nChange-Id: I61795b3afb4804060d494a08975c10adcf52f468\n(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)\n'}, {'number': 3, 'created': '2016-03-04 09:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0bfad6af76d355c93ac2cb18995a60f763edb205', 'message': 'Use current, but pinned versions of pip, setuptools and wheel\n\nThis patch provides a convenience script to check for the current\nversion of any package on PyPI, then output it in various ways.\n\nThis script is used in the SHA updating script in order to provide\na current set of critical packages to ensure that each SHA bump\nincludes an update to a current version of pip, setuptools and\nwheel but also to ensure that they are pinned to a specific version\nwith this particular set of packages.\n\nThis ensures that we keep current with these packages as they\nchange, but also ensures that the versions tested for each tag are\nthe versions used forever.\n\nThe patch also ensures that any package installed by pip is upgraded\nto the expected versions.\n\nThis is a combined backport of:\n - https://review.openstack.org/284701\n - https://review.openstack.org/284977\n - https://review.openstack.org/287700\n - https://review.openstack.org/287739\n\nBackport notes:\n - https://review.openstack.org/283039 is reverted as the pinning\n   is now handled properly elsewhere.\n - The pip pinning done via global-requirements in\n   https://review.openstack.org/270312 is removed.\n - The versions pinned are the versions used at the time of the\n   last rpc-repo build. This is to ensure that this tag implements\n   the same version of all the packages used as the time the tag\n   repo was built.\n\nChange-Id: I61795b3afb4804060d494a08975c10adcf52f468\n(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)\n'}, {'number': 4, 'created': '2016-03-04 10:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/06ef9d41232a65909daeda03bf85d72347b88210', 'message': 'Use current, but pinned versions of pip, setuptools and wheel\n\nThis patch provides a convenience script to check for the current\nversion of any package on PyPI, then output it in various ways.\n\nThis script is used in the SHA updating script in order to provide\na current set of critical packages to ensure that each SHA bump\nincludes an update to a current version of pip, setuptools and\nwheel but also to ensure that they are pinned to a specific version\nwith this particular set of packages.\n\nThis ensures that we keep current with these packages as they\nchange, but also ensures that the versions tested for each tag are\nthe versions used forever.\n\nThe patch also ensures that any package installed by pip is upgraded\nto the expected versions.\n\nThis is a combined backport of:\n - https://review.openstack.org/284701\n - https://review.openstack.org/284977\n - https://review.openstack.org/287700\n - https://review.openstack.org/287739\n\nBackport notes:\n - https://review.openstack.org/283039 is reverted as the pinning\n   is now handled properly elsewhere.\n - The pip pinning done via global-requirements in\n   https://review.openstack.org/270312 is removed.\n - The versions pinned are the versions used at the time of the\n   last rpc-repo build. This is to ensure that this tag implements\n   the same version of all the packages used as the time the tag\n   repo was built.\n - The SHA for the requirements repository is updated in order to\n   include the caps for osprofiler and testtools.\n\nChange-Id: I61795b3afb4804060d494a08975c10adcf52f468\n(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)\n'}, {'number': 5, 'created': '2016-03-04 11:48:47.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/roles/pip_install/defaults/main.yml', 'playbooks/roles/pip_install/tasks/main.yml', 'releasenotes/notes/pip-setuptools-wheel-pins-25494191c4739d52.yaml', 'requirements.txt', 'global-requirement-pins.txt', 'scripts/sources-branch-updater.sh', 'scripts/scripts-library.sh', 'scripts/get-pypi-pkg-version.py', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/repo_server/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9abc2c85cf62a21d80dfa2d8f6a70022c0a346fc', 'message': 'Use current, but pinned versions of pip, setuptools and wheel\n\nThis patch provides a convenience script to check for the current\nversion of any package on PyPI, then output it in various ways.\n\nThis script is used in the SHA updating script in order to provide\na current set of critical packages to ensure that each SHA bump\nincludes an update to a current version of pip, setuptools and\nwheel but also to ensure that they are pinned to a specific version\nwith this particular set of packages.\n\nThis ensures that we keep current with these packages as they\nchange, but also ensures that the versions tested for each tag are\nthe versions used forever.\n\nThe patch also ensures that any package installed by pip is upgraded\nto the expected versions.\n\nThis is a combined backport of:\n - https://review.openstack.org/284701\n - https://review.openstack.org/284977\n - https://review.openstack.org/287700\n - https://review.openstack.org/287739\n\nBackport notes:\n - https://review.openstack.org/283039 is reverted as the pinning\n   is now handled properly elsewhere.\n - The pip pinning done via global-requirements in\n   https://review.openstack.org/270312 is removed.\n - The versions pinned are the versions used at the time of the\n   last rpc-repo build. This is to ensure that this tag implements\n   the same version of all the packages used as the time the tag\n   repo was built.\n - The SHA for the requirements repository is updated in order to\n   include the caps for osprofiler and testtools.\n\nCloses-Bug: 1545505\nChange-Id: I61795b3afb4804060d494a08975c10adcf52f468\n(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)\n'}]",0,288005,9abc2c85cf62a21d80dfa2d8f6a70022c0a346fc,13,3,5,6816,,,0,"Use current, but pinned versions of pip, setuptools and wheel

This patch provides a convenience script to check for the current
version of any package on PyPI, then output it in various ways.

This script is used in the SHA updating script in order to provide
a current set of critical packages to ensure that each SHA bump
includes an update to a current version of pip, setuptools and
wheel but also to ensure that they are pinned to a specific version
with this particular set of packages.

This ensures that we keep current with these packages as they
change, but also ensures that the versions tested for each tag are
the versions used forever.

The patch also ensures that any package installed by pip is upgraded
to the expected versions.

This is a combined backport of:
 - https://review.openstack.org/284701
 - https://review.openstack.org/284977
 - https://review.openstack.org/287700
 - https://review.openstack.org/287739

Backport notes:
 - https://review.openstack.org/283039 is reverted as the pinning
   is now handled properly elsewhere.
 - The pip pinning done via global-requirements in
   https://review.openstack.org/270312 is removed.
 - The versions pinned are the versions used at the time of the
   last rpc-repo build. This is to ensure that this tag implements
   the same version of all the packages used as the time the tag
   repo was built.
 - The SHA for the requirements repository is updated in order to
   include the caps for osprofiler and testtools.

Closes-Bug: 1545505
Change-Id: I61795b3afb4804060d494a08975c10adcf52f468
(cherry picked from commit 6ea8e986f1bc826ffd54477eddc1ea6f04b8ea53)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/05/288005/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/pip_install/defaults/main.yml', 'playbooks/roles/pip_install/tasks/main.yml', 'releasenotes/notes/pip-setuptools-wheel-pins-25494191c4739d52.yaml', 'requirements.txt', 'scripts/sources-branch-updater.sh', 'scripts/scripts-library.sh', 'scripts/get-pypi-pkg-version.py', 'playbooks/inventory/group_vars/hosts.yml']",8,87a69be5eb69b11155bae1d1d8690143d00cb4d0,repeatable-build,# These are pinned to ensure exactly the same behaviour forever! # These pins are updated through the sources-branch-updater script pip_packages: - pip==8.0.3 - setuptools==20.1.1 - wheel==0.29.0,,145,15
openstack%2Fpuppet-nova~master~Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7,openstack/puppet-nova,master,Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7,Only require netaddr when needed,MERGED,2015-12-03 02:54:16.000000000,2016-03-04 20:13:10.000000000,2015-12-03 13:54:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7745}, {'_account_id': 9410}, {'_account_id': 9500}, {'_account_id': 15519}]","[{'number': 1, 'created': '2015-12-03 02:54:16.000000000', 'files': ['lib/puppet/provider/nova_floating/nova_manage.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/cff330053d11620bccea3bb2216c1a787767a3b5', 'message': ""Only require netaddr when needed\n\nNot all functions of the nova_floating provider require the netaddr gem.\nIf this gets autoloaded for dependencies or otherwise, then the netaddr\ngem is required even if the provider isn't instantiated.\n\nChange-Id: Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7\n""}]",0,252720,cff330053d11620bccea3bb2216c1a787767a3b5,10,7,1,10540,,,0,"Only require netaddr when needed

Not all functions of the nova_floating provider require the netaddr gem.
If this gets autoloaded for dependencies or otherwise, then the netaddr
gem is required even if the provider isn't instantiated.

Change-Id: Ic25dece3d4e7574dcac45e3f0e146dcea66ce2e7
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/20/252720/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/nova_floating/nova_manage.rb'],1,cff330053d11620bccea3bb2216c1a787767a3b5,hooks, require 'netaddr' require 'netaddr',require 'netaddr' ,2,2
openstack%2Fnetworking-ovn~master~I4ae2dd79417b8776141843bc5e2db09cd40970c0,openstack/networking-ovn,master,I4ae2dd79417b8776141843bc5e2db09cd40970c0,Run cross-tenant traffic tempest test,MERGED,2016-03-03 20:36:49.000000000,2016-03-04 20:08:33.000000000,2016-03-04 20:08:33.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-03-03 20:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0030700fdbf23dd1e2d834c8665ded855419792b', 'message': 'Run cross-tenant traffic tempest test\n\nChange-Id: I4ae2dd79417b8776141843bc5e2db09cd40970c0\n'}, {'number': 2, 'created': '2016-03-04 15:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/29a66edda8ea59428e047d7a50017ba4e1fc7c46', 'message': 'Run cross-tenant traffic tempest test\n\nChange-Id: I4ae2dd79417b8776141843bc5e2db09cd40970c0\n'}, {'number': 3, 'created': '2016-03-04 16:56:38.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/39d1fbdbd4c14549706d9cd9151160d85c8de07f', 'message': 'Run cross-tenant traffic tempest test\n\nThis test was probably fixed by changing the ""remote_group_id"" support\nto use IP addresses instead of port names in OVN ACLs.  It passes now,\nso re-enable it.\n\nCloses-bug: #1508256\nChange-Id: I4ae2dd79417b8776141843bc5e2db09cd40970c0\n'}]",0,288115,39d1fbdbd4c14549706d9cd9151160d85c8de07f,17,5,3,1561,,,0,"Run cross-tenant traffic tempest test

This test was probably fixed by changing the ""remote_group_id"" support
to use IP addresses instead of port names in OVN ACLs.  It passes now,
so re-enable it.

Closes-bug: #1508256
Change-Id: I4ae2dd79417b8776141843bc5e2db09cd40970c0
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/15/288115/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,0030700fdbf23dd1e2d834c8665ded855419792b,bug/1508256,,"# https://bugs.launchpad.net/networking-ovn/+bug/1508256 r=""$r|(?:tempest\.scenario\.test_security_groups_basic_ops\.TestSecurityGroupsBasicOps\.test_cross_tenant_traffic*)"" ",0,3
openstack%2Fdesignate~master~Icf1b50a9f74ccc2917a43e0d40792afc57b8fd94,openstack/designate,master,Icf1b50a9f74ccc2917a43e0d40792afc57b8fd94,Use assertGreater(),MERGED,2016-03-01 14:36:11.000000000,2016-03-04 20:01:18.000000000,2016-03-04 20:01:16.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 15171}, {'_account_id': 15699}, {'_account_id': 16962}]","[{'number': 1, 'created': '2016-03-01 14:36:11.000000000', 'files': ['designate/tests/test_utils.py', 'designate/tests/unit/test_objects/test_base.py', 'designate/tests/test_central/test_service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/1ad52cf88026dbd8f228875eb812ecbbe5c9cd8c', 'message': 'Use assertGreater()\n\nInstead of using assertTrue(A > B), developers\nshould use assertGreater(A, B).\n\nChange-Id: Icf1b50a9f74ccc2917a43e0d40792afc57b8fd94\n'}]",0,286630,1ad52cf88026dbd8f228875eb812ecbbe5c9cd8c,11,5,1,18603,,,0,"Use assertGreater()

Instead of using assertTrue(A > B), developers
should use assertGreater(A, B).

Change-Id: Icf1b50a9f74ccc2917a43e0d40792afc57b8fd94
",git fetch https://review.opendev.org/openstack/designate refs/changes/30/286630/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/test_utils.py', 'designate/tests/unit/test_objects/test_base.py', 'designate/tests/test_central/test_service.py']",3,1ad52cf88026dbd8f228875eb812ecbbe5c9cd8c,," self.assertGreater(len(servers), 0) self.assertGreater(zone.serial, original_serial) self.assertGreater(zone.serial, original_serial) self.assertGreater(zone['serial'], expected_zone['serial'])", self.assertTrue(len(servers) > 0) self.assertTrue(zone.serial > original_serial) self.assertTrue(zone.serial > original_serial) self.assertTrue(zone['serial'] > expected_zone['serial']),6,6
openstack%2Fpuppet-ceph~master~I9b190f9e928dbafb41477d939032390144fb0e5f,openstack/puppet-ceph,master,I9b190f9e928dbafb41477d939032390144fb0e5f,Update supported version information,MERGED,2016-02-08 21:05:51.000000000,2016-03-04 19:57:28.000000000,2016-03-04 19:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 2064}, {'_account_id': 8797}, {'_account_id': 9061}, {'_account_id': 11479}, {'_account_id': 13344}]","[{'number': 1, 'created': '2016-02-08 21:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/9c09728fbdc5fad6ac021173d1125080cc50db4f', 'message': 'Update supported version information\n\nThis updates the supported versions to what is supported by Ceph\nstarting with infernalis.\n\n* CentOS 7 or later\n* Debian Jessie 8.x or later\n* Ubuntu Trusty 14.04 or later\n* Fedora 22 or later.\n\nChange-Id: I9b190f9e928dbafb41477d939032390144fb0e5f\n'}, {'number': 2, 'created': '2016-02-08 22:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/e6833f34044924d6bd382aa338be4baccdd7a4ca', 'message': 'Update supported version information\n\nThis updates the supported versions to what is supported by Ceph\nstarting with infernalis.\n\n* CentOS 7 or later\n* Debian Jessie 8.x or later\n* Ubuntu Trusty 14.04 or later\n* Fedora 22 or later.\n\nChange-Id: I9b190f9e928dbafb41477d939032390144fb0e5f\n'}, {'number': 3, 'created': '2016-02-08 23:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/b1196ef232ff795ebf339182a4dac213f38dc923', 'message': 'Update supported version information\n\nThis updates the supported versions to what is supported by Ceph\nstarting with infernalis.\n\n* CentOS 7 or later\n* Debian Jessie 8.x or later\n* Ubuntu Trusty 14.04 or later\n* Fedora 22 or later\n\nChange-Id: I9b190f9e928dbafb41477d939032390144fb0e5f\n'}, {'number': 4, 'created': '2016-02-11 19:04:32.000000000', 'files': ['spec/classes/ceph_profile_params_spec.rb', 'metadata.json', 'spec/classes/ceph_profile_base_spec.rb', 'spec/classes/ceph_profile_osd_spec.rb', 'spec/defines/ceph_rgw_keystone_spec.rb', 'spec/classes/ceph_profile_client_spec.rb', 'spec/classes/ceph_profile_mon_spec.rb', 'spec/classes/ceph_repo_spec.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/5fbe54f026ec4094c09b260b6042367d9089fe71', 'message': 'Update supported version information\n\nThis updates the supported versions to what is supported by Ceph\nstarting with infernalis.\n\n* CentOS 7 or later\n* Debian Jessie 8.x or later\n* Ubuntu Trusty 14.04 or later\n* Fedora 22 or later\n\nChange-Id: I9b190f9e928dbafb41477d939032390144fb0e5f\n'}]",0,277562,5fbe54f026ec4094c09b260b6042367d9089fe71,24,6,4,11479,,,0,"Update supported version information

This updates the supported versions to what is supported by Ceph
starting with infernalis.

* CentOS 7 or later
* Debian Jessie 8.x or later
* Ubuntu Trusty 14.04 or later
* Fedora 22 or later

Change-Id: I9b190f9e928dbafb41477d939032390144fb0e5f
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/62/277562/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceph_profile_params_spec.rb', 'metadata.json', 'spec/classes/ceph_profile_base_spec.rb', 'spec/classes/ceph_profile_osd_spec.rb', 'spec/defines/ceph_rgw_keystone_spec.rb', 'manifests/repo.pp', 'spec/classes/ceph_profile_client_spec.rb', 'spec/classes/ceph_profile_mon_spec.rb', 'spec/classes/ceph_repo_spec.rb']",9,9c09728fbdc5fad6ac021173d1125080cc50db4f,update_supported_versions," :lsbdistcodename => 'jessie', :release => 'jessie', :release => 'jessie',"," :lsbdistcodename => 'wheezy', :release => 'wheezy', :release => 'wheezy',",16,19
openstack%2Fpython-neutronclient~master~If21c3be96b39240ce2d61be75633f6f84d7d35f5,openstack/python-neutronclient,master,If21c3be96b39240ce2d61be75633f6f84d7d35f5,Updated from global requirements,MERGED,2016-03-03 18:06:24.000000000,2016-03-04 19:52:21.000000000,2016-03-04 19:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 9656}, {'_account_id': 14605}, {'_account_id': 16272}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-03-03 18:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/87f2ae39c5d51f31bbcc8f87c1fb46b2d29756b3', 'message': 'Updated from global requirements\n\nChange-Id: If21c3be96b39240ce2d61be75633f6f84d7d35f5\n'}, {'number': 2, 'created': '2016-03-04 14:22:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5d28651f9b482de1ab3081b3b828eb3781f2fd3a', 'message': 'Updated from global requirements\n\nChange-Id: If21c3be96b39240ce2d61be75633f6f84d7d35f5\n'}]",0,288032,5d28651f9b482de1ab3081b3b828eb3781f2fd3a,14,6,2,11131,,,0,"Updated from global requirements

Change-Id: If21c3be96b39240ce2d61be75633f6f84d7d35f5
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/32/288032/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,87f2ae39c5d51f31bbcc8f87c1fb46b2d29756b3,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Fnetworking-ovn~master~I92ecb4b21a5581a925c164953df0710ead5eb402,openstack/networking-ovn,master,I92ecb4b21a5581a925c164953df0710ead5eb402,Update supported API extensions for tempest.,MERGED,2016-03-03 21:42:09.000000000,2016-03-04 19:50:41.000000000,2016-03-04 19:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-03-03 21:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b813ac319569d566c5b879b47b2b5f3bdb10a300', 'message': 'Update supported API extensions for tempest.\n\nI noticed in a tempest log that it thought security groups were\ndisabled.  This is because our list of enabled API extensions for the\ntempest config was not up to date.  Sort the list in the plugin and\nupdate the devstack plugin to match.\n\nChange-Id: I92ecb4b21a5581a925c164953df0710ead5eb402\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 2, 'created': '2016-03-04 14:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e0b8a0bee7bcccb4810b1d6970600feb9dae85b4', 'message': 'Update supported API extensions for tempest.\n\nI noticed in a tempest log that it thought security groups were\ndisabled.  This is because our list of enabled API extensions for the\ntempest config was not up to date.  Sort the list in the plugin and\nupdate the devstack plugin to always use the same list as the plugin.\n\nChange-Id: I92ecb4b21a5581a925c164953df0710ead5eb402\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 3, 'created': '2016-03-04 15:22:08.000000000', 'files': ['networking_ovn/common/extensions.py', 'devstack/plugin.sh', 'networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6b9d0fff2d643f2bc6443d629a789871eddf1a99', 'message': 'Update supported API extensions for tempest.\n\nI noticed in a tempest log that it thought security groups were\ndisabled.  This is because our list of enabled API extensions for the\ntempest config was not up to date.  Sort the list in the plugin and\nupdate the devstack plugin to always use the same list as the plugin.\n\nChange-Id: I92ecb4b21a5581a925c164953df0710ead5eb402\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",7,288142,6b9d0fff2d643f2bc6443d629a789871eddf1a99,20,5,3,1561,,,0,"Update supported API extensions for tempest.

I noticed in a tempest log that it thought security groups were
disabled.  This is because our list of enabled API extensions for the
tempest config was not up to date.  Sort the list in the plugin and
update the devstack plugin to always use the same list as the plugin.

Change-Id: I92ecb4b21a5581a925c164953df0710ead5eb402
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/42/288142/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'networking_ovn/plugin.py']",2,b813ac319569d566c5b879b47b2b5f3bdb10a300,tempest-api-extensions," # NOTE(russellb) If you add an extension here, you should also add it to # the NETWORK_API_EXTENSIONS setting in devstack/plugin.sh. supported_extension_aliases = [""agent"", ""availability_zone"", ""external-net"", ""extra_dhcp_opt"", ""extraroute"", ""net-mtu"", ""provider"", ""quotas"", ""router"", ""security-group"", ""subnet_allocation""]"," supported_extension_aliases = [""quotas"", ""extra_dhcp_opt"", ""agent"", ""security-group"", ""extraroute"", ""external-net"", ""router"", ""provider"", ""subnet_allocation"", ""availability_zone"", ""net-mtu""]",17,12
openstack%2Fnetworking-ovn~master~I0d704563334e27095a097029312d12ef6427a155,openstack/networking-ovn,master,I0d704563334e27095a097029312d12ef6427a155,Fix QoS unit tests.,MERGED,2016-03-04 15:22:08.000000000,2016-03-04 19:47:26.000000000,2016-03-04 19:47:26.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 8410}, {'_account_id': 9515}]","[{'number': 1, 'created': '2016-03-04 15:22:08.000000000', 'files': ['networking_ovn/tests/unit/test_ovn_plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e40922c470240a4bf3ac54ef53bd26d73cc59b68', 'message': 'Fix QoS unit tests.\n\nFix QoS unit tests to account for the following commit in Neutron:\n4b227c3771eba1cbaa27c6c33829108981cd9b69\n\nChange-Id: I0d704563334e27095a097029312d12ef6427a155\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,288524,e40922c470240a4bf3ac54ef53bd26d73cc59b68,8,4,1,1561,,,0,"Fix QoS unit tests.

Fix QoS unit tests to account for the following commit in Neutron:
4b227c3771eba1cbaa27c6c33829108981cd9b69

Change-Id: I0d704563334e27095a097029312d12ef6427a155
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/24/288524/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/tests/unit/test_ovn_plugin.py'],1,e40922c470240a4bf3ac54ef53bd26d73cc59b68,tempest-api-extensions, qos_policy.QosPolicy.get_object = mock.MagicMock(, qos_policy.QosPolicy.get_by_id = mock.MagicMock(,1,1
openstack%2Freleases~master~I4a0cd5c8af4c601fa7074b798964a92050835e6c,openstack/releases,master,I4a0cd5c8af4c601fa7074b798964a92050835e6c,Add tempest releases to releases.o.o,MERGED,2016-03-04 16:43:03.000000000,2016-03-04 19:42:52.000000000,2016-03-04 19:42:52.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-03-04 16:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7ea3574c0d9f9dd9f9b1b52d2c54c31e34a4738d', 'message': 'Add tempest releases to releases.o.o\n\nChange-Id: I4a0cd5c8af4c601fa7074b798964a92050835e6c\n'}, {'number': 2, 'created': '2016-03-04 17:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d88126a25a404148736f9bf3403c57086b58600a', 'message': 'Add tempest releases to releases.o.o\n\nChange-Id: I4a0cd5c8af4c601fa7074b798964a92050835e6c\n'}, {'number': 3, 'created': '2016-03-04 18:52:15.000000000', 'files': ['deliverables/mitaka/tempest.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ea1e198c2859f49f8a8f468741755bf84e189a29', 'message': 'Add tempest releases to releases.o.o\n\nChange-Id: I4a0cd5c8af4c601fa7074b798964a92050835e6c\n'}]",0,288575,ea1e198c2859f49f8a8f468741755bf84e189a29,9,3,3,5196,,,0,"Add tempest releases to releases.o.o

Change-Id: I4a0cd5c8af4c601fa7074b798964a92050835e6c
",git fetch https://review.opendev.org/openstack/releases refs/changes/75/288575/3 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/tempest.yaml'],1,7ea3574c0d9f9dd9f9b1b52d2c54c31e34a4738d,288575,--- launchpad: tempest send-announcements-to: openstack-dev@lists.openstack.org include-pypi-link: yes releases: - version: 10.0.0 projects: - repo: openstack/tempest hash: 09a60155435cfb8bfd1edb6eab3d4bec30515b8f - version: 9 projects: - repo: openstack/tempest hash: 9ccf77af488c3b6464356b6fab106ec78e3b7c51 - version: 8 projects: - repo: openstack/tempest hash: 600d40a30548310b96ee08d5a7a9d3541ba93343 ,,17,0
openstack%2Fpuppet-ceph~master~I35337ef6c74958cfcd04cf1710832e3558cd6866,openstack/puppet-ceph,master,I35337ef6c74958cfcd04cf1710832e3558cd6866,Fix documentation duplicate in rgw.pp,MERGED,2016-02-29 16:34:30.000000000,2016-03-04 19:40:09.000000000,2016-03-04 19:40:09.000000000,"[{'_account_id': 3}, {'_account_id': 7888}, {'_account_id': 8797}, {'_account_id': 11479}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-29 16:34:30.000000000', 'files': ['manifests/rgw.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/a796cb0b0181aca4bbf1057a2cb3e7fff215756d', 'message': 'Fix documentation duplicate in rgw.pp\n\nChange-Id: I35337ef6c74958cfcd04cf1710832e3558cd6866\n'}]",0,286143,a796cb0b0181aca4bbf1057a2cb3e7fff215756d,10,5,1,13344,,,0,"Fix documentation duplicate in rgw.pp

Change-Id: I35337ef6c74958cfcd04cf1710832e3558cd6866
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/43/286143/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/rgw.pp'],1,a796cb0b0181aca4bbf1057a2cb3e7fff215756d,bug/civitweb,# [*syslog*] Whether or not to log to syslog. # Optional. Default is true. #,# Optional. Default is apache-fastcgi. Other option is apache-proxy-fcgi. # # [*rgw_frontends*] String for rgw_frontends config. # Optional. Default is 'fastcgi socket_port=9000 socket_host=127.0.0.1'. # # [*syslog*] Whether or not to log to syslog. # Optional. Default is true. # # [*frontend_type*] What type of frontend to use,3,9
openstack%2Fopenstack-ansible-openstack_hosts~master~Ic4d555794578c11e2fc4ed8e3e9305d17247bbb4,openstack/openstack-ansible-openstack_hosts,master,Ic4d555794578c11e2fc4ed8e3e9305d17247bbb4,Initial commit for bindep requirements,MERGED,2016-03-03 15:13:01.000000000,2016-03-04 19:34:20.000000000,2016-03-04 19:34:20.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 15:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/043a598179e4d8deb1acc77d9591449d17bbc681', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ic4d555794578c11e2fc4ed8e3e9305d17247bbb4\n'}, {'number': 2, 'created': '2016-03-04 10:12:07.000000000', 'files': ['other-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/7626a8418143980903e685ea5cc1a51e171ade11', 'message': 'Initial commit for bindep requirements\n\nChange-Id: Ic4d555794578c11e2fc4ed8e3e9305d17247bbb4\n'}]",0,287877,7626a8418143980903e685ea5cc1a51e171ade11,9,3,2,6816,,,0,"Initial commit for bindep requirements

Change-Id: Ic4d555794578c11e2fc4ed8e3e9305d17247bbb4
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/77/287877/1 && git format-patch -1 --stdout FETCH_HEAD,['other-requirements.txt'],1,043a598179e4d8deb1acc77d9591449d17bbc681,bindep-requirements,"# This file facilitates OpenStack-CI package installation # before the execution of any tests. # # See the following for details: # - http://docs.openstack.org/infra/bindep/ # - https://github.com/openstack-infra/bindep # # Even if the role does not make use of this facility, it # is better to have this file empty, otherwise OpenStack-CI # will fall back to installing its default packages which # will potentially be detrimental to the tests executed. ",,11,0
openstack%2Fopenstack-ansible-openstack_hosts~master~Ia59123aca3c56ffd09337a17d2630432c945356b,openstack/openstack-ansible-openstack_hosts,master,Ia59123aca3c56ffd09337a17d2630432c945356b,Tests: Ensure that the apt cache is always refreshed,MERGED,2016-03-04 10:10:53.000000000,2016-03-04 19:34:14.000000000,2016-03-04 19:34:14.000000000,"[{'_account_id': 3}, {'_account_id': 12807}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-03-04 10:10:53.000000000', 'files': ['tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/fdd067d8871b6c570d1af2296ca6a9487ab64baf', 'message': 'Tests: Ensure that the apt cache is always refreshed\n\nChange-Id: Ia59123aca3c56ffd09337a17d2630432c945356b\n'}]",0,288341,fdd067d8871b6c570d1af2296ca6a9487ab64baf,7,3,1,6816,,,0,"Tests: Ensure that the apt cache is always refreshed

Change-Id: Ia59123aca3c56ffd09337a17d2630432c945356b
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/41/288341/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test.yml'],1,fdd067d8871b6c570d1af2296ca6a9487ab64baf,bindep-requirements, pre_tasks: - name: First ensure apt cache is always refreshed apt: update_cache: yes,,4,0
openstack%2Foslo.cache~master~I1be116b4a9e1ceccde2f21733ccb16b0a074cf41,openstack/oslo.cache,master,I1be116b4a9e1ceccde2f21733ccb16b0a074cf41,Updated from global requirements,MERGED,2016-03-04 14:21:20.000000000,2016-03-04 19:33:39.000000000,2016-03-04 19:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 14:21:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/efc1a96518b3c3e2fdd995ea5138b9cc03443ae7', 'message': 'Updated from global requirements\n\nChange-Id: I1be116b4a9e1ceccde2f21733ccb16b0a074cf41\n'}]",0,288474,efc1a96518b3c3e2fdd995ea5138b9cc03443ae7,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1be116b4a9e1ceccde2f21733ccb16b0a074cf41
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/74/288474/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,efc1a96518b3c3e2fdd995ea5138b9cc03443ae7,openstack/requirements,dogpile.cache>=0.5.7 # BSD,dogpile.cache>=0.5.4 # BSD,1,1
openstack%2Fswift~master~I3ea4b529025c8ac3c4092f3720124647861e6668,openstack/swift,master,I3ea4b529025c8ac3c4092f3720124647861e6668,Remove unused pngmath Sphinx extension,MERGED,2016-02-29 19:00:55.000000000,2016-03-04 19:32:16.000000000,2016-03-04 19:32:13.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 20541}]","[{'number': 1, 'created': '2016-02-29 19:00:55.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/087fa4fa01fc36343f2ce0974d3b36ec0b98afc8', 'message': 'Remove unused pngmath Sphinx extension\n\nThere\'s no RST file that uses "".. math"" and thus\nthe pngmath Sphinx extension is not used and can\nget removed.\n\nChange-Id: I3ea4b529025c8ac3c4092f3720124647861e6668\n'}]",0,286226,087fa4fa01fc36343f2ce0974d3b36ec0b98afc8,9,4,1,6547,,,0,"Remove unused pngmath Sphinx extension

There's no RST file that uses "".. math"" and thus
the pngmath Sphinx extension is not used and can
get removed.

Change-Id: I3ea4b529025c8ac3c4092f3720124647861e6668
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/286226/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,087fa4fa01fc36343f2ce0974d3b36ec0b98afc8,pngmath," 'sphinx.ext.todo', 'sphinx.ext.coverage',"," 'sphinx.ext.todo', 'sphinx.ext.coverage', 'sphinx.ext.pngmath',",1,1
openstack%2Frequirements~master~Iba93963f5e633f3711b26e7eed16a5b623e7683d,openstack/requirements,master,Iba93963f5e633f3711b26e7eed16a5b623e7683d,Add Freezer modules and projects for Mitaka release,MERGED,2016-01-21 22:51:40.000000000,2016-03-04 19:32:07.000000000,2016-03-04 19:32:06.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 8871}, {'_account_id': 11151}, {'_account_id': 14340}]","[{'number': 1, 'created': '2016-01-21 22:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/314a10e1c01185b2c556aa3fd5ace76d97ec2819', 'message': 'Add modules for freezer mitaka m2 release\n\nAdded the following modules to global-requirements.txt\n- pytest\n- pytest-cov\n- pytest\n- pytest-xdist\n- apscheduler\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: 03ad0cffdb9eda0c796b4ce6d0ed07aa80ce87ef\n'}, {'number': 2, 'created': '2016-01-21 22:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6d1039c5ea5164005ae0efd51dad8c847b94b07f', 'message': 'Add modules for freezer mitaka m2 release\n\nAdded the following modules to global-requirements.txt\n- pytest\n- pytest-cov\n- pytest-xdist\n- apscheduler\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: 03ad0cffdb9eda0c796b4ce6d0ed07aa80ce87ef\n'}, {'number': 3, 'created': '2016-01-22 08:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/229cc560141bc34dfee8cd8b5a9035080784a222', 'message': 'Add modules for freezer mitaka m2 release\n\nAdded the following modules to global-requirements.txt\n- pytest\n- pytest-cov\n- pytest-xdist\n- apscheduler\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: 03ad0cffdb9eda0c796b4ce6d0ed07aa80ce87ef\n'}, {'number': 4, 'created': '2016-01-23 13:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a9049343edd87d05f0aaa4af5719e55f75ae5369', 'message': 'Add modules for freezer mitaka m2 release\n\nAdded the following modules to global-requirements.txt\nand upper-contraints.txt:\n- pytest\n- pytest-cov\n- pytest-xdist\n- apscheduler\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: 03ad0cffdb9eda0c796b4ce6d0ed07aa80ce87ef\n'}, {'number': 5, 'created': '2016-02-06 22:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/78e5c205e0503e9acaf45125de2b0891f1b987d0', 'message': 'Add modules for freezer Mitaka M3 release\n\nAdded the following modules to global-requirements.txt\nand upper-contraints.txt:\n- pytest\n- pytest-cov\n- pytest-xdist\n- apscheduler\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: Iae75d00f6b3d18c55b32fd11b91836a1ce4ddd95\n'}, {'number': 6, 'created': '2016-03-01 09:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/14eb711433413236386fc05fdbeda7678233085c', 'message': ""Add modules for freezer Mitaka release\n\nAdded the following modules to global-requirements.txt\nand upper-contraints.txt:\n\n- apscheduler\nIs the library actively maintained?\nYes, last version releaset 2015-12-10 as per\n    - https://pypi.python.org/pypi/APScheduler/3.0.5\n\nIs the library good code?\nThe library provides:\n    Tests:\n    - https://bitbucket.org/agronholm/apscheduler/src/a6545cf29831?at=master\n    Extensive documentation:\n    - http://apscheduler.readthedocs.org/en/3.0/\n    Active bug tracking:\n    - https://bitbucket.org/agronholm/apscheduler/issues?status-new&status-open\n\nIs the library python 3 compatible?\n    - It support ptyhon>=3.3\n\nIs the library license compatible?\n    - Library license is MIT, thus a compatible license\n\nIs the library already packaged in the distros we target (Ubuntu latest / Fedora latest)?\n    - Debian:\n        - https://packages.debian.org/jessie/all/python-apscheduler/download\n    - Fedora:\n        - https://admin.fedoraproject.org/pkgdb/package/rpms/python-APScheduler/\n\nIs the function of this library already covered by other libraries in global-requirements.txt\n    - As far as we can see, there's not other scheduling related module available.\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: Iae75d00f6b3d18c55b32fd11b91836a1ce4ddd95\n""}, {'number': 7, 'created': '2016-03-01 11:30:34.000000000', 'files': ['global-requirements.txt', 'projects.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fec995f220f4c643cbfbb97c857a79851a08f752', 'message': ""Add Freezer modules and projects for Mitaka release\n\nAdded the following modules to global-requirements.txt\nand upper-contraints.txt:\n\n- apscheduler\nIs the library actively maintained?\nYes, last version releaset 2015-12-10 as per\n    - https://pypi.python.org/pypi/APScheduler/3.0.5\n\nIs the library good code?\nThe library provides:\n    Tests:\n    - https://bitbucket.org/agronholm/apscheduler/src/a6545cf29831?at=master\n    Extensive documentation:\n    - http://apscheduler.readthedocs.org/en/3.0/\n    Active bug tracking:\n    - https://bitbucket.org/agronholm/apscheduler/issues?status-new&status-open\n\nIs the library python 3 compatible?\n    - It support ptyhon>=3.3\n\nIs the library license compatible?\n    - Library license is MIT, thus a compatible license\n\nIs the library already packaged in the distros we target (Ubuntu latest / Fedora latest)?\n    - Debian:\n        - https://packages.debian.org/jessie/all/python-apscheduler/download\n    - Fedora:\n        - https://admin.fedoraproject.org/pkgdb/package/rpms/python-APScheduler/\n\nIs the function of this library already covered by other libraries in global-requirements.txt\n    - As far as we can see, there's not other scheduling related module available.\n\nChange-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d\nDepends-On: Iae75d00f6b3d18c55b32fd11b91836a1ce4ddd95\n""}]",1,271072,fec995f220f4c643cbfbb97c857a79851a08f752,33,6,7,11151,,,0,"Add Freezer modules and projects for Mitaka release

Added the following modules to global-requirements.txt
and upper-contraints.txt:

- apscheduler
Is the library actively maintained?
Yes, last version releaset 2015-12-10 as per
    - https://pypi.python.org/pypi/APScheduler/3.0.5

Is the library good code?
The library provides:
    Tests:
    - https://bitbucket.org/agronholm/apscheduler/src/a6545cf29831?at=master
    Extensive documentation:
    - http://apscheduler.readthedocs.org/en/3.0/
    Active bug tracking:
    - https://bitbucket.org/agronholm/apscheduler/issues?status-new&status-open

Is the library python 3 compatible?
    - It support ptyhon>=3.3

Is the library license compatible?
    - Library license is MIT, thus a compatible license

Is the library already packaged in the distros we target (Ubuntu latest / Fedora latest)?
    - Debian:
        - https://packages.debian.org/jessie/all/python-apscheduler/download
    - Fedora:
        - https://admin.fedoraproject.org/pkgdb/package/rpms/python-APScheduler/

Is the function of this library already covered by other libraries in global-requirements.txt
    - As far as we can see, there's not other scheduling related module available.

Change-Id: Iba93963f5e633f3711b26e7eed16a5b623e7683d
Depends-On: Iae75d00f6b3d18c55b32fd11b91836a1ce4ddd95
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/271072/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,314a10e1c01185b2c556aa3fd5ace76d97ec2819,(detached,apscheduler # MIT Licensepytest # MIT License pytest-cov # MIT License pytest-xdist # MIT License,,4,0
openstack%2Fapi-site~master~I0641e0f616fcfaf8113b40fb1044a24490de736d,openstack/api-site,master,I0641e0f616fcfaf8113b40fb1044a24490de736d,Correct the reference method id,MERGED,2016-02-13 07:09:45.000000000,2016-03-04 19:31:43.000000000,2016-03-04 19:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 13702}]","[{'number': 1, 'created': '2016-02-13 07:09:45.000000000', 'files': ['api-ref/src/wadls/networking-api/src/wadl/lbaas-v2.0.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/5ff1dcbe268f6670905b2e723113ae2f28123d22', 'message': 'Correct the reference method id\n\nCorrecting the method id to listHealthMonitorsv2 from\nlistHealthMonitors as there is no tag refering to\nlistHealthMonitors.\n\nCloses-Bug: #1545080\n\nChange-Id: I0641e0f616fcfaf8113b40fb1044a24490de736d\n'}]",0,279866,5ff1dcbe268f6670905b2e723113ae2f28123d22,7,3,1,19840,,,0,"Correct the reference method id

Correcting the method id to listHealthMonitorsv2 from
listHealthMonitors as there is no tag refering to
listHealthMonitors.

Closes-Bug: #1545080

Change-Id: I0641e0f616fcfaf8113b40fb1044a24490de736d
",git fetch https://review.opendev.org/openstack/api-site refs/changes/66/279866/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/networking-api/src/wadl/lbaas-v2.0.wadl'],1,5ff1dcbe268f6670905b2e723113ae2f28123d22,bug/1545080," <method name=""GET"" id=""listHealthMonitorsv2"">"," <method name=""GET"" id=""listHealthMonitors"">",1,1
openstack%2Fapi-site~master~Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0,openstack/api-site,master,Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0,Add cluster api into bk-api-ref,MERGED,2016-02-20 08:38:36.000000000,2016-03-04 19:31:36.000000000,2016-03-04 19:31:36.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-20 08:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/262b9e362647da11c832aafed94f89307f1d5fe9', 'message': 'Add cluster api into bk-api-ref\n\nIn the bk-api-ref.pdf generated, clustering API v1 section is missing.\nThis turned out to be a missing line in the book configuration.\n\nChange-Id: Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0\n'}, {'number': 2, 'created': '2016-02-20 09:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/2dcccbf2c61a3c6f0c8011775daa93addec1034a', 'message': 'Add cluster api into bk-api-ref\n\nIn the bk-api-ref.pdf generated, clustering API v1 section is missing.\nThis turned out to be a missing line in the book configuration.\n\nChange-Id: Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0\n'}, {'number': 3, 'created': '2016-02-21 06:44:23.000000000', 'files': ['api-ref-guides/src/bk-api-ref-clustering-v1.xml', 'api-ref-guides/src/bk-api-ref.xml', 'api-ref/src/docbkx/ch_clustering-v1.xml', 'api-ref/src/docbkx/api-ref-clustering-v1.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8062bb27b3272f54d07ecd0223b0993d60cb128f', 'message': 'Add cluster api into bk-api-ref\n\nIn the bk-api-ref.pdf generated, clustering API v1 section is missing.\nThis turned out to be a missing line in the book configuration.\n\nChange-Id: Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0\n'}]",0,282627,8062bb27b3272f54d07ecd0223b0993d60cb128f,16,5,3,8246,,,0,"Add cluster api into bk-api-ref

In the bk-api-ref.pdf generated, clustering API v1 section is missing.
This turned out to be a missing line in the book configuration.

Change-Id: Ie3a1b4c7c3041b67ce15159c4c0cd627e55c61d0
",git fetch https://review.opendev.org/openstack/api-site refs/changes/27/282627/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref-guides/src/bk-api-ref-clustering-v1.xml', 'api-ref-guides/src/bk-api-ref.xml', 'api-ref/src/docbkx/ch_clustering-v1.xml', 'api-ref/src/docbkx/api-ref-clustering-v1.xml']",4,262b9e362647da11c832aafed94f89307f1d5fe9,fix-cluster-api-inclusion, <year>2015-2016</year>, <year>2015</year>,5,3
openstack%2Fgnocchi~master~I66d01023d3fe78038aa61a5be9c93a346e3d4726,openstack/gnocchi,master,I66d01023d3fe78038aa61a5be9c93a346e3d4726,Pass aggregation when create AggregatedTimeSerie,MERGED,2016-03-04 15:46:57.000000000,2016-03-04 19:30:25.000000000,2016-03-04 19:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-03-04 15:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e4eeb30b1080f1e5a2c5a7d610cc27e5c691a7ec', 'message': 'Pass aggregation when create AggregatedTimeSerie\n\nChange-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726\nCloses-bug: #1552437\n'}, {'number': 2, 'created': '2016-03-04 17:38:07.000000000', 'files': ['gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/23262820683421c604c8be636cfe5afa584b1356', 'message': 'Pass aggregation when create AggregatedTimeSerie\n\nChange-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726\nCloses-bug: #1552437\n'}]",0,288537,23262820683421c604c8be636cfe5afa584b1356,10,2,2,2813,,,0,"Pass aggregation when create AggregatedTimeSerie

Change-Id: I66d01023d3fe78038aa61a5be9c93a346e3d4726
Closes-bug: #1552437
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/37/288537/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py']",2,e4eeb30b1080f1e5a2c5a7d610cc27e5c691a7ec,bug/1552437," def test_updated_measures(self): self.storage.add_measures(self.metric, [ storage.Measure(datetime.datetime(2014, 1, 1, 12, 0, 1), 69), storage.Measure(datetime.datetime(2014, 1, 1, 12, 7, 31), 42), ]) self.storage.process_background_tasks(self.index, sync=True) self.storage.add_measures(self.metric, [ storage.Measure(datetime.datetime(2014, 1, 1, 12, 9, 31), 4), storage.Measure(datetime.datetime(2014, 1, 1, 12, 12, 45), 44), ]) self.storage.process_background_tasks(self.index, sync=True) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 39.75), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 39.75), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 23.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric)) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 69), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 42.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric, aggregation='max')) self.assertEqual([ (utils.datetime_utc(2014, 1, 1), 86400.0, 4), (utils.datetime_utc(2014, 1, 1, 12), 3600.0, 4), (utils.datetime_utc(2014, 1, 1, 12), 300.0, 69.0), (utils.datetime_utc(2014, 1, 1, 12, 5), 300.0, 4.0), (utils.datetime_utc(2014, 1, 1, 12, 10), 300.0, 44.0), ], self.storage.get_measures(self.metric, aggregation='min')) ",,38,0
openstack%2Ftripleo-heat-templates~master~If99f37634d5da7e7fb7cfc31232e926bd5ff074a,openstack/tripleo-heat-templates,master,If99f37634d5da7e7fb7cfc31232e926bd5ff074a,Allow for usage of pre-allocated IPs for the management network,MERGED,2016-02-11 11:01:41.000000000,2016-03-04 19:29:53.000000000,2016-03-04 19:29:53.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-02-11 11:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c3fc88cf3d82c66c9e523487a4249b57fdcd06d', 'message': 'Allow for usage of pre-allocated IPs for the management network\n\nId3d4f12235501ae77200430a2dc022f378dce336 added support for pre-allocated\nIPs on the other overlay networks, but because the patch adding the\nmanagment network (I0813a13f60a4f797be04b34258a2cffa9ea7e84f) was\nunder review around the same time, we missed adding the from_pool\ncapability to the ManagementNetwork.\n\nChange-Id: If99f37634d5da7e7fb7cfc31232e926bd5ff074a\n'}, {'number': 2, 'created': '2016-02-11 11:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0cc3d70d31a8d510990b906d394489e34a67d544', 'message': 'Allow for usage of pre-allocated IPs for the management network\n\nId3d4f12235501ae77200430a2dc022f378dce336 added support for pre-allocated\nIPs on the other overlay networks, but because the patch adding the\nmanagment network (I0813a13f60a4f797be04b34258a2cffa9ea7e84f) was\nunder review around the same time, we missed adding the from_pool\ncapability to the ManagementNetwork.\n\nChange-Id: If99f37634d5da7e7fb7cfc31232e926bd5ff074a\n'}, {'number': 3, 'created': '2016-03-04 13:35:12.000000000', 'files': ['network/ports/management_from_pool.yaml', 'puppet/controller.yaml', 'environments/external-loadbalancer-vip.yaml', 'network/ports/management.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/07e99fef9ba96dd9a650ef43560e6a7794939a20', 'message': 'Allow for usage of pre-allocated IPs for the management network\n\nId3d4f12235501ae77200430a2dc022f378dce336 added support for pre-allocated\nIPs on the other overlay networks, but because the patch adding the\nmanagment network (I0813a13f60a4f797be04b34258a2cffa9ea7e84f) was\nunder review around the same time, we missed adding the from_pool\ncapability to the ManagementNetwork.\n\nChange-Id: If99f37634d5da7e7fb7cfc31232e926bd5ff074a\n'}]",9,278979,07e99fef9ba96dd9a650ef43560e6a7794939a20,29,5,3,4328,,,0,"Allow for usage of pre-allocated IPs for the management network

Id3d4f12235501ae77200430a2dc022f378dce336 added support for pre-allocated
IPs on the other overlay networks, but because the patch adding the
managment network (I0813a13f60a4f797be04b34258a2cffa9ea7e84f) was
under review around the same time, we missed adding the from_pool
capability to the ManagementNetwork.

Change-Id: If99f37634d5da7e7fb7cfc31232e926bd5ff074a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/278979/3 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/controller.yaml', 'environments/external-loadbalancer-vip.yaml', 'network/ports/management.yaml']",3,0c3fc88cf3d82c66c9e523487a4249b57fdcd06d,ipv6, IPPool: # Here for compatibility with from_pool.yaml default: {} type: json NodeIndex: # Here for compatibility with from_pool.yaml default: 0 type: number,,11,0
openstack%2Fglance~master~I0f140d9d8bc9654c9badcca8e3fe606df0f6c45a,openstack/glance,master,I0f140d9d8bc9654c9badcca8e3fe606df0f6c45a,Sync glance config examples from configgenerator,ABANDONED,2016-03-04 19:19:39.000000000,2016-03-04 19:29:24.000000000,,[],"[{'number': 1, 'created': '2016-03-04 19:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f7d1b7c9fbcbe0256f1319eb4661f56cad03869b', 'message': 'Sync glance config examples from configgenerator\n\nThis should be the last time reordering happening by the\nconfig generator. In future we should see only actual changes\nbut to get there we need to do this massive change once more.\n\nChange-Id: I0f140d9d8bc9654c9badcca8e3fe606df0f6c45a\n'}, {'number': 2, 'created': '2016-03-04 19:22:56.000000000', 'files': ['etc/glance-glare.conf', 'etc/glance-api.conf', 'etc/glance-manage.conf', 'etc/glance-scrubber.conf', 'etc/glance-registry.conf', 'etc/glance-cache.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/82c5226b477ec2c0c5fc0649a151ba66c4965213', 'message': 'Sync glance config examples from configgenerator\n\nThis should be the last time reordering happening by the\nconfig generator. In future we should see only actual changes\nbut to get there we need to do this massive change once more.\n\nCloses-Bug: 1553330\n\nChange-Id: I0f140d9d8bc9654c9badcca8e3fe606df0f6c45a\n'}]",0,288656,82c5226b477ec2c0c5fc0649a151ba66c4965213,3,0,2,5202,,,0,"Sync glance config examples from configgenerator

This should be the last time reordering happening by the
config generator. In future we should see only actual changes
but to get there we need to do this massive change once more.

Closes-Bug: 1553330

Change-Id: I0f140d9d8bc9654c9badcca8e3fe606df0f6c45a
",git fetch https://review.opendev.org/openstack/glance refs/changes/56/288656/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/glance-glare.conf', 'etc/glance-api.conf', 'etc/glance-manage.conf', 'etc/glance-scrubber.conf', 'etc/glance-registry.conf', 'etc/glance-cache.conf']",6,f7d1b7c9fbcbe0256f1319eb4661f56cad03869b,sync_configs,"# security risk, so use this setting with caution! Setting this to # true overrides the show_image_direct_url option. (boolean value)# Deploy the v3 OpenStack Objects API. (boolean value) # This option is deprecated for removal. # Its value may be silently ignored in the future. #enable_v3_api = false # (port value) # Minimum value: 0# beyond which the cache pruner, if running, starts cleaning the image # cache. (integer value)# The amount of time to let an incomplete image remain in the cache, # before the cache cleaner, if running, will remove the incomplete # image. (integer value)# Base directory that the image cache uses. (string value)# Port the registry server is listening on. (port value) # Minimum value: 0# If set to true, the logging level will be set to DEBUG instead of # the default INFO level. (boolean value)# If set to false, the logging level will be set to WARNING instead of # the default INFO level. (boolean value)# Note that when logging configuration files are used then all logging # configuration is set in the configuration file and other logging # configuration options are ignored (for example, # logging_context_format_string). (string value)# Defines the format string for %%(asctime)s in log records. Default: # %(default)s . This option is ignored if log_config_append is set. # (string value)# (Optional) Name of log file to send logging output to. If no default # is set, logging will go to stderr as defined by use_stderr. This # option is ignored if log_config_append is set. (string value)# (Optional) The base directory used for relative log_file paths. # This option is ignored if log_config_append is set. (string value)# Uses logging handler designed to watch file system. When log file is # moved or removed this handler will open a new log file with # specified path instantaneously. It makes sense only if log_file # option is specified and Linux platform is used. This option is # ignored if log_config_append is set. (boolean value) #watch_log_file = false # will be changed later to honor RFC5424. This option is ignored if # log_config_append is set. (boolean value)# Syslog facility to receive log lines. This option is ignored if # log_config_append is set. (string value)# Log output to standard error. This option is ignored if # log_config_append is set. (boolean value)# Format string to use for log messages when context is undefined. # (string value)# Additional data to append to log message when logging level for the # message is DEBUG. (string value)# Defines the format string for %(user_identity)s that is used in # logging_context_format_string. (string value) #logging_user_identity_format = %(user)s %(tenant)s %(domain)s %(user_domain)s %(project_domain)s # List of package logging levels in logger=LEVEL pairs. This option is # ignored if log_config_append is set. (list value) #default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,dogpile.core.dogpile=INFO","# security risk, so use this setting with caution! The overrides # show_image_direct_url. (boolean value)# (integer value) # Minimum value: 1# beyond which pruner, if running, starts cleaning the images cache. # (integer value)# The amount of time to let an image remain in the cache without being # accessed. (integer value)# Base directory that the Image Cache uses. (string value)# Port the registry server is listening on. (integer value) # Minimum value: 1# Print debugging output (set logging level to DEBUG instead of # default INFO level). (boolean value)# If set to false, will disable INFO logging level, making WARNING the # default. (boolean value)# (string value)# DEPRECATED. A logging.Formatter log message format string which may # use any of the available logging.LogRecord attributes. This option # is deprecated. Please use logging_context_format_string and # logging_default_format_string instead. (string value) #log_format = <None> # Format string for %%(asctime)s in log records. Default: %(default)s # . (string value)# (Optional) Name of log file to output to. If no default is set, # logging will go to stdout. (string value)# (Optional) The base directory used for relative --log-file paths. # (string value)# will be changed later to honor RFC5424. (boolean value)# (Optional) Enables or disables syslog rfc5424 format for logging. If # enabled, prefixes the MSG part of the syslog message with APP-NAME # (RFC5424). The format without the APP-NAME is deprecated in Kilo, # and will be removed in Mitaka, along with this option. (boolean # value) # This option is deprecated for removal. # Its value may be silently ignored in the future. #use_syslog_rfc_format = true # Syslog facility to receive log lines. (string value)# Log output to standard error. (boolean value)# Format string to use for log messages without context. (string # value)# Data to append to log format when level is DEBUG. (string value)# List of logger=LEVEL pairs. (list value) #default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN# This option is deprecated for removal. # Its value may be silently ignored in the future.",1355,993
openstack%2Fapi-site~master~I42fbc5645414af99fedc49d5299c1e15d619d5bd,openstack/api-site,master,I42fbc5645414af99fedc49d5299c1e15d619d5bd,Note that nova libvirt driver no longer honors device name on volume attach,MERGED,2016-02-15 20:45:08.000000000,2016-03-04 19:26:29.000000000,2016-03-04 19:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2016-02-15 20:45:08.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/bc38fb73477a4ac4d031dc3228c4956a6c083f5d', 'message': 'Note that nova libvirt driver no longer honors device name on volume attach\n\nCommit 0283234e837d9faf807e6e8da6ec6321ee56b31a in Liberty changed the\nnova libvirt driver to no longer honor user-supplied device names on the\nvolume attachment request.\n\nThis change updates the API docs to add a note about so users are aware\nthat if they know they are hitting a libvirt-managed compute, device names\nfor volume attachment are auto-generated.\n\nChange-Id: I42fbc5645414af99fedc49d5299c1e15d619d5bd\nCloses-Bug: #1479214\n'}]",0,280391,bc38fb73477a4ac4d031dc3228c4956a6c083f5d,7,3,1,6873,,,0,"Note that nova libvirt driver no longer honors device name on volume attach

Commit 0283234e837d9faf807e6e8da6ec6321ee56b31a in Liberty changed the
nova libvirt driver to no longer honor user-supplied device names on the
volume attachment request.

This change updates the API docs to add a note about so users are aware
that if they know they are hitting a libvirt-managed compute, device names
for volume attachment are auto-generated.

Change-Id: I42fbc5645414af99fedc49d5299c1e15d619d5bd
Closes-Bug: #1479214
",git fetch https://review.opendev.org/openstack/api-site refs/changes/91/280391/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'],1,bc38fb73477a4ac4d031dc3228c4956a6c083f5d,bug/1479214," Note that as of the 12.0.0 Liberty release, the Nova libvirt driver no longer honors a user-supplied device name. This is the same behavior as if the device name parameter is not supplied on the request.",,5,0
openstack%2Fkeystone~master~Ibba9bbebd9f7d0f9dcc0f0ee96d837b412bceb7c,openstack/keystone,master,Ibba9bbebd9f7d0f9dcc0f0ee96d837b412bceb7c,Updated from global requirements,MERGED,2016-03-04 14:17:20.000000000,2016-03-04 19:22:15.000000000,2016-03-04 19:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 14:17:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d6ab5d6a9eb4fc07714a49666537333ccb58e20', 'message': 'Updated from global requirements\n\nChange-Id: Ibba9bbebd9f7d0f9dcc0f0ee96d837b412bceb7c\n'}]",0,288468,9d6ab5d6a9eb4fc07714a49666537333ccb58e20,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ibba9bbebd9f7d0f9dcc0f0ee96d837b412bceb7c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/288468/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9d6ab5d6a9eb4fc07714a49666537333ccb58e20,openstack/requirements,dogpile.cache>=0.5.7 # BSD,dogpile.cache>=0.5.4 # BSD,1,1
openstack%2Fironic-ui~master~Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4,openstack/ironic-ui,master,Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4,Add API services Javascript,MERGED,2016-02-23 12:14:35.000000000,2016-03-04 19:15:53.000000000,2016-03-04 19:15:53.000000000,"[{'_account_id': 3}, {'_account_id': 9717}, {'_account_id': 11655}, {'_account_id': 16628}, {'_account_id': 19380}]","[{'number': 1, 'created': '2016-02-23 12:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/44d65fe819c0f39b7bba0ea379e14f97ceba68b9', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 2, 'created': '2016-02-23 15:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/673cf582aeed37425c14fa830f59757712290425', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 3, 'created': '2016-03-01 15:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/db6787a4520fcfea2b9209082af84debac4674cf', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 4, 'created': '2016-03-02 13:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a06bee4361a1ff040d275d35592d52b7674f1cb0', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 5, 'created': '2016-03-03 12:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/423ff34212188eba530232bac4a69dcbc6d75264', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 6, 'created': '2016-03-03 12:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/0f35276b16ab5c5e127626b856d68b8d3757cfa4', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 7, 'created': '2016-03-03 15:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/37bd46ea15b0eceb58c4325a174eba5ef3c49ead', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 8, 'created': '2016-03-04 11:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/20d0a0707ad8c828d812835bb13633d8e0f56691', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 9, 'created': '2016-03-04 11:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a317073d67aedbebb4b0c6c36267a0549114ec6e', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 10, 'created': '2016-03-04 15:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/3eddfd0e57bc3d0badcd43aaecc8c63bf93d62f1', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 11, 'created': '2016-03-04 16:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/1bc8e27fa306ce5cbf380a256f80df9fba7d223b', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 12, 'created': '2016-03-04 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/71bdbd76721589b3a5a6236568ede853e042a9b7', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}, {'number': 13, 'created': '2016-03-04 18:05:57.000000000', 'files': ['ironic_ui/static/dashboard/admin/ironic/ironic.module.js', 'ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/b8f7d7497d1dfaab6eb81a5e340a234bc0a7e2d9', 'message': 'Add API services Javascript\n\nThis will support the node-details and node-list controllers.\n\nChange-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4\nCo-Authored-By: Peter Piela <ppiela@cray.com>\n'}]",13,283540,b8f7d7497d1dfaab6eb81a5e340a234bc0a7e2d9,44,5,13,16628,,,0,"Add API services Javascript

This will support the node-details and node-list controllers.

Change-Id: Ie25e1a7f3344cc8254a913e3e3ed8319bc17bce4
Co-Authored-By: Peter Piela <ppiela@cray.com>
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/40/283540/6 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/static/dashboard/admin/ironic/ironic.module.js', 'ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js']",3,44d65fe819c0f39b7bba0ea379e14f97ceba68b9,split-patch,"/* * © Copyright 2015 Hewlett Packard Enterprise Development Company LP * © Copyright 2016 Cray Inc. * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function () { 'use strict'; angular .module('horizon.app.core.openstack-service-api') .factory('horizon.app.core.openstack-service-api.ironic', ironicAPI); ironicAPI.$inject = [ 'horizon.framework.util.http.service', 'horizon.framework.widgets.toast.service' ]; /** * @ngdoc service * @name horizon.app.core.openstack-service-api.ironic * @description Provides access to Ironic API */ function ironicAPI(apiService, toastService) { var service = { getNodes: getNodes, getNode: getNode, getPortsWithNode: getPortsWithNode, putNodeInMaintenanceMode: putNodeInMaintenanceMode, removeNodeFromMaintenanceMode: removeNodeFromMaintenanceMode, powerOnNode: powerOnNode, powerOffNode: powerOffNode }; return service; /////////// /** * @name horizon.app.core.openstack-service-api.ironic.getNodes * @description Retrieve a list of nodes * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-nodes * * @return Node collection in JSON * http://docs.openstack.org/developer/ironic/webapi/v1.html#NodeCollection */ function getNodes() { console.log(""openstack_dashbord/static/app/core/openstack-service-api/ironic-service.js:getNodes"") return apiService.get('/api/ironic/nodes/') .error(function() { toastService.add('error', gettext('Unable to retrieve Ironic nodes.')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.getNode * @description Retrieve information about the given node. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-nodes-(node_ident) * * @param {string} uuid – UUID or logical name of a node. */ function getNode(uuid) { return apiService.get('/api/ironic/nodes/' + uuid).error(function() { toastService.add('error', gettext('Unable to retrieve the Ironic node.')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.getPortsWithNode * @description Retrieve a list of ports associated with a node. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-ports * * @param {string} uuid – UUID or logical name of a node. */ function getPortsWithNode(uuid) { var config = { 'params' : { node_id: uuid } }; return apiService.get('/api/ironic/ports/', config).error(function() { toastService.add('error', gettext('Unable to retrieve the Ironic node ports.')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.putNodeInMaintenanceMode * @description Put the node in maintenance mode. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#put--v1-nodes-(node_ident)-maintenance * * @param {string} uuid – UUID or logical name of a node. */ function putNodeInMaintenanceMode(uuid, reason) { var data = { maint_reason: reason }; return apiService.patch('/api/ironic/nodes/' + uuid + '/maintenance', data).error(function() { toastService.add('error', gettext('Unable to put the Ironic node in maintenance mode.')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.removeNodeFromMaintenanceMode * @description Remove the node from maintenance mode. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#delete--v1-nodes-(node_ident)-maintenance * * @param {string} uuid – UUID or logical name of a node. */ function removeNodeFromMaintenanceMode(uuid) { return apiService.delete('/api/ironic/nodes/' + uuid + '/maintenance').error(function() { toastService.add('error', gettext('Unable to remove the Ironic node from maintenance mode.')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.powerOnNode * @description Set the power state of the node. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#put--v1-nodes-(node_ident)-states-power * * @param {string} uuid – UUID or logical name of a node. */ function powerOnNode(uuid) { var data = { state: 'on' }; return apiService.patch('/api/ironic/nodes/' + uuid + '/states/power', data) .error(function () { toastService.add('error', gettext('Unable to power on the node')); }); } /** * @name horizon.app.core.openstack-service-api.ironic.powerOffNode * @description Set the power state of the node. * * http://docs.openstack.org/developer/ironic/webapi/v1.html#put--v1-nodes-(node_ident)-states-power * * @param {string} uuid – UUID or logical name of a node. */ function powerOffNode(uuid) { var data = { state: 'off' }; return apiService.patch('/api/ironic/nodes/' + uuid + '/states/power', data) .error(function () { toastService.add('error', gettext('Unable to power off the node')); }); } } }()); ",,323,0
openstack%2Ffuel-specs~master~I91e97b3046b918ceb72565565697e05dd05519ae,openstack/fuel-specs,master,I91e97b3046b918ceb72565565697e05dd05519ae,Add spec for graceful cluster stop,MERGED,2016-02-26 18:30:07.000000000,2016-03-04 19:14:57.000000000,2016-03-04 19:14:57.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 9387}, {'_account_id': 10391}, {'_account_id': 14057}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 19158}]","[{'number': 1, 'created': '2016-02-26 18:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/041c3924e29195e4e15b231839dbf32fe9ca29e2', 'message': 'Add spec for graceful cluster start\n\nChange-Id: I91e97b3046b918ceb72565565697e05dd05519ae\nblueprint: graceful-stop-restart-deployment\n'}, {'number': 2, 'created': '2016-02-28 19:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/8dcc36daf4df027cca78c23e42eb5a84b9af5902', 'message': 'Add spec for graceful cluster start\n\nChange-Id: I91e97b3046b918ceb72565565697e05dd05519ae\nblueprint: graceful-stop-restart-deployment\n'}, {'number': 3, 'created': '2016-02-29 11:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/7226775242cf5616741be7642e1a8a1b466b9456', 'message': 'Add spec for graceful cluster stop\n\nChange-Id: I91e97b3046b918ceb72565565697e05dd05519ae\nblueprint: graceful-stop-restart-deployment\n'}, {'number': 4, 'created': '2016-02-29 14:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/728184beca52ab0e4f8e361ac84df675eac64581', 'message': 'Add spec for graceful cluster stop\n\nChange-Id: I91e97b3046b918ceb72565565697e05dd05519ae\nblueprint: graceful-stop-restart-deployment\n'}, {'number': 5, 'created': '2016-03-02 13:56:55.000000000', 'files': ['specs/9.0/graceful-stop-restart-deployment.rst', 'images/9.0/graceful-stop-restart-deployment/stopped-state-machine.png'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c5a2873b188d4846c11e62d934353132ea624c15', 'message': 'Add spec for graceful cluster stop\n\nChange-Id: I91e97b3046b918ceb72565565697e05dd05519ae\nblueprint: graceful-stop-restart-deployment\n'}]",10,285489,c5a2873b188d4846c11e62d934353132ea624c15,29,12,5,8786,,,0,"Add spec for graceful cluster stop

Change-Id: I91e97b3046b918ceb72565565697e05dd05519ae
blueprint: graceful-stop-restart-deployment
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/89/285489/4 && git format-patch -1 --stdout FETCH_HEAD,"['specs/9.0/graceful-stop-restart-deployment.rst', 'images/9.0/graceful-stop-restart-deployment/stopped-state-machine.png']",2,041c3924e29195e4e15b231839dbf32fe9ca29e2,bp/graceful-stop-restart-deployment,,,225,0
openstack%2Fproject-config~master~I9e41590e6c57ec0dda6f1beb4ba1ccda83eb7d9a,openstack/project-config,master,I9e41590e6c57ec0dda6f1beb4ba1ccda83eb7d9a,Make OpenStack-Ansible publish master docs,ABANDONED,2016-03-04 18:13:50.000000000,2016-03-04 18:59:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 6816}]","[{'number': 1, 'created': '2016-03-04 18:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/47afee0175bfeaacf58b52af31fc476d1779640c', 'message': ""Make OpenStack-Ansible publish master docs\n\nRecently https://review.openstack.org/279238 merged, resulting in\ndocs being published in a way that suits the library repo\npublishing process (ie only the latest tag is published).\n\nOpenStack-Ansible relies on the master branch content, and the HEAD\nof each named branch being published.\n\nThis patch implements a release job to ensure that the 'tags-only'\njob is not implemented for OpenStack-Ansible.\n\nChange-Id: I9e41590e6c57ec0dda6f1beb4ba1ccda83eb7d9a\n""}, {'number': 2, 'created': '2016-03-04 18:26:46.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b2edc6c94146e8106a94008ef194722c5a93f880', 'message': ""Make OpenStack-Ansible publish master docs\n\nRecently https://review.openstack.org/279238 merged, resulting in\ndocs being published in a way that suits the library repo\npublishing process (ie only the latest tag is published).\n\nOpenStack-Ansible relies on the master branch content, and the HEAD\nof each named branch being published.\n\nThis patch removes the 'openstack-server-publish-jobs' job template\nand sets out the post and release jobs to ensure that the 'tags-only'\njob is not implemented for OpenStack-Ansible.\n\nChange-Id: I9e41590e6c57ec0dda6f1beb4ba1ccda83eb7d9a\n""}]",6,288621,b2edc6c94146e8106a94008ef194722c5a93f880,8,4,2,6816,,,0,"Make OpenStack-Ansible publish master docs

Recently https://review.openstack.org/279238 merged, resulting in
docs being published in a way that suits the library repo
publishing process (ie only the latest tag is published).

OpenStack-Ansible relies on the master branch content, and the HEAD
of each named branch being published.

This patch removes the 'openstack-server-publish-jobs' job template
and sets out the post and release jobs to ensure that the 'tags-only'
job is not implemented for OpenStack-Ansible.

Change-Id: I9e41590e6c57ec0dda6f1beb4ba1ccda83eb7d9a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/288621/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,47afee0175bfeaacf58b52af31fc476d1779640c,docs-publishing-bug, release: - gate-openstack-ansible-docs,,2,0
openstack%2Fheat-translator~master~I510fe43eeef7e30a5f1ef432145694b1e5e2b99c,openstack/heat-translator,master,I510fe43eeef7e30a5f1ef432145694b1e5e2b99c,Updated from global requirements,MERGED,2016-03-03 18:00:57.000000000,2016-03-04 18:59:51.000000000,2016-03-04 18:59:51.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-03 18:00:57.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/24974d0f451969275d75d047be21c34eeba859d0', 'message': 'Updated from global requirements\n\nChange-Id: I510fe43eeef7e30a5f1ef432145694b1e5e2b99c\n'}]",0,288018,24974d0f451969275d75d047be21c34eeba859d0,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I510fe43eeef7e30a5f1ef432145694b1e5e2b99c
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/18/288018/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,24974d0f451969275d75d047be21c34eeba859d0,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Ftosca-parser~master~Ibd2ba779bd6318aa374e06205141f2b85fad6617,openstack/tosca-parser,master,Ibd2ba779bd6318aa374e06205141f2b85fad6617,Updated from global requirements,MERGED,2016-03-03 18:07:58.000000000,2016-03-04 18:54:28.000000000,2016-03-04 18:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-03 18:07:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/e30a7df9061a023afa54f16a2e2a69ba7e405bfc', 'message': 'Updated from global requirements\n\nChange-Id: Ibd2ba779bd6318aa374e06205141f2b85fad6617\n'}]",0,288040,e30a7df9061a023afa54f16a2e2a69ba7e405bfc,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ibd2ba779bd6318aa374e06205141f2b85fad6617
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/40/288040/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e30a7df9061a023afa54f16a2e2a69ba7e405bfc,openstack/requirements,"cliff!=1.16.0,!=1.17.0,>=1.15.0 # Apache-2.0","cliff!=1.16.0,>=1.15.0 # Apache-2.0",1,1
openstack%2Fshade~master~I9a63bfb7a85e69e66d32cf28d0e7fe207996e1b4,openstack/shade,master,I9a63bfb7a85e69e66d32cf28d0e7fe207996e1b4,Use warlock in the glance v2 tests,MERGED,2016-03-04 14:53:10.000000000,2016-03-04 18:51:08.000000000,2016-03-04 18:51:08.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 4146}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-04 14:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/33f8401d14dbb4a56508a062ee808aa17aeced24', 'message': ""Use warlock in the glance v2 tests\n\nWe were mocking what should have been a warlock object with a dict like\nobject. Instead of doing that, actually pull the model from glanceclient\nand construct a legit warlock object in the mock so that we can make\nsure our warlock morphing does the right thing. Also, warlock triggers\n'smarts' about which parameters to update, so update the test to mock\nout the right things.\n\nSadly we have to copy the task schema in, because the only place it\nexists in API form is in the glance source tree.\n\nChange-Id: I9a63bfb7a85e69e66d32cf28d0e7fe207996e1b4\n""}, {'number': 2, 'created': '2016-03-04 15:08:59.000000000', 'files': ['shade/tests/unit/test_caching.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/d72262e207ec172a2cc04247101959297410f5c3', 'message': ""Use warlock in the glance v2 tests\n\nWe were mocking what should have been a warlock object with a dict like\nobject. Instead of doing that, actually pull the model from glanceclient\nand construct a legit warlock object in the mock so that we can make\nsure our warlock morphing does the right thing. Also, warlock triggers\n'smarts' about which parameters to update, so update the test to mock\nout the right things.\n\nSadly we have to copy the task schema in, because the only place it\nexists in API form is in the glance source tree.\n\nChange-Id: I9a63bfb7a85e69e66d32cf28d0e7fe207996e1b4\n""}]",1,288502,d72262e207ec172a2cc04247101959297410f5c3,10,4,2,2,,,0,"Use warlock in the glance v2 tests

We were mocking what should have been a warlock object with a dict like
object. Instead of doing that, actually pull the model from glanceclient
and construct a legit warlock object in the mock so that we can make
sure our warlock morphing does the right thing. Also, warlock triggers
'smarts' about which parameters to update, so update the test to mock
out the right things.

Sadly we have to copy the task schema in, because the only place it
exists in API form is in the glance source tree.

Change-Id: I9a63bfb7a85e69e66d32cf28d0e7fe207996e1b4
",git fetch https://review.opendev.org/openstack/shade refs/changes/02/288502/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_caching.py'],1,33f8401d14dbb4a56508a062ee808aa17aeced24,fix_things,"from glanceclient.v2 import shellimport warlock# Mock out the gettext function so that the task schema can be copypasta def _(msg): return msg _TASK_PROPERTIES = { ""id"": { ""description"": _(""An identifier for the task""), ""pattern"": _('^([0-9a-fA-F]){8}-([0-9a-fA-F]){4}-([0-9a-fA-F]){4}' '-([0-9a-fA-F]){4}-([0-9a-fA-F]){12}$'), ""type"": ""string"" }, ""type"": { ""description"": _(""The type of task represented by this content""), ""enum"": [ ""import"", ], ""type"": ""string"" }, ""status"": { ""description"": _(""The current status of this task""), ""enum"": [ ""pending"", ""processing"", ""success"", ""failure"" ], ""type"": ""string"" }, ""input"": { ""description"": _(""The parameters required by task, JSON blob""), ""type"": [""null"", ""object""], }, ""result"": { ""description"": _(""The result of current task, JSON blob""), ""type"": [""null"", ""object""], }, ""owner"": { ""description"": _(""An identifier for the owner of this task""), ""type"": ""string"" }, ""message"": { ""description"": _(""Human-readable informative message only included"" "" when appropriate (usually on failure)""), ""type"": ""string"", }, ""expires_at"": { ""description"": _(""Datetime when this resource would be"" "" subject to removal""), ""type"": [""null"", ""string""] }, ""created_at"": { ""description"": _(""Datetime when this resource was created""), ""type"": ""string"" }, ""updated_at"": { ""description"": _(""Datetime when this resource was updated""), ""type"": ""string"" }, 'self': {'type': 'string'}, 'schema': {'type': 'string'} } _TASK_SCHEMA = dict( name='Task', properties=_TASK_PROPERTIES, additionalProperties=False, ) FakeImage = warlock.model_factory(shell.get_image_schema()) fake_image = FakeImage( id='a35e8afc-cae9-4e38-8441-2cd465f79f7b', name='name-99', status='active', visibility='private') FakeTask = warlock.model_factory(_TASK_SCHEMA) args = { 'id': '21FBD9A7-85EC-4E07-9D58-72F1ACF7CB1F', 'type': 'import', 'result': { 'image_id': 'a35e8afc-cae9-4e38-8441-2cd465f79f7b', }, } fake_task = FakeTask(**args) self._call_create_image(name='name-99', 'import_from': 'image_upload_v2_test_container/name-99', 'image_properties': {'name': 'name-99'}}) 'image_id': 'a35e8afc-cae9-4e38-8441-2cd465f79f7b'}"," # V2's warlock objects just work like dicts class FakeImage(dict): status = 'CREATED' id = '99' name = '99 name' def _shadeunittest(self): pass fake_image = FakeImage() fake_image.update({ 'id': '99', 'name': '99 name', shade.openstackcloud.IMAGE_MD5_KEY: fake_md5, shade.openstackcloud.IMAGE_SHA256_KEY: fake_sha256, }) class FakeTask(dict): status = 'success' result = {'image_id': '99'} def _shadeunittest(self): pass fake_task = FakeTask() fake_task.update({ 'id': '100', }) self._call_create_image(name='99 name', 'import_from': 'image_upload_v2_test_container/99 name', 'image_properties': {'name': '99 name'}}) 'image_id': '99', 'visibility': 'private'}",87,32
openstack%2Fshade~master~Iada5ff76cf9192a2c10e117536546989633c290e,openstack/shade,master,Iada5ff76cf9192a2c10e117536546989633c290e,Fixes for latest cinder and neutron clients,MERGED,2016-03-03 20:23:20.000000000,2016-03-04 18:42:16.000000000,2016-03-04 18:42:15.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2243}, {'_account_id': 3099}, {'_account_id': 4146}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-03 20:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f4380e370c6ad97fb4b50d6588609318cdf4aa8d', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\n'}, {'number': 2, 'created': '2016-03-03 22:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/b9c13221fd1827882ab475f23e7676e32642833a', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\n'}, {'number': 3, 'created': '2016-03-04 02:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a9d0b9624feabfbe35604855bbdabee79f778461', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n'}, {'number': 4, 'created': '2016-03-04 13:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/6a1d9018eb6291ed8f815ede032c740af15ca853', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n'}, {'number': 5, 'created': '2016-03-04 13:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0e3db4731768a80d3762b3a994d7d481f53cfd89', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n'}, {'number': 6, 'created': '2016-03-04 15:08:59.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/tests/unit/test_meta.py', 'shade/tests/functional/test_volume.py', 'shade/meta.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/3850774d8f3f766487462a9bb05e68eb9c8ffe91', 'message': 'Fixes for latest cinder and neutron clients\n\nIn obj_to_dict, if we get a dict-like-object, we should convert that\nwith Munch. Otherwise, we just convert its properties and not values.\n\nWhen comparing cinder things, do not compare the entire structure\nsince what we get from the create call can be different than what\nwe get from the list call. Just compare IDs.\n\nChange-Id: Iada5ff76cf9192a2c10e117536546989633c290e\nCo-Authored-By: Monty Taylor <mordred@inaugust.com>\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n'}]",1,288110,3850774d8f3f766487462a9bb05e68eb9c8ffe91,21,7,6,3099,,,0,"Fixes for latest cinder and neutron clients

In obj_to_dict, if we get a dict-like-object, we should convert that
with Munch. Otherwise, we just convert its properties and not values.

When comparing cinder things, do not compare the entire structure
since what we get from the create call can be different than what
we get from the list call. Just compare IDs.

Change-Id: Iada5ff76cf9192a2c10e117536546989633c290e
Co-Authored-By: Monty Taylor <mordred@inaugust.com>
Co-Authored-By: Sam Yaple <sam@yaple.net>
",git fetch https://review.opendev.org/openstack/shade refs/changes/10/288110/4 && git format-patch -1 --stdout FETCH_HEAD,"['shade/meta.py', 'shade/tests/functional/test_volume.py']",2,f4380e370c6ad97fb4b50d6588609318cdf4aa8d,fix_things," volume_ids = [v['id'] for v in self.cloud.list_volumes()] self.assertIn(volume['id'], volume_ids) snapshot_ids = [s['id'] for s in self.cloud.list_volume_snapshots()] self.assertIn(snapshot['id'], snapshot_ids) ret_snapshot = self.cloud.get_volume_snapshot_by_id(snapshot['id']) self.assertEqual(snapshot['id'], ret_snapshot['id']) # Need to delete snapshots before volumes if volume: self.cloud.delete_volume(volume_name)"," self.assertIn(volume, self.cloud.list_volumes()) self.assertIn(snapshot, self.cloud.list_volume_snapshots()) self.assertEqual(snapshot, self.cloud.get_volume_snapshot( snapshot['display_name'])) self.assertEqual(snapshot, self.cloud.get_volume_snapshot_by_id(snapshot['id'])) if volume: self.cloud.delete_volume(volume_name) ",13,12
openstack%2Fkolla~master~I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0,openstack/kolla,master,I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0,Reconfigure for Murano,MERGED,2016-03-04 03:53:19.000000000,2016-03-04 18:37:13.000000000,2016-03-04 18:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 13642}, {'_account_id': 14119}, {'_account_id': 18009}]","[{'number': 1, 'created': '2016-03-04 03:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/eb452633586e3f7f19655a77acb179fea6321a0b', 'message': 'WIP: Reconfigure for Murano\n\nAdd reconfiguration for murano-api, murano-engine\n\nChange-Id: I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0\nPartially-Implements: blueprint kolla-reconfig\n'}, {'number': 2, 'created': '2016-03-04 04:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/720af6bec2bb9ee208f11be8730da85510ecc5a0', 'message': 'WIP: Reconfigure for Murano\n\nAdd reconfiguration for murano-api, murano-engine\n\nChange-Id: I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0\nPartially-Implements: blueprint kolla-reconfig\n'}, {'number': 3, 'created': '2016-03-04 17:34:01.000000000', 'files': ['ansible/roles/murano/tasks/do_reconfigure.yml', 'ansible/roles/murano/tasks/reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/20f080223f72a7e2f697069e7d6b0a9ad6852d51', 'message': 'Reconfigure for Murano\n\nAdd reconfiguration for murano-api, murano-engine\n\nChange-Id: I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0\nPartially-Implements: blueprint kolla-reconfig\n'}]",4,288239,20f080223f72a7e2f697069e7d6b0a9ad6852d51,19,8,3,18009,,,0,"Reconfigure for Murano

Add reconfiguration for murano-api, murano-engine

Change-Id: I8a2b1b1cc2b6268d6d1f07b1dfcb96ba9f7fd7a0
Partially-Implements: blueprint kolla-reconfig
",git fetch https://review.opendev.org/openstack/kolla refs/changes/39/288239/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/murano/tasks/do_reconfigure.yml', 'ansible/roles/murano/tasks/reconfigure.yml']",2,eb452633586e3f7f19655a77acb179fea6321a0b,bp/kolla-reconfig,"- include: do_reconfigure.yml serial: ""30%"" when: inventory_hostname in groups['manila-api'] or inventory_hostname in groups['manila-scheduler'] or inventory_hostname in groups['manila-share']",,71,0
openstack%2Foctavia~master~I791d897c4efe00bc4c0fd3b9d249e561eeb82acb,openstack/octavia,master,I791d897c4efe00bc4c0fd3b9d249e561eeb82acb,Add bandit baseline to tox,MERGED,2016-03-01 23:29:20.000000000,2016-03-04 18:35:01.000000000,2016-03-04 18:31:02.000000000,"[{'_account_id': 3}, {'_account_id': 7473}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 15226}, {'_account_id': 16923}, {'_account_id': 17419}]","[{'number': 1, 'created': '2016-03-01 23:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/262ae650b9b10aa04e222ebf708f95e3ad59b307', 'message': 'Add bandit baseline to tox\n\nBandit baseline will check the last commit to see if\nit introduced any new security problems.\n\nDetails of how bandit can be configured for the gate are\ndocumented here:\n\nhttps://wiki.openstack.org/wiki/Security/Projects/Bandit#Gate_Testing_with_Bandit\n\nChange-Id: I791d897c4efe00bc4c0fd3b9d249e561eeb82acb\nPartial-Bug: #1552002\n'}, {'number': 2, 'created': '2016-03-03 22:42:22.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/octavia/commit/61a989452789a628d54848fd1379ef4afcdce67c', 'message': 'Add bandit baseline to tox\n\nBandit baseline will check the last commit to see if\nit introduced any new security problems.\n\nDetails of how bandit can be configured for the gate are\ndocumented here:\n\nhttps://wiki.openstack.org/wiki/Security/Projects/Bandit#Gate_Testing_with_Bandit\n\nChange-Id: I791d897c4efe00bc4c0fd3b9d249e561eeb82acb\nPartial-Bug: #1552002\n'}]",0,286892,61a989452789a628d54848fd1379ef4afcdce67c,23,7,2,7473,,,0,"Add bandit baseline to tox

Bandit baseline will check the last commit to see if
it introduced any new security problems.

Details of how bandit can be configured for the gate are
documented here:

https://wiki.openstack.org/wiki/Security/Projects/Bandit#Gate_Testing_with_Bandit

Change-Id: I791d897c4efe00bc4c0fd3b9d249e561eeb82acb
Partial-Bug: #1552002
",git fetch https://review.opendev.org/openstack/octavia refs/changes/92/286892/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,262ae650b9b10aa04e222ebf708f95e3ad59b307,bug/1552002, [testenv:bandit] commands = bandit-baseline -r octavia -ll -ii ,,5,0
openstack%2Fsahara-dashboard~master~I9f59a19a76573c0d40abb7a44a64093fa0f257f2,openstack/sahara-dashboard,master,I9f59a19a76573c0d40abb7a44a64093fa0f257f2,Updated from global requirements,MERGED,2016-03-04 14:42:11.000000000,2016-03-04 18:26:14.000000000,2016-03-04 18:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 12038}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 14:42:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/1183fd6b0d179a85ef08f6f89f9659f8b603482d', 'message': 'Updated from global requirements\n\nChange-Id: I9f59a19a76573c0d40abb7a44a64093fa0f257f2\n'}]",0,288493,1183fd6b0d179a85ef08f6f89f9659f8b603482d,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I9f59a19a76573c0d40abb7a44a64093fa0f257f2
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/93/288493/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1183fd6b0d179a85ef08f6f89f9659f8b603482d,openstack/requirements,django-compressor>=2.0 # MIT,django-compressor>=1.4 # MIT,1,1
openstack%2Fkolla~master~Id85859500aec283703b6b6714abf213a42286182,openstack/kolla,master,Id85859500aec283703b6b6714abf213a42286182,Add authentication for keepalived,MERGED,2016-02-06 14:20:49.000000000,2016-03-04 18:15:04.000000000,2016-03-04 18:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 11561}, {'_account_id': 13642}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-06 14:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f3a95d4a2de56cf3a08e04a610d9c2f5b81571cc', 'message': 'Add authentication for keepalived\n\nTrivialFix\n\nChange-Id: Id85859500aec283703b6b6714abf213a42286182\n'}, {'number': 2, 'created': '2016-02-27 03:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a0bd718030e17ce17bbfd9b33326f521c52b16c8', 'message': 'Add authentication for keepalived\n\nTrivialFix\n\nChange-Id: Id85859500aec283703b6b6714abf213a42286182\n'}, {'number': 3, 'created': '2016-03-04 13:29:01.000000000', 'files': ['ansible/roles/haproxy/templates/keepalived.conf.j2', 'etc/kolla/passwords.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e6b230d78436dfb7b38b1c30c4a9325909ae1d20', 'message': 'Add authentication for keepalived\n\nTrivialFix\n\nCloses-Bug: #1551314\nChange-Id: Id85859500aec283703b6b6714abf213a42286182\n'}]",3,277085,e6b230d78436dfb7b38b1c30c4a9325909ae1d20,27,6,3,7488,,,0,"Add authentication for keepalived

TrivialFix

Closes-Bug: #1551314
Change-Id: Id85859500aec283703b6b6714abf213a42286182
",git fetch https://review.opendev.org/openstack/kolla refs/changes/85/277085/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/haproxy/templates/keepalived.conf.j2', 'etc/kolla/passwords.yml']",2,f3a95d4a2de56cf3a08e04a610d9c2f5b81571cc,bug/1551314,"keepalived_password: ""password""",,5,0
openstack%2Fpuppet-cinder~master~Iacf844b10ee3e8a5668c6dc945cefaafd584635a,openstack/puppet-cinder,master,Iacf844b10ee3e8a5668c6dc945cefaafd584635a,Add public_endpoint and osapi_volume_base_url parameters,MERGED,2016-03-03 00:32:57.000000000,2016-03-04 18:09:58.000000000,2016-03-04 18:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 14007}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-03-03 00:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/eb28be9c9bcdda92a36d1aa5dcb3551a40807d3c', 'message': ""Add public_endpoint parameter\n\npublic_endpoint us used for configuring versions endpoint.\nIt's useful when running Cinder in SSL.\n\nChange-Id: Iacf844b10ee3e8a5668c6dc945cefaafd584635a\n""}, {'number': 2, 'created': '2016-03-03 02:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/d05588cb1310564374b5194048ef057cc230621a', 'message': 'Add public_endpoint and osapi_volume_base_url parameters\n\npublic_endpoint is used for configuring versions endpoint.\nosapi_volume_base_URL is used to present Cinder URL to users.\n\nThey are useful when running Cinder in SSL.\n\nChange-Id: Iacf844b10ee3e8a5668c6dc945cefaafd584635a\n'}, {'number': 3, 'created': '2016-03-03 19:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/255332d856dd8aca60f0bf09c86719f3f062897b', 'message': 'Add public_endpoint and osapi_volume_base_url parameters\n\npublic_endpoint is used for configuring versions endpoint.\nosapi_volume_base_URL is used to present Cinder URL to users.\n\nThey are useful when running Cinder in SSL.\n\nChange-Id: Iacf844b10ee3e8a5668c6dc945cefaafd584635a\n'}, {'number': 4, 'created': '2016-03-03 23:17:37.000000000', 'files': ['manifests/api.pp', 'spec/classes/cinder_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/dad95243235c803ac3364151023795dbf6133a3d', 'message': 'Add public_endpoint and osapi_volume_base_url parameters\n\npublic_endpoint is used for configuring versions endpoint.\nosapi_volume_base_URL is used to present Cinder URL to users.\n\nThey are useful when running Cinder in SSL.\n\nDepends-On: Ibfc3988a4de47c9d7d97159e7d1c0e57d64979ae\nChange-Id: Iacf844b10ee3e8a5668c6dc945cefaafd584635a\n'}]",0,287528,dad95243235c803ac3364151023795dbf6133a3d,18,4,4,3153,,,0,"Add public_endpoint and osapi_volume_base_url parameters

public_endpoint is used for configuring versions endpoint.
osapi_volume_base_URL is used to present Cinder URL to users.

They are useful when running Cinder in SSL.

Depends-On: Ibfc3988a4de47c9d7d97159e7d1c0e57d64979ae
Change-Id: Iacf844b10ee3e8a5668c6dc945cefaafd584635a
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/28/287528/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/cinder_api_spec.rb']",2,eb28be9c9bcdda92a36d1aa5dcb3551a40807d3c,ssl, is_expected.to contain_cinder_config('DEFAULT/public_endpoint').with( :value => '<SERVICE DEFAULT>' ),,9,0
openstack%2Fironic~master~Idd3a366bedd78b4fc17410fb84434db27a271484,openstack/ironic,master,Idd3a366bedd78b4fc17410fb84434db27a271484,Updated from global requirements,MERGED,2016-03-04 10:15:20.000000000,2016-03-04 18:08:05.000000000,2016-03-04 18:08:05.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 16272}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-03-04 10:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/29d77c23e120a585390a602cee9c9e1db48e31d1', 'message': 'Updated from global requirements\n\nChange-Id: Idd3a366bedd78b4fc17410fb84434db27a271484\n'}, {'number': 2, 'created': '2016-03-04 14:17:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c83c6f54a84777b6b77aee1c21dec9bfcf3f13b', 'message': 'Updated from global requirements\n\nChange-Id: Idd3a366bedd78b4fc17410fb84434db27a271484\n'}]",0,288351,7c83c6f54a84777b6b77aee1c21dec9bfcf3f13b,12,5,2,11131,,,0,"Updated from global requirements

Change-Id: Idd3a366bedd78b4fc17410fb84434db27a271484
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/288351/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,29d77c23e120a585390a602cee9c9e1db48e31d1,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0ironic-lib>=1.1.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0ironic-lib>=0.5.0 # Apache-2.0,2,2
openstack%2Ffuel-agent~master~I381647f7811d15ae9bdec8b3b9243be32fd2a725,openstack/fuel-agent,master,I381647f7811d15ae9bdec8b3b9243be32fd2a725,Add multipath support for fuel-agent,MERGED,2016-02-26 14:58:37.000000000,2016-03-04 18:05:46.000000000,2016-03-04 18:00:56.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6571}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 9377}, {'_account_id': 10288}, {'_account_id': 14200}]","[{'number': 1, 'created': '2016-02-26 14:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/2bf42c07274d0fa30eda0438dd13cf695d342f10', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 2, 'created': '2016-02-26 23:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/820e778477b0574d0eb84fef477f72fa8841dada', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 3, 'created': '2016-02-27 01:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/c3e5d7fa66b2df9514acdff2aa1cb859b78c3840', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 4, 'created': '2016-02-27 16:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/d95cbe13776615e9ff7eca6fef96484d5f4fc81d', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 5, 'created': '2016-02-27 18:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/d4fc8b6bb8b8a07ce91e224e681faf1e7d1a649a', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 6, 'created': '2016-02-27 21:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/375192a3a11024678279ad52958cfa29a6d0b188', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 7, 'created': '2016-02-27 22:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/5d3f75d3472a9784566cbfd98509fcbf3bca91b1', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 8, 'created': '2016-02-28 08:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/2c1276e574c0ce30528a95885b62832f587292d3', 'message': 'Add multupath support\n\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 9, 'created': '2016-02-28 12:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/677b067aaff5d5ef00e231268d0a12f5719b0ccf', 'message': 'Add multipath support for device\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 10, 'created': '2016-02-28 12:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/0cd59fadca6f5c248c57a0bc4772f6ae75623533', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 11, 'created': '2016-02-28 13:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/f73e17dab1d8a365579a9fea17285f3a6e6281aa', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 12, 'created': '2016-02-28 14:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/8e2da472d6c018d3749450d172c8a52b622b29b8', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 13, 'created': '2016-02-28 14:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/78fa9096281ad4a31682f708c32dc3101bc573fc', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 14, 'created': '2016-02-28 15:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/5002841b9b66f3aefc82540b96e01c269c0a0ff1', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 15, 'created': '2016-02-28 17:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/553bdad0209603ea85c7ff1fff4068249a17ee56', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 16, 'created': '2016-02-28 21:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/9a6029bb7641ff2fcae684b885aed67dac4f96de', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 17, 'created': '2016-02-28 21:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/8e7be10c17c624ff12128203f65b1c56c4cb652a', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 18, 'created': '2016-02-28 23:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/87ccd72a10ca15c236d7b65b3728c4cbd9fb39d2', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 19, 'created': '2016-02-29 12:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/678c66659a55fad5f06f575a84c0f92d67cbfae6', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 20, 'created': '2016-02-29 13:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/c3a0ad1e24cedcc7307f6bb4a406c93f72a485dc', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 21, 'created': '2016-02-29 13:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/cb03aed80d7a14b491914445a4f8643b38234c5c', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 22, 'created': '2016-02-29 13:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/a068872c1552e209bf1ae1b25ca87a61672e5cea', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 23, 'created': '2016-02-29 14:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/1684229c09ee850a632df95b0a139636a87e969c', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 24, 'created': '2016-02-29 16:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/b8f9f60af9efd4694f98805aebcd9a2e910dfc6f', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 25, 'created': '2016-03-01 07:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/b07527c4e8805138090a1402e697072484946a1e', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 26, 'created': '2016-03-01 07:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/f3da6791cd9cdd190bc0687cbd11426d973a2ee5', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 27, 'created': '2016-03-01 08:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/78bbad3343ac996221b0dc2ed37dc06b89a4ff32', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nFiltring wrong naming in pvdisplay.\nDisabling blacklisting of udev.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 28, 'created': '2016-03-01 16:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/537793ec958018ec0e050dabd83991f17ce9b9b6', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 29, 'created': '2016-03-01 17:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/a92d1d287143c2f390dd1486b1e0f912da3d7fd9', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 30, 'created': '2016-03-02 07:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/e07b6f81e27f9c294bf8695fb031c6e2ce0ba37a', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 31, 'created': '2016-03-02 07:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/8e884a729ab1aee804e89d2b21c661d6099ae5b9', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules.\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 32, 'created': '2016-03-02 19:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/103ebd16cd96297974a3486d7d2ef2133bf706a1', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 33, 'created': '2016-03-03 01:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/dc600ec29c0612b4f8ed4bb60524da405a727b46', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 34, 'created': '2016-03-03 01:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/3d8e3121252c2c29002f0354d5efe5de04dfd9b5', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 35, 'created': '2016-03-03 09:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/65adddbda9758ac736a74a9b476ca3e4ac6762ec', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 36, 'created': '2016-03-03 12:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/b2422cd4dbc9d7a77473025376bd64868203f9de', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 37, 'created': '2016-03-03 15:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/7c9dd6bccecb198b5f9b9663140b9d1a961364fe', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 38, 'created': '2016-03-03 17:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/03e49df47f24975dbd399a202def36417029a269', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 39, 'created': '2016-03-04 10:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/7dc6bfd6b9a9602d4e15e2a526b02eef31cd4886', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 40, 'created': '2016-03-04 14:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/e2edfdd1ef9ed16a816d5e847a25021b81301d90', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nDue to naming of partions on multipath devices following packages\nshould have versions not lower then specified:\n\nlibudev1:amd64                      204-5ubuntu20.19\nudev                                204-5ubuntu20.19\nlibparted0debian1:amd64             2.3-19ubuntu1.14.04.2\nparted                              2.3-19ubuntu1.14.04.2\n\nDocImpact\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 41, 'created': '2016-03-04 14:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/9d10e020c25ebe87729d7f6346ef66edb58a61fd', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nDue to naming of partitions on multipath devices following packages\nshould have versions not lower then specified:\n\nlibudev1:amd64                      204-5ubuntu20.19\nudev                                204-5ubuntu20.19\nlibparted0debian1:amd64             2.3-19ubuntu1.14.04.2\nparted                              2.3-19ubuntu1.14.04.2\n\nDocImpact\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}, {'number': 42, 'created': '2016-03-04 15:54:55.000000000', 'files': ['fuel_agent/tests/test_build_utils.py', 'fuel_agent/tests/test_hardware_utils.py', 'fuel_agent/objects/partition/parted.py', 'fuel_agent/tests/test_partition.py', 'fuel_agent/utils/utils.py', 'fuel_agent/utils/build.py', 'fuel_agent/tests/test_manager.py', 'fuel_agent/tests/test_nailgun.py', 'fuel_agent/utils/hardware.py', 'fuel_agent/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/3f9c5109155efb79f6b05be3a646818d91765423', 'message': 'Add multipath support for fuel-agent\n\nChanging used device name for provisioning.\nDisabling blacklisting of udev rules for multipath devices.\nExtending filter in lvm config\n\nDue to naming of partitions on multipath devices following packages\nshould have versions not lower then specified:\n\nlibudev1:amd64                      204-5ubuntu20.19\nudev                                204-5ubuntu20.19\nlibparted0debian1:amd64             2.3-19ubuntu1.14.04.2\nparted                              2.3-19ubuntu1.14.04.2\n\nDocImpact\nBlueprint: multipath-disks-support\nChange-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725\n'}]",61,285340,3f9c5109155efb79f6b05be3a646818d91765423,190,8,42,9377,,,0,"Add multipath support for fuel-agent

Changing used device name for provisioning.
Disabling blacklisting of udev rules for multipath devices.
Extending filter in lvm config

Due to naming of partitions on multipath devices following packages
should have versions not lower then specified:

libudev1:amd64                      204-5ubuntu20.19
udev                                204-5ubuntu20.19
libparted0debian1:amd64             2.3-19ubuntu1.14.04.2
parted                              2.3-19ubuntu1.14.04.2

DocImpact
Blueprint: multipath-disks-support
Change-Id: I381647f7811d15ae9bdec8b3b9243be32fd2a725
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/40/285340/39 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/drivers/nailgun.py', 'fuel_agent/manager.py']",2,2bf42c07274d0fa30eda0438dd13cf695d342f10,bp/multipath-disks-support," # LOG.debug(""Enabling udev's rules blacklisting"") # utils.blacklist_udev_rules(udev_rules_dir=CONF.udev_rules_dir, # udev_rules_lib_dir=CONF.udev_rules_lib_dir, # udev_rename_substr=CONF.udev_rename_substr, # udev_empty_rule=CONF.udev_empty_rule) # LOG.debug(""Disabling udev's rules blacklisting"") # utils.unblacklist_udev_rules( # udev_rules_dir=CONF.udev_rules_dir, # udev_rename_substr=CONF.udev_rename_substr)"," LOG.debug(""Enabling udev's rules blacklisting"") utils.blacklist_udev_rules(udev_rules_dir=CONF.udev_rules_dir, udev_rules_lib_dir=CONF.udev_rules_lib_dir, udev_rename_substr=CONF.udev_rename_substr, udev_empty_rule=CONF.udev_empty_rule) LOG.debug(""Disabling udev's rules blacklisting"") utils.unblacklist_udev_rules( udev_rules_dir=CONF.udev_rules_dir, udev_rename_substr=CONF.udev_rename_substr)",18,10
openstack%2Fironic~master~I2cf7071b714399947b2de20e938864e0624c4f11,openstack/ironic,master,I2cf7071b714399947b2de20e938864e0624c4f11,Remove code duplication.,MERGED,2016-03-04 12:52:01.000000000,2016-03-04 18:04:10.000000000,2016-03-04 18:04:10.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11929}]","[{'number': 1, 'created': '2016-03-04 12:52:01.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cf12ad9b409bbab440582fd20df64805bd541f85', 'message': 'Remove code duplication.\n\ndeploy_kernel and deploy_ramdisk are common for cases when\ndeploy driver is *_ipmitool and not *_ipmitool.\n\nChange-Id: I2cf7071b714399947b2de20e938864e0624c4f11\n'}]",0,288440,cf12ad9b409bbab440582fd20df64805bd541f85,10,5,1,14525,,,0,"Remove code duplication.

deploy_kernel and deploy_ramdisk are common for cases when
deploy driver is *_ipmitool and not *_ipmitool.

Change-Id: I2cf7071b714399947b2de20e938864e0624c4f11
",git fetch https://review.opendev.org/openstack/ironic refs/changes/40/288440/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,cf12ad9b409bbab440582fd20df64805bd541f85,," node_options=""\ $node_options \ -i deploy_kernel=$IRONIC_DEPLOY_KERNEL_ID \ -i deploy_ramdisk=$IRONIC_DEPLOY_RAMDISK_ID""", -i deploy_kernel=$IRONIC_DEPLOY_KERNEL_ID \ -i deploy_ramdisk=$IRONIC_DEPLOY_RAMDISK_ID \ -i deploy_kernel=$IRONIC_DEPLOY_KERNEL_ID \ -i deploy_ramdisk=$IRONIC_DEPLOY_RAMDISK_ID \,4,4
openstack%2Fkolla~master~Ibaa47c8825464566698d1ae068f5053834ed211a,openstack/kolla,master,Ibaa47c8825464566698d1ae068f5053834ed211a,Add Manila to the list of images provided by Kolla,MERGED,2016-03-04 16:28:48.000000000,2016-03-04 18:02:35.000000000,2016-03-04 18:02:35.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 13998}, {'_account_id': 14967}, {'_account_id': 16233}]","[{'number': 1, 'created': '2016-03-04 16:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/983d56a0ddbad3907d6f8407f9931dfed1c8d3ac', 'message': 'Add Manila in the list of images provided by Kolla\n\nAdding Manila and its developer website in the list of images\nprovided by Kolla  on README.\n\nDocImpact\n\nChange-Id: Ibaa47c8825464566698d1ae068f5053834ed211a\n'}, {'number': 2, 'created': '2016-03-04 16:37:56.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3637ef95a2f41690d9a8ddc09789fed7b226f3c0', 'message': 'Add Manila to the list of images provided by Kolla\n\nAdd Manila and its developer website to the list of images\nprovided by Kolla in README.\n\nDocImpact\n\nChange-Id: Ibaa47c8825464566698d1ae068f5053834ed211a\n'}]",6,288569,3637ef95a2f41690d9a8ddc09789fed7b226f3c0,12,6,2,14967,,,0,"Add Manila to the list of images provided by Kolla

Add Manila and its developer website to the list of images
provided by Kolla in README.

DocImpact

Change-Id: Ibaa47c8825464566698d1ae068f5053834ed211a
",git fetch https://review.opendev.org/openstack/kolla refs/changes/69/288569/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,983d56a0ddbad3907d6f8407f9931dfed1c8d3ac,Add-Manila-list-images-provided-by-Kolla,- `Manila <http://docs.openstack.org/developer/manila`__,,1,0
openstack%2Fkolla~master~Iceed173c3c3abea93b954f8d3cb45641de2aaa0f,openstack/kolla,master,Iceed173c3c3abea93b954f8d3cb45641de2aaa0f,Playbook for Manila upgrade,MERGED,2016-02-09 19:14:02.000000000,2016-03-04 17:58:29.000000000,2016-03-04 17:58:29.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 4715}, {'_account_id': 13642}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 14967}, {'_account_id': 16233}, {'_account_id': 16620}, {'_account_id': 18009}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-09 19:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c7ec51bc82b755d7aee477c8b0a1a6cb030ee4e9', 'message': '[WIP] Playbook for Manila upgrade\n\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nImplements: blueprint upgrade-manila\n'}, {'number': 2, 'created': '2016-02-25 17:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6e1d3aaf7557eb084e6942bab6d154b096c8563f', 'message': 'Playbook for Manila upgrade\n\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nImplements: blueprint upgrade-manila\n'}, {'number': 3, 'created': '2016-03-02 15:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c5f4124ae18e87c116544bd339411a8ec4a5dd40', 'message': 'Playbook for Manila upgrade\n\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nImplements: blueprint upgrade-kolla\n'}, {'number': 4, 'created': '2016-03-02 19:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/351f087572ba0301109462d9ff74b9e4b142e8cc', 'message': 'Playbook for Manila upgrade\n\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nPartially-Implements: blueprint upgrade-kolla\nImplements: blueprint upgrade-manila\n'}, {'number': 5, 'created': '2016-03-03 14:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/87680064fe86b352c518d1853ae7f64c7701e536', 'message': 'Playbook for Manila upgrade\n\nCo-Authored-By: Michal Rostecki <mrostecki@mirantis.com>\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nPartially-Implements: blueprint upgrade-kolla\nImplements: blueprint upgrade-manila\n'}, {'number': 6, 'created': '2016-03-04 06:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/838731ac51e9ca0011d0ad1a57b320f2df12aeb1', 'message': 'Playbook for Manila upgrade\n\nCo-Authored-By: Michal Rostecki <mrostecki@mirantis.com>\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nPartially-Implements: blueprint upgrade-kolla\nImplements: blueprint upgrade-manila\n'}, {'number': 7, 'created': '2016-03-04 16:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/68d60a55f75bd867587c81e024b834bbb60638dc', 'message': 'Playbook for Manila upgrade\n\nCo-Authored-By: Michal Rostecki <mrostecki@mirantis.com>\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nPartially-Implements: blueprint upgrade-kolla\nImplements: blueprint upgrade-manila\n'}, {'number': 8, 'created': '2016-03-04 16:22:15.000000000', 'files': ['ansible/roles/manila/tasks/bootstrap_service.yml', 'ansible/roles/manila/tasks/upgrade.yml', 'ansible/roles/manila/tasks/bootstrap.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4d0a3328f3b89757d785609d888b41152efe8179', 'message': 'Playbook for Manila upgrade\n\nCo-Authored-By: Michal Rostecki <mrostecki@mirantis.com>\nChange-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f\nPartially-Implements: blueprint upgrade-kolla\nImplements: blueprint upgrade-manila\n'}]",6,278045,4d0a3328f3b89757d785609d888b41152efe8179,53,12,8,14027,,,0,"Playbook for Manila upgrade

Co-Authored-By: Michal Rostecki <mrostecki@mirantis.com>
Change-Id: Iceed173c3c3abea93b954f8d3cb45641de2aaa0f
Partially-Implements: blueprint upgrade-kolla
Implements: blueprint upgrade-manila
",git fetch https://review.opendev.org/openstack/kolla refs/changes/45/278045/5 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/manila/tasks/bootstrap_service.yml', 'ansible/roles/manila/tasks/upgrade.yml', 'ansible/roles/manila/tasks/bootstrap.yml']",3,c7ec51bc82b755d7aee477c8b0a1a6cb030ee4e9,bp/upgrade-kolla,- include: bootstrap_service.yml,"- name: Running Manila bootstrap container kolla_docker: action: ""start_container"" common_options: ""{{ docker_common_options }}"" detach: False environment: KOLLA_BOOTSTRAP: KOLLA_CONFIG_STRATEGY: ""{{ config_strategy }}"" image: ""{{ manila_api_image_full }}"" name: ""bootstrap_manila"" restart_policy: ""never"" volumes: - ""{{ node_config_directory }}/manila-api/:{{ container_config_directory }}/:ro"" run_once: True delegate_to: ""{{ groups['manila-api'][0] }}""",24,15
openstack%2Ftripleo-heat-templates~master~Ib9911819e89f30270d4f7597639b33f30ad2e3a6,openstack/tripleo-heat-templates,master,Ib9911819e89f30270d4f7597639b33f30ad2e3a6,Run keystone-manage bootstrap for HA deployment too,MERGED,2016-03-04 13:58:48.000000000,2016-03-04 17:57:21.000000000,2016-03-04 17:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 2218}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-03-04 13:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b8c1dafb573b9c97573962dde0c7d7af11caca32', 'message': 'Run keystone-manage bootstrap for HA deployment too\n\nThis is necessary to keep creating the Default domain.\n\nChange-Id: Ib9911819e89f30270d4f7597639b33f30ad2e3a6\nCloses-Bug: #1549867\n'}, {'number': 2, 'created': '2016-03-04 14:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d584fa5094331dce1e164c231d9f42a84ce6fba', 'message': 'Run keystone-manage bootstrap for HA deployment too\n\nThis is necessary to keep creating the Default domain.\n\nChange-Id: Ib9911819e89f30270d4f7597639b33f30ad2e3a6\nCloses-Bug: #1549867\n'}, {'number': 3, 'created': '2016-03-04 14:46:10.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/32185f750e84fddd64405f6abbb664492ed6f6d9', 'message': 'Run keystone-manage bootstrap for HA deployment too\n\nThis is necessary to keep creating the Default domain.\n\nChange-Id: Ib9911819e89f30270d4f7597639b33f30ad2e3a6\nCloses-Bug: #1549867\n'}]",0,288460,32185f750e84fddd64405f6abbb664492ed6f6d9,16,6,3,8042,,,0,"Run keystone-manage bootstrap for HA deployment too

This is necessary to keep creating the Default domain.

Change-Id: Ib9911819e89f30270d4f7597639b33f30ad2e3a6
Closes-Bug: #1549867
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/288460/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,b8c1dafb573b9c97573962dde0c7d7af11caca32,bug/1549867,"$enable_keystone_bootstrap = $pacemaker_master and hiera('step') >= 5 enable_bootstrap => $enable_keystone_bootstrap,"," # TODO: when keystone resources will be managed by puppet-keystone # for the overcloud, set enable_bootstrap to the default value (True). enable_bootstrap => false,",2,3
openstack%2Fpython-openstackclient~master~Idd961a5fa3db825353700837a559621d17f782c5,openstack/python-openstackclient,master,Idd961a5fa3db825353700837a559621d17f782c5,[Volume] Check return value is None in volume unit tests,MERGED,2016-03-04 04:03:47.000000000,2016-03-04 17:55:26.000000000,2016-03-04 17:55:25.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-03-04 04:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a92bcf156861c97d08cd985373bbb72bad7c525c', 'message': '[Volume] Check return value is None in volume unit tests\n\ntake_action() in commands inheriting from Command returns nothing.\nSo we should assert the return is None in the unit tests of these\ncommands.\n\nChange-Id: Idd961a5fa3db825353700837a559621d17f782c5\nPartial-Bug: #1550636\n'}, {'number': 2, 'created': '2016-03-04 06:26:35.000000000', 'files': ['openstackclient/tests/volume/v2/test_backup.py', 'openstackclient/tests/volume/v1/test_qos_specs.py', 'openstackclient/tests/volume/v1/test_volume.py', 'openstackclient/tests/volume/v2/test_volume.py', 'openstackclient/tests/volume/v2/test_qos_specs.py', 'openstackclient/tests/volume/v2/test_type.py', 'openstackclient/tests/volume/v2/test_snapshot.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b58dd4f17f60b3c6347683b619c093b8d1a40c0b', 'message': '[Volume] Check return value is None in volume unit tests\n\ntake_action() in commands inheriting from Command returns nothing.\nSo we should assert the return is None in the unit tests of these\ncommands.\n\nChange-Id: Idd961a5fa3db825353700837a559621d17f782c5\nPartial-Bug: #1550636\n'}]",0,288241,b58dd4f17f60b3c6347683b619c093b8d1a40c0b,9,3,2,14937,,,0,"[Volume] Check return value is None in volume unit tests

take_action() in commands inheriting from Command returns nothing.
So we should assert the return is None in the unit tests of these
commands.

Change-Id: Idd961a5fa3db825353700837a559621d17f782c5
Partial-Bug: #1550636
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/41/288241/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/volume/v2/test_backup.py', 'openstackclient/tests/volume/v1/test_qos_specs.py', 'openstackclient/tests/volume/v1/test_volume.py', 'openstackclient/tests/volume/v2/test_volume.py', 'openstackclient/tests/volume/v2/test_qos_specs.py', 'openstackclient/tests/volume/v2/test_type.py', 'openstackclient/tests/volume/v2/test_snapshot.py']",7,a92bcf156861c97d08cd985373bbb72bad7c525c,bug/1550636," result = self.cmd.take_action(parsed_args) self.assertIsNone(result) parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) self.assertIsNone(result) result = self.cmd.take_action(parsed_args) self.assertIsNone(result)"," self.cmd.take_action(parsed_args) parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) self.cmd.take_action(parsed_args)",87,49
openstack%2Fkolla~master~I5fb534729c238e277435848c2f7ce76a50bd5d6d,openstack/kolla,master,I5fb534729c238e277435848c2f7ce76a50bd5d6d,Reconfigure for Memcached,MERGED,2016-03-04 00:28:58.000000000,2016-03-04 17:55:12.000000000,2016-03-04 17:55:12.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-03-04 00:28:58.000000000', 'files': ['ansible/roles/memcached/tasks/reconfigure.yml', 'ansible/roles/memcached/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8077173ceb9117b6510ebc48fc7f94d247c98fb8', 'message': 'Reconfigure for Memcached\n\nAdd reconfiguration for memcached\nuntested\n\nChange-Id: I5fb534729c238e277435848c2f7ce76a50bd5d6d\n'}]",1,288196,8077173ceb9117b6510ebc48fc7f94d247c98fb8,12,5,1,20815,,,0,"Reconfigure for Memcached

Add reconfiguration for memcached
untested

Change-Id: I5fb534729c238e277435848c2f7ce76a50bd5d6d
",git fetch https://review.opendev.org/openstack/kolla refs/changes/96/288196/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/memcached/tasks/reconfigure.yml', 'ansible/roles/memcached/tasks/do_reconfigure.yml']",2,8077173ceb9117b6510ebc48fc7f94d247c98fb8,bp/kolla-reconfig,"--- - name: Ensuring the containers up kolla_docker: name: ""{{ item.name }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false when: inventory_hostname in groups[item.group] with_items: - { name: memcached, group: memcached } - include: config.yml - name: Check the configs command: docker exec {{ item.name }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false register: check_results when: inventory_hostname in groups[item.group] with_items: - { name: memcached, group: memcached } # NOTE(jeffrey4l): when config_strategy == 'COPY_ALWAYS' # and container env['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE', # just remove the container and start again - name: Containers config strategy kolla_docker: name: ""{{ item.name }}"" action: ""get_container_env"" register: container_envs when: inventory_hostname in groups[item.group] with_items: - { name: memcached, group: memcached } - name: Remove the containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""remove_container"" register: remove_containers when: - config_strategy == ""COPY_ONCE"" or item[1]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - { name: memcached, group: memcached } - container_envs.results - check_results.results - include: start.yml when: remove_containers.changed - name: Restart containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""restart_container"" when: - config_strategy == 'COPY_ALWAYS' - item[1]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[2]['rc'] == 1 - inventory_hostname in groups[item[0]['group']] with_together: - { name: memcached, group: memcached } - container_envs.results - check_results.results ",,67,0
openstack%2Fopenstack-ansible-os_keystone~master~I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b,openstack/openstack-ansible-os_keystone,master,I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b,Enable SSL termination for all services,MERGED,2016-03-03 17:03:10.000000000,2016-03-04 17:54:54.000000000,2016-03-04 17:54:54.000000000,"[{'_account_id': 3}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 17:03:10.000000000', 'files': ['templates/keystone.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/107bed13e39f4e8e0fb5ab44aa8a4912ea372b6f', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b\nRe-Implementation-Of: https://review.openstack.org/#/c/277199/9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,287980,107bed13e39f4e8e0fb5ab44aa8a4912ea372b6f,6,2,1,7353,,,0,"Enable SSL termination for all services

This change makes it so that all services are expecting SSL termination
at the load balancer by default. This is more indicative of how a real
world deployment will be setup and is being added such that we can test
a more production like deployment system by default.

The AIO will now terminate SSL in HAProxy using a self-signed cert.

Change-Id: I09a7b9f0f180a79b4f46bb51322f96b1b2715f5b
Re-Implementation-Of: https://review.openstack.org/#/c/277199/9
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/80/287980/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/keystone.conf.j2', 'defaults/main.yml']",2,107bed13e39f4e8e0fb5ab44aa8a4912ea372b6f,,# External SSL forwarding proto keystone_ssl_external: true keystone_secure_proxy_ssl_header: HTTP_X_FORWARDED_PROTO ,## Secure Proxy SSL Information #keystone_secure_proxy_ssl_header: X-Forwarded-For ,5,4
openstack%2Fmanila-image-elements~master~I1282ddd84ec4693696135a12b0a0ea5a954ea1e4,openstack/manila-image-elements,master,I1282ddd84ec4693696135a12b0a0ea5a954ea1e4,Provide link to where images are uploaded,MERGED,2016-03-04 16:40:49.000000000,2016-03-04 17:54:38.000000000,2016-03-04 17:54:38.000000000,"[{'_account_id': 3}, {'_account_id': 8851}, {'_account_id': 11865}, {'_account_id': 16643}]","[{'number': 1, 'created': '2016-03-04 16:40:49.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/manila-image-elements/commit/8ada4c7949cbc1221a81c9a8c68b2e77cdad6b75', 'message': 'Provide link to where images are uploaded\n\nNow that images are automatically uploaded to tarballs site,\nprovide a link so people can just download images without needing\nto pull the source and build their own.\n\nChange-Id: I1282ddd84ec4693696135a12b0a0ea5a954ea1e4\n'}]",0,288573,8ada4c7949cbc1221a81c9a8c68b2e77cdad6b75,8,4,1,2417,,,0,"Provide link to where images are uploaded

Now that images are automatically uploaded to tarballs site,
provide a link so people can just download images without needing
to pull the source and build their own.

Change-Id: I1282ddd84ec4693696135a12b0a0ea5a954ea1e4
",git fetch https://review.opendev.org/openstack/manila-image-elements refs/changes/73/288573/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8ada4c7949cbc1221a81c9a8c68b2e77cdad6b75,doc_tarballs_site,* Built Images: http://tarballs.openstack.org/manila-image-elements/images,,1,0
openstack%2Fopenstack-ansible-os_swift~master~I6273ffa453b4e5eb8a33767974d390a126296c47,openstack/openstack-ansible-os_swift,master,I6273ffa453b4e5eb8a33767974d390a126296c47,Enable SSL termination for all services,MERGED,2016-03-03 16:47:00.000000000,2016-03-04 17:54:28.000000000,2016-03-04 17:54:28.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-03-03 16:47:00.000000000', 'files': ['templates/proxy-server.conf.j2', 'templates/swift-dispersion.conf.j2', 'tasks/swift_service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/77f6ab08b0e79694395cb4b76630642b4f0c6692', 'message': 'Enable SSL termination for all services\n\nThis change makes it so that all services are expecting SSL termination\nat the load balancer by default. This is more indicative of how a real\nworld deployment will be setup and is being added such that we can test\na more production like deployment system by default.\n\nThe AIO will now terminate SSL in HAProxy using a self-signed cert.\n\nChange-Id: I6273ffa453b4e5eb8a33767974d390a126296c47\nRe-Implementation-Of: https://review.openstack.org/#/c/277199/9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,287975,77f6ab08b0e79694395cb4b76630642b4f0c6692,7,3,1,7353,,,0,"Enable SSL termination for all services

This change makes it so that all services are expecting SSL termination
at the load balancer by default. This is more indicative of how a real
world deployment will be setup and is being added such that we can test
a more production like deployment system by default.

The AIO will now terminate SSL in HAProxy using a self-signed cert.

Change-Id: I6273ffa453b4e5eb8a33767974d390a126296c47
Re-Implementation-Of: https://review.openstack.org/#/c/277199/9
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/75/287975/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/proxy-server.conf.j2', 'templates/swift-dispersion.conf.j2', 'tasks/swift_service_setup.yml']",3,77f6ab08b0e79694395cb4b76630642b4f0c6692,," insecure: ""{{ keystone_service_adminuri_insecure }}"" insecure: ""{{ keystone_service_adminuri_insecure }}""",,4,0
openstack%2Fpython-keystoneclient~master~Ia79ed7a02a48553eba8eb83a654c3c75601fa07d,openstack/python-keystoneclient,master,Ia79ed7a02a48553eba8eb83a654c3c75601fa07d,Update Client examples to use sessions,MERGED,2016-02-28 15:12:12.000000000,2016-03-04 17:49:49.000000000,2016-03-04 17:49:49.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 20259}]","[{'number': 1, 'created': '2016-02-28 15:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1a6b739bda9d2b60555c20afbda47f1d9eed2d7f', 'message': ""Update Client examples to use sessions\n\nThe docstring examples in the v2_0 and v3 Client classes showed\npassing username and password. Passing username and password is\ndeprecated in favor of using keystoneauth session. The examples\nshouldn't use deprecated behavior otherwise we'll never get\ndevelopers to stop using it.\n\nChange-Id: Ia79ed7a02a48553eba8eb83a654c3c75601fa07d\n""}, {'number': 2, 'created': '2016-02-28 17:17:51.000000000', 'files': ['keystoneclient/v2_0/client.py', 'keystoneclient/v3/client.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1a7552f40095904d8aa1bacd51ac8962717cad91', 'message': ""Update Client examples to use sessions\n\nThe docstring examples in the v2_0 and v3 Client classes showed\npassing username and password. Passing username and password is\ndeprecated in favor of using keystoneauth session. The examples\nshouldn't use deprecated behavior otherwise we'll never get\ndevelopers to stop using it.\n\nChange-Id: Ia79ed7a02a48553eba8eb83a654c3c75601fa07d\n""}]",0,285808,1a7552f40095904d8aa1bacd51ac8962717cad91,11,5,2,6486,,,0,"Update Client examples to use sessions

The docstring examples in the v2_0 and v3 Client classes showed
passing username and password. Passing username and password is
deprecated in favor of using keystoneauth session. The examples
shouldn't use deprecated behavior otherwise we'll never get
developers to stop using it.

Change-Id: Ia79ed7a02a48553eba8eb83a654c3c75601fa07d
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/08/285808/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v2_0/client.py', 'keystoneclient/v3/client.py']",2,1a6b739bda9d2b60555c20afbda47f1d9eed2d7f,deprecated," >>> from keystoneauth1.identity import v3 >>> from keystoneauth1 import session >>> auth = v3.Password(user_domain_name=DOMAIN_NAME, ... username=USER, ... password=PASS, ... project_domain_name=PROJECT_DOMAIN_NAME, ... project_name=PROJECT_NAME, ... auth_url=KEYSTONE_URL) >>> sess = session.Session(auth=auth) >>> keystone = client.Client(session=sess)"," >>> keystone = client.Client(user_domain_name=DOMAIN_NAME, ... username=USER, ... password=PASS, ... project_domain_name=PROJECT_DOMAIN_NAME, ... project_name=PROJECT_NAME, ... auth_url=KEYSTONE_URL) ...",33,19
openstack%2Fproject-config~master~Iad060e88d81fc1f73a65f38e5dbf251426c07fa7,openstack/project-config,master,Iad060e88d81fc1f73a65f38e5dbf251426c07fa7,Convert infra* jobs to ubuntu-trusty,MERGED,2016-03-04 16:39:43.000000000,2016-03-04 17:48:47.000000000,2016-03-04 17:48:47.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-03-04 16:39:43.000000000', 'files': ['jenkins/jobs/infra.yaml', 'jenkins/jobs/infra-publish-jobs.yaml', 'jenkins/jobs/infra-publications.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c7167cf9b6d5f27459f74f0573e9717b8a6713d5', 'message': 'Convert infra* jobs to ubuntu-trusty\n\nConvert infra* jobs that explicitely set bare-trusty to use\nubuntu-trusty.\n\nChange-Id: Iad060e88d81fc1f73a65f38e5dbf251426c07fa7\n'}]",0,288572,c7167cf9b6d5f27459f74f0573e9717b8a6713d5,9,5,1,6547,,,0,"Convert infra* jobs to ubuntu-trusty

Convert infra* jobs that explicitely set bare-trusty to use
ubuntu-trusty.

Change-Id: Iad060e88d81fc1f73a65f38e5dbf251426c07fa7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/288572/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/infra.yaml', 'jenkins/jobs/infra-publish-jobs.yaml', 'jenkins/jobs/infra-publications.yaml']",3,c7167cf9b6d5f27459f74f0573e9717b8a6713d5,bindep, node: ubuntu-trusty - install-distro-packages - revoke-sudo node: ubuntu-trusty - install-distro-packages - revoke-sudo, node: bare-trusty - revoke-sudo node: bare-trusty - revoke-sudo,20,13
openstack%2Fmonasca-agent~master~Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9,openstack/monasca-agent,master,Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9,Improved performance of process check,MERGED,2016-03-04 06:13:37.000000000,2016-03-04 17:46:00.000000000,2016-03-04 17:46:00.000000000,"[{'_account_id': 3}, {'_account_id': 11809}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 18179}]","[{'number': 1, 'created': '2016-03-04 06:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/8bc5477371f25924cc294a7d03a5cf8c2332abe6', 'message': 'Improved performance of process check\n\nMost of the time in the process check was spent on reading the command line.\nCaching that once up front reduces test time from ~118 seconds to ~17 seconds.\nTest script used was\n\nhttps://github.com/hpcloud-mon/monasca-perf/blob/master/monasca_perf/agent_plugin_test.py\n\nChange-Id: Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9\n'}, {'number': 2, 'created': '2016-03-04 07:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/46c74ab90612cc4b48fea60c57ed8b2608bb93bd', 'message': 'Improved performance of process check\n\nMost of the time in the process check was spent on reading the command line.\nCaching that once up front reduces test time from ~118 seconds to ~17 seconds.\nTest script used was\n\nhttps://github.com/hpcloud-mon/monasca-perf/blob/master/monasca_perf/agent_plugin_test.py\n\nChange-Id: Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9\n'}, {'number': 3, 'created': '2016-03-04 15:32:45.000000000', 'files': ['monasca_agent/collector/checks_d/process.py', 'tests/test_process.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/b5d70eee243ec19bfac98321fab8942dcadd29be', 'message': 'Improved performance of process check\n\nMost of the time in the process check was spent on reading the command line.\nCaching that once up front reduces test time from ~118 seconds to ~17 seconds.\nTest script used was\n\nhttps://github.com/hpcloud-mon/monasca-perf/blob/master/monasca_perf/agent_plugin_test.py\n\nChange-Id: Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9\n'}]",1,288259,b5d70eee243ec19bfac98321fab8942dcadd29be,16,5,3,14273,,,0,"Improved performance of process check

Most of the time in the process check was spent on reading the command line.
Caching that once up front reduces test time from ~118 seconds to ~17 seconds.
Test script used was

https://github.com/hpcloud-mon/monasca-perf/blob/master/monasca_perf/agent_plugin_test.py

Change-Id: Ib9d541a83dd7e6f866ee29d6b53e14d071131ad9
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/59/288259/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_agent/collector/checks_d/process.py'],1,8bc5477371f25924cc294a7d03a5cf8c2332abe6,,"from collections import namedtupleProcessStruct = namedtuple(""Process"", ""name pid username cmdline"") if proc.username == username: if proc.name == string: cmdline = proc.cmdline self._current_process_list = [] for process in psutil.process_iter(): p = ProcessStruct(name=process, pid=process.pid, username=process.username(), cmdline=process.cmdline()) self._current_process_list.append(p)", if proc.username() == username: if proc.name() == string: cmdline = proc.cmdline() self._current_process_list = [process for process in psutil.process_iter()],14,4
openstack%2Frally~master~I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab,openstack/rally,master,I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab,Refactored atomic action in authenticate scenario,MERGED,2016-02-01 20:42:33.000000000,2016-03-04 17:43:49.000000000,2016-03-04 17:43:48.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 20301}]","[{'number': 1, 'created': '2016-02-01 20:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b69e427cdb9779f472b9212f8bf336c4147bbf36', 'message': 'Refactored authenticate.py to remove atomic actions from loops when performing multiple repititions.\n\nbug #1540545\n\nChange-Id: I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab\n'}, {'number': 2, 'created': '2016-02-02 16:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c6d39adb50c44de7f3d0ba412cac529b9a9b8592', 'message': 'Refactored authenticate.py to remove atomic actions from loops when performing multiple repititions.\n\nbug #1540545\n\nChange-Id: I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab\n'}, {'number': 3, 'created': '2016-02-02 20:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6dd7dc5e82d0520fc965badca27bc4d8b2c2e1db', 'message': 'Refactored authenticate.py to remove atomic actions from loops when performing multiple repititions.\n\nCloses-bug: #1540545\n\nChange-Id: I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab\n'}, {'number': 4, 'created': '2016-03-02 19:22:42.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/authenticate/test_authenticate.py', 'rally/plugins/openstack/scenarios/authenticate/authenticate.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/abff77ae79e4949d88c69a945844f4d4a43fcf34', 'message': 'Refactored atomic action in authenticate scenario\n\nCloses-bug: #1540545\n\nChange-Id: I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab\n'}]",2,274882,abff77ae79e4949d88c69a945844f4d4a43fcf34,28,7,4,20301,,,0,"Refactored atomic action in authenticate scenario

Closes-bug: #1540545

Change-Id: I4ec7d07607fa6ac2e1befe262a1c80ce4f9b4eab
",git fetch https://review.opendev.org/openstack/rally refs/changes/82/274882/4 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/scenarios/authenticate/authenticate.py'],1,b69e427cdb9779f472b9212f8bf336c4147bbf36,bug/1540545," with atomic.ActionTimer(self, ""authenticate.validate_glance_%s_times"" % repetitions): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_nova_%s_times"" % repetitions): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_cinder_%s_times"" % repetitions): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_neutron_%s_times"" % repetitions): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_heat_%s_times"" % repetitions): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_monasca_%s_times"" % repetitions): for i in range(repetitions):"," for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_glance""): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_nova""): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_cinder""): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_neutron""): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_heat""): for i in range(repetitions): with atomic.ActionTimer(self, ""authenticate.validate_monasca""):",12,12
openstack%2Fopenstack-manuals~master~I686bdda2ee27de4e5c43bb8d95c0126c8c300558,openstack/openstack-manuals,master,I686bdda2ee27de4e5c43bb8d95c0126c8c300558,Add manila install guide documentation,MERGED,2016-01-28 19:48:27.000000000,2016-03-04 17:43:28.000000000,2016-03-04 17:43:28.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 2417}, {'_account_id': 6547}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 9382}, {'_account_id': 9515}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14963}, {'_account_id': 14966}, {'_account_id': 14967}, {'_account_id': 16233}, {'_account_id': 19222}, {'_account_id': 19779}, {'_account_id': 20831}]","[{'number': 1, 'created': '2016-01-28 19:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/638412398773e533537121179df4b030cfa39575', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 2, 'created': '2016-02-02 20:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e394ca2e60d3dbbff29fd56eea86056e7720e258', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 3, 'created': '2016-02-12 19:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6c2b3eaace8d1177f61fab8c77c406f7c89601d4', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 4, 'created': '2016-02-15 20:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ff3e176750969f6e86ba606748679207748325e', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 5, 'created': '2016-02-16 17:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6c0ea3868768500ddfe6a7865ce615e5bb8e2f2e', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 6, 'created': '2016-02-16 19:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fc780980b015a86588de7bda5cefdcf9b933b21b', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 7, 'created': '2016-02-19 15:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/899c9dcc84cda158fd57d782ecbd78c817a80bc6', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 8, 'created': '2016-02-19 18:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4138df75c7867bf97ff5b784788fd45a185cc6dd', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 9, 'created': '2016-02-19 19:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/62433ee862c08f66e064a39a3d57930c84f859ec', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 10, 'created': '2016-02-19 21:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a7fd6361cb37300326fae1f9489968edba203b37', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 11, 'created': '2016-02-22 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9573dece88541d0be2dad5d44c62032b4a00118f', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 12, 'created': '2016-02-25 00:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fe74e02e9feb37781c73eb5e137583e3edec854a', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 13, 'created': '2016-02-25 10:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da901a04e21f3a8aa293ae94bda983ac5ea9c07f', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 14, 'created': '2016-02-25 17:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/29dd3330636bb3614c99ae9c6891e0ff69a85533', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 15, 'created': '2016-02-26 15:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eae3611fd7d4b706fdd127f120636d436630a422', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 16, 'created': '2016-03-02 11:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/01a76b410b27ce12891f781f34a7dc573a5da947', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 17, 'created': '2016-03-02 16:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/effc0c9c061aeae7ab790a55959ec9ab81308be1', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 18, 'created': '2016-03-02 17:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6f308eefbc20d10826e8c1b68a2c7c5bb169d6c5', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}, {'number': 19, 'created': '2016-03-04 11:03:26.000000000', 'files': ['doc/install-guide/source/launch-instance-manila.rst', 'doc/install-guide/source/manila-next-steps.rst', 'doc/install-guide/source/conf.py', 'doc/install-guide/source/launch-instance.rst', 'doc/install-guide/source/manila-share-install.rst', 'doc/install-guide/source/manila.rst', 'doc/common/get_started_file_storage.rst', 'doc/install-guide/source/index.rst', 'doc/install-guide/source/manila-controller-install.rst', 'doc/install-guide/source/manila-verify.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/51b44ccdc78625dad490e911e6f12e0b4eb49d53', 'message': 'Add manila install guide documentation\n\nIt is an effort to document manila install guide.\nOnly Ubuntu distro has been properly updated until now.\nLiberty packages have been used for the tests, but it can be\nchanged to mitaka as soon as they are available. Thanks in\nadvance for any feedback about this initial effort.\n\nChange-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558\nImplements: blueprint create-manila-install-guide\n'}]",178,273724,51b44ccdc78625dad490e911e6f12e0b4eb49d53,87,18,19,14966,,,0,"Add manila install guide documentation

It is an effort to document manila install guide.
Only Ubuntu distro has been properly updated until now.
Liberty packages have been used for the tests, but it can be
changed to mitaka as soon as they are available. Thanks in
advance for any feedback about this initial effort.

Change-Id: I686bdda2ee27de4e5c43bb8d95c0126c8c300558
Implements: blueprint create-manila-install-guide
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/273724/17 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/launch-instance-manila.rst', 'doc/install-guide/source/manila-next-steps.rst', 'doc/install-guide/source/manila-share-install.rst', 'doc/install-guide/source/manila.rst', 'doc/install-guide/source/index.rst', 'doc/install-guide/source/manila-controller-install.rst', 'doc/install-guide/source/manila-verify.rst']",7,638412398773e533537121179df4b030cfa39575,bp/create-manila-install-guide,".. _manila-verify: Verify operation ~~~~~~~~~~~~~~~~ Verify operation of the Share File System service. .. note:: Perform these commands on the controller node. #. Source the ``admin`` credentials to gain access to admin-only CLI commands: .. code-block:: console $ source admin-openrc.sh #. At using manila client, use keystone authentication version 2: .. code-block:: console $ export OS_AUTH_URL=http://controller:35357/v2.0 $ export OS_IDENTITY_API_VERSION=2 #. List service components to verify successful launch of each process: .. code-block:: console $ manila service-list +------------------+------------+------+---------+-------+----------------------------+---------------------+ | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | +------------------+------------+------+---------+-------+----------------------------+---------------------+ | manila-scheduler | controller | nova | enabled | up | 2014-10-18T01:30:54.000000 | None | | manila-share | share1@generic | nova | enabled | up | 2014-10-18T01:30:57.000000 | None | +------------------+------------+------+---------+-------+----------------------------+---------------------+ ",,1018,0
openstack%2Frequirements~master~If450efce9a7e2fa435b8b9e983ad22f6a883a059,openstack/requirements,master,If450efce9a7e2fa435b8b9e983ad22f6a883a059,Bump openstacksdk version to 0.8.1,MERGED,2016-02-27 01:32:44.000000000,2016-03-04 17:40:02.000000000,2016-03-04 17:40:02.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-27 01:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2a082d7a7b062e13b30f124e4b732ecefb0e1e4e', 'message': 'Bump openstacksdk version to 0.8.0\n\nThis patch propose bumping openstacksdk version from 0.7.4 to 0.8.0.\n\nChange-Id: If450efce9a7e2fa435b8b9e983ad22f6a883a059\n'}, {'number': 2, 'created': '2016-03-03 15:48:37.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6ec5270f151ce2bf6c1642fa5e3993d11ca06fa7', 'message': 'Bump openstacksdk version to 0.8.1\n\nThis patch propose bumping openstacksdk version from 0.7.4 to 0.8.1.\nVersion 0.7.4 was released back in Jan, 2016. Since then, there have\nbeen quite some changes including bug fixes. As of now, Senlin,\npython-senlinclient, python-openstackclient are among the users of this\nlibrary. Actually, since the deprecation of apiclient from oslo,\nswitching to openstacksdk is the best option for some teams.\nsenlin and python-senlinclient requires this specific version to\nfunction correctly.\n\nChange-Id: If450efce9a7e2fa435b8b9e983ad22f6a883a059\n'}]",0,285599,6ec5270f151ce2bf6c1642fa5e3993d11ca06fa7,15,6,2,8246,,,0,"Bump openstacksdk version to 0.8.1

This patch propose bumping openstacksdk version from 0.7.4 to 0.8.1.
Version 0.7.4 was released back in Jan, 2016. Since then, there have
been quite some changes including bug fixes. As of now, Senlin,
python-senlinclient, python-openstackclient are among the users of this
library. Actually, since the deprecation of apiclient from oslo,
switching to openstacksdk is the best option for some teams.
senlin and python-senlinclient requires this specific version to
function correctly.

Change-Id: If450efce9a7e2fa435b8b9e983ad22f6a883a059
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/285599/2 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,2a082d7a7b062e13b30f124e4b732ecefb0e1e4e,bump-sdk-version,openstacksdk===0.8.0,openstacksdk===0.7.4,2,2
openstack%2Fhorizon~master~I25dd5bfcaa888b688a6834ef01d79f856d397d87,openstack/horizon,master,I25dd5bfcaa888b688a6834ef01d79f856d397d87,Horizon's list of http exceptions is incomplete,ABANDONED,2015-08-28 15:40:20.000000000,2016-03-04 17:38:55.000000000,,"[{'_account_id': 3}, {'_account_id': 8040}, {'_account_id': 9659}]","[{'number': 1, 'created': '2015-08-28 15:40:20.000000000', 'files': ['horizon/exceptions.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1091ccd52977f8d7651cd5ecd61722d983cf89df', 'message': 'Horizon\'s list of http exceptions is incomplete\n\nCurrently, in horizon/exceptions.py, we have many of the http-status\ncode errors wrapped up in exceptions. But we don\'t have all of them. For\nthe sake of completeness, and to not force people to create them\nthemselves, and therefore likely having some overlap.\n\nHere\'s a good source for a somewhat exhaustive list:\n\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n\nIt\'s also entirely possible that we only want to complete the\nstatus-codes that would be relayed back to users for their own errors.\nSomething like ""all the 4XX"" erorrs.\n\nI\'ll start with just the 4XX errors and see if people argue on Gerrit.\n\nChange-Id: I25dd5bfcaa888b688a6834ef01d79f856d397d87\nCloses-Bug: #1489930\n'}]",0,218360,1091ccd52977f8d7651cd5ecd61722d983cf89df,10,3,1,9659,,,0,"Horizon's list of http exceptions is incomplete

Currently, in horizon/exceptions.py, we have many of the http-status
code errors wrapped up in exceptions. But we don't have all of them. For
the sake of completeness, and to not force people to create them
themselves, and therefore likely having some overlap.

Here's a good source for a somewhat exhaustive list:

http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html

It's also entirely possible that we only want to complete the
status-codes that would be relayed back to users for their own errors.
Something like ""all the 4XX"" erorrs.

I'll start with just the 4XX errors and see if people argue on Gerrit.

Change-Id: I25dd5bfcaa888b688a6834ef01d79f856d397d87
Closes-Bug: #1489930
",git fetch https://review.opendev.org/openstack/horizon refs/changes/60/218360/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/exceptions.py'],1,1091ccd52977f8d7651cd5ecd61722d983cf89df,bug/1489930,"class BadRequest(HorizonException): """"""Generic error to replace all ""Bad Request""-type API errors."""""" status_code = 400 # 402 - Payment Required is reserved for future use. # http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html class MethodNotAllowed(HorizonException): """"""Generic error to replace all ""Not Found""-type API errors."""""" status_code = 405 class NotAcceptable(HorizonException): """"""Generic error to replace all ""Not Acceptable""-type API errors. See 10.4.7 of http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html """""" status_code = 406 class ProxyAuthenticationRequired(HorizonException): """"""Generic error to replace all ""Proxy Authentication Required""-type API errors. """""" status_code = 407 class RequestTimeout(HorizonException): """"""Generic error to replace all ""Request Timeout""-type API errors."""""" status_code = 408 class Gone(HorizonException): """"""Generic error to replace all ""Gone""-type API errors. See 10.4.7 of http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html """""" status_code = 410 class LengthRequired(HorizonException): """"""Generic error to replace all ""Length Required""-type API errors."""""" status_code = 411 class PreconditionFailed(HorizonException): """"""Generic error to replace all ""Precondition Failed""-type API errors."""""" status_code = 412 class RequestEntityTooLarge(HorizonException): """"""Generic error to replace all ""Request Entity Too Large""-type API errors. """""" status_code = 413 class RequestURITooLong(HorizonException): """"""Generic error to replace all ""Request URI Too Long""-type API errors."""""" status_code = 414 class UnsupportedMediaType(HorizonException): """"""Generic error to replace all ""Unsupported Media Type""-type API errors. """""" status_code = 415 class RequestedRangeNotSatisfiable(HorizonException): """"""Generic error to replace all ""Requested Range Not Satisfiable""-type API errors. """""" status_code = 416 class ExpectationFailed(HorizonException): """"""Generic error to replace all ""Expectation Failed""-type API errors."""""" status_code = 417 ",,81,0
openstack%2Fsearchlight~master~I960577854279476868fa1aa5973c319a520e359d,openstack/searchlight,master,I960577854279476868fa1aa5973c319a520e359d,Updated from global requirements,MERGED,2016-03-04 10:21:49.000000000,2016-03-04 17:37:22.000000000,2016-03-04 17:37:22.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 10063}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 10:21:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/942b7d3fd5d499b4ec9f2fd3f2d7bd99b7b7aaae', 'message': 'Updated from global requirements\n\nChange-Id: I960577854279476868fa1aa5973c319a520e359d\n'}]",0,288363,942b7d3fd5d499b4ec9f2fd3f2d7bd99b7b7aaae,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: I960577854279476868fa1aa5973c319a520e359d
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/63/288363/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,942b7d3fd5d499b4ec9f2fd3f2d7bd99b7b7aaae,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Foslo-specs~master~I5a48c4262a189af71689a937bb707f5ea7144c7e,openstack/oslo-specs,master,I5a48c4262a189af71689a937bb707f5ea7144c7e,PBR should allow for 4 component versions,ABANDONED,2015-07-24 16:56:58.000000000,2016-03-04 17:34:33.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1941}, {'_account_id': 4190}, {'_account_id': 5263}, {'_account_id': 5623}, {'_account_id': 9076}, {'_account_id': 11778}, {'_account_id': 12071}, {'_account_id': 16628}]","[{'number': 1, 'created': '2015-07-24 16:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8206f2e95041d6e84db4e8f31e41f343159df911', 'message': 'PBR could allow more than 3 components\n\nInitial commit of the spec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}, {'number': 2, 'created': '2015-07-24 17:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/f967e2f45650f5d521b3a47d7a77fb1706b5f91e', 'message': 'PBR could allow more than 3 components\n\nInitial commit of the spec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}, {'number': 3, 'created': '2015-11-04 03:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/79e1fbd3d5184486ff182576f9eb7401de56b046', 'message': 'PBR could allow more than 3 components\n\nInitial commit of the spec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}, {'number': 4, 'created': '2015-11-11 23:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/3df074e377972c7269039c121480eb0e75c352aa', 'message': 'PBR should allow for 4 component versions\n\nSpec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}, {'number': 5, 'created': '2015-11-11 23:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/fada97695e2a21fbf52cdd0fe7b18147d8199084', 'message': 'PBR should allow for 4 component versions\n\nSpec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}, {'number': 6, 'created': '2015-11-19 05:25:47.000000000', 'files': ['specs/liberty/pbr-fourth-component.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/372e8675675812b8e8cf7b596006cc33536289a1', 'message': 'PBR should allow for 4 component versions\n\nSpec for pbr to help support the xstatic use-case.\n\nChange-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e\n'}]",8,205623,372e8675675812b8e8cf7b596006cc33536289a1,35,11,6,9659,,,0,"PBR should allow for 4 component versions

Spec for pbr to help support the xstatic use-case.

Change-Id: I5a48c4262a189af71689a937bb707f5ea7144c7e
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/23/205623/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/pbr-3-component-limit.rst'],1,8206f2e95041d6e84db4e8f31e41f343159df911,pbr_fourth_component,"============================ pbr - More than 3 components ============================ Include the URL of your launchpad blueprint: # TODO Problem description =================== Horizon currently uses xstatic to package javascript libraries in a manner that is apparently acceptable to the distros and also works for everyone else. When we grab a javascript library (Jasmine 2.2.0 for example) we'd really like to have the xstatic-package's version represent the wrapped package's version. So jasmine-2.2.0 -> xstatic-jasmine-2.2.0.0 and if we need to make a change it would go to xstatic-jasmine-2.2.0.1 . Currently, when we tag our package with 2.2.0.2, the resulting wheel is named XStatic-Jasmine-2.2.0.dev1.tar.gz . This breaks the zuul deployment process (I don't know the correct name of the process.) But here's a sample result: http://logs.openstack.org/f8/f8f71eb0e7d2ab1567798986a6f32ac9de2c055d/release/xstatic-jasmine-pypi-both-upload/7523258/console.html Thus, our xstatic packages don't ever get to pypi. Proposed change =============== Allow a 4th component on version names, potentially only if an ""allow exceptions"" flag is specified. Alternatives ------------ Allow for N components ~~~~~~~~~~~~~~~~~~~~~~ Allow for an unspecified number of components, again potentially only if an ""allow exceptions"" flag is specified. Allow for X.Y.Z.postN ~~~~~~~~~~~~~~~~~~~~~ Since we are really only using this mechanism to wrap existing code (and thus their version numbers) the ""postN"" mechanism could be appropriate. In theory, the postN style changes don't allow for code changes and instead only metadata and doc fixes and ... Here's the relevant portion from https://www.python.org/dev/peps/pep-0440/#id26 The use of post-releases to publish maintenance releases containing actual bug fixes is strongly discouraged. In general, it is better to use a longer release number and increment the final component for each maintenance release. It's possible that we could consider the javascript code as the ""product"" and that our wrapping of it is metadata. But perhaps not. Impact on Existing APIs ----------------------- I do not know the impact on our build process or pbr or the packages that depend upon pbr. Security impact --------------- None Performance Impact ------------------ None Configuration Impact -------------------- None (Depending) Developer Impact ---------------- None Testing Impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Other contributors: Milestones ---------- Work Items ---------- Incubation ========== N/A Adoption -------- N/A Library ------- N/A Anticipated API Stabilization ----------------------------- N/A Documentation Impact ==================== Dependencies ============ None References ========== https://www.python.org/dev/peps/pep-0440/#post-releases http://semver.org/ ",,142,0
openstack%2Fnetworking-powervm~master~I334a0c1ae138e3e533ed40d1dcbbb3e363fd6155,openstack/networking-powervm,master,I334a0c1ae138e3e533ed40d1dcbbb3e363fd6155,Update the requirements,MERGED,2016-03-03 00:58:42.000000000,2016-03-04 17:33:53.000000000,2016-03-04 17:33:53.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 9623}, {'_account_id': 12947}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 18549}]","[{'number': 1, 'created': '2016-03-03 00:58:42.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-powervm/commit/df396bc4163b2936ff400908fb1229f02f5b6bfd', 'message': 'Update the requirements\n\nThis update brings changes in line with the global requirements.  Also\nincludes a setuptools version that prevents the docs build from failing.\n\nChange-Id: I334a0c1ae138e3e533ed40d1dcbbb3e363fd6155\n'}]",0,287535,df396bc4163b2936ff400908fb1229f02f5b6bfd,9,7,1,8190,,,0,"Update the requirements

This update brings changes in line with the global requirements.  Also
includes a setuptools version that prevents the docs build from failing.

Change-Id: I334a0c1ae138e3e533ed40d1dcbbb3e363fd6155
",git fetch https://review.opendev.org/openstack/networking-powervm refs/changes/35/287535/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,df396bc4163b2936ff400908fb1229f02f5b6bfd,req_update,mock>=1.2 # BSD,mock>=1.2;python_version<'3.3' # BSD,5,4
openstack%2Fcharm-neutron-api~master~I6ebee0ac3704a56f31ffbd48206360a3f0ba267a,openstack/charm-neutron-api,master,I6ebee0ac3704a56f31ffbd48206360a3f0ba267a,Changes for Calico networking with OpenStack Liberty,MERGED,2016-03-04 16:21:20.000000000,2016-03-04 17:25:48.000000000,2016-03-04 17:25:48.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 16:21:20.000000000', 'files': ['templates/liberty/neutron.conf', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/892db0dbd799f513a27e6186790ec74b3ada4cd3', 'message': 'Changes for Calico networking with OpenStack Liberty\n\n- Stable PPA source for Liberty onwards\n- New neutron.conf for Liberty without dhcp_agents_per_network = 1000\n- Testing for PPA source\n\nChange-Id: I6ebee0ac3704a56f31ffbd48206360a3f0ba267a\n'}]",0,288565,892db0dbd799f513a27e6186790ec74b3ada4cd3,7,3,1,13734,,,0,"Changes for Calico networking with OpenStack Liberty

- Stable PPA source for Liberty onwards
- New neutron.conf for Liberty without dhcp_agents_per_network = 1000
- Testing for PPA source

Change-Id: I6ebee0ac3704a56f31ffbd48206360a3f0ba267a
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/65/288565/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/liberty/neutron.conf', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py']",3,892db0dbd799f513a27e6186790ec74b3ada4cd3,calico-liberty-support," def test_calico_source_liberty(self): self.get_os_codename_install_source.return_value = 'liberty' nutils.additional_install_locations('Calico', '') self.add_source.assert_called_with('ppa:project-calico/stable') ",,16,5
openstack%2Fglance~master~Iad4e1df61b26ce469c22da9321d448adbd822668,openstack/glance,master,Iad4e1df61b26ce469c22da9321d448adbd822668,Resolve i18n and Sphinx issues in signature_utils,MERGED,2016-02-25 14:10:59.000000000,2016-03-04 17:21:23.000000000,2016-03-04 17:21:23.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6802}, {'_account_id': 6804}, {'_account_id': 14676}, {'_account_id': 15524}, {'_account_id': 17123}]","[{'number': 1, 'created': '2016-02-25 14:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0422d02de45b4af342cabf938043186263703395', 'message': 'Resolve i18n and Sphinx issues in signature_utils\n\nThis patch makes the existing error messages in the\nsignature_utils module i18n-compliant and changes the\ndocstrings to include the full type name of the\nexceptions thrown by each method.\n\nChange-Id: Iad4e1df61b26ce469c22da9321d448adbd822668\n'}, {'number': 2, 'created': '2016-02-25 15:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f03a42bca47a9257f4144e13e70b1422d9ac8bd0', 'message': 'Resolve i18n and Sphinx issues in signature_utils\n\nThis patch makes the existing error messages in the\nsignature_utils module i18n-compliant and changes the\ndocstrings to include the full type name of the\nexceptions thrown by each method.\n\nChange-Id: Iad4e1df61b26ce469c22da9321d448adbd822668\n'}, {'number': 3, 'created': '2016-03-03 14:04:48.000000000', 'files': ['glance/common/signature_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0c439749f2095187aba4c4073d41a6c0f0675176', 'message': 'Resolve i18n and Sphinx issues in signature_utils\n\nThis patch makes the existing error messages in the\nsignature_utils module i18n-compliant and changes the\ndocstrings to include the full type name of the\nexceptions thrown by each method.\n\nChange-Id: Iad4e1df61b26ce469c22da9321d448adbd822668\n'}]",2,284726,0c439749f2095187aba4c4073d41a6c0f0675176,20,7,3,15524,,,0,"Resolve i18n and Sphinx issues in signature_utils

This patch makes the existing error messages in the
signature_utils module i18n-compliant and changes the
docstrings to include the full type name of the
exceptions thrown by each method.

Change-Id: Iad4e1df61b26ce469c22da9321d448adbd822668
",git fetch https://review.opendev.org/openstack/glance refs/changes/26/284726/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/signature_utils.py'],1,0422d02de45b4af342cabf938043186263703395,,"from glance.i18n import _, _LE :raises: glance.common.exception.SignatureVerificationError if the RSA-PSS specific properties are invalid _('Invalid mask_gen_algorithm: %s') % mask_gen_algorithm ) _('Invalid pss_salt_length: %s') % pss_salt_length ) :raises: glance.common.exception.SignatureVerificationError if verification fails _('Required image properties for signature verification do not' ' exist. Cannot verify signature.') ) _('Unable to verify signature since the algorithm is unsupported ' 'on this system') ) _('Signature verification failed.') ) _('Error occurred while verifying the signature') ) :raises: glance.common.exception.SignatureVerificationError if the signature data is malformatted _('The signature data was not properly encoded using base64') ) :raises: glance.common.exception.SignatureVerificationError if the hash method name is invalid _('Invalid signature hash method: %s') % hash_method_name ) :raises: glance.common.exception.SignatureVerificationError if the signature key type is invalid _('Invalid signature key type: %s') % signature_key_type ) :raises: glance.common.exception.SignatureVerificationError if public key format is invalid _('Invalid public key type for signature key type: %s') % signature_key_type ) :raises: glance.common.exception.SignatureVerificationError if the retrieval fails or the format is invalid _('Unable to retrieve certificate with ID: %s') % signature_certificate_uuid ) _('Invalid certificate format: %s') % cert.format ) _('Certificate format not supported: %s') % cert.format ) :raises: glance.common.exception.SignatureVerificationError if the certificate valid time range does not include now _('Certificate is not valid before: %s UTC') % certificate.not_valid_before ) _('Certificate is not valid after: %s UTC') % certificate.not_valid_after )",from glance.i18n import _LE :raises: SignatureVerificationError if the RSA-PSS specific properties are invalid 'Invalid mask_gen_algorithm: %s' % mask_gen_algorithm) 'Invalid pss_salt_length: %s' % pss_salt_length) :raises: SignatureVerificationError if verification fails 'Required image properties for signature verification do not' ' exist. Cannot verify signature.') 'Unable to verify signature since the algorithm is unsupported ' 'on this system') 'Signature verification failed.') 'Error occurred while verifying the signature') :raises: SignatureVerificationError if the signature data is malformatted 'The signature data was not properly encoded using base64') :raises: SignatureVerificationError if the hash method name is invalid 'Invalid signature hash method: %s' % hash_method_name) :raises: SignatureVerificationError if the signature key type is invalid 'Invalid signature key type: %s' % signature_key_type) :raises: SignatureVerificationError if public key format is invalid 'Invalid public key type for signature key type: %s' % signature_key_type) :raises: SignatureVerificationError if the retrieval fails or the format is invalid 'Unable to retrieve certificate with ID: %s' % signature_certificate_uuid) 'Invalid certificate format: %s' % cert.format) 'Certificate format not supported: %s' % cert.format) :raises: SignatureVerificationError if the certificate valid time range does not include now 'Certificate is not valid before: %s UTC' % certificate.not_valid_before) 'Certificate is not valid after: %s UTC' % certificate.not_valid_after),53,33
openstack%2Fcookbook-openstack-network~master~Ie64c46537da548fe0de9ef006aecee0ca08b4af3,openstack/cookbook-openstack-network,master,Ie64c46537da548fe0de9ef006aecee0ca08b4af3,python package dependency attributes need to be an array,MERGED,2016-03-04 12:45:44.000000000,2016-03-04 17:21:17.000000000,2016-03-04 17:21:17.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 14790}]","[{'number': 1, 'created': '2016-03-04 12:45:44.000000000', 'files': ['attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/e7aefcd3a8209b4c603647f4c0aef4616ab1f049', 'message': 'python package dependency attributes need to be an array\n\nChange-Id: Ie64c46537da548fe0de9ef006aecee0ca08b4af3\n'}]",0,288435,e7aefcd3a8209b4c603647f4c0aef4616ab1f049,7,3,1,11915,,,0,"python package dependency attributes need to be an array

Change-Id: Ie64c46537da548fe0de9ef006aecee0ca08b4af3
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/35/288435/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/default.rb'],1,e7aefcd3a8209b4c603647f4c0aef4616ab1f049,, %w(python-neutron-lbaas) %w(python-neutron-vpnaas), 'python-neutron-lbaas' 'python-neutron-vpnaas',2,2
openstack%2Fnetworking-odl~master~I5bfb83c2bdb703845d990a319724c26d1a809296,openstack/networking-odl,master,I5bfb83c2bdb703845d990a319724c26d1a809296,Unit test failures after recent neutron changes,ABANDONED,2016-02-15 19:41:21.000000000,2016-03-04 17:20:59.000000000,,"[{'_account_id': 3}, {'_account_id': 107}, {'_account_id': 333}, {'_account_id': 10386}, {'_account_id': 11114}, {'_account_id': 17377}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-15 19:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/8b52b04363ad13433636fc344b30ecdb65f12b3e', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 2, 'created': '2016-02-15 19:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/c9d9b2614ced297ee35993964a7c3126515714e9', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 3, 'created': '2016-02-17 15:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/987297a780e47e0c171dd4cadfac8a077b3f7f59', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 4, 'created': '2016-02-19 21:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/246bd5c62b94f4f80feb1749cd5a975e0a645b51', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 5, 'created': '2016-02-22 10:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/da2cbd73d0f9f5f3fff1cf8aac81b98731be3e7e', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nCo-Authored-By: Arvind Somya <asomya@cisco.com>\nCo-Authored-By: Federico Ressi <federico.ressi@intel.com>\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 6, 'created': '2016-02-24 17:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/de3ae1ce2f2c0b064dd294e320f4d518021b9e4b', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nCo-Authored-By: Arvind Somya <asomya@cisco.com>\nCo-Authored-By: Federico Ressi <federico.ressi@intel.com>\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 7, 'created': '2016-03-03 09:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/cb4efee145c1bcadab8f1117112c352d099e9014', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nCo-Authored-By: Arvind Somya <asomya@cisco.com>\nCo-Authored-By: Federico Ressi <federico.ressi@intel.com>\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}, {'number': 8, 'created': '2016-03-04 10:15:13.000000000', 'files': ['networking_odl/tests/unit/ml2/test_mechanism_odl.py', 'networking_odl/ml2/network_topology.py'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/3a035f3856d0c3010d39c4f91a5acbdf80e90b28', 'message': ""Unit test failures after recent neutron changes\n\nThis patch fixes the unit tests failure for the test\n'test_update_port_host_id_changed' after a change in Neutron\nintroduced the enw test.\n\nCo-Authored-By: Arvind Somya <asomya@cisco.com>\nCo-Authored-By: Federico Ressi <federico.ressi@intel.com>\nChange-Id: I5bfb83c2bdb703845d990a319724c26d1a809296\nCloses-bug: #1545827\n""}]",5,280374,3a035f3856d0c3010d39c4f91a5acbdf80e90b28,51,7,8,107,,,0,"Unit test failures after recent neutron changes

This patch fixes the unit tests failure for the test
'test_update_port_host_id_changed' after a change in Neutron
introduced the enw test.

Co-Authored-By: Arvind Somya <asomya@cisco.com>
Co-Authored-By: Federico Ressi <federico.ressi@intel.com>
Change-Id: I5bfb83c2bdb703845d990a319724c26d1a809296
Closes-bug: #1545827
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/74/280374/6 && git format-patch -1 --stdout FETCH_HEAD,"['networking_odl/common/utils.py', 'networking_odl/tests/unit/ml2/test_mechanism_odl.py', 'networking_odl/ml2/network_topology.py']",3,8b52b04363ad13433636fc344b30ecdb65f12b3e,bug/1545827, # The cache calls this method to fetch new elements when at least one, # The cache calls this method to fecth new elements when at least one,9,2
openstack%2Fpython-openstackclient~master~I8bfe67141572a0bf406959dea83eaf1f2c30b890,openstack/python-openstackclient,master,I8bfe67141572a0bf406959dea83eaf1f2c30b890,Updated from global requirements,MERGED,2016-03-04 10:21:04.000000000,2016-03-04 17:20:43.000000000,2016-03-04 17:20:42.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-03-04 10:21:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6a96ffc22130f2a852f3371df9aa1e0eb5de9934', 'message': 'Updated from global requirements\n\nChange-Id: I8bfe67141572a0bf406959dea83eaf1f2c30b890\n'}]",0,288360,6a96ffc22130f2a852f3371df9aa1e0eb5de9934,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I8bfe67141572a0bf406959dea83eaf1f2c30b890
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/60/288360/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6a96ffc22130f2a852f3371df9aa1e0eb5de9934,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Ffuel-docs~master~I2c6ecb67b3e324cc24002e385c6b9c17e74e45ce,openstack/fuel-docs,master,I2c6ecb67b3e324cc24002e385c6b9c17e74e45ce,Fix build dir to work in gate,MERGED,2016-03-04 14:17:22.000000000,2016-03-04 17:20:00.000000000,2016-03-04 17:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13505}, {'_account_id': 17626}]","[{'number': 1, 'created': '2016-03-04 14:17:22.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/71bb75019bca81845e0a5e8537565987a2192829', 'message': 'Fix build dir to work in gate\n\nChange-Id: I2c6ecb67b3e324cc24002e385c6b9c17e74e45ce\n'}]",0,288469,71bb75019bca81845e0a5e8537565987a2192829,12,4,1,9977,,,0,"Fix build dir to work in gate

Change-Id: I2c6ecb67b3e324cc24002e385c6b9c17e74e45ce
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/69/288469/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,71bb75019bca81845e0a5e8537565987a2192829,fix-build-dir,build-dir = doc/build,build-dir = build,1,1
openstack%2Fos-win~master~I6a23a5097372df24a6815693a5fb025ad3b192f5,openstack/os-win,master,I6a23a5097372df24a6815693a5fb025ad3b192f5,Removes forgotten TODO and __init__,MERGED,2016-03-03 17:05:21.000000000,2016-03-04 17:18:49.000000000,2016-03-04 17:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2016-03-03 17:05:21.000000000', 'files': ['os_win/utils/pathutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/4d473a72824fe64d0326deee64a7a59a01e82ead', 'message': 'Removes forgotten TODO and __init__\n\nThe TODO in question was addressed in a previous commit, but\nthe comment was not removed.\nAlso, the __init__ is in the same situation.\n\nChange-Id: I6a23a5097372df24a6815693a5fb025ad3b192f5\n'}]",0,287982,4d473a72824fe64d0326deee64a7a59a01e82ead,8,2,1,8213,,,0,"Removes forgotten TODO and __init__

The TODO in question was addressed in a previous commit, but
the comment was not removed.
Also, the __init__ is in the same situation.

Change-Id: I6a23a5097372df24a6815693a5fb025ad3b192f5
",git fetch https://review.opendev.org/openstack/os-win refs/changes/82/287982/1 && git format-patch -1 --stdout FETCH_HEAD,['os_win/utils/pathutils.py'],1,4d473a72824fe64d0326deee64a7a59a01e82ead,,,"# TODO(claudiub): Remove PathUtils parent class when the SMB related methods # are called from SMBUtils. super(PathUtils, self).__init__()",0,4
openstack%2Foctavia~master~I08d778537cf3e9d08959772afe4613307cc4b932,openstack/octavia,master,I08d778537cf3e9d08959772afe4613307cc4b932,Updated from global requirements,MERGED,2016-03-04 10:19:28.000000000,2016-03-04 17:15:39.000000000,2016-03-04 17:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 16272}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-03-04 10:19:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/1421d34b8dca07283039f4ab2dff9f64be0ad079', 'message': 'Updated from global requirements\n\nChange-Id: I08d778537cf3e9d08959772afe4613307cc4b932\n'}]",0,288358,1421d34b8dca07283039f4ab2dff9f64be0ad079,10,5,1,11131,,,0,"Updated from global requirements

Change-Id: I08d778537cf3e9d08959772afe4613307cc4b932
",git fetch https://review.opendev.org/openstack/octavia refs/changes/58/288358/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1421d34b8dca07283039f4ab2dff9f64be0ad079,openstack/requirements,python-glanceclient>=2.0.0 # Apache-2.0,python-glanceclient>=1.2.0 # Apache-2.0,1,1
openstack%2Fkolla~master~I085ef2884749bb4ecc546b78052a5688e8b36ad3,openstack/kolla,master,I085ef2884749bb4ecc546b78052a5688e8b36ad3,Set mongodb log file to shared volume by heka,MERGED,2016-03-04 03:52:24.000000000,2016-03-04 17:01:24.000000000,2016-03-04 17:01:23.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 16620}, {'_account_id': 16993}, {'_account_id': 19300}, {'_account_id': 19542}, {'_account_id': 20683}]","[{'number': 1, 'created': '2016-03-04 03:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/47952c34a180869ebda4a495f480258f250d334a', 'message': 'Set mongodb log file to shared volume by heka\n\nTrivialFix\n\nChange-Id: I085ef2884749bb4ecc546b78052a5688e8b36ad3\n'}, {'number': 2, 'created': '2016-03-04 16:06:35.000000000', 'files': ['ansible/roles/mongodb/templates/mongodb.conf.j2', 'ansible/roles/mongodb/tasks/bootstrap.yml', 'ansible/roles/mongodb/tasks/start.yml', 'docker/mongodb/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ef24d9e597a12c3bdb23bd49357e4b38609a1e19', 'message': 'Set mongodb log file to shared volume by heka\n\nTrivialFix\n\nChange-Id: I085ef2884749bb4ecc546b78052a5688e8b36ad3\n'}]",4,288238,ef24d9e597a12c3bdb23bd49357e4b38609a1e19,16,9,2,16993,,,0,"Set mongodb log file to shared volume by heka

TrivialFix

Change-Id: I085ef2884749bb4ecc546b78052a5688e8b36ad3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/288238/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/mongodb/templates/mongodb.conf.j2', 'ansible/roles/mongodb/tasks/bootstrap.yml', 'ansible/roles/mongodb/tasks/start.yml', 'docker/mongodb/extend_start.sh']",4,47952c34a180869ebda4a495f480258f250d334a,fix-mongodb-log,"if [[ ! -d ""/var/log/kolla/mongodb"" ]]; then mkdir -p /var/log/kolla/mongodb fi if [[ $(stat -c %a /var/log/kolla/mongodb) != ""755"" ]]; then chmod 755 /var/log/kolla/mongodb fi ",,11,1
openstack%2Fpuppet-cinder~master~I4f7e8137fa3e1ad3e141c58eaba110b12101d22c,openstack/puppet-cinder,master,I4f7e8137fa3e1ad3e141c58eaba110b12101d22c,Replace defines for managing cinder types with providers,MERGED,2016-01-28 12:54:27.000000000,2016-03-04 16:54:59.000000000,2016-03-04 16:30:06.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 8297}, {'_account_id': 8482}, {'_account_id': 8797}, {'_account_id': 9500}, {'_account_id': 14007}, {'_account_id': 14985}, {'_account_id': 16771}]","[{'number': 1, 'created': '2016-01-28 12:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/2421643cb9007e0171daef2b92849266989e8b3c', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 2, 'created': '2016-02-01 15:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/0773b7db673ee0037f34db93157a296e7b47b015', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 3, 'created': '2016-02-03 12:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/b0d2a037144f58c1e4cd0ab6693fab49b3157dcb', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 4, 'created': '2016-02-03 13:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/eb4dfdf05dc3139a12d76a5e7736a6ec7e667b33', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 5, 'created': '2016-02-04 10:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/6774fd204b7c4f85bfef88bd828af97ee77f0450', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 6, 'created': '2016-02-04 13:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/df702dce66ed777eedc825bafcf57383f8f6d70e', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 7, 'created': '2016-02-05 15:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7c650196efe36ada17331be5af1fab487c66a06c', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 8, 'created': '2016-02-08 17:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7c811c17a0835369c2734881a44985dea3edc20a', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nDepends-On: I2580796808ffbd603edfcafcde15df8c37b67a27\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 9, 'created': '2016-02-11 17:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/3d16805edae317d2437cfd26a901af2b941aafa5', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 10, 'created': '2016-02-12 14:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/13c0fc7405afd8c55665be87233c70c16a5439a5', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 11, 'created': '2016-02-15 09:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/d383273a433f074fbbe703f39b45935de5d2d235', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nDepends-On: I2580796808ffbd603edfcafcde15df8c37b67a27\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 12, 'created': '2016-02-16 15:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/89b32c0098d95afc1984e8fb6ec37e89771792e5', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nDepends-On: I2580796808ffbd603edfcafcde15df8c37b67a27\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 13, 'created': '2016-02-24 14:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/f3fdfef46082d32b48f658ec6ea1358282314681', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 14, 'created': '2016-03-03 17:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/c293b38e698f45c865e15ab05d089a5f4f2d061c', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}, {'number': 15, 'created': '2016-03-04 14:57:39.000000000', 'files': ['manifests/vmware.pp', 'spec/defines/cinder_type_spec.rb', 'spec/defines/cinder_type_set_spec.rb', 'lib/puppet/type/cinder_type.rb', 'manifests/type.pp', 'spec/unit/provider/cinder_spec.rb', 'spec/unit/provider/cinder_type/openstack_spec.rb', 'README.md', 'lib/puppet/provider/cinder_type/openstack.rb', 'manifests/type_set.pp', 'spec/unit/type/cinder_type_spec.rb', 'spec/classes/cinder_vmware_spec.rb', 'lib/puppet/provider/cinder.rb', 'manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9bc49efba89267967927f74d99cd6807b0fecae1', 'message': 'Replace defines for managing cinder types with providers\n\nWe have define classes, which allow to manage Cinder types and their\nproperties. This patch switches using of define classes to puppet\nproviders, based on openstack auth from openstacklib.\n\nrelated blueprint use-openstackclient-in-module-resources\n\nChange-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c\n'}]",22,273513,9bc49efba89267967927f74d99cd6807b0fecae1,135,12,15,7745,,,0,"Replace defines for managing cinder types with providers

We have define classes, which allow to manage Cinder types and their
properties. This patch switches using of define classes to puppet
providers, based on openstack auth from openstacklib.

related blueprint use-openstackclient-in-module-resources

Change-Id: I4f7e8137fa3e1ad3e141c58eaba110b12101d22c
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/13/273513/10 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/type/cinder_type_key.rb', 'spec/defines/cinder_type_spec.rb', 'spec/defines/cinder_type_set_spec.rb', 'lib/puppet/provider/cinder_type/openstack.rb', 'manifests/type_set.pp', 'lib/puppet/type/cinder_type.rb', 'manifests/type.pp', 'lib/puppet/provider/cinder_type_key/openstack.rb', 'lib/puppet/provider/cinder.rb']",9,2421643cb9007e0171daef2b92849266989e8b3c,bp/use-openstackclient-in-module-resources,"require 'puppet/util/inifile' require 'puppet/provider/openstack' require 'puppet/provider/openstack/auth' require 'puppet/provider/openstack/credentials' class Puppet::Provider::Cinder < Puppet::Provider::Openstack extend Puppet::Provider::Openstack::Auth def self.conf_filename '/etc/cinder/cinder.conf' end def self.cinder_conf return @cinder_conf if @cinder_conf @cinder_conf = Puppet::Util::IniConfig::File.new @cinder_conf.read(conf_filename) @cinder_conf end def self.request(service, action, properties=nil) begin super rescue Puppet::Error::OpenstackAuthInputError, Puppet::Error::OpenstackUnauthorizedError => error cinder_request(service, action, error, properties) end end def self.cinder_request(service, action, error, properties=nil) properties ||= [] @credentials.username = cinder_credentials['admin_user'] @credentials.password = cinder_credentials['admin_password'] @credentials.project_name = cinder_credentials['admin_tenant_name'] @credentials.auth_url = auth_endpoint raise error unless @credentials.set? Puppet::Provider::Openstack.request(service, action, properties, @credentials) end def self.withenv(hash, &block) saved = ENV.to_hash hash.each do |name, val| ENV[name.to_s] = val end yield ensure ENV.clear saved.each do |name, val| ENV[name] = val end end def self.cinder_credentials @cinder_credentials ||= get_cinder_credentials end def cinder_credentials self.class.cinder_credentials end def self.get_cinder_credentials auth_keys = ['auth_uri', 'admin_tenant_name', 'admin_user', 'admin_password'] conf = cinder_conf if conf and conf['keystone_authtoken'] and auth_keys.all?{|k| !conf['keystone_authtoken'][k].nil?} creds = Hash[ auth_keys.map \ { |k| [k, conf['keystone_authtoken'][k].strip] } ] if conf['DEFAULT'] and conf['DEFAULT']['os_region_name'] creds['os_region_name'] = conf['DEFAULT']['os_region_name'].strip end return creds else raise(Puppet::Error, ""File: #{conf_filename} does not contain all "" + ""required sections. Cinder types will not work if cinder is not "" + ""correctly configured."") end end def self.get_auth_endpoint q = cinder_credentials ""#{q['auth_uri']}"" end def self.auth_endpoint @auth_endpoint ||= get_auth_endpoint end def self.auth_cinder(*args) q = cinder_credentials authenv = { :OS_AUTH_URL => self.auth_endpoint, :OS_USERNAME => q['admin_user'], :OS_TENANT_NAME => q['admin_tenant_name'], :OS_PASSWORD => q['admin_password'] } if q.key?('os_region_name') authenv[:OS_REGION_NAME] = q['os_region_name'] end begin withenv authenv do cinder(args) end rescue Exception => e if (e.message =~ /\[Errno 111\] Connection refused/) or (e.message =~ /\(HTTP 400\)/) sleep 10 withenv authenv do cinder(args) end else raise(e) end end end def auth_cinder(*args) self.class.auth_cinder(args) end def self.reset @cinder_conf = nil @cinder_credentials = nil end end ",,285,242
openstack%2Fironic-ui~master~I76e6daaca705b3a023f8c15da600fd7bbfda3178,openstack/ironic-ui,master,I76e6daaca705b3a023f8c15da600fd7bbfda3178,Added registration of ironic-ui rest endpoints,ABANDONED,2016-03-04 16:44:11.000000000,2016-03-04 16:52:44.000000000,,[],"[{'number': 1, 'created': '2016-03-04 16:44:11.000000000', 'files': ['ironic_ui/content/ironic/urls.py'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/3df7f6ae516532b06a27590cc1f73300d91b3ef5', 'message': 'Added registration of ironic-ui rest endpoints\n\nChange-Id: I76e6daaca705b3a023f8c15da600fd7bbfda3178\n'}]",0,288577,3df7f6ae516532b06a27590cc1f73300d91b3ef5,2,0,1,19380,,,0,"Added registration of ironic-ui rest endpoints

Change-Id: I76e6daaca705b3a023f8c15da600fd7bbfda3178
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/77/288577/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_ui/content/ironic/urls.py'],1,3df7f6ae516532b06a27590cc1f73300d91b3ef5,,import ironic_ui.api.ironic_rest_api,,1,0
openstack%2Fbarbican~master~I1b2360d967bf4b8378eda4766c7ef3113eedffad,openstack/barbican,master,I1b2360d967bf4b8378eda4766c7ef3113eedffad,Make clean up of soft deletions configurable,MERGED,2016-02-25 17:14:52.000000000,2016-03-04 16:50:55.000000000,2016-03-04 16:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 11970}, {'_account_id': 14926}, {'_account_id': 15274}, {'_account_id': 16046}, {'_account_id': 17579}]","[{'number': 1, 'created': '2016-02-25 17:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e3ca1df88f87883ef396bf55397af7549d3fd3b8', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage\n    2) Make clean up configurable\n    3) Create documentation for clean up\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 2, 'created': '2016-02-25 19:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8db2ede025bdffce4ff219a810e7500287e41267', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage\n    2) Make clean up configurable and add documentation\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 3, 'created': '2016-02-26 20:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d47b7cdf9262ded1f735a6cfacf9d89b0c98134f', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage\n    2) Make clean up configurable and add documentation\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 4, 'created': '2016-03-01 15:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e1e19caf2d29a4689f380f35e032a986162829fd', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 5, 'created': '2016-03-01 18:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/38e9bd23d92a4b27cc034d22484e4eda533fb126', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 6, 'created': '2016-03-03 13:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ec8f7b24b2f97868e42941c3e7b55481601d1299', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 7, 'created': '2016-03-03 18:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7f38fa9291f08e58ead17604b9bf17ac6d41c997', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 8, 'created': '2016-03-03 22:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5ba9421673ecca3c40d84ddef6dd3750d478d343', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 9, 'created': '2016-03-03 22:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/81212ac72d87c16acbebc764dc17319ea16d4096', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}, {'number': 10, 'created': '2016-03-04 15:40:27.000000000', 'files': ['barbican/tests/cmd/test_db_cleanup.py', 'barbican/tests/database_utils.py', 'doc/source/admin-guide-cloud/barbican_manage.rst', 'barbican/model/clean.py', 'barbican/cmd/db_manage.py', 'barbican/cmd/barbican_manage.py', 'doc/source/admin-guide-cloud/database_cleaning.rst', 'barbican/tests/cmd/test_barbican_manage.py', 'doc/source/admin-guide-cloud/index.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/acd998c66f23345c79e9025bacb78184c6eaea70', 'message': 'Make clean up of soft deletions configurable\n\nAdds the following features to the command:\n1) Be able to set minimum number of days to keep soft deletions\n2) Clean unassociated projects\n3) Soft delete secrets that are expired\n4) Set verbose flag\n5) Set the log file location\n\nDocumentation for running the command was also added.\n\nThis is the second CR for cleaning up the barbican database.\n    1) Simple soft deletion clean up for barbican-db-manage.\n    2) Make clean up configurable and add documentation.\n\nChange-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad\nPartially-implements: blueprint clean-db-soft-deletes\n'}]",57,284821,acd998c66f23345c79e9025bacb78184c6eaea70,42,17,10,17579,,,0,"Make clean up of soft deletions configurable

Adds the following features to the command:
1) Be able to set minimum number of days to keep soft deletions
2) Clean unassociated projects
3) Soft delete secrets that are expired
4) Set verbose flag
5) Set the log file location

Documentation for running the command was also added.

This is the second CR for cleaning up the barbican database.
    1) Simple soft deletion clean up for barbican-db-manage.
    2) Make clean up configurable and add documentation.

Change-Id: I1b2360d967bf4b8378eda4766c7ef3113eedffad
Partially-implements: blueprint clean-db-soft-deletes
",git fetch https://review.opendev.org/openstack/barbican refs/changes/21/284821/10 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/cmd/test_db_cleanup.py', 'barbican/model/clean.py', 'barbican/cmd/db_manage.py']",3,e3ca1df88f87883ef396bf55397af7549d3fd3b8,bp/barbican-db-garbage-management," create_parser.add_argument( '--min_num_days_keep_soft_deletions', '-d', type=int, default=90, help='minimum number of days to keep soft deletions') create_parser.add_argument('--clean_unassociated_projects', '-p', action=""store_true"", help='remove projects that have no ' 'associated resources') create_parser.add_argument('--soft-delete-expired-secrets', '-e', action=""store_true"", help='soft delete expired secrets') create_parser.add_argument('--verbose', '-V', action='store_true', help='Show full information about the' ' cleanup') create_parser.add_argument('--log-file', '-L', default='/var/log/barbican/' 'barbican-clean.log', type=str, help='set log file location') BarbicanDBCleanCommands.clean( sql_url=args.dburl, min_num_days=args.min_num_days_keep_soft_deletions, do_clean_unassociated_projects=args.clean_unassociated_projects, do_soft_delete_expired_secrets=args.soft_delete_expired_secrets, verbose=args.verbose, log_file=args.log_file)", BarbicanDBCleanCommands.clean(args.dburl),387,28
openstack%2Fopenstack-ansible-os_ceilometer~master~If27e19e7c6bb2d20e7b0093a8d4e29c30952fb14,openstack/openstack-ansible-os_ceilometer,master,If27e19e7c6bb2d20e7b0093a8d4e29c30952fb14,Check for AODH host before adding alarm_connection,MERGED,2016-03-03 16:24:17.000000000,2016-03-04 16:48:48.000000000,2016-03-04 16:48:48.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 12807}]","[{'number': 1, 'created': '2016-03-03 16:24:17.000000000', 'files': ['templates/ceilometer.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/d9dfc53a4a401886b5619d81a1feaf72f797072a', 'message': 'Check for AODH host before adding alarm_connection\n\nCurrently the os_ceilometer role will configure ceilometer.conf to\ninclude a line in the [databases] section for alarm_connection no matter\nwhat, and it will default to looking for the aodh user in mongodb\nserving at localhost. If the user installs ceilometer but not aodh, this\nwill break the ceilometer service as the API will not start up while it\ntimes out looking for the unconfigured database. This patch ensures that\nthere are hosts configured for AODH before adding that line to the conf\nfile.\n\nChange-Id: If27e19e7c6bb2d20e7b0093a8d4e29c30952fb14\nCloses-bug: #1549426\n'}]",0,287959,d9dfc53a4a401886b5619d81a1feaf72f797072a,7,3,1,17275,,,0,"Check for AODH host before adding alarm_connection

Currently the os_ceilometer role will configure ceilometer.conf to
include a line in the [databases] section for alarm_connection no matter
what, and it will default to looking for the aodh user in mongodb
serving at localhost. If the user installs ceilometer but not aodh, this
will break the ceilometer service as the API will not start up while it
times out looking for the unconfigured database. This patch ensures that
there are hosts configured for AODH before adding that line to the conf
file.

Change-Id: If27e19e7c6bb2d20e7b0093a8d4e29c30952fb14
Closes-bug: #1549426
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/59/287959/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/ceilometer.conf.j2'],1,d9dfc53a4a401886b5619d81a1feaf72f797072a,bug/1549426,{% if groups['aodh_all'] is defined and groups['aodh_all'] | length > 0 %}{% endif %},,2,0
openstack%2Fcharm-cinder~master~I6d50531792a821101c3d808b0d2a2ba41faa2474,openstack/charm-cinder,master,I6d50531792a821101c3d808b0d2a2ba41faa2474,Rollup templates to drop unsupported releases,MERGED,2016-03-03 14:47:37.000000000,2016-03-04 16:48:40.000000000,2016-03-04 16:48:40.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-03 14:47:37.000000000', 'files': ['templates/grizzly/api-paste.ini', 'templates/folsom/api-paste.ini', 'templates/havana/api-paste.ini', 'templates/grizzly/cinder.conf', 'templates/cinder.conf'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/a9a5e1660091506f5c206acec5a5d3cb48c4bdbe', 'message': 'Rollup templates to drop unsupported releases\n\nFolsom, grizzly and havana have not been supported for some time;\nrollup any templates as required and drop unsupported series.\n\nChange-Id: I6d50531792a821101c3d808b0d2a2ba41faa2474\n'}]",0,287848,a9a5e1660091506f5c206acec5a5d3cb48c4bdbe,9,4,1,935,,,0,"Rollup templates to drop unsupported releases

Folsom, grizzly and havana have not been supported for some time;
rollup any templates as required and drop unsupported series.

Change-Id: I6d50531792a821101c3d808b0d2a2ba41faa2474
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/48/287848/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/grizzly/api-paste.ini', 'templates/folsom/api-paste.ini', 'templates/havana/api-paste.ini', 'templates/grizzly/cinder.conf', 'templates/cinder.conf']",5,a9a5e1660091506f5c206acec5a5d3cb48c4bdbe,rollup-templates,,"############################################################################### # [ WARNING ] # cinder configuration file maintained by Juju # local changes may be overwritten. ############################################################################### [DEFAULT] rootwrap_config = /etc/cinder/rootwrap.conf api_paste_confg = /etc/cinder/api-paste.ini iscsi_helper = tgtadm volume_name_template = volume-%s volume_group = cinder-volumes verbose = {{ verbose }} debug = {{ debug }} use_syslog = {{ use_syslog }} auth_strategy = keystone state_path = /var/lib/cinder lock_path = /var/lock/cinder volumes_dir = /var/lib/cinder/volumes {% include ""parts/database"" %} {% if rabbitmq_host %} notification_driver = cinder.openstack.common.notifier.rabbit_notifier control_exchange = cinder {% if rabbit_ssl_port %} rabbit_use_ssl=True rabbit_port={{ rabbit_ssl_port }} {% if rabbit_ssl_ca %} kombu_ssl_ca_certs={{rabbit_ssl_ca}} {% endif %} {% endif %} rabbit_host = {{ rabbitmq_host }} rabbit_userid = {{ rabbitmq_user }} rabbit_password = {{ rabbitmq_password }} rabbit_virtual_host = {{ rabbitmq_virtual_host }} {% endif -%} {% if volume_driver -%} volume_driver = {{ volume_driver }} {% endif -%} {% if rbd_pool -%} rbd_pool = {{ rbd_pool }} host = {{ host }} rbd_user = {{ rbd_user }} {% endif -%} {% if osapi_volume_listen_port -%} osapi_volume_listen_port = {{ osapi_volume_listen_port }} {% endif -%} {% if glance_api_servers -%} glance_api_servers = {{ glance_api_servers }} {% endif -%} {% if glance_api_version -%} glance_api_version = {{ glance_api_version }} {% endif -%} {% if region -%} os_region_name = {{ region }} {% endif -%} {% if user_config_flags -%} {% for key, value in user_config_flags.iteritems() -%} {{ key }} = {{ value }} {% endfor -%} {% endif -%} {% include ""parts/backends"" %} ",0,332
openstack%2Fcharm-ceilometer~master~I97377182fe28e3f7aa98784b537e1a353a58280d,openstack/charm-ceilometer,master,I97377182fe28e3f7aa98784b537e1a353a58280d,Remove templates for unsupported releases,MERGED,2016-03-04 11:53:28.000000000,2016-03-04 16:47:49.000000000,2016-03-04 16:47:49.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-03-04 11:53:28.000000000', 'files': ['templates/havana/ceilometer.conf', 'templates/grizzly/ceilometer.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/98d931fb7f3f281470ff62abf5aa467a3d79edf0', 'message': 'Remove templates for unsupported releases\n\nGrizzly and Havana have been unsupported for some time; remove\ntemplates as they are no longer tested or required.\n\nChange-Id: I97377182fe28e3f7aa98784b537e1a353a58280d\n'}]",0,288418,98d931fb7f3f281470ff62abf5aa467a3d79edf0,10,4,1,935,,,0,"Remove templates for unsupported releases

Grizzly and Havana have been unsupported for some time; remove
templates as they are no longer tested or required.

Change-Id: I97377182fe28e3f7aa98784b537e1a353a58280d
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/18/288418/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/havana/ceilometer.conf', 'templates/grizzly/ceilometer.conf']",2,98d931fb7f3f281470ff62abf5aa467a3d79edf0,rollup-configurations,,"# grizzly ############################################################################### # [ WARNING ] # ceilometer configuration file maintained by Juju # local changes may be overwritten. ############################################################################### [DEFAULT] debug = {{ debug }} verbose = {{ verbose }} use_syslog = {{ use_syslog }} metering_secret = {{ metering_secret }} metering_api_port = {{ port }} {% include ""parts/rabbitmq"" %} database_connection = mongodb://{{ db_host }}:{{ db_port }}/{{ db_name }} os_auth_url = {{ auth_protocol }}://{{ auth_host }}:{{ auth_port }}/v2.0 os_tenant_name = {{ admin_tenant_name }} os_username = {{ admin_user }} os_password = {{ admin_password }} logdir = /var/log/ceilometer [keystone_authtoken] auth_host = {{ auth_host }} auth_port = {{ auth_port }} auth_protocol = {{ auth_protocol }} admin_tenant_name = {{ admin_tenant_name }} admin_user = {{ admin_user }} admin_password = {{ admin_password }} ",0,57
